{"filename": "_get_gql_ops.py", "chunked_list": ["import httpx\n\n# update this url on next run\nurl = \"https://abs.twimg.com/responsive-web/client-web/api.f4ff3bfa.js\"\nscript = httpx.get(url).text\n\nops = \"\"\"\nSearchTimeline\nUserByRestId\nUserByScreenName", "UserByRestId\nUserByScreenName\nTweetDetail\nFollowers\nFollowing\nRetweeters\nFavoriters\nUserTweets\nUserTweetsAndReplies\nListLatestTweetsTimeline", "UserTweetsAndReplies\nListLatestTweetsTimeline\n\"\"\"\n\nops = [op.strip() for op in ops.split(\"\\n\") if op.strip()]\n\nfor x in ops:\n    idx = script.split(f'operationName:\"{x}\"')[0].split(\"queryId:\")[-1]\n    idx = idx.strip('\",')\n    print(f'OP_{x} = \"{idx}/{x}\"')", ""]}
{"filename": "twscrape/accounts_pool.py", "chunked_list": ["# ruff: noqa: E501\nimport asyncio\nimport sqlite3\nimport uuid\nfrom datetime import datetime, timezone\nfrom typing import TypedDict\n\nfrom fake_useragent import UserAgent\n\nfrom .account import Account", "\nfrom .account import Account\nfrom .db import execute, fetchall, fetchone\nfrom .logger import logger\nfrom .login import login\nfrom .utils import parse_cookies, utc_ts\n\n\nclass AccountInfo(TypedDict):\n    username: str\n    logged_in: bool\n    active: bool\n    last_used: datetime | None\n    total_req: int\n    error_msg: str | None", "class AccountInfo(TypedDict):\n    username: str\n    logged_in: bool\n    active: bool\n    last_used: datetime | None\n    total_req: int\n    error_msg: str | None\n\n\ndef guess_delim(line: str):\n    lp, rp = tuple([x.strip() for x in line.split(\"username\")])\n    return rp[0] if not lp else lp[-1]", "\ndef guess_delim(line: str):\n    lp, rp = tuple([x.strip() for x in line.split(\"username\")])\n    return rp[0] if not lp else lp[-1]\n\n\nclass AccountsPool:\n    # _order_by: str = \"RANDOM()\"\n    _order_by: str = \"username\"\n\n    def __init__(self, db_file=\"accounts.db\"):\n        self._db_file = db_file\n\n    async def load_from_file(self, filepath: str, line_format: str):\n        line_delim = guess_delim(line_format)\n        tokens = line_format.split(line_delim)\n\n        required = set([\"username\", \"password\", \"email\", \"email_password\"])\n        if not required.issubset(tokens):\n            raise ValueError(f\"Invalid line format: {line_format}\")\n\n        accounts = []\n        with open(filepath, \"r\") as f:\n            lines = f.read().split(\"\\n\")\n            lines = [x.strip() for x in lines if x.strip()]\n\n            for line in lines:\n                data = [x.strip() for x in line.split(line_delim)]\n                if len(data) < len(tokens):\n                    raise ValueError(f\"Invalid line: {line}\")\n\n                data = data[: len(tokens)]\n                vals = {k: v for k, v in zip(tokens, data) if k != \"_\"}\n                accounts.append(vals)\n\n        for x in accounts:\n            await self.add_account(**x)\n\n    async def add_account(\n        self,\n        username: str,\n        password: str,\n        email: str,\n        email_password: str,\n        user_agent: str | None = None,\n        proxy: str | None = None,\n        cookies: str | None = None,\n    ):\n        qs = \"SELECT * FROM accounts WHERE username = :username\"\n        rs = await fetchone(self._db_file, qs, {\"username\": username})\n        if rs:\n            logger.warning(f\"Account {username} already exists\")\n            return\n\n        account = Account(\n            username=username,\n            password=password,\n            email=email,\n            email_password=email_password,\n            user_agent=user_agent or UserAgent().safari,\n            active=False,\n            locks={},\n            stats={},\n            headers={},\n            cookies=parse_cookies(cookies) if cookies else {},\n            proxy=proxy,\n        )\n\n        if \"ct0\" in account.cookies:\n            account.active = True\n\n        await self.save(account)\n        logger.info(f\"Account {username} added successfully (active={account.active})\")\n\n    async def delete_accounts(self, usernames: str | list[str]):\n        usernames = usernames if isinstance(usernames, list) else [usernames]\n        usernames = list(set(usernames))\n        if not usernames:\n            logger.warning(\"No usernames provided\")\n            return\n\n        qs = f\"\"\"DELETE FROM accounts WHERE username IN ({','.join([f'\"{x}\"' for x in usernames])})\"\"\"\n        await execute(self._db_file, qs)\n\n    async def delete_inactive(self):\n        qs = \"DELETE FROM accounts WHERE active = false\"\n        await execute(self._db_file, qs)\n\n    async def get(self, username: str):\n        qs = \"SELECT * FROM accounts WHERE username = :username\"\n        rs = await fetchone(self._db_file, qs, {\"username\": username})\n        if not rs:\n            raise ValueError(f\"Account {username} not found\")\n        return Account.from_rs(rs)\n\n    async def get_all(self):\n        qs = \"SELECT * FROM accounts\"\n        rs = await fetchall(self._db_file, qs)\n        return [Account.from_rs(x) for x in rs]\n\n    async def save(self, account: Account):\n        data = account.to_rs()\n        cols = list(data.keys())\n\n        qs = f\"\"\"\n        INSERT INTO accounts ({\",\".join(cols)}) VALUES ({\",\".join([f\":{x}\" for x in cols])})\n        ON CONFLICT(username) DO UPDATE SET {\",\".join([f\"{x}=excluded.{x}\" for x in cols])}\n        \"\"\"\n        await execute(self._db_file, qs, data)\n\n    async def login(self, account: Account, email_first: bool = False):\n        try:\n            await login(account, email_first=email_first)\n            logger.info(f\"Logged in to {account.username} successfully\")\n            return True\n        except Exception as e:\n            logger.error(f\"Error logging in to {account.username}: {e}\")\n            return False\n        finally:\n            await self.save(account)\n\n    async def login_all(self, email_first=False):\n        qs = \"SELECT * FROM accounts WHERE active = false AND error_msg IS NULL\"\n        rs = await fetchall(self._db_file, qs)\n\n        accounts = [Account.from_rs(rs) for rs in rs]\n        # await asyncio.gather(*[login(x) for x in self.accounts])\n\n        counter = {\"total\": len(accounts), \"success\": 0, \"failed\": 0}\n        for i, x in enumerate(accounts, start=1):\n            logger.info(f\"[{i}/{len(accounts)}] Logging in {x.username} - {x.email}\")\n            status = await self.login(x, email_first=email_first)\n            counter[\"success\" if status else \"failed\"] += 1\n        return counter\n\n    async def relogin(self, usernames: str | list[str], email_first=False):\n        usernames = usernames if isinstance(usernames, list) else [usernames]\n        usernames = list(set(usernames))\n        if not usernames:\n            logger.warning(\"No usernames provided\")\n            return\n\n        qs = f\"\"\"\n        UPDATE accounts SET\n            active = false,\n            locks = json_object(),\n            last_used = NULL,\n            error_msg = NULL,\n            headers = json_object(),\n            cookies = json_object(),\n            user_agent = \"{UserAgent().safari}\"\n        WHERE username IN ({','.join([f'\"{x}\"' for x in usernames])})\n        \"\"\"\n\n        await execute(self._db_file, qs)\n        await self.login_all(email_first=email_first)\n\n    async def relogin_failed(self, email_first=False):\n        qs = \"SELECT username FROM accounts WHERE active = false AND error_msg IS NOT NULL\"\n        rs = await fetchall(self._db_file, qs)\n        await self.relogin([x[\"username\"] for x in rs], email_first=email_first)\n\n    async def reset_locks(self):\n        qs = \"UPDATE accounts SET locks = json_object()\"\n        await execute(self._db_file, qs)\n\n    async def set_active(self, username: str, active: bool):\n        qs = \"UPDATE accounts SET active = :active WHERE username = :username\"\n        await execute(self._db_file, qs, {\"username\": username, \"active\": active})\n\n    async def lock_until(self, username: str, queue: str, unlock_at: int, req_count=0):\n        qs = f\"\"\"\n        UPDATE accounts SET\n            locks = json_set(locks, '$.{queue}', datetime({unlock_at}, 'unixepoch')),\n            stats = json_set(stats, '$.{queue}', COALESCE(json_extract(stats, '$.{queue}'), 0) + {req_count}),\n            last_used = datetime({utc_ts()}, 'unixepoch')\n        WHERE username = :username\n        \"\"\"\n        await execute(self._db_file, qs, {\"username\": username})\n\n    async def unlock(self, username: str, queue: str, req_count=0):\n        qs = f\"\"\"\n        UPDATE accounts SET\n            locks = json_remove(locks, '$.{queue}'),\n            stats = json_set(stats, '$.{queue}', COALESCE(json_extract(stats, '$.{queue}'), 0) + {req_count}),\n            last_used = datetime({utc_ts()}, 'unixepoch')\n        WHERE username = :username\n        \"\"\"\n        await execute(self._db_file, qs, {\"username\": username})\n\n    async def get_for_queue(self, queue: str):\n        q1 = f\"\"\"\n        SELECT username FROM accounts\n        WHERE active = true AND (\n            locks IS NULL\n            OR json_extract(locks, '$.{queue}') IS NULL\n            OR json_extract(locks, '$.{queue}') < datetime('now')\n        )\n        ORDER BY {self._order_by}\n        LIMIT 1\n        \"\"\"\n\n        if int(sqlite3.sqlite_version_info[1]) >= 35:\n            qs = f\"\"\"\n            UPDATE accounts SET\n                locks = json_set(locks, '$.{queue}', datetime('now', '+15 minutes')),\n                last_used = datetime({utc_ts()}, 'unixepoch')\n            WHERE username = ({q1})\n            RETURNING *\n            \"\"\"\n            rs = await fetchone(self._db_file, qs)\n        else:\n            tx = uuid.uuid4().hex\n            qs = f\"\"\"\n            UPDATE accounts SET\n                locks = json_set(locks, '$.{queue}', datetime('now', '+15 minutes')),\n                last_used = datetime({utc_ts()}, 'unixepoch'),\n                _tx = '{tx}'\n            WHERE username = ({q1})\n            \"\"\"\n            await execute(self._db_file, qs)\n\n            qs = f\"SELECT * FROM accounts WHERE _tx = '{tx}'\"\n            rs = await fetchone(self._db_file, qs)\n\n        return Account.from_rs(rs) if rs else None\n\n    async def get_for_queue_or_wait(self, queue: str) -> Account:\n        msg_shown = False\n        while True:\n            account = await self.get_for_queue(queue)\n            if not account:\n                if not msg_shown:\n                    nat = await self.next_available_at(queue)\n                    msg = f'No account available for queue \"{queue}\". Next available at {nat}'\n                    logger.info(msg)\n                    msg_shown = True\n                await asyncio.sleep(5)\n                continue\n            else:\n                if msg_shown:\n                    logger.info(f\"Account available for queue {queue}\")\n\n            return account\n\n    async def next_available_at(self, queue: str):\n        qs = f\"\"\"\n        SELECT json_extract(locks, '$.\"{queue}\"') as lock_until\n        FROM accounts\n        WHERE active = true AND json_extract(locks, '$.\"{queue}\"') IS NOT NULL\n        ORDER BY lock_until ASC\n        LIMIT 1\n        \"\"\"\n        rs = await fetchone(self._db_file, qs)\n        if rs:\n            now = datetime.utcnow().replace(tzinfo=timezone.utc)\n            trg = datetime.fromisoformat(rs[0]).replace(tzinfo=timezone.utc)\n            if trg < now:\n                return \"now\"\n\n            at_local = datetime.now() + (trg - now)\n            return at_local.strftime(\"%H:%M:%S\")\n\n        return \"none\"\n\n    async def mark_banned(self, username: str, error_msg: str):\n        qs = \"\"\"\n        UPDATE accounts SET active = false, error_msg = :error_msg\n        WHERE username = :username\n        \"\"\"\n        await execute(self._db_file, qs, {\"username\": username, \"error_msg\": error_msg})\n\n    async def stats(self):\n        def locks_count(queue: str):\n            return f\"\"\"\n            SELECT COUNT(*) FROM accounts\n            WHERE json_extract(locks, '$.{queue}') IS NOT NULL\n                AND json_extract(locks, '$.{queue}') > datetime('now')\n            \"\"\"\n\n        qs = \"SELECT DISTINCT(f.key) as k from accounts, json_each(locks) f\"\n        rs = await fetchall(self._db_file, qs)\n        gql_ops = [x[\"k\"] for x in rs]\n\n        config = [\n            (\"total\", \"SELECT COUNT(*) FROM accounts\"),\n            (\"active\", \"SELECT COUNT(*) FROM accounts WHERE active = true\"),\n            (\"inactive\", \"SELECT COUNT(*) FROM accounts WHERE active = false\"),\n            *[(f\"locked_{x}\", locks_count(x)) for x in gql_ops],\n        ]\n\n        qs = f\"SELECT {','.join([f'({q}) as {k}' for k, q in config])}\"\n        rs = await fetchone(self._db_file, qs)\n        return dict(rs) if rs else {}\n\n    async def accounts_info(self):\n        accounts = await self.get_all()\n\n        items: list[AccountInfo] = []\n        for x in accounts:\n            item: AccountInfo = {\n                \"username\": x.username,\n                \"logged_in\": (x.headers or {}).get(\"authorization\", \"\") != \"\",\n                \"active\": x.active,\n                \"last_used\": x.last_used,\n                \"total_req\": sum(x.stats.values()),\n                \"error_msg\": str(x.error_msg)[0:60],\n            }\n            items.append(item)\n\n        old_time = datetime(1970, 1, 1).replace(tzinfo=timezone.utc)\n        items = sorted(items, key=lambda x: x[\"username\"].lower())\n        items = sorted(\n            items,\n            key=lambda x: x[\"last_used\"] or old_time if x[\"total_req\"] > 0 else old_time,\n            reverse=True,\n        )\n        items = sorted(items, key=lambda x: x[\"active\"], reverse=True)\n        # items = sorted(items, key=lambda x: x[\"total_req\"], reverse=True)\n        return items", ""]}
{"filename": "twscrape/account.py", "chunked_list": ["import json\nimport sqlite3\nfrom dataclasses import asdict, dataclass, field\nfrom datetime import datetime\n\nfrom httpx import AsyncClient, AsyncHTTPTransport\n\nfrom .constants import TOKEN\nfrom .models import JSONTrait\nfrom .utils import from_utciso", "from .models import JSONTrait\nfrom .utils import from_utciso\n\n\n@dataclass\nclass Account(JSONTrait):\n    username: str\n    password: str\n    email: str\n    email_password: str\n    user_agent: str\n    active: bool\n    locks: dict[str, datetime] = field(default_factory=dict)  # queue: datetime\n    stats: dict[str, int] = field(default_factory=dict)  # queue: requests\n    headers: dict[str, str] = field(default_factory=dict)\n    cookies: dict[str, str] = field(default_factory=dict)\n    proxy: str | None = None\n    error_msg: str | None = None\n    last_used: datetime | None = None\n    _tx: str | None = None\n\n    @staticmethod\n    def from_rs(rs: sqlite3.Row):\n        doc = dict(rs)\n        doc[\"locks\"] = {k: from_utciso(v) for k, v in json.loads(doc[\"locks\"]).items()}\n        doc[\"stats\"] = {k: v for k, v in json.loads(doc[\"stats\"]).items() if isinstance(v, int)}\n        doc[\"headers\"] = json.loads(doc[\"headers\"])\n        doc[\"cookies\"] = json.loads(doc[\"cookies\"])\n        doc[\"active\"] = bool(doc[\"active\"])\n        doc[\"last_used\"] = from_utciso(doc[\"last_used\"]) if doc[\"last_used\"] else None\n        return Account(**doc)\n\n    def to_rs(self):\n        rs = asdict(self)\n        rs[\"locks\"] = json.dumps(rs[\"locks\"], default=lambda x: x.isoformat())\n        rs[\"stats\"] = json.dumps(rs[\"stats\"])\n        rs[\"headers\"] = json.dumps(rs[\"headers\"])\n        rs[\"cookies\"] = json.dumps(rs[\"cookies\"])\n        rs[\"last_used\"] = rs[\"last_used\"].isoformat() if rs[\"last_used\"] else None\n        return rs\n\n    def make_client(self) -> AsyncClient:\n        transport = AsyncHTTPTransport(retries=2)\n        client = AsyncClient(proxies=self.proxy, follow_redirects=True, transport=transport)\n\n        # saved from previous usage\n        client.cookies.update(self.cookies)\n        client.headers.update(self.headers)\n\n        # default settings\n        client.headers[\"user-agent\"] = self.user_agent\n        client.headers[\"content-type\"] = \"application/json\"\n        client.headers[\"authorization\"] = TOKEN\n        client.headers[\"x-twitter-active-user\"] = \"yes\"\n        client.headers[\"x-twitter-client-language\"] = \"en\"\n\n        if \"ct0\" in client.cookies:\n            client.headers[\"x-csrf-token\"] = client.cookies[\"ct0\"]\n\n        return client", ""]}
{"filename": "twscrape/models.py", "chunked_list": ["import email.utils\nimport json\nimport os\nimport random\nimport re\nimport string\nimport traceback\nfrom dataclasses import asdict, dataclass, field\nfrom datetime import datetime\nfrom typing import Generator, Optional", "from datetime import datetime\nfrom typing import Generator, Optional\n\nimport httpx\n\nfrom .logger import logger\nfrom .utils import find_item, get_or, int_or_none, to_old_rep\n\n\n@dataclass\nclass JSONTrait:\n    def dict(self):\n        return asdict(self)\n\n    def json(self):\n        return json.dumps(self.dict(), default=str)", "\n@dataclass\nclass JSONTrait:\n    def dict(self):\n        return asdict(self)\n\n    def json(self):\n        return json.dumps(self.dict(), default=str)\n\n", "\n\n@dataclass\nclass Coordinates(JSONTrait):\n    longitude: float\n    latitude: float\n\n    @staticmethod\n    def parse(tw_obj: dict):\n        if tw_obj.get(\"coordinates\"):\n            coords = tw_obj[\"coordinates\"][\"coordinates\"]\n            return Coordinates(coords[0], coords[1])\n        if tw_obj.get(\"geo\"):\n            coords = tw_obj[\"geo\"][\"coordinates\"]\n            return Coordinates(coords[1], coords[0])\n        return None", "\n\n@dataclass\nclass Place(JSONTrait):\n    id: str\n    fullName: str\n    name: str\n    type: str\n    country: str\n    countryCode: str\n\n    @staticmethod\n    def parse(obj: dict):\n        return Place(\n            id=obj[\"id\"],\n            fullName=obj[\"full_name\"],\n            name=obj[\"name\"],\n            type=obj[\"place_type\"],\n            country=obj[\"country\"],\n            countryCode=obj[\"country_code\"],\n        )", "\n\n@dataclass\nclass TextLink(JSONTrait):\n    url: str\n    text: str | None\n    tcourl: str | None\n\n    @staticmethod\n    def parse(obj: dict):\n        tmp = TextLink(\n            url=obj.get(\"expanded_url\", None),\n            text=obj.get(\"display_url\", None),\n            tcourl=obj.get(\"url\", None),\n        )\n\n        if tmp.url is None or tmp.tcourl is None:\n            return None\n\n        return tmp", "\n\n@dataclass\nclass UserRef(JSONTrait):\n    id: int\n    username: str\n    displayname: str\n    _type: str = \"snscrape.modules.twitter.UserRef\"\n\n    @staticmethod\n    def parse(obj: dict):\n        return UserRef(id=int(obj[\"id_str\"]), username=obj[\"screen_name\"], displayname=obj[\"name\"])", "\n\n@dataclass\nclass User(JSONTrait):\n    id: int\n    id_str: str\n    url: str\n    username: str\n    displayname: str\n    rawDescription: str\n    created: datetime\n    followersCount: int\n    friendsCount: int\n    statusesCount: int\n    favouritesCount: int\n    listedCount: int\n    mediaCount: int\n    location: str\n    profileImageUrl: str\n    profileBannerUrl: str | None = None\n    protected: bool | None = None\n    verified: bool | None = None\n    blue: bool | None = None\n    blueType: str | None = None\n    descriptionLinks: list[TextLink] = field(default_factory=list)\n    _type: str = \"snscrape.modules.twitter.User\"\n\n    # todo:\n    # link: typing.Optional[TextLink] = None\n    # label: typing.Optional[\"UserLabel\"] = None\n\n    @staticmethod\n    def parse(obj: dict, res=None):\n        return User(\n            id=int(obj[\"id_str\"]),\n            id_str=obj[\"id_str\"],\n            url=f'https://twitter.com/{obj[\"screen_name\"]}',\n            username=obj[\"screen_name\"],\n            displayname=obj[\"name\"],\n            rawDescription=obj[\"description\"],\n            created=email.utils.parsedate_to_datetime(obj[\"created_at\"]),\n            followersCount=obj[\"followers_count\"],\n            friendsCount=obj[\"friends_count\"],\n            statusesCount=obj[\"statuses_count\"],\n            favouritesCount=obj[\"favourites_count\"],\n            listedCount=obj[\"listed_count\"],\n            mediaCount=obj[\"media_count\"],\n            location=obj[\"location\"],\n            profileImageUrl=obj[\"profile_image_url_https\"],\n            profileBannerUrl=obj.get(\"profile_banner_url\"),\n            verified=obj.get(\"verified\"),\n            blue=obj.get(\"is_blue_verified\"),\n            blueType=obj.get(\"verified_type\"),\n            protected=obj.get(\"protected\"),\n            descriptionLinks=_parse_links(obj, [\"entities.description.urls\", \"entities.url.urls\"]),\n        )", "\n\n@dataclass\nclass Tweet(JSONTrait):\n    id: int\n    id_str: str\n    url: str\n    date: datetime\n    user: User\n    lang: str\n    rawContent: str\n    replyCount: int\n    retweetCount: int\n    likeCount: int\n    quoteCount: int\n    conversationId: int\n    hashtags: list[str]\n    cashtags: list[str]\n    mentionedUsers: list[UserRef]\n    links: list[TextLink]\n    viewCount: int | None = None\n    retweetedTweet: Optional[\"Tweet\"] = None\n    quotedTweet: Optional[\"Tweet\"] = None\n    place: Optional[Place] = None\n    coordinates: Optional[Coordinates] = None\n    inReplyToTweetId: int | None = None\n    inReplyToUser: UserRef | None = None\n    source: str | None = None\n    sourceUrl: str | None = None\n    sourceLabel: str | None = None\n    media: Optional[\"Media\"] = None\n    _type: str = \"snscrape.modules.twitter.Tweet\"\n\n    # todo:\n    # renderedContent: str\n    # card: typing.Optional[\"Card\"] = None\n    # vibe: typing.Optional[\"Vibe\"] = None\n\n    @staticmethod\n    def parse(obj: dict, res: dict):\n        tw_usr = User.parse(res[\"users\"][obj[\"user_id_str\"]])\n\n        rt_id = _first(obj, [\"retweeted_status_id_str\", \"retweeted_status_result.result.rest_id\"])\n        rt_obj = get_or(res, f\"tweets.{rt_id}\")\n\n        qt_id = _first(obj, [\"quoted_status_id_str\", \"quoted_status_result.result.rest_id\"])\n        qt_obj = get_or(res, f\"tweets.{qt_id}\")\n\n        doc = Tweet(\n            id=int(obj[\"id_str\"]),\n            id_str=obj[\"id_str\"],\n            url=f'https://twitter.com/{tw_usr.username}/status/{obj[\"id_str\"]}',\n            date=email.utils.parsedate_to_datetime(obj[\"created_at\"]),\n            user=tw_usr,\n            lang=obj[\"lang\"],\n            rawContent=get_or(obj, \"note_tweet.note_tweet_results.result.text\", obj[\"full_text\"]),\n            replyCount=obj[\"reply_count\"],\n            retweetCount=obj[\"retweet_count\"],\n            likeCount=obj[\"favorite_count\"],\n            quoteCount=obj[\"quote_count\"],\n            conversationId=int(obj[\"conversation_id_str\"]),\n            hashtags=[x[\"text\"] for x in get_or(obj, \"entities.hashtags\", [])],\n            cashtags=[x[\"text\"] for x in get_or(obj, \"entities.symbols\", [])],\n            mentionedUsers=[UserRef.parse(x) for x in get_or(obj, \"entities.user_mentions\", [])],\n            links=_parse_links(obj, [\"entities.urls\"]),\n            viewCount=_get_views(obj, rt_obj or {}),\n            retweetedTweet=Tweet.parse(rt_obj, res) if rt_obj else None,\n            quotedTweet=Tweet.parse(qt_obj, res) if qt_obj else None,\n            place=Place.parse(obj[\"place\"]) if obj.get(\"place\") else None,\n            coordinates=Coordinates.parse(obj),\n            inReplyToTweetId=int_or_none(obj, \"in_reply_to_status_id_str\"),\n            inReplyToUser=_get_reply_user(obj, res),\n            source=obj.get(\"source\", None),\n            sourceUrl=_get_source_url(obj),\n            sourceLabel=_get_source_label(obj),\n            media=Media.parse(obj),\n        )\n\n        # issue #42 \u2013 restore full rt text\n        rt = doc.retweetedTweet\n        if rt is not None and rt.user is not None and doc.rawContent.endswith(\"\u2026\"):\n            prefix = f\"RT @{rt.user.username}: \"\n            rt_msg = f\"{prefix}{rt.rawContent}\"\n            if doc.rawContent != rt_msg and doc.rawContent.startswith(prefix):\n                doc.rawContent = rt_msg\n\n        return doc", "\n\n@dataclass\nclass MediaPhoto(JSONTrait):\n    url: str\n\n    @staticmethod\n    def parse(obj: dict):\n        return MediaPhoto(url=obj[\"media_url_https\"])\n", "\n\n@dataclass\nclass MediaVideo(JSONTrait):\n    thumbnailUrl: str\n    variants: list[\"MediaVideoVariant\"]\n    duration: int\n    views: int | None = None\n\n    @staticmethod\n    def parse(obj: dict):\n        return MediaVideo(\n            thumbnailUrl=obj[\"media_url_https\"],\n            variants=[\n                MediaVideoVariant.parse(x) for x in obj[\"video_info\"][\"variants\"] if \"bitrate\" in x\n            ],\n            duration=obj[\"video_info\"][\"duration_millis\"],\n            views=int_or_none(obj, \"mediaStats.viewCount\"),\n        )", "\n\n@dataclass\nclass MediaAnimated(JSONTrait):\n    thumbnailUrl: str\n    videoUrl: str\n\n    @staticmethod\n    def parse(obj: dict):\n        try:\n            return MediaAnimated(\n                thumbnailUrl=obj[\"media_url_https\"],\n                videoUrl=obj[\"video_info\"][\"variants\"][0][\"url\"],\n            )\n        except KeyError:\n            return None", "\n\n@dataclass\nclass MediaVideoVariant(JSONTrait):\n    contentType: str\n    bitrate: int\n    url: str\n\n    @staticmethod\n    def parse(obj: dict):\n        return MediaVideoVariant(\n            contentType=obj[\"content_type\"],\n            bitrate=obj[\"bitrate\"],\n            url=obj[\"url\"],\n        )", "\n\n@dataclass\nclass Media(JSONTrait):\n    photos: list[MediaPhoto] = field(default_factory=list)\n    videos: list[MediaVideo] = field(default_factory=list)\n    animated: list[MediaAnimated] = field(default_factory=list)\n\n    @staticmethod\n    def parse(obj: dict):\n        photos: list[MediaPhoto] = []\n        videos: list[MediaVideo] = []\n        animated: list[MediaAnimated] = []\n\n        for x in get_or(obj, \"extended_entities.media\", []):\n            if x[\"type\"] == \"video\":\n                if video := MediaVideo.parse(x):\n                    videos.append(video)\n                continue\n\n            if x[\"type\"] == \"photo\":\n                if photo := MediaPhoto.parse(x):\n                    photos.append(photo)\n                continue\n\n            if x[\"type\"] == \"animated_gif\":\n                if animated_gif := MediaAnimated.parse(x):\n                    animated.append(animated_gif)\n                continue\n\n            logger.warning(f\"Unknown media type: {x['type']}: {json.dumps(x)}\")\n\n        return Media(photos=photos, videos=videos, animated=animated)", "\n\n# internal helpers\n\n\ndef _get_reply_user(tw_obj: dict, res: dict):\n    user_id = tw_obj.get(\"in_reply_to_user_id_str\", None)\n    if user_id is None:\n        return None\n\n    if user_id in res[\"users\"]:\n        return UserRef.parse(res[\"users\"][user_id])\n\n    mentions = get_or(tw_obj, \"entities.user_mentions\", [])\n    mention = find_item(mentions, lambda x: x[\"id_str\"] == tw_obj[\"in_reply_to_user_id_str\"])\n    if mention:\n        return UserRef.parse(mention)\n\n    # todo: user not found in reply (probably deleted or hidden)\n    return None", "\n\ndef _get_source_url(tw_obj: dict):\n    source = tw_obj.get(\"source\", None)\n    if source and (match := re.search(r'href=[\\'\"]?([^\\'\" >]+)', source)):\n        return str(match.group(1))\n    return None\n\n\ndef _get_source_label(tw_obj: dict):\n    source = tw_obj.get(\"source\", None)\n    if source and (match := re.search(r\">([^<]*)<\", source)):\n        return str(match.group(1))\n    return None", "\ndef _get_source_label(tw_obj: dict):\n    source = tw_obj.get(\"source\", None)\n    if source and (match := re.search(r\">([^<]*)<\", source)):\n        return str(match.group(1))\n    return None\n\n\ndef _parse_links(obj: dict, paths: list[str]):\n    links = []\n    for x in paths:\n        links.extend(get_or(obj, x, []))\n\n    links = [TextLink.parse(x) for x in links]\n    links = [x for x in links if x is not None]\n    return links", "def _parse_links(obj: dict, paths: list[str]):\n    links = []\n    for x in paths:\n        links.extend(get_or(obj, x, []))\n\n    links = [TextLink.parse(x) for x in links]\n    links = [x for x in links if x is not None]\n    return links\n\n\ndef _first(obj: dict, paths: list[str]):\n    for x in paths:\n        cid = get_or(obj, x, None)\n        if cid is not None:\n            return cid\n    return None", "\n\ndef _first(obj: dict, paths: list[str]):\n    for x in paths:\n        cid = get_or(obj, x, None)\n        if cid is not None:\n            return cid\n    return None\n\n\ndef _get_views(obj: dict, rt_obj: dict):\n    for x in [obj, rt_obj]:\n        for y in [\"ext_views.count\", \"views.count\"]:\n            k = int_or_none(x, y)\n            if k is not None:\n                return k\n    return None", "\n\ndef _get_views(obj: dict, rt_obj: dict):\n    for x in [obj, rt_obj]:\n        for y in [\"ext_views.count\", \"views.count\"]:\n            k = int_or_none(x, y)\n            if k is not None:\n                return k\n    return None\n", "\n\ndef _write_dump(kind: str, e: Exception, x: dict, obj: dict):\n    uniq = \"\".join(random.choice(string.ascii_lowercase) for _ in range(5))\n    time = datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n    dumpfile = f\"/tmp/twscrape/twscrape_parse_error_{time}_{uniq}.txt\"\n    os.makedirs(os.path.dirname(dumpfile), exist_ok=True)\n\n    with open(dumpfile, \"w\") as fp:\n        msg = [\n            f\"Error parsing {kind}. Error: {type(e)}\",\n            traceback.format_exc(),\n            json.dumps(x, default=str),\n            json.dumps(obj, default=str),\n        ]\n        fp.write(\"\\n\\n\".join(msg))\n\n    logger.error(f\"Failed to parse response of {kind}, writing dump to {dumpfile}\")", "\n\ndef _parse_items(rep: httpx.Response, kind: str, limit: int = -1):\n    if kind == \"user\":\n        Cls, key = User, \"users\"\n    elif kind == \"tweet\":\n        Cls, key = Tweet, \"tweets\"\n    else:\n        raise ValueError(f\"Invalid kind: {kind}\")\n\n    # check for dict, because httpx.Response can be mocked in tests with different type\n    res = rep if isinstance(rep, dict) else rep.json()\n    obj = to_old_rep(res)\n\n    ids = set()\n    for x in obj[key].values():\n        if limit != -1 and len(ids) >= limit:\n            # todo: move somewhere in configuration like force_limit\n            # https://github.com/vladkens/twscrape/issues/26#issuecomment-1656875132\n            # break\n            pass\n\n        try:\n            tmp = Cls.parse(x, obj)\n            if tmp.id not in ids:\n                ids.add(tmp.id)\n                yield tmp\n        except Exception as e:\n            _write_dump(kind, e, x, obj)\n            continue", "\n\n# public helpers\n\n\ndef parse_tweets(rep: httpx.Response, limit: int = -1) -> Generator[Tweet, None, None]:\n    return _parse_items(rep, \"tweet\", limit)  # type: ignore\n\n\ndef parse_users(rep: httpx.Response, limit: int = -1) -> Generator[User, None, None]:\n    return _parse_items(rep, \"user\", limit)  # type: ignore", "\ndef parse_users(rep: httpx.Response, limit: int = -1) -> Generator[User, None, None]:\n    return _parse_items(rep, \"user\", limit)  # type: ignore\n\n\ndef parse_tweet(rep: httpx.Response, twid: int) -> Tweet | None:\n    try:\n        docs = list(parse_tweets(rep))\n        for x in docs:\n            if x.id == twid:\n                return x\n        return None\n    except Exception as e:\n        logger.error(f\"Failed to parse tweet {twid} - {type(e)}:\\n{traceback.format_exc()}\")\n        return None", "\n\ndef parse_user(rep: httpx.Response) -> User | None:\n    try:\n        docs = list(parse_users(rep))\n        if len(docs) == 1:\n            return docs[0]\n        return None\n    except Exception as e:\n        logger.error(f\"Failed to parse user - {type(e)}:\\n{traceback.format_exc()}\")\n        return None", ""]}
{"filename": "twscrape/logger.py", "chunked_list": ["import sys\nfrom typing import Literal\n\nfrom loguru import logger\n\n_LEVELS = Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n_LOG_LEVEL: _LEVELS = \"INFO\"\n\n\ndef set_log_level(level: _LEVELS):\n    global _LOG_LEVEL\n    _LOG_LEVEL = level", "\ndef set_log_level(level: _LEVELS):\n    global _LOG_LEVEL\n    _LOG_LEVEL = level\n\n\nlogger.remove()\nlogger.add(sys.stderr, filter=lambda r: r[\"level\"].no >= logger.level(_LOG_LEVEL).no)\n", ""]}
{"filename": "twscrape/db.py", "chunked_list": ["import asyncio\nimport sqlite3\nfrom collections import defaultdict\n\nimport aiosqlite\n\nfrom .logger import logger\n\nMIN_SQLITE_VERSION = \"3.34\"\n", "MIN_SQLITE_VERSION = \"3.34\"\n\n\ndef lock_retry(max_retries=5, delay=1):\n    def decorator(func):\n        async def wrapper(*args, **kwargs):\n            for i in range(max_retries):\n                try:\n                    return await func(*args, **kwargs)\n                except sqlite3.OperationalError as e:\n                    if i == max_retries - 1 or \"database is locked\" not in str(e):\n                        raise e\n\n                    # print(f\"Retrying in {delay} second(s) ({i+1}/{max_retries})\")\n                    await asyncio.sleep(delay)\n\n        return wrapper\n\n    return decorator", "\n\nasync def get_sqlite_version():\n    async with aiosqlite.connect(\":memory:\") as db:\n        async with db.execute(\"SELECT SQLITE_VERSION()\") as cur:\n            rs = await cur.fetchone()\n            return rs[0] if rs else \"3.0.0\"\n\n\nasync def check_version():", "\nasync def check_version():\n    ver = await get_sqlite_version()\n    ver = \".\".join(ver.split(\".\")[:2])\n\n    if ver < MIN_SQLITE_VERSION:\n        msg = f\"SQLite version '{ver}' is too old, please upgrade to {MIN_SQLITE_VERSION}+\"\n        raise SystemError(msg)\n\n", "\n\nasync def migrate(db: aiosqlite.Connection):\n    async with db.execute(\"PRAGMA user_version\") as cur:\n        rs = await cur.fetchone()\n        uv = rs[0] if rs else 0\n\n    async def v1():\n        qs = \"\"\"\n        CREATE TABLE IF NOT EXISTS accounts (", "        qs = \"\"\"\n        CREATE TABLE IF NOT EXISTS accounts (\n            username TEXT PRIMARY KEY NOT NULL COLLATE NOCASE,\n            password TEXT NOT NULL,\n            email TEXT NOT NULL COLLATE NOCASE,\n            email_password TEXT NOT NULL,\n            user_agent TEXT NOT NULL,\n            active BOOLEAN DEFAULT FALSE NOT NULL,\n            locks TEXT DEFAULT '{}' NOT NULL,\n            headers TEXT DEFAULT '{}' NOT NULL,", "            locks TEXT DEFAULT '{}' NOT NULL,\n            headers TEXT DEFAULT '{}' NOT NULL,\n            cookies TEXT DEFAULT '{}' NOT NULL,\n            proxy TEXT DEFAULT NULL,\n            error_msg TEXT DEFAULT NULL\n        );\"\"\"\n        await db.execute(qs)\n\n    async def v2():\n        await db.execute(\"ALTER TABLE accounts ADD COLUMN stats TEXT DEFAULT '{}' NOT NULL\")", "    async def v2():\n        await db.execute(\"ALTER TABLE accounts ADD COLUMN stats TEXT DEFAULT '{}' NOT NULL\")\n        await db.execute(\"ALTER TABLE accounts ADD COLUMN last_used TEXT DEFAULT NULL\")\n\n    async def v3():\n        await db.execute(\"ALTER TABLE accounts ADD COLUMN _tx TEXT DEFAULT NULL\")\n\n    migrations = {\n        1: v1,\n        2: v2,", "        1: v1,\n        2: v2,\n        3: v3,\n    }\n\n    # logger.debug(f\"Current migration v{uv} (latest v{len(migrations)})\")\n    for i in range(uv + 1, len(migrations) + 1):\n        logger.info(f\"Running migration to v{i}\")\n        try:\n            await migrations[i]()\n        except sqlite3.OperationalError as e:\n            if \"duplicate column name\" not in str(e):\n                raise e\n\n        await db.execute(f\"PRAGMA user_version = {i}\")\n        await db.commit()", "\n\nclass DB:\n    _init_queries: defaultdict[str, list[str]] = defaultdict(list)\n    _init_once: defaultdict[str, bool] = defaultdict(bool)\n\n    def __init__(self, db_path):\n        self.db_path = db_path\n        self.conn = None\n\n    async def __aenter__(self):\n        await check_version()\n        db = await aiosqlite.connect(self.db_path)\n        db.row_factory = aiosqlite.Row\n\n        if not self._init_once[self.db_path]:\n            await migrate(db)\n            self._init_once[self.db_path] = True\n\n        self.conn = db\n        return db\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        if self.conn:\n            await self.conn.commit()\n            await self.conn.close()", "\n\n@lock_retry()\nasync def execute(db_path: str, qs: str, params: dict | None = None):\n    async with DB(db_path) as db:\n        await db.execute(qs, params)\n\n\n@lock_retry()\nasync def fetchone(db_path: str, qs: str, params: dict | None = None):", "@lock_retry()\nasync def fetchone(db_path: str, qs: str, params: dict | None = None):\n    async with DB(db_path) as db:\n        async with db.execute(qs, params) as cur:\n            row = await cur.fetchone()\n            return row\n\n\n@lock_retry()\nasync def fetchall(db_path: str, qs: str, params: dict | None = None):", "@lock_retry()\nasync def fetchall(db_path: str, qs: str, params: dict | None = None):\n    async with DB(db_path) as db:\n        async with db.execute(qs, params) as cur:\n            rows = await cur.fetchall()\n            return rows\n\n\n@lock_retry()\nasync def executemany(db_path: str, qs: str, params: list[dict]):", "@lock_retry()\nasync def executemany(db_path: str, qs: str, params: list[dict]):\n    async with DB(db_path) as db:\n        await db.executemany(qs, params)\n"]}
{"filename": "twscrape/api.py", "chunked_list": ["# ruff: noqa: F405\nfrom httpx import Response\n\nfrom .accounts_pool import AccountsPool\nfrom .constants import *  # noqa: F403\nfrom .logger import set_log_level\nfrom .models import parse_tweet, parse_tweets, parse_user, parse_users\nfrom .queue_client import QueueClient\nfrom .utils import encode_params, find_obj, get_by_path\n", "from .utils import encode_params, find_obj, get_by_path\n\nSEARCH_FEATURES = {\n    \"tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled\": True,\n}\n\n\nclass API:\n    pool: AccountsPool\n\n    def __init__(self, pool: AccountsPool | str | None = None, debug=False):\n        if isinstance(pool, AccountsPool):\n            self.pool = pool\n        elif isinstance(pool, str):\n            self.pool = AccountsPool(pool)\n        else:\n            self.pool = AccountsPool()\n\n        self.debug = debug\n        if self.debug:\n            set_log_level(\"DEBUG\")\n\n    # general helpers\n\n    def _is_end(self, rep: Response, q: str, res: list, cur: str | None, cnt: int, lim: int):\n        new_count = len(res)\n        new_total = cnt + new_count\n\n        is_res = new_count > 0\n        is_cur = cur is not None\n        is_lim = lim > 0 and new_total >= lim\n\n        return rep if is_res else None, new_total, is_cur and not is_lim\n\n    def _get_cursor(self, obj: dict):\n        if cur := find_obj(obj, lambda x: x.get(\"cursorType\") == \"Bottom\"):\n            return cur.get(\"value\")\n        return None\n\n    # gql helpers\n\n    async def _gql_items(self, op: str, kv: dict, ft: dict | None = None, limit=-1):\n        queue, cursor, count, active = op.split(\"/\")[-1], None, 0, True\n        kv, ft = {**kv}, {**GQL_FEATURES, **(ft or {})}\n\n        async with QueueClient(self.pool, queue, self.debug) as client:\n            while active:\n                params = {\"variables\": kv, \"features\": ft}\n                if cursor is not None:\n                    params[\"variables\"][\"cursor\"] = cursor\n                if queue in (\"SearchTimeline\", \"ListLatestTweetsTimeline\"):\n                    params[\"fieldToggles\"] = {\"withArticleRichContentState\": False}\n\n                rep = await client.get(f\"{GQL_URL}/{op}\", params=encode_params(params))\n                obj = rep.json()\n\n                entries = get_by_path(obj, \"entries\") or []\n                entries = [x for x in entries if not x[\"entryId\"].startswith(\"cursor-\")]\n                cursor = self._get_cursor(obj)\n\n                rep, count, active = self._is_end(rep, queue, entries, cursor, count, limit)\n                if rep is None:\n                    return\n\n                yield rep\n\n    async def _gql_item(self, op: str, kv: dict, ft: dict | None = None):\n        ft = ft or {}\n        queue = op.split(\"/\")[-1]\n        async with QueueClient(self.pool, queue, self.debug) as client:\n            params = {\"variables\": {**kv}, \"features\": {**GQL_FEATURES, **ft}}\n            return await client.get(f\"{GQL_URL}/{op}\", params=encode_params(params))\n\n    # search\n\n    async def search_raw(self, q: str, limit=-1, kv=None):\n        op = OP_SearchTimeline\n        kv = {\n            \"rawQuery\": q,\n            \"count\": 20,\n            \"product\": \"Latest\",\n            \"querySource\": \"typed_query\",\n            **(kv or {}),\n        }\n        async for x in self._gql_items(op, kv, ft=SEARCH_FEATURES, limit=limit):\n            yield x\n\n    async def search(self, q: str, limit=-1, kv=None):\n        async for rep in self.search_raw(q, limit=limit, kv=kv):\n            for x in parse_tweets(rep.json(), limit):\n                yield x\n\n    # user_by_id\n\n    async def user_by_id_raw(self, uid: int, kv=None):\n        op = OP_UserByRestId\n        kv = {\"userId\": str(uid), \"withSafetyModeUserFields\": True, **(kv or {})}\n        ft = {\n            \"hidden_profile_likes_enabled\": True,\n            \"highlights_tweets_tab_ui_enabled\": True,\n            \"creator_subscriptions_tweet_preview_api_enabled\": True,\n        }\n        return await self._gql_item(op, kv, ft)\n\n    async def user_by_id(self, uid: int, kv=None):\n        rep = await self.user_by_id_raw(uid, kv=kv)\n        return parse_user(rep)\n\n    # user_by_login\n\n    async def user_by_login_raw(self, login: str, kv=None):\n        op = OP_UserByScreenName\n        kv = {\"screen_name\": login, \"withSafetyModeUserFields\": True, **(kv or {})}\n        ft = {\n            \"highlights_tweets_tab_ui_enabled\": True,\n            \"hidden_profile_likes_enabled\": True,\n            \"creator_subscriptions_tweet_preview_api_enabled\": True,\n            \"subscriptions_verification_info_verified_since_enabled\": True,\n        }\n        return await self._gql_item(op, kv, ft)\n\n    async def user_by_login(self, login: str, kv=None):\n        rep = await self.user_by_login_raw(login, kv=kv)\n        return parse_user(rep)\n\n    # tweet_details\n\n    async def tweet_details_raw(self, twid: int, kv=None):\n        op = OP_TweetDetail\n        kv = {\n            \"focalTweetId\": str(twid),\n            \"referrer\": \"tweet\",  # tweet, profile\n            \"with_rux_injections\": False,\n            \"includePromotedContent\": True,\n            \"withCommunity\": True,\n            \"withQuickPromoteEligibilityTweetFields\": True,\n            \"withBirdwatchNotes\": True,\n            \"withVoice\": True,\n            \"withV2Timeline\": True,\n            \"withDownvotePerspective\": False,\n            \"withReactionsMetadata\": False,\n            \"withReactionsPerspective\": False,\n            \"withSuperFollowsTweetFields\": False,\n            \"withSuperFollowsUserFields\": False,\n            **(kv or {}),\n        }\n        ft = {\n            \"responsive_web_twitter_blue_verified_badge_is_enabled\": True,\n            \"longform_notetweets_richtext_consumption_enabled\": True,\n            **SEARCH_FEATURES,\n        }\n        return await self._gql_item(op, kv, ft)\n\n    async def tweet_details(self, twid: int, kv=None):\n        rep = await self.tweet_details_raw(twid, kv=kv)\n        return parse_tweet(rep, twid)\n\n    # followers\n\n    async def followers_raw(self, uid: int, limit=-1, kv=None):\n        op = OP_Followers\n        kv = {\"userId\": str(uid), \"count\": 20, \"includePromotedContent\": False, **(kv or {})}\n        async for x in self._gql_items(op, kv, limit=limit):\n            yield x\n\n    async def followers(self, uid: int, limit=-1, kv=None):\n        async for rep in self.followers_raw(uid, limit=limit, kv=kv):\n            for x in parse_users(rep.json(), limit):\n                yield x\n\n    # following\n\n    async def following_raw(self, uid: int, limit=-1, kv=None):\n        op = OP_Following\n        kv = {\"userId\": str(uid), \"count\": 20, \"includePromotedContent\": False, **(kv or {})}\n        async for x in self._gql_items(op, kv, limit=limit):\n            yield x\n\n    async def following(self, uid: int, limit=-1, kv=None):\n        async for rep in self.following_raw(uid, limit=limit, kv=kv):\n            for x in parse_users(rep.json(), limit):\n                yield x\n\n    # retweeters\n\n    async def retweeters_raw(self, twid: int, limit=-1, kv=None):\n        op = OP_Retweeters\n        kv = {\"tweetId\": str(twid), \"count\": 20, \"includePromotedContent\": True, **(kv or {})}\n        async for x in self._gql_items(op, kv, limit=limit):\n            yield x\n\n    async def retweeters(self, twid: int, limit=-1, kv=None):\n        async for rep in self.retweeters_raw(twid, limit=limit, kv=kv):\n            for x in parse_users(rep.json(), limit):\n                yield x\n\n    # favoriters\n\n    async def favoriters_raw(self, twid: int, limit=-1, kv=None):\n        op = OP_Favoriters\n        kv = {\"tweetId\": str(twid), \"count\": 20, \"includePromotedContent\": True, **(kv or {})}\n        async for x in self._gql_items(op, kv, limit=limit):\n            yield x\n\n    async def favoriters(self, twid: int, limit=-1, kv=None):\n        async for rep in self.favoriters_raw(twid, limit=limit, kv=kv):\n            for x in parse_users(rep.json(), limit):\n                yield x\n\n    # user_tweets\n\n    async def user_tweets_raw(self, uid: int, limit=-1, kv=None):\n        op = OP_UserTweets\n        kv = {\n            \"userId\": str(uid),\n            \"count\": 40,\n            \"includePromotedContent\": True,\n            \"withQuickPromoteEligibilityTweetFields\": True,\n            \"withVoice\": True,\n            \"withV2Timeline\": True,\n            **(kv or {}),\n        }\n        async for x in self._gql_items(op, kv, limit=limit):\n            yield x\n\n    async def user_tweets(self, uid: int, limit=-1, kv=None):\n        async for rep in self.user_tweets_raw(uid, limit=limit, kv=kv):\n            for x in parse_tweets(rep.json(), limit):\n                yield x\n\n    # user_tweets_and_replies\n\n    async def user_tweets_and_replies_raw(self, uid: int, limit=-1, kv=None):\n        op = OP_UserTweetsAndReplies\n        kv = {\n            \"userId\": str(uid),\n            \"count\": 40,\n            \"includePromotedContent\": True,\n            \"withCommunity\": True,\n            \"withVoice\": True,\n            \"withV2Timeline\": True,\n            **(kv or {}),\n        }\n        async for x in self._gql_items(op, kv, limit=limit):\n            yield x\n\n    async def user_tweets_and_replies(self, uid: int, limit=-1, kv=None):\n        async for rep in self.user_tweets_and_replies_raw(uid, limit=limit, kv=kv):\n            for x in parse_tweets(rep.json(), limit):\n                yield x\n\n    # list timeline\n\n    async def list_timeline_raw(self, list_id: int, limit=-1, kv=None):\n        op = OP_ListLatestTweetsTimeline\n        kv = {\n            \"listId\": str(list_id),\n            \"count\": 20,\n            **(kv or {}),\n        }\n        async for x in self._gql_items(op, kv, ft=SEARCH_FEATURES, limit=limit):\n            yield x\n\n    async def list_timeline(self, list_id: int, limit=-1, kv=None):\n        async for rep in self.list_timeline_raw(list_id, limit=limit, kv=kv):\n            for x in parse_tweets(rep, limit):\n                yield x", ""]}
{"filename": "twscrape/__init__.py", "chunked_list": ["# ruff: noqa: F401\nfrom .account import Account\nfrom .accounts_pool import AccountsPool\nfrom .api import API\nfrom .logger import set_log_level\nfrom .models import *  # noqa: F403\nfrom .utils import gather\n"]}
{"filename": "twscrape/utils.py", "chunked_list": ["import base64\nimport json\nfrom collections import defaultdict\nfrom datetime import datetime, timezone\nfrom typing import Any, AsyncGenerator, Callable, TypeVar\n\nfrom httpx import HTTPStatusError, Response\n\nfrom .logger import logger\n", "from .logger import logger\n\nT = TypeVar(\"T\")\n\n\nasync def gather(gen: AsyncGenerator[T, None]) -> list[T]:\n    items = []\n    async for x in gen:\n        items.append(x)\n    return items", "        items.append(x)\n    return items\n\n\ndef raise_for_status(rep: Response, label: str):\n    try:\n        rep.raise_for_status()\n    except HTTPStatusError as e:\n        logger.warning(f\"{label} - {rep.status_code} - {rep.text}\")\n        raise e", "\n\ndef encode_params(obj: dict):\n    res = {}\n    for k, v in obj.items():\n        if isinstance(v, dict):\n            v = {a: b for a, b in v.items() if b is not None}\n            v = json.dumps(v, separators=(\",\", \":\"))\n\n        res[k] = str(v)\n\n    return res", "\n\ndef get_or(obj: dict, key: str, default_value: T = None) -> Any | T:\n    for part in key.split(\".\"):\n        if part not in obj:\n            return default_value\n        obj = obj[part]\n    return obj\n\n\ndef int_or_none(obj: dict, key: str):\n    try:\n        val = get_or(obj, key)\n        return int(val) if val is not None else None\n    except Exception:\n        return None", "\n\ndef int_or_none(obj: dict, key: str):\n    try:\n        val = get_or(obj, key)\n        return int(val) if val is not None else None\n    except Exception:\n        return None\n\n", "\n\n# https://stackoverflow.com/a/43184871\ndef get_by_path(obj: dict, key: str, default=None):\n    stack = [iter(obj.items())]\n    while stack:\n        for k, v in stack[-1]:\n            if k == key:\n                return v\n            elif isinstance(v, dict):\n                stack.append(iter(v.items()))\n                break\n            elif isinstance(v, list):\n                stack.append(iter(enumerate(v)))\n                break\n        else:\n            stack.pop()\n    return default", "\n\ndef find_item(lst: list[T], fn: Callable[[T], bool]) -> T | None:\n    for item in lst:\n        if fn(item):\n            return item\n    return None\n\n\ndef find_or_fail(lst: list[T], fn: Callable[[T], bool]) -> T:\n    item = find_item(lst, fn)\n    if item is None:\n        raise ValueError()\n    return item", "\ndef find_or_fail(lst: list[T], fn: Callable[[T], bool]) -> T:\n    item = find_item(lst, fn)\n    if item is None:\n        raise ValueError()\n    return item\n\n\ndef find_obj(obj: dict, fn: Callable[[dict], bool]) -> Any | None:\n    if not isinstance(obj, dict):\n        return None\n\n    if fn(obj):\n        return obj\n\n    for _, v in obj.items():\n        if isinstance(v, dict):\n            if res := find_obj(v, fn):\n                return res\n        elif isinstance(v, list):\n            for x in v:\n                if res := find_obj(x, fn):\n                    return res\n\n    return None", "def find_obj(obj: dict, fn: Callable[[dict], bool]) -> Any | None:\n    if not isinstance(obj, dict):\n        return None\n\n    if fn(obj):\n        return obj\n\n    for _, v in obj.items():\n        if isinstance(v, dict):\n            if res := find_obj(v, fn):\n                return res\n        elif isinstance(v, list):\n            for x in v:\n                if res := find_obj(x, fn):\n                    return res\n\n    return None", "\n\ndef get_typed_object(obj: dict, res: defaultdict[str, list]):\n    obj_type = obj.get(\"__typename\", None)\n    if obj_type is not None:\n        res[obj_type].append(obj)\n\n    for _, v in obj.items():\n        if isinstance(v, dict):\n            get_typed_object(v, res)\n        elif isinstance(v, list):\n            for x in v:\n                if isinstance(x, dict):\n                    get_typed_object(x, res)\n\n    return res", "\n\ndef to_old_obj(obj: dict):\n    return {\n        **obj,\n        **obj[\"legacy\"],\n        \"id_str\": str(obj[\"rest_id\"]),\n        \"id\": int(obj[\"rest_id\"]),\n        \"legacy\": None,\n    }", "\n\ndef to_old_rep(obj: dict) -> dict[str, dict]:\n    tmp = get_typed_object(obj, defaultdict(list))\n\n    tweets = [x for x in tmp.get(\"Tweet\", []) if \"legacy\" in x]\n    tweets = {str(x[\"rest_id\"]): to_old_obj(x) for x in tweets}\n\n    users = [x for x in tmp.get(\"User\", []) if \"legacy\" in x and \"id\" in x]\n    users = {str(x[\"rest_id\"]): to_old_obj(x) for x in users}\n\n    return {\"tweets\": tweets, \"users\": users}", "\n\ndef utc_ts() -> int:\n    return int(datetime.utcnow().replace(tzinfo=timezone.utc).timestamp())\n\n\ndef from_utciso(iso: str) -> datetime:\n    return datetime.fromisoformat(iso).replace(tzinfo=timezone.utc)\n\n\ndef print_table(rows: list[dict], hr_after=False):\n    if not rows:\n        return\n\n    def prt(x):\n        if isinstance(x, str):\n            return x\n\n        if isinstance(x, int):\n            return f\"{x:,}\"\n\n        if isinstance(x, datetime):\n            return x.isoformat().split(\"+\")[0].replace(\"T\", \" \")\n\n        return str(x)\n\n    keys = list(rows[0].keys())\n    rows = [{k: k for k in keys}, *[{k: prt(x.get(k, \"\")) for k in keys} for x in rows]]\n    colw = [max(len(x[k]) for x in rows) + 1 for k in keys]\n\n    lines = []\n    for row in rows:\n        line = [f\"{row[k]:<{colw[i]}}\" for i, k in enumerate(keys)]\n        lines.append(\" \".join(line))\n\n    max_len = max(len(x) for x in lines)\n    # lines.insert(1, \"\u2500\" * max_len)\n    # lines.insert(0, \"\u2500\" * max_len)\n    print(\"\\n\".join(lines))\n    if hr_after:\n        print(\"-\" * max_len)", "\n\ndef print_table(rows: list[dict], hr_after=False):\n    if not rows:\n        return\n\n    def prt(x):\n        if isinstance(x, str):\n            return x\n\n        if isinstance(x, int):\n            return f\"{x:,}\"\n\n        if isinstance(x, datetime):\n            return x.isoformat().split(\"+\")[0].replace(\"T\", \" \")\n\n        return str(x)\n\n    keys = list(rows[0].keys())\n    rows = [{k: k for k in keys}, *[{k: prt(x.get(k, \"\")) for k in keys} for x in rows]]\n    colw = [max(len(x[k]) for x in rows) + 1 for k in keys]\n\n    lines = []\n    for row in rows:\n        line = [f\"{row[k]:<{colw[i]}}\" for i, k in enumerate(keys)]\n        lines.append(\" \".join(line))\n\n    max_len = max(len(x) for x in lines)\n    # lines.insert(1, \"\u2500\" * max_len)\n    # lines.insert(0, \"\u2500\" * max_len)\n    print(\"\\n\".join(lines))\n    if hr_after:\n        print(\"-\" * max_len)", "\n\ndef parse_cookies(val: str) -> dict[str, str]:\n    try:\n        val = base64.b64decode(val).decode()\n    except Exception:\n        pass\n\n    try:\n        try:\n            res = json.loads(val)\n            if isinstance(res, dict) and \"cookies\" in res:\n                res = res[\"cookies\"]\n\n            if isinstance(res, list):\n                return {x[\"name\"]: x[\"value\"] for x in res}\n            if isinstance(res, dict):\n                return res\n        except json.JSONDecodeError:\n            res = val.split(\"; \")\n            res = [x.split(\"=\") for x in res]\n            return {x[0]: x[1] for x in res}\n    except Exception:\n        pass\n\n    raise ValueError(f\"Invalid cookie value: {val}\")", ""]}
{"filename": "twscrape/queue_client.py", "chunked_list": ["import json\nimport os\nfrom datetime import datetime\nfrom typing import Any\n\nimport httpx\n\nfrom .accounts_pool import Account, AccountsPool\nfrom .logger import logger\nfrom .utils import utc_ts", "from .logger import logger\nfrom .utils import utc_ts\n\nReqParams = dict[str, str | int] | None\nTMP_TS = datetime.utcnow().isoformat().split(\".\")[0].replace(\"T\", \"_\").replace(\":\", \"-\")[0:16]\n\n\nclass Ctx:\n    def __init__(self, acc: Account, clt: httpx.AsyncClient):\n        self.acc = acc\n        self.clt = clt\n        self.req_count = 0", "\n\nclass ApiError(Exception):\n    def __init__(self, rep: httpx.Response, res: dict):\n        self.rep = rep\n        self.res = res\n        self.errors = [x[\"message\"] for x in res[\"errors\"]]\n        self.acc = getattr(rep, \"__username\", \"<UNKNOWN>\")\n\n    def __str__(self):\n        msg = f\"(code {self.rep.status_code}): {' ~ '.join(self.errors)}\"\n        return f\"ApiError on {req_id(self.rep)} {msg}\"", "\n\nclass RateLimitError(Exception):\n    pass\n\n\nclass BannedError(Exception):\n    pass\n\n\ndef req_id(rep: httpx.Response):\n    lr = str(rep.headers.get(\"x-rate-limit-remaining\", -1))\n    ll = str(rep.headers.get(\"x-rate-limit-limit\", -1))\n    sz = max(len(lr), len(ll))\n    lr, ll = lr.rjust(sz), ll.rjust(sz)\n\n    username = getattr(rep, \"__username\", \"<UNKNOWN>\")\n    return f\"{lr}/{ll} - {username}\"", "\n\ndef req_id(rep: httpx.Response):\n    lr = str(rep.headers.get(\"x-rate-limit-remaining\", -1))\n    ll = str(rep.headers.get(\"x-rate-limit-limit\", -1))\n    sz = max(len(lr), len(ll))\n    lr, ll = lr.rjust(sz), ll.rjust(sz)\n\n    username = getattr(rep, \"__username\", \"<UNKNOWN>\")\n    return f\"{lr}/{ll} - {username}\"", "\n\ndef dump_rep(rep: httpx.Response):\n    count = getattr(dump_rep, \"__count\", -1) + 1\n    setattr(dump_rep, \"__count\", count)\n\n    acc = getattr(rep, \"__username\", \"<unknown>\")\n    outfile = f\"{count:05d}_{rep.status_code}_{acc}.txt\"\n    outfile = f\"/tmp/twscrape-{TMP_TS}/{outfile}\"\n    os.makedirs(os.path.dirname(outfile), exist_ok=True)\n\n    msg = []\n    msg.append(f\"{count:,d} - {req_id(rep)}\")\n    msg.append(f\"{rep.status_code} {rep.request.method} {rep.request.url}\")\n    msg.append(\"\\n\")\n    # msg.append(\"\\n\".join([str(x) for x in list(rep.request.headers.items())]))\n    msg.append(\"\\n\".join([str(x) for x in list(rep.headers.items())]))\n    msg.append(\"\\n\")\n\n    try:\n        msg.append(json.dumps(rep.json(), indent=2))\n    except json.JSONDecodeError:\n        msg.append(rep.text)\n\n    txt = \"\\n\".join(msg)\n    with open(outfile, \"w\") as f:\n        f.write(txt)", "\n\nclass QueueClient:\n    def __init__(self, pool: AccountsPool, queue: str, debug=False):\n        self.pool = pool\n        self.queue = queue\n        self.debug = debug\n        self.ctx: Ctx | None = None\n\n    async def __aenter__(self):\n        await self._get_ctx()\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await self._close_ctx()\n\n    async def _close_ctx(self, reset_at=-1, banned=False, msg=\"\"):\n        if self.ctx is None:\n            return\n\n        ctx, self.ctx, self.req_count = self.ctx, None, 0\n        username = ctx.acc.username\n        await ctx.clt.aclose()\n\n        if banned:\n            await self.pool.mark_banned(username, msg)\n            return\n\n        if reset_at > 0:\n            await self.pool.lock_until(ctx.acc.username, self.queue, reset_at, ctx.req_count)\n            return\n\n        await self.pool.unlock(ctx.acc.username, self.queue, ctx.req_count)\n\n    async def _get_ctx(self) -> Ctx:\n        if self.ctx:\n            return self.ctx\n\n        acc = await self.pool.get_for_queue_or_wait(self.queue)\n        clt = acc.make_client()\n        self.ctx = Ctx(acc, clt)\n        return self.ctx\n\n    async def _check_rep(self, rep: httpx.Response):\n        if self.debug:\n            dump_rep(rep)\n\n        try:\n            res = rep.json()\n        except json.JSONDecodeError:\n            res: Any = {\"_raw\": rep.text}\n\n        msg = \"OK\"\n        if \"errors\" in res:\n            msg = set([f'({x.get(\"code\", -1)}) {x[\"message\"]}' for x in res[\"errors\"]])\n            msg = \"; \".join(list(msg))\n\n        if self.debug:\n            fn = logger.debug if rep.status_code == 200 else logger.warning\n            fn(f\"{rep.status_code:3d} - {req_id(rep)} - {msg}\")\n\n        # need to add some features in api.py\n        if msg.startswith(\"The following features cannot be null\"):\n            logger.error(f\"Invalid request: {msg}\")\n            exit(1)\n\n        # general api rate limit\n        if int(rep.headers.get(\"x-rate-limit-remaining\", -1)) == 0:\n            await self._close_ctx(int(rep.headers.get(\"x-rate-limit-reset\", -1)))\n            raise RateLimitError(msg)\n\n        # possible new limits for tweets view per account\n        if msg.startswith(\"(88) Rate limit exceeded\") or rep.status_code == 429:\n            await self._close_ctx(utc_ts() + 60 * 60 * 4)  # lock for 4 hours\n            raise RateLimitError(msg)\n\n        if msg.startswith(\"(326) Authorization: Denied by access control\"):\n            await self._close_ctx(-1, banned=True, msg=msg)\n            raise BannedError(msg)\n\n        # possible banned by old api flow\n        if rep.status_code in (401, 403):\n            await self._close_ctx(utc_ts() + 60 * 60 * 12)  # lock for 12 hours\n            raise RateLimitError(msg)\n\n        # content not found\n        if rep.status_code == 200 and \"_Missing: No status found with that ID.\" in msg:\n            return  # ignore this error\n\n        # todo: (32) Could not authenticate you\n\n        if msg != \"OK\":\n            raise ApiError(rep, res)\n\n        rep.raise_for_status()\n\n    async def get(self, url: str, params: ReqParams = None):\n        return await self.req(\"GET\", url, params=params)\n\n    async def req(self, method: str, url: str, params: ReqParams = None):\n        retry_count = 0\n        while True:\n            ctx = await self._get_ctx()\n\n            try:\n                rep = await ctx.clt.request(method, url, params=params)\n                setattr(rep, \"__username\", ctx.acc.username)\n                await self._check_rep(rep)\n\n                ctx.req_count += 1  # count only successful\n                retry_count = 0\n                return rep\n            except (RateLimitError, BannedError):\n                # already handled\n                continue\n            except (httpx.ReadTimeout, httpx.ProxyError):\n                # http transport failed, just retry\n                continue\n            except Exception as e:\n                retry_count += 1\n                if retry_count >= 3:\n                    logger.warning(f\"Unknown error {type(e)}: {e}\")\n                    await self._close_ctx(utc_ts() + 60 * 15)  # 15 minutes", ""]}
{"filename": "twscrape/constants.py", "chunked_list": ["TOKEN = \"Bearer AAAAAAAAAAAAAAAAAAAAANRILgAAAAAAnNwIzUejRCOuH5E6I8xnZz4puTs%3D1Zv7ttfk8LF81IUq16cHjhLTvJu4FA33AGWWjCpTnA\"  # noqa: E501\n\nGQL_URL = \"https://twitter.com/i/api/graphql\"\nLOGIN_URL = \"https://api.twitter.com/1.1/onboarding/task.json\"\n\nOP_SearchTimeline = \"L1VfBERtzc3VkBBT0YAYHA/SearchTimeline\"\nOP_UserByRestId = \"Lxg1V9AiIzzXEiP2c8dRnw/UserByRestId\"\nOP_UserByScreenName = \"oUZZZ8Oddwxs8Cd3iW3UEA/UserByScreenName\"\nOP_TweetDetail = \"NmCeCgkVlsRGS1cAwqtgmw/TweetDetail\"\nOP_Followers = \"FKV1jfu4AawGapl2KCZbQw/Followers\"", "OP_TweetDetail = \"NmCeCgkVlsRGS1cAwqtgmw/TweetDetail\"\nOP_Followers = \"FKV1jfu4AawGapl2KCZbQw/Followers\"\nOP_Following = \"sKlU5dd_nanz9P2CxBt2sg/Following\"\nOP_Retweeters = \"Gnw_Swm60cS-biSLn2OWNw/Retweeters\"\nOP_Favoriters = \"rUyh8HWk8IXv_fvVKj3QjA/Favoriters\"\nOP_UserTweets = \"x8SpjuBpqoww-edf0aUUKA/UserTweets\"\nOP_UserTweetsAndReplies = \"RB2KVuVBRZe4GW8KkoVF2A/UserTweetsAndReplies\"\nOP_ListLatestTweetsTimeline = \"2Vjeyo_L0nizAUhHe3fKyA/ListLatestTweetsTimeline\"\n\nGQL_FEATURES = {", "\nGQL_FEATURES = {\n    \"blue_business_profile_image_shape_enabled\": True,\n    \"responsive_web_graphql_exclude_directive_enabled\": True,\n    \"verified_phone_label_enabled\": False,\n    \"responsive_web_graphql_skip_user_profile_image_extensions_enabled\": False,\n    \"responsive_web_graphql_timeline_navigation_enabled\": True,\n    \"tweetypie_unmention_optimization_enabled\": True,\n    \"vibe_api_enabled\": True,\n    \"responsive_web_edit_tweet_api_enabled\": True,", "    \"vibe_api_enabled\": True,\n    \"responsive_web_edit_tweet_api_enabled\": True,\n    \"graphql_is_translatable_rweb_tweet_is_translatable_enabled\": True,\n    \"view_counts_everywhere_api_enabled\": True,\n    \"longform_notetweets_consumption_enabled\": True,\n    \"tweet_awards_web_tipping_enabled\": False,\n    \"freedom_of_speech_not_reach_fetch_enabled\": True,\n    \"standardized_nudges_misinfo\": True,\n    \"tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled\": False,\n    \"interactive_text_enabled\": True,", "    \"tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled\": False,\n    \"interactive_text_enabled\": True,\n    \"responsive_web_text_conversations_enabled\": False,\n    \"longform_notetweets_rich_text_read_enabled\": True,\n    \"responsive_web_enhance_cards_enabled\": False,\n    \"creator_subscriptions_tweet_preview_api_enabled\": True,\n    \"longform_notetweets_inline_media_enabled\": True,\n    \"responsive_web_media_download_video_enabled\": False,\n    \"rweb_lists_timeline_redesign_enabled\": True,\n    \"responsive_web_twitter_article_tweet_consumption_enabled\": False,", "    \"rweb_lists_timeline_redesign_enabled\": True,\n    \"responsive_web_twitter_article_tweet_consumption_enabled\": False,\n}\n"]}
{"filename": "twscrape/login.py", "chunked_list": ["from datetime import datetime, timedelta, timezone\n\nfrom httpx import AsyncClient, HTTPStatusError, Response\n\nfrom .account import Account\nfrom .constants import LOGIN_URL\nfrom .imap import imap_get_email_code, imap_login\nfrom .logger import logger\nfrom .utils import raise_for_status\n", "from .utils import raise_for_status\n\n\nasync def get_guest_token(client: AsyncClient):\n    rep = await client.post(\"https://api.twitter.com/1.1/guest/activate.json\")\n    raise_for_status(rep, \"guest_token\")\n    return rep.json()[\"guest_token\"]\n\n\nasync def login_initiate(client: AsyncClient) -> Response:", "\nasync def login_initiate(client: AsyncClient) -> Response:\n    payload = {\n        \"input_flow_data\": {\n            \"flow_context\": {\"debug_overrides\": {}, \"start_location\": {\"location\": \"unknown\"}}\n        },\n        \"subtask_versions\": {},\n    }\n\n    rep = await client.post(LOGIN_URL, params={\"flow_name\": \"login\"}, json=payload)", "\n    rep = await client.post(LOGIN_URL, params={\"flow_name\": \"login\"}, json=payload)\n    raise_for_status(rep, \"login_initiate\")\n    return rep\n\n\nasync def login_instrumentation(client: AsyncClient, acc: Account, prev: dict) -> Response:\n    payload = {\n        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [", "        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [\n            {\n                \"subtask_id\": \"LoginJsInstrumentationSubtask\",\n                \"js_instrumentation\": {\"response\": \"{}\", \"link\": \"next_link\"},\n            }\n        ],\n    }\n\n    rep = await client.post(LOGIN_URL, json=payload)", "\n    rep = await client.post(LOGIN_URL, json=payload)\n    raise_for_status(rep, \"login_instrumentation\")\n    return rep\n\n\nasync def login_enter_username(client: AsyncClient, acc: Account, prev: dict) -> Response:\n    payload = {\n        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [", "        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [\n            {\n                \"subtask_id\": \"LoginEnterUserIdentifierSSO\",\n                \"settings_list\": {\n                    \"setting_responses\": [\n                        {\n                            \"key\": \"user_identifier\",\n                            \"response_data\": {\"text_data\": {\"result\": acc.username}},\n                        }", "                            \"response_data\": {\"text_data\": {\"result\": acc.username}},\n                        }\n                    ],\n                    \"link\": \"next_link\",\n                },\n            }\n        ],\n    }\n\n    rep = await client.post(LOGIN_URL, json=payload)", "\n    rep = await client.post(LOGIN_URL, json=payload)\n    raise_for_status(rep, \"login_username\")\n    return rep\n\n\nasync def login_enter_password(client: AsyncClient, acc: Account, prev: dict) -> Response:\n    payload = {\n        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [", "        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [\n            {\n                \"subtask_id\": \"LoginEnterPassword\",\n                \"enter_password\": {\"password\": acc.password, \"link\": \"next_link\"},\n            }\n        ],\n    }\n\n    rep = await client.post(LOGIN_URL, json=payload)", "\n    rep = await client.post(LOGIN_URL, json=payload)\n    raise_for_status(rep, \"login_password\")\n    return rep\n\n\nasync def login_duplication_check(client: AsyncClient, acc: Account, prev: dict) -> Response:\n    payload = {\n        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [", "        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [\n            {\n                \"subtask_id\": \"AccountDuplicationCheck\",\n                \"check_logged_in_account\": {\"link\": \"AccountDuplicationCheck_false\"},\n            }\n        ],\n    }\n\n    rep = await client.post(LOGIN_URL, json=payload)", "\n    rep = await client.post(LOGIN_URL, json=payload)\n    raise_for_status(rep, \"login_duplication_check\")\n    return rep\n\n\nasync def login_confirm_email(client: AsyncClient, acc: Account, prev: dict, imap) -> Response:\n    payload = {\n        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [", "        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [\n            {\n                \"subtask_id\": \"LoginAcid\",\n                \"enter_text\": {\"text\": acc.email, \"link\": \"next_link\"},\n            }\n        ],\n    }\n\n    rep = await client.post(LOGIN_URL, json=payload)", "\n    rep = await client.post(LOGIN_URL, json=payload)\n    raise_for_status(rep, \"login_confirm_email\")\n    return rep\n\n\nasync def login_confirm_email_code(client: AsyncClient, acc: Account, prev: dict, imap):\n    if not imap:\n        imap = await imap_login(acc.email, acc.email_password)\n", "\n    now_time = datetime.now(timezone.utc) - timedelta(seconds=30)\n    value = await imap_get_email_code(imap, acc.email, now_time)\n\n    payload = {\n        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [\n            {\n                \"subtask_id\": \"LoginAcid\",\n                \"enter_text\": {\"text\": value, \"link\": \"next_link\"},", "                \"subtask_id\": \"LoginAcid\",\n                \"enter_text\": {\"text\": value, \"link\": \"next_link\"},\n            }\n        ],\n    }\n\n    rep = await client.post(LOGIN_URL, json=payload)\n    raise_for_status(rep, \"login_confirm_email\")\n    return rep\n", "    return rep\n\n\nasync def login_success(client: AsyncClient, acc: Account, prev: dict) -> Response:\n    payload = {\n        \"flow_token\": prev[\"flow_token\"],\n        \"subtask_inputs\": [],\n    }\n\n    rep = await client.post(LOGIN_URL, json=payload)", "\n    rep = await client.post(LOGIN_URL, json=payload)\n    raise_for_status(rep, \"login_success\")\n    return rep\n\n\nasync def next_login_task(client: AsyncClient, acc: Account, rep: Response, imap):\n    ct0 = client.cookies.get(\"ct0\", None)\n    if ct0:\n        client.headers[\"x-csrf-token\"] = ct0\n        client.headers[\"x-twitter-auth-type\"] = \"OAuth2Session\"", "    if ct0:\n        client.headers[\"x-csrf-token\"] = ct0\n        client.headers[\"x-twitter-auth-type\"] = \"OAuth2Session\"\n\n    prev = rep.json()\n    assert \"flow_token\" in prev, f\"flow_token not in {rep.text}\"\n\n    for x in prev[\"subtasks\"]:\n        task_id = x[\"subtask_id\"]\n\n        try:\n            if task_id == \"LoginSuccessSubtask\":\n                return await login_success(client, acc, prev)\n            if task_id == \"LoginAcid\":\n                is_code = x[\"enter_text\"][\"hint_text\"].lower() == \"confirmation code\"\n                fn = login_confirm_email_code if is_code else login_confirm_email\n                return await fn(client, acc, prev, imap)\n            if task_id == \"AccountDuplicationCheck\":\n                return await login_duplication_check(client, acc, prev)\n            if task_id == \"LoginEnterPassword\":\n                return await login_enter_password(client, acc, prev)\n            if task_id == \"LoginEnterUserIdentifierSSO\":\n                return await login_enter_username(client, acc, prev)\n            if task_id == \"LoginJsInstrumentationSubtask\":\n                return await login_instrumentation(client, acc, prev)\n        except Exception as e:\n            acc.error_msg = f\"login_step={task_id} err={e}\"\n            logger.error(f\"Error in {task_id}: {e}\")\n            raise e", "\n    return None\n\n\nasync def login(acc: Account, email_first=False) -> Account:\n    log_id = f\"{acc.username} - {acc.email}\"\n    if acc.active:\n        logger.info(f\"account already active {log_id}\")\n        return acc\n\n    if email_first:\n        imap = await imap_login(acc.email, acc.email_password)\n    else:\n        imap = None", "\n    if email_first:\n        imap = await imap_login(acc.email, acc.email_password)\n    else:\n        imap = None\n\n    client = acc.make_client()\n    guest_token = await get_guest_token(client)\n    client.headers[\"x-guest-token\"] = guest_token\n", "    client.headers[\"x-guest-token\"] = guest_token\n\n    rep = await login_initiate(client)\n    while True:\n        if not rep:\n            break\n\n        try:\n            rep = await next_login_task(client, acc, rep, imap)\n        except HTTPStatusError as e:\n            if e.response.status_code == 403:\n                logger.error(f\"403 error {log_id}\")\n                return acc", "\n    client.headers[\"x-csrf-token\"] = client.cookies[\"ct0\"]\n    client.headers[\"x-twitter-auth-type\"] = \"OAuth2Session\"\n\n    acc.active = True\n    acc.headers = {k: v for k, v in client.headers.items()}\n    acc.cookies = {k: v for k, v in client.cookies.items()}\n    return acc\n", ""]}
{"filename": "twscrape/imap.py", "chunked_list": ["import asyncio\nimport email as emaillib\nimport imaplib\nimport time\nfrom datetime import datetime\n\nfrom .logger import logger\n\nMAX_WAIT_SEC = 30\n", "MAX_WAIT_SEC = 30\n\n\nclass EmailLoginError(Exception):\n    def __init__(self, message=\"Email login error\"):\n        self.message = message\n        super().__init__(self.message)\n\n\nclass EmailCodeTimeoutError(Exception):\n    def __init__(self, message=\"Email code timeout\"):\n        self.message = message\n        super().__init__(self.message)", "\nclass EmailCodeTimeoutError(Exception):\n    def __init__(self, message=\"Email code timeout\"):\n        self.message = message\n        super().__init__(self.message)\n\n\nIMAP_MAPPING: dict[str, str] = {\n    \"yahoo.com\": \"imap.mail.yahoo.com\",\n    \"icloud.com\": \"imap.mail.me.com\",", "    \"yahoo.com\": \"imap.mail.yahoo.com\",\n    \"icloud.com\": \"imap.mail.me.com\",\n    \"outlook.com\": \"imap-mail.outlook.com\",\n    \"hotmail.com\": \"imap-mail.outlook.com\",\n}\n\n\ndef add_imap_mapping(email_domain: str, imap_domain: str):\n    IMAP_MAPPING[email_domain] = imap_domain\n", "\n\ndef _get_imap_domain(email: str) -> str:\n    email_domain = email.split(\"@\")[1]\n    if email_domain in IMAP_MAPPING:\n        return IMAP_MAPPING[email_domain]\n    return f\"imap.{email_domain}\"\n\n\ndef _wait_email_code(imap: imaplib.IMAP4_SSL, count: int, min_t: datetime | None) -> str | None:\n    for i in range(count, 0, -1):\n        _, rep = imap.fetch(str(i), \"(RFC822)\")\n        for x in rep:\n            if isinstance(x, tuple):\n                msg = emaillib.message_from_bytes(x[1])\n\n                msg_time = datetime.strptime(msg.get(\"Date\", \"\"), \"%a, %d %b %Y %H:%M:%S %z\")\n                msg_from = str(msg.get(\"From\", \"\")).lower()\n                msg_subj = str(msg.get(\"Subject\", \"\")).lower()\n                logger.info(f\"({i} of {count}) {msg_from} - {msg_time} - {msg_subj}\")\n\n                if min_t is not None and msg_time < min_t:\n                    return None\n\n                if \"info@twitter.com\" in msg_from and \"confirmation code is\" in msg_subj:\n                    # eg. Your Twitter confirmation code is XXX\n                    return msg_subj.split(\" \")[-1].strip()\n\n    return None", "\ndef _wait_email_code(imap: imaplib.IMAP4_SSL, count: int, min_t: datetime | None) -> str | None:\n    for i in range(count, 0, -1):\n        _, rep = imap.fetch(str(i), \"(RFC822)\")\n        for x in rep:\n            if isinstance(x, tuple):\n                msg = emaillib.message_from_bytes(x[1])\n\n                msg_time = datetime.strptime(msg.get(\"Date\", \"\"), \"%a, %d %b %Y %H:%M:%S %z\")\n                msg_from = str(msg.get(\"From\", \"\")).lower()\n                msg_subj = str(msg.get(\"Subject\", \"\")).lower()\n                logger.info(f\"({i} of {count}) {msg_from} - {msg_time} - {msg_subj}\")\n\n                if min_t is not None and msg_time < min_t:\n                    return None\n\n                if \"info@twitter.com\" in msg_from and \"confirmation code is\" in msg_subj:\n                    # eg. Your Twitter confirmation code is XXX\n                    return msg_subj.split(\" \")[-1].strip()\n\n    return None", "\n\nasync def imap_get_email_code(\n    imap: imaplib.IMAP4_SSL, email: str, min_t: datetime | None = None\n) -> str:\n    try:\n        start_time, was_count = time.time(), 0\n        while True:\n            _, rep = imap.select(\"INBOX\")\n            now_count = int(rep[0].decode(\"utf-8\")) if len(rep) > 0 and rep[0] is not None else 0\n            if now_count > was_count:\n                code = _wait_email_code(imap, now_count, min_t)\n                if code is not None:\n                    return code\n\n            logger.info(f\"Waiting for confirmation code for {email}, msg_count: {now_count}\")\n            if MAX_WAIT_SEC < time.time() - start_time:\n                logger.info(f\"Timeout waiting for confirmation code for {email}\")\n                raise EmailCodeTimeoutError()\n            await asyncio.sleep(5)\n    except Exception as e:\n        imap.select(\"INBOX\")\n        imap.close()\n        logger.error(f\"Error getting confirmation code for {email}: {e}\")\n        raise e", "\n\nasync def imap_login(email: str, password: str):\n    domain = _get_imap_domain(email)\n    imap = imaplib.IMAP4_SSL(domain)\n\n    try:\n        imap.login(email, password)\n    except imaplib.IMAP4.error as e:\n        logger.error(f\"Error logging into {email} on {domain}: {e}\")\n        imap.select(\"INBOX\")\n        imap.close()\n        raise EmailLoginError() from e", "\n    return imap\n"]}
{"filename": "twscrape/cli.py", "chunked_list": ["#!/usr/bin/env python3\n\nimport argparse\nimport asyncio\nimport io\nimport json\nimport sqlite3\nfrom importlib.metadata import version\n\nimport httpx", "\nimport httpx\n\nfrom .api import API, AccountsPool\nfrom .db import get_sqlite_version\nfrom .logger import logger, set_log_level\nfrom .models import Tweet, User\nfrom .utils import print_table\n\n\nclass CustomHelpFormatter(argparse.HelpFormatter):\n    def __init__(self, prog):\n        super().__init__(prog, max_help_position=30, width=120)", "\n\nclass CustomHelpFormatter(argparse.HelpFormatter):\n    def __init__(self, prog):\n        super().__init__(prog, max_help_position=30, width=120)\n\n\ndef get_fn_arg(args):\n    names = [\"query\", \"tweet_id\", \"user_id\", \"username\", \"list_id\"]\n    for name in names:\n        if name in args:\n            return name, getattr(args, name)\n\n    logger.error(f\"Missing argument: {names}\")\n    exit(1)", "\n\ndef to_str(doc: httpx.Response | Tweet | User | None) -> str:\n    if doc is None:\n        return \"Not Found. See --raw for more details.\"\n\n    tmp = doc.json()\n    return tmp if isinstance(tmp, str) else json.dumps(tmp, default=str)\n\n", "\n\nasync def main(args):\n    if args.debug:\n        set_log_level(\"DEBUG\")\n\n    if args.command == \"version\":\n        print(f\"twscrape: {version('twscrape')}\")\n        print(f\"SQLite client: {sqlite3.version}\")\n        print(f\"SQLite runtime: {sqlite3.sqlite_version} ({await get_sqlite_version()})\")\n        return", "\n    pool = AccountsPool(args.db)\n    api = API(pool, debug=args.debug)\n\n    if args.command == \"accounts\":\n        print_table(await pool.accounts_info())\n        return\n\n    if args.command == \"stats\":\n        rep = await pool.stats()\n        total, active, inactive = rep[\"total\"], rep[\"active\"], rep[\"inactive\"]\n\n        res = []\n        for k, v in rep.items():\n            if not k.startswith(\"locked\") or v == 0:\n                continue\n            res.append({\"queue\": k, \"locked\": v, \"available\": max(active - v, 0)})\n\n        res = sorted(res, key=lambda x: x[\"locked\"], reverse=True)\n        print_table(res, hr_after=True)\n        print(f\"Total: {total} - Active: {active} - Inactive: {inactive}\")\n        return", "    if args.command == \"stats\":\n        rep = await pool.stats()\n        total, active, inactive = rep[\"total\"], rep[\"active\"], rep[\"inactive\"]\n\n        res = []\n        for k, v in rep.items():\n            if not k.startswith(\"locked\") or v == 0:\n                continue\n            res.append({\"queue\": k, \"locked\": v, \"available\": max(active - v, 0)})\n\n        res = sorted(res, key=lambda x: x[\"locked\"], reverse=True)\n        print_table(res, hr_after=True)\n        print(f\"Total: {total} - Active: {active} - Inactive: {inactive}\")\n        return", "\n    if args.command == \"add_accounts\":\n        await pool.load_from_file(args.file_path, args.line_format)\n        return\n\n    if args.command == \"del_accounts\":\n        await pool.delete_accounts(args.usernames)\n        return\n\n    if args.command == \"login_accounts\":\n        stats = await pool.login_all(email_first=args.email_first)\n        print(stats)\n        return", "\n    if args.command == \"login_accounts\":\n        stats = await pool.login_all(email_first=args.email_first)\n        print(stats)\n        return\n\n    if args.command == \"relogin_failed\":\n        await pool.relogin_failed(email_first=args.email_first)\n        return\n\n    if args.command == \"relogin\":\n        await pool.relogin(args.usernames, email_first=args.email_first)\n        return", "\n    if args.command == \"relogin\":\n        await pool.relogin(args.usernames, email_first=args.email_first)\n        return\n\n    if args.command == \"reset_locks\":\n        await pool.reset_locks()\n        return\n\n    if args.command == \"delete_inactive\":\n        await pool.delete_inactive()\n        return", "\n    if args.command == \"delete_inactive\":\n        await pool.delete_inactive()\n        return\n\n    fn = args.command + \"_raw\" if args.raw else args.command\n    fn = getattr(api, fn, None)\n    if fn is None:\n        logger.error(f\"Unknown command: {args.command}\")\n        exit(1)", "\n    _, val = get_fn_arg(args)\n\n    if \"limit\" in args:\n        async for doc in fn(val, limit=args.limit):\n            print(to_str(doc))\n    else:\n        doc = await fn(val)\n        print(to_str(doc))\n", "\n\ndef custom_help(p):\n    buffer = io.StringIO()\n    p.print_help(buffer)\n    msg = buffer.getvalue()\n\n    cmd = msg.split(\"positional arguments:\")[1].strip().split(\"\\n\")[0]\n    msg = msg.replace(\"positional arguments:\", \"commands:\")\n    msg = [x for x in msg.split(\"\\n\") if cmd not in x and \"...\" not in x]\n    msg[0] = f\"{msg[0]} <command> [...]\"\n\n    i = 0\n    for i, line in enumerate(msg):\n        if line.strip().startswith(\"search\"):\n            break\n\n    msg.insert(i, \"\")\n    msg.insert(i + 1, \"search commands:\")\n\n    print(\"\\n\".join(msg))", "\n\ndef run():\n    p = argparse.ArgumentParser(add_help=False, formatter_class=CustomHelpFormatter)\n    p.add_argument(\"--db\", default=\"accounts.db\", help=\"Accounts database file\")\n    p.add_argument(\"--debug\", action=\"store_true\", help=\"Enable debug mode\")\n    subparsers = p.add_subparsers(dest=\"command\")\n\n    def c_one(name: str, msg: str, a_name: str, a_msg: str, a_type: type = str):\n        p = subparsers.add_parser(name, help=msg)\n        p.add_argument(a_name, help=a_msg, type=a_type)\n        p.add_argument(\"--raw\", action=\"store_true\", help=\"Print raw response\")\n        return p\n\n    def c_lim(name: str, msg: str, a_name: str, a_msg: str, a_type: type = str):\n        p = c_one(name, msg, a_name, a_msg, a_type)\n        p.add_argument(\"--limit\", type=int, default=-1, help=\"Max tweets to retrieve\")\n        return p\n\n    subparsers.add_parser(\"version\", help=\"Show version\")\n    subparsers.add_parser(\"accounts\", help=\"List all accounts\")\n    subparsers.add_parser(\"stats\", help=\"Get current usage stats\")\n\n    add_accounts = subparsers.add_parser(\"add_accounts\", help=\"Add accounts\")\n    add_accounts.add_argument(\"file_path\", help=\"File with accounts\")\n    add_accounts.add_argument(\"line_format\", help=\"args of Pool.add_account splited by same delim\")\n\n    del_accounts = subparsers.add_parser(\"del_accounts\", help=\"Delete accounts\")\n    del_accounts.add_argument(\"usernames\", nargs=\"+\", default=[], help=\"Usernames to delete\")\n\n    login_cmd = subparsers.add_parser(\"login_accounts\", help=\"Login accounts\")\n    relogin = subparsers.add_parser(\"relogin\", help=\"Re-login selected accounts\")\n    relogin.add_argument(\"usernames\", nargs=\"+\", default=[], help=\"Usernames to re-login\")\n    re_failed = subparsers.add_parser(\"relogin_failed\", help=\"Retry login for failed accounts\")\n\n    check_email = [login_cmd, relogin, re_failed]\n    for cmd in check_email:\n        cmd.add_argument(\"--email-first\", action=\"store_true\", help=\"Check email first\")\n\n    subparsers.add_parser(\"reset_locks\", help=\"Reset all locks\")\n    subparsers.add_parser(\"delete_inactive\", help=\"Delete inactive accounts\")\n\n    c_lim(\"search\", \"Search for tweets\", \"query\", \"Search query\")\n    c_one(\"tweet_details\", \"Get tweet details\", \"tweet_id\", \"Tweet ID\", int)\n    c_lim(\"retweeters\", \"Get retweeters of a tweet\", \"tweet_id\", \"Tweet ID\", int)\n    c_lim(\"favoriters\", \"Get favoriters of a tweet\", \"tweet_id\", \"Tweet ID\", int)\n    c_one(\"user_by_id\", \"Get user data by ID\", \"user_id\", \"User ID\", int)\n    c_one(\"user_by_login\", \"Get user data by username\", \"username\", \"Username\")\n    c_lim(\"followers\", \"Get user followers\", \"user_id\", \"User ID\", int)\n    c_lim(\"following\", \"Get user following\", \"user_id\", \"User ID\", int)\n    c_lim(\"user_tweets\", \"Get user tweets\", \"user_id\", \"User ID\", int)\n    c_lim(\"user_tweets_and_replies\", \"Get user tweets and replies\", \"user_id\", \"User ID\", int)\n    c_lim(\"list_timeline\", \"Get tweets from list\", \"list_id\", \"List ID\", int)\n\n    args = p.parse_args()\n    if args.command is None:\n        return custom_help(p)\n\n    asyncio.run(main(args))", ""]}
{"filename": "tests/__init__.py", "chunked_list": [""]}
{"filename": "tests/test_parser.py", "chunked_list": ["import json\nimport os\n\nfrom twscrape import API, gather\nfrom twscrape.logger import set_log_level\nfrom twscrape.models import Tweet, User, parse_tweet\n\nBASE_DIR = os.path.dirname(__file__)\nDATA_DIR = os.path.join(BASE_DIR, \"mocked-data\")\nos.makedirs(DATA_DIR, exist_ok=True)", "DATA_DIR = os.path.join(BASE_DIR, \"mocked-data\")\nos.makedirs(DATA_DIR, exist_ok=True)\n\nset_log_level(\"DEBUG\")\n\n\nclass Files:\n    search_raw = \"search_raw.json\"\n    user_by_id_raw = \"user_by_id_raw.json\"\n    user_by_login_raw = \"user_by_login_raw.json\"\n    tweet_details_raw = \"tweet_details_raw.json\"\n    followers_raw = \"followers_raw.json\"\n    following_raw = \"following_raw.json\"\n    retweeters_raw = \"retweeters_raw.json\"\n    favoriters_raw = \"favoriters_raw.json\"\n    user_tweets_raw = \"user_tweets_raw.json\"\n    user_tweets_and_replies_raw = \"user_tweets_and_replies_raw.json\"", "\n\ndef fake_rep(fn: str, filename: str | None = None):\n    if filename is None:\n        filename = os.path.join(DATA_DIR, getattr(Files, fn))\n\n    if not filename.startswith(\"/\"):\n        filename = os.path.join(DATA_DIR, filename)\n\n    if not filename.endswith(\".json\"):\n        filename += \".json\"\n\n    with open(filename) as fp:\n        data = fp.read()\n\n    rep = lambda: None  # noqa: E731\n    rep.text = data\n    rep.json = lambda: json.loads(data)\n    return rep", "\n\ndef mock_rep(obj, fn: str, filename: str | None = None):\n    async def cb_rep(*args, **kwargs):\n        return fake_rep(fn, filename)\n\n    setattr(obj, fn, cb_rep)\n\n\ndef mock_gen(obj, fn: str):\n    async def cb_gen(*args, **kwargs):\n        yield fake_rep(fn)\n\n    setattr(obj, fn, cb_gen)", "\ndef mock_gen(obj, fn: str):\n    async def cb_gen(*args, **kwargs):\n        yield fake_rep(fn)\n\n    setattr(obj, fn, cb_gen)\n\n\ndef check_tweet(doc: Tweet | None):\n    assert doc is not None\n    assert doc.id is not None\n    assert doc.id_str is not None\n    assert isinstance(doc.id, int)\n    assert isinstance(doc.id_str, str)\n    assert doc.id == int(doc.id_str)\n\n    assert doc.url is not None\n    assert doc.id_str in doc.url\n    assert doc.user is not None\n\n    obj = doc.dict()\n    assert doc.id == obj[\"id\"]\n    assert doc.user.id == obj[\"user\"][\"id\"]\n\n    assert \"url\" in obj\n    assert \"_type\" in obj\n    assert obj[\"_type\"] == \"snscrape.modules.twitter.Tweet\"\n\n    assert \"url\" in obj[\"user\"]\n    assert \"_type\" in obj[\"user\"]\n    assert obj[\"user\"][\"_type\"] == \"snscrape.modules.twitter.User\"\n\n    txt = doc.json()\n    assert isinstance(txt, str)\n    assert str(doc.id) in txt\n\n    if doc.media is not None:\n        if len(doc.media.photos) > 0:\n            assert doc.media.photos[0].url is not None\n\n        if len(doc.media.videos) > 0:\n            for x in doc.media.videos:\n                assert x.thumbnailUrl is not None\n                assert x.duration is not None\n                for v in x.variants:\n                    assert v.url is not None\n                    assert v.bitrate is not None\n                    assert v.contentType is not None\n\n    if doc.retweetedTweet is not None:\n        assert doc.rawContent.endswith(doc.retweetedTweet.rawContent), \"content should be full\"\n\n    check_user(doc.user)", "def check_tweet(doc: Tweet | None):\n    assert doc is not None\n    assert doc.id is not None\n    assert doc.id_str is not None\n    assert isinstance(doc.id, int)\n    assert isinstance(doc.id_str, str)\n    assert doc.id == int(doc.id_str)\n\n    assert doc.url is not None\n    assert doc.id_str in doc.url\n    assert doc.user is not None\n\n    obj = doc.dict()\n    assert doc.id == obj[\"id\"]\n    assert doc.user.id == obj[\"user\"][\"id\"]\n\n    assert \"url\" in obj\n    assert \"_type\" in obj\n    assert obj[\"_type\"] == \"snscrape.modules.twitter.Tweet\"\n\n    assert \"url\" in obj[\"user\"]\n    assert \"_type\" in obj[\"user\"]\n    assert obj[\"user\"][\"_type\"] == \"snscrape.modules.twitter.User\"\n\n    txt = doc.json()\n    assert isinstance(txt, str)\n    assert str(doc.id) in txt\n\n    if doc.media is not None:\n        if len(doc.media.photos) > 0:\n            assert doc.media.photos[0].url is not None\n\n        if len(doc.media.videos) > 0:\n            for x in doc.media.videos:\n                assert x.thumbnailUrl is not None\n                assert x.duration is not None\n                for v in x.variants:\n                    assert v.url is not None\n                    assert v.bitrate is not None\n                    assert v.contentType is not None\n\n    if doc.retweetedTweet is not None:\n        assert doc.rawContent.endswith(doc.retweetedTweet.rawContent), \"content should be full\"\n\n    check_user(doc.user)", "\n\ndef check_user(doc: User):\n    assert doc.id is not None\n    assert doc.id_str is not None\n    assert isinstance(doc.id, int)\n    assert isinstance(doc.id_str, str)\n    assert doc.id == int(doc.id_str)\n\n    assert doc.username is not None\n    assert doc.descriptionLinks is not None\n\n    if len(doc.descriptionLinks) > 0:\n        for x in doc.descriptionLinks:\n            assert x.url is not None\n            assert x.text is not None\n            assert x.tcourl is not None\n\n    obj = doc.dict()\n    assert doc.id == obj[\"id\"]\n    assert doc.username == obj[\"username\"]\n\n    txt = doc.json()\n    assert isinstance(txt, str)\n    assert str(doc.id) in txt", "\n\nasync def test_search():\n    api = API()\n    mock_gen(api, \"search_raw\")\n\n    items = await gather(api.search(\"elon musk lang:en\", limit=20))\n    assert len(items) > 0\n\n    for doc in items:\n        check_tweet(doc)", "\n    for doc in items:\n        check_tweet(doc)\n\n\nasync def test_user_by_id():\n    api = API()\n    mock_rep(api, \"user_by_id_raw\")\n\n    doc = await api.user_by_id(2244994945)", "\n    doc = await api.user_by_id(2244994945)\n    assert doc.id == 2244994945\n    assert doc.username == \"TwitterDev\"\n\n    obj = doc.dict()\n    assert doc.id == obj[\"id\"]\n    assert doc.username == obj[\"username\"]\n\n    txt = doc.json()", "\n    txt = doc.json()\n    assert isinstance(txt, str)\n    assert str(doc.id) in txt\n\n\nasync def test_user_by_login():\n    api = API()\n    mock_rep(api, \"user_by_login_raw\")\n", "    mock_rep(api, \"user_by_login_raw\")\n\n    doc = await api.user_by_login(\"twitterdev\")\n    assert doc.id == 2244994945\n    assert doc.username == \"TwitterDev\"\n\n    obj = doc.dict()\n    assert doc.id == obj[\"id\"]\n    assert doc.username == obj[\"username\"]\n", "    assert doc.username == obj[\"username\"]\n\n    txt = doc.json()\n    assert isinstance(txt, str)\n    assert str(doc.id) in txt\n\n\nasync def test_tweet_details():\n    api = API()\n    mock_rep(api, \"tweet_details_raw\")", "    api = API()\n    mock_rep(api, \"tweet_details_raw\")\n\n    doc = await api.tweet_details(1649191520250245121)\n    assert doc is not None, \"tweet should not be None\"\n    check_tweet(doc)\n\n    assert doc.id == 1649191520250245121\n    assert doc.user is not None, \"tweet.user should not be None\"\n", "    assert doc.user is not None, \"tweet.user should not be None\"\n\n\nasync def test_followers():\n    api = API()\n    mock_gen(api, \"followers_raw\")\n\n    users = await gather(api.followers(2244994945))\n    assert len(users) > 0\n\n    for doc in users:\n        check_user(doc)", "    assert len(users) > 0\n\n    for doc in users:\n        check_user(doc)\n\n\nasync def test_following():\n    api = API()\n    mock_gen(api, \"following_raw\")\n", "    mock_gen(api, \"following_raw\")\n\n    users = await gather(api.following(2244994945))\n    assert len(users) > 0\n\n    for doc in users:\n        check_user(doc)\n\n\nasync def test_retweters():", "\nasync def test_retweters():\n    api = API()\n    mock_gen(api, \"retweeters_raw\")\n\n    users = await gather(api.retweeters(1649191520250245121))\n    assert len(users) > 0\n\n    for doc in users:\n        check_user(doc)", "    for doc in users:\n        check_user(doc)\n\n\nasync def test_favoriters():\n    api = API()\n    mock_gen(api, \"favoriters_raw\")\n\n    users = await gather(api.favoriters(1649191520250245121))\n    assert len(users) > 0", "    users = await gather(api.favoriters(1649191520250245121))\n    assert len(users) > 0\n\n    for doc in users:\n        check_user(doc)\n\n\nasync def test_user_tweets():\n    api = API()\n    mock_gen(api, \"user_tweets_raw\")", "    api = API()\n    mock_gen(api, \"user_tweets_raw\")\n\n    tweets = await gather(api.user_tweets(2244994945))\n    assert len(tweets) > 0\n\n    for doc in tweets:\n        check_tweet(doc)\n\n", "\n\nasync def test_user_tweets_and_replies():\n    api = API()\n    mock_gen(api, \"user_tweets_and_replies_raw\")\n\n    tweets = await gather(api.user_tweets_and_replies(2244994945))\n    assert len(tweets) > 0\n\n    for doc in tweets:\n        check_tweet(doc)", "\n    for doc in tweets:\n        check_tweet(doc)\n\n\nasync def test_tweet_with_video():\n    api = API()\n\n    files = [\n        (\"manual_tweet_with_video_1.json\", 1671508600538161153),", "    files = [\n        (\"manual_tweet_with_video_1.json\", 1671508600538161153),\n        (\"manual_tweet_with_video_2.json\", 1671753569412820992),\n    ]\n\n    for file, twid in files:\n        mock_rep(api, \"tweet_details_raw\", file)\n        doc = await api.tweet_details(twid)\n        assert doc is not None\n        check_tweet(doc)", "\n\nasync def test_issue_28():\n    api = API()\n\n    mock_rep(api, \"tweet_details_raw\", \"_issue_28_1\")\n    doc = await api.tweet_details(1658409412799737856)\n    assert doc is not None\n    check_tweet(doc)\n", "    check_tweet(doc)\n\n    assert doc.id == 1658409412799737856\n    assert doc.user is not None\n\n    assert doc.retweetedTweet is not None\n    assert doc.retweetedTweet.viewCount is not None\n    assert doc.viewCount is not None  # views should come from retweetedTweet\n    assert doc.viewCount == doc.retweetedTweet.viewCount\n    check_tweet(doc.retweetedTweet)", "    assert doc.viewCount == doc.retweetedTweet.viewCount\n    check_tweet(doc.retweetedTweet)\n\n    mock_rep(api, \"tweet_details_raw\", \"_issue_28_2\")\n    doc = await api.tweet_details(1658421690001502208)\n    assert doc is not None\n    check_tweet(doc)\n    assert doc.id == 1658421690001502208\n    assert doc.viewCount is not None\n", "    assert doc.viewCount is not None\n\n    assert doc.quotedTweet is not None\n    assert doc.quotedTweet.id != doc.id\n    check_tweet(doc.quotedTweet)\n    assert doc.quotedTweet.viewCount is not None\n\n\nasync def test_issue_42():\n    file = os.path.join(os.path.dirname(__file__), \"mocked-data/_issue_42.json\")\n    with open(file) as f:\n        data = json.load(f)", "async def test_issue_42():\n    file = os.path.join(os.path.dirname(__file__), \"mocked-data/_issue_42.json\")\n    with open(file) as f:\n        data = json.load(f)\n\n    doc = parse_tweet(data, 1665951747842641921)\n    assert doc is not None\n    assert doc.retweetedTweet is not None\n    assert doc.rawContent is not None\n    assert doc.retweetedTweet.rawContent is not None", "    assert doc.rawContent is not None\n    assert doc.retweetedTweet.rawContent is not None\n\n    assert doc.rawContent.endswith(doc.retweetedTweet.rawContent)\n"]}
{"filename": "tests/test_api.py", "chunked_list": ["from twscrape.api import API\nfrom twscrape.logger import set_log_level\nfrom twscrape.utils import gather\n\nset_log_level(\"DEBUG\")\n\n\nclass MockedError(Exception):\n    pass\n", "\n\nGQL_GEN = [\n    \"followers\",\n    \"following\",\n    \"retweeters\",\n    \"favoriters\",\n    \"user_tweets\",\n    \"user_tweets_and_replies\",\n]", "    \"user_tweets_and_replies\",\n]\n\n\nasync def test_gql_params(api_mock: API, monkeypatch):\n    for func in GQL_GEN:\n        args = []\n\n        def mock_gql_items(*a, **kw):\n            args.append((a, kw))\n            raise MockedError()\n\n        try:\n            monkeypatch.setattr(api_mock, \"_gql_items\", mock_gql_items)\n            await gather(getattr(api_mock, func)(\"user1\", limit=100, kv={\"count\": 100}))\n        except MockedError:\n            pass\n\n        assert len(args) == 1, f\"{func} not called once\"\n        assert args[0][1][\"limit\"] == 100, f\"limit not changed in {func}\"\n        assert args[0][0][1][\"count\"] == 100, f\"count not changed in {func}\"", ""]}
{"filename": "tests/test_pool.py", "chunked_list": ["from twscrape.accounts_pool import AccountsPool\nfrom twscrape.utils import utc_ts\n\n\nasync def test_add_accounts(pool_mock: AccountsPool):\n    # should add account\n    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")\n    acc = await pool_mock.get(\"user1\")\n    assert acc.username == \"user1\"\n    assert acc.password == \"pass1\"", "    assert acc.username == \"user1\"\n    assert acc.password == \"pass1\"\n    assert acc.email == \"email1\"\n    assert acc.email_password == \"email_pass1\"\n\n    # should not add account with same username\n    await pool_mock.add_account(\"user1\", \"pass2\", \"email2\", \"email_pass2\")\n    acc = await pool_mock.get(\"user1\")\n    assert acc.username == \"user1\"\n    assert acc.password == \"pass1\"", "    assert acc.username == \"user1\"\n    assert acc.password == \"pass1\"\n    assert acc.email == \"email1\"\n    assert acc.email_password == \"email_pass1\"\n\n    # should not add account with different username case\n    await pool_mock.add_account(\"USER1\", \"pass2\", \"email2\", \"email_pass2\")\n    acc = await pool_mock.get(\"user1\")\n    assert acc.username == \"user1\"\n    assert acc.password == \"pass1\"", "    assert acc.username == \"user1\"\n    assert acc.password == \"pass1\"\n    assert acc.email == \"email1\"\n    assert acc.email_password == \"email_pass1\"\n\n    # should add account with different username\n    await pool_mock.add_account(\"user2\", \"pass2\", \"email2\", \"email_pass2\")\n    acc = await pool_mock.get(\"user2\")\n    assert acc.username == \"user2\"\n    assert acc.password == \"pass2\"", "    assert acc.username == \"user2\"\n    assert acc.password == \"pass2\"\n    assert acc.email == \"email2\"\n    assert acc.email_password == \"email_pass2\"\n\n\nasync def test_get_all(pool_mock: AccountsPool):\n    # should return empty list\n    accs = await pool_mock.get_all()\n    assert len(accs) == 0", "    accs = await pool_mock.get_all()\n    assert len(accs) == 0\n\n    # should return all accounts\n    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")\n    await pool_mock.add_account(\"user2\", \"pass2\", \"email2\", \"email_pass2\")\n    accs = await pool_mock.get_all()\n    assert len(accs) == 2\n    assert accs[0].username == \"user1\"\n    assert accs[1].username == \"user2\"", "    assert accs[0].username == \"user1\"\n    assert accs[1].username == \"user2\"\n\n\nasync def test_save(pool_mock: AccountsPool):\n    # should save account\n    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")\n    acc = await pool_mock.get(\"user1\")\n    acc.password = \"pass2\"\n    await pool_mock.save(acc)", "    acc.password = \"pass2\"\n    await pool_mock.save(acc)\n    acc = await pool_mock.get(\"user1\")\n    assert acc.password == \"pass2\"\n\n    # should not save account\n    acc = await pool_mock.get(\"user1\")\n    acc.username = \"user2\"\n    await pool_mock.save(acc)\n    acc = await pool_mock.get(\"user1\")", "    await pool_mock.save(acc)\n    acc = await pool_mock.get(\"user1\")\n    assert acc.username == \"user1\"\n\n\nasync def test_get_for_queue(pool_mock: AccountsPool):\n    Q = \"test_queue\"\n\n    # should return account\n    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")", "    # should return account\n    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")\n    await pool_mock.set_active(\"user1\", True)\n    acc = await pool_mock.get_for_queue(Q)\n    assert acc is not None\n    assert acc.username == \"user1\"\n    assert acc.active is True\n    assert acc.locks is not None\n    assert Q in acc.locks\n    assert acc.locks[Q] is not None", "    assert Q in acc.locks\n    assert acc.locks[Q] is not None\n\n    # should return None\n    acc = await pool_mock.get_for_queue(Q)\n    assert acc is None\n\n\nasync def test_account_unlock(pool_mock: AccountsPool):\n    Q = \"test_queue\"", "async def test_account_unlock(pool_mock: AccountsPool):\n    Q = \"test_queue\"\n\n    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")\n    await pool_mock.set_active(\"user1\", True)\n    acc = await pool_mock.get_for_queue(Q)\n    assert acc is not None\n    assert acc.locks[Q] is not None\n\n    # should unlock account and make available for queue", "\n    # should unlock account and make available for queue\n    await pool_mock.unlock(acc.username, Q)\n    acc = await pool_mock.get_for_queue(Q)\n    assert acc is not None\n    assert acc.locks[Q] is not None\n\n    # should update lock time\n    end_time = utc_ts() + 60  # + 1 minute\n    await pool_mock.lock_until(acc.username, Q, end_time)", "    end_time = utc_ts() + 60  # + 1 minute\n    await pool_mock.lock_until(acc.username, Q, end_time)\n\n    acc = await pool_mock.get(acc.username)\n    assert int(acc.locks[Q].timestamp()) == end_time\n\n\nasync def test_get_stats(pool_mock: AccountsPool):\n    Q = \"SearchTimeline\"\n", "    Q = \"SearchTimeline\"\n\n    # should return empty stats\n    stats = await pool_mock.stats()\n    for k, v in stats.items():\n        assert v == 0, f\"{k} should be 0\"\n\n    # should increate total\n    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")\n    stats = await pool_mock.stats()", "    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")\n    stats = await pool_mock.stats()\n    assert stats[\"total\"] == 1\n    assert stats[\"active\"] == 0\n\n    # should increate active\n    await pool_mock.set_active(\"user1\", True)\n    stats = await pool_mock.stats()\n    assert stats[\"total\"] == 1\n    assert stats[\"active\"] == 1", "    assert stats[\"total\"] == 1\n    assert stats[\"active\"] == 1\n\n    # should update queue stats\n    acc = await pool_mock.get_for_queue(Q)\n    assert acc is not None\n    stats = await pool_mock.stats()\n    assert stats[\"total\"] == 1\n    assert stats[\"active\"] == 1\n    assert stats[f\"locked_{Q}\"] == 1", "    assert stats[\"active\"] == 1\n    assert stats[f\"locked_{Q}\"] == 1\n"]}
{"filename": "tests/test_utils.py", "chunked_list": ["# ruff: noqa: E501\nfrom twscrape.utils import parse_cookies\n\n\ndef test_cookies_parse():\n    val = \"abc=123; def=456; ghi=789\"\n    assert parse_cookies(val) == {\"abc\": \"123\", \"def\": \"456\", \"ghi\": \"789\"}\n\n    val = '{\"abc\": \"123\", \"def\": \"456\", \"ghi\": \"789\"}'\n    assert parse_cookies(val) == {\"abc\": \"123\", \"def\": \"456\", \"ghi\": \"789\"}\n\n    val = '[{\"name\": \"abc\", \"value\": \"123\"}, {\"name\": \"def\", \"value\": \"456\"}, {\"name\": \"ghi\", \"value\": \"789\"}]'\n    assert parse_cookies(val) == {\"abc\": \"123\", \"def\": \"456\", \"ghi\": \"789\"}\n\n    val = \"eyJhYmMiOiAiMTIzIiwgImRlZiI6ICI0NTYiLCAiZ2hpIjogIjc4OSJ9\"\n    assert parse_cookies(val) == {\"abc\": \"123\", \"def\": \"456\", \"ghi\": \"789\"}\n\n    val = \"W3sibmFtZSI6ICJhYmMiLCAidmFsdWUiOiAiMTIzIn0sIHsibmFtZSI6ICJkZWYiLCAidmFsdWUiOiAiNDU2In0sIHsibmFtZSI6ICJnaGkiLCAidmFsdWUiOiAiNzg5In1d\"\n    assert parse_cookies(val) == {\"abc\": \"123\", \"def\": \"456\", \"ghi\": \"789\"}", ""]}
{"filename": "tests/conftest.py", "chunked_list": ["import pytest\n\nfrom twscrape.accounts_pool import AccountsPool\nfrom twscrape.api import API\nfrom twscrape.queue_client import QueueClient\n\n\n@pytest.fixture\ndef pool_mock(tmp_path) -> AccountsPool:\n    db_path = tmp_path / \"test.db\"\n    yield AccountsPool(db_path)  # type: ignore", "def pool_mock(tmp_path) -> AccountsPool:\n    db_path = tmp_path / \"test.db\"\n    yield AccountsPool(db_path)  # type: ignore\n\n\n@pytest.fixture\nasync def client_fixture(pool_mock: AccountsPool):\n    pool_mock._order_by = \"username\"\n\n    for x in range(1, 3):\n        await pool_mock.add_account(f\"user{x}\", f\"pass{x}\", f\"email{x}\", f\"email_pass{x}\")\n        await pool_mock.set_active(f\"user{x}\", True)", "\n    for x in range(1, 3):\n        await pool_mock.add_account(f\"user{x}\", f\"pass{x}\", f\"email{x}\", f\"email_pass{x}\")\n        await pool_mock.set_active(f\"user{x}\", True)\n\n    client = QueueClient(pool_mock, \"SearchTimeline\")\n    yield pool_mock, client\n\n\n@pytest.fixture", "\n@pytest.fixture\nasync def api_mock(pool_mock: AccountsPool):\n    await pool_mock.add_account(\"user1\", \"pass1\", \"email1\", \"email_pass1\")\n    await pool_mock.set_active(\"user1\", True)\n\n    api = API(pool_mock)\n    yield api\n", ""]}
{"filename": "tests/test_queue_client.py", "chunked_list": ["from contextlib import aclosing\n\nimport httpx\nfrom pytest_httpx import HTTPXMock\n\nfrom twscrape.accounts_pool import AccountsPool\nfrom twscrape.logger import set_log_level\nfrom twscrape.queue_client import QueueClient\n\nset_log_level(\"ERROR\")", "\nset_log_level(\"ERROR\")\n\nDB_FILE = \"/tmp/twscrape_test_queue_client.db\"\nURL = \"https://example.com/api\"\nCF = tuple[AccountsPool, QueueClient]\n\n\nasync def get_locked(pool: AccountsPool) -> set[str]:\n    rep = await pool.get_all()", "async def get_locked(pool: AccountsPool) -> set[str]:\n    rep = await pool.get_all()\n    return set([x.username for x in rep if x.locks.get(\"SearchTimeline\", None) is not None])\n\n\nasync def test_lock_account_when_used(httpx_mock: HTTPXMock, client_fixture):\n    pool, client = client_fixture\n\n    locked = await get_locked(pool)\n    assert len(locked) == 0", "    locked = await get_locked(pool)\n    assert len(locked) == 0\n\n    # should lock account on getting it\n    await client.__aenter__()\n    locked = await get_locked(pool)\n    assert len(locked) == 1\n    assert \"user1\" in locked\n\n    # keep locked on request", "\n    # keep locked on request\n    httpx_mock.add_response(url=URL, json={\"foo\": \"bar\"}, status_code=200)\n    assert (await client.get(URL)).json() == {\"foo\": \"bar\"}\n\n    locked = await get_locked(pool)\n    assert len(locked) == 1\n    assert \"user1\" in locked\n\n    # unlock on exit", "\n    # unlock on exit\n    await client.__aexit__(None, None, None)\n    locked = await get_locked(pool)\n    assert len(locked) == 0\n\n\nasync def test_do_not_switch_account_on_200(httpx_mock: HTTPXMock, client_fixture: CF):\n    pool, client = client_fixture\n", "    pool, client = client_fixture\n\n    # get account and lock it\n    await client.__aenter__()\n    locked1 = await get_locked(pool)\n    assert len(locked1) == 1\n\n    # make several requests with status=200\n    for x in range(1):\n        httpx_mock.add_response(url=URL, json={\"foo\": x}, status_code=200)\n        rep = await client.get(URL)\n        assert rep.json() == {\"foo\": x}", "    for x in range(1):\n        httpx_mock.add_response(url=URL, json={\"foo\": x}, status_code=200)\n        rep = await client.get(URL)\n        assert rep.json() == {\"foo\": x}\n\n    # account should not be switched\n    locked2 = await get_locked(pool)\n    assert locked1 == locked2\n\n    # unlock on exit", "\n    # unlock on exit\n    await client.__aexit__(None, None, None)\n    locked3 = await get_locked(pool)\n    assert len(locked3) == 0\n\n\nasync def test_switch_acc_on_http_error(httpx_mock: HTTPXMock, client_fixture: CF):\n    pool, client = client_fixture\n", "    pool, client = client_fixture\n\n    # locked account on enter\n    await client.__aenter__()\n    locked1 = await get_locked(pool)\n    assert len(locked1) == 1\n\n    # fail one request, account should be switched\n    httpx_mock.add_response(url=URL, json={\"foo\": \"1\"}, status_code=403)\n    httpx_mock.add_response(url=URL, json={\"foo\": \"2\"}, status_code=200)", "    httpx_mock.add_response(url=URL, json={\"foo\": \"1\"}, status_code=403)\n    httpx_mock.add_response(url=URL, json={\"foo\": \"2\"}, status_code=200)\n\n    rep = await client.get(URL)\n    assert rep.json() == {\"foo\": \"2\"}\n\n    locked2 = await get_locked(pool)\n    assert len(locked2) == 2\n\n    # unlock on exit (failed account still should locked)", "\n    # unlock on exit (failed account still should locked)\n    await client.__aexit__(None, None, None)\n    locked3 = await get_locked(pool)\n    assert len(locked3) == 1\n    assert locked1 == locked3  # failed account locked\n\n\nasync def test_retry_with_same_acc_on_network_error(httpx_mock: HTTPXMock, client_fixture: CF):\n    pool, client = client_fixture", "async def test_retry_with_same_acc_on_network_error(httpx_mock: HTTPXMock, client_fixture: CF):\n    pool, client = client_fixture\n\n    # locked account on enter\n    await client.__aenter__()\n    locked1 = await get_locked(pool)\n    assert len(locked1) == 1\n\n    # timeout on first request, account should not be switched\n    httpx_mock.add_exception(httpx.ReadTimeout(\"Unable to read within timeout\"))", "    # timeout on first request, account should not be switched\n    httpx_mock.add_exception(httpx.ReadTimeout(\"Unable to read within timeout\"))\n    httpx_mock.add_response(url=URL, json={\"foo\": \"2\"}, status_code=200)\n\n    rep = await client.get(URL)\n    assert rep.json() == {\"foo\": \"2\"}\n\n    locked2 = await get_locked(pool)\n    assert locked2 == locked1\n", "    assert locked2 == locked1\n\n    # check username added to request obj (for logging)\n    username = getattr(rep, \"__username\", None)\n    assert username is not None\n\n\nasync def test_ctx_closed_on_break(httpx_mock: HTTPXMock, client_fixture: CF):\n    pool, client = client_fixture\n", "    pool, client = client_fixture\n\n    async def get_data_stream():\n        async with client as c:\n            counter = 0\n            while True:\n                counter += 1\n                check_retry = counter == 2\n                before_ctx = c.ctx\n\n                if check_retry:\n                    httpx_mock.add_response(url=URL, json={\"counter\": counter}, status_code=403)\n                    httpx_mock.add_response(url=URL, json={\"counter\": counter}, status_code=200)\n                else:\n                    httpx_mock.add_response(url=URL, json={\"counter\": counter}, status_code=200)", "                before_ctx = c.ctx\n\n                if check_retry:\n                    httpx_mock.add_response(url=URL, json={\"counter\": counter}, status_code=403)\n                    httpx_mock.add_response(url=URL, json={\"counter\": counter}, status_code=200)\n                else:\n                    httpx_mock.add_response(url=URL, json={\"counter\": counter}, status_code=200)\n\n                rep = await c.get(URL)\n\n                if check_retry:\n                    assert before_ctx != c.ctx\n                elif before_ctx is not None:\n                    assert before_ctx == c.ctx", "                rep = await c.get(URL)\n\n                if check_retry:\n                    assert before_ctx != c.ctx\n                elif before_ctx is not None:\n                    assert before_ctx == c.ctx\n\n                assert rep.json() == {\"counter\": counter}\n                yield rep.json()[\"counter\"]\n\n                if counter == 9:\n                    return", "                yield rep.json()[\"counter\"]\n\n                if counter == 9:\n                    return\n\n    # need to use async with to break to work\n    async with aclosing(get_data_stream()) as gen:\n        async for x in gen:\n            if x == 3:\n                break", "            if x == 3:\n                break\n\n    # ctx should be None after break\n    assert client.ctx is None\n"]}
{"filename": "examples/parallel_search.py", "chunked_list": ["\"\"\"\nThis example shows how to use twscrape to complete some queries in parallel.\nTo limit the number of concurrent requests, see examples/parallel_search_with_limit.py\n\"\"\"\nimport asyncio\n\nimport twscrape\n\n\nasync def worker(api: twscrape.API, q: str):", "\nasync def worker(api: twscrape.API, q: str):\n    tweets = []\n    try:\n        async for doc in api.search(q):\n            tweets.append(doc)\n    except Exception as e:\n        print(e)\n    finally:\n        return tweets", "\n\nasync def main():\n    api = twscrape.API()\n    # add accounts here or before from cli (see README.md for examples)\n    await api.pool.add_account(\"u1\", \"p1\", \"eu1\", \"ep1\")\n    await api.pool.login_all()\n\n    queries = [\"elon musk\", \"tesla\", \"spacex\", \"neuralink\", \"boring company\"]\n    results = await asyncio.gather(*(worker(api, q) for q in queries))", "    queries = [\"elon musk\", \"tesla\", \"spacex\", \"neuralink\", \"boring company\"]\n    results = await asyncio.gather(*(worker(api, q) for q in queries))\n\n    combined = dict(zip(queries, results))\n    for k, v in combined.items():\n        print(k, len(v))\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())", "if __name__ == \"__main__\":\n    asyncio.run(main())\n"]}
{"filename": "examples/parallel_search_with_limit.py", "chunked_list": ["\"\"\"\nThis example shows how to use twscrape in parallel with concurrency limit.\n\"\"\"\nimport asyncio\nimport time\n\nimport twscrape\n\n\nasync def worker(queue: asyncio.Queue, api: twscrape.API):", "\nasync def worker(queue: asyncio.Queue, api: twscrape.API):\n    while True:\n        query = await queue.get()\n\n        try:\n            tweets = await twscrape.gather(api.search(query))\n            print(f\"{query} - {len(tweets)} - {int(time.time())}\")\n            # do something with tweets here, eg same to file, etc\n        except Exception as e:\n            print(f\"Error on {query} - {type(e)}\")\n        finally:\n            queue.task_done()", "\n\nasync def main():\n    api = twscrape.API()\n    # add accounts here or before from cli (see README.md for examples)\n    await api.pool.add_account(\"u1\", \"p1\", \"eu1\", \"ep1\")\n    await api.pool.login_all()\n\n    queries = [\"elon musk\", \"tesla\", \"spacex\", \"neuralink\", \"boring company\"]\n", "    queries = [\"elon musk\", \"tesla\", \"spacex\", \"neuralink\", \"boring company\"]\n\n    queue = asyncio.Queue()\n\n    workers_count = 2  # limit concurrency here 2 concurrent requests at time\n    workers = [asyncio.create_task(worker(queue, api)) for _ in range(workers_count)]\n    for q in queries:\n        queue.put_nowait(q)\n\n    await queue.join()\n    for worker_task in workers:\n        worker_task.cancel()", "\n    await queue.join()\n    for worker_task in workers:\n        worker_task.cancel()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n", ""]}
