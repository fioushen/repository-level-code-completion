{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages, Extension\n\nVERSION = '0.8.5'\nDESCRIPTION = 'Boolean Hypervectors'\nLONG_DESCRIPTION = 'Boolean Hypervectors with various operators for experiments in hyperdimensional computing (HDC).'\n\nnative = Extension(\"bhv.cnative\",\n                   sources=['bhv/cnative/bindings.cpp',\n                            'bhv/cnative/TurboSHAKE_opt/TurboSHAKE.cpp',\n                            'bhv/cnative/TurboSHAKE_opt/KeccakP-1600-opt64.cpp',", "                            'bhv/cnative/TurboSHAKE_opt/TurboSHAKE.cpp',\n                            'bhv/cnative/TurboSHAKE_opt/KeccakP-1600-opt64.cpp',\n                            'bhv/cnative/TurboSHAKE_AVX512/TurboSHAKE.cpp',\n                            'bhv/cnative/TurboSHAKE_AVX512/KeccakP-1600-AVX512.cpp',\n                            ],\n                   include_dirs=['bhv/cnative', 'bhv/cnative/TurboSHAKEopt'],\n                   extra_compile_args=['-std=c++2a', '-O3', '-march=native', '-Wall'],\n                   language='c++',\n                   optional=True)\n", "                   optional=True)\n\nsetup(\n    name=\"bhv\",\n    version=VERSION,\n    author=\"Adam Vandervorst\",\n    author_email=\"contact@adamv.be\",\n    description=DESCRIPTION,\n    long_description=LONG_DESCRIPTION,\n    url=\"https://github.com/Adam-Vandervorst/PyBHV\",", "    long_description=LONG_DESCRIPTION,\n    url=\"https://github.com/Adam-Vandervorst/PyBHV\",\n    packages=find_packages(),\n    install_requires=[],\n    extras_require={\n        \"pytorch\": [\"torch>=2.0.0\"],\n        \"np\": [\"numpy>=1.24.2\"],\n    },\n    keywords='ai binary hypervector hdc bsc',\n    python_requires='>=3.8',", "    keywords='ai binary hypervector hdc bsc',\n    python_requires='>=3.8',\n    classifiers=[\n        'Development Status :: 2 - Pre-Alpha',\n\n        'Intended Audience :: Developers',\n        'Intended Audience :: Science/Research',\n\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'Topic :: Software Development :: Libraries',", "        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'Topic :: Software Development :: Libraries',\n\n        'License :: Free for non-commercial use',\n\n        'Environment :: GPU :: NVIDIA CUDA',\n\n        'Operating System :: POSIX :: Linux',\n\n        'Programming Language :: Python :: 3.8',", "\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n\n        'Typing :: Typed',\n    ],\n    ext_modules=[native]\n)", "    ext_modules=[native]\n)\n"]}
{"filename": "bhv/pytorch.py", "chunked_list": ["from .abstract import *\nimport torch\n\n\n# GPT-4 wrote this code, do not use in production\ndef pack_bool_to_long(bool_tensor):\n    assert bool_tensor.dtype == torch.bool, \"Input tensor must be of dtype torch.bool\"\n    assert bool_tensor.numel() % 64 == 0, \"Input tensor must have a number of elements divisible by 64\"\n\n    bool_tensor = bool_tensor.view(-1, 64)\n    packed_tensor = torch.zeros(bool_tensor.shape[0], dtype=torch.int64)\n\n    for i in range(64):\n        packed_tensor |= (bool_tensor[:, i].to(torch.int64) << i)\n\n    return packed_tensor", "\n\n# GPT-4 wrote this code, do not use in production\ndef unpack_long_to_bool(packed_tensor):\n    assert packed_tensor.dtype == torch.int64, \"Input tensor must be of dtype torch.int64\"\n\n    bool_tensor = torch.zeros(packed_tensor.numel() * 64, dtype=torch.bool)\n\n    for i in range(64):\n        bool_tensor[i::64] = ((packed_tensor >> i) & 1).bool()\n\n    return bool_tensor", "\n\nclass TorchBoolPermutation(MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\n    def __init__(self, tensor: torch.IntTensor):\n        self.data: torch.BoolTensor = tensor\n\n    @classmethod\n    def random(cls) -> 'TorchBoolPermutation':\n        return TorchBoolPermutation(torch.randperm(DIMENSION))\n\n    def __mul__(self, other: 'TorchBoolPermutation') -> 'TorchBoolPermutation':\n        return TorchBoolPermutation(self.data[other.data])\n\n    def __invert__(self) -> 'TorchBoolPermutation':\n        inv_permutation = torch.empty_like(self.data)\n        inv_permutation[self.data] = torch.arange(DIMENSION)\n        return TorchBoolPermutation(inv_permutation)\n\n    def __call__(self, hv: 'TorchBoolBHV') -> 'TorchBoolBHV':\n        return hv.permute_bits(self)", "\nTorchBoolPermutation.IDENTITY = TorchBoolPermutation(torch.arange(DIMENSION))\n\n\nclass TorchBoolBHV(AbstractBHV):\n    def __init__(self, tensor: torch.BoolTensor):\n        self.data: torch.BoolTensor = tensor\n\n    @classmethod\n    def rand(cls) -> 'TorchBoolBHV':\n        return TorchBoolBHV(torch.empty(DIMENSION, dtype=torch.bool).random_())\n\n    @classmethod\n    def random(cls, active: float) -> 'TorchBoolBHV':\n        assert 0. <= active <= 1.\n        return TorchBoolBHV(torch.empty(DIMENSION, dtype=torch.bool).bernoulli_(active))\n\n    def select(self, when1: 'TorchBoolBHV', when0: 'TorchBoolBHV') -> 'TorchBoolBHV':\n        return TorchBoolBHV(torch.where(self.data, when1.data, when0.data))\n\n    @classmethod\n    def majority(cls, vs: list['TorchBoolBHV']) -> 'TorchBoolBHV':\n        data = [v.data for v in vs]\n        extra = [cls.rand().data] if len(vs) % 2 == 0 else []\n\n        tensor = torch.stack(data + extra)\n        counts = tensor.sum(dim=-2, dtype=torch.uint8 if len(vs) < 256 else torch.int32)\n\n        threshold = (len(vs) + len(extra))//2\n\n        return TorchBoolBHV(torch.greater(counts,  threshold).to(torch.bool))\n\n    def roll_bits(self, n: int) -> 'TorchBoolBHV':\n        return TorchBoolBHV(torch.roll(self.data, n))\n\n    def permute_bits(self, permutation: TorchBoolPermutation) -> 'TorchBoolBHV':\n        return TorchBoolBHV(self.data[permutation.data])\n\n    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'TorchBoolBHV':\n        return self.permute_bits(TorchBoolPermutation.get(permutation_id))\n\n    def swap_halves(self) -> 'TorchBoolBHV':\n        return self.roll_bits(DIMENSION//2)\n\n    def rehash(self) -> 'TorchBoolBHV':\n        # torch to bytes is broken hence custom function https://github.com/pytorch/pytorch/issues/33041\n        offsets = [(H & self).active() for H in self._HS]\n        res = self._HASH\n        for o in offsets:\n            res = res ^ self.roll_bits(o)\n        return res\n\n    def __eq__(self, other: 'TorchBoolBHV') -> bool:\n        return torch.equal(self.data, other.data)\n\n    def __xor__(self, other: 'TorchBoolBHV') -> 'TorchBoolBHV':\n        return TorchBoolBHV(torch.bitwise_xor(self.data, other.data))\n\n    def __and__(self, other: 'TorchBoolBHV') -> 'TorchBoolBHV':\n        return TorchBoolBHV(torch.bitwise_and(self.data, other.data))\n\n    def __or__(self, other: 'TorchBoolBHV') -> 'TorchBoolBHV':\n        return TorchBoolBHV(torch.bitwise_or(self.data, other.data))\n\n    def __invert__(self) -> 'TorchBoolBHV':\n        return TorchBoolBHV(torch.bitwise_not(self.data))\n\n    def active(self) -> int:\n        return torch.sum(self.data).item()\n\n    def pack(self) -> 'TorchPackedBHV':\n        return TorchPackedBHV(pack_bool_to_long(self.data))", "\nTorchBoolBHV.ZERO = TorchBoolBHV(torch.zeros(DIMENSION, dtype=torch.bool))\nTorchBoolBHV.ONE = TorchBoolBHV(torch.ones(DIMENSION, dtype=torch.bool))\nTorchBoolBHV._HASH = TorchBoolBHV.rand()\nTorchBoolBHV._HS = TorchBoolBHV.nrand2(5, power=2)\nTorchBoolBHV._FEISTAL_SUBKEYS = TorchBoolBHV.nrand2(TorchBoolBHV._FEISTAL_ROUNDS, 4)\n_halfb = torch.zeros(DIMENSION, dtype=torch.bool)\n_halfb[:DIMENSION//2] = 1\nTorchBoolBHV.HALF = TorchBoolBHV(_halfb)\n", "TorchBoolBHV.HALF = TorchBoolBHV(_halfb)\n\n\nclass TorchWordPermutation(MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\n    def __init__(self, tensor: torch.IntTensor):\n        self.data: torch.BoolTensor = tensor\n\n    @classmethod\n    def random(cls) -> 'TorchWordPermutation':\n        return TorchWordPermutation(torch.randperm(DIMENSION//64))\n\n    def __mul__(self, other: 'TorchWordPermutation') -> 'TorchWordPermutation':\n        return TorchWordPermutation(self.data[other.data])\n\n    def __invert__(self) -> 'TorchWordPermutation':\n        inv_permutation = torch.empty_like(self.data)\n        inv_permutation[self.data] = torch.arange(DIMENSION//64)\n        return TorchWordPermutation(inv_permutation)\n\n    def __call__(self, hv: 'TorchPackedBHV') -> 'TorchPackedBHV':\n        return hv.permute_words(self)", "\nTorchWordPermutation.IDENTITY = TorchWordPermutation(torch.arange(DIMENSION//64))\n\n\nclass TorchPackedBHV(AbstractBHV):\n    def __init__(self, tensor: torch.LongTensor):\n        assert DIMENSION % 64 == 0\n        self.data: torch.LongTensor = tensor\n\n    @classmethod\n    def rand(cls) -> Self:\n        return TorchPackedBHV(torch.randint(-9223372036854775808, 9223372036854775807, size=(DIMENSION//64,), dtype=torch.long))\n\n    @classmethod\n    def random(cls, active) -> Self:\n        assert 0. <= active <= 1.\n        return TorchBoolBHV.random(active).pack()\n\n    def roll_words(self, n: int) -> 'TorchPackedBHV':\n        return TorchPackedBHV(torch.roll(self.data, n))\n\n    def permute_words(self, permutation: TorchWordPermutation) -> 'TorchPackedBHV':\n        return TorchPackedBHV(self.data[permutation.data])\n\n    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'TorchPackedBHV':\n        return self.permute_words(TorchWordPermutation.get(permutation_id))\n\n    def swap_halves(self) -> 'TorchPackedBHV':\n        return self.roll_words(DIMENSION//128)\n\n    def rehash(self) -> 'TorchPackedBHV':\n        return self.unpack().rehash().pack()\n\n    def __eq__(self, other: 'TorchBoolBHV') -> bool:\n        return torch.equal(self.data, other.data)\n\n    def __xor__(self, other: 'TorchPackedBHV') -> 'TorchPackedBHV':\n        return TorchPackedBHV(torch.bitwise_xor(self.data, other.data))\n\n    def __and__(self, other: 'TorchPackedBHV') -> 'TorchPackedBHV':\n        return TorchPackedBHV(torch.bitwise_and(self.data, other.data))\n\n    def __or__(self, other: 'TorchPackedBHV') -> 'TorchPackedBHV':\n        return TorchPackedBHV(torch.bitwise_or(self.data, other.data))\n\n    def __invert__(self) -> 'TorchPackedBHV':\n        return TorchPackedBHV(torch.bitwise_not(self.data))\n\n    def active(self) -> int:\n        # currently no efficient implementation available for this https://github.com/pytorch/pytorch/issues/36380\n        x = self.data\n        x = x - ((x >> 1) & 0x5555555555555555)\n        x = (x & 0x3333333333333333) + ((x >> 2) & 0x3333333333333333)\n        x = (x + (x >> 4)) & 0x0f0f0f0f0f0f0f0f\n        x = (x * 0x0101010101010101) >> 56\n        return torch.sum(x).item()\n\n    def unpack(self) -> 'TorchBoolBHV':\n        return TorchBoolBHV(unpack_long_to_bool(self.data))", "\nTorchPackedBHV.ZERO = TorchPackedBHV(torch.zeros(DIMENSION//64, dtype=torch.long))\nTorchPackedBHV.ONE = TorchPackedBHV(torch.full((DIMENSION//64,), fill_value=-1, dtype=torch.long))  # -1 is all ones in torch's encoding\nTorchPackedBHV._FEISTAL_SUBKEYS = TorchPackedBHV.nrand2(TorchPackedBHV._FEISTAL_ROUNDS, 4)\n_half64 = torch.zeros(DIMENSION//64, dtype=torch.long)\n_half64[:DIMENSION//128] = -1\nTorchPackedBHV.HALF = TorchPackedBHV(_half64)\n"]}
{"filename": "bhv/np.py", "chunked_list": ["from .abstract import *\nimport numpy as np\nfrom sys import byteorder, version_info\n\n\nclass NumPyBoolPermutation(MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n    rng = np.random.default_rng()\n\n    def __init__(self, array: np.ndarray):\n        self.data: np.ndarray = array\n\n    @classmethod\n    def random(cls) -> 'NumPyBoolPermutation':\n        return NumPyBoolPermutation(cls.rng.permutation(DIMENSION))\n\n    def __mul__(self, other: 'NumPyBoolPermutation') -> 'NumPyBoolPermutation':\n        return NumPyBoolPermutation(self.data[other.data])\n\n    def __invert__(self) -> 'NumPyBoolPermutation':\n        inv_permutation = np.empty_like(self.data)\n        inv_permutation[self.data] = np.arange(DIMENSION)\n        return NumPyBoolPermutation(inv_permutation)\n\n    def __call__(self, hv: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n        return hv.permute_bits(self)", "\nNumPyBoolPermutation.IDENTITY = NumPyBoolPermutation(np.arange(DIMENSION))\n\n\nclass NumPyBoolBHV(AbstractBHV):\n    def __init__(self, array: np.ndarray):\n        self.data: np.ndarray = array\n\n    @classmethod\n    def rand(cls) -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.random.randint(0, high=2, size=DIMENSION, dtype=np.bool_))\n\n    @classmethod\n    def random(cls, active: float) -> 'NumPyBoolBHV':\n        assert 0. <= active <= 1.\n        return NumPyBoolBHV(np.random.binomial(1, active, DIMENSION))\n\n    def select(self, when1: 'NumPyBoolBHV', when0: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.where(self.data, when1.data, when0.data))\n\n    def swap_halves(self) -> 'NumPyBoolBHV':\n        return self.roll_bits(DIMENSION//2)\n\n    def rehash(self) -> 'NumPyBoolBHV':\n        return self.pack8().rehash().unpack()\n\n    def roll_bits(self, n: int) -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.roll(self.data, n))\n\n    def permute_bits(self, permutation: 'NumPyBoolPermutation') -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(self.data[permutation.data])\n\n    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'NumPyBoolBHV':\n        return self.permute_bits(NumPyBoolPermutation.get(permutation_id))\n\n    @classmethod\n    def majority(cls, vs: list['NumPyBoolBHV']) -> 'NumPyBoolBHV':\n        data = [v.data for v in vs]\n        extra = [cls.rand().data] if len(vs) % 2 == 0 else []\n\n        tensor = np.stack(data + extra)\n        counts = tensor.sum(axis=-2, dtype=np.uint8 if len(vs) < 256 else np.uint32)\n\n        threshold = (len(vs) + len(extra))//2\n\n        return NumPyBoolBHV(np.greater(counts, threshold))\n\n    def __eq__(self, other: 'NumPyBoolBHV') -> bool:\n        return np.array_equal(self.data, other.data)\n\n    def __xor__(self, other: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.bitwise_xor(self.data, other.data))\n\n    def __and__(self, other: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.bitwise_and(self.data, other.data))\n\n    def __or__(self, other: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.bitwise_or(self.data, other.data))\n\n    def __invert__(self) -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.bitwise_not(self.data))\n\n    def active(self) -> int:\n        return int(np.sum(self.data))\n\n    def pack8(self) -> 'NumPyPacked8BHV':\n        return NumPyPacked8BHV(np.packbits(self.data))\n\n    def pack64(self) -> 'NumPyPacked64BHV':\n        return NumPyPacked64BHV(np.packbits(self.data).view(dtype=np.uint64))\n\n    def to_bytes(self):\n        return self.pack8().to_bytes()\n\n    @classmethod\n    def from_bytes(cls, bs):\n        return NumPyPacked8BHV.from_bytes(bs).unpack()\n\n    def bits(self):\n        return iter(self.data.astype(np.uint8))\n\n    def bitstring(self) -> str:\n        b = ord('0')\n        return (self.data.astype(np.uint8) + b).tobytes().decode('ascii')\n\n    @classmethod\n    def from_bitstring(cls, s: str) -> str:\n        b = ord('0')\n        return cls((np.frombuffer(bytes(s, 'ascii'), dtype=np.uint8) - b).astype(np.bool_))", "\nNumPyBoolBHV.ZERO = NumPyBoolBHV(np.zeros(DIMENSION, dtype=np.bool_))\nNumPyBoolBHV.ONE = NumPyBoolBHV(np.ones(DIMENSION, dtype=np.bool_))\nNumPyBoolBHV._FEISTAL_SUBKEYS = NumPyBoolBHV.nrand2(NumPyBoolBHV._FEISTAL_ROUNDS, 4)\n_halfb = np.zeros(DIMENSION, dtype=np.bool_)\n_halfb[:DIMENSION//2] = np.bool_(True)\nNumPyBoolBHV.HALF = NumPyBoolBHV(_halfb)\n\n\nclass NumPyBytePermutation(MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n    rng = np.random.default_rng()\n\n    def __init__(self, array: np.ndarray):\n        self.data: np.ndarray = array\n\n    @classmethod\n    def random(cls) -> 'NumPyBytePermutation':\n        return NumPyBytePermutation(cls.rng.permutation(DIMENSION//8))\n\n    def __mul__(self, other: 'NumPyBytePermutation') -> 'NumPyBytePermutation':\n        return NumPyBytePermutation(self.data[other.data])\n\n    def __invert__(self) -> 'NumPyBytePermutation':\n        inv_permutation = np.empty_like(self.data)\n        inv_permutation[self.data] = np.arange(DIMENSION//8)\n        return NumPyBytePermutation(inv_permutation)\n\n    def __call__(self, hv: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n        return hv.permute_bytes(self)", "\nclass NumPyBytePermutation(MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n    rng = np.random.default_rng()\n\n    def __init__(self, array: np.ndarray):\n        self.data: np.ndarray = array\n\n    @classmethod\n    def random(cls) -> 'NumPyBytePermutation':\n        return NumPyBytePermutation(cls.rng.permutation(DIMENSION//8))\n\n    def __mul__(self, other: 'NumPyBytePermutation') -> 'NumPyBytePermutation':\n        return NumPyBytePermutation(self.data[other.data])\n\n    def __invert__(self) -> 'NumPyBytePermutation':\n        inv_permutation = np.empty_like(self.data)\n        inv_permutation[self.data] = np.arange(DIMENSION//8)\n        return NumPyBytePermutation(inv_permutation)\n\n    def __call__(self, hv: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n        return hv.permute_bytes(self)", "\nNumPyBytePermutation.IDENTITY = NumPyBytePermutation(np.arange(DIMENSION//8))\n\n\nclass NumPyPacked8BHV(AbstractBHV):\n    def __init__(self, array: np.ndarray):\n        self.data: np.ndarray = array\n\n    @classmethod\n    def rand(cls) -> 'NumPyPacked8BHV':\n        return NumPyPacked8BHV(np.random.randint(0, 255, DIMENSION//8, dtype=np.uint8))\n\n    @classmethod\n    def random(cls, active: float) -> 'NumPyPacked8BHV':\n        assert 0. <= active <= 1.\n        return NumPyBoolBHV.random(active).pack8()\n\n    def roll_bytes(self, n: int) -> 'NumPyPacked8BHV':\n        assert abs(n) < DIMENSION//8, \"only supports DIMENSION/8 rolls\"\n        return NumPyPacked8BHV(np.roll(self.data, n))\n\n    def swap_halves(self) -> 'NumPyPacked8BHV':\n        return self.roll_bytes(DIMENSION//16)\n\n    def permute_bytes(self, permutation: 'NumPyBytePermutation') -> 'NumPyPacked8BHV':\n        return NumPyPacked8BHV(self.data[permutation.data])\n\n    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'NumPyPacked8BHV':\n        return self.permute_bytes(NumPyBytePermutation.get(permutation_id))\n\n    def rehash(self) -> 'NumPyPacked8BHV':\n        byte_data = self.to_bytes()\n        rehashed_byte_data = hashlib.shake_256(byte_data).digest(DIMENSION//8)\n        return NumPyPacked8BHV.from_bytes(rehashed_byte_data)\n\n    def __eq__(self, other: 'NumPyPacked8BHV') -> bool:\n        return np.array_equal(self.data, other.data)\n\n    def __xor__(self, other: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n        return NumPyPacked8BHV(np.bitwise_xor(self.data, other.data))\n\n    def __and__(self, other: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n        return NumPyPacked8BHV(np.bitwise_and(self.data, other.data))\n\n    def __or__(self, other: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n        return NumPyPacked8BHV(np.bitwise_or(self.data, other.data))\n\n    def __invert__(self) -> 'NumPyPacked8BHV':\n        return NumPyPacked8BHV(np.bitwise_not(self.data))\n\n    if version_info[2] >= 10:\n        def active(self) -> int:\n            return int.from_bytes(self.data.tobytes(), byteorder).bit_count()\n    else:\n        lookup = np.array([bin(i).count(\"1\") for i in range(256)])\n\n        def active(self) -> int:\n            return self.lookup[self.data].sum()\n\n    def unpack(self) -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.unpackbits(self.data))\n\n    def repack64(self) -> 'NumPyPacked64BHV':\n        return NumPyPacked64BHV(self.data.view(dtype=np.uint64))\n\n    def to_bytes(self):\n        return self.data.tobytes()\n\n    @classmethod\n    def from_bytes(cls, bs):\n        return cls(np.frombuffer(bs, dtype=np.uint8))", "\n\nNumPyPacked8BHV.ZERO = NumPyPacked8BHV(np.zeros(DIMENSION//8, dtype=np.uint8))\nNumPyPacked8BHV.ONE = NumPyPacked8BHV(np.full(DIMENSION//8, fill_value=255, dtype=np.uint8))\nNumPyPacked8BHV._FEISTAL_SUBKEYS = NumPyPacked8BHV.nrand2(NumPyPacked8BHV._FEISTAL_ROUNDS, 4)\n_half8 = np.zeros(DIMENSION//8, dtype=np.uint8)\n_half8[:DIMENSION//16] = np.uint8(255)\nNumPyPacked8BHV.HALF = NumPyPacked8BHV(_half8)\n\n\nclass NumPyWordPermutation(MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n    rng = np.random.default_rng()\n\n    def __init__(self, array: np.ndarray):\n        self.data: np.ndarray = array\n\n    @classmethod\n    def random(cls) -> 'NumPyWordPermutation':\n        return NumPyWordPermutation(cls.rng.permutation(DIMENSION//64))\n\n    def __mul__(self, other: 'NumPyWordPermutation') -> 'NumPyWordPermutation':\n        return NumPyWordPermutation(self.data[other.data])\n\n    def __invert__(self) -> 'NumPyWordPermutation':\n        inv_permutation = np.empty_like(self.data)\n        inv_permutation[self.data] = np.arange(DIMENSION//64)\n        return NumPyWordPermutation(inv_permutation)\n\n    def __call__(self, hv: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n        return hv.permute_words(self)", "\n\nclass NumPyWordPermutation(MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n    rng = np.random.default_rng()\n\n    def __init__(self, array: np.ndarray):\n        self.data: np.ndarray = array\n\n    @classmethod\n    def random(cls) -> 'NumPyWordPermutation':\n        return NumPyWordPermutation(cls.rng.permutation(DIMENSION//64))\n\n    def __mul__(self, other: 'NumPyWordPermutation') -> 'NumPyWordPermutation':\n        return NumPyWordPermutation(self.data[other.data])\n\n    def __invert__(self) -> 'NumPyWordPermutation':\n        inv_permutation = np.empty_like(self.data)\n        inv_permutation[self.data] = np.arange(DIMENSION//64)\n        return NumPyWordPermutation(inv_permutation)\n\n    def __call__(self, hv: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n        return hv.permute_words(self)", "\nNumPyWordPermutation.IDENTITY = NumPyWordPermutation(np.arange(DIMENSION//64))\n\n\nclass NumPyPacked64BHV(AbstractBHV):\n    rng = np.random.SFC64()\n\n    def __init__(self, array: np.ndarray):\n        self.data: np.ndarray = array\n\n    @classmethod\n    def rand(cls) -> 'NumPyPacked64BHV':\n        return NumPyPacked64BHV(cls.rng.random_raw(DIMENSION//64))\n\n    @classmethod\n    def random(cls, active: float) -> 'NumPyPacked64BHV':\n        assert 0. <= active <= 1.\n        return NumPyBoolBHV.random(active).pack64()\n\n    @classmethod\n    def majority(cls, vs: list['NumPyPacked64BHV']) -> 'NumPyPacked64BHV':\n        if len(vs) <= 9:\n            return cls._majority_via_custom(vs)\n        else:\n            return cls._majority_via_unpacked(vs)\n\n    @classmethod\n    def _majority_via_unpacked(cls, vs: list['NumPyPacked64BHV']) -> 'NumPyPacked64BHV':\n        return NumPyBoolBHV.majority([v.unpack() for v in vs]).pack64()\n\n    def swap_halves(self) -> 'NumPyPacked64BHV':\n        return self.roll_words(DIMENSION//128)\n\n    def rehash(self) -> 'NumPyPacked64BHV':\n        return self.repack8().rehash().repack64()\n\n    def roll_words(self, n: int) -> 'NumPyPacked64BHV':\n        assert abs(n) < DIMENSION//64, \"only supports DIMENSION/64 rolls\"\n        return NumPyPacked64BHV(np.roll(self.data, n))\n\n    def roll_word_bits(self, n: int) -> 'NumPyPacked64BHV':\n        assert abs(n) < 64, \"only supports 64 rolls\"\n        # https://github.com/numba/numba/issues/6381\n        if n == 0:\n            return NumPyPacked64BHV(self.data)\n        elif n > 0:\n            return NumPyPacked64BHV(np.bitwise_or(np.right_shift(self.data, np.uint64(n)), np.left_shift(self.data, np.uint64(64 - n))))\n        else:\n            return NumPyPacked64BHV(np.bitwise_or(np.left_shift(self.data, np.uint64(n)), np.right_shift(self.data, np.uint64(64 - n))))\n\n    # roll_words and roll_word_bits could be combined for more options allowing positive and negative combinations\n    # ((1 2 3 4) (a b c d) (\u03b1 \u03b2 \u03b3 \u03b4))\n    # rolled by 1, -2 for example results in\n    # ((\u03b3 \u03b4 \u03b1 \u03b2) (3 4 1 2) (c d a b))\n\n    def permute_words(self, permutation: 'NumPyWordPermutation') -> 'NumPyPacked64BHV':\n        return NumPyPacked64BHV(self.data[permutation.data])\n\n    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'NumPyPacked64BHV':\n        return self.permute_words(NumPyWordPermutation.get(permutation_id))\n\n    def __eq__(self, other: 'NumPyPacked64BHV') -> bool:\n        return np.array_equal(self.data, other.data)\n\n    def __xor__(self, other: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n        return NumPyPacked64BHV(np.bitwise_xor(self.data, other.data))\n\n    def __and__(self, other: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n        return NumPyPacked64BHV(np.bitwise_and(self.data, other.data))\n\n    def __or__(self, other: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n        return NumPyPacked64BHV(np.bitwise_or(self.data, other.data))\n\n    def __invert__(self) -> 'NumPyPacked64BHV':\n        return NumPyPacked64BHV(np.bitwise_not(self.data))\n\n    if version_info[2] >= 10:\n        def active(self) -> int:\n            return int.from_bytes(self.data.tobytes(), byteorder).bit_count()\n    else:\n        def active(self) -> int:\n            return self.repack8().active()\n\n    def unpack(self) -> 'NumPyBoolBHV':\n        return NumPyBoolBHV(np.unpackbits(self.data.view(np.uint8)))\n\n    def repack8(self) -> 'NumPyPacked8BHV':\n        return NumPyPacked8BHV(self.data.view(dtype=np.uint8))\n\n    def to_bytes(self):\n        return self.repack8().to_bytes()\n\n    @classmethod\n    def from_bytes(cls, bs):\n        return NumPyPacked8BHV.from_bytes(bs).repack64()", "\nNumPyPacked64BHV.ZERO = NumPyPacked64BHV(np.zeros(DIMENSION//64, dtype=np.uint64))\nNumPyPacked64BHV.ONE = NumPyPacked64BHV(np.full(DIMENSION//64, fill_value=-1, dtype=np.uint64))\nNumPyPacked64BHV._FEISTAL_SUBKEYS = NumPyPacked64BHV.nrand2(NumPyPacked64BHV._FEISTAL_ROUNDS, 4)\n_half64 = np.zeros(DIMENSION//64, dtype=np.uint64)\n_half64[:DIMENSION//128] = np.uint64(-1)\nNumPyPacked64BHV.HALF = NumPyPacked64BHV(_half64)\n"]}
{"filename": "bhv/embedding.py", "chunked_list": ["from bhv.abstract import AbstractBHV\nfrom typing import Generic, TypeVar, Type, Optional\n\nT = TypeVar('T')\n\n\nclass Embedding(Generic[T]):\n    def forward(self, x: T) -> AbstractBHV:\n        raise NotImplementedError()\n\n    def back(self, x: AbstractBHV) -> Optional[T]:\n        raise NotImplementedError()", "\n\nclass Random(Embedding):\n    def __init__(self, hvt: Type[AbstractBHV]):\n        self.hvt = hvt\n        self.hvs = {}\n\n    def forward(self, x: T) -> AbstractBHV:\n        if x in self.hvs:\n            return self.hvs[x]\n        else:\n            hv = self.hvt.rand()\n            self.hvs[x] = hv\n            return hv\n\n    def back(self, input_hv: AbstractBHV, threshold=.1) -> Optional[T]:\n        best_x = None\n        best_score = 1.\n        for x, hv in self.hvs.items():\n            score = input_hv.bit_error_rate(hv)\n            if score < best_score and score < threshold:\n                best_score = score\n                best_x = x\n        return best_x", "\n\nclass InterpolateBetween(Embedding):\n    def __init__(self, hvt: Type[AbstractBHV], begin: AbstractBHV = None, end: AbstractBHV = None):\n        self.hvt = hvt\n        self.begin = hvt.rand() if begin is None else begin\n        self.end = hvt.rand() if end is None else end\n\n    def forward(self, x: float) -> AbstractBHV:\n        return self.end.select_random(self.begin, x)\n\n    def back(self, input_hv: AbstractBHV, threshold=.1) -> Optional[float]:\n        beginh = self.begin.bit_error_rate(input_hv)\n        endh = self.end.bit_error_rate(input_hv)\n        totalh = endh + beginh\n        if abs(totalh - .5) < threshold:\n            return beginh/totalh", "\n\n\ndef make_mask(on, n):\n    ar = torch.zeros(n, dtype=torch.bool)\n    ar[:on] = True\n    perm = torch.randperm(n)\n    return ar[perm]\n\ndef binarize_3(x, n):\n    on = int(float(x)*(n+1))\n    if x == 1.0:\n        return torch.ones(n, dtype=torch.bool)\n    ar = torch.zeros(n, dtype=torch.bool)\n    ar[:on] = True\n    return ar", "\ndef binarize_3(x, n):\n    on = int(float(x)*(n+1))\n    if x == 1.0:\n        return torch.ones(n, dtype=torch.bool)\n    ar = torch.zeros(n, dtype=torch.bool)\n    ar[:on] = True\n    return ar\n\ndef filln(xs, n):\n    ar = torch.empty(len(xs)*n, dtype=torch.bool)\n    for i, x in enumerate(xs):\n        ar[i*n:(i + 1)*n] = binarize_3(x, n)\n    return ar", "\ndef filln(xs, n):\n    ar = torch.empty(len(xs)*n, dtype=torch.bool)\n    for i, x in enumerate(xs):\n        ar[i*n:(i + 1)*n] = binarize_3(x, n)\n    return ar\n"]}
{"filename": "bhv/poibin.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# MIT License\n#\n# Copyright (c) 2016 Mika J. Straka\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", "#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\"\"\"\nCreated on Tue Mar 29, 2016\n\nModule:\n    poibin - Poisson Binomial Distribution\n\nAuthor:", "\nAuthor:\n    Mika Straka\n\nDescription:\n    Implementation of the Poisson Binomial distribution for the sum of\n    independent and not identically distributed random variables as described\n    in the reference [Hong2013]_.\n\n    Implemented method:", "\n    Implemented method:\n\n        * ``pmf``: probability mass function\n        * ``cdf``: cumulative distribution function\n        * ``pval``: p-value (1 - cdf)\n\nUsage:\n    Be ``p`` a list or  NumPy array of success probabilities for ``n``\n    non-identically distributed Bernoulli random variables.", "    Be ``p`` a list or  NumPy array of success probabilities for ``n``\n    non-identically distributed Bernoulli random variables.\n\n    Import the module and create an instance of the distribution with::\n\n        >>> from poibin import PoiBin\n        >>> pb = PoiBin(p)\n\n    Be ``x`` a list or NumPy array of different number of successes.\n    To obtain the:", "    Be ``x`` a list or NumPy array of different number of successes.\n    To obtain the:\n\n    * probability mass function of x, use::\n\n        >>> pb.pmf(x)\n\n    * cumulative distribution function of x, use::\n\n        >>> pb.cdf(x)", "\n        >>> pb.cdf(x)\n\n    * p-values of x, use::\n\n        >>> pb.pval(x)\n\n    The functions are applied component-wise and a NumPy array of the same\n    length as ``x`` is returned.\n", "    length as ``x`` is returned.\n\nReferences:\n.. [Hong2013] Yili Hong, On computing the distribution function for the Poisson\n    binomial distribution,\n    Computational Statistics & Data Analysis, Volume 59, March 2013,\n    Pages 41-51, ISSN 0167-9473,\n    http://dx.doi.org/10.1016/j.csda.2012.10.006.\n\"\"\"\n", "\"\"\"\n\nimport collections\nimport numpy as np\n\n\nclass PoiBin(object):\n    \"\"\"Poisson Binomial distribution for random variables.\n\n    This class implements the Poisson Binomial distribution for Bernoulli\n    trials with different success probabilities. The distribution describes\n    thus a random variable that is the sum of independent and not identically\n    distributed single Bernoulli random variables.\n\n    The class offers methods for calculating the probability mass function, the\n    cumulative distribution function, and p-values for right-sided testing.\n    \"\"\"\n\n    def __init__(self, probabilities):\n        \"\"\"Initialize the class and calculate the ``pmf`` and ``cdf``.\n\n        :param probabilities: sequence of success probabilities :math:`p_i \\\\in\n            [0, 1] \\\\forall i \\\\in [0, N]` for :math:`N` independent but not\n            identically distributed Bernoulli random variables\n        :type probabilities: numpy.array\n        \"\"\"\n        self.success_probabilities = np.array(probabilities)\n        self.number_trials = self.success_probabilities.size\n        self.check_input_prob()\n        self.omega = 2 * np.pi / (self.number_trials + 1)\n        self.pmf_list = self.get_pmf_xi()\n        self.cdf_list = self.get_cdf(self.pmf_list)\n\n# ------------------------------------------------------------------------------\n# Methods for the Poisson Binomial Distribution\n# ------------------------------------------------------------------------------\n\n    def pmf(self, number_successes):\n        \"\"\"Calculate the probability mass function ``pmf`` for the input values.\n\n        The ``pmf`` is defined as\n\n        .. math::\n\n            pmf(k) = Pr(X = k), k = 0, 1, ..., n.\n\n        :param number_successes: number of successful trials for which the\n            probability mass function is calculated\n        :type number_successes: int or list of integers\n        \"\"\"\n        self.check_rv_input(number_successes)\n        return self.pmf_list[number_successes]\n\n    def cdf(self, number_successes):\n        \"\"\"Calculate the cumulative distribution function for the input values.\n\n        The cumulative distribution function ``cdf`` for a number ``k`` of\n        successes is defined as\n\n        .. math::\n\n            cdf(k) = Pr(X \\\\leq k), k = 0, 1, ..., n.\n\n        :param number_successes: number of successful trials for which the\n            cumulative distribution function is calculated\n        :type number_successes: int or list of integers\n        \"\"\"\n        self.check_rv_input(number_successes)\n        return self.cdf_list[number_successes]\n\n    def pval(self, number_successes):\n        \"\"\"Return the p-values corresponding to the input numbers of successes.\n\n        The p-values for right-sided testing are defined as\n\n        .. math::\n\n            pval(k) = Pr(X \\\\geq k ),  k = 0, 1, ..., n.\n\n        .. note::\n\n            Since :math:`cdf(k) = Pr(X <= k)`, the function returns\n\n            .. math::\n\n                1 - cdf(X < k) & = 1 - cdf(X <= k - 1)\n                               & = 1 - cdf(X <= k) + pmf(X = k),\n\n                               k = 0, 1, .., n.\n\n        :param number_successes: number of successful trials for which the\n            p-value is calculated\n        :type number_successes: int, numpy.array, or list of integers\n        \"\"\"\n        self.check_rv_input(number_successes)\n        i = 0\n        try:\n            isinstance(number_successes, collections.Iterable)\n            pvalues = np.array(number_successes, dtype='float')\n            # if input is iterable (list, numpy.array):\n            for k in number_successes:\n                pvalues[i] = 1. - self.cdf(k) + self.pmf(k)\n                i += 1\n            return pvalues\n        except TypeError:\n            # if input is an integer:\n            if number_successes == 0:\n                return 1\n            else:\n                return 1 - self.cdf(number_successes - 1)\n\n# ------------------------------------------------------------------------------\n# Methods to obtain pmf and cdf\n# ------------------------------------------------------------------------------\n\n    def get_cdf(self, event_probabilities):\n        \"\"\"Return the values of the cumulative density function.\n\n        Return a list which contains all the values of the cumulative\n        density function for :math:`i = 0, 1, ..., n`.\n\n        :param event_probabilities: array of single event probabilities\n        :type event_probabilities: numpy.array\n        \"\"\"\n        cdf = np.empty(self.number_trials + 1)\n        cdf[0] = event_probabilities[0]\n        for i in range(1, self.number_trials + 1):\n            cdf[i] = cdf[i - 1] + event_probabilities[i]\n        return cdf\n\n    def get_pmf_xi(self):\n        \"\"\"Return the values of the variable ``xi``.\n\n        The components ``xi`` make up the probability mass function, i.e.\n        :math:`\\\\xi(k) = pmf(k) = Pr(X = k)`.\n        \"\"\"\n        chi = np.empty(self.number_trials + 1, dtype=complex)\n        chi[0] = 1\n        half_number_trials = int(\n            self.number_trials / 2 + self.number_trials % 2)\n        # set first half of chis:\n        chi[1:half_number_trials + 1] = self.get_chi(\n            np.arange(1, half_number_trials + 1))\n        # set second half of chis:\n        chi[half_number_trials + 1:self.number_trials + 1] = np.conjugate(\n            chi[1:self.number_trials - half_number_trials + 1] [::-1])\n        chi /= self.number_trials + 1\n        xi = np.fft.fft(chi)\n        if self.check_xi_are_real(xi):\n            xi = xi.real\n        else:\n            raise TypeError(\"pmf / xi values have to be real.\")\n        xi += np.finfo(type(xi[0])).eps\n        return xi\n\n    def get_chi(self, idx_array):\n        \"\"\"Return the values of ``chi`` for the specified indices.\n\n        :param idx_array: array of indices for which the ``chi`` values should\n            be calculated\n        :type idx_array: numpy.array\n        \"\"\"\n        # get_z:\n        exp_value = np.exp(self.omega * idx_array * 1j)\n        xy = 1 - self.success_probabilities + \\\n            self.success_probabilities * exp_value[:, np.newaxis]\n        # sum over the principal values of the arguments of z:\n        argz_sum = np.arctan2(xy.imag, xy.real).sum(axis=1)\n        # get d value:\n        exparg = np.log(np.abs(xy)).sum(axis=1)\n        d_value = np.exp(exparg)\n        # get chi values:\n        chi = d_value * np.exp(argz_sum * 1j)\n        return chi\n\n# ------------------------------------------------------------------------------\n# Auxiliary functions\n# ------------------------------------------------------------------------------\n\n    def check_rv_input(self, number_successes):\n        \"\"\"Assert that the input values ``number_successes`` are OK.\n\n        The input values ``number_successes`` for the random variable have to be\n        integers, greater or equal to 0, and smaller or equal to the total\n        number of trials ``self.number_trials``.\n\n        :param number_successes: number of successful trials\n        :type number_successes: int or list of integers \"\"\"\n        try:\n            for k in number_successes:\n                assert (type(k) == int or type(k) == np.int64), \\\n                        \"Values in input list must be integers\"\n                assert k >= 0, 'Values in input list cannot be negative.'\n                assert k <= self.number_trials, \\\n                    'Values in input list must be smaller or equal to the ' \\\n                    'number of input probabilities \"n\"'\n        except TypeError:\n            assert (type(number_successes) == int or \\\n                type(number_successes) == np.int64), \\\n                'Input value must be an integer.'\n            assert number_successes >= 0, \"Input value cannot be negative.\"\n            assert number_successes <= self.number_trials, \\\n                'Input value cannot be greater than ' + str(self.number_trials)\n        return True\n\n    @staticmethod\n    def check_xi_are_real(xi_values):\n        \"\"\"Check whether all the ``xi``s have imaginary part equal to 0.\n\n        The probabilities :math:`\\\\xi(k) = pmf(k) = Pr(X = k)` have to be\n        positive and must have imaginary part equal to zero.\n\n        :param xi_values: single event probabilities\n        :type xi_values: complex\n        \"\"\"\n        return np.all(xi_values.imag <= np.finfo(float).eps)\n\n    def check_input_prob(self):\n        \"\"\"Check that all the input probabilities are in the interval [0, 1].\"\"\"\n        if self.success_probabilities.shape != (self.number_trials,):\n            raise ValueError(\n                \"Input must be an one-dimensional array or a list.\")\n        if not np.all(self.success_probabilities >= 0):\n            raise ValueError(\"Input probabilities have to be non negative.\")\n        if not np.all(self.success_probabilities <= 1):\n            raise ValueError(\"Input probabilities have to be smaller than 1.\")", ""]}
{"filename": "bhv/lookup.py", "chunked_list": ["from .abstract import AbstractBHV\nfrom typing import TypeVar, Generic, Iterable, Iterator, Optional, Mapping\nfrom math import comb\n\n\nK = TypeVar(\"K\")\n\n\nclass Store(Generic[K]):\n    @classmethod\n    def auto_associative(cls, vs: Iterable[AbstractBHV]) -> 'Store[int]':\n        return cls(dict(enumerate(vs)))\n\n    def __init__(self, hvs: Mapping[K, AbstractBHV]):\n        self.hvs = hvs\n\n    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n        raise NotImplementedError()\n\n    def closest(self, v: AbstractBHV) -> Optional[K]:\n        raise NotImplementedError()", "class Store(Generic[K]):\n    @classmethod\n    def auto_associative(cls, vs: Iterable[AbstractBHV]) -> 'Store[int]':\n        return cls(dict(enumerate(vs)))\n\n    def __init__(self, hvs: Mapping[K, AbstractBHV]):\n        self.hvs = hvs\n\n    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n        raise NotImplementedError()\n\n    def closest(self, v: AbstractBHV) -> Optional[K]:\n        raise NotImplementedError()", "\n\nclass StoreList(Store):\n    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n        for k, v_ in self.hvs.items():\n            if v_.std_apart(v) <= threshold:\n                yield k\n\n    def closest(self, v: AbstractBHV) -> Optional[K]:\n        closest = None\n        shortest_distance = float('inf')\n\n        for k, v_ in self.hvs.items():\n            d = v_.std_apart(v)\n            if d < shortest_distance:\n                closest = k\n                shortest_distance = d\n\n        return closest", "\n\nclass StoreRejectList(Store):\n    def __init__(self, hvs: dict[K, AbstractBHV]):\n        super().__init__(hvs)\n        vs = list(hvs.values())\n        representative = vs[0]\n        self.bundle = representative.majority(vs)\n        self.bundle_size = len(vs)\n        self.included_std = AbstractBHV.frac_to_std(AbstractBHV.maj_ber(self.bundle_size))\n    # expected number of bits flipped compared to the majority of N random hvs\n    # E[bit_error_rate(v, MAJ(v, v_0, ..v_n))]\n    # E[v_q != MAJ(v, v_0, ..v_n)_q] WLOG\n    # E[1_q != MAJ(1, v_0, ..v_n)_q]\n    # E[1 != MAJ(1, v_0, ..v_n)_q]\n    # PoiBin(1, af(v_0), ..af(v_n)).cdf(n//2)\n    # further assuming af(v_0) == af(v_k) == 0.5,\n    # for n=1,3,5,...\n    # E[v_q != MAJ(v, v_0, ..v_n)_q]\n    # E[MAJ(v, v_0, ..v_n)_q]\n    # E[1 | SUM(v_k) > n/2\n    #   0 | SUM(v_k) < n/2    # doesn't contribute\n    #   v | SUM(v_k) = n/2]   # using af(v) == 0.5\n    # in code\n    # sum(.5 if sum(bc) == n//2 else (sum(bc) > n//2) for bc in bitconfigs(n))\n    # E[SUM(v_k) > n/2] + E[V]\n    # (comb(n - 1, (n - 1)//2))/2**n\n    # n! / ((n/2)! * (n - n/2)!)\n\n    def related_reject(self, v: AbstractBHV, threshold=6, reject_safety=3) -> Iterator[K]:\n        if self.bundle.unrelated(v, self.included_std - reject_safety):\n            return\n        for k, v_ in self.hvs.items():\n            if v_.std_apart(v) <= threshold:\n                yield k\n\n    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n        for k, v_ in self.hvs.items():\n            if v_.std_apart(v) <= threshold:\n                yield k\n\n    def find_closest(self, v: AbstractBHV) -> Optional[K]:\n        closest = None\n        shortest_distance = float('inf')\n\n        for k, v_ in self.hvs.items():\n            d = v_.std_apart(v)\n            if d < shortest_distance:\n                closest = k\n                shortest_distance = d\n\n        return closest", "\n\nclass StoreChunks(Store):\n    def __init__(self, hvs: dict[K, AbstractBHV], chunk_size=50):\n        super().__init__(hvs)\n        ks = list(hvs.keys())\n        vs = list(hvs.values())\n        representative = vs[0]\n        self.chunks = [(representative.majority(vs[i*chunk_size:(i+1)*chunk_size]), dict(zip(ks[i*chunk_size:(i+1)*chunk_size], vs[i*chunk_size:(i+1)*chunk_size])))\n                       for i in range(len(vs)//chunk_size+1)]\n        self.total_size = len(vs)\n        self.chunk_size = chunk_size\n        self.included_std = AbstractBHV.frac_to_std(AbstractBHV.maj_ber(chunk_size))\n\n    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n        for maj, chunk in self.chunks:\n            if not maj.unrelated(v, self.included_std - 3):\n                for k, v_ in chunk.items():\n                    if v_.related(v, threshold):\n                        yield k\n\n    def find_closest(self, v: AbstractBHV) -> Optional[K]:\n        closest = None\n        shortest_distance = float('inf')\n\n        for k, v_ in self.hvs.items():\n            d = v_.std_apart(v)\n            if d < shortest_distance:\n                closest = k\n                shortest_distance = d\n\n        return closest", ""]}
{"filename": "bhv/vanilla.py", "chunked_list": ["from .abstract import *\nimport random\nfrom sys import byteorder, version_info\n\n\nclass VanillaPermutation(MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\n    def __init__(self, indices):\n        self.data = indices\n\n    @classmethod\n    def random(cls) -> 'VanillaPermutation':\n        p = list(range(DIMENSION//8))\n        random.shuffle(p)\n        return VanillaPermutation(p)\n\n    def __mul__(self, other: 'VanillaPermutation') -> 'VanillaPermutation':\n        return VanillaPermutation([self.data[other.data[i]] for i in range(DIMENSION//8)])\n\n    def __invert__(self) -> 'VanillaPermutation':\n        p = [None]*(DIMENSION//8)\n        for i, j in enumerate(self.data):\n            p[j] = i\n        return VanillaPermutation(p)\n\n    def __call__(self, hv: 'VanillaBHV') -> 'VanillaBHV':\n        return hv.permute_bytes(self)", "\nVanillaPermutation.IDENTITY = VanillaPermutation(list(range(DIMENSION//8)))\n\n\nclass VanillaBHV(AbstractBHV):\n    def __init__(self, data: bytes):\n        self.data: bytes = data\n\n    @classmethod\n    def rand(cls) -> 'VanillaBHV':\n        return VanillaBHV(random.randbytes(DIMENSION//8))\n\n    @classmethod\n    def random(cls, active: float) -> 'VanillaBHV':\n        assert 0. <= active <= 1.\n        return VanillaBHV(bytes([\n            (random.random() < active) | (random.random() < active) << 1 | (random.random() < active) << 2 | (random.random() < active) << 3 |\n            (random.random() < active) << 4 | (random.random() < active) << 5 | (random.random() < active) << 6 | (random.random() < active) << 7\n            for _ in range(DIMENSION//8)]))\n\n    def roll_bytes(self, n: int) -> 'VanillaBHV':\n        assert abs(n) < DIMENSION//8, \"only supports DIMENSION/8 rolls\"\n        return VanillaBHV(self.data[n:] + self.data[:n])\n\n    def swap_halves(self) -> 'VanillaBHV':\n        return self.roll_bytes(DIMENSION//16)\n\n    def permute_bytes(self, permutation: 'VanillaPermutation') -> 'VanillaBHV':\n        return VanillaBHV(bytes([self.data[i] for i in permutation.data]))\n\n    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'VanillaBHV':\n        return self.permute_bytes(VanillaPermutation.get(permutation_id))\n\n    def rehash(self) -> 'VanillaBHV':\n        return VanillaBHV(hashlib.shake_256(self.data).digest(DIMENSION//8))\n\n    def __eq__(self, other: 'VanillaBHV') -> bool:\n        return self.data == other.data\n\n    def __xor__(self, other: 'VanillaBHV') -> 'VanillaBHV':\n        return self.from_int(self.to_int() ^ other.to_int())\n\n    def __and__(self, other: 'VanillaBHV') -> 'VanillaBHV':\n        return self.from_int(self.to_int() & other.to_int())\n\n    def __or__(self, other: 'VanillaBHV') -> 'VanillaBHV':\n        return self.from_int(self.to_int() | other.to_int())\n\n    if version_info[2] >= 10:\n        def active(self) -> int:\n            return self.to_int().bit_count()\n    else:\n        def active(self) -> int:\n            return bin(self.to_int()).count(\"1\")\n\n    def to_int(self) -> int:\n        return int.from_bytes(self.data, \"big\", signed=False)\n\n    @classmethod\n    def from_int(cls, i: int):\n        return VanillaBHV(i.to_bytes(DIMENSION//8, \"big\", signed=False))\n\n    def to_bytes(self):\n        return self.data\n\n    @classmethod\n    def from_bytes(cls, bs):\n        return cls(bs)\n\n    def bitstring(self) -> str:\n        return bin(self.to_int())[2:].rjust(DIMENSION, \"0\")\n\n    @classmethod\n    def from_bitstring(cls, s: str) -> Self:\n        return cls.from_int(int(s, 2))", "\nVanillaBHV.ZERO = VanillaBHV(bytes([0 for _ in range(DIMENSION//8)]))\nVanillaBHV.ONE = VanillaBHV(bytes([0xff for _ in range(DIMENSION//8)]))\nVanillaBHV._FEISTAL_SUBKEYS = VanillaBHV.nrand2(VanillaBHV._FEISTAL_ROUNDS, 4)\nVanillaBHV.HALF = VanillaBHV(bytes([0 for _ in range(DIMENSION//16)] + [0xff for _ in range(DIMENSION//16)]))\n"]}
{"filename": "bhv/abstract.py", "chunked_list": ["from statistics import NormalDist\nfrom itertools import accumulate\nfrom functools import cache\nfrom operator import or_, and_\nfrom math import comb, log2\nfrom typing import Iterator\n\nfrom .shared import *\n\n\nclass StoreBHV:\n    def __deepcopy__(self, memodict={}):\n        return self.from_bytes(self.to_bytes())\n\n    def to_bytes(self):\n        raise NotImplementedError()\n\n    @classmethod\n    def from_bytes(cls, bs: bytes):\n        raise NotImplementedError()\n\n    def bits(self):\n        for b in self.to_bytes():\n            yield (b >> 7) & 0x1\n            yield (b >> 6) & 0x1\n            yield (b >> 5) & 0x1\n            yield (b >> 4) & 0x1\n            yield (b >> 3) & 0x1\n            yield (b >> 2) & 0x1\n            yield (b >> 1) & 0x1\n            yield b & 0x1\n\n    @classmethod\n    def from_bitstream(cls, bits_s: 'Iterator[bool]') -> Self:\n        it = iter(bits_s)\n        bs = bytes(\n            (next(it) << 7) | (next(it) << 6) | (next(it) << 5) | (next(it) << 4) | (next(it) << 3) | (next(it) << 2) | (next(it) << 1) | next(it)\n            for _ in range(DIMENSION//8)\n        )\n        return cls.from_bytes(bs)\n\n    def bitstring(self) -> str:\n        return \"\".join(\"1\" if b else \"0\" for b in self.bits())\n\n    @classmethod\n    def from_bitstring(cls, s: str) -> Self:\n        return cls.from_bitstream(c == \"1\" for c in s)", "\n\nclass StoreBHV:\n    def __deepcopy__(self, memodict={}):\n        return self.from_bytes(self.to_bytes())\n\n    def to_bytes(self):\n        raise NotImplementedError()\n\n    @classmethod\n    def from_bytes(cls, bs: bytes):\n        raise NotImplementedError()\n\n    def bits(self):\n        for b in self.to_bytes():\n            yield (b >> 7) & 0x1\n            yield (b >> 6) & 0x1\n            yield (b >> 5) & 0x1\n            yield (b >> 4) & 0x1\n            yield (b >> 3) & 0x1\n            yield (b >> 2) & 0x1\n            yield (b >> 1) & 0x1\n            yield b & 0x1\n\n    @classmethod\n    def from_bitstream(cls, bits_s: 'Iterator[bool]') -> Self:\n        it = iter(bits_s)\n        bs = bytes(\n            (next(it) << 7) | (next(it) << 6) | (next(it) << 5) | (next(it) << 4) | (next(it) << 3) | (next(it) << 2) | (next(it) << 1) | next(it)\n            for _ in range(DIMENSION//8)\n        )\n        return cls.from_bytes(bs)\n\n    def bitstring(self) -> str:\n        return \"\".join(\"1\" if b else \"0\" for b in self.bits())\n\n    @classmethod\n    def from_bitstring(cls, s: str) -> Self:\n        return cls.from_bitstream(c == \"1\" for c in s)", "\n\nclass BaseBHV(StoreBHV):\n    @classmethod\n    def rand(cls) -> Self:\n        raise NotImplementedError()\n\n    @classmethod\n    def nrand(cls, n: int) -> list[Self]:\n        return [cls.rand() for _ in range(n)]\n\n    @classmethod\n    def majority(cls, vs: list[Self]) -> Self:\n        raise NotImplementedError()\n\n    @classmethod\n    def majority3(cls, x, y, z) -> Self:\n        return cls.majority([x, y, z])\n\n    def __eq__(self, other: Self) -> bool:\n        raise NotImplementedError()\n\n    def __xor__(self, other: Self) -> Self:\n        raise NotImplementedError()\n\n    def active(self) -> int:\n        raise NotImplementedError()\n\n    def permute(self, permutation_id: int) -> Self:\n        raise NotImplementedError()\n\n    def active_fraction(self) -> float:\n        return self.active()/DIMENSION\n\n    def hamming(self, other: Self) -> int:\n        return (self ^ other).active()\n\n    def bit_error_rate(self, other: Self) -> float:\n        return self.hamming(other)/DIMENSION\n\n    def std_apart(self, other: Self, invert=False) -> float:\n        return self.frac_to_std(self.bit_error_rate(other), invert)\n\n    @staticmethod\n    def normal(mean=0., p=.5):\n        return NormalDist(mean, (DIMENSION*p*(1 - p))**.5)\n\n    @staticmethod\n    def maj_ber(n):\n        return comb(n - 1, (n - 1)//2)/2**n\n\n    @staticmethod\n    def frac_to_std(frac, invert=False):\n        n = AbstractBHV.normal(0.0)\n        estdvs = n.zscore(0.5*DIMENSION)\n        stdvs = n.zscore(frac*DIMENSION)\n        return estdvs - stdvs if invert else stdvs\n\n    @staticmethod\n    def std_to_frac(std, invert=False):\n        n = AbstractBHV.normal(0.0)\n        frac = (std*n.stdev + n.mean)/DIMENSION\n        return 1. - frac if invert else frac\n\n    def zscore(self) -> float:\n        n = AbstractBHV.normal(0.5*DIMENSION)\n        return n.zscore(self.active())\n\n    def pvalue(self) -> float:\n        n = AbstractBHV.normal(0.5*DIMENSION)\n        s = n.cdf(self.active())\n        return 2.*min(s, 1. - s)\n\n    def related(self, other: Self, stdvs=6) -> bool:\n        return abs(self.std_apart(other)) <= stdvs\n\n    def unrelated(self, other: Self, stdvs=6) -> bool:\n        return abs(self.std_apart(other, invert=True)) <= stdvs\n\n    @classmethod\n    def _majority5_via_3(cls, a: Self, b: Self, c: Self, d: Self, e: Self) -> Self:\n        return cls.majority3(a, cls.majority3(b, c, d), cls.majority3(e, d, cls.majority3(c, b, a)))\n\n    @classmethod\n    def _majority7_via_3(cls, a: Self, b: Self, c: Self, d: Self, e: Self, f: Self, g: Self) -> Self:\n        mdef = cls.majority3(d, e, f)\n        mabc = cls.majority3(a, b, c)\n        return cls.majority3(g, cls.majority3(c, mdef, cls.majority3(a, b, mdef)), cls.majority3(f, mabc, cls.majority3(d, e, mabc)))\n\n    @classmethod\n    def _majority9_via_3(cls, a: Self, b: Self, c: Self, d: Self, e: Self, f: Self, g: Self, h: Self, i: Self) -> Self:\n        mabc = cls.majority3(a, b, c)\n        mdef = cls.majority3(d, e, f)\n        mghi = cls.majority3(g, h, i)\n\n        l_ = cls.majority3(cls.majority3(c, mdef, b), mdef, a)\n        l = cls.majority3(cls.majority3(i, l_, h), l_, g)\n\n        r_ = cls.majority3(cls.majority3(c, mghi, b), mghi, a)\n        r = cls.majority3(cls.majority3(f, r_, e), r_, d)\n\n        m = cls.majority3(mabc, mdef, mghi)\n        return cls.majority3(l, m, r)", "\n\nclass BooleanAlgBHV(BaseBHV):\n    def __and__(self, other: Self) -> Self:\n        raise NotImplementedError()\n\n    def __or__(self, other: Self) -> Self:\n        raise NotImplementedError()\n\n    def __invert__(self) -> Self:\n        return self ^ self.ONE\n\n    @classmethod\n    def rand2(cls, power: int) -> Self:\n        assert power >= 0\n        r = cls.rand()\n        return r if power == 0 else r & cls.rand2(power - 1)\n\n    @classmethod\n    def nrand2(cls, n: int, power: int) -> list[Self]:\n        assert power >= 0\n        return [cls.rand2(power) for _ in range(n)]\n\n    def select(self, when1: Self, when0: Self) -> Self:\n        return when0 ^ (self & (when0 ^ when1))\n\n    def select_rand(self, other: Self) -> Self:\n        return self.rand().select(self, other)\n\n    def select_rand2(self, other: Self, power_left: int) -> Self:\n        return self.rand2(power_left).select(self, other)\n\n    def randomize_half(self) -> Self:\n        return self.rand().select_rand(self)\n\n    def randomize_pow(self, pow_randomize: int) -> Self:\n        return self.rand().select_rand2(self, pow_randomize)\n\n    def flip_half(self) -> Self:\n        return self ^ self.rand()\n\n    def flip_pow(self, pow_flip: int) -> Self:\n        return self ^ self.rand2(pow_flip)\n\n    def flip_pow_on(self, pow_flip_on: int) -> Self:\n        return self | ~self.rand2(pow_flip_on)\n\n    def flip_pow_off(self, pow_flip_off: int) -> Self:\n        return self & self.rand2(pow_flip_off)\n\n    def overlap(self, other: Self) -> float:\n        return (self & other).active_fraction()\n\n    def jaccard(self, other: Self, distance=False) -> float:\n        union_active = (self | other).active()\n        if union_active == 0:\n            raise RuntimeError(\"Jaccard index where both vectors are zero\")\n        res = (self & other).active() / union_active\n        return 1. - res if distance else res\n\n    def cosine(self, other: Self, distance=False) -> float:\n        s_active = self.active()\n        o_active = other.active()\n        if not s_active or not o_active:\n            raise RuntimeError(\"Cosine similarity where one of the two vectors is zero\")\n        res = (self & other).active() / (s_active*o_active)**.5\n        return 1. - res if distance else res\n\n    def bias_rel(self, other: Self, rel: Self) -> float:\n        rel_l = rel.overlap(self)\n        rel_r = rel.overlap(other)\n        return rel_l/(rel_l + rel_r)\n\n    def mutual_information(self, other: Self, distance=False) -> float:\n        nself = ~self\n        nother = ~other\n\n        # Probabilities\n        P00 = nself.overlap(nother)\n        P01 = nself.overlap(other)\n        P10 = self.overlap(nother)\n        P11 = self.overlap(other)\n\n        # Marginal probabilities\n        PX0 = (P00 + P01)\n        PX1 = (P10 + P11)\n        PY0 = (P00 + P10)\n        PY1 = (P01 + P11)\n\n        # Mutual Information\n        MI = 0\n        if P00 and PX0 and PY0:\n            MI += P00 * log2(P00 / (PX0 * PY0))\n        if P01 and PX0 and PY1:\n            MI += P01 * log2(P01 / (PX0 * PY1))\n        if P10 and PX1 and PY0:\n            MI += P10 * log2(P10 / (PX1 * PY0))\n        if P11 and PX1 and PY1:\n            MI += P11 * log2(P11 / (PX1 * PY1))\n\n        return 1 - MI if distance else MI\n\n    def tversky(self, other: Self, l: float, r: float) -> float:\n        o = self.overlap(other)\n        lr = self.overlap(~other)\n        rl = other.overlap(~self)\n        return o/(l*lr + r*rl + o)\n\n    @classmethod\n    def majority(cls, vs: list[Self]) -> Self:\n        n = len(vs)\n\n        if n == 0:\n            return cls.rand()\n        elif n == 1:\n            return vs[0]\n        elif n % 2 == 0:\n            return cls.majority([cls.rand()] + vs)\n        else:\n            return cls._true_majority(vs)\n\n    @classmethod\n    def _true_majority(cls, vs: list[Self]) -> Self:\n        assert len(vs) % 2 == 1,  \"The true majority function which is only defined on uneven length inputs, see `majority`\"\n        half = len(vs)//2\n        disjunction = list(accumulate(vs[:half-1:-1], or_))[1:]\n        conjunction = list(accumulate(vs[:half-1:-1], and_))[1:]\n\n        @cache\n        def rec(ons, offs):\n            if ons + 1 > half:\n                return disjunction[-offs - 1]\n            if offs + 1 > half:\n                return conjunction[-ons - 1]\n            return vs[ons + offs].select(\n                rec(ons + 1, offs),\n                rec(ons, offs + 1)\n            )\n\n        return rec(0, 0)\n\n    # Alternative implementations\n\n    @classmethod\n    def _majority3_select(cls, a: Self, b: Self, c: Self) -> Self:\n        # C:  1 0 0 1 0 1 1\n\n        # |:  1 1 1 1 0 1 0\n        # &:  1 0 0 0 0 0 0\n\n        # M:  1 0 0 1 0 1 0\n\n        return a.select(b | c, b & c)\n\n    @classmethod\n    def _majority5_select(cls, x4: Self, x3: Self, x2: Self, x1: Self, x0: Self) -> Self:\n        t1 = x1 | x0\n        b1 = x1 & x0\n        m2 = x2.select(t1, b1)\n        t2 = x2 | t1\n        b2 = x2 & b1\n        m3h = x3.select(t2, m2)\n        m3l = x3.select(m2, b2)\n        m4 = x4.select(m3h, m3l)\n        return m4\n\n    @classmethod\n    def _majority7_select(cls, x6: Self, x5: Self, x4: Self, x3: Self, x2: Self, x1: Self, x0: Self) -> Self:\n        t1 = x1 | x0\n        b1 = x1 & x0\n        m2 = x2.select(t1, b1)\n        t2 = x2 | t1\n        b2 = x2 & b1\n        m3h = x3.select(t2, m2)\n        m3l = x3.select(m2, b2)\n        m4 = x4.select(m3h, m3l)\n        t3 = x3 | t2\n        b3 = x3 & b2\n        m4h = x4.select(t3, m3h)\n        m4l = x4.select(m3l, b3)\n        m5h = x5.select(m4h, m4)\n        m5l = x5.select(m4, m4l)\n        m6 = x6.select(m5h, m5l)\n        return m6\n\n    @classmethod\n    def _majority9_select(cls, x8: Self, x7: Self, x6: Self, x5: Self, x4: Self, x3: Self, x2: Self, x1: Self, x0: Self) -> Self:\n        t1 = x0 | x1\n        b1 = x0 & x1\n        m2 = x2.select(t1, b1)\n        t2 = x2 | t1\n        b2 = x2 & b1\n        m3h = x3.select(t2, m2)\n        m3l = x3.select(m2, b2)\n        t3 = x3 | t2\n        b3 = x3 & b2\n        m4h = x4.select(t3, m3h)\n        m4 = x4.select(m3h, m3l)\n        m4l = x4.select(m3l, b3)\n        t4 = x4 | t3\n        b4 = x4 & b3\n        m5hh = x5.select(t4, m4h)\n        m5h = x5.select(m4h, m4)\n        m5l = x5.select(m4, m4l)\n        m5ll = x5.select(m4l, b4)\n        m6h = x6.select(m5hh, m5h)\n        m6 = x6.select(m5h, m5l)\n        m6l = x6.select(m5l, m5ll)\n        m7h = x7.select(m6h, m6)\n        m7l = x7.select(m6, m6l)\n        m8 = x8.select(m7h, m7l)\n        return m8\n\n    @classmethod\n    def _majority3(cls, a: Self, b: Self, c: Self) -> Self:\n        # a:  1 0 0 1 0 1 1\n        # b:  1 1 0 1 0 1 0\n        # c:  1 0 1 0 0 0 0\n        # M:  1 0 0 1 0 1 0\n\n        # at least 2/3 agreeing on TRUE\n        abh = a & b\n        bch = b & c\n        cah = c & a\n        h = abh | bch | cah\n        return h\n\n    @classmethod\n    def _majority5(cls, a: Self, b: Self, c: Self, d: Self, e: Self) -> Self:\n        # at least 3/5 agreeing on TRUE\n\n        # 2*10 AND\n        # 9*1 OR\n        # (b \u2227 d \u2227 e) \u2228 (a \u2227 d \u2227 e) \u2228 (b \u2227 c \u2227 e) \u2228 (a \u2227 c \u2227 e) \u2228 (b \u2227 c \u2227 d) \u2228 (a \u2227 c \u2227 d) \u2228 (c \u2227 d \u2227 e) \u2228 (a \u2227 b \u2227 e) \u2228 (a \u2227 b \u2227 d) \u2228 (a \u2227 b \u2227 c)\n\n        ab = a & b\n        cd = c & d\n        de = d & e\n        ce = c & e\n\n        bde = b & de\n        ade = a & de\n\n        bce = b & ce\n        ace = a & ce\n\n        bcd = b & cd\n        acd = a & cd\n        cde = e & cd\n\n        abe = ab & e\n        abd = ab & d\n        abc = ab & c\n\n        h = bde | ade | bce | ace | bcd | acd | cde | abe | abd | abc\n        return h\n\n    @classmethod\n    def _majority_via_custom(cls, vs: list[Self]):\n        n = len(vs)\n        if n == 0:\n            return cls.rand()\n        elif n == 1:\n            return vs[0]\n        elif n == 2:\n            return vs[0].select_rand(vs[1])\n        elif n == 3:\n            return cls._majority3(vs[0], vs[1], vs[2])\n        elif n == 4:\n            return cls._majority5_via_3(vs[0], vs[1], vs[2], vs[3], cls.rand())\n        elif n == 5:\n            return cls._majority5_via_3(vs[0], vs[1], vs[2], vs[3], vs[4])\n        elif n == 6:\n            return cls._majority7_via_3(vs[0], vs[1], vs[2], vs[3], vs[4], vs[5], cls.rand())\n        elif n == 7:\n            return cls._majority7_via_3(vs[0], vs[1], vs[2], vs[3], vs[4], vs[5], vs[6])\n        elif n == 8:\n            return cls._majority9_via_3(vs[0], vs[1], vs[2], vs[3], vs[4], vs[5], vs[6], vs[7], cls.rand())\n        elif n == 9:\n            return cls._majority9_via_3(vs[0], vs[1], vs[2], vs[3], vs[4], vs[5], vs[6], vs[7], vs[8])\n        else:\n            raise RuntimeError(f\"No optimal implementations beyond MAJORITY-9 (tried to take MAJORITY-{n})\")\n\n    ZERO: Self\n    ONE: Self", "\n\nclass FractionalBHV(BooleanAlgBHV):\n    @classmethod\n    def random(cls, active: float) -> Self:\n        raise NotImplementedError()\n\n    @classmethod\n    def nrandom(cls, n: int, active: float) -> list[Self]:\n        assert 0. <= active <= 1.\n        return [cls.random(active) for _ in range(n)]\n\n    def select_random(self, other: Self, frac_left: float) -> Self:\n        return self.random(frac_left).select(self, other)\n\n    def randomize_frac(self, frac_randomize: float) -> Self:\n        return self.rand().select_random(self, frac_randomize)\n\n    def flip_frac(self, frac_flip: float) -> Self:\n        return self ^ self.random(frac_flip)\n\n    def flip_frac_on(self, frac_flip_on: float) -> Self:\n        return self | self.random(frac_flip_on)\n\n    def flip_frac_off(self, frac_flip_off: float) -> Self:\n        return self & self.random(1. - frac_flip_off)", "\n\nclass CryptoBHV(FractionalBHV):\n    def swap_halves(self) -> Self:\n        raise NotImplementedError()\n\n    def rehash(self) -> Self:\n        raise NotImplementedError()\n\n    _FEISTAL_ROUNDS = 8\n    _FEISTAL_SUBKEYS: list[Self]\n\n    @classmethod\n    def _feistal_round(cls, block: Self, round_key: Self) -> Self:\n        L = block & cls.HALF\n        R = (block ^ (L ^ round_key).rehash().swap_halves()) & ~cls.HALF\n\n        return (L | R).swap_halves()\n\n    def feistal(self, k: Self, inv=False) -> Self:\n        block = self\n        rounds = range(self._FEISTAL_ROUNDS)\n\n        for r in reversed(rounds) if inv else rounds:\n            block = self._feistal_round(block, self._FEISTAL_SUBKEYS[r] & k)\n\n        return block.swap_halves()\n\n    HALF: Self", "\n\nclass AbstractBHV(CryptoBHV):\n    pass\n\n\nclass Permutation:\n    @classmethod\n    def nrandom(cls, n) -> list[Self]:\n        return [cls.random() for _ in range(n)]\n\n    @classmethod\n    def random(cls) -> Self:\n        raise NotImplementedError()\n\n    def __mul__(self, other: Self) -> Self:\n        raise NotImplementedError()\n\n    def __invert__(self) -> Self:\n        raise NotImplementedError()\n\n    def __pow__(self, power):\n        permutation = self\n        for _ in range(power - 1):\n            permutation = permutation*permutation\n        return permutation\n\n    def __call__(self, hv: 'AbstractBHV') -> 'AbstractBHV':\n        raise NotImplementedError()\n\n    IDENTITY: Self", "\n\nclass MemoizedPermutation(Permutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]'\n\n    @classmethod\n    def _get_singular(cls, permutation_id: int) -> Self:\n        if permutation_id == 0:\n            return cls.IDENTITY\n        elif permutation_id in cls._permutations:\n            return cls._permutations[permutation_id]\n        elif -permutation_id in cls._permutations:\n            inv_permutation = cls._permutations[-permutation_id]\n            permutation = ~inv_permutation\n            cls._permutations[permutation_id] = permutation\n            return permutation\n        else:\n            permutation = cls.random()\n            cls._permutations[permutation_id] = permutation\n            return permutation\n\n    @classmethod\n    def _get_composite(cls, permutation_id: 'tuple[int, ...]') -> Self:\n        # this can be optimized a lot by looking for partial compositions\n        composite_permutation = cls._get_singular(permutation_id[0])\n        for component_permutation_id in permutation_id[1:]:\n            component_permutation = cls.get(component_permutation_id)\n            composite_permutation = composite_permutation * component_permutation\n\n        cls._permutations[permutation_id] = composite_permutation\n        return composite_permutation\n\n    @classmethod\n    def get(cls, permutation_id: 'int | tuple[int, ...]') -> Self:\n        permutation = cls._get_singular(permutation_id) if isinstance(permutation_id, int) else \\\n            cls._get_composite(permutation_id)\n        return permutation", ""]}
{"filename": "bhv/variants.py", "chunked_list": ["from typing import Generic, TypeVar, Type\nfrom copy import deepcopy\nfrom .abstract import *\n\nHV = TypeVar(\"HV\", bound=BooleanAlgBHV, covariant=True)\n\n\nclass LinearBHVModel(Generic[HV]):\n    def __init__(self, bhv: Type[HV]):\n        self.bhv = bhv\n        self.used = IdSet()\n    \n    def spawn(self, one: 'HV.ONE', zero: 'HV.ZERO') -> (HV, HV):\n        assert one not in self.used and zero not in self.used\n        self.used.add(one); self.used.add(zero)\n        # I O  ->  P N\n        # 1 0  ->  1 0  |  0 1\n        r = self.bhv.select_rand(one, zero)\n        return (r, ~r)\n\n    def xor(self, x: HV, y: HV) -> (HV, HV, HV):\n        assert x not in self.used and y not in self.used\n        self.used.add(x); self.used.add(y)\n        # L R  ->  X L R\n        # 0 0  ->  0 0 0\n        # 0 1  ->  1 0 0\n        # 1 0  ->  1 0 0\n        # 1 1  ->  0 1 1\n        b = x & y\n        return (x ^ y, b, deepcopy(b))\n\n    def thresholds3(self, x: 'HV', y: 'HV', z: 'HV') -> ('HV', 'HV', 'HV'):\n        assert x not in self.used and y not in self.used and z not in self.used\n        self.used.add(x); self.used.add(y); self.used.add(z)\n        # x y z  ->  + M -\n        # x y z  ->  + M -\n        # 0 0 0  ->  0 0 0\n\n        # 0 0 1  ->  0 0 1\n        # 0 1 0  ->  0 0 1\n        # 1 0 0  ->  0 0 1\n\n        # 0 1 1  ->  0 1 1\n        # 1 0 1  ->  0 1 1\n        # 1 1 0  ->  0 1 1\n\n        # 1 1 1  ->  1 1 1\n        return (x & y & z, self.bhv.majority([x, y, z]), x | y | z)\n\n    def and_or(self, x: 'HV', y: 'HV') -> ('HV', 'HV'):\n        assert x not in self.used and y not in self.used\n        self.used.add(x); self.used.add(y)\n        # x y  ->  & |\n        # 0 0  ->  0 0\n        # 0 1  ->  0 1\n        # 1 0  ->  0 1\n        # 1 1  ->  1 1\n        return (x & y, x | y)\n\n    def switch(self, cond: 'HV', left: 'HV', right: 'HV') -> ('HV', 'HV', 'HV'):\n        assert cond not in self.used and left not in self.used and right not in self.used\n        self.used.add(cond); self.used.add(left); self.used.add(right)\n        # C L R  ->  C P N\n        # 0 0 0  ->  0 0 0\n        # 0 0 1  ->  0 0 1\n        # 0 1 0  ->  0 1 0\n        # 0 1 1  ->  0 1 1\n\n        # 1 0 0  ->  1 0 0\n        # 1 0 1  ->  1 1 0\n        # 1 1 0  ->  1 0 1\n        # 1 1 1  ->  1 1 1\n\n        pos = self.bhv.select(cond, left, right)\n        neg = self.bhv.select(cond, right, left)\n        return (deepcopy(cond), pos, neg)\n\n    def invert(self, x: 'HV', one: 'HV.ONE', zero: 'HV.ZERO') -> ('HV', 'HV', 'HV'):\n        # P I O  ->  N A B\n        # 0 1 0  ->  1 0 0\n        # 1 1 0  ->  0 1 1\n        (self_1, self_2, inverted) = self.switch(x, one, zero)\n        return (inverted, self_1, self_2)\n\n    def permute(self, x: 'HV', permutation_id: int) -> 'HV':\n        assert x not in self.used\n        self.used.add(x)\n        return self.bhv.permute(permutation_id)", "\n\nclass Tank:\n    def __init__(self, capacity: float, fill=None, check=True, record=False):\n        self.capacity = capacity\n        self.level = capacity if fill is None else fill\n        self.check = check\n        self.record = record\n        self.updates = []\n\n    def update(self, amount: float):\n        if self.check:\n            if amount < 0:\n                assert self.level >= amount, \"not enough to drain\"\n            else:\n                assert amount <= self.capacity, \"too much to fill\"\n        if self.record:\n            self.updates.append(amount)\n        self.level += amount\n\n    def historical_levels(self):\n        assert self.record, \"history not recorded, please pass record=True\"\n        level = self.level\n        record = [level]\n        for update in reversed(self.updates):\n            level -= update\n            record.append(level)\n        record.reverse()\n        return record", "\n\nclass AdiabaticBHVModel:\n    def __init__(self, tank: Tank, bhv: Type[HV]):\n        self.tank = tank\n        self.bhv = bhv\n        self.used = IdSet()\n\n    def get_one(self) -> 'HV.ONE':\n        self.tank.update(-DIMENSION)\n        return deepcopy(self.bhv.ONE)\n\n    def get_zero(self) -> 'HV.ZERO':\n        self.tank.update(0)\n        return deepcopy(self.bhv.ZERO)\n\n    def spawn(self) -> ('HV', 'HV'):\n        # Note: maybe there's a more efficient way to generate random vectors in this context\n        # I O  ->  P N\n        # 1 0  ->  1 0  |  0 1\n        r = self.bhv.rand()\n        self.tank.update(-DIMENSION)\n        return (r, ~r)\n\n    def xor(self, x: 'HV', y: 'HV') -> 'HV':\n        assert x not in self.used and y not in self.used\n        self.used.add(x); self.used.add(y)\n        # L R  ->  X\n        # 0 0  ->  0\n        # 0 1  ->  1\n        # 1 0  ->  1\n        # 1 1  ->  0\n        b = (x & y).active()\n        self.tank.update(2*b)\n        return x ^ y\n\n    def majority3(self, x: 'HV', y: 'HV', z: 'HV') -> 'HV':\n        assert x not in self.used and y not in self.used and z not in self.used\n        self.used.add(x); self.used.add(y); self.used.add(z)\n        # x y z  ->  M\n        # 0 0 0  ->  0\n\n        # 0 0 1  ->  0\n        # 0 1 0  ->  0\n        # 1 0 0  ->  0\n\n        # 0 1 1  ->  1\n        # 1 0 1  ->  1\n        # 1 1 0  ->  1\n\n        # 1 1 1  ->  1\n        self.tank.update((x & y & z).active() + (x | y | z).active())\n        return self.bhv.majority([x, y, z])\n\n    def and_or(self, x: 'HV', y: 'HV') -> ('HV', 'HV'):\n        assert x not in self.used and y not in self.used\n        self.used.add(x); self.used.add(y)\n        # x y  ->  & |\n        # 0 0  ->  0 0\n        # 0 1  ->  0 1\n        # 1 0  ->  0 1\n        # 1 1  ->  1 1\n        self.tank.update(0)\n        return (x & y, x | y)\n\n    def switch(self, cond: 'HV', left: 'HV', right: 'HV') -> ('HV', 'HV', 'HV'):\n        assert cond not in self.used and left not in self.used and right not in self.used\n        self.used.add(cond); self.used.add(left); self.used.add(right)\n        # C L R  ->  C P N\n        # 0 0 0  ->  0 0 0\n        # 0 0 1  ->  0 0 1\n        # 0 1 0  ->  0 1 0\n        # 0 1 1  ->  0 1 1\n\n        # 1 0 0  ->  1 0 0\n        # 1 0 1  ->  1 1 0\n        # 1 1 0  ->  1 0 1\n        # 1 1 1  ->  1 1 1\n\n        pos = cond.select(left, right)\n        neg = cond.select(right, left)\n        self.tank.update(0)\n        return (deepcopy(cond), pos, neg)\n\n    def invert(self, x: 'HV') -> 'HV':\n        assert x not in self.used\n        self.used.add(x)\n        # P I O  ->  N A B\n        # 0 1 0  ->  1 0 0\n        # 1 1 0  ->  0 1 1\n        self.tank.update(2*(x.active() - DIMENSION//2))\n        return ~x\n\n    def permute(self, permutation_id: int) -> 'HV':\n        self.tank.update(0)\n        return self.bhv.permute(permutation_id)", "\n"]}
{"filename": "bhv/slice.py", "chunked_list": ["from .abstract import *\nimport random\n\n\nclass Slice(AbstractBHV):\n    def __init__(self, b):\n        self.b = b\n\n    @classmethod\n    def rand(cls) -> Self:\n        return cls.random(.5)\n\n    @classmethod\n    def random(cls, active: float) -> Self:\n        assert 0. <= active <= 1.\n        return Slice(random.random() > active)\n\n    def permute(self, permutation_id: int) -> Self:\n        raise NotImplementedError()\n\n    def swap_halves(self) -> Self:\n        raise NotImplementedError()\n\n    def rehash(self) -> Self:\n        raise NotImplementedError()\n\n    def __eq__(self, other: Self) -> bool:\n        return Slice(self.b == other.b)\n\n    def __xor__(self, other: Self) -> Self:\n        return Slice(self.b ^ other.b)\n\n    def __and__(self, other: Self) -> Self:\n        return Slice(self.b & other.b)\n\n    def __or__(self, other: Self) -> Self:\n        return Slice(self.b | other.b)\n\n    def __invert__(self) -> Self:\n        return Slice(not self.b)\n\n    @classmethod\n    def _true_majority(cls, vs: list[Self]) -> Self:\n        return Slice(sum(v.b for v in vs) > len(vs)//2)\n\n    def active(self) -> int:\n        return int(self.b)", "Slice.ONE = Slice(True)\nSlice.ZERO = Slice(False)\n"]}
{"filename": "bhv/__init__.py", "chunked_list": ["from .abstract import AbstractBHV\nfrom .shared import DIMENSION\n"]}
{"filename": "bhv/shared.py", "chunked_list": ["try:\n    from typing import Self\nexcept ImportError:\n    Self = 'AbstractBHV'\n\nDIMENSION = 8192\n\nfrom itertools import groupby\nfrom functools import partial\nfrom dataclasses import fields, is_dataclass", "from functools import partial\nfrom dataclasses import fields, is_dataclass\nfrom base64 import _urlsafe_encode_translation\nimport hashlib\nimport binascii\nimport sys\n\nsys.setrecursionlimit(75_000)\n\n\ndef stable_hash(d, try_cache=False) -> bytes:\n    \"\"\"\n    Python's `hash` is not stable. That's a problem if you want to use it for persistence and inter-run consistency.\n    This one is hand rolled, so don't fully trust it. In fact, if you see anything suspicious, please let me know.\n    :param d: Something you want to hash\n    :return: The 16-byte md5 hash of the bytes of all (nested) items.\n    \"\"\"\n    if try_cache and hasattr(d, \"__stable_hash\"):\n        return d.__stable_hash\n\n    stable_hash_try_cache = partial(stable_hash, try_cache=try_cache)\n\n    t = bytes(type(d).__name__, 'utf-8')\n    t += bytes([2])\n    if isinstance(d, str):\n        t += bytes(d, 'utf-8')\n    elif isinstance(d, float):\n        t += bytes(d.hex(), 'ascii')\n    elif isinstance(d, list) or isinstance(d, tuple):\n        t += b''.join(map(stable_hash_try_cache, d))\n    elif isinstance(d, set) or isinstance(d, frozenset):\n        t += b''.join(sorted(map(stable_hash_try_cache, d)))\n    elif isinstance(d, dict):\n        for k, v in d.items():\n            t += stable_hash_try_cache(k)\n            t += bytes([1])\n            t += stable_hash_try_cache(v)\n    elif is_dataclass(d):\n        for f in fields(d):\n            t += bytes(f.name, 'utf-8')\n            t += bytes([1])\n            t += stable_hash_try_cache(getattr(d, f.name))\n    else:\n        t += bytes(d)\n    res = hashlib.md5(t, usedforsecurity=False).digest()\n    if try_cache:\n        try:\n            d.__stable_hash = res\n        except AttributeError:\n            pass\n    return res", "\n\ndef stable_hash(d, try_cache=False) -> bytes:\n    \"\"\"\n    Python's `hash` is not stable. That's a problem if you want to use it for persistence and inter-run consistency.\n    This one is hand rolled, so don't fully trust it. In fact, if you see anything suspicious, please let me know.\n    :param d: Something you want to hash\n    :return: The 16-byte md5 hash of the bytes of all (nested) items.\n    \"\"\"\n    if try_cache and hasattr(d, \"__stable_hash\"):\n        return d.__stable_hash\n\n    stable_hash_try_cache = partial(stable_hash, try_cache=try_cache)\n\n    t = bytes(type(d).__name__, 'utf-8')\n    t += bytes([2])\n    if isinstance(d, str):\n        t += bytes(d, 'utf-8')\n    elif isinstance(d, float):\n        t += bytes(d.hex(), 'ascii')\n    elif isinstance(d, list) or isinstance(d, tuple):\n        t += b''.join(map(stable_hash_try_cache, d))\n    elif isinstance(d, set) or isinstance(d, frozenset):\n        t += b''.join(sorted(map(stable_hash_try_cache, d)))\n    elif isinstance(d, dict):\n        for k, v in d.items():\n            t += stable_hash_try_cache(k)\n            t += bytes([1])\n            t += stable_hash_try_cache(v)\n    elif is_dataclass(d):\n        for f in fields(d):\n            t += bytes(f.name, 'utf-8')\n            t += bytes([1])\n            t += stable_hash_try_cache(getattr(d, f.name))\n    else:\n        t += bytes(d)\n    res = hashlib.md5(t, usedforsecurity=False).digest()\n    if try_cache:\n        try:\n            d.__stable_hash = res\n        except AttributeError:\n            pass\n    return res", "\n\ndef stable_hashcode(d, version=0, try_cache=False) -> str:\n    \"\"\"\n    A thin wrapper around `stable_hash` which returns a string and incorporates a version.\n    :param d: Something you want to hash\n    :param version: Increase this number if you want to unconditionally break all hashcodes\n    :return: The 24 character base64 (with - and _) string hash\n    \"\"\"\n    h = stable_hash(d, try_cache)\n    padded = h.rjust(18, version.to_bytes(1, \"little\"))\n    base64 = binascii.b2a_base64(padded, newline=False)\n    url_safe = base64.translate(_urlsafe_encode_translation)\n    return url_safe.decode()", "\n\ndef nbs(i, w):\n    k = 1\n    for _ in range(w):\n        yield i ^ k\n        k <<= 1\n\n\ndef binw(i, w):\n    return bin(i)[2:].rjust(w, '0')", "\ndef binw(i, w):\n    return bin(i)[2:].rjust(w, '0')\n\n\ndef to_bitmask(s):\n    return [x == '1' for x in s]\n\n\ndef bin_bitmask(m):\n    return ''.join(\"01\"[x] for x in m)", "\ndef bin_bitmask(m):\n    return ''.join(\"01\"[x] for x in m)\n\n\ndef bitconfigs(n):\n    return [to_bitmask(binw(i, n)) for i in range(2**n)]\n\n\ndef unique_by_id(xs):\n    return list(reversed({id(x): x for x in reversed(xs)}.values()))", "\ndef unique_by_id(xs):\n    return list(reversed({id(x): x for x in reversed(xs)}.values()))\n\n\ndef format_multiple(xs, start=\"\", sep=\"\", end=\"\", indent=\"\", aindent=\"\", newline_threshold=40):\n    ss = list(map(str, xs))\n    maxlen = max(map(len, ss))\n    if maxlen >= newline_threshold:\n        return start + sep.rstrip(\" \").join(\"\\n\" + aindent + indent + s for s in ss) + \"\\n\" + aindent + end\n    else:\n        return start + sep.join(s for s in ss) + end", "\n\ndef format_list(xs, **kwargs):\n    return format_multiple(xs, start=\"[\", sep=\", \", end=\"]\", **kwargs)\n\n\nclass IdSet:\n    def __init__(self, iterable=()):\n        self.data = {id(x) for x in iterable}\n\n    def __contains__(self, item):\n        return id(item) in self.data\n\n    def add(self, item):\n        self.data.add(id(item))", ""]}
{"filename": "bhv/native.py", "chunked_list": ["from bhv.abstract import AbstractBHV, DIMENSION\nfrom bhv.cnative import CNativePackedBHV, _DIMENSION\n\nassert DIMENSION == _DIMENSION()\n\n\nclass NativePackedBHV(AbstractBHV):\n    def __init__(self, native_bhv):\n        self.ins = native_bhv\n\n    @classmethod\n    def rand(cls):\n        return NativePackedBHV(CNativePackedBHV.rand())\n\n    @classmethod\n    def random(cls, p):\n        return NativePackedBHV(CNativePackedBHV.random(p))\n\n    def __or__(self, other):\n        return NativePackedBHV(self.ins | other.ins)\n\n    def __and__(self, other):\n        return NativePackedBHV(self.ins & other.ins)\n\n    def __xor__(self, other):\n        return NativePackedBHV(self.ins ^ other.ins)\n\n    def __invert__(self):\n        return NativePackedBHV(~self.ins)\n\n    def select(self, when1, when0):\n        return NativePackedBHV(self.ins.select(when1.ins, when0.ins))\n\n    def ternary(self, y, z, op):\n        return NativePackedBHV(self.ins.ternary(y.ins, z.ins, op))\n\n    @classmethod\n    def majority(cls, xs):\n        return NativePackedBHV(CNativePackedBHV.majority([x.ins for x in xs]))\n\n    @classmethod\n    def representative(cls, xs):\n        return NativePackedBHV(CNativePackedBHV.representative([x.ins for x in xs]))\n\n    def active(self):\n        return self.ins.active()\n\n    def hamming(self, other):\n        return self.ins.hamming(other.ins)\n\n    def permute_words(self, permutation_id: int):\n        return NativePackedBHV(self.ins.permute_words(permutation_id))\n\n    def permute_byte_bits(self, permutation_id: int):\n        return NativePackedBHV(self.ins.permute_byte_bits(permutation_id))\n\n    def roll_words(self, d: int):\n        return NativePackedBHV(self.ins.roll_words(d))\n\n    def roll_word_bits(self, d: int):\n        return NativePackedBHV(self.ins.roll_word_bits(d))\n\n    def _permute_composite(self, permutation_id: 'tuple'):\n        v = self\n        for e in permutation_id:\n            v = v.permute(e)\n        return v\n\n    def permute(self, permutation_id: 'int | tuple'):\n        if isinstance(permutation_id, tuple):\n            return self._permute_composite(permutation_id)\n        return NativePackedBHV(self.ins.permute(permutation_id))\n\n    def rehash(self):\n        return NativePackedBHV(self.ins.rehash())\n\n    def swap_halves(self):\n        return NativePackedBHV(self.ins.swap_halves())\n\n    def __eq__(self, other):\n        return self.ins == other.ins\n\n    @classmethod\n    def from_bytes(cls, bs):\n        return NativePackedBHV(CNativePackedBHV.from_bytes(bs))\n\n    def to_bytes(self):\n        return self.ins.to_bytes()\n\n    def __getstate__(self):\n        return self.to_bytes()\n\n    def __setstate__(self, state):\n        self.ins = CNativePackedBHV.from_bytes(state)", "\nNativePackedBHV.ZERO = NativePackedBHV(CNativePackedBHV.ZERO)\nNativePackedBHV.ONE = NativePackedBHV(CNativePackedBHV.ONE)\nNativePackedBHV.HALF = NativePackedBHV(CNativePackedBHV.HALF)\nNativePackedBHV._FEISTAL_SUBKEYS = NativePackedBHV.nrand2(NativePackedBHV._FEISTAL_ROUNDS, 4)\n"]}
{"filename": "bhv/visualization.py", "chunked_list": ["from .abstract import AbstractBHV, DIMENSION\n\n\nclass DistanceGraph:\n    @classmethod\n    def from_scope(cls, local_dict):\n        return cls(*zip(*[(v, k) for k, v in local_dict.items() if isinstance(v, AbstractBHV)]))\n\n    def __init__(self, hvs: 'list[AbstractBHV]', labels: 'list[str]'):\n        self.hvs = hvs\n        self.labels = labels\n        self.adj = [[round(min(v.std_apart(w, invert=True), v.std_apart(w))) if not v.unrelated(w) else None\n                     for v in self.hvs]\n                    for w in self.hvs]\n\n    def graphviz(self):\n        for i, (r, l) in enumerate(zip(self.adj, self.labels)):\n            print(f\"{i} [label=\\\"{l}\\\"];\")\n            for j, d in enumerate(r):\n                if i < j and d is not None:\n                    print(f\"{i} -- {j} [label=\\\"{d}\\\"];\")", "\n\nclass Image:\n    @classmethod\n    def load_pbm(cls, file: 'IO[Any]', bhv: 'AbstractBHV', binary=False):\n        if binary:\n            header = file.readline().rstrip()\n            assert header == b\"P4\"\n            dimension, n = map(int, file.readline().rstrip().split(b\" \"))\n            assert dimension == DIMENSION\n            hvs = [bhv.from_bytes(file.read(DIMENSION//8)) for _ in range(n)]\n            return cls(hvs)\n        else:\n            header = file.readline().rstrip()\n            assert header == \"P1\"\n            dimension, n = map(int, file.readline().rstrip().split(\" \"))\n            assert dimension == DIMENSION\n            hvs = [bhv.from_bitstring(file.readline().rstrip()) for _ in range(n)]\n            return cls(hvs)\n\n    def __init__(self, hvs: 'list[AbstractBHV]'):\n        self.hvs = hvs\n\n    def pbm(self, file: 'IO[Any]', binary=False):\n        if binary:\n            file.write(b\"P4\\n\" + bytes(str(DIMENSION), \"ascii\") + b\" \" + bytes(str(len(self.hvs)), \"ascii\") + b\"\\n\")\n            for hv in self.hvs:\n                file.write(hv.to_bytes())\n        else:\n            file.write(f\"P1\\n{DIMENSION} {len(self.hvs)}\\n\")\n            for hv in self.hvs:\n                file.write(hv.bitstring())\n                file.write('\\n')", ""]}
{"filename": "bhv/unification.py", "chunked_list": ["from .symbolic import Var, Symbolic\nfrom typing import Optional\n\nKnowledge = dict[str, Symbolic]\n\n\n# Unify t1 with t2 using/improving the passed knowledge.\ndef unify(t1: Symbolic, t2: Symbolic, knowledge: Optional[Knowledge] = None) -> Optional[Knowledge]:\n    if knowledge is None:\n        knowledge = {}\n\n    if isinstance(t1, Var) and isinstance(t2, Var) and t1.name == t2.name:\n        return knowledge  # does global variable equality\n    elif isinstance(t2, Var):\n        return unify_variable(t2.name, t1, knowledge)\n    elif isinstance(t1, Var):\n        return unify_variable(t1.name, t2, knowledge)\n    else:\n        if t1.constant() != t2.constant():\n            return None\n        else:\n            cs1 = t1.children()\n            cs2 = t2.children()\n            if len(cs1) != len(cs2):\n                return None\n            else:\n                k = knowledge\n\n                for l, r in zip(cs1, cs2):\n                    k = unify(l, r, k)\n                    if k is None:\n                        return None\n                return k", "\n\ndef unify_variable(v: str, t: Symbolic, knowledge: Knowledge) -> Optional[Knowledge]:\n    if v in knowledge:\n        return unify(knowledge[v], t, knowledge)\n    elif isinstance(t, Var) and t.name in knowledge:\n        return unify(Var(v), knowledge[t.name], knowledge)\n    elif occurs_check(v, t, knowledge):\n        return None\n    else:\n        return {**knowledge, v: t}", "\n\ndef occurs_check(v: str, t, knowledge: Knowledge):\n    if isinstance(t, Var) and t.name == v:\n        return True\n    elif isinstance(t, Var) and t.name in knowledge:\n        return occurs_check(v, knowledge[t.name], knowledge)\n    else:\n        return any(occurs_check(v, arg, knowledge) for arg in t.children())\n", ""]}
{"filename": "bhv/symbolic.py", "chunked_list": ["from dataclasses import dataclass, field, fields\nfrom string import ascii_uppercase\nfrom .abstract import *\nfrom .shared import stable_hashcode, bitconfigs, unique_by_id, format_multiple, format_list\nfrom .slice import Slice\n\n\nclass Symbolic:\n    name = None\n\n    def named(self, name):\n        if name is not None: self.name = name\n        return self\n\n    def nodename(self, **kwargs):\n        return self.name or f\"{type(self).__name__.upper()}\"\n\n    def nodeid(self, structural=False, **kwargs):\n        return f\"{type(self).__name__}{stable_hashcode(self, try_cache=True).replace('-', '') if structural else str(id(self))}\"\n\n    def labeled_children(self, **kwargs):\n        return [(getattr(self, f.name), f.name) for f in fields(self) if type(f.type) is type and issubclass(f.type, Symbolic)]\n\n    def children(self, **kwargs):\n        return [c for c, _ in self.labeled_children(**kwargs)]\n\n    def vars(self) -> list[str]:\n        return [v.name for v in self.preorder(lambda x: isinstance(x, Var))]\n\n    def substitute(self, vars):\n        if isinstance(self, Var) and self.name in vars:\n            return vars[self.name]\n        else:\n            return self.map(lambda x: x.substitute(vars))\n\n    def substitute_term(self, f):\n        res = f(self)\n        if res:\n            return res\n        else:\n            return self.map(lambda x: x.substitute_term(f))\n\n    def reconstruct(self, *cs):\n        assert not self.labeled_children()\n        return self\n\n    def map(self, f):\n        return self.reconstruct(*map(f, self.children())).named(self.name)\n\n    def constant(self):\n        return self.map(lambda x: None)\n\n    def draw_node(self, **kwargs):\n        print(f\"{self.nodeid(**kwargs)} [label=\\\"{self.nodename(**kwargs)}\\\"];\")\n\n    def draw_edges(self, **kwargs):\n        for c, label in self.labeled_children(**kwargs):\n            print(f\"{c.nodeid(**kwargs)} -> {self.nodeid(**kwargs)} [label=\\\"{label}\\\"];\")\n\n    def draw_children(self, **kwargs):\n        for c, label in self.labeled_children(**kwargs):\n            c.graphviz(**kwargs)\n\n    def graphviz(self, structural=False, done=None, **kwargs):\n        noden = self.nodeid(structural, **kwargs)\n        if done is None:\n            done = set()\n        if noden in done:\n            return\n        done.add(noden)\n        kwargs |= dict(done=done, structural=structural)\n        self.draw_node(**kwargs)\n        self.draw_edges(**kwargs)\n        self.draw_children(**kwargs)\n\n    def show_program(self, name=\"f\", indent=\"    \", **kwargs):\n        kwargs[\"indent\"] = indent\n        kwargs[\"aindent\"] = indent\n        kwargs[\"toplevel\"] = True\n        def extracted(x: Symbolic):\n            return x.map(lambda x: x if isinstance(x, Var) else Var(f\"_{subexpressions.index(x)}\"))\n        subexpressions = unique_by_id(self.preorder(lambda x: not isinstance(x, Var))[1:])\n        subexpressions.reverse()\n        free_vars = unique_by_id(self.preorder(lambda x: isinstance(x, Var)))\n        arguments = [fv.show(**kwargs) for fv in free_vars]\n        lines = [(x.name or f\"_{i}\") + \" = \" + extracted(x).show(**kwargs) for i, x in enumerate(subexpressions)]\n        last = f\"return {extracted(self).show(**kwargs)}\"\n        code = format_multiple([*lines, last], start=f\"def {name}({format_multiple(arguments, sep=', ')}):\", indent=indent, newline_threshold=0)\n        return code\n\n    def show(self, **kwargs):\n        \"\"\"\n        Shows the expression tree code-style.\n        Only works on referentially transparent DAGs.\n        :param kwargs: drawing options\n        :return: str\n        \"\"\"\n        raise NotImplementedError()\n\n    def instantiate(self, **kwargs):\n        raise NotImplementedError()\n\n    def execute(self, random: 'dict[int, AbstractBHV]' = None,\n                rand2: 'dict[int, AbstractBHV]' = None,\n                rand: 'dict[int, AbstractBHV]' = None,\n                randomperms: 'dict[int, MemoizedPermutation]' = None,\n                calculated = None, **kwargs):\n        if random is None: random = {}\n        if rand2 is None: rand2 = {}\n        if rand is None: rand = {}\n        if randomperms is None: randomperms = {}\n        if calculated is None: calculated = {}\n        kwargs |= dict(random=random, rand2=rand2, rand=rand, randomperms=randomperms, calculated=calculated)\n        if id(self) in calculated:\n            return calculated[id(self)]\n        else:\n            result = self.instantiate(**kwargs)\n            calculated[id(self)] = result\n            return result\n\n    def optimal_sharing(self, form=None, **kwargs):\n        if form is None: form = {}\n        kwargs |= dict(form=form)\n\n        sh = stable_hashcode(self, try_cache=True)\n        if sh in form:\n            return form[sh]\n        else:\n            r = self.map(lambda c: c.optimal_sharing(**kwargs))\n            shr = stable_hashcode(r, try_cache=True)\n            if shr in form:\n                raise RuntimeError(\"Includes check failed\")\n            form[shr] = r\n            return r\n\n    def internal_size(self):\n        return 1\n\n    def size(self, counted=None, recount=False, **kwargs):\n        if counted is None: counted = {}\n        kwargs |= dict(counted=counted)\n        if id(self) in counted:\n            return counted[id(self)] if recount else 0\n        else:\n            t = self.internal_size()\n            for c in self.children():\n                t += c.size(**kwargs)\n            counted[id(self)] = t\n            return t\n\n    def simplify(self, **kwargs):\n        x = self\n        while True:\n            x_ = x.map(lambda c: c.simplify(**kwargs))\n            x_r = x_.reduce(**kwargs)\n            if x_r is not None:\n                x_ = x_r\n            if x == x_:\n                return x\n            else:\n                x = x_\n\n    def reduce(self, **kwargs):\n        return None\n\n    def preorder(self, p=lambda x: True):\n        return [self]*p(self) + [v for c in self.children() for v in c.preorder(p)]\n\n    def truth_assignments(self, vars):\n        configs = bitconfigs(len(vars))\n\n        return [self.execute(vars={v.name: Slice(b) for b, v in zip(config, vars)}, bhv=Slice).b\n                for config in configs]", "\n\n@dataclass\nclass List(Symbolic):\n    xs: list[Symbolic]\n\n    def show(self, **kwargs):\n        return format_list((x.show(**kwargs) for x in self.xs),\n                           **{k: kwargs[k] for k in [\"indent\", \"aindent\", \"newline_threshold\"] if k in kwargs})\n\n    def labeled_children(self, **kwargs):\n        return [(x, str(i)) for i, x in enumerate(self.xs)]\n\n    def reconstruct(self, *cs):\n        return List(cs)\n\n    def graphviz(self, structural=False, done=None, **kwargs):\n        noden = self.nodeid(structural, **kwargs)\n        if done is None:\n            done = set()\n        if noden in done:\n            return\n        done.add(noden)\n        kwargs |= dict(done=done, structural=structural)\n        print(f\"subgraph cluster_{self.nodename()} \" + \"{\")\n        print(f\"label = \\\"{self.nodename()}\\\";\")\n        for c in self.xs:\n            c.draw_node(**kwargs)\n        print(\"}\")\n        for c in self.xs:\n            c.draw_edges(**kwargs)\n            c.draw_children(**kwargs)\n\n    def instantiate(self, **kwargs):\n        return [x.instantiate(**kwargs) for x in self.xs]\n\n    def truth_table(self, vars):\n        return [x.truth_assignments(vars) for x in self.xs]", "\n\nclass SymbolicPermutation(Symbolic, MemoizedPermutation):\n    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\n    @classmethod\n    def random(cls) -> 'SymbolicPermutation':\n        return PermRandom()\n\n    def __mul__(self, other: 'SymbolicPermutation') -> 'SymbolicPermutation':\n        return PermCompose(self, other)\n\n    def __invert__(self) -> 'SymbolicPermutation':\n        return PermInvert(self)\n\n    def __call__(self, hv: 'SymbolicBHV') -> 'SymbolicBHV':\n        return PermApply(self, hv)", "\n@dataclass\nclass PermVar(SymbolicPermutation):\n    name: str\n    def nodename(self, **kwargs):\n        return self.name\n\n    def show(self, **kwargs):\n        symbolic_var = kwargs.get(\"symbolic_var\", False)\n        return f\"ParmVar(\\\"{self.name}\\\")\" if symbolic_var else self.name\n\n    def instantiate(self, **kwargs):\n        permvars = kwargs.get(\"permvars\")\n        if permvars is None:\n            raise RuntimeError(f\"No Perm vars supplied but tried to instantiate `{self.name}`\")\n        elif self.name not in permvars:\n            raise RuntimeError(f\"Perm var `{self.name}` not in permvars ({set(permvars.keys())})\")\n        else:\n            return permvars[self.name]", "randpermid = 0\ndef next_perm_id():\n    global randpermid\n    randpermid += 1\n    return randpermid\n@dataclass\nclass PermRandom(SymbolicPermutation):\n    id: int = field(default_factory=next_perm_id)\n\n    def show(self, **kwargs):\n        impl = kwargs.get(\"impl\", \"\")\n        random_id = kwargs.get(\"random_id\", False)\n        return f\"<{impl}random {self.id}>\" if random_id else impl + \"random()\"\n\n    def instantiate(self, **kwargs):\n        randomperms = kwargs.get(\"randomperms\")\n        if self.id in randomperms:\n            return randomperms[self.id]\n        else:\n            r = kwargs.get(\"perm\").random()\n            randomperms[self.id] = r\n            return r", "@dataclass\nclass PermCompose(SymbolicPermutation):\n    l: SymbolicPermutation\n    r: SymbolicPermutation\n\n    def reconstruct(self, l, r):\n        return PermCompose(l, r)\n\n    def show(self, **kwargs):\n        brackets = not kwargs.get(\"toplevel\", False)\n        return \"(\"*brackets + f\"{self.l.show(**kwargs)} * {self.r.show(**kwargs)}\" + \")\"*brackets\n\n    def instantiate(self, **kwargs):\n        return self.l.execute(**kwargs) * self.r.execute(**kwargs)", "@dataclass\nclass PermInvert(SymbolicPermutation):\n    p: SymbolicPermutation\n\n    def reconstruct(self, p):\n        return PermInvert(p)\n\n    def show(self, **kwargs):\n        brackets = not kwargs.get(\"toplevel\", False)\n        return \"(\"*brackets + f\"~{self.p.show(**kwargs)}\" + \")\"*brackets\n\n    def instantiate(self, **kwargs):\n        return ~self.p.execute(**kwargs)", "\n\nclass SymbolicBHV(Symbolic, AbstractBHV):\n    @classmethod\n    def synth(cls, vs, t):\n        assert 2**len(vs) == len(t)\n        if vs:\n            return vs[0].select(\n                    cls.synth(vs[1:], t[:len(t)//2]),\n                    cls.synth(vs[1:], t[len(t)//2:]))\n        else:\n            return cls.ONE if t[0] else cls.ZERO\n\n    @classmethod\n    def synth_af(cls, af: float, depth=1, v_gen=lambda x: Rand(x), threshold=1e-6):\n        assert 0. < af < 1.\n        d = af - (1 / 2) ** depth\n        v = v_gen(depth)\n        if abs(d) > threshold:\n            if d > 0:\n                return v | cls.synth_af(d, depth + 1, v_gen, threshold)\n            else:\n                return v & cls.synth_af(af, depth + 1, v_gen, threshold)\n        else:\n            return v\n\n    @classmethod\n    def synth_af_ternary(cls, af: float, depth=1, v_gen=lambda x: Rand(x), threshold=1e-6):\n        assert 0. < af < 1.\n        da = af - (1 / 2) ** depth\n        va = v_gen(depth)\n\n        if abs(da) < threshold:\n            return va\n\n        if da > 0:\n            af = da\n\n        depth += 1\n        db = af - (1 / 2) ** depth\n        vb = v_gen(depth)\n\n        if db > 0:\n            af = db\n\n        if abs(db) > threshold:\n            ternary_instr = {(True, True): [0,1,1,1,1,1,1,1],\n                             (True, False): [0,0,0,1,1,1,1,1],\n                             (False, True): [0,0,0,0,0,1,1,1],\n                             (False, False): [0,0,0,0,0,0,0,1]}[(da > 0, db > 0)]\n            # TODO implement Ternary op\n            vr = cls.synth_af_ternary(af, depth + 1, v_gen, threshold)\n            return cls.synth([va, vb, vr], ternary_instr)\n\n        if da > 0:\n            return va | vb\n        else:\n            return va & vb\n\n    @classmethod\n    def rand(cls) -> Self:\n        return Rand()\n\n    @classmethod\n    def rand2(cls, power: int) -> Self:\n        assert power >= 0\n        return Rand2(power)\n\n    @classmethod\n    def random(cls, active: float) -> Self:\n        assert 0. <= active <= 1.\n        return Random(active)\n\n    @classmethod\n    def majority(cls, vs: list[Self]) -> Self:\n        return Majority(vs)\n\n    def permute(self, permutation_id: 'int | tuple[int, ...]') -> Self:\n        return Permute(permutation_id, self)\n\n    def swap_halves(self) -> Self:\n        return SwapHalves(self)\n\n    def rehash(self) -> Self:\n        return ReHash(self)\n\n    def __xor__(self, other: Self) -> Self:\n        return Xor(self, other)\n\n    def __and__(self, other: Self) -> Self:\n        return And(self, other)\n\n    def __or__(self, other: Self) -> Self:\n        return Or(self, other)\n\n    def __invert__(self) -> Self:\n        return Invert(self)\n\n    def select(self, when1: Self, when0: Self) -> Self:\n        return Select(self, when0, when1)\n\n    def active_fraction(self) -> int:\n        return ActiveFraction(self)\n\n    def bias_rel(self, other: Self, rel: Self) -> float:\n        return BiasRel(rel, self, other)\n\n    def unrelated(self, other: Self, stdvs=6) -> bool:\n        return Unrelated(self, other, stdvs)\n\n    def expected_active_fraction(self, **kwargs):\n        raise NotImplementedError()", "\n\n@dataclass\nclass PermApply(SymbolicBHV):\n    p: SymbolicPermutation\n    v: SymbolicBHV\n\n    def reconstruct(self, p, v):\n        return PermApply(p, v)\n\n    def show(self, **kwargs):\n        return f\"{self.p.show(**kwargs)}({self.v.show(**kwargs)})\"\n\n    def instantiate(self, **kwargs):\n        return self.p.execute(**kwargs)(self.v.execute(**kwargs))\n\n    def expected_active_fraction(self, **kwargs):\n        return self.v.expected_active(**kwargs)", "@dataclass\nclass Var(SymbolicBHV):\n    name: str\n    @classmethod\n    def shortname(cls, i: int, letters=ascii_uppercase):\n        n = len(letters)\n        return cls(letters[i % n] + str(i // n) * (i > n))\n\n    def nodename(self, **kwards):\n        return self.name\n\n    def show(self, **kwargs):\n        symbolic_var = kwargs.get(\"symbolic_var\", False)\n        return f\"Var(\\\"{self.name}\\\")\" if symbolic_var else self.name\n\n    def instantiate(self, **kwargs):\n        vars = kwargs.get(\"vars\")\n        if vars is None:\n            raise RuntimeError(f\"No vars supplied but tried to instantiate `{self.name}`\")\n        elif self.name not in vars:\n            raise RuntimeError(f\"Var `{self.name}` not in vars ({set(vars.keys())})\")\n        else:\n            return vars[self.name]\n\n    def expected_active_fraction(self, **kwargs):\n        return kwargs.get(\"vars\").get(self.name)", "@dataclass\nclass Zero(SymbolicBHV):\n    def show(self, **kwargs):\n        return kwargs.get(\"impl\", \"\") + \"ZERO\"\n\n    def instantiate(self, **kwargs):\n        return kwargs.get(\"bhv\").ZERO\n\n    def expected_active_fraction(self, **kwargs):\n        return 0.", "@dataclass\nclass One(SymbolicBHV):\n    def show(self, **kwargs):\n        return kwargs.get(\"impl\", \"\") + \"ONE\"\n\n    def instantiate(self, **kwargs):\n        return kwargs.get(\"bhv\").ONE\n\n    def expected_active_fraction(self, **kwargs):\n        return 1.", "SymbolicBHV.ZERO = Zero()\nSymbolicBHV.ONE = One()\nrandid = 0\ndef next_id():\n    global randid\n    randid += 1\n    return randid\n@dataclass\nclass Rand(SymbolicBHV):\n    id: int = field(default_factory=next_id)\n\n    def show(self, **kwargs):\n        impl = kwargs.get(\"impl\", \"\")\n        random_id = kwargs.get(\"random_id\", False)\n        return f\"<{impl}rand {self.id}>\" if random_id else impl + \"rand()\"\n\n    def instantiate(self, **kwargs):\n        rand = kwargs.get(\"rand\")\n        if self.id in rand:\n            return rand[self.id]\n        else:\n            r = kwargs.get(\"bhv\").rand()\n            rand[self.id] = r\n            return r\n\n    def expected_active_fraction(self, **kwargs):\n        return .5", "class Rand(SymbolicBHV):\n    id: int = field(default_factory=next_id)\n\n    def show(self, **kwargs):\n        impl = kwargs.get(\"impl\", \"\")\n        random_id = kwargs.get(\"random_id\", False)\n        return f\"<{impl}rand {self.id}>\" if random_id else impl + \"rand()\"\n\n    def instantiate(self, **kwargs):\n        rand = kwargs.get(\"rand\")\n        if self.id in rand:\n            return rand[self.id]\n        else:\n            r = kwargs.get(\"bhv\").rand()\n            rand[self.id] = r\n            return r\n\n    def expected_active_fraction(self, **kwargs):\n        return .5", "@dataclass\nclass Rand2(SymbolicBHV):\n    power: int\n\n    def show(self, **kwargs):\n        return kwargs.get(\"impl\", \"\") + f\"rand2({self.power})\"\n\n    def instantiate(self, **kwargs):\n        rand2 = kwargs.get(\"rand2\")\n        if self.id in rand2:\n            return rand2[self.id]\n        else:\n            r = kwargs.get(\"bhv\").rand2(self.power)\n            rand2[self.id] = r\n            return r\n\n    def expected_active_fraction(self, **kwargs):\n        return 1/self.power", "@dataclass\nclass Random(SymbolicBHV):\n    frac: float\n\n    def show(self, **kwargs):\n        return kwargs.get(\"impl\", \"\") + f\"random({self.frac})\"\n\n    def instantiate(self, **kwargs):\n        random = kwargs.get(\"random\")\n        if self.id in random:\n            return random[self.id]\n        else:\n            r = kwargs.get(\"bhv\").random(self.frac)\n            random[self.id] = r\n            return r\n\n    def expected_active_fraction(self, **kwargs):\n        return self.frac", "@dataclass\nclass Majority(SymbolicBHV):\n    vs: list[SymbolicBHV]\n\n    def labeled_children(self, **kwargs):\n        return list(zip(self.vs, map(str, range(len(self.vs)))))\n\n    def reconstruct(self, *cs):\n        return Majority(cs)\n\n    def show(self, **kwargs):\n        args = format_list((v.show(**kwargs) for v in self.vs), **{k: kwargs[k] for k in [\"indent\", \"aindent\", \"newline_threshold\"] if k in kwargs})\n        return kwargs.get(\"impl\", \"\") + f\"majority({args})\"\n\n    def instantiate(self, **kwargs):\n        return kwargs.get(\"bhv\").majority([v.execute(**kwargs) for v in self.vs])\n\n    def expected_active_fraction(self, **kwargs):\n        from .poibin import PoiBin\n        return 1. - PoiBin([v.expected_active_fraction(**kwargs) for v in self.vs]).cdf(len(self.vs)//2)", "@dataclass\nclass Permute(SymbolicBHV):\n    id: 'int | tuple[int, ...]'\n    v: SymbolicBHV\n\n    def reconstruct(self, v):\n        return Permute(self.id, v)\n\n    def show(self, **kwargs):\n        return f\"{self.v.show(**kwargs)}.permute({self.id})\"\n\n    def instantiate(self, **kwargs):\n        return self.v.execute(**kwargs).permute(self.id)\n\n    def expected_active_fraction(self, **kwargs):\n        return self.v.expected_active_fraction(**kwargs)", "@dataclass\nclass SwapHalves(SymbolicBHV):\n    v: SymbolicBHV\n\n    def reconstruct(self, v):\n        return SwapHalves(v)\n\n    def show(self, **kwargs):\n        return f\"{self.v.show(**kwargs)}.swap_halves()\"\n\n    def instantiate(self, **kwargs):\n        return self.v.execute(**kwargs).swap_halves()\n\n    def expected_active_fraction(self, **kwargs):\n        return self.v.expected_active_fraction(**kwargs)", "@dataclass\nclass ReHash(SymbolicBHV):\n    v: SymbolicBHV\n\n    def reconstruct(self, v):\n        return ReHash(v)\n\n    def show(self, **kwargs):\n        return f\"{self.v.show(**kwargs)}.rehash()\"\n\n    def instantiate(self, **kwargs):\n        return self.v.execute(**kwargs).rehash()\n\n    def expected_active_fraction(self, **kwargs):\n        return .5", "@dataclass\nclass Eq(Symbolic):\n    l: SymbolicBHV\n    r: SymbolicBHV\n\n    def swap(self):\n        return Eq(self.r, self.l)\n\n    def reconstruct(self, l, r):\n        return Eq(l, r)\n\n    def show(self, toplevel=True, **kwargs):\n        brackets = not toplevel\n        kwargs[\"toplevel\"] = False\n        return \"(\"*brackets + f\"{self.l.show(**kwargs)} == {self.r.show(**kwargs)}\" + \")\"*brackets\n\n    def instantiate(self, **kwargs):\n        return self.l.execute(**kwargs) == self.r.execute(**kwargs)", "@dataclass\nclass Xor(SymbolicBHV):\n    l: SymbolicBHV\n    r: SymbolicBHV\n\n    def reconstruct(self, l, r):\n        return Xor(l, r)\n\n    def show(self, **kwargs):\n        brackets = not kwargs.get(\"toplevel\", False)\n        return \"(\"*brackets + f\"{self.l.show(**kwargs)} ^ {self.r.show(**kwargs)}\" + \")\"*brackets\n\n    def instantiate(self, **kwargs):\n        return self.l.execute(**kwargs) ^ self.r.execute(**kwargs)\n\n    def reduce(self, **kwargs):\n        if self.l == self.ONE:\n            return ~self.r\n        elif self.r == self.ONE:\n            return ~self.l\n        elif self.l == self.ZERO:\n            return self.r\n        elif self.r == self.ZERO:\n            return self.l\n        elif self.l == self.r:\n            return self.ZERO\n        elif self.l == ~self.r or ~self.l == self.r:\n            return self.ONE\n        elif isinstance(self.l, Invert) and isinstance(self.r, Invert):\n            return Xor(self.l.v, self.r.v)\n        elif isinstance(self.l, And) and isinstance(self.r, And):\n            if self.l.l == self.r.l: return And(self.l.l, Xor(self.l.r, self.r.r))\n            elif self.l.l == self.r.r: return And(self.l.l, Xor(self.l.r, self.r.l))\n            elif self.l.r == self.r.l: return And(self.l.r, Xor(self.l.l, self.r.r))\n            elif self.l.r == self.r.r: return And(self.l.r, Xor(self.l.l, self.r.l))\n\n    def expected_active_fraction(self, **kwargs):\n        afl = self.l.expected_active_fraction(**kwargs)\n        afr = self.r.expected_active_fraction(**kwargs)\n        return afl*(1. - afr) + (1. - afl)*afr", "@dataclass\nclass And(SymbolicBHV):\n    l: SymbolicBHV\n    r: SymbolicBHV\n\n    def reconstruct(self, l, r):\n        return And(l, r)\n\n    def show(self, **kwargs):\n        brackets = not kwargs.get(\"toplevel\", False)\n        return \"(\"*brackets + f\"{self.l.show(**kwargs)} & {self.r.show(**kwargs)}\" + \")\"*brackets\n\n    def instantiate(self, **kwargs):\n        return self.l.execute(**kwargs) & self.r.execute(**kwargs)\n\n    def reduce(self, **kwargs):\n        if self.l == self.ZERO or self.r == self.ZERO:\n            return self.ZERO\n        elif self.l == self.ONE:\n            return self.r\n        elif self.r == self.ONE:\n            return self.l\n        elif isinstance(self.l, Invert) and self.l.v == self.r:\n            return self.ZERO\n        elif isinstance(self.r, Invert) and self.r.v == self.l:\n            return self.ZERO\n        elif isinstance(self.l, Invert) and isinstance(self.r, Invert):\n            return Invert(Or(self.l.v, self.r.v))\n\n    def expected_active_fraction(self, **kwargs):\n        afl = self.l.expected_active_fraction(**kwargs)\n        afr = self.r.expected_active_fraction(**kwargs)\n        return afl*afr", "@dataclass\nclass Or(SymbolicBHV):\n    l: SymbolicBHV\n    r: SymbolicBHV\n\n    def reconstruct(self, l, r):\n        return Or(l, r)\n\n    def show(self, **kwargs):\n        brackets = not kwargs.get(\"toplevel\", False)\n        return \"(\"*brackets + f\"{self.l.show(**kwargs)} | {self.r.show(**kwargs)}\" + \")\"*brackets\n\n    def instantiate(self, **kwargs):\n        return self.l.execute(**kwargs) | self.r.execute(**kwargs)\n\n    def reduce(self, **kwargs):\n        if self.l == self.ONE or self.r == self.ONE:\n            return self.ONE\n        elif self.l == self.ZERO:\n            return self.r\n        elif self.r == self.ZERO:\n            return self.l\n        elif isinstance(self.l, Invert) and self.l.v == self.r:\n            return self.ONE\n        elif isinstance(self.r, Invert) and self.r.v == self.l:\n            return self.ONE\n        elif isinstance(self.l, Invert) and isinstance(self.r, Invert):\n            return Invert(And(self.l.v, self.r.v))\n\n    def expected_active_fraction(self, **kwargs):\n        afl = self.l.expected_active_fraction(**kwargs)\n        afr = self.r.expected_active_fraction(**kwargs)\n        return 1. - ((1. - afl)*(1. - afr))", "@dataclass\nclass Invert(SymbolicBHV):\n    v: SymbolicBHV\n\n    def reconstruct(self, v):\n        return Invert(v)\n\n    def show(self, **kwargs):\n        brackets = not kwargs.get(\"toplevel\", False)\n        return \"(\"*brackets + f\"~{self.v.show(**kwargs)}\" + \")\"*brackets\n\n    def instantiate(self, **kwargs):\n        return ~self.v.execute(**kwargs)\n\n    def reduce(self, **kwargs):\n        if self.v == self.ONE:\n            return self.ZERO\n        elif self.v == self.ZERO:\n            return self.ONE\n        elif isinstance(self.v, Invert):\n            return self.v.v\n\n    def expected_active_fraction(self, **kwargs):\n        return 1. - self.v.expected_active_fraction(**kwargs)", "@dataclass\nclass Select(SymbolicBHV):\n    cond: SymbolicBHV\n    when1: SymbolicBHV\n    when0: SymbolicBHV\n\n    def reconstruct(self, c, w1, w0):\n        return Select(c, w1, w0)\n\n    def nodename(self, compact_select=False, **kwargs):\n        return f\"ON {self.cond.nodename()}\" if compact_select else super().nodename(**kwargs)\n\n    def labeled_children(self, compact_select=False, **kwargs):\n        return [(self.when1, \"1\"), (self.when0, \"0\")] if compact_select else super().labeled_children(**kwargs)\n\n    def show(self, **kwargs):\n        return f\"{self.cond.show(**kwargs)}.select({self.when1.show(**kwargs)}, {self.when0.show(**kwargs)})\"\n\n    def instantiate(self, **kwargs):\n        return self.cond.execute(**kwargs).select(self.when1.execute(**kwargs), self.when0.execute(**kwargs))\n\n    def internal_size(self):\n        return 3\n\n    def reduce(self, **kwargs):\n        expand_select_xor = kwargs.get(\"expand_select_xor\", False)\n        expand_select_and_or = kwargs.get(\"expand_select_and_or\", False)\n\n        if self.when1 == self.ONE and self.when0 == self.ZERO:\n            return self.cond\n        elif self.when1 == self.ZERO and self.when0 == self.ONE:\n            return ~self.cond\n        elif self.when0 == self.when1:\n            return self.when0\n        elif self.when1 == self.ONE:\n            return self.cond | self.when0\n        elif self.when1 == self.ZERO:\n            return ~self.cond & self.when0\n        elif self.when0 == self.ONE:\n            return ~self.cond | self.when1\n        elif self.when0 == self.ZERO:\n            return self.cond & self.when1\n        else:\n            if self.when1 == ~self.when0:\n                return self.cond ^ self.when0\n            elif self.when0 == ~self.when1:\n                return self.cond ^ self.when0\n            elif isinstance(self.when0, Invert) and isinstance(self.when1, Invert):\n                return ~Select(self.cond, self.when1.v, self.when0.v)\n            else:\n                if expand_select_xor:\n                    return self.when0 ^ (self.cond & (self.when0 ^ self.when1))\n                elif expand_select_and_or:\n                    return (self.cond & self.when1) | (~self.cond & self.when0)\n\n    def expected_active_fraction(self, **kwargs):\n        afc = self.cond.expected_active_fraction(**kwargs)\n        af1 = self.when1.expected_active_fraction(**kwargs)\n        af0 = self.when0.expected_active_fraction(**kwargs)\n        return afc*af1 + (1. - afc)*af0", "@dataclass\nclass ActiveFraction(Symbolic):\n    v: SymbolicBHV\n\n    def reconstruct(self, v):\n        return ActiveFraction(v)\n\n    def show(self, **kwargs):\n        return f\"{self.v.show(**kwargs)}.active_fraction()\"\n\n    def instantiate(self, **kwargs):\n        return self.v.execute(**kwargs).active_fraction()", "@dataclass\nclass BiasRel(Symbolic):\n    rel: SymbolicBHV\n    l: SymbolicBHV\n    r: SymbolicBHV\n\n    def reconstruct(self, rel, l, r):\n        return BiasRel(rel, l, r)\n\n    def show(self, **kwargs):\n        return f\"{self.l.show(**kwargs)}.bias_rel({self.r.show(**kwargs)}, {self.rel.show(**kwargs)})\"\n\n    def instantiate(self, **kwargs):\n        return self.l.execute(**kwargs).bias_rel(self.r.execute(**kwargs), self.rel.execute(**kwargs))", "@dataclass\nclass Related(Symbolic):\n    l: SymbolicBHV\n    r: SymbolicBHV\n    stdvs: float\n\n    def reconstruct(self, l, r):\n        return Related(l, r, self.stdvs)\n\n    def show(self, **kwargs):\n        return f\"{self.l.show(**kwargs)}.related({self.r.show(**kwargs)}, {self.stdvs})\"\n\n    def instantiate(self, **kwargs):\n        return self.l.execute(**kwargs).related(self.r.execute(**kwargs), self.stdvs)", "@dataclass\nclass Unrelated(Symbolic):\n    l: SymbolicBHV\n    r: SymbolicBHV\n    stdvs: float\n\n    def reconstruct(self, l, r):\n        return Unrelated(l, r, self.stdvs)\n\n    def show(self, **kwargs):\n        return f\"{self.l.show(**kwargs)}.unrelated({self.r.show(**kwargs)}, {self.stdvs})\"\n\n    def instantiate(self, **kwargs):\n        return self.l.execute(**kwargs).unrelated(self.r.execute(**kwargs), self.stdvs)", ""]}
{"filename": "tests/sym_laws.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV as BHV, Var, Eq, Or, And, Xor, Invert, Majority\nfrom bhv.unification import unify\nfrom bhv.shared import stable_hashcode\n\n\nx = Var(\"x\")\ny = Var(\"y\")\nz = Var(\"z\")\nu = Var(\"u\")\nv = Var(\"v\")", "u = Var(\"u\")\nv = Var(\"v\")\nw = Var(\"w\")\n\n\ndef associative3(m): return Eq(m(x, u, m(y, u, z)), m(z, u, m(y, u, x)))\ndef commutative3_1(m): return Eq(m(x, y, z), m(z, y, x))\ndef commutative3_2(m): return Eq(m(x, y, z), m(y, x, z))\ndef distributive3(m, w): return Eq(m(x, y, w(u, v, z)), w(m(x, y, u), m(x, y, v), z))\n", "def distributive3(m, w): return Eq(m(x, y, w(u, v, z)), w(m(x, y, u), m(x, y, v), z))\n\n\ndef associative(m): return Eq(m(m(x, y), z), m(x, m(y, z))).named(f\"{m.__name__} associative\")\ndef commutative(m): return Eq(m(x, y), m(y, x)).named(f\"{m.__name__} commutative\")\ndef idempotent(m): return Eq(m(x, x), x).named(f\"{m.__name__} idempotent\")\ndef self_inverse(m, u): return Eq(m(x, x), u).named(f\"{m.__name__} self inverse {u}\")\ndef involutive(f): return Eq(f(f(x)), x).named(f\"{f.__name__} involutive\")\ndef equals(f, a, b): return Eq(f(a), b).named(f\"{f.__name__}({a}) equals {b}\")\ndef right_unit(m, u): return Eq(m(x, u), x).named(f\"{m.__name__} right unit {u}\")\ndef right_absorbing(m, z): return Eq(m(x, z), z).named(f\"{m.__name__} right absorbing {z}\")", "def equals(f, a, b): return Eq(f(a), b).named(f\"{f.__name__}({a}) equals {b}\")\ndef right_unit(m, u): return Eq(m(x, u), x).named(f\"{m.__name__} right unit {u}\")\ndef right_absorbing(m, z): return Eq(m(x, z), z).named(f\"{m.__name__} right absorbing {z}\")\ndef absorptive(m, w): return Eq(m(x, w(x, y)), x).named(f\"{m.__name__} absorbs w.r.t. {w.__name__}\")\ndef distributive(m, w): return Eq(m(x, w(y, z)), w(m(x, y), m(x, z))).named(f\"{m.__name__} distributes over {w.__name__}\")\ndef demorgan(f, m, w): return Eq(f(m(x, y)), w(f(x), f(y))).named(f\"De Morgan {f.__name__} over {m.__name__}, and {m.__name__}\")\ndef drop_left(f, m): return Eq(f(m(x, y)), m(f(x), y)).named(f\"Drop {f.__name__} left into {m.__name__}\")\ndef complement(m, f, z): return Eq(m(x, f(x)), z).named(f\"Complement by {f.__name__} under {m.__name__} is {z}\")\ndef propagate(f, m): return Eq(f(m(x)), m(f(x)))\ndef propagate2(f, m): return Eq(f(m(x, y)), m(f(x), f(y)))\ndef propagate3(f, m): return Eq(f(m(x, y, z)), m(f(x), f(y), f(z)))", "def propagate(f, m): return Eq(f(m(x)), m(f(x)))\ndef propagate2(f, m): return Eq(f(m(x, y)), m(f(x), f(y)))\ndef propagate3(f, m): return Eq(f(m(x, y, z)), m(f(x), f(y), f(z)))\ndef expand_single_inner(f, k, m, w): return Eq(k(x, y), m(w(x, f(y)), w(f(x), y)))\ndef expand_single_outer(f, k, m, w): return Eq(k(x, y), m(w(x, y), f(m(x, y))))\ndef determinism(f): return Eq(f(x), f(x))\ndef extensionality(f, g): return Eq(f(x), g(x))\ndef extensionality2(f, g): return Eq(f(x, y), g(x, y))\ndef extensionality3(f, g): return Eq(f(x, y, z), g(x, y, z))\ndef extensionality4(f, g): return Eq(f(x, y, z, u), g(x, y, z, u))\ndef extensionality5(f, g): return Eq(f(x, y, z, u, v), g(x, y, z, u, v))", "def extensionality3(f, g): return Eq(f(x, y, z), g(x, y, z))\ndef extensionality4(f, g): return Eq(f(x, y, z, u), g(x, y, z, u))\ndef extensionality5(f, g): return Eq(f(x, y, z, u, v), g(x, y, z, u, v))\ndef extensionality6(f, g): return Eq(f(x, y, z, u, v, w), g(x, y, z, u, v, w))\ndef extensionality7(f, g): return Eq(f(x, y, z, u, v, w, r), g(x, y, z, u, v, w, r))\ndef extensionalityN(f, g): return Eq(f(xs), g(xs))\ndef encode_decode(enc, dec): return Eq(x, dec(enc(x)))\ndef invariant_under(f, p): return Eq(f(x), f(p(x))).named(f\"{f.__name__} is invariant under {p.__name__}\")\ndef invariant_under2(f, p): return Eq(f(x, y), f(p(x), p(y))).named(f\"{f.__name__} is invariant under {p.__name__}\")\ndef identity(f): return Eq(f(x), x)\ndef invariant2(m): return Eq(m(x, y), y)", "def invariant_under2(f, p): return Eq(f(x, y), f(p(x), p(y))).named(f\"{f.__name__} is invariant under {p.__name__}\")\ndef identity(f): return Eq(f(x), x)\ndef invariant2(m): return Eq(m(x, y), y)\ndef invariant3(m): return Eq(m(x, y, z), z)\ndef invariant3_1(m): return Eq(m(x, x, z), x)\ndef invariant3_2(m): return Eq(m(x, x, z), z)\n\ndef lattice(join): return [associative(join), commutative(join), idempotent(join)]\ndef bounded_lattice(join, top, bot): return lattice(join) + [right_unit(join, bot), right_absorbing(join, top)]\ndef xor_props(xor_, bot): return [associative(xor_), commutative(xor_), self_inverse(xor_, bot), right_unit(xor_, bot)]\ndef not_props(not_, bot, top): return [involutive(not_), equals(not_, top, bot), equals(not_, bot, top)]", "def bounded_lattice(join, top, bot): return lattice(join) + [right_unit(join, bot), right_absorbing(join, top)]\ndef xor_props(xor_, bot): return [associative(xor_), commutative(xor_), self_inverse(xor_, bot), right_unit(xor_, bot)]\ndef not_props(not_, bot, top): return [involutive(not_), equals(not_, top, bot), equals(not_, bot, top)]\ndef or_and_props(or_, and_): return [distributive(or_, and_), distributive(and_, or_), absorptive(or_, and_), absorptive(and_, or_)]\ndef gf2(add, mul, one, zero):\n    return [\n        right_unit(add, zero),\n        right_unit(mul, one),\n        associative(add), commutative(add),\n        associative(mul), commutative(mul),\n        idempotent(mul),\n        self_inverse(add, zero),\n        distributive(mul, add)\n    ]", "def maj3_inv(maj3, inv):\n    return [\n        commutative3_1(maj3),\n        commutative3_2(maj3),\n        invariant3_1(maj3),\n        invariant3_2(maj3),\n        associative3(maj3),\n        distributive3(maj3, maj3),\n        propagate3(inv, maj3)\n    ]\ndef boolean_algebra(conj, disj, inv, zero, one):\n    return [\n        right_unit(disj, zero),\n        right_unit(conj, one),\n        commutative(conj),\n        commutative(disj),\n        distributive(conj, disj),\n        distributive(disj, conj),\n        associative(conj),\n        associative(disj),\n        complement(disj, inv, one),\n        complement(conj, inv, zero),\n    ]", "def boolean_algebra(conj, disj, inv, zero, one):\n    return [\n        right_unit(disj, zero),\n        right_unit(conj, one),\n        commutative(conj),\n        commutative(disj),\n        distributive(conj, disj),\n        distributive(disj, conj),\n        associative(conj),\n        associative(disj),\n        complement(disj, inv, one),\n        complement(conj, inv, zero),\n    ]", "\n\ndef bhv_props():\n    extra = [\n        demorgan(Invert, Or, And),\n        demorgan(Invert, And, Or),\n        drop_left(Invert, Xor),\n        expand_single_inner(Invert, Xor, Or, And),\n        expand_single_outer(Invert, Xor, And, Or),\n        distributive(And, Xor),\n        complement(Xor, Invert, BHV.ONE),\n        invariant_under2(Xor, Invert),\n        Eq(x ^ (x & y), x & ~y),\n        Eq(x ^ (~x & y), x | y),\n        Eq((x & y) ^ (x & z), x & (y ^ z)),\n    ]\n\n    return (\n        bounded_lattice(And, BHV.ZERO, BHV.ONE) +\n        bounded_lattice(Or, BHV.ONE, BHV.ZERO) +\n        xor_props(Xor, BHV.ZERO) +\n        not_props(Invert, BHV.ZERO, BHV.ONE) +\n        or_and_props(Or, And) +\n        gf2(Xor, And, BHV.ONE, BHV.ZERO) +\n        # maj3_inv(majority3, Invert) +\n        boolean_algebra(And, Or, Invert, BHV.ZERO, BHV.ONE) +\n        extra)", "\n\nprops = bhv_props()\nprops = [p.swap() if p.r.size() > p.l.size() else p for p in props]\nprops = list({stable_hashcode(p): p for p in props}.values())\nprops.sort(key=lambda p: (p.r.size() - p.l.size()) or (len(p.r.vars()) - len(p.l.vars())))\n\nsep = next(filter(lambda p: (p.r.size() - p.l.size()) >= 0, props))\nprops = props[:props.index(sep)]\n", "props = props[:props.index(sep)]\n\n\ndef search(e):\n    fvars = set(e.vars())\n    for prop in props:\n        bindings = unify(e, prop.l)\n        if bindings and not set(bindings) & fvars:\n            print(\"applying\", prop.name, \"to\", e.show())\n            return prop.r.substitute(bindings)\n    return None", "\n\ndef rec(x):\n    cs = x.children()\n\n    for i in range(len(cs)):\n        res_c = search(cs[i])\n        if res_c is None:\n            continue\n        else:\n            cs[i] = res_c\n            return x.reconstruct(*cs)\n\n    for i in range(len(cs)):\n        res_c = rec(cs[i])\n        if res_c is None:\n            continue\n        else:\n            cs[i] = res_c\n            return x.reconstruct(*cs)", "\ndef greedy(initial, iters=100):\n    e = initial\n\n    for i in range(iters):\n        res_e = search(e)\n        if res_e is not None:\n            e = res_e\n        else:\n            rec_e = rec(e)\n            if rec_e is not None:\n                e = rec_e\n            else:\n                print(\"early\", i)\n                return e\n\n    return e", "\n\nif __name__ == '__main__':\n    x1 = Var(\"x1\")\n\n    teste1 = (~(~(x1))) ^ (~x1 & BHV.rand())\n    print(greedy(teste1).show())\n\n    teste2 = ~(x1 ^ BHV.ZERO)\n    print(greedy(teste2).show())", ""]}
{"filename": "tests/fiestal.py", "chunked_list": ["import unittest\n\n# from bhv.np import NumPyPacked64BHV as BHV, DIMENSION\n# from bhv.pytorch import TorchPackedBHV as BHV, DIMENSION\n# from bhv.vanilla import VanillaBHV as BHV, DIMENSION\nfrom bhv.native import NativePackedBHV as BHV, DIMENSION\nfrom bhv.symbolic import Var, SymbolicBHV\n\n\nclass TestFeistal(unittest.TestCase):\n    def test_halves(self):\n        h1 = BHV.HALF\n        h2 = ~BHV.HALF\n\n        self.assertEqual(h1.active(), DIMENSION/2)\n        self.assertEqual(h2.active(), DIMENSION/2)\n        self.assertEqual(h1.hamming(h2), DIMENSION)\n\n        self.assertEqual(h1.swap_halves(), h2)\n        self.assertEqual(h2.swap_halves(), h1)\n\n        r = BHV.rand()\n\n        self.assertEqual(r.swap_halves().swap_halves(), r)\n        self.assertEqual(r.swap_halves().swap_halves().swap_halves(), r.swap_halves())\n\n    def test_keys(self):\n        x = BHV.rand()\n\n        ks = BHV.nrand(10)\n\n        x_enc_k = [x.feistal(k) for k in ks]\n\n        x_dec_k = [x_enc.feistal(k, inv=True) for x_enc, k in zip(x_enc_k, ks)]\n\n        for k, x_enc, x_dec in zip(ks, x_enc_k, x_dec_k):\n            self.assertEqual(x, x_dec, msg=\"inverse\")\n            self.assertNotEqual(x_enc, x_dec, msg=\"variant\")\n            self.assertNotEqual(x_enc, ~x_dec, msg=\"not opposite\")\n            self.assertNotEqual(x_enc, k, msg=\"not key\")\n            self.assertNotEqual(x_enc, BHV.HALF, msg=\"not half\")\n\n        for x_enc_i in x_enc_k:\n            eq = False\n            for x_enc_j in x_enc_k:\n                if x_enc_i == x_enc_j:\n                    if eq: self.fail(\"different keys produce the same result\")\n                    eq = True\n                else:\n                    self.assertTrue(x_enc_i.unrelated(x_enc_j))", "\nclass TestFeistal(unittest.TestCase):\n    def test_halves(self):\n        h1 = BHV.HALF\n        h2 = ~BHV.HALF\n\n        self.assertEqual(h1.active(), DIMENSION/2)\n        self.assertEqual(h2.active(), DIMENSION/2)\n        self.assertEqual(h1.hamming(h2), DIMENSION)\n\n        self.assertEqual(h1.swap_halves(), h2)\n        self.assertEqual(h2.swap_halves(), h1)\n\n        r = BHV.rand()\n\n        self.assertEqual(r.swap_halves().swap_halves(), r)\n        self.assertEqual(r.swap_halves().swap_halves().swap_halves(), r.swap_halves())\n\n    def test_keys(self):\n        x = BHV.rand()\n\n        ks = BHV.nrand(10)\n\n        x_enc_k = [x.feistal(k) for k in ks]\n\n        x_dec_k = [x_enc.feistal(k, inv=True) for x_enc, k in zip(x_enc_k, ks)]\n\n        for k, x_enc, x_dec in zip(ks, x_enc_k, x_dec_k):\n            self.assertEqual(x, x_dec, msg=\"inverse\")\n            self.assertNotEqual(x_enc, x_dec, msg=\"variant\")\n            self.assertNotEqual(x_enc, ~x_dec, msg=\"not opposite\")\n            self.assertNotEqual(x_enc, k, msg=\"not key\")\n            self.assertNotEqual(x_enc, BHV.HALF, msg=\"not half\")\n\n        for x_enc_i in x_enc_k:\n            eq = False\n            for x_enc_j in x_enc_k:\n                if x_enc_i == x_enc_j:\n                    if eq: self.fail(\"different keys produce the same result\")\n                    eq = True\n                else:\n                    self.assertTrue(x_enc_i.unrelated(x_enc_j))", "\n\nclass TestRehash(unittest.TestCase):\n    def test_deterministic(self):\n        v = BHV.rand()\n        h1 = v.rehash()\n        h2 = v.rehash()\n\n        self.assertEqual(h1, h2)\n\n    def test_random_different(self):\n        vs = BHV.nrand(10)\n        hs = [v.rehash() for v in vs]\n\n        for v in hs:\n            eq = False\n            for v_ in hs:\n                if v == v_:\n                    if eq: self.fail(\"different keys produce the same result\")\n                    eq = True\n                else:\n                    self.assertTrue(v.unrelated(v_))\n\n    def test_close_different(self):\n        seed = BHV.rand()\n        vs = [seed.flip_pow(8) for _ in range(10)]\n\n        for v in vs:\n            eq = False\n            for v_ in vs:\n                if v == v_:\n                    if eq: self.fail(\"flip_pow produced the same vector\")\n                    eq = True\n                else:\n                    self.assertTrue(v.related(v_))\n\n        hs = [v.rehash() for v in vs]\n\n        for v in hs:\n            eq = False\n            for v_ in hs:\n                if v == v_:\n                    if eq: self.fail(\"different keys produce the same result\")\n                    eq = True\n                else:\n                    self.assertTrue(v.unrelated(v_))", "\n\nif __name__ == '__main__':\n    unittest.main()\n"]}
{"filename": "tests/native_test.py", "chunked_list": ["from time import monotonic_ns\n\n# from bhv.np import NumPyBoolBHV as BHV\nfrom bhv.np import NumPyPacked64BHV as BHV\n# from bhv.native import CNativePackedBHV as BHV\n\nx = 0x7834d688d8827099\nfor i in range(5000000):\n    x = x + (x % 7)\n", "\nN = 201\n\nt0 = monotonic_ns()\n\nrs = [BHV.rand() for _ in range(N)]\n\nt1 = monotonic_ns()\nprint(\"rand\", t1 - t0)\n", "print(\"rand\", t1 - t0)\n\nps = [r.roll_words(42) for r in rs]\n\nt2 = monotonic_ns()\nprint(\"new permute\", t2 - t1)\n\nfor r, p in zip(rs, ps):\n    assert r == p.roll_words(-42)\n", "\nt3 = monotonic_ns()\nprint(\"rpermute eq\", t3 - t2)\n\nm = BHV.majority(rs)\n\nt4 = monotonic_ns()\nprint(\"majority\", t4 - t3)\n\nif False:\n    ds = [r ^ m for r in rs]\n\n    t5 = monotonic_ns()\n    print(\"xor\", t5 - t4)\n\n    qs = [d.active() for d in ds]\n\n    t6 = monotonic_ns()\n    print(\"active\", t6 - t5)\nelse:\n    qs = [BHV.hamming(r, m) for r in rs]\n\n    t5 = monotonic_ns()\n    print(\"hamming\", t5 - t4)", "\nif False:\n    ds = [r ^ m for r in rs]\n\n    t5 = monotonic_ns()\n    print(\"xor\", t5 - t4)\n\n    qs = [d.active() for d in ds]\n\n    t6 = monotonic_ns()\n    print(\"active\", t6 - t5)\nelse:\n    qs = [BHV.hamming(r, m) for r in rs]\n\n    t5 = monotonic_ns()\n    print(\"hamming\", t5 - t4)", "\nprint(sum(qs)/N)\n"]}
{"filename": "tests/composites.py", "chunked_list": ["import unittest\n\n# import torch\n\n# from bhv.np import NumPyPacked64BHV as BHV\nfrom bhv.vanilla import VanillaBHV as BHV\n\n\nDELTA = 0.015\n", "DELTA = 0.015\n\n\nclass TestComposites(unittest.TestCase):\n    def test_flip_frac_on(self):\n        # self | BHV.random(flip_on_frac)\n        r = BHV.rand()\n        self.assertLessEqual(r.zscore(), 4, \"rerun test\")\n\n        self.assertEqual(r.flip_frac_on(.0), r)\n        self.assertEqual(r.flip_frac_on(1.), BHV.ONE)\n\n        for i in range(11):\n            k = i/10\n            ber = i/20\n            tweaked = r.flip_frac_on(k)\n            self.assertAlmostEqual(tweaked.bit_error_rate(r), ber, delta=DELTA)\n            self.assertAlmostEqual(tweaked.bit_error_rate(BHV.ONE), .5 - ber, delta=DELTA)\n            self.assertAlmostEqual(BHV.ZERO.flip_frac_on(k).active_fraction(), k, delta=DELTA)\n\n    def test_flip_pow_on(self):\n        # self | ~BHV.rand2(flip_on_pow)\n        r = BHV.rand()\n        self.assertLessEqual(r.zscore(), 4, \"rerun test\")\n\n        for pow in range(20):\n            tweaked = r.flip_pow_on(pow)\n            expected = 2**(-pow - 2)\n            self.assertAlmostEqual(tweaked.bit_error_rate(BHV.ONE), expected, delta=DELTA)\n            self.assertAlmostEqual(tweaked.bit_error_rate(r), .5 - expected, delta=DELTA)\n\n    def test_flip_frac_off(self):\n        # self & BHV.random(1. - flip_off_frac)\n        r = BHV.rand()\n        self.assertLessEqual(r.zscore(), 4, \"rerun test\")\n\n        self.assertEqual(r.flip_frac_off(.0), r)\n        self.assertEqual(r.flip_frac_off(1.), BHV.ZERO)\n\n        for i in range(11):\n            k = i/10\n            ber = i/20\n            tweaked = r.flip_frac_off(k)\n            self.assertAlmostEqual(tweaked.bit_error_rate(r), ber, delta=DELTA)\n            self.assertAlmostEqual(tweaked.bit_error_rate(BHV.ZERO), .5 - ber, delta=DELTA)\n            self.assertAlmostEqual(BHV.ONE.flip_frac_off(k).active_fraction(), 1. - k, delta=DELTA)\n\n    def test_flip_pow_off(self):\n        # self & BHV.rand2(flip_off_pow)\n        r = BHV.rand()\n        self.assertLessEqual(r.zscore(), 4, \"rerun test\")\n\n        for i in range(20):\n            tweaked = r.flip_pow_off(i)\n            expected = 2**(-i - 2)\n            self.assertAlmostEqual(tweaked.bit_error_rate(BHV.ZERO), expected, delta=DELTA)\n            self.assertAlmostEqual(tweaked.bit_error_rate(r), .5 - expected, delta=DELTA)\n\n    def test_interpolate_flip_equivalence(self):\n        # r.select(flip_frac_on(l, f), flip_frac_off(l, f))\n        # equiv\n        # r.select_random(l, f)\n        a, b = BHV.nrand(2)\n        self.assertLessEqual(a.zscore(), 4, \"rerun test\")\n        self.assertLessEqual(b.zscore(), 4, \"rerun test\")\n\n        def interpolate_via_frac(l, r, f):\n            return r.select(l.flip_frac_on(f), l.flip_frac_off(f))\n\n        def interpolate(l, r, f):\n            return r.select_random(l, f)\n\n        for i in range(11):\n            aib = interpolate_via_frac(a, b, i/10)\n            aib_ref = interpolate(a, b, i/10)\n            self.assertLessEqual(aib.zscore(), 4)\n            self.assertAlmostEqual(aib.bit_error_rate(a), aib_ref.bit_error_rate(a), delta=DELTA)\n            self.assertAlmostEqual(aib.bit_error_rate(b), aib_ref.bit_error_rate(b), delta=DELTA)\n\n    def test_interpolate_pow_equivalence(self):\n        a, b = BHV.nrand(2)\n        self.assertLessEqual(a.zscore(), 4, \"rerun test\")\n        self.assertLessEqual(b.zscore(), 4, \"rerun test\")\n\n        def interpolatep(l, r, p):\n            if p > 0:\n                return r.select_rand2(l, p)\n            else:\n                return l.select_rand2(r, -p)\n\n        for i in range(-20, 20):\n            aib = interpolatep(a, b, i)\n            assert aib.zscore() < 4\n            expected = .5 - 2**(-abs(i) - 2) if i < 0 else 2**(-abs(i) - 2)\n            self.assertAlmostEqual(aib.bit_error_rate(a), expected, delta=DELTA)\n            self.assertAlmostEqual(aib.bit_error_rate(b), .5 - expected, delta=DELTA)", "\n\nif __name__ == '__main__':\n    unittest.main()\n"]}
{"filename": "tests/embedding.py", "chunked_list": ["import unittest\n\nfrom bhv.np import NumPyPacked64BHV as BHV\nfrom bhv.embedding import Random, InterpolateBetween\n\n\nclass TestRandomEmbedding(unittest.TestCase):\n    def test_random(self):\n        a, b, c = \"abc\"\n        embedding = Random(BHV)\n        hva = embedding.forward(a)\n        hvb = embedding.forward(b)\n        self.assertTrue(hva.unrelated(hvb))\n        hva_ = embedding.forward(a)\n        self.assertEqual(hva, hva_)\n\n        hvq = BHV.rand()\n        self.assertIsNone(embedding.back(hvq))\n\n        self.assertEqual(b, embedding.back(hvb))", "\n\nclass TestInterpolateLineEmbedding(unittest.TestCase):\n    def test_internal(self):\n        embedding = InterpolateBetween(BHV)\n        a, b, c = .1, .5, .68\n        self.assertAlmostEqual(a, embedding.back(embedding.forward(a)), 2)\n\n\nif __name__ == '__main__':\n    unittest.main()", "\nif __name__ == '__main__':\n    unittest.main()\n"]}
{"filename": "tests/test_pytorch.py", "chunked_list": ["import unittest\n\nimport torch\n\nfrom bhv.pytorch import TorchPackedBHV, TorchBoolBHV\n\n\nclass TestTorchBoolBHV(unittest.TestCase):\n    def test_basic(self):\n        self.assertTrue(True)", "\n\nclass TestTorchBHVConversion(unittest.TestCase):\n    def test_random(self):\n        rp = TorchPackedBHV.rand()\n        self.assertTrue(torch.equal(rp.data, rp.unpack().pack().data))\n        ru = TorchBoolBHV.rand()\n        self.assertTrue(torch.equal(ru.data, ru.pack().unpack().data))\n\n    def test_extrema(self):\n        self.assertTrue(torch.equal(TorchPackedBHV.ZERO.unpack().data, TorchBoolBHV.ZERO.data))\n        self.assertTrue(torch.equal(TorchPackedBHV.ZERO.data, TorchBoolBHV.ZERO.pack().data))\n        self.assertTrue(torch.equal(TorchPackedBHV.ONE.unpack().data, TorchBoolBHV.ONE.data))\n        self.assertTrue(torch.equal(TorchPackedBHV.ONE.data, TorchBoolBHV.ONE.pack().data))", "\n\nif __name__ == '__main__':\n    unittest.main()\n"]}
{"filename": "tests/lsynthesis.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV as BHV, Var\nfrom bhv.slice import Slice\n\n\ndef tos(i, b): return bin(i)[2:].rjust(b, '0')\ndef tomask(s): return [x == '1' for x in s]\ndef frommask(m): return ''.join(\"01\"[x] for x in m)\ndef bitconfigs(n): return [tomask(tos(i, n)) for i in range(2**n)]\n\n", "\n\nnames = [Var(\"a\"), Var(\"b\"), Var(\"c\")]\nconfigurations = bitconfigs(3)\noperators = 0\nfor target in bitconfigs(8):\n    f = BHV.synth(names, target)\n    f_ = f.simplify()\n\n    # print(f_.show())\n\n    retrieved = [f_.execute(vars=dict(a=Slice(a), b=Slice(b), c=Slice(c)), bhv=Slice).b for a, b, c in configurations]\n    operators += f_.size()\n    # print(frommask(target))\n    # print(frommask(retrieved))\n    assert target == retrieved", "\nprint(\"average operators:\", operators/256)\n\nprint(tos(184, 8), BHV.synth(names, tomask(tos(184, 8))).simplify().show())\nprint(tos(110, 8), BHV.synth(names, tomask(tos(110, 8))).simplify().show())\nprint(tos(90, 8), BHV.synth(names, tomask(tos(90, 8))).simplify().show())\nprint(tos(30, 8), BHV.synth(names, tomask(tos(30, 8))).simplify().show())\nprint(tos(22, 8), BHV.synth(names, tomask(tos(22, 8))).simplify().show())\n\nmaj3 = [sum(c) >= 2 for c in configurations]", "\nmaj3 = [sum(c) >= 2 for c in configurations]\nprint(frommask(maj3), BHV.synth(names, maj3).simplify().show())\n"]}
{"filename": "tests/metrics.py", "chunked_list": ["from bhv.np import NumPyPacked64BHV as BHV\n\na = BHV.rand()\nfor i in range(0, 21):\n    p = i/20\n\n    b = a.flip_frac(p)\n    print(p)\n    print(\"ber\", 1. - a.bit_error_rate(b))\n    print(\"cos\", a.cosine(b))\n    print(\"jac\", a.jaccard(b))\n    print(\"mut\", a.mutual_information(b, distance=True))\n    print(\"tve\", a.tversky(b, .5, .5))", ""]}
{"filename": "tests/laws.py", "chunked_list": ["from time import monotonic\nfrom itertools import product, groupby\n\nfrom bhv.abstract import AbstractBHV, DIMENSION\nfrom bhv.native import NativePackedBHV\nfrom bhv.np import NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV\n# from bhv.pytorch import TorchBoolBHV, TorchPackedBHV\nfrom bhv.vanilla import VanillaBHV\n\n\ndef associative(m): return lambda x, y, z: m(m(x, y), z) == m(x, m(y, z))", "\n\ndef associative(m): return lambda x, y, z: m(m(x, y), z) == m(x, m(y, z))\ndef associative3(m): return lambda x, y, z, u: m(x, u, m(y, u, z)) == m(z, u, m(y, u, x))\ndef commutative(m): return lambda x, y: m(x, y) == m(y, x)\ndef commutative3(m): return lambda x, y, z: m(x, y, z) == m(y, x, z) == m(z, y, x)\ndef idempotent(m): return lambda x: m(x, x) == x\ndef self_inverse(m, u): return lambda x: m(x, x) == u\ndef self_inverse_op(f): return lambda x: f(f(x)) == x\ndef equals(f, a, b): return lambda: f(a) == b\ndef right_unit(m, u): return lambda x: m(x, u) == x", "def self_inverse_op(f): return lambda x: f(f(x)) == x\ndef equals(f, a, b): return lambda: f(a) == b\ndef right_unit(m, u): return lambda x: m(x, u) == x\ndef right_absorbing(m, z): return lambda x: m(x, z) == z\ndef absorptive(m, w): return lambda x, y: m(x, w(x, y)) == x\ndef distributive(m, w): return lambda x, y, z: m(x, w(y, z)) == w(m(x, y), m(x, z))\ndef distributive3(m, w): return lambda x, y, z, u, v: m(x, y, w(u, v, z)) == w(m(x, y, u), m(x, y, v), z)\ndef demorgan(f, m, w): return lambda x, y: f(m(x, y)) == w(f(x), f(y))\ndef drop_left(f, m): return lambda x, y: f(m(x, y)) == m(f(x), y)\ndef propagate(f, m): return lambda x: f(m(x)) == m(f(x))\ndef propagate2(f, m): return lambda x, y: f(m(x, y)) == m(f(x), f(y))", "def drop_left(f, m): return lambda x, y: f(m(x, y)) == m(f(x), y)\ndef propagate(f, m): return lambda x: f(m(x)) == m(f(x))\ndef propagate2(f, m): return lambda x, y: f(m(x, y)) == m(f(x), f(y))\ndef propagate3(f, m): return lambda x, y, z: f(m(x, y, z)) == m(f(x), f(y), f(z))\ndef expand_single_inner(f, k, m, w): return lambda x, y: k(x, y) == m(w(x, f(y)), w(f(x), y))\ndef expand_single_outer(f, k, m, w): return lambda x, y: k(x, y) == m(w(x, y), f(m(x, y)))\ndef determinism(f): return lambda x: f(x) == f(x)\ndef extensionality(f, g): return lambda x: f(x) == g(x)\ndef extensionality2(f, g): return lambda x, y: f(x, y) == g(x, y)\ndef extensionality3(f, g): return lambda x, y, z: f(x, y, z) == g(x, y, z)\ndef extensionality4(f, g): return lambda x, y, z, u: f(x, y, z, u) == g(x, y, z, u)", "def extensionality2(f, g): return lambda x, y: f(x, y) == g(x, y)\ndef extensionality3(f, g): return lambda x, y, z: f(x, y, z) == g(x, y, z)\ndef extensionality4(f, g): return lambda x, y, z, u: f(x, y, z, u) == g(x, y, z, u)\ndef extensionality5(f, g): return lambda x, y, z, u, v: f(x, y, z, u, v) == g(x, y, z, u, v)\ndef extensionality6(f, g): return lambda x, y, z, u, v, w: f(x, y, z, u, v, w) == g(x, y, z, u, v, w)\ndef extensionality7(f, g): return lambda x, y, z, u, v, w, r: f(x, y, z, u, v, w, r) == g(x, y, z, u, v, w, r)\ndef extensionality9(f, g): return lambda x, y, z, u, v, w, r, i, j: f(x, y, z, u, v, w, r, i, j) == g(x, y, z, u, v, w, r, i, j)\ndef extensionalityN(f, g): return lambda xs: f(xs) == g(xs)\ndef encode_decode(enc, dec): return lambda x: x == dec(enc(x))\ndef invariant_under(f, p): return lambda x: f(x) == f(p(x))\ndef invariant_under2(f, p): return lambda x, y: f(x, y) == f(p(x), p(y))", "def encode_decode(enc, dec): return lambda x: x == dec(enc(x))\ndef invariant_under(f, p): return lambda x: f(x) == f(p(x))\ndef invariant_under2(f, p): return lambda x, y: f(x, y) == f(p(x), p(y))\ndef identity(f): return lambda x: f(x) == x\ndef invariant2(m): return lambda x, y: m(x, y) == y\ndef invariant3(m): return lambda x, y, z: m(x, y, z) == z\ndef invariant3_2(m): return lambda x, y, z: m(x, y, z) == y == z\ndef complement(m, f, z): return lambda x: m(x, f(x)) == z\n\ndef transport(law, l, r): return lambda f, g: law(f, lambda x: r(g(l(x))))\ndef transport2(law, l, r): return lambda f, g: law(f, lambda x, y: r(g(l(x), l(y))))", "\ndef transport(law, l, r): return lambda f, g: law(f, lambda x: r(g(l(x))))\ndef transport2(law, l, r): return lambda f, g: law(f, lambda x, y: r(g(l(x), l(y))))\ndef transport3(law, l, r): return lambda f, g: law(f, lambda x, y, z: r(g(l(x), l(y), l(z))))\ndef assume2(law, p): return lambda f: lambda x, y: True if p(x, y) else law(f)(x, y)\ndef assume3(law, p): return lambda f: lambda x, y, z: True if p(x, y, z) else law(f)(x, y, z)\n\ndef lattice(join): return [associative(join), commutative(join), idempotent(join)]\ndef bounded_lattice(join, top, bot): return lattice(join) + [right_unit(join, bot), right_absorbing(join, top)]\ndef xor_props(xor_, bot): return [associative(xor_), commutative(xor_), self_inverse(xor_, bot), right_unit(xor_, bot)]\ndef not_props(not_, bot, top): return [self_inverse_op(not_), equals(not_, top, bot), equals(not_, bot, top)]", "def bounded_lattice(join, top, bot): return lattice(join) + [right_unit(join, bot), right_absorbing(join, top)]\ndef xor_props(xor_, bot): return [associative(xor_), commutative(xor_), self_inverse(xor_, bot), right_unit(xor_, bot)]\ndef not_props(not_, bot, top): return [self_inverse_op(not_), equals(not_, top, bot), equals(not_, bot, top)]\ndef or_and_props(or_, and_): return [distributive(or_, and_), distributive(and_, or_), absorptive(or_, and_), absorptive(and_, or_)]\ndef gf2(add, mul, one, zero):\n    return [\n        right_unit(add, zero),\n        right_unit(mul, one),\n        associative(add), commutative(add),\n        associative(mul), commutative(mul),\n        idempotent(mul),\n        self_inverse(add, zero),\n        distributive(mul, add)\n    ]", "def maj3_inv(maj3, inv):\n    return [\n        commutative3(maj3),\n        assume3(invariant3_2(lambda x, y, z: maj3(z, y, x)), lambda x, y, z: x == y),\n        assume3(invariant3(maj3), lambda x, y, z: x == inv(y)),\n        associative3(maj3),\n        distributive3(maj3, maj3),\n        propagate3(inv, maj3)\n    ]\ndef boolean_algebra(conj, disj, inv, zero, one):\n    return [\n        right_unit(disj, zero),\n        right_unit(conj, one),\n        commutative(conj),\n        commutative(disj),\n        distributive(conj, disj),\n        distributive(disj, conj),\n        associative(conj),\n        associative(disj),\n        complement(disj, inv, one),\n        complement(conj, inv, zero),\n    ]", "def boolean_algebra(conj, disj, inv, zero, one):\n    return [\n        right_unit(disj, zero),\n        right_unit(conj, one),\n        commutative(conj),\n        commutative(disj),\n        distributive(conj, disj),\n        distributive(disj, conj),\n        associative(conj),\n        associative(disj),\n        complement(disj, inv, one),\n        complement(conj, inv, zero),\n    ]", "def permute_props(permute):\n    \u03c0, \u03c4, \u03c3 = 42, 13, 39\n    \u03a0, \u03a4, \u03a3 = lambda x: permute(x, \u03c0), lambda x: permute(x, \u03c4), lambda x: permute(x, \u03c3)\n    \u03a0inv, \u03a4inv, \u03a3inv = lambda x: permute(x, -\u03c0), lambda x: permute(x, -\u03c4), lambda x: permute(x, -\u03c3)\n    return [\n        extensionality(lambda x: \u03a0(\u03a4(x)), lambda x: permute(x, (\u03c4, \u03c0))),\n        extensionality(lambda x: \u03a0(\u03a4(x)), lambda x: permute(x, (0, \u03c4, 0, \u03c0, 0))),\n        extensionality(lambda x: \u03a0(\u03a3(\u03a4(x))), lambda x: permute(x, (\u03c4, \u03c3, \u03c0))),\n        identity(lambda x: permute(x, 0)),\n        identity(lambda x: \u03a0inv(\u03a0(x))),\n        identity(lambda x: \u03a4inv(\u03a4(x))),\n        identity(lambda x: \u03a3(\u03a3inv(x))),\n    ]", "\n\ndef bhv_props(impl: AbstractBHV):\n    \u03a0, \u03a4, \u03a3 = lambda x: impl.permute(x, 42), lambda x: impl.permute(x, 13), lambda x: impl.permute(x, -39)\n    extra = [\n        demorgan(impl.__invert__, impl.__or__, impl.__and__),\n        demorgan(impl.__invert__, impl.__and__, impl.__or__),\n        drop_left(impl.__invert__, impl.__xor__),\n        expand_single_inner(impl.__invert__, impl.__xor__, impl.__or__, impl.__and__),\n        expand_single_outer(impl.__invert__, impl.__xor__, impl.__and__, impl.__or__),\n        distributive(impl.__and__, impl.__xor__),\n        propagate(\u03a0, impl.__invert__),\n        propagate2(\u03a0, impl.__xor__),\n        propagate2(\u03a0, impl.__and__),\n        propagate2(\u03a0, impl.__or__),\n        propagate3(\u03a0, impl.majority3),\n\n        complement(impl.__xor__, impl.__invert__, impl.ONE),\n        invariant_under2(impl.__xor__, impl.__invert__),\n        lambda a, b: a ^ (a & b) == a & ~b,\n        lambda a, b: a ^ (~a & b) == a | b\n    ]\n\n    return (\n        bounded_lattice(impl.__and__, impl.ZERO, impl.ONE) +\n        bounded_lattice(impl.__or__, impl.ONE, impl.ZERO) +\n        xor_props(impl.__xor__, impl.ZERO) +\n        not_props(impl.__invert__, impl.ZERO, impl.ONE) +\n        or_and_props(impl.__or__, impl.__and__) +\n        gf2(impl.__xor__, impl.__and__, impl.ONE, impl.ZERO) +\n        maj3_inv(impl.majority3, impl.__invert__) +\n        boolean_algebra(impl.__and__, impl.__or__, impl.__invert__, impl.ZERO, impl.ONE) +\n        permute_props(impl.permute) +\n        bhv_conv_metrics(\u03a0) +\n        extra)", "\n\ndef bhv_conv_ops(dom: AbstractBHV, codom: AbstractBHV, l, r):\n    return [\n        transport(extensionality, l, r)(dom.__invert__, codom.__invert__),\n        transport2(extensionality2, l, r)(dom.__or__, codom.__or__),\n        transport2(extensionality2, l, r)(dom.__and__, codom.__and__),\n        transport2(extensionality2, l, r)(dom.__xor__, codom.__xor__),\n        transport3(extensionality3, l, r)(dom.select, codom.select),\n    ]", "\n\ndef bhv_conv_metrics(under):\n    return [\n        invariant_under(lambda x: x.active(), under),\n        invariant_under(lambda x: x.active_fraction(), under),\n\n        invariant_under2(lambda x, y: x.hamming(y), under),\n        assume2(invariant_under2(lambda x, y: x.cosine(y), under), lambda x, y: x.active() != 0 and y.active() != 0),\n        assume2(invariant_under2(lambda x, y: x.jaccard(y), under), lambda x, y: x.active() != 0 or y.active() != 0),\n        invariant_under2(lambda x, y: x.std_apart(y), under),\n        invariant_under2(lambda x, y: x.related(y), under),\n        invariant_under2(lambda x, y: x.bit_error_rate(y), under),\n        invariant_under2(lambda x, y: x.mutual_information(y), under),\n    ]", "\n\ndef run_for(impl: AbstractBHV, ts):\n    argts = {}\n    for t in ts:\n        arity = t.__code__.co_argcount\n        argts.setdefault(arity, []).append(t)\n    max_depth = max(argts.keys())\n\n    extrema = [impl.ZERO, impl.ONE]\n    shared = extrema + impl.nrand(3)\n    collections = [shared + impl.nrand(1) for d in range(max_depth + 1)]\n\n    def rec(args, depth):\n        for tn in argts.get(depth, []):\n            assert tn(*args), f\"property {tn.__qualname__} failed on {args} using implementation {impl.__name__}\"\n        if depth <= max_depth:\n            for x in collections[depth]:\n                rec(args + (x,), depth + 1)\n\n    rec((), 0)", "\n\ndef run():\n    # all_implementations = [VanillaBHV, NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV, TorchBoolBHV, TorchPackedBHV, NativePackedBHV]\n    all_implementations = [VanillaBHV, NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV, NativePackedBHV]\n\n    for impl in all_implementations:\n        print(f\"Testing {impl.__name__}...\")\n        t0 = monotonic()\n        run_for(impl, bhv_props(impl))\n        t = monotonic() - t0\n        print(f\"took ({t:.3} s)\")\n\n    print(f\"Testing packing and unpacking NumPyBoolBHV...\")\n    run_for(NumPyBoolBHV, [encode_decode(NumPyBoolBHV.pack64, NumPyPacked64BHV.unpack)])\n    print(f\"Testing packing and unpacking NumPyPacked64BHV...\")\n    run_for(NumPyPacked64BHV, [encode_decode(NumPyPacked64BHV.unpack, NumPyBoolBHV.pack64)])\n    print(\"Testing operators equal between NumPyBoolBHV and NumPyPacked64BHV\")\n    run_for(NumPyBoolBHV, bhv_conv_ops(NumPyBoolBHV, NumPyPacked64BHV, NumPyBoolBHV.pack64, NumPyPacked64BHV.unpack))\n    print(\"Testing metrics invariant under pack64\")\n    run_for(NumPyBoolBHV, bhv_conv_metrics(NumPyBoolBHV.pack64))\n    # run_for(TorchBoolBHV, bhv_conv_metrics(TorchBoolBHV.pack))\n    print(\"Testing large unbalanced majority\")\n    rs = [~v for v in NumPyPacked64BHV.nrand2(1001, 3)]\n    rs_ = [r.unpack() for r in rs]\n    assert NumPyPacked64BHV.majority(rs) == NumPyBoolBHV.majority(rs_).pack64()\n    # rs = [~v for v in TorchPackedBHV.nrand2(1001, 3)]\n    # rs_ = [r.unpack() for r in rs]\n    # assert TorchPackedBHV.majority(rs) == TorchBoolBHV.majority(rs_).pack()\n    print(\"Testing bits and bytes\")\n    for impl in all_implementations:\n        r = impl.rand()\n        rb = r.to_bytes()\n        rbits = list(r.bits())\n        rstr = r.bitstring()\n        for impl_ in all_implementations:\n            assert impl_.from_bytes(rb).to_bytes() == rb, f\"{impl}, {impl_}\"\n            assert list(impl_.from_bitstream(rbits).bits()) == rbits, f\"{impl}, {impl_}\"\n            assert impl_.from_bytes(rb).bitstring() == rstr, f\"{impl}, {impl_}\"\n            assert impl_.from_bitstring(rstr).bitstring() == rstr, f\"{impl}, {impl_}\"\n\n    print(\"Testing word-level roll equivalence\")\n    rs_np = NumPyPacked64BHV.nrand(10)\n    rs_native = [NativePackedBHV.from_bytes(r.to_bytes()) for r in rs_np]\n\n    word_rot_pos_np = [r.roll_words(12) for r in rs_np]\n    word_rot_pos_native = [r.roll_words(12) for r in rs_native]\n    assert [r == NumPyPacked64BHV.from_bytes(r_.to_bytes()) for r, r_ in zip(word_rot_pos_np, word_rot_pos_native)]\n    word_rot_neg_np = [r.roll_words(-12) for r in rs_np]\n    word_rot_neg_native = [r.roll_words(-12) for r in rs_native]\n    assert [r == NumPyPacked64BHV.from_bytes(r_.to_bytes()) for r, r_ in zip(word_rot_neg_np, word_rot_neg_native)]\n    word_bit_rot_pos_np = [r.roll_word_bits(12) for r in rs_np]\n    word_bit_rot_pos_native = [r.roll_word_bits(12) for r in rs_native]\n    assert [r == NumPyPacked64BHV.from_bytes(r_.to_bytes()) for r, r_ in zip(word_bit_rot_pos_np, word_bit_rot_pos_native)]\n    word_bit_rot_neg_np = [r.roll_word_bits(-12) for r in rs_np]\n    word_bit_rot_neg_native = [r.roll_word_bits(-12) for r in rs_native]\n    assert [r == NumPyPacked64BHV.from_bytes(r_.to_bytes()) for r, r_ in zip(word_bit_rot_neg_np, word_bit_rot_neg_native)]\n\n\n    print(\"Testing NumPyPacked64BHV majority equivalence\")\n    run_for(NumPyPacked64BHV, [\n        extensionality3(NumPyPacked64BHV._majority3, lambda x, y, z: NumPyPacked64BHV._majority_via_unpacked([x, y, z])),\n        extensionality5(NumPyPacked64BHV._majority5, lambda x, y, z, u, v: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v])),\n        extensionality5(NumPyPacked64BHV._majority5_via_3, NumPyPacked64BHV._majority5),\n        # this is slow, obviously\n        # extensionality7(NumPyPacked64BHV._majority7_via_3, lambda x, y, z, u, v, w, r: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v, w, r])),\n        # extensionality7(NumPyPacked64BHV._majority7_via_ite, lambda x, y, z, u, v, w, r: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v, w, r])),\n        # extensionality7(NumPyPacked64BHV._majority7_via_3, lambda x, y, z, u, v, w, r: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v, w, r])),\n        # extensionality9(NumPyPacked64BHV._majority9_via_3, lambda x, y, z, u, v, w, r, i, j: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v, w, r, i, j])),\n    ])\n\n    t0 = monotonic()\n    for s in range(3, 55, 2):\n        rs = NumPyPacked64BHV.nrand(s)\n        assert NumPyPacked64BHV.majority(rs) == NumPyPacked64BHV._majority_via_unpacked(rs), f\"mismatch for size {s}\"\n    t = monotonic() - t0\n    print(f\"took ({t:.3} s)\")", "\n\nif __name__ == '__main__':\n    run()\n"]}
{"filename": "tests/reconstruct_program.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV as BHV, List, Var\nfrom bhv.vanilla import VanillaBHV\n\n\na, b, c, d = Var(\"a\"), Var(\"b\"), Var(\"c\"), Var(\"d\")\n\nabc = BHV.majority([a, b, c]).named(\"test\")\n\na1 = a.flip_frac_on(.1)\na0 = a.flip_frac_off(.1)", "a1 = a.flip_frac_on(.1)\na0 = a.flip_frac_off(.1)\n\ncq = c.select(a0, a1).named(\"mix\")\n\nb_d = b ^ d\nabc_d = abc ^ d\n\ncode = List([cq, b_d, abc_d]).named(\"O\").graphviz()#.show_program(name=\"run\", impl=\"VanillaBHV.\")\n# .simplify(expand_select_and_or=True)", "code = List([cq, b_d, abc_d]).named(\"O\").graphviz()#.show_program(name=\"run\", impl=\"VanillaBHV.\")\n# .simplify(expand_select_and_or=True)\n# print(code)\n\n# assert code == \"\"\"\n# def run(a, b, c, d):\n#     _0 = VanillaBHV.majority([a, b, c])\n#     _1 = _0 ^ d\n#     _2 = b ^ d\n#     _3 = VanillaBHV.random(0.2)", "#     _2 = b ^ d\n#     _3 = VanillaBHV.random(0.2)\n#     _4 = a ^ _3\n#     _5 = a & _4\n#     _6 = ~c\n#     _7 = _6 & _5\n#     _8 = VanillaBHV.random(0.2)\n#     _9 = a ^ _3\n#     _10 = a | _4\n#     _11 = c & _10", "#     _10 = a | _4\n#     _11 = c & _10\n#     _12 = _11 | _7\n#     return [_12, _2, _1]\n# \"\"\".lstrip()\n"]}
{"filename": "tests/marshalling.py", "chunked_list": ["import io\nfrom time import monotonic_ns\n\nfrom bhv.abstract import AbstractBHV, DIMENSION\nfrom bhv.native import NativePackedBHV\nfrom bhv.np import NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV\n# from bhv.pytorch import TorchBoolBHV, TorchPackedBHV\nfrom bhv.vanilla import VanillaBHV\n\nfrom bhv.visualization import Image", "\nfrom bhv.visualization import Image\n\nall_implementations = [VanillaBHV, NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV, NativePackedBHV]\n\nN = 5\n\n\nfor impl in all_implementations:\n    rs = impl.nrand(N)\n\n    print(impl.__name__)\n    print(\" binary\")\n    with io.BytesIO() as f:\n        t0 = monotonic_ns()\n        Image(rs).pbm(f, binary=True)\n        print(\"  serializing\", monotonic_ns() - t0)\n\n        contents = f.getvalue()\n\n    with io.BytesIO(contents) as f:\n        t0 = monotonic_ns()\n        rs_ = Image.load_pbm(f, impl, binary=True).hvs\n        print(\"  deserializing\", monotonic_ns() - t0)\n\n    assert len(rs) == len(rs_)\n    for r, r_ in zip(rs, rs_):\n        assert r == r_\n\n    print(\" string\")\n    with io.StringIO() as f:\n        t0 = monotonic_ns()\n        Image(rs).pbm(f, binary=False)\n        print(\"  serializing\", monotonic_ns() - t0)\n\n        string = f.getvalue()\n\n    with io.StringIO(string) as f:\n        t0 = monotonic_ns()\n        rs_ = Image.load_pbm(f, impl, binary=False).hvs\n        print(\"  deserializing\", monotonic_ns() - t0)\n\n    assert len(rs) == len(rs_)\n    for r, r_ in zip(rs, rs_):\n        assert r == r_", "for impl in all_implementations:\n    rs = impl.nrand(N)\n\n    print(impl.__name__)\n    print(\" binary\")\n    with io.BytesIO() as f:\n        t0 = monotonic_ns()\n        Image(rs).pbm(f, binary=True)\n        print(\"  serializing\", monotonic_ns() - t0)\n\n        contents = f.getvalue()\n\n    with io.BytesIO(contents) as f:\n        t0 = monotonic_ns()\n        rs_ = Image.load_pbm(f, impl, binary=True).hvs\n        print(\"  deserializing\", monotonic_ns() - t0)\n\n    assert len(rs) == len(rs_)\n    for r, r_ in zip(rs, rs_):\n        assert r == r_\n\n    print(\" string\")\n    with io.StringIO() as f:\n        t0 = monotonic_ns()\n        Image(rs).pbm(f, binary=False)\n        print(\"  serializing\", monotonic_ns() - t0)\n\n        string = f.getvalue()\n\n    with io.StringIO(string) as f:\n        t0 = monotonic_ns()\n        rs_ = Image.load_pbm(f, impl, binary=False).hvs\n        print(\"  deserializing\", monotonic_ns() - t0)\n\n    assert len(rs) == len(rs_)\n    for r, r_ in zip(rs, rs_):\n        assert r == r_", "\n"]}
{"filename": "tests/inspect_random.py", "chunked_list": ["from statistics import fmean, stdev\n\nfrom scipy.stats import kstest, shapiro, anderson, probplot\nimport matplotlib\nmatplotlib.use(\"cairo\")\nimport matplotlib.pyplot as plt\n\nfrom bhv.native import NativePackedBHV as BHV, DIMENSION\n\n", "\n\nN = 100_000\n\n\ndef test_unbiased_variance():\n    rs = BHV.nrand(N)\n    afs = [int(r.active()) for r in rs]\n\n    af = fmean(afs)\n    sd = stdev(afs)\n    mn = min(afs)\n    mx = max(afs)\n    print(af, sd, mn, mx)\n    print(shapiro(afs), kstest(afs, 'norm'), anderson(afs))\n    probplot(afs, dist=\"norm\", plot=plt)\n    with open(f\"rand_{BHV.__name__}.svg\", 'wb') as f:\n        plt.savefig(f, format=\"svg\")\n\n    with open(f\"rand_{BHV.__name__}.bin\", \"wb\") as f:\n        for r in rs:\n            f.write(r.to_bytes())", "\ndef test_unrelated():\n    rs = BHV.nrand(int(N**.5))\n\n    afs = [int(r.hamming(r_)) for r in rs for r_ in rs if r is not r_]\n\n    af = fmean(afs)\n    sd = stdev(afs)\n    mn = min(afs)\n    mx = max(afs)\n    print(af, sd, mn, mx)\n    print(shapiro(afs), kstest(afs, 'norm'), anderson(afs))\n    probplot(afs, dist=\"norm\", plot=plt)\n    with open(f\"hamming_{BHV.__name__}.svg\", 'wb') as f:\n        plt.savefig(f, format=\"svg\")", "\n\ntest_unbiased_variance()\n"]}
{"filename": "tests/sym.py", "chunked_list": ["from bhv.abstract import AbstractBHV\nfrom bhv.symbolic import Var, SymbolicBHV, Rand\n\n\ndef large_majority_plot():\n    print(\"digraph {\")\n    all_vars = [Var.shortname(i) for i in range(8, -1, -1)]\n    AbstractBHV.majority(all_vars).graphviz(structural=False, compact_select=True)\n    print(\"}\")\n", "\n\ndef active_fraction():\n    rfs = [1/2, 1/4, 3/4, 5/8, 3/8, 9/16, 11/16, 31/32, 61/128, 123/256]\n\n    for rf in rfs:\n        res = SymbolicBHV.synth_af(rf)\n        print(res.show())\n        print(*[r.nodename() for r in res.preorder() if not isinstance(r, Rand)])\n        assert rf == res.expected_active_fraction()", "\n\ndef mock(T, **fields):\n    return type(f\"Mocked{T.__name__}\", (T,), fields)\n\n\nif __name__ == '__main__':\n    print(SymbolicBHV.random(.25).select((Var(\"X\") & ~Var(\"Y\")), (Var(\"X\") | ~Var(\"Y\")))\n          .show(impl=\"SymbolicBHV.\", symbolic_var=True))\n\n    print(mock(SymbolicBHV, majority=vars(AbstractBHV)['majority']).majority([Var(\"X\"), Var(\"Y\")])\n          .show(random_id=True))", ""]}
{"filename": "tests/blocklsynth.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV as BHV, Var, List\nfrom bhv.slice import Slice\nfrom bhv.shared import bin_bitmask, nbs\nfrom string import ascii_lowercase\nfrom random import shuffle, sample, random, randrange\nfrom statistics import pstdev, fmean\n\n\nI = 8\nO = 16", "I = 8\nO = 16\nnames = [Var(x) for x in ascii_lowercase[:I]]\nfs = []\n\nfor j in range(O):\n    target = [i % 2 == 0 for i in range(2**I)]\n    shuffle(target)\n\n    f = BHV.synth(names, target).simplify()\n    assert target == f.truth_assignments(names)\n    fs.append(f)", "\n# print([f.expected_active_fraction(vars={x: .5 for x in ascii_lowercase[:I]}) for f in fs])\n# print(List(\"O\", fs).show())\n# List(\"O\", fs).graphviz(structural=True)\n\n\ninitial = names\nlayers = [initial]\n# sizes = [20, 20, 20, 20, O]\nsizes = [1]*30 + [O]", "# sizes = [20, 20, 20, 20, O]\nsizes = [1]*30 + [O]\n\n\n# for size in sizes:\n#     layer = []\n#     for elem in range(size):\n#         r = random()\n#         i, j, k = sample(layers[-1], k=3)\n#", "#         i, j, k = sample(layers[-1], k=3)\n#\n#         layer.append(BHV.majority3(\n#                 i if random() < .666 else ~i,\n#                 j if random() < .666 else ~j,\n#                 k if random() < .666 else ~k))\n#\n#     layers.append(layer)\n\n# for size in sizes:", "\n# for size in sizes:\n#     layer = []\n#     for elem in range(size):\n#         r = random()\n#         if r < .75:\n#             i, j = sample(layers[-1], k=2)\n#             layer.append(i ^ j)\n#         else:\n#             i, = sample(layers[-1], k=1)", "#         else:\n#             i, = sample(layers[-1], k=1)\n#             layer.append(~i)\n#     layers.append(layer)\n\n# for size in sizes:\n#     layer = []\n#     for elem in range(size):\n#         i, j, k = sample(layers[-1], k=3)\n#         layer.append(BHV.select(i, ~j, k))", "#         i, j, k = sample(layers[-1], k=3)\n#         layer.append(BHV.select(i, ~j, k))\n#     layers.append(layer)\n\nprint([f.expected_active_fraction(vars={x: .5 for x in ascii_lowercase[:I]}) for f in layers[-1]])\nprint(List(layers[-1]).size())\n# List(\"O\", layers[-1]).graphviz(compact_select=False)\n\nfor fk in [fs, layers[-1]]:\n    truth_table = [fi.truth_assignments(names) for fi in fk]\n\n    truth_tables_sims = [[sum(a ^ a_ for a, a_ in zip(ta, ta_)) for ta_ in truth_table] for ta in truth_table]\n    mean_stdev = [(abs(.5 - fmean(diffs)/2**I), pstdev(diffs)/2**I) for diffs in truth_tables_sims]\n    print(max(x for x, _ in mean_stdev), max(y for _, y in mean_stdev))\n\n    truth_tables_sens = [fmean(sum(ta[i] ^ ta[j] for j in nbs(i, I))/I for i in range(2**I)) for ta in truth_table]\n    print(abs(.5 - fmean(truth_tables_sens)), pstdev(truth_tables_sens))", "for fk in [fs, layers[-1]]:\n    truth_table = [fi.truth_assignments(names) for fi in fk]\n\n    truth_tables_sims = [[sum(a ^ a_ for a, a_ in zip(ta, ta_)) for ta_ in truth_table] for ta in truth_table]\n    mean_stdev = [(abs(.5 - fmean(diffs)/2**I), pstdev(diffs)/2**I) for diffs in truth_tables_sims]\n    print(max(x for x, _ in mean_stdev), max(y for _, y in mean_stdev))\n\n    truth_tables_sens = [fmean(sum(ta[i] ^ ta[j] for j in nbs(i, I))/I for i in range(2**I)) for ta in truth_table]\n    print(abs(.5 - fmean(truth_tables_sens)), pstdev(truth_tables_sens))\n", "\n\n\n    # for assignments in truth_table:\n    #     print(bin_bitmask(assignments))\n\n\"\"\"\n8, 16\n\nref", "\nref\n0.04296875 0.125760625250041\n0.0008544921875 0.019445229885344226\n\nmaj3 not [20, 20, 20, 20, O]\n0.12060546875 0.2121091726734187\n0.162841796875 0.03379297840161043\n\nmaj3 not [200, 200, 200, 200, O]", "\nmaj3 not [200, 200, 200, 200, O]\n0.080078125 0.15209000803614153\n0.120849609375 0.030429560571682487\n\nxor not [20, 20, 20, 20, O]\n0.0625 0.16535945694153692\n0.0078125 0.12077831901359615\n\nxor not [200, 200, 200, 200, O]", "\nxor not [200, 200, 200, 200, O]\n0.03125 0.12103072956898178\n0.0 0.1875\n\nite not [200, 200, 200, 200, O]\n0.05029296875 0.13149097664047601\n0.0791015625 0.025633603024231812\n\nite not [20, 20, 20, 20, O]", "\nite not [20, 20, 20, 20, O]\n0.1044921875 0.1579708702179055\n0.124267578125 0.030601447254438183\n\nmaj3-9 1/3not [20, 20, 20, 20, O]\n0.07861328125 0.18325514715650032\n0.091552734375 0.03555998508028247\n\"\"\"", "\"\"\""]}
{"filename": "tests/symbolic.py", "chunked_list": ["import unittest\n\nfrom bhv.symbolic import Var, SymbolicBHV\nfrom bhv.shared import stable_hashcode\n\n\nclass TestReduction(unittest.TestCase):\n    def test_optimal_sharing(self):\n        x = Var(\"x\")\n        y = Var(\"y\")\n\n        se = (x ^ y)\n\n        e = se | ~se\n        e_ = (x ^ y) | ~(x ^ y)\n\n        self.assertEqual(stable_hashcode(e), stable_hashcode(se | ~se))\n        self.assertNotEqual(stable_hashcode(e), e_)\n        self.assertEqual(stable_hashcode(e), stable_hashcode(e_.optimal_sharing()))\n\n    def test_reduce(self):\n        x = Var(\"x\")\n        y = Var(\"y\")\n\n        e = ~(~((x & y) ^ (x & (y & ~y))))\n\n        self.assertEqual(e.simplify(), (x & y))", "\n\nif __name__ == '__main__':\n    unittest.main()\n"]}
{"filename": "benchmarks/lookup.py", "chunked_list": ["# Similarity search\n# from bhv.np import NumPyPacked64BHV as BHV\nfrom bhv.native import NativePackedBHV as BHV\nfrom bhv.lookup import StoreList, StoreRejectList, StoreChunks\n\nfrom time import monotonic\nfrom random import shuffle, random, randrange, sample\nfrom statistics import pstdev, fmean\n\n", "\n\nrepeat_pipeline = 1\nrepeat_lookup = 10\nthresholds = [0, 3, 6]\ndeviations = [0, 1, 2, 4]\nsizes = [20, 1000]\n\n# e.g.\n# hvs=[10, 20, 30, 50, 100]", "# e.g.\n# hvs=[10, 20, 30, 50, 100]\n# v=20 + 5\n# threshold=10\n# returns 20, 30\n\nindex_times = {s: [] for s in sizes}\nlookup_times = {s: {t: [] for t in thresholds} for s in sizes}\ndistances = {s: {t: {d: [] for d in deviations} for t in thresholds} for s in sizes}\n\nfor _ in range(repeat_pipeline):\n    for size in sizes:\n        rs = BHV.nrand(size)\n        ps = {deviation: [r.flip_frac(BHV.std_to_frac(deviation))\n                          for r in sample(rs, repeat_lookup)]\n              for deviation in deviations}\n\n        t_index = monotonic()\n        index = StoreChunks.auto_associative(rs)\n        index_times[size].append(monotonic() - t_index)\n\n        for threshold in thresholds:\n            t_lookup = monotonic()\n            for deviation in deviations:\n                for p in ps[deviation]:\n                    ms = list(index.related(p, threshold))\n                    distances[size][threshold][deviation].append([index.hvs[m].std_apart(p) for m in ms])\n\n            lookup_times[size][threshold].append(monotonic() - t_lookup)", "distances = {s: {t: {d: [] for d in deviations} for t in thresholds} for s in sizes}\n\nfor _ in range(repeat_pipeline):\n    for size in sizes:\n        rs = BHV.nrand(size)\n        ps = {deviation: [r.flip_frac(BHV.std_to_frac(deviation))\n                          for r in sample(rs, repeat_lookup)]\n              for deviation in deviations}\n\n        t_index = monotonic()\n        index = StoreChunks.auto_associative(rs)\n        index_times[size].append(monotonic() - t_index)\n\n        for threshold in thresholds:\n            t_lookup = monotonic()\n            for deviation in deviations:\n                for p in ps[deviation]:\n                    ms = list(index.related(p, threshold))\n                    distances[size][threshold][deviation].append([index.hvs[m].std_apart(p) for m in ms])\n\n            lookup_times[size][threshold].append(monotonic() - t_lookup)", "\n\nfor size in sizes:\n    print(\"size\", size)\n    for threshold in thresholds:\n        print(\" threshold\", threshold)\n        print(\" lookup\", fmean(lookup_times[size][threshold]), \"+-\", pstdev(lookup_times[size][threshold]))\n        for deviation in deviations:\n            print(\"  deviation\", deviation)\n            print(\"  results\", distances[size][threshold][deviation])", ""]}
{"filename": "benchmarks/exact_synthesis.py", "chunked_list": ["# execution of generated N-input M-output boolean functions\n# currently the synthesis and reduction rules make the program consist of\n# XOR, NOT, AND, OR\n# NOTE: takes about a minute and doesn't show intermediate results\nfrom bhv.np import NumPyPacked64BHV as BHV\n# from bhv.native import NativePackedBHV as BHV\nfrom bhv.symbolic import SymbolicBHV, Var, List\n\nfrom time import monotonic\nfrom string import ascii_lowercase", "from time import monotonic\nfrom string import ascii_lowercase\nfrom random import shuffle\nfrom statistics import pstdev, fmean\n\n\nrepeat_pipeline = 3\nrepeat_executions = 10\n\nI = 8", "\nI = 8\nO = 16\n\nnames = [Var(x) for x in ascii_lowercase[:I]]\n\nsynthesis_times = []\noptimization_times = []\nexecution_times = []\n\nfor _ in range(repeat_pipeline):\n    t_synth = monotonic()\n    fs = []\n    for j in range(O):\n        target = [i % 2 == 0 for i in range(2**I)]\n        shuffle(target)\n        f = SymbolicBHV.synth(names, target)\n        assert target == f.truth_assignments(names)\n        fs.append(f)\n\n    t_opt = monotonic()\n    synthesis_times.append(t_opt - t_synth)\n    cf = List(fs)\n    print(cf.size())\n    # could be commented out for more load on execution\n    cf = cf.simplify(expand_select_and_or=True)\n    print(cf.size())\n    # could be commented out for more load on execution\n    cf = cf.optimal_sharing()\n    print(cf.size())\n\n    t_exec = monotonic()\n    optimization_times.append(t_exec - t_opt)\n    for _ in range(repeat_executions):\n        # the random vector gen could be separated out from the timing\n        inputs = {x: BHV.rand() for x in ascii_lowercase[:I]}\n        result = cf.execute(vars=inputs, bhv=BHV)\n        # the checking below should be separated out from the timing\n        # since it boils down to `active`\n        for v in result:\n            assert v.zscore() <= 4\n            for w in result:\n                assert v is w or not v.related(w, 9)\n\n    execution_times.append(monotonic() - t_exec)", "execution_times = []\n\nfor _ in range(repeat_pipeline):\n    t_synth = monotonic()\n    fs = []\n    for j in range(O):\n        target = [i % 2 == 0 for i in range(2**I)]\n        shuffle(target)\n        f = SymbolicBHV.synth(names, target)\n        assert target == f.truth_assignments(names)\n        fs.append(f)\n\n    t_opt = monotonic()\n    synthesis_times.append(t_opt - t_synth)\n    cf = List(fs)\n    print(cf.size())\n    # could be commented out for more load on execution\n    cf = cf.simplify(expand_select_and_or=True)\n    print(cf.size())\n    # could be commented out for more load on execution\n    cf = cf.optimal_sharing()\n    print(cf.size())\n\n    t_exec = monotonic()\n    optimization_times.append(t_exec - t_opt)\n    for _ in range(repeat_executions):\n        # the random vector gen could be separated out from the timing\n        inputs = {x: BHV.rand() for x in ascii_lowercase[:I]}\n        result = cf.execute(vars=inputs, bhv=BHV)\n        # the checking below should be separated out from the timing\n        # since it boils down to `active`\n        for v in result:\n            assert v.zscore() <= 4\n            for w in result:\n                assert v is w or not v.related(w, 9)\n\n    execution_times.append(monotonic() - t_exec)", "\nprint(\"synth:\", fmean(synthesis_times), \"+-\", pstdev(synthesis_times))\nprint(\"optim:\", fmean(optimization_times), \"+-\", pstdev(optimization_times))\n# only this actual includes hypervector computations\nprint(\"execu:\", fmean(execution_times), \"+-\", pstdev(execution_times))\n"]}
{"filename": "benchmarks/random_network.py", "chunked_list": ["# N-input M-output computational vat implementations using different primitives\n# NOTE: can fail due to tight bounds on the probabilistic properties, run multiple times\n# from bhv.np import NumPyPacked64BHV as BHV\nfrom bhv.native import NativePackedBHV as BHV\nfrom bhv.symbolic import SymbolicBHV, Var, List\n\nfrom time import monotonic\nfrom string import ascii_lowercase\nfrom random import shuffle, random, sample\nfrom statistics import pstdev, fmean", "from random import shuffle, random, sample\nfrom statistics import pstdev, fmean\n\n\nrepeat_pipeline = 3\nrepeat_executions = 10\n\nI = 50\nO = 50\nsizes = [200]*20 + [O]", "O = 50\nsizes = [200]*20 + [O]\nvat_type: '\"MAJ3\" | \"XOR NOT\", \"SELECT EQ\"' = \"XOR NOT\"\n\nnames = [Var(x) for x in ascii_lowercase[:I]]\n\nconstruct_times = []\nexecution_times = []\n\nfor _ in range(repeat_pipeline):\n    initial = names\n    layers = [initial]\n\n    t_constr = monotonic()\n    for size in sizes:\n        layer = []\n        for elem in range(size):\n            if vat_type == \"MAJ3\":\n                i, j, k = sample(layers[-1], k=3)\n                layer.append(SymbolicBHV.majority3(\n                        i if random() < 2/3 else ~i,\n                        j if random() < 2/3 else ~j,\n                        k if random() < 2/3 else ~k))\n            elif vat_type == \"XOR NOT\":\n                r = random()\n                if r < .8:\n                    i, j = sample(layers[-1], k=2)\n                    layer.append(i ^ j)\n                else:\n                    i, = sample(layers[-1], k=1)\n                    layer.append(~i)\n            elif vat_type == \"SELECT EQ\":\n                r = random()\n                if r < 1/3:\n                    i, j, k = sample(layers[-1], k=3)\n                    layer.append(SymbolicBHV.select(i, j, k))\n                else:\n                    i, j = sample(layers[-1], k=2)\n                    layer.append(~(i ^ j))\n        layers.append(layer)\n\n    cf = List(layers[-1])\n\n    t_exec = monotonic()\n    construct_times.append(t_exec - t_constr)\n    for _ in range(repeat_executions):\n        # the random vector gen could be separated out from the timing\n        inputs = {x: BHV.rand() for x in ascii_lowercase[:I]}\n        result = cf.execute(vars=inputs, bhv=BHV)\n        # the checking below should be separated out from the timing\n        # since it boils down to `active`\n        for v in result:\n            assert v.zscore() <= 4\n            for w in result:\n                assert v is w or not v.related(w, 9)\n\n    execution_times.append(monotonic() - t_exec)", "\nfor _ in range(repeat_pipeline):\n    initial = names\n    layers = [initial]\n\n    t_constr = monotonic()\n    for size in sizes:\n        layer = []\n        for elem in range(size):\n            if vat_type == \"MAJ3\":\n                i, j, k = sample(layers[-1], k=3)\n                layer.append(SymbolicBHV.majority3(\n                        i if random() < 2/3 else ~i,\n                        j if random() < 2/3 else ~j,\n                        k if random() < 2/3 else ~k))\n            elif vat_type == \"XOR NOT\":\n                r = random()\n                if r < .8:\n                    i, j = sample(layers[-1], k=2)\n                    layer.append(i ^ j)\n                else:\n                    i, = sample(layers[-1], k=1)\n                    layer.append(~i)\n            elif vat_type == \"SELECT EQ\":\n                r = random()\n                if r < 1/3:\n                    i, j, k = sample(layers[-1], k=3)\n                    layer.append(SymbolicBHV.select(i, j, k))\n                else:\n                    i, j = sample(layers[-1], k=2)\n                    layer.append(~(i ^ j))\n        layers.append(layer)\n\n    cf = List(layers[-1])\n\n    t_exec = monotonic()\n    construct_times.append(t_exec - t_constr)\n    for _ in range(repeat_executions):\n        # the random vector gen could be separated out from the timing\n        inputs = {x: BHV.rand() for x in ascii_lowercase[:I]}\n        result = cf.execute(vars=inputs, bhv=BHV)\n        # the checking below should be separated out from the timing\n        # since it boils down to `active`\n        for v in result:\n            assert v.zscore() <= 4\n            for w in result:\n                assert v is w or not v.related(w, 9)\n\n    execution_times.append(monotonic() - t_exec)", "\nprint(\"construct:\", fmean(construct_times), \"+-\", pstdev(construct_times))\n# this actual includes hypervector computations\nprint(\"execution:\", fmean(execution_times), \"+-\", pstdev(execution_times))\n"]}
{"filename": "benchmarks/layerwise_random_execution.py", "chunked_list": ["# N-input M-output stack of random computation (from different families)\n# NOTE: can fail due to tight bounds on the probabilistic properties, run multiple times\n# from bhv.np import NumPyPacked64BHV as BHV\nfrom bhv.native import NativePackedBHV as BHV\n\nfrom time import monotonic\nfrom random import shuffle, random, randrange, sample\nfrom statistics import pstdev, fmean\nfrom multiprocessing import Pool\n", "from multiprocessing import Pool\n\n\nrepeat_pipeline = 3\n\nI = 500\nO = 500\nsizes = [10000]*100 + [O]\nvat_type: '\"MAJ3\" | \"XOR NOT\" | \"SELECT EQ\" | \"TERNARY\"' = \"MAJ3\"\n", "vat_type: '\"MAJ3\" | \"XOR NOT\" | \"SELECT EQ\" | \"TERNARY\"' = \"MAJ3\"\n\n\nif vat_type == \"MAJ3\":\n    def execute(_):\n        i, j, k = sample(values[-1], k=3)\n        return BHV.majority([\n                i if random() < 2/3 else ~i,\n                j if random() < 2/3 else ~j,\n                k if random() < 2/3 else ~k])\nelif vat_type == \"XOR NOT\":\n    def execute(_):\n        r = random()\n        if r < .8:\n            i, j = sample(values[-1], k=2)\n            return i ^ j\n        else:\n            i, = sample(values[-1], k=1)\n            return ~i\nelif vat_type == \"SELECT EQ\":\n    def execute(_):\n        r = random()\n        if r < 1/3:\n            i, j, k = sample(values[-1], k=3)\n            return BHV.select(i, j, k)\n        else:\n            i, j = sample(values[-1], k=2)\n            return ~(i ^ j)\nelif vat_type == \"TERNARY\":\n    OPS = [15, 23, 27, 29, 30, 39, 43, 45, 46, 51, 53, 54, 57, 58, 60, 71, 75, 77, 78, 83, 85, 86, 89, 90, 92, 99, 101, 102, 105, 106, 108, 113, 114, 116, 120, 135, 139, 141, 142, 147, 149, 150, 153, 154, 156, 163, 165, 166, 169, 170, 172, 177, 178, 180, 184, 195, 197, 198, 201, 202, 204, 209, 210, 212, 216, 225, 226, 228, 232, 240]\n    def execute(_):\n        op, = sample(OPS, k=1)\n        i, j, k = sample(values[-1], k=3)\n        return BHV.ternary(i, j, k, op)", "\nexecution_times = []\n\nfor _ in range(repeat_pipeline):\n    t_exec = monotonic()\n\n    value = [BHV.rand() for _ in range(I)]\n    values = [value]\n\n    with Pool() as p:\n        for size in sizes:\n            values.append(p.map(execute, range(size)))\n    # for size in sizes:\n    #     values.append(list(map(execute, range(size))))\n\n    result = values[-1]\n\n    for v in result:\n        assert v.zscore() <= 4\n        for w in result:\n            assert v is w or not v.related(w, 9)\n\n    execution_times.append(monotonic() - t_exec)", "\nprint(\"execution:\", fmean(execution_times), \"+-\", pstdev(execution_times))\n"]}
{"filename": "benchmarks/majority.py", "chunked_list": ["# Majority of a various number of inputs\nfrom bhv import DIMENSION, AbstractBHV\n# from bhv.np import NumPyPacked64BHV as BHV\n# from bhv.np import NumPyBoolBHV as BHV\nfrom bhv.native import CNativePackedBHV as BHV\n\nfrom time import monotonic\nfrom statistics import pstdev, fmean\n\n", "\n\nrepeat_pipeline = 5\n\nsizes = list(range(1, 2000, 2))\nsizes += list(range(2001, 20000, 20))\nsizes += list(range(20001, 200000, 200))\nsizes += list(range(200001, 1000001, 2000))\n\n", "\n\ndistances = {s: [] for s in sizes}\nexecution_times = {s: [] for s in sizes}\n\nrs = [BHV.rand() for _ in range(1000001)]\n\nfor i in range(repeat_pipeline):\n    print(f\"repetition {i + 1}/{repeat_pipeline}\")\n    for size in sizes:\n        s = rs[:size]\n\n        t_exec = monotonic()\n\n        maj = BHV.majority(s)\n\n        execution_times[size].append(monotonic() - t_exec)\n\n        distances[size].append(fmean(AbstractBHV.frac_to_std(r.hamming(maj)/DIMENSION, invert=True) for r in s))\n\n        del s", "\n\nwith open(\"results/majority_2000_native_simd.csv\", 'w') as f:\n    f.write(\"size,distance,time\\n\")\n    for size in sizes:\n        print(size)\n        print(\"mean distance:\", fmean(distances[size]), \"+-\", pstdev(distances[size]))\n        print(\"timing:\", fmean(execution_times[size]), \"+-\", pstdev(execution_times[size]))\n        f.write(f\"{size},{fmean(distances[size])},{fmean(execution_times[size])}\\n\")\n", ""]}
{"filename": "examples/ca_rules.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV, Var\nfrom bhv.np import NumPyBoolBHV as BHV, DIMENSION\nfrom bhv.visualization import Image\nimport numpy as np\n\n\ndef make_rule(r: int):\n    mask = [b == '1' for b in bin(r)[2:].rjust(8, \"0\")]\n    formula = SymbolicBHV.synth([Var(\"left\"), Var(\"center\"), Var(\"right\")], mask)\n    formula = formula.simplify()\n    print(\"formula:\", formula.show())\n    return lambda x: formula.execute(vars={\"left\": x.roll_bits(1), \"center\": x, \"right\": x.roll_bits(-1)})", "\n\nRULE = 90\nITERATIONS = 10000\n\nrule = make_rule(RULE)\n\n# completely random\n# last_v = BHV.rand()\n", "# last_v = BHV.rand()\n\n# low fraction of on bits\nlast_v = BHV.random(.03)\n\n# single on bit\n# initial = np.zeros(DIMENSION, dtype=np.bool_)\n# initial[64] = np.bool_(1)\n# last_v = BHV(initial)\n", "# last_v = BHV(initial)\n\nvs = [last_v]\n\nfor i in range(ITERATIONS):\n    vs.append(rule(vs[-1]))\n\nwith open(f\"rule{RULE}.pbm\", 'wb') as f:\n    Image(vs).pbm(f, binary=True)\n", ""]}
{"filename": "examples/reasoning_by_analogy_linear.py", "chunked_list": ["# The linear variant of https://colab.research.google.com/drive/10XSpooxDAeYVMivF3W2-N0W5yEIUfdZl#scrollTo=dQ7044izy3_y\n# This is of theoretical interest\nfrom bhv.vanilla import VanillaBHV as BHV\nfrom bhv.variants import LinearBHVModel\n\n\n# Operation on linear are checked\nlinear = LinearBHVModel(BHV)\n\n# declare up front how many spaces and entropy we're going to use", "\n# declare up front how many spaces and entropy we're going to use\n# ONE and ZERO are singletons, so using permute(0) to copy them for linearity checking\nsymbol_ones = [BHV.ONE.permute(0) for _ in range(9)]\nsymbol_zeros = [BHV.ZERO.permute(0) for _ in range(9)]\ncopy_ones = [BHV.ONE.permute(0) for _ in range(6)]\ncopy_zeros = [BHV.ZERO.permute(0) for _ in range(6)]\n\n\n((name, neg_name), (capital_city, neg_capital_city), (money, neg_money),", "\n((name, neg_name), (capital_city, neg_capital_city), (money, neg_money),\n (united_states, _neg), (washington_dc, _neg), (dollar, neg_dollar),\n (mexico, _neg), (mexico_city, neg_mexico_city), (peso, _neg)) = [linear.spawn(one, zero)\n    for one, zero in zip(symbol_ones, symbol_zeros)]\n\n(name_is_united_states, _and, _and) = linear.xor(name, united_states)\n(capital_city_is_washington_dc, _and, _and) = linear.xor(capital_city, washington_dc)\n(money_is_dollar, _and, _and) = linear.xor(money, dollar)\n", "(money_is_dollar, _and, _and) = linear.xor(money, dollar)\n\n(_ands, USA, _ors) = linear.thresholds3(name_is_united_states, capital_city_is_washington_dc, money_is_dollar)\n\n# note to make more than on record, we need to re-use the field names\n# we invert the negated version we got during spawning the random vectors to obtain copies\n((name_copy, _id, _id),\n (capital_city_copy, _id, _id),\n (money_copy, _id, _id),\n (dollar_copy, _id, _id),", " (money_copy, _id, _id),\n (dollar_copy, _id, _id),\n (mexico_city_copy, _id, _id)) = [linear.invert(neg, one, zero)\n    for neg, one, zero in zip([neg_name, neg_capital_city, neg_money, neg_dollar, neg_mexico_city], copy_ones, copy_zeros)]\n\n(name_is_mexico, _and, _and) = linear.xor(name_copy, mexico)\n(capital_city_is_mexico_city, _and, _and) = linear.xor(capital_city_copy, mexico_city)\n(money_is_peso, _and, _and) = linear.xor(money_copy, peso)\n\n(_ands, MEX, _ors) = linear.thresholds3(name_is_mexico, capital_city_is_mexico_city, money_is_peso)", "\n(_ands, MEX, _ors) = linear.thresholds3(name_is_mexico, capital_city_is_mexico_city, money_is_peso)\n\n(orig_pair, _and, _and) = linear.xor(USA, MEX)\n# another method of copying\n(_neg, pair_one, pair_two) = linear.invert(orig_pair, copy_ones[-1], copy_zeros[-1])\n\n(dollar_of_mexico, _and, _and) = linear.xor(dollar_copy, pair_one)\n\n# ignoring linearity for these checks, we'd have to make another copy of peso and dollar", "\n# ignoring linearity for these checks, we'd have to make another copy of peso and dollar\nassert not peso.unrelated(dollar_of_mexico)\nassert peso.hamming(dollar_of_mexico) < dollar.hamming(dollar_of_mexico)\n\n(mexico_city_of_usa, _and, _and) = linear.xor(mexico_city_copy, pair_two)\n\n# ignoring linearity\nassert not washington_dc.unrelated(mexico_city_of_usa)\nassert washington_dc.hamming(mexico_city_of_usa) < mexico_city.hamming(mexico_city_of_usa)", "assert not washington_dc.unrelated(mexico_city_of_usa)\nassert washington_dc.hamming(mexico_city_of_usa) < mexico_city.hamming(mexico_city_of_usa)\n"]}
{"filename": "examples/viz_distances.py", "chunked_list": ["from bhv.vanilla import VanillaBHV as BHV\nfrom bhv.visualization import DistanceGraph\n\n\na, b, c, d = BHV.nrand(4)\n\nabc = BHV.majority([a, b, c])\n\na1 = a.flip_frac_on(.1)\na0 = a.flip_frac_off(.1)", "a1 = a.flip_frac_on(.1)\na0 = a.flip_frac_off(.1)\n\ncq = c.select(a0, a1)\n\nb_d = b ^ d\nabc_d = abc ^ d\n\nDistanceGraph.from_scope(locals()).graphviz()\n", "DistanceGraph.from_scope(locals()).graphviz()\n"]}
{"filename": "examples/kanerva09.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nFollowing along with [Kanerva 2009](http://ww.robertdick.org/iesr/papers/kanerva09jan.pdf), starting from \"Hyperdimensional Representation\". Please do open these side-by-side, while there is quite a bit of text copied over, it's mostly formulas, where as the interesting insights can only be found in the paper.\n\nAlso the booleans {0, 1} are used instead of {-1, 1}.\n\"\"\"\n\n# Let's install the package\n# pip install bhv==0.3.0\n", "# pip install bhv==0.3.0\n\n# Hypervectors here are called Boolean-Hyper-Vectors or BHVs for short.\n# Import a BHV implementation\nfrom bhv.vanilla import VanillaBHV as BHV\n# Import the corresponding permutation datastructure, we'll get to this\nfrom bhv.vanilla import VanillaPermutation as Perm\n\n\"\"\"> We can measure distances between points in Euclidean\nor Hamming metric. For binary spaces the Hamming distance is the simplest: it is the number of places at which", "\"\"\"> We can measure distances between points in Euclidean\nor Hamming metric. For binary spaces the Hamming distance is the simplest: it is the number of places at which\ntwo binary vectors differ, and it is also the length of the\nshortest path from one corner point to the other along the\nedges of the hypercube. In fact, there are 2k such shortest\npaths between two points that are k bits apart. Naturally,\nthe maximum Hamming distance is 10,000 bits, from any\npoint to its opposite point.\n\nOne example of opposite points is 101010... and 010101... which differs in every position.", "\nOne example of opposite points is 101010... and 010101... which differs in every position.\nThe example of opposite points below is all zeros and all ones.\nThe absolute distance in number of bits can be retrieved by `hamming`.\n\"\"\"\n\nprint(BHV.ONE.hamming(BHV.ZERO))\n# Note that the hypervector dimension here is 8192 instead of 10000\n\n\"\"\"", "\n\"\"\"\n\n> Although the points are not concentrated or clustered\nanywhere in the space\u2014because every point is just like\nevery other point\u2014the distances are highly concentrated\nhalf-way into the space, or around the distance of 5,000\nbits, or 0.5.\n\nLet's generate two random BHVs and find their bit-error-rate (BER), this should be close to 0.5. The BER corresponds to the hamming distance over the number of dimensions. `rand`\"\"\"", "\nLet's generate two random BHVs and find their bit-error-rate (BER), this should be close to 0.5. The BER corresponds to the hamming distance over the number of dimensions. `rand`\"\"\"\n\nprint(BHV.rand().bit_error_rate(BHV.rand()))\n\n\"\"\"\n\n> It is easy to see that half the space is closer to a\npoint than 0.5 and the other half is further away, but it is\nsomewhat surprising that less than a millionth of the space", "point than 0.5 and the other half is further away, but it is\nsomewhat surprising that less than a millionth of the space\nis closer than 0.476 and less than a thousand-millionth is\ncloser than 0.47; similarly, less than a millionth is further\nthan 0.524 away and less than a thousand-millionth is\nfurther than 0.53. These figures are based on the binomial\ndistribution with mean 5,000 and standard deviation (STD)\n50, and on its approximation with the normal distribution\u2014\nthe distance from any point of the space to a randomly\ndrawn point follows the binomial distribution. ", "the distance from any point of the space to a randomly\ndrawn point follows the binomial distribution. \n\nThis is a useful notion, and how likely a BHV is to occur randomly generated,\ncan be found by `zscore` (giving you the standard deviations) \nand `pvalue` (the absolute chance). \n\"\"\"\n\n# very likely to be randomly generated, because it is\n# Here -1.0 would mean \"one standard deviation less 1s than expected\"", "# very likely to be randomly generated, because it is\n# Here -1.0 would mean \"one standard deviation less 1s than expected\"\nprint(BHV.rand().zscore())\n# flipping just 5% extra on, makes it a 6 sigma+ outlier\nprint(BHV.rand().flip_frac_on(0.05).zscore())\n\n\"\"\"\n\n> We can go on\ntaking vectors at random without needing to worry about", "> We can go on\ntaking vectors at random without needing to worry about\nrunning out of vectors\u2014we run out of time before we run\nout of vectors. We say that such vectors are unrelated.\n\nAll vectors we'll practically sample are all unrelated.\nThere's a `related` function that takes the safety margin, 6 sigma by default.\"\"\"\n\nrandom_bhvs = BHV.nrand(10)\nfor x in random_bhvs:\n    for y in random_bhvs:\n        if x != y:\n            assert x.unrelated(y)", "random_bhvs = BHV.nrand(10)\nfor x in random_bhvs:\n    for y in random_bhvs:\n        if x != y:\n            assert x.unrelated(y)\n\n\"\"\"\n\n> Measured in standard deviations, the bulk of the space, and\nthe unrelated vectors, are 100 STDs away from any given", "> Measured in standard deviations, the bulk of the space, and\nthe unrelated vectors, are 100 STDs away from any given\nvector.\n\nSo we expect two BHVs in the space to be 100 (or in our case, 90) STDs apart.\"\"\"\n\nprint(BHV.rand().std_apart(BHV.rand()))\n\n\"\"\"\n", "\"\"\"\n\n> This peculiar distribution of the space makes hyperdimensional representation robust. When meaningful entities\nare represented by 10,000-bit vectors, many of the bits can\nbe changed\u2014more than a third\u2014by natural variation in\nstimulus and by random errors and noise, and the resulting\nvector can still be identified with the correct one, in that it\nis closer to the original \u2018\u2018error-free\u2019\u2019 vector than to any\nunrelated vector chosen so far, with near certainty.\n", "unrelated vector chosen so far, with near certainty.\n\nLet's try and flip 1/3 bits, and see how many STDs they are apart.\nThis is a lot less than the previous test!\"\"\"\n\nr = BHV.rand()\n\nprint(r.std_apart(r.flip_frac(1/3)))\n\n\"\"\"", "\n\"\"\"\n\n> The robustness is illustrated further by the following\nexample. Let us assume that two meaningful vectors A and\nB are only 2,500 bits apart\u2014when only 1/4 of their bits\ndiffer. The probability of this happening by chance is about\nzero, but a system can create such vectors when their\nmeanings are related; more on such relations will be said\nlater. So let us assume that 1/3 of the bits of A are changed", "meanings are related; more on such relations will be said\nlater. So let us assume that 1/3 of the bits of A are changed\nat random; will the resulting \u2018\u2018noisy\u2019\u2019 A vector be closer to\nB than to A\u2014would it be falsely identified with B? It is\npossible but most unlikely because the noisy vector would\nbe 4,166 bits away from B, on the average, and only 3,333\nbits from A; the difference is 17 STDs. The (relative)\ndistance from the noisy A vector to B is given by d = e -\n2de with d = 1/4 and e = 1/3. Thus, adding e amount of\nnoise to the first vector increases the distance to the second", "2de with d = 1/4 and e = 1/3. Thus, adding e amount of\nnoise to the first vector increases the distance to the second\nvector by (1 - 2d)e on the average. Intuitively, most\ndirections that are away from A in hyperspace are also\naway from B.\n\nLet's follow the full example.\n\n\n\"\"\"", "\n\"\"\"\n\nA = BHV.rand()\nA_corrupted = A.flip_frac(1/3)\nB = A.flip_frac(1/4)\n\nd = 1/4\ne = 1/3\nrelative_distance = d + e - 2*d*e", "e = 1/3\nrelative_distance = d + e - 2*d*e\n\nprint(relative_distance)\nprint(A_corrupted.bit_error_rate(B))\n\n# Note this is not the 17 STDs from the paper because we're working in less dimensions\nprint(A_corrupted.std_apart(B) - A.std_apart(A_corrupted))\n\n\"\"\"", "\n\"\"\"\n\n> The similarity of patterns is the flip-side of distance. We\nsay that two patterns, vectors, points are similar to each\nother when the distance between them is considerably\nsmaller than 0.5. We can now describe points of the space\nand their neighborhoods as follows. Each point has a large\n\u2018\u2018private\u2019\u2019 neighborhood in terms of distance: the volume of\nspace within, say, 1/3 or 3,333 bits is insignificant compared to the total space. The rest of the space\u2014all the", "\u2018\u2018private\u2019\u2019 neighborhood in terms of distance: the volume of\nspace within, say, 1/3 or 3,333 bits is insignificant compared to the total space. The rest of the space\u2014all the\nunrelated \u2018\u2018stuff\u2019\u2019\u2014becomes significant only when the\ndistance approaches 0.5. In a certain probabilistic sense,\nthen, two points even as far as 0.45 apart are very close to\neach other. Furthermore, the \u2018\u2018private\u2019\u2019 neighborhoods of\nany two unrelated points have points in common\u2014there\nare patterns that are closely related to any two unrelated\npatterns. For example, a point C half-way between unrelated points A and B is very closely related to both, and\nanother half-way point D can be unrelated to the first, C.", "patterns. For example, a point C half-way between unrelated points A and B is very closely related to both, and\nanother half-way point D can be unrelated to the first, C.\nThis can be shown with as few as four dimensions:\nA = 0000, B = 0011, C = 0001, and D = 0010. However, the \u2018\u2018unusual\u2019\u2019 probabilities implied by these relative\ndistances require high dimensionality. This is significant\nwhen representing objects and concepts with points of the\nhyperspace, and significantly different from what we are\naccustomed to in ordinary three-dimensional space.\n\nLet's do the same experiment (with BHVs) and verify for ourselves that while both C and D are at a halfwaypoint, they're further removed from each other than from A B.", "\nLet's do the same experiment (with BHVs) and verify for ourselves that while both C and D are at a halfwaypoint, they're further removed from each other than from A B.\n\n\"\"\"\n\nA = BHV.ZERO\nB = BHV.ONE\nC = BHV.rand() # random is halfway between 0 and 1 on average\nD = ~C # the inverse of C is unrelated to C\n", "D = ~C # the inverse of C is unrelated to C\n\nprint(A.bit_error_rate(C), B.bit_error_rate(C))\nprint(A.bit_error_rate(D), B.bit_error_rate(D))\nprint(C.bit_error_rate(D))\n\n\"\"\"\n\n> The sum (and the mean) of random vectors has the\nfollowing important property: it is similar to each of the", "> The sum (and the mean) of random vectors has the\nfollowing important property: it is similar to each of the\nvectors being added together. The similarity is very pronounced when only a few vectors are added\n\nWe're working with BHVs so we don't have a sum with the same properties, but there is a notion of mean. The mean is a \"majority\" operation plus a tiebreaker for even numbers of BHVs.\"\"\"\n\nvs = BHV.nrand(5)\nvs_mean = BHV.majority(vs)\n\n# while the random vectors are pairwise unrelated\nfor i in range(5):\n    assert vs[i].unrelated(vs[(i + 1) % 5])", "\n# while the random vectors are pairwise unrelated\nfor i in range(5):\n    assert vs[i].unrelated(vs[(i + 1) % 5])\n# they're all related to the mean\nprint(vs[0].bit_error_rate(vs_mean))\nprint(vs[0].std_apart(vs_mean))\n\n#for v in vs:\n#    assert v.sixsigma(vs_mean)", "#for v in vs:\n#    assert v.sixsigma(vs_mean)\n\n\"\"\"\n\n> A very basic and simple multiplication of binary vectors is\nby componentwise Exclusive-Or (XOR). The XOR of two vectors has 0s where the two agree and it has 1s where they\ndisagree. For example, 0011\u202610 XOR 0101\u202600 =\n0110\u202610. Mathematically, the XOR is the arithmetic sum\nmodulo 2. The (1, -1)-binary system, also called bipolar,", "0110\u202610. Mathematically, the XOR is the arithmetic sum\nmodulo 2. The (1, -1)-binary system, also called bipolar,\nis equivalent to the (0, 1)-binary system when the XOR is\nreplaced by ordinary multiplication. We will use the\nnotation A  B for the multiplication of the vectors A and\nB\u2014for their product-vector. Here * is the XOR unless\notherwise noted.\nThe XOR commutes, A \\* B = B \\* A, and is its own\ninverse so that A \\* A = O, where O is the vector of all 0s\n(in algebra terms O is the unit vector because A \\* O \\= A).", "inverse so that A \\* A = O, where O is the vector of all 0s\n(in algebra terms O is the unit vector because A \\* O \\= A).\n\nHere we'll denote XOR with the carret `^`. The laws are thoroughly tested in the library, but let's look at a few examples here.\"\"\"\n\nA = BHV.rand()\nB = BHV.rand()\n\n# commutative\nassert A ^ B == B ^ A", "# commutative\nassert A ^ B == B ^ A\n# it's own inverse\nassert A ^ A == BHV.ZERO\n\n\"\"\"\n\n> Since the XOR-vector has 1s where the two vectors disagree, the number of 1s in it is the Hamming distance\nbetween the two vectors. By denoting the number of 1s in a\nbinary vector X with |X| we can write the Hamming distance d between A and B as d(A, B) = |A * B|", "between the two vectors. By denoting the number of 1s in a\nbinary vector X with |X| we can write the Hamming distance d between A and B as d(A, B) = |A * B|\n\nHere we'll refrain from choosing a standard distance metric, but this fact is used everywere.\"\"\"\n\nA = BHV.rand()\nB = BHV.rand()\n\nassert A.hamming(B) == (A ^ B).active()\n", "assert A.hamming(B) == (A ^ B).active()\n\n\"\"\"\n\n> Multiplication can be thought of as a mapping of points\nin the space. Multiplying the vector X with A maps it to\nthe vector X_A = A \\* X which is as far from X as there are 1s\nin A (i.e., d(A, X) = |X_A \\* X| = |(A \\* X) \\* X| = |A \\* X \\* X| = |A|).\n\nAnother few important properties, set out in code.\"\"\"", "\nAnother few important properties, set out in code.\"\"\"\n\nA = BHV.rand()\nX = BHV.rand()\n\nX_A = A ^ X\n\nassert X_A.hamming(X) == A.active()\n", "assert X_A.hamming(X) == A.active()\n\n\"\"\"\n\n> If A is a typical (random) vector of the space,\nabout half of its bits are 1s, and so X_A is in the part of the\nspace that is unrelated to X in terms of the distance criterion. Thus we can say that multiplication randomizes.\n\nLet's check this \"\"\"\n", "Let's check this \"\"\"\n\nA = BHV.rand()\nX = BHV.rand()\n\nX_A = A ^ X\n\nprint(X_A.std_apart(X))\n\n\"\"\"", "\n\"\"\"\n\n> Mapping with multiplication preserves distance. This is\nseen readily by considering X_A = A \\* X and Y_A = A \\* Y;\ntaking their XOR, and noting that the two As cancel out\nthus: X_A \\* Y_A = (A \\* X) \\* (A \\* Y) = A \\* X \\* A \\* Y = X \\* Y\nSince the XOR-vector is the same, the Hamming distance\nis the same: |X_A \\* Y_A| = |X \\* Y|\n", "is the same: |X_A \\* Y_A| = |X \\* Y|\n\nAnd the logical extension\"\"\"\n\nA = BHV.rand()\nX = BHV.rand()\nY = BHV.rand()\n\nX_A = A ^ X\nY_A = A ^ Y", "X_A = A ^ X\nY_A = A ^ Y\n\nassert (X_A ^ Y_A) == X ^ Y\n\n\"\"\"\n\n> A very useful property of multiplication is that it\ndistributes over addition. That means, for example, that\nA \\* \\[X + Y + Z\\] = \\[A \\* X + A \\* Y + A \\* Z\\]", "distributes over addition. That means, for example, that\nA \\* \\[X + Y + Z\\] = \\[A \\* X + A \\* Y + A \\* Z\\]\nThe brackets \\[\u2026\\] stand for normalization. Distributivity is\ninvaluable in analyzing these representations and in\nunderstanding how they work and fail.\n\nThe BHVs do not support normalization in the sense that's meant here. Therefore, care has to be taken as to not introduce unwanted noise. Instead of adding multiple times, and normalizing, one should prefer the addition (here mean) of multiple items.\"\"\"\n\nA, X, Y, Z = BHV.nrand(4)\n", "A, X, Y, Z = BHV.nrand(4)\n\nLHS = A ^ BHV.majority([X, Y, Z])\nRHS = BHV.majority([A ^ X, A ^ Y, A ^ Z])\n\nassert LHS == RHS\n\n\"\"\"\n\n> Permutations reorder the vector components and thus are", "\n> Permutations reorder the vector components and thus are\nvery simple; they are also very useful in constructing a\ncognitive code. We will denote the permutation of a vector\nwith a multiplication by a matrix (the permutation matrix\n\u03a0), thus X_\u03a0 = \u03a0X. We can also describe the permutation\nof n elements as the list of the integers 1, 2, 3, \u2026, n in the\npermuted order. A random permutation is then one where\nthe order of the list is random\u2014it is a permutation chosen\nrandomly from the n! possible permutations.", "the order of the list is random\u2014it is a permutation chosen\nrandomly from the n! possible permutations.\n\nWhen theory hits reality, it's not quite as pretty. Firstly, a 8192x8192 matrix is large (LA folks are laughing in the background) and wasteful. This can be resolved by using a denser representation (`NumPyWordPermutation` uses an array of indices, which is [still no optimal](https://hackmd.io/@dabo/rkP8Pcf9t#A-compact-data-structure-for-storing-a-permutation)). Secondly, the number of permutations 8192! is extremely large (28000+ digits). Therefore, implementions needn't support all permutations (`NumPyWordPermutation` only supports permutations on 64 bit words at the moment). Let's take a look at the basic properties with an explicit representation.\n\"\"\"\n\n\u03a0 = Perm.random()\n\nX, Y = BHV.nrand(2)\n", "X, Y = BHV.nrand(2)\n\nassert \u03a0(X) ^ \u03a0(Y) == \u03a0(X ^ Y)\nassert \u03a0(X).hamming(\u03a0(Y)) == X.hamming(Y)\n\n\"\"\"\n\n> As mentioned above, we can map the same vector with two\ndifferent permutations and ask how similar the resulting\nvectors are: by permuting X with \u03a0 and \u0393, what is the", "different permutations and ask how similar the resulting\nvectors are: by permuting X with \u03a0 and \u0393, what is the\ndistance between \u03a0X and \u0393X (...)? Unlike above with multiplication by\na vector, this depends on the vector X (e.g., the 0-vector is\nunaffected by permutation).\n\nLet's generate another permutation.\"\"\"\n\n\u03a0, \u0393 = Perm.nrandom(2)\n", "\u03a0, \u0393 = Perm.nrandom(2)\n\nX = BHV.rand()\n\nassert \u03a0(X).unrelated(\u0393(X))\n"]}
{"filename": "examples/majority_classification.py", "chunked_list": ["from bhv.vanilla import VanillaBHV as BHV\n\nN = 199*2\n\nxs = BHV.nrand(N)\nys = [i % 2 == 0 for i in range(N)]\n\npos = BHV.majority([x for x, y in zip(xs, ys) if y])\nneg = BHV.majority([x for x, y in zip(xs, ys) if not y])\n", "neg = BHV.majority([x for x, y in zip(xs, ys) if not y])\n\nright = 0\nfor x, y in zip(xs, ys):\n    spos = x.hamming(pos)\n    sneg = x.hamming(neg)\n    prediction = spos < sneg\n    right += prediction == y\nprint(f\"acc {right/N}\")\n", "print(f\"acc {right/N}\")\n"]}
{"filename": "examples/reasoning_by_analogy_adiabatic.py", "chunked_list": ["# The adiabatic variant of https://colab.research.google.com/drive/10XSpooxDAeYVMivF3W2-N0W5yEIUfdZl#scrollTo=dQ7044izy3_y\n# This is of theoretical interest\nfrom bhv.vanilla import VanillaBHV as BHV, DIMENSION\nfrom bhv.variants import AdiabaticBHVModel, Tank\n\n\n# declare up front how much charge we have in our tank\ntank = Tank(10*DIMENSION, record=True)\nadiabatic = AdiabaticBHVModel(tank, BHV)\n", "adiabatic = AdiabaticBHVModel(tank, BHV)\n\n((name, neg_name), (capital_city, neg_capital_city), (money, neg_money),\n (united_states, _neg), (washington_dc, _neg), (dollar, neg_dollar),\n (mexico, _neg), (mexico_city, neg_mexico_city), (peso, _neg)) = [adiabatic.spawn() for _ in range(9)]\n\nname_is_united_states = adiabatic.xor(name, united_states)\ncapital_city_is_washington_dc = adiabatic.xor(capital_city, washington_dc)\nmoney_is_dollar = adiabatic.xor(money, dollar)\n", "money_is_dollar = adiabatic.xor(money, dollar)\n\n# majority is quite a flooding operation\nUSA = adiabatic.majority3(name_is_united_states, capital_city_is_washington_dc, money_is_dollar)\n\n# note to make more than on record, we need to re-use the field names\n# we invert the negated version we got during spawning the random vectors to obtain copies to save charge\n(name_copy,\n capital_city_copy,\n money_copy,", " capital_city_copy,\n money_copy,\n dollar_copy,\n mexico_city_copy) = [adiabatic.invert(neg)\n    for neg in [neg_name, neg_capital_city, neg_money, neg_dollar, neg_mexico_city]]\n\nname_is_mexico = adiabatic.xor(name_copy, mexico)\ncapital_city_is_mexico_city = adiabatic.xor(capital_city_copy, mexico_city)\nmoney_is_peso = adiabatic.xor(money_copy, peso)\n", "money_is_peso = adiabatic.xor(money_copy, peso)\n\nMEX = adiabatic.majority3(name_is_mexico, capital_city_is_mexico_city, money_is_peso)\n\norig_pair = adiabatic.xor(USA, MEX)\n# another method of copying\n(pair_one, pair_two, _neg) = adiabatic.switch(orig_pair, adiabatic.get_one(), adiabatic.get_zero())\n\ndollar_of_mexico = adiabatic.xor(dollar_copy, pair_one)\n", "dollar_of_mexico = adiabatic.xor(dollar_copy, pair_one)\n\n# ignoring adiabaticity for these checks, we'd have to make another copy of peso and dollar\nassert not peso.unrelated(dollar_of_mexico)\nassert peso.hamming(dollar_of_mexico) < dollar.hamming(dollar_of_mexico)\n\nmexico_city_of_usa = adiabatic.xor(mexico_city_copy, pair_two)\n\n# ignoring adiabaticity\nassert not washington_dc.unrelated(mexico_city_of_usa)", "# ignoring adiabaticity\nassert not washington_dc.unrelated(mexico_city_of_usa)\nassert washington_dc.hamming(mexico_city_of_usa) < mexico_city.hamming(mexico_city_of_usa)\n\nhistorical_levels = tank.historical_levels()\n\nprint(\"final tank level:\", tank.level, \"historical min,max:\", min(historical_levels), max(historical_levels))\n"]}
{"filename": "examples/state_machine.py", "chunked_list": ["# TurnstileExample\n# Implementing the Turnstile state machine with Hypervectors\n# The state machine: https://en.wikipedia.org/wiki/Finite-state_machine#Example:_coin-operated_turnstile\n\nfrom bhv.vanilla import VanillaBHV as BHV, VanillaPermutation as Perm\n\n\n# states\nlocked = BHV.rand()\nunlocked = BHV.rand()", "locked = BHV.rand()\nunlocked = BHV.rand()\n# input symbols\ntoken = BHV.rand()\npush = BHV.rand()\n# next state permutation\nPNext = Perm.random()\n# inverse for querying the next state\nQNext = ~PNext\n", "QNext = ~PNext\n\ntransition = BHV.majority([\n    (push ^ locked ^ PNext(locked)),\n    (token ^ locked ^ PNext(unlocked)),\n    (push ^ unlocked ^ PNext(locked)),\n    (token ^ unlocked ^ PNext(unlocked))\n])\n\n# note this doesn't exactly give the right state\ndef next_state(state, input):\n    return QNext(transition ^ input ^ state)", "\n# note this doesn't exactly give the right state\ndef next_state(state, input):\n    return QNext(transition ^ input ^ state)\n\n# so we make a noisy lookup table\ntable = [locked, unlocked]\ndef closest(noisy):\n    return min(table, key=noisy.hamming)\n", "\n# and check if the transition system works as expected\nassert closest(next_state(locked, push)) == locked\nassert closest(next_state(locked, token)) == unlocked\nassert closest(next_state(unlocked, push)) == locked\nassert closest(next_state(unlocked, token)) == unlocked\n"]}
{"filename": "examples/winnow_classification.py", "chunked_list": ["# require NumPy\nfrom bhv.np import NumPyBoolBHV as BHV, DIMENSION\nimport numpy as np\n\nN = 22\nEPOCHS = 30\n\nxs = BHV.nrand(N)\nys = [i % 2 == 0 for i in range(N)]\n", "ys = [i % 2 == 0 for i in range(N)]\n\nthreshold = DIMENSION//2\nalpha = 2\nws = np.ones(DIMENSION, dtype=np.uint16)\n\nfor i in range(EPOCHS):\n    right = 0\n    for x, y in zip(xs, ys):\n        total = np.dot(x.data, ws)\n        prediction = total > threshold\n        right += prediction == y\n        if prediction != y:\n            if y:\n                ws = np.where(x.data == 1, ws*alpha, ws)\n            else:\n                ws = np.where(x.data == 1, ws/alpha, ws)\n                # ws = np.where(x.data == 1, np.zeros_like(ws), ws)\n    print(f\"acc {right/N}\")", ""]}
{"filename": "examples/grandmother_example.py", "chunked_list": ["# Let's try and encode some rules, and do some rule-based computing\n# If x is the mother of y and y is the father of z then x is the grandmother of z\n\n# from bhv.np import NumPyPacked64BHV as BHV, NumPyWordPermutation as Perm\nfrom bhv.vanilla import VanillaBHV as BHV, VanillaPermutation as Perm\n\n# relation utility\nrel_subject = Perm.random()\nrel_object = ~rel_subject\n", "rel_object = ~rel_subject\n\n# relations\nmother_of = BHV.rand()\nfather_of = BHV.rand()\ngrandmother_of = BHV.rand()\n\n# extractors\nmother_of_mother = rel_subject(mother_of)\nmother_of_child = rel_object(mother_of)", "mother_of_mother = rel_subject(mother_of)\nmother_of_child = rel_object(mother_of)\nfather_of_father = rel_subject(father_of)\nfather_of_child = rel_object(father_of)\ngrandmother_of_grandmother = rel_subject(grandmother_of)\ngrandmother_of_child = rel_object(grandmother_of)\n\ndef apply_rel(rel, x, y):\n  sx = rel_subject(rel) ^ x\n  sy = rel_object(rel) ^ y\n  return BHV.majority([sx, sy])", "\n# our rule, read `xor` as \"implied by\" and `BHV.majority` as \"and\"\n# note this is applied to multiple \"datapoints\" ...\ndef generate_sample():\n  person_x = BHV.rand()\n  person_y = BHV.rand()\n  person_z = BHV.rand()\n\n  mxy = apply_rel(mother_of, person_x, person_y)\n  fyz = apply_rel(father_of, person_y, person_z)\n  gxz = apply_rel(grandmother_of, person_x, person_z)\n\n  return gxz ^ BHV.majority([mxy, fyz])", "\n# ... and averaged out for higher accuracy\ngrandmother_rule = BHV.majority([generate_sample() for _ in range(15)])\n\n# applying grandmother rule\"\nanna = BHV.rand()\nbill = BHV.rand()\ncid = BHV.rand()\nanna_mother_of_bill = apply_rel(mother_of, anna, bill)\nbill_father_of_cid = apply_rel(father_of, bill, cid)", "anna_mother_of_bill = apply_rel(mother_of, anna, bill)\nbill_father_of_cid = apply_rel(father_of, bill, cid)\ncalculated_anna_grandmother_of_cid = grandmother_rule ^ BHV.majority([anna_mother_of_bill, bill_father_of_cid])\nactual_anna_grandmother_of_cid = apply_rel(grandmother_of, anna, cid)\n\nassert not calculated_anna_grandmother_of_cid.unrelated(actual_anna_grandmother_of_cid)\n"]}
