{"filename": "spoolman/main.py", "chunked_list": ["\"\"\"Main entrypoint to the server.\"\"\"\n\nimport logging\nimport os\nimport subprocess\nfrom logging.handlers import TimedRotatingFileHandler\nfrom pathlib import Path\nfrom typing import Union\n\nimport uvicorn", "\nimport uvicorn\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.middleware.gzip import GZipMiddleware\nfrom fastapi.staticfiles import StaticFiles\nfrom scheduler.asyncio.scheduler import Scheduler\n\nfrom spoolman import env\nfrom spoolman.api.v1.router import app as v1_app", "from spoolman import env\nfrom spoolman.api.v1.router import app as v1_app\nfrom spoolman.database import database\n\n# Define a file logger with log rotation\nlog_file = env.get_data_dir().joinpath(\"spoolman.log\")\nfile_handler = TimedRotatingFileHandler(log_file, when=\"midnight\", backupCount=5)\nfile_handler.setFormatter(logging.Formatter(\"%(asctime)s:%(levelname)s:%(message)s\", \"%Y-%m-%d %H:%M:%S\"))\n\n# Define a console logger", "\n# Define a console logger\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(logging.Formatter(\"%(name)-26s %(levelname)-8s %(message)s\"))\n\n# Setup the spoolman logger, which all spoolman modules will use\nroot_logger = logging.getLogger()\nroot_logger.setLevel(env.get_logging_level())\nroot_logger.addHandler(file_handler)\nroot_logger.addHandler(console_handler)", "root_logger.addHandler(file_handler)\nroot_logger.addHandler(console_handler)\n\n# Get logger instance for this module\nlogger = logging.getLogger(__name__)\n\n\n# Setup FastAPI\nclass SinglePageApplication(StaticFiles):\n    \"\"\"Serve a single page application.\"\"\"\n\n    def __init__(self, directory: str) -> None:\n        \"\"\"Construct.\"\"\"\n        super().__init__(directory=directory, packages=None, html=True, check_dir=True)\n\n    def lookup_path(self, path: str) -> tuple[str, Union[os.stat_result, None]]:\n        \"\"\"Return index.html if the requested file cannot be found.\"\"\"\n        full_path, stat_result = super().lookup_path(path)\n\n        if stat_result is None:\n            return super().lookup_path(\"index.html\")\n\n        return (full_path, stat_result)", "class SinglePageApplication(StaticFiles):\n    \"\"\"Serve a single page application.\"\"\"\n\n    def __init__(self, directory: str) -> None:\n        \"\"\"Construct.\"\"\"\n        super().__init__(directory=directory, packages=None, html=True, check_dir=True)\n\n    def lookup_path(self, path: str) -> tuple[str, Union[os.stat_result, None]]:\n        \"\"\"Return index.html if the requested file cannot be found.\"\"\"\n        full_path, stat_result = super().lookup_path(path)\n\n        if stat_result is None:\n            return super().lookup_path(\"index.html\")\n\n        return (full_path, stat_result)", "\n\napp = FastAPI(\n    debug=env.is_debug_mode(),\n    title=\"Spoolman\",\n    version=env.get_version(),\n)\napp.add_middleware(GZipMiddleware)\napp.mount(\"/api/v1\", v1_app)\napp.mount(\"/\", app=SinglePageApplication(directory=\"client/dist\"), name=\"client\")", "app.mount(\"/api/v1\", v1_app)\napp.mount(\"/\", app=SinglePageApplication(directory=\"client/dist\"), name=\"client\")\n\n\n# Allow all origins if in debug mode\nif env.is_debug_mode():\n    logger.warning(\"Running in debug mode, allowing all origins.\")\n\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )", "\n\n@app.on_event(\"startup\")\nasync def startup() -> None:\n    \"\"\"Run the service's startup sequence.\"\"\"\n    logger.info(\"Starting Spoolman v%s...\", app.version)\n\n    logger.info(\"Setting up database...\")\n    database.setup_db(database.get_connection_url())\n", "    database.setup_db(database.get_connection_url())\n\n    logger.info(\"Performing migrations...\")\n    # Run alembic in a subprocess.\n    # There is some issue with the uvicorn worker that causes the process to hang when running alembic directly.\n    # See: https://github.com/sqlalchemy/alembic/discussions/1155\n    project_root = Path(__file__).parent.parent\n    subprocess.run([\"alembic\", \"upgrade\", \"head\"], check=True, cwd=project_root)  # noqa: S603, S607, ASYNC101\n\n    # Setup scheduler", "\n    # Setup scheduler\n    schedule = Scheduler()\n    database.schedule_tasks(schedule)\n\n    logger.info(\"Startup complete.\")\n\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)", "if __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"]}
{"filename": "spoolman/docs.py", "chunked_list": ["\"\"\"Functions for generating documentation.\"\"\"\n\nimport json\nimport logging\nfrom pathlib import Path\nfrom typing import Any\n\nfrom fastapi import FastAPI\nfrom fastapi.openapi.utils import get_openapi\n", "from fastapi.openapi.utils import get_openapi\n\nfrom spoolman.api.v1.router import app as v1_app\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler())  # Print all log messages to stdout\n\n\ndef generate_openapi(app: FastAPI) -> dict[str, Any]:\n    \"\"\"Generate the OpenAPI document for a specific FastAPI app.\n\n    Args:\n        app (FastAPI): The FastAPI app.\n\n    Returns:\n        dict[str, Any]: The OpenAPI document.\n    \"\"\"\n    return get_openapi(\n        title=app.title,\n        version=app.version,\n        openapi_version=app.openapi_version,\n        description=app.description,\n        routes=app.routes,\n        contact=app.contact,\n        license_info=app.license_info,\n        servers=app.servers,\n        tags=app.openapi_tags,\n        terms_of_service=app.terms_of_service,\n    )", "\ndef generate_openapi(app: FastAPI) -> dict[str, Any]:\n    \"\"\"Generate the OpenAPI document for a specific FastAPI app.\n\n    Args:\n        app (FastAPI): The FastAPI app.\n\n    Returns:\n        dict[str, Any]: The OpenAPI document.\n    \"\"\"\n    return get_openapi(\n        title=app.title,\n        version=app.version,\n        openapi_version=app.openapi_version,\n        description=app.description,\n        routes=app.routes,\n        contact=app.contact,\n        license_info=app.license_info,\n        servers=app.servers,\n        tags=app.openapi_tags,\n        terms_of_service=app.terms_of_service,\n    )", "\n\ndef generate_docs() -> None:\n    \"\"\"Generate documentation for this service in the docs/ directory.\"\"\"\n    target_dir = Path(\"docs\")\n\n    logger.info('Generating documentation to \"%s\"...', target_dir.resolve())\n\n    target_dir.mkdir(parents=True, exist_ok=True)\n\n    spec = json.dumps(generate_openapi(v1_app))\n\n    with target_dir.joinpath(\"index.html\").open(\"w\") as f:\n        f.write(\n            f\"\"\"\n        <!DOCTYPE html>\n        <html>\n        <head>\n        <title>Spoolman REST API v1 - ReDoc</title>\n        <meta charset=\"utf-8\"/>\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n        <link href=\"https://fonts.googleapis.com/css?family=Montserrat:300,400,700|Roboto:300,400,700\" rel=\"stylesheet\">\n        <link rel=\"shortcut icon\" href=\"https://fastapi.tiangolo.com/img/favicon.png\">\n        <style> body {{margin: 0; padding: 0; }} </style>\n        </head>\n        <body>\n            <div id=\"redoc-container\"></div>\n            <script src=\"https://cdn.jsdelivr.net/npm/redoc/bundles/redoc.standalone.js\"> </script>\n            <script>\n                var spec = {spec};\n                Redoc.init(spec, {{}}, document.getElementById(\"redoc-container\"));\n            </script>\n        </body>\n        </html>\"\"\",\n        )\n\n    logger.info(\"Documentation generated successfully.\")", ""]}
{"filename": "spoolman/__init__.py", "chunked_list": [""]}
{"filename": "spoolman/env.py", "chunked_list": ["\"\"\"Utilities for grabbing config from environment variables.\"\"\"\n\nimport logging\nimport os\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import Optional\nfrom urllib import parse\n\nimport pkg_resources", "\nimport pkg_resources\nfrom platformdirs import user_data_dir\n\n\nclass DatabaseType(Enum):\n    \"\"\"The database type.\"\"\"\n\n    POSTGRES = \"postgres\"\n    MYSQL = \"mysql\"\n    SQLITE = \"sqlite\"\n    COCKROACHDB = \"cockroachdb\"\n\n    def to_drivername(self: \"DatabaseType\") -> str:\n        \"\"\"Get the drivername for the database type.\n\n        Returns:\n            str: The drivername.\n        \"\"\"\n        if self is DatabaseType.POSTGRES:\n            return \"postgresql+asyncpg\"\n        if self is DatabaseType.MYSQL:\n            return \"mysql+aiomysql\"\n        if self is DatabaseType.SQLITE:\n            return \"sqlite+aiosqlite\"\n        if self is DatabaseType.COCKROACHDB:\n            return \"cockroachdb+asyncpg\"\n        raise ValueError(f\"Unknown database type '{self}'.\")", "\n\ndef get_database_type() -> Optional[DatabaseType]:\n    \"\"\"Get the database type from environment variables.\n\n    Returns None if no environment variable was set for the database type.\n\n    Returns:\n        Optional[DatabaseType]: The database type.\n    \"\"\"\n    database_type = os.getenv(\"SPOOLMAN_DB_TYPE\")\n    if database_type is None:\n        return None\n    if database_type == \"postgres\":\n        return DatabaseType.POSTGRES\n    if database_type == \"mysql\":\n        return DatabaseType.MYSQL\n    if database_type == \"sqlite\":\n        return DatabaseType.SQLITE\n    if database_type == \"cockroachdb\":\n        return DatabaseType.COCKROACHDB\n    raise ValueError(f\"Failed to parse SPOOLMAN_DB_TYPE variable: Unknown database type '{database_type}'.\")", "\n\ndef get_host() -> Optional[str]:\n    \"\"\"Get the DB host from environment variables.\n\n    Returns None if no environment variable was set for the host.\n\n    Returns:\n        Optional[str]: The host.\n    \"\"\"\n    return os.getenv(\"SPOOLMAN_DB_HOST\")", "\n\ndef get_port() -> Optional[int]:\n    \"\"\"Get the DB port from environment variables.\n\n    Returns None if no environment variable was set for the port.\n\n    Returns:\n        Optional[str]: The port.\n    \"\"\"\n    port = os.getenv(\"SPOOLMAN_DB_PORT\")\n    if port is None:\n        return None\n    try:\n        return int(port)\n    except ValueError as exc:\n        raise ValueError(f\"Failed to parse SPOOLMAN_DB_PORT variable: {exc!s}\") from exc", "\n\ndef get_database() -> Optional[str]:\n    \"\"\"Get the DB name from environment variables.\n\n    Returns None if no environment variable was set for the name.\n\n    Returns:\n        Optional[str]: The name.\n    \"\"\"\n    return os.getenv(\"SPOOLMAN_DB_NAME\")", "\n\ndef get_query() -> Optional[dict[str, str]]:\n    \"\"\"Get the DB query from environment variables.\n\n    Returns None if no environment variable was set for the query.\n\n    Returns:\n        Optional[dict]: The query.\n    \"\"\"\n    query = os.getenv(\"SPOOLMAN_DB_QUERY\")\n    if query is None:\n        return None\n    try:\n        parsed_dict = parse.parse_qs(query, strict_parsing=True)\n        return {key: value[0] for key, value in parsed_dict.items()}\n    except ValueError as exc:\n        raise ValueError(f\"Failed to parse SPOOLMAN_DB_QUERY variable: {exc!s}\") from exc", "\n\ndef get_username() -> Optional[str]:\n    \"\"\"Get the DB username from environment variables.\n\n    Returns None if no environment variable was set for the username.\n\n    Returns:\n        Optional[str]: The username.\n    \"\"\"\n    return os.getenv(\"SPOOLMAN_DB_USERNAME\")", "\n\ndef get_password() -> Optional[str]:\n    \"\"\"Get the DB password from environment variables.\n\n    Returns None if no environment variables were set for the password.\n\n    Raises:\n        ValueError: If it failed to read the password from a password file.\n\n    Returns:\n        Optional[str]: The password.\n    \"\"\"\n    # First attempt: grab password from a file. This is the most secure way of storing passwords.\n    file_path = os.getenv(\"SPOOLMAN_DB_PASSWORD_FILE\")\n    if file_path is not None:\n        file = Path(file_path)\n        if not file.exists() or not file.is_file():\n            raise ValueError(\n                \"Failed to parse SPOOLMAN_DB_PASSWORD_FILE variable: \"\n                f'Database password file \"{file_path}\" does not exist.',\n            )\n        try:\n            with file.open(encoding=\"utf-8\") as f:\n                return f.read()\n        except OSError as exc:\n            raise ValueError(\n                \"Failed to parse SPOOLMAN_DB_PASSWORD_FILE variable: \"\n                f'Failed to read password from file \"{file_path}\": {exc!s}.',\n            ) from exc\n\n    # Second attempt: grab directly from an environment variable.\n    return os.getenv(\"SPOOLMAN_DB_PASSWORD\")", "\n\ndef get_logging_level() -> int:\n    \"\"\"Get the logging level from environment variables.\n\n    Returns \"INFO\" if no environment variable was set for the logging level.\n\n    Returns:\n        str: The logging level.\n    \"\"\"\n    log_level_str = os.getenv(\"SPOOLMAN_LOGGING_LEVEL\", \"INFO\").upper()\n    if log_level_str == \"DEBUG\":\n        return logging.DEBUG\n    if log_level_str == \"INFO\":\n        return logging.INFO\n    if log_level_str == \"WARNING\":\n        return logging.WARNING\n    if log_level_str == \"ERROR\":\n        return logging.ERROR\n    if log_level_str == \"CRITICAL\":\n        return logging.CRITICAL\n    raise ValueError(f\"Failed to parse SPOOLMAN_LOGGING_LEVEL variable: Unknown logging level '{log_level_str}'.\")", "\n\ndef is_debug_mode() -> bool:\n    \"\"\"Get whether debug mode is enabled from environment variables.\n\n    Returns False if no environment variable was set for debug mode.\n\n    Returns:\n        bool: Whether debug mode is enabled.\n    \"\"\"\n    debug_mode = os.getenv(\"SPOOLMAN_DEBUG_MODE\", \"FALSE\").upper()\n    if debug_mode == \"FALSE\" or debug_mode == \"0\":\n        return False\n    if debug_mode == \"TRUE\" or debug_mode == \"1\":\n        return True\n    raise ValueError(f\"Failed to parse SPOOLMAN_DEBUG_MODE variable: Unknown debug mode '{debug_mode}'.\")", "\n\ndef is_automatic_backup_enabled() -> bool:\n    \"\"\"Get whether automatic backup is enabled from environment variables.\n\n    Returns True if no environment variable was set for automatic backup.\n\n    Returns:\n        bool: Whether automatic backup is enabled.\n    \"\"\"\n    automatic_backup = os.getenv(\"SPOOLMAN_AUTOMATIC_BACKUP\", \"TRUE\").upper()\n    if automatic_backup == \"FALSE\" or automatic_backup == \"0\":\n        return False\n    if automatic_backup == \"TRUE\" or automatic_backup == \"1\":\n        return True\n    raise ValueError(\n        f\"Failed to parse SPOOLMAN_AUTOMATIC_BACKUP variable: Unknown automatic backup '{automatic_backup}'.\",\n    )", "\n\ndef get_data_dir() -> Path:\n    \"\"\"Get the data directory.\n\n    Returns:\n        Path: The data directory.\n    \"\"\"\n    data_dir = Path(user_data_dir(\"spoolman\"))\n    data_dir.mkdir(parents=True, exist_ok=True)\n    return data_dir", "\n\ndef get_backups_dir() -> Path:\n    \"\"\"Get the backups directory.\n\n    Returns:\n        Path: The backups directory.\n    \"\"\"\n    data_dir = get_data_dir()\n    backups_dir = data_dir.joinpath(\"backups\")\n    backups_dir.mkdir(parents=True, exist_ok=True)\n    return backups_dir", "\n\ndef get_version() -> str:\n    \"\"\"Get the version of the package.\n\n    Returns:\n        str: The version.\n    \"\"\"\n    return pkg_resources.get_distribution(\"spoolman\").version\n", ""]}
{"filename": "spoolman/bump.py", "chunked_list": ["\"\"\"A python script that bumps the version number of a project.\"\"\"\n\n# ruff: noqa: PLR2004, T201, S603, S607\n\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\n\n\ndef bump() -> None:\n    \"\"\"Bump the version number of the project.\"\"\"\n    project_root = Path(__file__).parent.parent\n\n    if len(sys.argv) < 2:\n        print(\"Please specify a bump type, e.g. major, minor, micro.\")\n        sys.exit(1)\n\n    if subprocess.run([\"git\", \"diff\", \"--quiet\", \"pyproject.toml\"], cwd=project_root).returncode != 0:\n        print(\"The pyproject.toml file is dirty, please commit your changes before bumping the version number.\")\n        sys.exit(1)\n\n    if subprocess.run([\"git\", \"diff\", \"--cached\", \"--quiet\"], cwd=project_root).returncode != 0:\n        print(\"There are staged changes, please commit them before bumping the version number.\")\n        sys.exit(1)\n\n    if subprocess.run([\"pip\", \"show\", \"pdm-bump\"], cwd=project_root, capture_output=True).returncode != 0:\n        print(\"Please install pdm-bump using pip.\")\n        sys.exit(1)\n\n    # Bump the version number, read the pdm bump output to determine the new version number\n    bump_type = sys.argv[1]\n    bump_output = subprocess.run([\"pdm\", \"bump\", bump_type], cwd=project_root, capture_output=True, check=True)\n    # Example output: \"Performing increment of version: 0.7.0 -> 0.8.0\\nSome more text\"\n    # Parse using regex\n    new_version_match = re.search(r\"-> ([A-Za-z0-9\\.\\-]+)\", bump_output.stdout.decode())\n    if new_version_match is None:\n        print(\"Failed to parse pdm bump output, did it fail?\")\n        sys.exit(1)\n    new_version = new_version_match.group(1)\n\n    # Stage the pyproject.toml file\n    subprocess.run([\"git\", \"add\", \"pyproject.toml\"], cwd=project_root, check=True)\n\n    # Commit the changes\n    subprocess.run([\"git\", \"commit\", \"-m\", f\"Bump version to {new_version}\"], cwd=project_root, check=True)\n\n    # Tag the commit, prefix with \"v\"\n    subprocess.run([\"git\", \"tag\", f\"v{new_version}\"], cwd=project_root, check=True)\n\n    # Notify user that the process is complete\n    print(f\"Bumped version to {new_version}.\")", "\n\ndef bump() -> None:\n    \"\"\"Bump the version number of the project.\"\"\"\n    project_root = Path(__file__).parent.parent\n\n    if len(sys.argv) < 2:\n        print(\"Please specify a bump type, e.g. major, minor, micro.\")\n        sys.exit(1)\n\n    if subprocess.run([\"git\", \"diff\", \"--quiet\", \"pyproject.toml\"], cwd=project_root).returncode != 0:\n        print(\"The pyproject.toml file is dirty, please commit your changes before bumping the version number.\")\n        sys.exit(1)\n\n    if subprocess.run([\"git\", \"diff\", \"--cached\", \"--quiet\"], cwd=project_root).returncode != 0:\n        print(\"There are staged changes, please commit them before bumping the version number.\")\n        sys.exit(1)\n\n    if subprocess.run([\"pip\", \"show\", \"pdm-bump\"], cwd=project_root, capture_output=True).returncode != 0:\n        print(\"Please install pdm-bump using pip.\")\n        sys.exit(1)\n\n    # Bump the version number, read the pdm bump output to determine the new version number\n    bump_type = sys.argv[1]\n    bump_output = subprocess.run([\"pdm\", \"bump\", bump_type], cwd=project_root, capture_output=True, check=True)\n    # Example output: \"Performing increment of version: 0.7.0 -> 0.8.0\\nSome more text\"\n    # Parse using regex\n    new_version_match = re.search(r\"-> ([A-Za-z0-9\\.\\-]+)\", bump_output.stdout.decode())\n    if new_version_match is None:\n        print(\"Failed to parse pdm bump output, did it fail?\")\n        sys.exit(1)\n    new_version = new_version_match.group(1)\n\n    # Stage the pyproject.toml file\n    subprocess.run([\"git\", \"add\", \"pyproject.toml\"], cwd=project_root, check=True)\n\n    # Commit the changes\n    subprocess.run([\"git\", \"commit\", \"-m\", f\"Bump version to {new_version}\"], cwd=project_root, check=True)\n\n    # Tag the commit, prefix with \"v\"\n    subprocess.run([\"git\", \"tag\", f\"v{new_version}\"], cwd=project_root, check=True)\n\n    # Notify user that the process is complete\n    print(f\"Bumped version to {new_version}.\")", ""]}
{"filename": "spoolman/math.py", "chunked_list": ["\"\"\"Various math-related functions.\"\"\"\n\nimport math\n\n\ndef weight_from_length(*, length: float, diameter: float, density: float) -> float:\n    \"\"\"Calculate the weight of a piece of filament.\n\n    Args:\n        length (float): Filament length in mm\n        diameter (float): Filament diameter in mm\n        density (float): Density of filament material in g/cm3\n\n    Returns:\n        float: Weight in g\n    \"\"\"\n    volume_mm3 = length * math.pi * (diameter / 2) ** 2\n    volume_cm3 = volume_mm3 / 1000\n    return density * volume_cm3", "\n\ndef length_from_weight(*, weight: float, diameter: float, density: float) -> float:\n    \"\"\"Calculate the length of a piece of filament.\n\n    Args:\n        weight (float): Filament weight in g\n        diameter (float): Filament diameter in mm\n        density (float): Density of filament material in g/cm3\n\n    Returns:\n        float: Length in mm\n    \"\"\"\n    volume_cm3 = weight / density\n    volume_mm3 = volume_cm3 * 1000\n    return volume_mm3 / (math.pi * (diameter / 2) ** 2)", ""]}
{"filename": "spoolman/exceptions.py", "chunked_list": ["\"\"\"Various exceptions used.\"\"\"\n\n\nclass ItemNotFoundError(Exception):\n    pass\n\n\nclass ItemDeleteError(Exception):\n    pass\n", "\n\nclass ItemCreateError(Exception):\n    pass\n"]}
{"filename": "spoolman/database/database.py", "chunked_list": ["\"\"\"SQLAlchemy database setup.\"\"\"\n\nimport datetime\nimport logging\nimport shutil\nimport sqlite3\nfrom collections.abc import AsyncGenerator\nfrom os import PathLike\nfrom pathlib import Path\nfrom typing import Optional, Union", "from pathlib import Path\nfrom typing import Optional, Union\n\nfrom scheduler.asyncio.scheduler import Scheduler\nfrom sqlalchemy import URL\nfrom sqlalchemy.ext.asyncio import AsyncEngine, AsyncSession, async_sessionmaker, create_async_engine\n\nfrom spoolman import env\n\nlogger = logging.getLogger(__name__)", "\nlogger = logging.getLogger(__name__)\n\n\ndef get_connection_url() -> URL:\n    \"\"\"Construct the connection URL for the database based on environment variables.\"\"\"\n    db_type = env.get_database_type()\n    host = env.get_host()\n    port = env.get_port()\n    database = env.get_database()\n    query = env.get_query()\n    username = env.get_username()\n    password = env.get_password()\n\n    if db_type is None:\n        db_type = env.DatabaseType.SQLITE\n\n        database = str(env.get_data_dir().joinpath(\"spoolman.db\"))\n        logger.info('No database type specified, using a default SQLite database located at \"%s\"', database)\n    elif db_type is env.DatabaseType.SQLITE:\n        if database is not None:\n            raise ValueError(\"Cannot specify a database name when using SQLite.\")\n\n        database = str(env.get_data_dir().joinpath(\"spoolman.db\"))\n        logger.info('Using SQLite database located at \"%s\"', database)\n    else:\n        logger.info('Connecting to database of type \"%s\" at \"%s:%s\"', db_type, host, port)\n\n    return URL.create(\n        drivername=db_type.to_drivername(),\n        host=host,\n        port=port,\n        database=database,\n        query=query or {},\n        username=username,\n        password=password,\n    )", "\n\nclass Database:\n    connection_url: URL\n    engine: Optional[AsyncEngine]\n    session_maker: Optional[async_sessionmaker[AsyncSession]]\n\n    def __init__(self: \"Database\", connection_url: URL) -> None:\n        \"\"\"Construct the Database wrapper and set config parameters.\"\"\"\n        self.connection_url = connection_url\n\n    def is_file_based_sqlite(self: \"Database\") -> bool:\n        \"\"\"Return True if the database is file based.\"\"\"\n        return (\n            self.connection_url.drivername[:6] == \"sqlite\"\n            and self.connection_url.database is not None\n            and self.connection_url.database != \":memory:\"\n        )\n\n    def connect(self: \"Database\") -> None:\n        \"\"\"Connect to the database.\"\"\"\n        if env.get_logging_level() == logging.DEBUG:\n            logging.getLogger(\"sqlalchemy.engine\").setLevel(logging.INFO)\n\n        connect_args = {}\n        if self.connection_url.drivername == \"sqlite+aiosqlite\":\n            connect_args[\"timeout\"] = 60\n\n        self.engine = create_async_engine(\n            self.connection_url,\n            connect_args=connect_args,\n            pool_pre_ping=True,\n        )\n        self.session_maker = async_sessionmaker(self.engine, autocommit=False, autoflush=True, expire_on_commit=False)\n\n    def backup(self: \"Database\", target_path: Union[str, PathLike[str]]) -> None:\n        \"\"\"Backup the database.\"\"\"\n        if not self.is_file_based_sqlite() or self.connection_url.database is None:\n            return\n\n        logger.info(\"Backing up SQLite database to %s\", target_path)\n\n        def progress(_: int, remaining: int, total: int) -> None:\n            logger.info(\"Copied %d of %d pages.\", total - remaining, total)\n\n        if self.connection_url.database == target_path:\n            raise ValueError(\"Cannot backup database to itself.\")\n        if Path(target_path).exists():\n            raise ValueError(\"Backup target file already exists.\")\n\n        with sqlite3.connect(self.connection_url.database) as src, sqlite3.connect(target_path) as dst:\n            src.backup(dst, pages=1, progress=progress)\n\n        logger.info(\"Backup complete.\")\n\n    def backup_and_rotate(\n        self: \"Database\",\n        backup_folder: Union[str, PathLike[str]],\n        num_backups: int = 5,\n    ) -> Optional[Path]:\n        \"\"\"Backup the database and rotate existing backups.\n\n        Args:\n            backup_folder: The folder to store the backups in.\n            num_backups: The number of backups to keep.\n\n        Returns:\n            The path to the created backup or None if no backup was created.\n        \"\"\"\n        if not self.is_file_based_sqlite() or self.connection_url.database is None:\n            logger.info(\"Skipping backup as the database is not SQLite.\")\n            return None\n\n        backup_folder = Path(backup_folder)\n        backup_folder.mkdir(parents=True, exist_ok=True)\n\n        # Delete oldest backup\n        backup_path = backup_folder.joinpath(f\"spoolman.db.{num_backups}\")\n        if backup_path.exists():\n            logger.info(\"Deleting oldest backup %s\", backup_path)\n            backup_path.unlink()\n\n        # Rotate existing backups\n        for i in range(num_backups - 1, -1, -1):\n            if i == 0:\n                backup_path = backup_folder.joinpath(\"spoolman.db\")\n            else:\n                backup_path = backup_folder.joinpath(f\"spoolman.db.{i}\")\n            if backup_path.exists():\n                logger.debug(\"Rotating backup %s to %s\", backup_path, backup_folder.joinpath(f\"spoolman.db.{i + 1}\"))\n                shutil.move(backup_path, backup_folder.joinpath(f\"spoolman.db.{i + 1}\"))\n\n        # Create new backup\n        backup_path = backup_folder.joinpath(\"spoolman.db\")\n        self.backup(backup_path)\n\n        return backup_path", "\n\n__db: Optional[Database] = None\n\n\ndef setup_db(connection_url: URL) -> None:\n    \"\"\"Connect to the database.\n\n    Args:\n        connection_url: The URL to connect to the database.\n    \"\"\"\n    global __db  # noqa: PLW0603\n    __db = Database(connection_url)\n    __db.connect()", "\n\nasync def backup_global_db(num_backups: int = 5) -> Optional[Path]:\n    \"\"\"Backup the database and rotate existing backups.\n\n    Returns:\n        The path to the created backup or None if no backup was created.\n    \"\"\"\n    if __db is None:\n        raise RuntimeError(\"DB is not setup.\")", "    if __db is None:\n        raise RuntimeError(\"DB is not setup.\")\n    return __db.backup_and_rotate(env.get_data_dir().joinpath(\"backups\"), num_backups=num_backups)\n\n\nasync def _backup_task() -> Optional[Path]:\n    \"\"\"Perform scheduled backup of the database.\"\"\"\n    logger.info(\"Performing scheduled database backup.\")\n    if __db is None:\n        raise RuntimeError(\"DB is not setup.\")", "    if __db is None:\n        raise RuntimeError(\"DB is not setup.\")\n    return __db.backup_and_rotate(env.get_data_dir().joinpath(\"backups\"), num_backups=5)\n\n\ndef schedule_tasks(scheduler: Scheduler) -> None:\n    \"\"\"Schedule tasks to be executed by the provided scheduler.\n\n    Args:\n        scheduler: The scheduler to use for scheduling tasks.\n    \"\"\"\n    if __db is None:\n        raise RuntimeError(\"DB is not setup.\")\n    if not env.is_automatic_backup_enabled():\n        return\n    if \"sqlite\" in __db.connection_url.drivername:\n        logger.info(\"Scheduling automatic database backup for midnight.\")\n        # Schedule for midnight\n        scheduler.daily(datetime.time(hour=0, minute=0, second=0), _backup_task)  # type: ignore[arg-type]", "\n\nasync def get_db_session() -> AsyncGenerator[AsyncSession, None]:\n    \"\"\"Get a DB session to be used with FastAPI's dependency system.\n\n    Yields:\n        The database session.\n    \"\"\"\n    if __db is None or __db.session_maker is None:\n        raise RuntimeError(\"DB is not setup.\")", "    if __db is None or __db.session_maker is None:\n        raise RuntimeError(\"DB is not setup.\")\n    async with __db.session_maker() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception as exc:\n            await session.rollback()\n            raise exc\n        finally:\n            await session.close()", ""]}
{"filename": "spoolman/database/filament.py", "chunked_list": ["\"\"\"Helper functions for interacting with filament database objects.\"\"\"\n\nfrom typing import Optional\n\nfrom sqlalchemy import select\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.orm import contains_eager, joinedload\n\nfrom spoolman.database import models, vendor", "\nfrom spoolman.database import models, vendor\nfrom spoolman.exceptions import ItemDeleteError, ItemNotFoundError\n\n\nasync def create(\n    *,\n    db: AsyncSession,\n    density: float,\n    diameter: float,", "    density: float,\n    diameter: float,\n    name: Optional[str] = None,\n    vendor_id: Optional[int] = None,\n    material: Optional[str] = None,\n    price: Optional[float] = None,\n    weight: Optional[float] = None,\n    spool_weight: Optional[float] = None,\n    article_number: Optional[str] = None,\n    comment: Optional[str] = None,", "    article_number: Optional[str] = None,\n    comment: Optional[str] = None,\n    settings_extruder_temp: Optional[int] = None,\n    settings_bed_temp: Optional[int] = None,\n    color_hex: Optional[str] = None,\n) -> models.Filament:\n    \"\"\"Add a new filament to the database.\"\"\"\n    vendor_item: Optional[models.Vendor] = None  # noqa: FA100\n    if vendor_id is not None:\n        vendor_item = await vendor.get_by_id(db, vendor_id)", "    if vendor_id is not None:\n        vendor_item = await vendor.get_by_id(db, vendor_id)\n\n    db_item = models.Filament(\n        name=name,\n        vendor=vendor_item,\n        material=material,\n        price=price,\n        density=density,\n        diameter=diameter,", "        density=density,\n        diameter=diameter,\n        weight=weight,\n        spool_weight=spool_weight,\n        article_number=article_number,\n        comment=comment,\n        settings_extruder_temp=settings_extruder_temp,\n        settings_bed_temp=settings_bed_temp,\n        color_hex=color_hex,\n    )", "        color_hex=color_hex,\n    )\n    db.add(db_item)\n    await db.flush()\n    return db_item\n\n\nasync def get_by_id(db: AsyncSession, filament_id: int) -> models.Filament:\n    \"\"\"Get a filament object from the database by the unique ID.\"\"\"\n    filament = await db.get(", "    \"\"\"Get a filament object from the database by the unique ID.\"\"\"\n    filament = await db.get(\n        models.Filament,\n        filament_id,\n        options=[joinedload(\"*\")],  # Load all nested objects as well\n    )\n    if filament is None:\n        raise ItemNotFoundError(f\"No filament with ID {filament_id} found.\")\n    return filament\n", "    return filament\n\n\nasync def find(\n    *,\n    db: AsyncSession,\n    vendor_name: Optional[str] = None,\n    vendor_id: Optional[int] = None,\n    name: Optional[str] = None,\n    material: Optional[str] = None,", "    name: Optional[str] = None,\n    material: Optional[str] = None,\n    article_number: Optional[str] = None,\n) -> list[models.Filament]:\n    \"\"\"Find a list of filament objects by search criteria.\"\"\"\n    stmt = (\n        select(models.Filament)\n        .options(contains_eager(models.Filament.vendor))\n        .join(models.Filament.vendor, isouter=True)\n    )\n    if vendor_name is not None:\n        stmt = stmt.where(models.Vendor.name.ilike(f\"%{vendor_name}%\"))", "        .join(models.Filament.vendor, isouter=True)\n    )\n    if vendor_name is not None:\n        stmt = stmt.where(models.Vendor.name.ilike(f\"%{vendor_name}%\"))\n    if vendor_id is not None:\n        stmt = stmt.where(models.Filament.vendor_id == vendor_id)\n    if name is not None:\n        stmt = stmt.where(models.Filament.name.ilike(f\"%{name}%\"))\n    if material is not None:\n        stmt = stmt.where(models.Filament.material.ilike(f\"%{material}%\"))\n    if article_number is not None:\n        stmt = stmt.where(models.Filament.article_number.ilike(f\"%{article_number}%\"))", "    if material is not None:\n        stmt = stmt.where(models.Filament.material.ilike(f\"%{material}%\"))\n    if article_number is not None:\n        stmt = stmt.where(models.Filament.article_number.ilike(f\"%{article_number}%\"))\n\n    rows = await db.execute(stmt)\n    return list(rows.scalars().all())\n\n\nasync def update(", "\nasync def update(\n    *,\n    db: AsyncSession,\n    filament_id: int,\n    data: dict,\n) -> models.Filament:\n    \"\"\"Update the fields of a filament object.\"\"\"\n    filament = await get_by_id(db, filament_id)\n    for k, v in data.items():\n        if k == \"vendor_id\":\n            if v is None:\n                filament.vendor = None\n            else:\n                filament.vendor = await vendor.get_by_id(db, v)\n        else:\n            setattr(filament, k, v)", "    filament = await get_by_id(db, filament_id)\n    for k, v in data.items():\n        if k == \"vendor_id\":\n            if v is None:\n                filament.vendor = None\n            else:\n                filament.vendor = await vendor.get_by_id(db, v)\n        else:\n            setattr(filament, k, v)\n    await db.flush()", "    await db.flush()\n    return filament\n\n\nasync def delete(db: AsyncSession, filament_id: int) -> None:\n    \"\"\"Delete a filament object.\"\"\"\n    filament = await get_by_id(db, filament_id)\n    await db.delete(filament)\n    try:\n        await db.flush()  # Flush immediately so any errors are propagated in this request.\n    except IntegrityError as exc:\n        await db.rollback()\n        raise ItemDeleteError(\"Failed to delete filament.\") from exc", "    try:\n        await db.flush()  # Flush immediately so any errors are propagated in this request.\n    except IntegrityError as exc:\n        await db.rollback()\n        raise ItemDeleteError(\"Failed to delete filament.\") from exc\n"]}
{"filename": "spoolman/database/models.py", "chunked_list": ["\"\"\"SQLAlchemy data models.\"\"\"\n\nfrom datetime import datetime\nfrom typing import Optional\n\nfrom sqlalchemy import ForeignKey, Integer, String\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship\nfrom sqlalchemy.sql import func\n\n\nclass Base(DeclarativeBase):\n    pass", "\n\nclass Base(DeclarativeBase):\n    pass\n\n\nclass Vendor(Base):\n    __tablename__ = \"vendor\"\n\n    id: Mapped[int] = mapped_column(Integer, primary_key=True, index=True)\n    registered: Mapped[datetime] = mapped_column(default=func.now())\n    name: Mapped[str] = mapped_column(String(64))\n    comment: Mapped[Optional[str]] = mapped_column(String(1024))\n    filaments: Mapped[list[\"Filament\"]] = relationship(back_populates=\"vendor\")", "\n\nclass Filament(Base):\n    __tablename__ = \"filament\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    registered: Mapped[datetime] = mapped_column(default=func.now())\n    name: Mapped[Optional[str]] = mapped_column(String(64))\n    vendor_id: Mapped[Optional[int]] = mapped_column(ForeignKey(\"vendor.id\"))\n    vendor: Mapped[Optional[\"Vendor\"]] = relationship(back_populates=\"filaments\")\n    spools: Mapped[list[\"Spool\"]] = relationship(back_populates=\"filament\")\n    material: Mapped[Optional[str]] = mapped_column(String(64))\n    price: Mapped[Optional[float]] = mapped_column()\n    density: Mapped[float] = mapped_column()\n    diameter: Mapped[float] = mapped_column()\n    weight: Mapped[Optional[float]] = mapped_column(comment=\"The filament weight of a full spool (net weight).\")\n    spool_weight: Mapped[Optional[float]] = mapped_column(comment=\"The weight of an empty spool.\")\n    article_number: Mapped[Optional[str]] = mapped_column(String(64))\n    comment: Mapped[Optional[str]] = mapped_column(String(1024))\n    settings_extruder_temp: Mapped[Optional[int]] = mapped_column(comment=\"Overridden extruder temperature.\")\n    settings_bed_temp: Mapped[Optional[int]] = mapped_column(comment=\"Overridden bed temperature.\")\n    color_hex: Mapped[Optional[str]] = mapped_column(String(8))", "\n\nclass Spool(Base):\n    __tablename__ = \"spool\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    registered: Mapped[datetime] = mapped_column(default=func.now())\n    first_used: Mapped[Optional[datetime]] = mapped_column()\n    last_used: Mapped[Optional[datetime]] = mapped_column()\n    filament_id: Mapped[int] = mapped_column(ForeignKey(\"filament.id\"))\n    filament: Mapped[\"Filament\"] = relationship(back_populates=\"spools\")\n    used_weight: Mapped[float] = mapped_column()\n    location: Mapped[Optional[str]] = mapped_column(String(64))\n    lot_nr: Mapped[Optional[str]] = mapped_column(String(64))\n    comment: Mapped[Optional[str]] = mapped_column(String(1024))\n    archived: Mapped[Optional[bool]] = mapped_column()", ""]}
{"filename": "spoolman/database/vendor.py", "chunked_list": ["\"\"\"Helper functions for interacting with vendor database objects.\"\"\"\n\nfrom typing import Optional\n\nfrom sqlalchemy import select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom spoolman.database import models\nfrom spoolman.exceptions import ItemNotFoundError\n", "from spoolman.exceptions import ItemNotFoundError\n\n\nasync def create(\n    *,\n    db: AsyncSession,\n    name: Optional[str] = None,\n    comment: Optional[str] = None,\n) -> models.Vendor:\n    \"\"\"Add a new vendor to the database.\"\"\"", ") -> models.Vendor:\n    \"\"\"Add a new vendor to the database.\"\"\"\n    db_item = models.Vendor(\n        name=name,\n        comment=comment,\n    )\n    db.add(db_item)\n    await db.flush()\n    return db_item\n", "    return db_item\n\n\nasync def get_by_id(db: AsyncSession, vendor_id: int) -> models.Vendor:\n    \"\"\"Get a vendor object from the database by the unique ID.\"\"\"\n    vendor = await db.get(models.Vendor, vendor_id)\n    if vendor is None:\n        raise ItemNotFoundError(f\"No vendor with ID {vendor_id} found.\")\n    return vendor\n", "    return vendor\n\n\nasync def find(\n    *,\n    db: AsyncSession,\n    name: Optional[str] = None,\n) -> list[models.Vendor]:\n    \"\"\"Find a list of vendor objects by search criteria.\"\"\"\n    stmt = select(models.Vendor)\n    if name is not None:\n        stmt = stmt.where(models.Vendor.name.ilike(f\"%{name}%\"))", "    \"\"\"Find a list of vendor objects by search criteria.\"\"\"\n    stmt = select(models.Vendor)\n    if name is not None:\n        stmt = stmt.where(models.Vendor.name.ilike(f\"%{name}%\"))\n\n    rows = await db.execute(stmt)\n    return list(rows.scalars().all())\n\n\nasync def update(", "\nasync def update(\n    *,\n    db: AsyncSession,\n    vendor_id: int,\n    data: dict,\n) -> models.Vendor:\n    \"\"\"Update the fields of a vendor object.\"\"\"\n    vendor = await get_by_id(db, vendor_id)\n    for k, v in data.items():\n        setattr(vendor, k, v)", "    vendor = await get_by_id(db, vendor_id)\n    for k, v in data.items():\n        setattr(vendor, k, v)\n    await db.flush()\n    return vendor\n\n\nasync def delete(db: AsyncSession, vendor_id: int) -> None:\n    \"\"\"Delete a vendor object.\"\"\"\n    vendor = await get_by_id(db, vendor_id)", "    \"\"\"Delete a vendor object.\"\"\"\n    vendor = await get_by_id(db, vendor_id)\n    await db.delete(vendor)\n"]}
{"filename": "spoolman/database/__init__.py", "chunked_list": [""]}
{"filename": "spoolman/database/spool.py", "chunked_list": ["\"\"\"Helper functions for interacting with spool database objects.\"\"\"\n\nfrom datetime import datetime, timezone\nfrom typing import Optional\n\nimport sqlalchemy\nfrom sqlalchemy import case\nfrom sqlalchemy.exc import NoResultFound\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.orm import contains_eager, joinedload", "from sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.orm import contains_eager, joinedload\n\nfrom spoolman.database import filament, models\nfrom spoolman.exceptions import ItemCreateError, ItemNotFoundError\nfrom spoolman.math import weight_from_length\n\n\ndef utc_timezone_naive(dt: datetime) -> datetime:\n    \"\"\"Convert a datetime object to UTC and remove timezone info.\"\"\"\n    return dt.astimezone(tz=timezone.utc).replace(tzinfo=None)", "def utc_timezone_naive(dt: datetime) -> datetime:\n    \"\"\"Convert a datetime object to UTC and remove timezone info.\"\"\"\n    return dt.astimezone(tz=timezone.utc).replace(tzinfo=None)\n\n\nasync def create(\n    *,\n    db: AsyncSession,\n    filament_id: int,\n    remaining_weight: Optional[float] = None,", "    filament_id: int,\n    remaining_weight: Optional[float] = None,\n    used_weight: Optional[float] = None,\n    first_used: Optional[datetime] = None,\n    last_used: Optional[datetime] = None,\n    location: Optional[str] = None,\n    lot_nr: Optional[str] = None,\n    comment: Optional[str] = None,\n    archived: bool = False,\n) -> models.Spool:", "    archived: bool = False,\n) -> models.Spool:\n    \"\"\"Add a new spool to the database. Leave weight empty to assume full spool.\"\"\"\n    filament_item = await filament.get_by_id(db, filament_id)\n    if used_weight is None:\n        if remaining_weight is not None:\n            if filament_item.weight is None:\n                raise ItemCreateError(\"remaining_weight can only be used if the filament type has a weight set.\")\n            used_weight = max(filament_item.weight - remaining_weight, 0)\n        else:\n            used_weight = 0", "\n    # Convert datetime values to UTC and remove timezone info\n    if first_used is not None:\n        first_used = utc_timezone_naive(first_used)\n    if last_used is not None:\n        last_used = utc_timezone_naive(last_used)\n\n    db_item = models.Spool(\n        filament=filament_item,\n        used_weight=used_weight,", "        filament=filament_item,\n        used_weight=used_weight,\n        first_used=first_used,\n        last_used=last_used,\n        location=location,\n        lot_nr=lot_nr,\n        comment=comment,\n        archived=archived,\n    )\n    db.add(db_item)", "    )\n    db.add(db_item)\n    await db.flush()\n    return db_item\n\n\nasync def get_by_id(db: AsyncSession, spool_id: int) -> models.Spool:\n    \"\"\"Get a spool object from the database by the unique ID.\"\"\"\n    spool = await db.get(\n        models.Spool,", "    spool = await db.get(\n        models.Spool,\n        spool_id,\n        options=[joinedload(\"*\")],  # Load all nested objects as well\n    )\n    if spool is None:\n        raise ItemNotFoundError(f\"No spool with ID {spool_id} found.\")\n    return spool\n\n", "\n\nasync def find(\n    *,\n    db: AsyncSession,\n    filament_name: Optional[str] = None,\n    filament_id: Optional[int] = None,\n    filament_material: Optional[str] = None,\n    vendor_name: Optional[str] = None,\n    vendor_id: Optional[int] = None,", "    vendor_name: Optional[str] = None,\n    vendor_id: Optional[int] = None,\n    location: Optional[str] = None,\n    lot_nr: Optional[str] = None,\n    allow_archived: bool = False,\n) -> list[models.Spool]:\n    \"\"\"Find a list of spool objects by search criteria.\"\"\"\n    stmt = (\n        sqlalchemy.select(models.Spool)\n        .join(models.Spool.filament, isouter=True)", "        sqlalchemy.select(models.Spool)\n        .join(models.Spool.filament, isouter=True)\n        .join(models.Filament.vendor, isouter=True)\n        .options(contains_eager(models.Spool.filament).contains_eager(models.Filament.vendor))\n    )\n    if filament_name is not None:\n        stmt = stmt.where(models.Filament.name.ilike(f\"%{filament_name}%\"))\n    if filament_id is not None:\n        stmt = stmt.where(models.Spool.filament_id == filament_id)\n    if filament_material is not None:\n        stmt = stmt.where(models.Filament.material.ilike(f\"%{filament_material}%\"))", "    if filament_material is not None:\n        stmt = stmt.where(models.Filament.material.ilike(f\"%{filament_material}%\"))\n    if vendor_name is not None:\n        stmt = stmt.where(models.Vendor.name.ilike(f\"%{vendor_name}%\"))\n    if vendor_id is not None:\n        stmt = stmt.where(models.Filament.vendor_id == vendor_id)\n    if location is not None:\n        stmt = stmt.where(models.Spool.location.ilike(f\"%{location}%\"))\n    if lot_nr is not None:\n        stmt = stmt.where(models.Spool.lot_nr.ilike(f\"%{lot_nr}%\"))\n    if not allow_archived:\n        # Since the archived field is nullable, and default is false, we need to check for both false or null\n        stmt = stmt.where(\n            sqlalchemy.or_(\n                models.Spool.archived.is_(False),  # noqa: FBT003\n                models.Spool.archived.is_(None),\n            ),\n        )", "    if lot_nr is not None:\n        stmt = stmt.where(models.Spool.lot_nr.ilike(f\"%{lot_nr}%\"))\n    if not allow_archived:\n        # Since the archived field is nullable, and default is false, we need to check for both false or null\n        stmt = stmt.where(\n            sqlalchemy.or_(\n                models.Spool.archived.is_(False),  # noqa: FBT003\n                models.Spool.archived.is_(None),\n            ),\n        )", "\n    rows = await db.execute(stmt)\n    return list(rows.scalars().all())\n\n\nasync def update(\n    *,\n    db: AsyncSession,\n    spool_id: int,\n    data: dict,", "    spool_id: int,\n    data: dict,\n) -> models.Spool:\n    \"\"\"Update the fields of a spool object.\"\"\"\n    spool = await get_by_id(db, spool_id)\n    for k, v in data.items():\n        if k == \"filament_id\":\n            spool.filament = await filament.get_by_id(db, v)\n        elif k == \"remaining_weight\":\n            if spool.filament.weight is None:\n                raise ItemCreateError(\"remaining_weight can only be used if the filament type has a weight set.\")\n            spool.used_weight = max(spool.filament.weight - v, 0)\n        elif isinstance(v, datetime):\n            setattr(spool, k, utc_timezone_naive(v))\n        else:\n            setattr(spool, k, v)", "    await db.flush()\n    return spool\n\n\nasync def delete(db: AsyncSession, spool_id: int) -> None:\n    \"\"\"Delete a spool object.\"\"\"\n    spool = await get_by_id(db, spool_id)\n    await db.delete(spool)\n\n", "\n\nasync def use_weight_safe(db: AsyncSession, spool_id: int, weight: float) -> None:\n    \"\"\"Consume filament from a spool by weight in a way that is safe against race conditions.\n\n    Args:\n        db (AsyncSession): Database session\n        spool_id (int): Spool ID\n        weight (float): Filament weight to consume, in grams\n    \"\"\"", "        weight (float): Filament weight to consume, in grams\n    \"\"\"\n    await db.execute(\n        sqlalchemy.update(models.Spool)\n        .where(models.Spool.id == spool_id)\n        .values(\n            used_weight=case(\n                (models.Spool.used_weight + weight >= 0.0, models.Spool.used_weight + weight),  # noqa: PLR2004\n                else_=0.0,  # Set used_weight to 0 if the result would be negative\n            ),", "                else_=0.0,  # Set used_weight to 0 if the result would be negative\n            ),\n        ),\n    )\n\n\nasync def use_weight(db: AsyncSession, spool_id: int, weight: float) -> models.Spool:\n    \"\"\"Consume filament from a spool by weight.\n\n    Increases the used_weight attribute of the spool.", "\n    Increases the used_weight attribute of the spool.\n    Updates the first_used and last_used attributes where appropriate.\n\n    Args:\n        db (AsyncSession): Database session\n        spool_id (int): Spool ID\n        weight (float): Filament weight to consume, in grams\n\n    Returns:", "\n    Returns:\n        models.Spool: Updated spool object\n    \"\"\"\n    await use_weight_safe(db, spool_id, weight)\n\n    spool = await get_by_id(db, spool_id)\n\n    if spool.first_used is None:\n        spool.first_used = datetime.utcnow()", "    if spool.first_used is None:\n        spool.first_used = datetime.utcnow()\n    spool.last_used = datetime.utcnow()\n\n    await db.flush()\n    return spool\n\n\nasync def use_length(db: AsyncSession, spool_id: int, length: float) -> models.Spool:\n    \"\"\"Consume filament from a spool by length.", "async def use_length(db: AsyncSession, spool_id: int, length: float) -> models.Spool:\n    \"\"\"Consume filament from a spool by length.\n\n    Increases the used_weight attribute of the spool.\n    Updates the first_used and last_used attributes where appropriate.\n\n    Args:\n        db (AsyncSession): Database session\n        spool_id (int): Spool ID\n        length (float): Length of filament to consume, in mm", "        spool_id (int): Spool ID\n        length (float): Length of filament to consume, in mm\n\n    Returns:\n        models.Spool: Updated spool object\n    \"\"\"\n    # Get filament diameter and density\n    result = await db.execute(\n        sqlalchemy.select(models.Filament.diameter, models.Filament.density)\n        .join(models.Spool, models.Spool.filament_id == models.Filament.id)", "        sqlalchemy.select(models.Filament.diameter, models.Filament.density)\n        .join(models.Spool, models.Spool.filament_id == models.Filament.id)\n        .where(models.Spool.id == spool_id),\n    )\n    try:\n        filament_info = result.one()\n    except NoResultFound as exc:\n        raise ItemNotFoundError(\"Filament not found for spool.\") from exc\n\n    # Calculate and use weight", "\n    # Calculate and use weight\n    weight = weight_from_length(\n        length=length,\n        diameter=filament_info[0],\n        density=filament_info[1],\n    )\n    await use_weight_safe(db, spool_id, weight)\n\n    # Get spool with new weight and update first_used and last_used", "\n    # Get spool with new weight and update first_used and last_used\n    spool = await get_by_id(db, spool_id)\n\n    if spool.first_used is None:\n        spool.first_used = datetime.utcnow()\n    spool.last_used = datetime.utcnow()\n\n    await db.flush()\n    return spool", "    await db.flush()\n    return spool\n"]}
{"filename": "spoolman/api/__init__.py", "chunked_list": [""]}
{"filename": "spoolman/api/v1/filament.py", "chunked_list": ["\"\"\"Filament related endpoints.\"\"\"\n\nimport logging\nfrom typing import Annotated, Optional\n\nfrom fastapi import APIRouter, Depends, Query\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field, validator\nfrom pydantic.error_wrappers import ErrorWrapper", "from pydantic import BaseModel, Field, validator\nfrom pydantic.error_wrappers import ErrorWrapper\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom spoolman.api.v1.models import Filament, Message\nfrom spoolman.database import filament\nfrom spoolman.database.database import get_db_session\nfrom spoolman.exceptions import ItemDeleteError\n\nlogger = logging.getLogger(__name__)", "\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter(\n    prefix=\"/filament\",\n    tags=[\"filament\"],\n)\n\n# ruff: noqa: D103, B008\n", "# ruff: noqa: D103, B008\n\n\nclass FilamentParameters(BaseModel):\n    name: Optional[str] = Field(\n        max_length=64,\n        description=(\n            \"Filament name, to distinguish this filament type among others from the same vendor.\"\n            \"Should contain its color for example.\"\n        ),\n        example=\"PolyTerra\u2122 Charcoal Black\",\n    )\n    vendor_id: Optional[int] = Field(description=\"The ID of the vendor of this filament type.\")\n    material: Optional[str] = Field(\n        max_length=64,\n        description=\"The material of this filament, e.g. PLA.\",\n        example=\"PLA\",\n    )\n    price: Optional[float] = Field(\n        ge=0,\n        description=\"The price of this filament in the system configured currency.\",\n        example=20.0,\n    )\n    density: float = Field(gt=0, description=\"The density of this filament in g/cm3.\", example=1.24)\n    diameter: float = Field(gt=0, description=\"The diameter of this filament in mm.\", example=1.75)\n    weight: Optional[float] = Field(\n        gt=0,\n        description=\"The weight of the filament in a full spool, in grams. (net weight)\",\n        example=1000,\n    )\n    spool_weight: Optional[float] = Field(gt=0, description=\"The empty spool weight, in grams.\", example=140)\n    article_number: Optional[str] = Field(\n        max_length=64,\n        description=\"Vendor article number, e.g. EAN, QR code, etc.\",\n        example=\"PM70820\",\n    )\n    comment: Optional[str] = Field(\n        max_length=1024,\n        description=\"Free text comment about this filament type.\",\n        example=\"\",\n    )\n    settings_extruder_temp: Optional[int] = Field(\n        ge=0,\n        description=\"Overridden extruder temperature, in \u00b0C.\",\n        example=210,\n    )\n    settings_bed_temp: Optional[int] = Field(\n        ge=0,\n        description=\"Overridden bed temperature, in \u00b0C.\",\n        example=60,\n    )\n    color_hex: Optional[str] = Field(\n        description=\"Hexadecimal color code of the filament, e.g. FF0000 for red. Supports alpha channel at the end.\",\n        example=\"FF0000\",\n    )\n\n    @validator(\"color_hex\")\n    @classmethod\n    def color_hex_validator(cls, v: Optional[str]) -> Optional[str]:  # noqa: ANN102\n        \"\"\"Validate the color_hex field.\"\"\"\n        if not v:\n            return None\n        if v.startswith(\"#\"):\n            v = v[1:]\n        v = v.upper()\n\n        for c in v:\n            if c not in \"0123456789ABCDEF\":\n                raise ValueError(\"Invalid character in color code.\")\n\n        if len(v) not in (6, 8):\n            raise ValueError(\"Color code must be 6 or 8 characters long.\")\n\n        return v", "\n\nclass FilamentUpdateParameters(FilamentParameters):\n    density: Optional[float] = Field(gt=0, description=\"The density of this filament in g/cm3.\", example=1.24)\n    diameter: Optional[float] = Field(gt=0, description=\"The diameter of this filament in mm.\", example=1.75)\n\n\n@router.get(\n    \"\",\n    name=\"Find filaments\",", "    \"\",\n    name=\"Find filaments\",\n    description=\"Get a list of filaments that matches the search query.\",\n    response_model_exclude_none=True,\n)\nasync def find(\n    *,\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    vendor_name: Optional[str] = Query(\n        default=None,", "    vendor_name: Optional[str] = Query(\n        default=None,\n        title=\"Vendor Name\",\n        description=\"Partial case-insensitive search term for the filament vendor name.\",\n    ),\n    vendor_id: Optional[int] = Query(\n        default=None,\n        title=\"Vendor ID\",\n        description=\"Match an exact vendor ID.\",\n    ),", "        description=\"Match an exact vendor ID.\",\n    ),\n    name: Optional[str] = Query(\n        default=None,\n        title=\"Filament Name\",\n        description=\"Partial case-insensitive search term for the filament name.\",\n    ),\n    material: Optional[str] = Query(\n        default=None,\n        title=\"Filament Material\",", "        default=None,\n        title=\"Filament Material\",\n        description=\"Partial case-insensitive search term for the filament material.\",\n    ),\n    article_number: Optional[str] = Query(\n        default=None,\n        title=\"Filament Article Number\",\n        description=\"Partial case-insensitive search term for the filament article number.\",\n    ),\n) -> list[Filament]:", "    ),\n) -> list[Filament]:\n    db_items = await filament.find(\n        db=db,\n        vendor_name=vendor_name,\n        vendor_id=vendor_id,\n        name=name,\n        material=material,\n        article_number=article_number,\n    )", "        article_number=article_number,\n    )\n    return [Filament.from_db(db_item) for db_item in db_items]\n\n\n@router.get(\n    \"/{filament_id}\",\n    name=\"Get filament\",\n    description=\"Get a specific filament.\",\n    response_model_exclude_none=True,", "    description=\"Get a specific filament.\",\n    response_model_exclude_none=True,\n    responses={404: {\"model\": Message}},\n)\nasync def get(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    filament_id: int,\n) -> Filament:\n    db_item = await filament.get_by_id(db, filament_id)\n    return Filament.from_db(db_item)", "    db_item = await filament.get_by_id(db, filament_id)\n    return Filament.from_db(db_item)\n\n\n@router.post(\n    \"\",\n    name=\"Add filament\",\n    description=\"Add a new filament to the database.\",\n    response_model_exclude_none=True,\n)", "    response_model_exclude_none=True,\n)\nasync def create(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    body: FilamentParameters,\n) -> Filament:\n    db_item = await filament.create(\n        db=db,\n        density=body.density,\n        diameter=body.diameter,", "        density=body.density,\n        diameter=body.diameter,\n        name=body.name,\n        vendor_id=body.vendor_id,\n        material=body.material,\n        price=body.price,\n        weight=body.weight,\n        spool_weight=body.spool_weight,\n        article_number=body.article_number,\n        comment=body.comment,", "        article_number=body.article_number,\n        comment=body.comment,\n        settings_extruder_temp=body.settings_extruder_temp,\n        settings_bed_temp=body.settings_bed_temp,\n        color_hex=body.color_hex,\n    )\n\n    return Filament.from_db(db_item)\n\n", "\n\n@router.patch(\n    \"/{filament_id}\",\n    name=\"Update filament\",\n    description=\"Update any attribute of a filament. Only fields specified in the request will be affected.\",\n    response_model_exclude_none=True,\n    responses={404: {\"model\": Message}},\n)\nasync def update(", ")\nasync def update(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    filament_id: int,\n    body: FilamentUpdateParameters,\n) -> Filament:\n    patch_data = body.dict(exclude_unset=True)\n\n    if \"density\" in patch_data and body.density is None:\n        raise RequestValidationError([ErrorWrapper(ValueError(\"density cannot be unset\"), (\"query\", \"density\"))])\n    if \"diameter\" in patch_data and body.diameter is None:\n        raise RequestValidationError([ErrorWrapper(ValueError(\"diameter cannot be unset\"), (\"query\", \"diameter\"))])", "    if \"density\" in patch_data and body.density is None:\n        raise RequestValidationError([ErrorWrapper(ValueError(\"density cannot be unset\"), (\"query\", \"density\"))])\n    if \"diameter\" in patch_data and body.diameter is None:\n        raise RequestValidationError([ErrorWrapper(ValueError(\"diameter cannot be unset\"), (\"query\", \"diameter\"))])\n\n    db_item = await filament.update(\n        db=db,\n        filament_id=filament_id,\n        data=patch_data,\n    )", "        data=patch_data,\n    )\n\n    return Filament.from_db(db_item)\n\n\n@router.delete(\n    \"/{filament_id}\",\n    name=\"Delete filament\",\n    description=\"Delete a filament.\",", "    name=\"Delete filament\",\n    description=\"Delete a filament.\",\n    response_model=Message,\n    responses={\n        403: {\"model\": Message},\n        404: {\"model\": Message},\n    },\n)\nasync def delete(  # noqa: ANN201\n    db: Annotated[AsyncSession, Depends(get_db_session)],", "async def delete(  # noqa: ANN201\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    filament_id: int,\n):\n    try:\n        await filament.delete(db, filament_id)\n    except ItemDeleteError:\n        logger.exception(\"Failed to delete filament.\")\n        return JSONResponse(\n            status_code=403,\n            content={\"message\": \"Failed to delete filament, see server logs for more information.\"},\n        )", "    return Message(message=\"Success!\")\n"]}
{"filename": "spoolman/api/v1/models.py", "chunked_list": ["\"\"\"Pydantic data models for typing the FastAPI request/responses.\"\"\"\n\nfrom datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field\n\nfrom spoolman.database import models\nfrom spoolman.math import length_from_weight\n", "from spoolman.math import length_from_weight\n\n\nclass Message(BaseModel):\n    message: str = Field()\n\n\nclass Vendor(BaseModel):\n    id: int = Field(description=\"Unique internal ID of this vendor.\")\n    registered: datetime = Field(description=\"When the vendor was registered in the database. UTC Timezone.\")\n    name: str = Field(max_length=64, description=\"Vendor name.\", example=\"Polymaker\")\n    comment: Optional[str] = Field(max_length=1024, description=\"Free text comment about this vendor.\", example=\"\")\n\n    @staticmethod\n    def from_db(item: models.Vendor) -> \"Vendor\":\n        \"\"\"Create a new Pydantic vendor object from a database vendor object.\"\"\"\n        return Vendor(\n            id=item.id,\n            registered=item.registered,\n            name=item.name,\n            comment=item.comment,\n        )", "\n\nclass Filament(BaseModel):\n    id: int = Field(description=\"Unique internal ID of this filament type.\")\n    registered: datetime = Field(description=\"When the filament was registered in the database. UTC Timezone.\")\n    name: Optional[str] = Field(\n        max_length=64,\n        description=(\n            \"Filament name, to distinguish this filament type among others from the same vendor.\"\n            \"Should contain its color for example.\"\n        ),\n        example=\"PolyTerra\u2122 Charcoal Black\",\n    )\n    vendor: Optional[Vendor] = Field(description=\"The vendor of this filament type.\")\n    material: Optional[str] = Field(\n        max_length=64,\n        description=\"The material of this filament, e.g. PLA.\",\n        example=\"PLA\",\n    )\n    price: Optional[float] = Field(\n        ge=0,\n        description=\"The price of this filament in the system configured currency.\",\n        example=20.0,\n    )\n    density: float = Field(gt=0, description=\"The density of this filament in g/cm3.\", example=1.24)\n    diameter: float = Field(gt=0, description=\"The diameter of this filament in mm.\", example=1.75)\n    weight: Optional[float] = Field(\n        gt=0,\n        description=\"The weight of the filament in a full spool, in grams.\",\n        example=1000,\n    )\n    spool_weight: Optional[float] = Field(gt=0, description=\"The empty spool weight, in grams.\", example=140)\n    article_number: Optional[str] = Field(\n        max_length=64,\n        description=\"Vendor article number, e.g. EAN, QR code, etc.\",\n        example=\"PM70820\",\n    )\n    comment: Optional[str] = Field(\n        max_length=1024,\n        description=\"Free text comment about this filament type.\",\n        example=\"\",\n    )\n    settings_extruder_temp: Optional[int] = Field(\n        ge=0,\n        description=\"Overridden extruder temperature, in \u00b0C.\",\n        example=210,\n    )\n    settings_bed_temp: Optional[int] = Field(\n        ge=0,\n        description=\"Overridden bed temperature, in \u00b0C.\",\n        example=60,\n    )\n    color_hex: Optional[str] = Field(\n        min_length=6,\n        max_length=8,\n        description=\"Hexadecimal color code of the filament, e.g. FF0000 for red. Supports alpha channel at the end.\",\n        example=\"FF0000\",\n    )\n\n    @staticmethod\n    def from_db(item: models.Filament) -> \"Filament\":\n        \"\"\"Create a new Pydantic filament object from a database filament object.\"\"\"\n        return Filament(\n            id=item.id,\n            registered=item.registered,\n            name=item.name,\n            vendor=Vendor.from_db(item.vendor) if item.vendor is not None else None,\n            material=item.material,\n            price=item.price,\n            density=item.density,\n            diameter=item.diameter,\n            weight=item.weight,\n            spool_weight=item.spool_weight,\n            article_number=item.article_number,\n            comment=item.comment,\n            settings_extruder_temp=item.settings_extruder_temp,\n            settings_bed_temp=item.settings_bed_temp,\n            color_hex=item.color_hex,\n        )", "\n\nclass Spool(BaseModel):\n    id: int = Field(description=\"Unique internal ID of this spool of filament.\")\n    registered: datetime = Field(description=\"When the spool was registered in the database. UTC Timezone.\")\n    first_used: Optional[datetime] = Field(description=\"First logged occurence of spool usage. UTC Timezone.\")\n    last_used: Optional[datetime] = Field(description=\"Last logged occurence of spool usage. UTC Timezone.\")\n    filament: Filament = Field(description=\"The filament type of this spool.\")\n    remaining_weight: Optional[float] = Field(\n        default=None,\n        ge=0,\n        description=(\n            \"Estimated remaining weight of filament on the spool in grams. \"\n            \"Only set if the filament type has a weight set.\"\n        ),\n        example=500.6,\n    )\n    used_weight: float = Field(ge=0, description=\"Consumed weight of filament from the spool in grams.\", example=500.3)\n    remaining_length: Optional[float] = Field(\n        default=None,\n        ge=0,\n        description=(\n            \"Estimated remaining length of filament on the spool in millimeters.\"\n            \" Only set if the filament type has a weight set.\"\n        ),\n        example=5612.4,\n    )\n    used_length: float = Field(\n        ge=0,\n        description=\"Consumed length of filament from the spool in millimeters.\",\n        example=50.7,\n    )\n    location: Optional[str] = Field(max_length=64, description=\"Where this spool can be found.\", example=\"Shelf A\")\n    lot_nr: Optional[str] = Field(\n        max_length=64,\n        description=\"Vendor manufacturing lot/batch number of the spool.\",\n        example=\"52342\",\n    )\n    comment: Optional[str] = Field(\n        max_length=1024,\n        description=\"Free text comment about this specific spool.\",\n        example=\"\",\n    )\n    archived: bool = Field(description=\"Whether this spool is archived and should not be used anymore.\")\n\n    @staticmethod\n    def from_db(item: models.Spool) -> \"Spool\":\n        \"\"\"Create a new Pydantic spool object from a database spool object.\"\"\"\n        filament = Filament.from_db(item.filament)\n\n        remaining_weight: Optional[float] = None  # noqa: FA100\n        remaining_length: Optional[float] = None  # noqa: FA100\n        if filament.weight is not None:\n            remaining_weight = max(filament.weight - item.used_weight, 0)\n            remaining_length = length_from_weight(\n                weight=remaining_weight,\n                density=filament.density,\n                diameter=filament.diameter,\n            )\n\n        used_length = length_from_weight(\n            weight=item.used_weight,\n            density=filament.density,\n            diameter=filament.diameter,\n        )\n\n        return Spool(\n            id=item.id,\n            registered=item.registered,\n            first_used=item.first_used,\n            last_used=item.last_used,\n            filament=filament,\n            used_weight=item.used_weight,\n            used_length=used_length,\n            remaining_weight=remaining_weight,\n            remaining_length=remaining_length,\n            location=item.location,\n            lot_nr=item.lot_nr,\n            comment=item.comment,\n            archived=item.archived if item.archived is not None else False,\n        )", "\n\nclass Info(BaseModel):\n    version: str = Field(example=\"0.7.0\")\n    debug_mode: bool = Field(example=False)\n    automatic_backups: bool = Field(example=True)\n    data_dir: str = Field(example=\"/home/app/.local/share/spoolman\")\n    backups_dir: str = Field(example=\"/home/app/.local/share/spoolman/backups\")\n    db_type: str = Field(example=\"sqlite\")\n", "\n\nclass HealthCheck(BaseModel):\n    status: str = Field(example=\"healthy\")\n\n\nclass BackupResponse(BaseModel):\n    path: str = Field(\n        default=None,\n        description=\"Path to the created backup file.\",\n        example=\"/home/app/.local/share/spoolman/backups/spoolman.db\",\n    )", ""]}
{"filename": "spoolman/api/v1/vendor.py", "chunked_list": ["\"\"\"Vendor related endpoints.\"\"\"\n\nfrom typing import Annotated, Optional\n\nfrom fastapi import APIRouter, Depends, Query\nfrom fastapi.exceptions import RequestValidationError\nfrom pydantic import BaseModel, Field\nfrom pydantic.error_wrappers import ErrorWrapper\nfrom sqlalchemy.ext.asyncio import AsyncSession\n", "from sqlalchemy.ext.asyncio import AsyncSession\n\nfrom spoolman.api.v1.models import Message, Vendor\nfrom spoolman.database import vendor\nfrom spoolman.database.database import get_db_session\n\nrouter = APIRouter(\n    prefix=\"/vendor\",\n    tags=[\"vendor\"],\n)", "    tags=[\"vendor\"],\n)\n\n# ruff: noqa: D103,B008\n\n\nclass VendorParameters(BaseModel):\n    name: str = Field(max_length=64, description=\"Vendor name.\", example=\"Polymaker\")\n    comment: Optional[str] = Field(\n        max_length=1024,\n        description=\"Free text comment about this vendor.\",\n        example=\"\",\n    )", "\n\nclass VendorUpdateParameters(VendorParameters):\n    name: Optional[str] = Field(max_length=64, description=\"Vendor name.\", example=\"Polymaker\")\n    comment: Optional[str] = Field(\n        max_length=1024,\n        description=\"Free text comment about this vendor.\",\n        example=\"\",\n    )\n", "\n\n@router.get(\n    \"\",\n    name=\"Find vendor\",\n    description=\"Get a list of vendors that matches the search query.\",\n    response_model_exclude_none=True,\n)\nasync def find(\n    db: Annotated[AsyncSession, Depends(get_db_session)],", "async def find(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    name: Optional[str] = Query(\n        default=None,\n        title=\"Vendor Name\",\n        description=\"Partial case-insensitive search term for the vendor name.\",\n    ),\n) -> list[Vendor]:\n    db_items = await vendor.find(\n        db=db,", "    db_items = await vendor.find(\n        db=db,\n        name=name,\n    )\n    return [Vendor.from_db(db_item) for db_item in db_items]\n\n\n@router.get(\n    \"/{vendor_id}\",\n    name=\"Get vendor\",", "    \"/{vendor_id}\",\n    name=\"Get vendor\",\n    description=\"Get a specific vendor.\",\n    response_model_exclude_none=True,\n    responses={404: {\"model\": Message}},\n)\nasync def get(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    vendor_id: int,\n) -> Vendor:", "    vendor_id: int,\n) -> Vendor:\n    db_item = await vendor.get_by_id(db, vendor_id)\n    return Vendor.from_db(db_item)\n\n\n@router.post(\n    \"\",\n    name=\"Add vendor\",\n    description=\"Add a new vendor to the database.\",", "    name=\"Add vendor\",\n    description=\"Add a new vendor to the database.\",\n    response_model_exclude_none=True,\n)\nasync def create(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    body: VendorParameters,\n) -> Vendor:\n    db_item = await vendor.create(\n        db=db,", "    db_item = await vendor.create(\n        db=db,\n        name=body.name,\n        comment=body.comment,\n    )\n\n    return Vendor.from_db(db_item)\n\n\n@router.patch(", "\n@router.patch(\n    \"/{vendor_id}\",\n    name=\"Update vendor\",\n    description=\"Update any attribute of a vendor. Only fields specified in the request will be affected.\",\n    response_model_exclude_none=True,\n    responses={404: {\"model\": Message}},\n)\nasync def update(\n    db: Annotated[AsyncSession, Depends(get_db_session)],", "async def update(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    vendor_id: int,\n    body: VendorUpdateParameters,\n) -> Vendor:\n    patch_data = body.dict(exclude_unset=True)\n\n    if \"name\" in patch_data and body.name is None:\n        raise RequestValidationError([ErrorWrapper(ValueError(\"name cannot be unset\"), (\"query\", \"name\"))])\n", "\n    db_item = await vendor.update(\n        db=db,\n        vendor_id=vendor_id,\n        data=patch_data,\n    )\n\n    return Vendor.from_db(db_item)\n\n", "\n\n@router.delete(\n    \"/{vendor_id}\",\n    name=\"Delete vendor\",\n    description=(\n        \"Delete a vendor. The vendor attribute of any filaments who refer to the deleted vendor will be cleared.\"\n    ),\n    responses={404: {\"model\": Message}},\n)", "    responses={404: {\"model\": Message}},\n)\nasync def delete(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    vendor_id: int,\n) -> Message:\n    await vendor.delete(db, vendor_id)\n    return Message(message=\"Success!\")\n", ""]}
{"filename": "spoolman/api/v1/router.py", "chunked_list": ["\"\"\"Router setup for the v1 version of the API.\"\"\"\n\n# ruff: noqa: D103\n\nimport logging\n\nfrom fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\nfrom starlette.requests import Request\nfrom starlette.responses import Response", "from starlette.requests import Request\nfrom starlette.responses import Response\n\nfrom spoolman import env\nfrom spoolman.database.database import backup_global_db\nfrom spoolman.exceptions import ItemNotFoundError\n\nfrom . import filament, models, spool, vendor\n\nlogger = logging.getLogger(__name__)", "\nlogger = logging.getLogger(__name__)\n\napp = FastAPI(\n    title=\"Spoolman REST API v1\",\n    version=\"1.0.0\",\n    root_path_in_servers=False,\n)\n\n", "\n\n@app.exception_handler(ItemNotFoundError)\nasync def itemnotfounderror_exception_handler(_request: Request, exc: ItemNotFoundError) -> Response:\n    logger.debug(exc, exc_info=True)\n    return JSONResponse(\n        status_code=404,\n        content={\"message\": exc.args[0]},\n    )\n", "    )\n\n\n# Add a general info endpoint\n@app.get(\"/info\")\nasync def info() -> models.Info:\n    \"\"\"Return general info about the API.\"\"\"\n    return models.Info(\n        version=env.get_version(),\n        debug_mode=env.is_debug_mode(),", "        version=env.get_version(),\n        debug_mode=env.is_debug_mode(),\n        automatic_backups=env.is_automatic_backup_enabled(),\n        data_dir=str(env.get_data_dir().resolve()),\n        backups_dir=str(env.get_backups_dir().resolve()),\n        db_type=str(env.get_database_type() or \"sqlite\"),\n    )\n\n\n# Add health check endpoint", "\n# Add health check endpoint\n@app.get(\"/health\")\nasync def health() -> models.HealthCheck:\n    \"\"\"Return a health check.\"\"\"\n    return models.HealthCheck(status=\"healthy\")\n\n\n# Add endpoint for triggering a db backup\n@app.post(", "# Add endpoint for triggering a db backup\n@app.post(\n    \"/backup\",\n    description=\"Trigger a database backup. Only applicable for SQLite databases.\",\n    response_model=models.BackupResponse,\n    responses={500: {\"model\": models.Message}},\n)\nasync def backup():  # noqa: ANN201\n    \"\"\"Trigger a database backup.\"\"\"\n    path = await backup_global_db()\n    if path is None:\n        return JSONResponse(\n            status_code=500,\n            content={\"message\": \"Backup failed. See server logs for more information.\"},\n        )", "    \"\"\"Trigger a database backup.\"\"\"\n    path = await backup_global_db()\n    if path is None:\n        return JSONResponse(\n            status_code=500,\n            content={\"message\": \"Backup failed. See server logs for more information.\"},\n        )\n    return models.BackupResponse(path=str(path))\n\n", "\n\n# Add routers\napp.include_router(filament.router)\napp.include_router(spool.router)\napp.include_router(vendor.router)\n"]}
{"filename": "spoolman/api/v1/__init__.py", "chunked_list": [""]}
{"filename": "spoolman/api/v1/spool.py", "chunked_list": ["\"\"\"Spool related endpoints.\"\"\"\n\nimport logging\nfrom datetime import datetime\nfrom typing import Annotated, Optional\n\nfrom fastapi import APIRouter, Depends, Query\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field", "from fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\nfrom pydantic.error_wrappers import ErrorWrapper\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom spoolman.api.v1.models import Message, Spool\nfrom spoolman.database import spool\nfrom spoolman.database.database import get_db_session\nfrom spoolman.exceptions import ItemCreateError\n", "from spoolman.exceptions import ItemCreateError\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter(\n    prefix=\"/spool\",\n    tags=[\"spool\"],\n)\n\n# ruff: noqa: D103,B008", "\n# ruff: noqa: D103,B008\n\n\nclass SpoolParameters(BaseModel):\n    first_used: Optional[datetime] = Field(description=\"First logged occurence of spool usage.\")\n    last_used: Optional[datetime] = Field(description=\"Last logged occurence of spool usage.\")\n    filament_id: int = Field(description=\"The ID of the filament type of this spool.\")\n    remaining_weight: Optional[float] = Field(\n        ge=0,\n        description=(\n            \"Remaining weight of filament on the spool. Can only be used if the filament type has a weight set.\"\n        ),\n        example=800,\n    )\n    used_weight: Optional[float] = Field(ge=0, description=\"Used weight of filament on the spool.\", example=200)\n    location: Optional[str] = Field(max_length=64, description=\"Where this spool can be found.\", example=\"Shelf A\")\n    lot_nr: Optional[str] = Field(\n        max_length=64,\n        description=\"Vendor manufacturing lot/batch number of the spool.\",\n        example=\"52342\",\n    )\n    comment: Optional[str] = Field(\n        max_length=1024,\n        description=\"Free text comment about this specific spool.\",\n        example=\"\",\n    )\n    archived: bool = Field(default=False, description=\"Whether this spool is archived and should not be used anymore.\")", "\n\nclass SpoolUpdateParameters(SpoolParameters):\n    filament_id: Optional[int] = Field(description=\"The ID of the filament type of this spool.\")\n\n\nclass SpoolUseParameters(BaseModel):\n    use_length: Optional[float] = Field(description=\"Length of filament to reduce by, in mm.\", example=2.2)\n    use_weight: Optional[float] = Field(description=\"Filament weight to reduce by, in g.\", example=5.3)\n", "\n\n@router.get(\n    \"\",\n    name=\"Find spool\",\n    description=\"Get a list of spools that matches the search query.\",\n    response_model_exclude_none=True,\n)\nasync def find(\n    *,", "async def find(\n    *,\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    filament_name: Optional[str] = Query(\n        default=None,\n        title=\"Filament Name\",\n        description=\"Partial case-insensitive search term for the filament name.\",\n    ),\n    filament_id: Optional[int] = Query(\n        default=None,", "    filament_id: Optional[int] = Query(\n        default=None,\n        title=\"Filament ID\",\n        description=\"Match an exact filament ID.\",\n    ),\n    filament_material: Optional[str] = Query(\n        default=None,\n        title=\"Filament Material\",\n        description=\"Partial case-insensitive search term for the filament material.\",\n    ),", "        description=\"Partial case-insensitive search term for the filament material.\",\n    ),\n    vendor_name: Optional[str] = Query(\n        default=None,\n        title=\"Vendor Name\",\n        description=\"Partial case-insensitive search term for the filament vendor name.\",\n    ),\n    vendor_id: Optional[int] = Query(\n        default=None,\n        title=\"Vendor ID\",", "        default=None,\n        title=\"Vendor ID\",\n        description=\"Match an exact vendor ID.\",\n    ),\n    location: Optional[str] = Query(\n        default=None,\n        title=\"Location\",\n        description=\"Partial case-insensitive search term for the spool location.\",\n    ),\n    lot_nr: Optional[str] = Query(", "    ),\n    lot_nr: Optional[str] = Query(\n        default=None,\n        title=\"Lot/Batch Number\",\n        description=\"Partial case-insensitive search term for the spool lot number.\",\n    ),\n    allow_archived: bool = Query(\n        default=False,\n        title=\"Allow Archived\",\n        description=\"Whether to include archived spools in the search results.\",", "        title=\"Allow Archived\",\n        description=\"Whether to include archived spools in the search results.\",\n    ),\n) -> list[Spool]:\n    db_items = await spool.find(\n        db=db,\n        filament_name=filament_name,\n        filament_id=filament_id,\n        filament_material=filament_material,\n        vendor_name=vendor_name,", "        filament_material=filament_material,\n        vendor_name=vendor_name,\n        vendor_id=vendor_id,\n        location=location,\n        lot_nr=lot_nr,\n        allow_archived=allow_archived,\n    )\n    return [Spool.from_db(db_item) for db_item in db_items]\n\n", "\n\n@router.get(\n    \"/{spool_id}\",\n    name=\"Get spool\",\n    description=\"Get a specific spool.\",\n    response_model_exclude_none=True,\n    responses={404: {\"model\": Message}},\n)\nasync def get(", ")\nasync def get(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    spool_id: int,\n) -> Spool:\n    db_item = await spool.get_by_id(db, spool_id)\n    return Spool.from_db(db_item)\n\n\n@router.post(", "\n@router.post(\n    \"\",\n    name=\"Add spool\",\n    description=(\n        \"Add a new spool to the database. \"\n        \"Only specify either remaining_weight or used_weight. \"\n        \"If no weight is set, the spool will be assumed to be full.\"\n    ),\n    response_model_exclude_none=True,", "    ),\n    response_model_exclude_none=True,\n    response_model=Spool,\n    responses={\n        400: {\"model\": Message},\n    },\n)\nasync def create(  # noqa: ANN201\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    body: SpoolParameters,", "    db: Annotated[AsyncSession, Depends(get_db_session)],\n    body: SpoolParameters,\n):\n    if body.remaining_weight is not None and body.used_weight is not None:\n        return JSONResponse(\n            status_code=400,\n            content={\"message\": \"Only specify either remaining_weight or used_weight.\"},\n        )\n\n    try:\n        db_item = await spool.create(\n            db=db,\n            filament_id=body.filament_id,\n            remaining_weight=body.remaining_weight,\n            used_weight=body.used_weight,\n            first_used=body.first_used,\n            last_used=body.last_used,\n            location=body.location,\n            lot_nr=body.lot_nr,\n            comment=body.comment,\n            archived=body.archived,\n        )\n        return Spool.from_db(db_item)\n    except ItemCreateError:\n        logger.exception(\"Failed to create spool.\")\n        return JSONResponse(\n            status_code=400,\n            content={\"message\": \"Failed to create spool, see server logs for more information.\"},\n        )", "\n    try:\n        db_item = await spool.create(\n            db=db,\n            filament_id=body.filament_id,\n            remaining_weight=body.remaining_weight,\n            used_weight=body.used_weight,\n            first_used=body.first_used,\n            last_used=body.last_used,\n            location=body.location,\n            lot_nr=body.lot_nr,\n            comment=body.comment,\n            archived=body.archived,\n        )\n        return Spool.from_db(db_item)\n    except ItemCreateError:\n        logger.exception(\"Failed to create spool.\")\n        return JSONResponse(\n            status_code=400,\n            content={\"message\": \"Failed to create spool, see server logs for more information.\"},\n        )", "\n\n@router.patch(\n    \"/{spool_id}\",\n    name=\"Update spool\",\n    description=(\n        \"Update any attribute of a spool. \"\n        \"Only fields specified in the request will be affected. \"\n        \"remaining_weight and used_weight can't be set at the same time.\"\n    ),", "        \"remaining_weight and used_weight can't be set at the same time.\"\n    ),\n    response_model_exclude_none=True,\n    response_model=Spool,\n    responses={\n        400: {\"model\": Message},\n        404: {\"model\": Message},\n    },\n)\nasync def update(  # noqa: ANN201", ")\nasync def update(  # noqa: ANN201\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    spool_id: int,\n    body: SpoolUpdateParameters,\n):\n    patch_data = body.dict(exclude_unset=True)\n\n    if body.remaining_weight is not None and body.used_weight is not None:\n        return JSONResponse(\n            status_code=400,\n            content={\"message\": \"Only specify either remaining_weight or used_weight.\"},\n        )", "    if body.remaining_weight is not None and body.used_weight is not None:\n        return JSONResponse(\n            status_code=400,\n            content={\"message\": \"Only specify either remaining_weight or used_weight.\"},\n        )\n\n    if \"filament_id\" in patch_data and body.filament_id is None:\n        raise RequestValidationError(\n            [ErrorWrapper(ValueError(\"filament_id cannot be unset\"), (\"query\", \"filament_id\"))],\n        )", "\n    try:\n        db_item = await spool.update(\n            db=db,\n            spool_id=spool_id,\n            data=patch_data,\n        )\n    except ItemCreateError:\n        logger.exception(\"Failed to update spool.\")\n        return JSONResponse(\n            status_code=400,\n            content={\"message\": \"Failed to update spool, see server logs for more information.\"},\n        )", "\n    return Spool.from_db(db_item)\n\n\n@router.delete(\n    \"/{spool_id}\",\n    name=\"Delete spool\",\n    description=\"Delete a spool.\",\n    responses={404: {\"model\": Message}},\n)", "    responses={404: {\"model\": Message}},\n)\nasync def delete(\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    spool_id: int,\n) -> Message:\n    await spool.delete(db, spool_id)\n    return Message(message=\"Success!\")\n\n", "\n\n@router.put(\n    \"/{spool_id}/use\",\n    name=\"Use spool filament\",\n    description=(\n        \"Use some length or weight of filament from the spool. Specify either a length or a weight, not both.\"\n    ),\n    response_model_exclude_none=True,\n    response_model=Spool,", "    response_model_exclude_none=True,\n    response_model=Spool,\n    responses={\n        400: {\"model\": Message},\n        404: {\"model\": Message},\n    },\n)\nasync def use(  # noqa: ANN201\n    db: Annotated[AsyncSession, Depends(get_db_session)],\n    spool_id: int,", "    db: Annotated[AsyncSession, Depends(get_db_session)],\n    spool_id: int,\n    body: SpoolUseParameters,\n):\n    if body.use_weight is not None and body.use_length is not None:\n        return JSONResponse(\n            status_code=400,\n            content={\"message\": \"Only specify either use_weight or use_length.\"},\n        )\n\n    if body.use_weight is not None:\n        db_item = await spool.use_weight(db, spool_id, body.use_weight)\n        return Spool.from_db(db_item)", "\n    if body.use_weight is not None:\n        db_item = await spool.use_weight(db, spool_id, body.use_weight)\n        return Spool.from_db(db_item)\n\n    if body.use_length is not None:\n        db_item = await spool.use_length(db, spool_id, body.use_length)\n        return Spool.from_db(db_item)\n\n    return JSONResponse(", "\n    return JSONResponse(\n        status_code=400,\n        content={\"message\": \"Either use_weight or use_length must be specified.\"},\n    )\n"]}
{"filename": "migrations/__init__.py", "chunked_list": ["\"\"\"Database migrations system.\"\"\"\n"]}
{"filename": "migrations/env.py", "chunked_list": ["\"\"\"Alembic environment file.\"\"\"\n\nimport asyncio\nfrom logging.config import fileConfig\n\nfrom alembic import context\nfrom sqlalchemy.engine import Connection\n\nfrom spoolman.database.database import Database, get_connection_url\nfrom spoolman.database.models import Base", "from spoolman.database.database import Database, get_connection_url\nfrom spoolman.database.models import Base\n\nconfig = context.config\n\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\ntarget_metadata = Base.metadata\n", "target_metadata = Base.metadata\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    context.configure(\n        url=get_connection_url(),\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n        render_as_batch=True,\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()", "\n\ndef do_run_migrations(connection: Connection) -> None:\n    \"\"\"Run migrations in 'online' mode.\"\"\"\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n", "\n\nasync def run_async_migrations() -> None:\n    \"\"\"In this scenario we need to create an Engine and associate a connection with the context.\"\"\"\n    db = Database(get_connection_url())\n    db.connect()\n\n    if db.engine is None:\n        raise RuntimeError(\"Engine not created.\")\n", "\n    async with db.engine.connect() as connection:\n        await connection.run_sync(do_run_migrations)\n\n    await db.engine.dispose()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    asyncio.run(run_async_migrations())", ""]}
{"filename": "migrations/versions/2023_08_12_2121-92793c8a937c_color_hex_alpha.py", "chunked_list": ["\"\"\"color_hex alpha.\n\nRevision ID: 92793c8a937c\nRevises: 92186a5f7b0f\nCreate Date: 2023-08-12 21:21:08.536216\n\"\"\"\nimport sqlalchemy as sa\nfrom alembic import op\n\n# revision identifiers, used by Alembic.", "\n# revision identifiers, used by Alembic.\nrevision = \"92793c8a937c\"\ndown_revision = \"92186a5f7b0f\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    with op.batch_alter_table(\"filament\") as batch_op:\n        batch_op.alter_column(\"color_hex\", type_=sa.String(length=8), existing_nullable=True)", "def upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    with op.batch_alter_table(\"filament\") as batch_op:\n        batch_op.alter_column(\"color_hex\", type_=sa.String(length=8), existing_nullable=True)\n\n\ndef downgrade() -> None:\n    \"\"\"Perform the downgrade.\"\"\"\n    with op.batch_alter_table(\"filament\") as batch_op:\n        batch_op.alter_column(\"color_hex\", type_=sa.String(length=6), existing_nullable=True)", ""]}
{"filename": "migrations/versions/2023_05_28_2136-b47376d60c6d_add_extruder_and_bed_temperature_.py", "chunked_list": ["\"\"\"add extruder and bed temperature override.\n\nRevision ID: b47376d60c6d\nRevises: 684d32cf7e4d\nCreate Date: 2023-05-28 21:36:53.452067\n\"\"\"\nimport sqlalchemy as sa\nfrom alembic import op\n\n# revision identifiers, used by Alembic.", "\n# revision identifiers, used by Alembic.\nrevision = \"b47376d60c6d\"\ndown_revision = \"684d32cf7e4d\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    op.add_column(\n        \"filament\",\n        sa.Column(\"settings_extruder_temp\", sa.Integer(), nullable=True, comment=\"Overridden extruder temperature.\"),\n    )\n    op.add_column(\n        \"filament\",\n        sa.Column(\"settings_bed_temp\", sa.Integer(), nullable=True, comment=\"Overridden bed temperature.\"),\n    )", "def upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    op.add_column(\n        \"filament\",\n        sa.Column(\"settings_extruder_temp\", sa.Integer(), nullable=True, comment=\"Overridden extruder temperature.\"),\n    )\n    op.add_column(\n        \"filament\",\n        sa.Column(\"settings_bed_temp\", sa.Integer(), nullable=True, comment=\"Overridden bed temperature.\"),\n    )", "\n\ndef downgrade() -> None:\n    \"\"\"Perform the downgrade.\"\"\"\n    op.drop_column(\"filament\", \"settings_bed_temp\")\n    op.drop_column(\"filament\", \"settings_extruder_temp\")\n"]}
{"filename": "migrations/versions/2023_07_14_1217-92186a5f7b0f_add_spool_archived_field.py", "chunked_list": ["\"\"\"add spool archived field.\n\nRevision ID: 92186a5f7b0f\nRevises: db385b808a20\nCreate Date: 2023-07-14 12:17:13.162618\n\"\"\"\nimport sqlalchemy as sa\nfrom alembic import op\n\n# revision identifiers, used by Alembic.", "\n# revision identifiers, used by Alembic.\nrevision = \"92186a5f7b0f\"\ndown_revision = \"db385b808a20\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    op.add_column(\"spool\", sa.Column(\"archived\", sa.Boolean(), nullable=True))", "def upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    op.add_column(\"spool\", sa.Column(\"archived\", sa.Boolean(), nullable=True))\n\n\ndef downgrade() -> None:\n    \"\"\"Perform the downgrade.\"\"\"\n    op.drop_column(\"spool\", \"archived\")\n", ""]}
{"filename": "migrations/versions/__init__.py", "chunked_list": ["\"\"\"Database migration versions.\"\"\"\n"]}
{"filename": "migrations/versions/2023_05_27_2146-684d32cf7e4d_initial.py", "chunked_list": ["\"\"\"initial.\n\nRevision ID: 684d32cf7e4d\nCreate Date: 2023-05-27 21:46:24.361353\n\"\"\"\nimport sqlalchemy as sa\nfrom alembic import op\nfrom sqlalchemy.engine.reflection import Inspector\n\n# revision identifiers, used by Alembic.", "\n# revision identifiers, used by Alembic.\nrevision = \"684d32cf7e4d\"\ndown_revision = None\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    conn = op.get_bind()\n    inspector = Inspector.from_engine(conn)  # type: ignore[arg-type]\n    tables = inspector.get_table_names()\n    if \"vendor\" in tables:\n        # If the vendor table exists, we assume that the initial migration has already been performed.\n        return\n\n    op.create_table(\n        \"vendor\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"registered\", sa.DateTime(), nullable=False, server_default=sa.func.now()),\n        sa.Column(\"name\", sa.String(length=64), nullable=False),\n        sa.Column(\"comment\", sa.String(length=1024), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(op.f(\"ix_vendor_id\"), \"vendor\", [\"id\"], unique=False)\n    op.create_table(\n        \"filament\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"registered\", sa.DateTime(), nullable=False, server_default=sa.func.now()),\n        sa.Column(\"name\", sa.String(length=64), nullable=True),\n        sa.Column(\"vendor_id\", sa.Integer(), nullable=True),\n        sa.Column(\"material\", sa.String(length=64), nullable=True),\n        sa.Column(\"price\", sa.Float(), nullable=True),\n        sa.Column(\"density\", sa.Float(), nullable=False),\n        sa.Column(\"diameter\", sa.Float(), nullable=False),\n        sa.Column(\"weight\", sa.Float(), nullable=True, comment=\"The filament weight of a full spool (net weight).\"),\n        sa.Column(\"spool_weight\", sa.Float(), nullable=True, comment=\"The weight of an empty spool.\"),\n        sa.Column(\"article_number\", sa.String(length=64), nullable=True),\n        sa.Column(\"comment\", sa.String(length=1024), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"vendor_id\"],\n            [\"vendor.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(op.f(\"ix_filament_id\"), \"filament\", [\"id\"], unique=False)\n    op.create_table(\n        \"spool\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"registered\", sa.DateTime(), nullable=False, server_default=sa.func.now()),\n        sa.Column(\"first_used\", sa.DateTime(), nullable=True),\n        sa.Column(\"last_used\", sa.DateTime(), nullable=True),\n        sa.Column(\"filament_id\", sa.Integer(), nullable=False),\n        sa.Column(\"used_weight\", sa.Float(), nullable=False),\n        sa.Column(\"location\", sa.String(length=64), nullable=True),\n        sa.Column(\"lot_nr\", sa.String(length=64), nullable=True),\n        sa.Column(\"comment\", sa.String(length=1024), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"filament_id\"],\n            [\"filament.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(op.f(\"ix_spool_id\"), \"spool\", [\"id\"], unique=False)", "def upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    conn = op.get_bind()\n    inspector = Inspector.from_engine(conn)  # type: ignore[arg-type]\n    tables = inspector.get_table_names()\n    if \"vendor\" in tables:\n        # If the vendor table exists, we assume that the initial migration has already been performed.\n        return\n\n    op.create_table(\n        \"vendor\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"registered\", sa.DateTime(), nullable=False, server_default=sa.func.now()),\n        sa.Column(\"name\", sa.String(length=64), nullable=False),\n        sa.Column(\"comment\", sa.String(length=1024), nullable=True),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(op.f(\"ix_vendor_id\"), \"vendor\", [\"id\"], unique=False)\n    op.create_table(\n        \"filament\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"registered\", sa.DateTime(), nullable=False, server_default=sa.func.now()),\n        sa.Column(\"name\", sa.String(length=64), nullable=True),\n        sa.Column(\"vendor_id\", sa.Integer(), nullable=True),\n        sa.Column(\"material\", sa.String(length=64), nullable=True),\n        sa.Column(\"price\", sa.Float(), nullable=True),\n        sa.Column(\"density\", sa.Float(), nullable=False),\n        sa.Column(\"diameter\", sa.Float(), nullable=False),\n        sa.Column(\"weight\", sa.Float(), nullable=True, comment=\"The filament weight of a full spool (net weight).\"),\n        sa.Column(\"spool_weight\", sa.Float(), nullable=True, comment=\"The weight of an empty spool.\"),\n        sa.Column(\"article_number\", sa.String(length=64), nullable=True),\n        sa.Column(\"comment\", sa.String(length=1024), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"vendor_id\"],\n            [\"vendor.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(op.f(\"ix_filament_id\"), \"filament\", [\"id\"], unique=False)\n    op.create_table(\n        \"spool\",\n        sa.Column(\"id\", sa.Integer(), nullable=False),\n        sa.Column(\"registered\", sa.DateTime(), nullable=False, server_default=sa.func.now()),\n        sa.Column(\"first_used\", sa.DateTime(), nullable=True),\n        sa.Column(\"last_used\", sa.DateTime(), nullable=True),\n        sa.Column(\"filament_id\", sa.Integer(), nullable=False),\n        sa.Column(\"used_weight\", sa.Float(), nullable=False),\n        sa.Column(\"location\", sa.String(length=64), nullable=True),\n        sa.Column(\"lot_nr\", sa.String(length=64), nullable=True),\n        sa.Column(\"comment\", sa.String(length=1024), nullable=True),\n        sa.ForeignKeyConstraint(\n            [\"filament_id\"],\n            [\"filament.id\"],\n        ),\n        sa.PrimaryKeyConstraint(\"id\"),\n    )\n    op.create_index(op.f(\"ix_spool_id\"), \"spool\", [\"id\"], unique=False)", "\n\ndef downgrade() -> None:\n    \"\"\"Perform the downgrade.\"\"\"\n    op.drop_index(op.f(\"ix_spool_id\"), table_name=\"spool\")\n    op.drop_table(\"spool\")\n    op.drop_index(op.f(\"ix_filament_id\"), table_name=\"filament\")\n    op.drop_table(\"filament\")\n    op.drop_index(op.f(\"ix_vendor_id\"), table_name=\"vendor\")\n    op.drop_table(\"vendor\")", ""]}
{"filename": "migrations/versions/2023_06_01_1953-db385b808a20_add_filament_color_code.py", "chunked_list": ["\"\"\"add filament color code.\n\nRevision ID: db385b808a20\nRevises: b47376d60c6d\nCreate Date: 2023-06-01 19:53:44.440616\n\"\"\"\nimport sqlalchemy as sa\nfrom alembic import op\n\n# revision identifiers, used by Alembic.", "\n# revision identifiers, used by Alembic.\nrevision = \"db385b808a20\"\ndown_revision = \"b47376d60c6d\"\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    op.add_column(\"filament\", sa.Column(\"color_hex\", sa.String(length=6), nullable=True))", "def upgrade() -> None:\n    \"\"\"Perform the upgrade.\"\"\"\n    op.add_column(\"filament\", sa.Column(\"color_hex\", sa.String(length=6), nullable=True))\n\n\ndef downgrade() -> None:\n    \"\"\"Perform the downgrade.\"\"\"\n    op.drop_column(\"filament\", \"color_hex\")\n", ""]}
{"filename": "tests_integration/run.py", "chunked_list": ["\"\"\"Build and run the integration tests.\"\"\"\n\n# ruff: noqa: S605, S607, T201\n\nimport os\nimport sys\n\nif __name__ == \"__main__\":\n    print(\"Building and running integration tests...\")\n    print(\"Building Spoolman...\")\n    if os.system(\"docker build -t donkie/spoolman:test .\") > 0:\n        print(\"Failed to build Spoolman!\")\n        sys.exit(1)\n    print(\"Building Spoolman tester...\")\n    if os.system(\"docker build -t donkie/spoolman-tester:latest tests_integration\") > 0:\n        print(\"Failed to build Spoolman tester!\")\n        sys.exit(1)\n\n    # Support input arguments for running only specific tests\n    if len(sys.argv) > 1:\n        targets = sys.argv[1:]\n        # Check that all targets are valid\n        for target in targets:\n            if target not in [\"postgres\", \"sqlite\", \"mariadb\", \"cockroachdb\"]:\n                print(f\"Unknown target: {target}\")\n                sys.exit(1)\n    else:\n        print(\"No targets specified, running all tests...\")\n        targets = [\n            \"postgres\",\n            \"sqlite\",\n            \"mariadb\",\n            \"cockroachdb\",\n        ]\n\n    for target in targets:\n        print(f\"Running integration tests against {target}...\")\n        os.system(f\"docker-compose -f tests_integration/docker-compose-{target}.yml down -v\")\n        if (\n            os.system(f\"docker-compose -f tests_integration/docker-compose-{target}.yml up --abort-on-container-exit\")\n            > 0\n        ):\n            print(f\"Integration tests against {target} failed!\")\n            sys.exit(1)\n\n    print(\"Integration tests passed!\")", ""]}
{"filename": "tests_integration/__init__.py", "chunked_list": ["\"\"\"Integration tests root.\"\"\"\n"]}
{"filename": "tests_integration/tests/test_vendor.py", "chunked_list": ["\"\"\"Integration tests for the Vendor API endpoint.\"\"\"\n\nimport httpx\n\nURL = \"http://spoolman:8000\"\n\n\ndef test_add_vendor():\n    \"\"\"Test adding a vendor to the database.\"\"\"\n    # Execute\n    name = \"John\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    result = httpx.post(\n        f\"{URL}/api/v1/vendor\",\n        json={\"name\": name, \"comment\": comment},\n    )\n    result.raise_for_status()\n\n    # Verify\n    vendor = result.json()\n    assert vendor == {\n        \"id\": vendor[\"id\"],\n        \"registered\": vendor[\"registered\"],\n        \"name\": name,\n        \"comment\": comment,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/vendor/{vendor['id']}\").raise_for_status()", "\n\ndef test_add_vendor_required():\n    \"\"\"Test adding a vendor with only the required fields to the database.\"\"\"\n    # Execute\n    name = \"John\"\n    result = httpx.post(\n        f\"{URL}/api/v1/vendor\",\n        json={\"name\": name},\n    )\n    result.raise_for_status()\n\n    # Verify\n    vendor = result.json()\n    assert vendor == {\n        \"id\": vendor[\"id\"],\n        \"registered\": vendor[\"registered\"],\n        \"name\": name,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/vendor/{vendor['id']}\").raise_for_status()", "\n\ndef test_get_vendor():\n    \"\"\"Test getting a vendor from the database.\"\"\"\n    # Setup\n    name = \"John\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    result = httpx.post(\n        f\"{URL}/api/v1/vendor\",\n        json={\"name\": name, \"comment\": comment},\n    )\n    result.raise_for_status()\n    added_vendor = result.json()\n\n    # Execute\n    result = httpx.get(\n        f\"{URL}/api/v1/vendor/{added_vendor['id']}\",\n    )\n    result.raise_for_status()\n\n    # Verify\n    vendor = result.json()\n    assert vendor[\"name\"] == name\n    assert vendor[\"comment\"] == comment\n    assert vendor[\"id\"] == added_vendor[\"id\"]\n    assert vendor[\"registered\"] == added_vendor[\"registered\"]\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/vendor/{vendor['id']}\").raise_for_status()", "\n\ndef test_get_vendor_not_found():\n    \"\"\"Test getting a vendor that does not exist.\"\"\"\n    # Execute\n    result = httpx.get(f\"{URL}/api/v1/vendor/123456789\")\n\n    # Verify\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"vendor\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\ndef test_find_vendors():\n    \"\"\"Test finding vendors from the database.\"\"\"\n    # Setup\n    name_1 = \"John\"\n    comment_1 = \"abcdefgh\u00e5\u00e4\u00f6\"\n    result = httpx.post(\n        f\"{URL}/api/v1/vendor\",\n        json={\"name\": name_1, \"comment\": comment_1},\n    )\n    result.raise_for_status()\n    vendor_1 = result.json()\n\n    name_2 = \"Stan\"\n    comment_2 = \"gfdadfg\"\n    result = httpx.post(\n        f\"{URL}/api/v1/vendor\",\n        json={\"name\": name_2, \"comment\": comment_2},\n    )\n    result.raise_for_status()\n    vendor_2 = result.json()\n\n    added_vendors_by_id = {\n        vendor_1[\"id\"]: vendor_1,\n        vendor_2[\"id\"]: vendor_2,\n    }\n\n    # Execute - Find all vendors\n    result = httpx.get(\n        f\"{URL}/api/v1/vendor\",\n    )\n    result.raise_for_status()\n\n    # Verify\n    vendors = result.json()\n    assert len(vendors) == 2\n\n    for vendor in vendors:\n        assert vendor == added_vendors_by_id[vendor[\"id\"]]\n\n    # Execute - Find a specific vendor\n    result = httpx.get(\n        f\"{URL}/api/v1/vendor\",\n        params={\"name\": name_1},\n    )\n    result.raise_for_status()\n\n    # Verify\n    vendors = result.json()\n    assert len(vendors) == 1\n\n    vendor = vendors[0]\n\n    assert vendor[\"name\"] == name_1\n    assert vendor[\"comment\"] == comment_1\n    assert vendor[\"id\"] == vendor_1[\"id\"]\n    assert vendor[\"registered\"] == vendor_1[\"registered\"]\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/vendor/{vendor_1['id']}\").raise_for_status()\n    httpx.delete(f\"{URL}/api/v1/vendor/{vendor_2['id']}\").raise_for_status()", "\n\ndef test_delete_vendor():\n    \"\"\"Test deleting a vendor from the database.\"\"\"\n    # Setup\n    name = \"John\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    result = httpx.post(\n        f\"{URL}/api/v1/vendor\",\n        json={\"name\": name, \"comment\": comment},\n    )\n    result.raise_for_status()\n    added_vendor = result.json()\n\n    # Execute\n    httpx.delete(\n        f\"{URL}/api/v1/vendor/{added_vendor['id']}\",\n    ).raise_for_status()\n\n    # Verify\n    result = httpx.get(\n        f\"{URL}/api/v1/vendor/{added_vendor['id']}\",\n    )\n    assert result.status_code == 404", "\n\ndef test_delete_vendor_not_found():\n    \"\"\"Test deleting a vendor that does not exist.\"\"\"\n    # Execute\n    result = httpx.delete(f\"{URL}/api/v1/vendor/123456789\")\n\n    # Verify\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"vendor\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\ndef test_update_vendor():\n    \"\"\"Test update a vendor in the database.\"\"\"\n    # Setup\n    name = \"John\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    result = httpx.post(\n        f\"{URL}/api/v1/vendor\",\n        json={\"name\": name, \"comment\": comment},\n    )\n    result.raise_for_status()\n    added_vendor = result.json()\n\n    # Execute\n    new_name = \"Stan\"\n    new_comment = \"gfdadfg\"\n    result = httpx.patch(\n        f\"{URL}/api/v1/vendor/{added_vendor['id']}\",\n        json={\"name\": new_name, \"comment\": new_comment},\n    )\n    result.raise_for_status()\n\n    # Verify\n    vendor = result.json()\n    assert vendor[\"name\"] == new_name\n    assert vendor[\"comment\"] == new_comment\n    assert vendor[\"id\"] == added_vendor[\"id\"]\n    assert vendor[\"registered\"] == added_vendor[\"registered\"]\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/vendor/{vendor['id']}\").raise_for_status()", "\n\ndef test_update_vendor_not_found():\n    \"\"\"Test updating a vendor that does not exist.\"\"\"\n    # Execute\n    result = httpx.patch(f\"{URL}/api/v1/vendor/123456789\", json={\"name\": \"John\"})\n\n    # Verify\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"vendor\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", ""]}
{"filename": "tests_integration/tests/test_filament.py", "chunked_list": ["\"\"\"Integration tests for the Filament API endpoint.\"\"\"\n\nfrom typing import Any\n\nimport httpx\n\nURL = \"http://spoolman:8000\"\n\n\ndef test_add_filament(random_vendor: dict[str, Any]):\n    \"\"\"Test adding a filament to the database.\"\"\"\n    # Execute\n    name = \"Filament X\"\n    material = \"PLA\"\n    price = 100\n    density = 1.25\n    diameter = 1.75\n    weight = 1000\n    spool_weight = 250\n    article_number = \"123456789\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    settings_extruder_temp = 200\n    settings_bed_temp = 60\n    color_hex = \"FF0000\"\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"name\": name,\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": material,\n            \"price\": price,\n            \"density\": density,\n            \"diameter\": diameter,\n            \"weight\": weight,\n            \"spool_weight\": spool_weight,\n            \"article_number\": article_number,\n            \"comment\": comment,\n            \"settings_extruder_temp\": settings_extruder_temp,\n            \"settings_bed_temp\": settings_bed_temp,\n            \"color_hex\": color_hex,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    filament = result.json()\n    assert filament == {\n        \"id\": filament[\"id\"],\n        \"registered\": filament[\"registered\"],\n        \"name\": name,\n        \"vendor\": random_vendor,\n        \"material\": material,\n        \"price\": price,\n        \"density\": density,\n        \"diameter\": diameter,\n        \"weight\": weight,\n        \"spool_weight\": spool_weight,\n        \"article_number\": article_number,\n        \"comment\": comment,\n        \"settings_extruder_temp\": settings_extruder_temp,\n        \"settings_bed_temp\": settings_bed_temp,\n        \"color_hex\": color_hex,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/filament/{filament['id']}\").raise_for_status()", "\ndef test_add_filament(random_vendor: dict[str, Any]):\n    \"\"\"Test adding a filament to the database.\"\"\"\n    # Execute\n    name = \"Filament X\"\n    material = \"PLA\"\n    price = 100\n    density = 1.25\n    diameter = 1.75\n    weight = 1000\n    spool_weight = 250\n    article_number = \"123456789\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    settings_extruder_temp = 200\n    settings_bed_temp = 60\n    color_hex = \"FF0000\"\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"name\": name,\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": material,\n            \"price\": price,\n            \"density\": density,\n            \"diameter\": diameter,\n            \"weight\": weight,\n            \"spool_weight\": spool_weight,\n            \"article_number\": article_number,\n            \"comment\": comment,\n            \"settings_extruder_temp\": settings_extruder_temp,\n            \"settings_bed_temp\": settings_bed_temp,\n            \"color_hex\": color_hex,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    filament = result.json()\n    assert filament == {\n        \"id\": filament[\"id\"],\n        \"registered\": filament[\"registered\"],\n        \"name\": name,\n        \"vendor\": random_vendor,\n        \"material\": material,\n        \"price\": price,\n        \"density\": density,\n        \"diameter\": diameter,\n        \"weight\": weight,\n        \"spool_weight\": spool_weight,\n        \"article_number\": article_number,\n        \"comment\": comment,\n        \"settings_extruder_temp\": settings_extruder_temp,\n        \"settings_bed_temp\": settings_bed_temp,\n        \"color_hex\": color_hex,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/filament/{filament['id']}\").raise_for_status()", "\n\ndef test_add_filament_required():\n    \"\"\"Test adding a filament with only the required fields to the database.\"\"\"\n    # Execute\n    density = 1.25\n    diameter = 1.75\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"density\": density,\n            \"diameter\": diameter,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    filament = result.json()\n    assert filament == {\n        \"id\": filament[\"id\"],\n        \"registered\": filament[\"registered\"],\n        \"density\": density,\n        \"diameter\": diameter,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/filament/{filament['id']}\").raise_for_status()", "\n\ndef test_get_filament(random_vendor: dict[str, Any]):\n    \"\"\"Test getting a filament from the database.\"\"\"\n    # Setup\n    name = \"Filament X\"\n    material = \"PLA\"\n    price = 100\n    density = 1.25\n    diameter = 1.75\n    weight = 1000\n    spool_weight = 250\n    article_number = \"123456789\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    settings_extruder_temp = 200\n    settings_bed_temp = 60\n    color_hex = \"FF0000\"\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"name\": name,\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": material,\n            \"price\": price,\n            \"density\": density,\n            \"diameter\": diameter,\n            \"weight\": weight,\n            \"spool_weight\": spool_weight,\n            \"article_number\": article_number,\n            \"comment\": comment,\n            \"settings_extruder_temp\": settings_extruder_temp,\n            \"settings_bed_temp\": settings_bed_temp,\n            \"color_hex\": color_hex,\n        },\n    )\n    result.raise_for_status()\n    added_filament = result.json()\n\n    # Execute\n    result = httpx.get(\n        f\"{URL}/api/v1/filament/{added_filament['id']}\",\n    )\n    result.raise_for_status()\n\n    # Verify\n    filament = result.json()\n    assert filament == {\n        \"id\": added_filament[\"id\"],\n        \"registered\": added_filament[\"registered\"],\n        \"name\": name,\n        \"vendor\": random_vendor,\n        \"material\": material,\n        \"price\": price,\n        \"density\": density,\n        \"diameter\": diameter,\n        \"weight\": weight,\n        \"spool_weight\": spool_weight,\n        \"article_number\": article_number,\n        \"comment\": comment,\n        \"settings_extruder_temp\": settings_extruder_temp,\n        \"settings_bed_temp\": settings_bed_temp,\n        \"color_hex\": color_hex,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/filament/{filament['id']}\").raise_for_status()", "\n\ndef test_get_filament_not_found():\n    \"\"\"Test getting a filament that does not exist.\"\"\"\n    # Execute\n    result = httpx.get(\n        f\"{URL}/api/v1/filament/123456789\",\n    )\n\n    # Verify\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"filament\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\ndef test_find_filaments(random_vendor: dict[str, Any]):\n    \"\"\"Test finding filaments from the database.\"\"\"\n    # Setup\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"name\": \"Filament X\",\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": \"PLA\",\n            \"price\": 100,\n            \"density\": 1.25,\n            \"diameter\": 1.75,\n            \"weight\": 1000,\n            \"spool_weight\": 250,\n            \"article_number\": \"123456789\",\n            \"comment\": \"abcdefgh\u00e5\u00e4\u00f6\",\n        },\n    )\n    result.raise_for_status()\n    filament_1 = result.json()\n\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"name\": \"Filament Y\",\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": \"ABS\",\n            \"price\": 200,\n            \"density\": 1.25,\n            \"diameter\": 1.75,\n            \"weight\": 1000,\n            \"spool_weight\": 250,\n            \"article_number\": \"987654321\",\n            \"comment\": \"abcdefgh\u00e5\u00e4\u00f6\",\n        },\n    )\n    result.raise_for_status()\n    filament_2 = result.json()\n\n    added_filaments_by_id = {\n        filament_1[\"id\"]: filament_1,\n        filament_2[\"id\"]: filament_2,\n    }\n\n    # Execute - find all filaments\n    result = httpx.get(\n        f\"{URL}/api/v1/filament\",\n    )\n    result.raise_for_status()\n\n    # Verify\n    filaments = result.json()\n    assert len(filaments) == 2\n    for filament in filaments:\n        assert filament == added_filaments_by_id[filament[\"id\"]]\n\n    # Execute - find filaments by name\n    result = httpx.get(\n        f\"{URL}/api/v1/filament\",\n        params={\"name\": \"Filament X\"},\n    )\n    result.raise_for_status()\n\n    # Verify\n    filaments = result.json()\n    assert len(filaments) == 1\n    assert filaments[0] == added_filaments_by_id[filament_1[\"id\"]]\n\n    # Execute - find filaments by material\n    result = httpx.get(\n        f\"{URL}/api/v1/filament\",\n        params={\"material\": \"abs\"},\n    )\n    result.raise_for_status()\n\n    # Verify\n    filaments = result.json()\n    assert len(filaments) == 1\n    assert filaments[0] == added_filaments_by_id[filament_2[\"id\"]]\n\n    # Execute - find filaments by vendor id\n    result = httpx.get(\n        f\"{URL}/api/v1/filament\",\n        params={\"vendor_id\": random_vendor[\"id\"]},\n    )\n    result.raise_for_status()\n\n    # Verify\n    filaments = result.json()\n    assert len(filaments) == 2\n    for filament in filaments:\n        assert filament == added_filaments_by_id[filament[\"id\"]]\n\n    # Execute - find filaments by vendor name\n    result = httpx.get(\n        f\"{URL}/api/v1/filament\",\n        params={\"vendor_name\": random_vendor[\"name\"]},\n    )\n    result.raise_for_status()\n\n    # Verify\n    filaments = result.json()\n    assert len(filaments) == 2\n    for filament in filaments:\n        assert filament == added_filaments_by_id[filament[\"id\"]]\n\n    # Execute - find filaments by article number\n    result = httpx.get(\n        f\"{URL}/api/v1/filament\",\n        params={\"article_number\": \"321\"},\n    )\n    result.raise_for_status()\n\n    # Verify\n    filaments = result.json()\n    assert len(filaments) == 1\n    assert filaments[0] == added_filaments_by_id[filament_2[\"id\"]]\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/filament/{filament_1['id']}\").raise_for_status()\n    httpx.delete(f\"{URL}/api/v1/filament/{filament_2['id']}\").raise_for_status()", "\n\ndef test_delete_filament(random_vendor: dict[str, Any]):\n    \"\"\"Test deleting a filament from the database.\"\"\"\n    # Setup\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"name\": \"Filament X\",\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": \"PLA\",\n            \"price\": 100,\n            \"density\": 1.25,\n            \"diameter\": 1.75,\n            \"weight\": 1000,\n            \"spool_weight\": 250,\n            \"article_number\": \"123456789\",\n            \"comment\": \"abcdefgh\u00e5\u00e4\u00f6\",\n        },\n    )\n    result.raise_for_status()\n    added_filament = result.json()\n\n    # Execute\n    httpx.delete(\n        f\"{URL}/api/v1/filament/{added_filament['id']}\",\n    ).raise_for_status()\n\n    # Verify\n    result = httpx.get(\n        f\"{URL}/api/v1/filament/{added_filament['id']}\",\n    )\n    assert result.status_code == 404", "\n\ndef test_delete_filament_not_found():\n    \"\"\"Test deleting a filament that does not exist.\"\"\"\n    # Execute\n    result = httpx.delete(f\"{URL}/api/v1/filament/123456789\")\n\n    # Verify\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"filament\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\ndef test_update_filament(random_vendor: dict[str, Any]):\n    \"\"\"Test updating a filament in the database.\"\"\"\n    # Setup\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"name\": \"Filament X\",\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": \"PLA\",\n            \"price\": 100,\n            \"density\": 1.25,\n            \"diameter\": 1.75,\n            \"weight\": 1000,\n            \"spool_weight\": 250,\n            \"article_number\": \"123456789\",\n            \"comment\": \"abcdefgh\u00e5\u00e4\u00f6\",\n            \"settings_extruder_temp\": 200,\n            \"settings_bed_temp\": 60,\n            \"color_hex\": \"FF0000\",\n        },\n    )\n    result.raise_for_status()\n    added_filament = result.json()\n\n    # Execute\n    new_name = \"Filament Y\"\n    new_material = \"ABS\"\n    new_price = 200\n    new_density = 4.2\n    new_diameter = 0.12\n    new_weight = 5431\n    new_spool_weight = 123\n    new_article_number = \"987654321\"\n    new_comment = \"test\"\n    new_settings_extruder_temp = 210\n    new_settings_bed_temp = 70\n    new_color_hex = \"00FF00\"\n    result = httpx.patch(\n        f\"{URL}/api/v1/filament/{added_filament['id']}\",\n        json={\n            \"name\": new_name,\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": new_material,\n            \"price\": new_price,\n            \"density\": new_density,\n            \"diameter\": new_diameter,\n            \"weight\": new_weight,\n            \"spool_weight\": new_spool_weight,\n            \"article_number\": new_article_number,\n            \"comment\": new_comment,\n            \"settings_extruder_temp\": new_settings_extruder_temp,\n            \"settings_bed_temp\": new_settings_bed_temp,\n            \"color_hex\": new_color_hex,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    filament = result.json()\n    assert filament == {\n        \"id\": added_filament[\"id\"],\n        \"registered\": added_filament[\"registered\"],\n        \"name\": new_name,\n        \"vendor\": random_vendor,\n        \"material\": new_material,\n        \"price\": new_price,\n        \"density\": new_density,\n        \"diameter\": new_diameter,\n        \"weight\": new_weight,\n        \"spool_weight\": new_spool_weight,\n        \"article_number\": new_article_number,\n        \"comment\": new_comment,\n        \"settings_extruder_temp\": new_settings_extruder_temp,\n        \"settings_bed_temp\": new_settings_bed_temp,\n        \"color_hex\": new_color_hex,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/filament/{filament['id']}\").raise_for_status()", "\n\ndef test_update_filament_not_found():\n    \"\"\"Test updating a filament that does not exist.\"\"\"\n    # Execute\n    result = httpx.patch(\n        f\"{URL}/api/v1/filament/123456789\",\n        json={\"name\": \"Filament Y\"},\n    )\n\n    # Verify\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"filament\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\ndef test_add_filament_color_hex_alpha():\n    \"\"\"Test adding a filament with an alpha channel in the color hex.\"\"\"\n    color_hex = \"FF000088\"\n\n    # Execute\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"density\": 1.25,\n            \"diameter\": 1.75,\n            \"color_hex\": color_hex,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    filament = result.json()\n    assert filament[\"color_hex\"] == color_hex", ""]}
{"filename": "tests_integration/tests/__init__.py", "chunked_list": ["\"\"\"Tests for the integration of the application.\"\"\"\n"]}
{"filename": "tests_integration/tests/test_spool.py", "chunked_list": ["\"\"\"Integration tests for the Spool API endpoint.\"\"\"\n\nimport asyncio\nimport math\nfrom typing import Any\n\nimport httpx\nimport pytest\n\nfrom .conftest import length_from_weight", "\nfrom .conftest import length_from_weight\n\nURL = \"http://spoolman:8000\"\n\n\ndef test_add_spool_remaining_weight(random_filament: dict[str, Any]):\n    \"\"\"Test adding a spool to the database.\"\"\"\n    # Execute\n    remaining_weight = 750\n    location = \"The Pantry\"\n    lot_nr = \"123456789\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    archived = True\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"first_used\": \"2023-01-02T12:00:00+01:00\",\n            \"last_used\": \"2023-01-02T11:00:00Z\",\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": remaining_weight,\n            \"location\": location,\n            \"lot_nr\": lot_nr,\n            \"comment\": comment,\n            \"archived\": archived,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    used_weight = random_filament[\"weight\"] - remaining_weight\n    used_length = length_from_weight(\n        weight=used_weight,\n        density=random_filament[\"density\"],\n        diameter=random_filament[\"diameter\"],\n    )\n    remaining_length = length_from_weight(\n        weight=remaining_weight,\n        density=random_filament[\"density\"],\n        diameter=random_filament[\"diameter\"],\n    )\n\n    spool = result.json()\n    assert spool == {\n        \"id\": spool[\"id\"],\n        \"registered\": spool[\"registered\"],\n        \"first_used\": \"2023-01-02T11:00:00\",\n        \"last_used\": \"2023-01-02T11:00:00\",\n        \"filament\": random_filament,\n        \"remaining_weight\": pytest.approx(remaining_weight),\n        \"used_weight\": pytest.approx(used_weight),\n        \"remaining_length\": pytest.approx(remaining_length),\n        \"used_length\": pytest.approx(used_length),\n        \"location\": location,\n        \"lot_nr\": lot_nr,\n        \"comment\": comment,\n        \"archived\": archived,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\ndef test_add_spool_used_weight(random_filament: dict[str, Any]):\n    \"\"\"Test adding a spool to the database.\"\"\"\n    # Execute\n    first_used = \"2023-01-01T00:00:00\"\n    last_used = \"2023-01-02T00:00:00\"\n    used_weight = 250\n    location = \"The Pantry\"\n    lot_nr = \"123456789\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    archived = True\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"first_used\": first_used,\n            \"last_used\": last_used,\n            \"filament_id\": random_filament[\"id\"],\n            \"used_weight\": used_weight,\n            \"location\": location,\n            \"lot_nr\": lot_nr,\n            \"comment\": comment,\n            \"archived\": archived,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    remaining_weight = random_filament[\"weight\"] - used_weight\n    used_length = length_from_weight(\n        weight=used_weight,\n        density=random_filament[\"density\"],\n        diameter=random_filament[\"diameter\"],\n    )\n    remaining_length = length_from_weight(\n        weight=remaining_weight,\n        density=random_filament[\"density\"],\n        diameter=random_filament[\"diameter\"],\n    )\n\n    spool = result.json()\n    assert spool == {\n        \"id\": spool[\"id\"],\n        \"registered\": spool[\"registered\"],\n        \"first_used\": first_used,\n        \"last_used\": last_used,\n        \"filament\": random_filament,\n        \"remaining_weight\": pytest.approx(remaining_weight),\n        \"used_weight\": pytest.approx(used_weight),\n        \"remaining_length\": pytest.approx(remaining_length),\n        \"used_length\": pytest.approx(used_length),\n        \"location\": location,\n        \"lot_nr\": lot_nr,\n        \"comment\": comment,\n        \"archived\": archived,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\ndef test_add_spool_required(random_filament: dict[str, Any]):\n    \"\"\"Test adding a spool with only the required fields to the database.\"\"\"\n    # Execute\n    used_weight = 250\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"used_weight\": used_weight,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    remaining_weight = random_filament[\"weight\"] - used_weight\n    used_length = length_from_weight(\n        weight=used_weight,\n        density=random_filament[\"density\"],\n        diameter=random_filament[\"diameter\"],\n    )\n    remaining_length = length_from_weight(\n        weight=remaining_weight,\n        density=random_filament[\"density\"],\n        diameter=random_filament[\"diameter\"],\n    )\n\n    spool = result.json()\n    assert spool == {\n        \"id\": spool[\"id\"],\n        \"registered\": spool[\"registered\"],\n        \"filament\": random_filament,\n        \"used_weight\": pytest.approx(used_weight),\n        \"remaining_weight\": pytest.approx(remaining_weight),\n        \"used_length\": pytest.approx(used_length),\n        \"remaining_length\": pytest.approx(remaining_length),\n        \"archived\": False,\n    }\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\ndef test_add_spool_both_used_and_remaining_weight(random_filament: dict[str, Any]):\n    \"\"\"Test adding a spool to the database.\"\"\"\n    # Execute\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": 750,\n            \"used_weight\": 250,\n        },\n    )\n    assert result.status_code == 400  # Cannot set both used and remaining weight", "\n\ndef test_get_spool(random_filament: dict[str, Any]):\n    \"\"\"Test getting a spool from the database.\"\"\"\n    # Setup\n    first_used = \"2023-01-01T00:00:00\"\n    last_used = \"2023-01-02T00:00:00\"\n    remaining_weight = 750\n    location = \"The Pantry\"\n    lot_nr = \"123456789\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    archived = True\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"first_used\": first_used,\n            \"last_used\": last_used,\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": remaining_weight,\n            \"location\": location,\n            \"lot_nr\": lot_nr,\n            \"comment\": comment,\n            \"archived\": archived,\n        },\n    )\n    result.raise_for_status()\n    spool = result.json()\n\n    # Execute\n    result = httpx.get(f\"{URL}/api/v1/spool/{spool['id']}\")\n    result.raise_for_status()\n\n    # Verify\n    assert result.json() == spool\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\ndef test_get_spool_not_found():\n    \"\"\"Test getting a spool that does not exist.\"\"\"\n    # Execute\n    result = httpx.get(f\"{URL}/api/v1/spool/123456789\")\n\n    # Verify\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"spool\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\ndef test_find_spools(random_filament: dict[str, Any]):  # noqa: PLR0915\n    \"\"\"Test finding spools in the database.\"\"\"\n    # Setup\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": 1000,\n            \"location\": \"The Pantry\",\n            \"lot_nr\": \"123456789\",\n        },\n    )\n    result.raise_for_status()\n    spool_1 = result.json()\n\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": 1000,\n            \"location\": \"Living Room\",\n            \"lot_nr\": \"987654321\",\n        },\n    )\n    result.raise_for_status()\n    spool_2 = result.json()\n\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": 1000,\n            \"archived\": True,\n        },\n    )\n    result.raise_for_status()\n    spool_3 = result.json()\n\n    added_spools_by_id = {\n        spool_1[\"id\"]: spool_1,\n        spool_2[\"id\"]: spool_2,\n        spool_3[\"id\"]: spool_3,\n    }\n\n    # Execute - find all spools\n    result = httpx.get(f\"{URL}/api/v1/spool\")\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 2\n    for spool in spools:\n        assert spool == added_spools_by_id[spool[\"id\"]]\n        assert spool[\"archived\"] is False\n\n    # Execute - find all spools, including archived\n    result = httpx.get(f\"{URL}/api/v1/spool?allow_archived=true\")\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 3\n    for spool in spools:\n        assert spool == added_spools_by_id[spool[\"id\"]]\n\n    # Execute - find spools by filament name\n    result = httpx.get(\n        f\"{URL}/api/v1/spool\",\n        params={\"filament_name\": random_filament[\"name\"]},\n    )\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 2\n    for spool in spools:\n        assert spool == added_spools_by_id[spool[\"id\"]]\n\n    # Execute - find spools by filament id\n    result = httpx.get(\n        f\"{URL}/api/v1/spool\",\n        params={\"filament_id\": random_filament[\"id\"]},\n    )\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 2\n    for spool in spools:\n        assert spool == added_spools_by_id[spool[\"id\"]]\n\n    # Execute - find spools by filament material\n    result = httpx.get(\n        f\"{URL}/api/v1/spool\",\n        params={\"filament_material\": random_filament[\"material\"]},\n    )\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 2\n    for spool in spools:\n        assert spool == added_spools_by_id[spool[\"id\"]]\n\n    # Execute - find spools by filament vendor name\n    result = httpx.get(\n        f\"{URL}/api/v1/spool\",\n        params={\"vendor_name\": random_filament[\"vendor\"][\"name\"]},\n    )\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 2\n    for spool in spools:\n        assert spool == added_spools_by_id[spool[\"id\"]]\n\n    # Execute - find spools by filament vendor id\n    result = httpx.get(\n        f\"{URL}/api/v1/spool\",\n        params={\"vendor_id\": random_filament[\"vendor\"][\"id\"]},\n    )\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 2\n    for spool in spools:\n        assert spool == added_spools_by_id[spool[\"id\"]]\n\n    # Execute - find spools by location\n    result = httpx.get(\n        f\"{URL}/api/v1/spool\",\n        params={\"location\": \"The Pantry\"},\n    )\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 1\n    assert spools[0] == added_spools_by_id[spool_1[\"id\"]]\n\n    # Execute - find spools by lot nr\n    result = httpx.get(\n        f\"{URL}/api/v1/spool\",\n        params={\"lot_nr\": \"123456789\"},\n    )\n    result.raise_for_status()\n\n    # Verify\n    spools = result.json()\n    assert len(spools) == 1\n    assert spools[0] == added_spools_by_id[spool_1[\"id\"]]\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool_1['id']}\").raise_for_status()\n    httpx.delete(f\"{URL}/api/v1/spool/{spool_2['id']}\").raise_for_status()\n    httpx.delete(f\"{URL}/api/v1/spool/{spool_3['id']}\").raise_for_status()", "\n\ndef test_delete_spool(random_filament: dict[str, Any]):\n    \"\"\"Test deleting a spool from the database.\"\"\"\n    # Setup\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": 1000,\n            \"location\": \"The Pantry\",\n            \"lot_nr\": \"123456789\",\n        },\n    )\n    result.raise_for_status()\n    spool = result.json()\n\n    # Execute\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()\n\n    # Verify\n    result = httpx.get(f\"{URL}/api/v1/spool/{spool['id']}\")\n    assert result.status_code == 404", "\n\ndef test_delete_spool_not_found():\n    \"\"\"Test deleting a spool that does not exist.\"\"\"\n    # Execute\n    result = httpx.delete(f\"{URL}/api/v1/spool/123456789\")\n\n    # Verify\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"spool\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\ndef test_update_spool(random_filament: dict[str, Any]):\n    \"\"\"Test updating a spool in the database.\"\"\"\n    # Setup\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": 1000,\n            \"location\": \"The Pantry\",\n            \"lot_nr\": \"123456789\",\n        },\n    )\n    result.raise_for_status()\n    spool = result.json()\n\n    # Execute\n    first_used = \"2023-01-01T12:00:00+02:00\"\n    last_used = \"2023-01-02T12:00:00+02:00\"\n    remaining_weight = 750\n    location = \"Living Room\"\n    lot_nr = \"987654321\"\n    comment = \"abcdefgh\u00e5\u00e4\u00f6\"\n    archived = True\n    result = httpx.patch(\n        f\"{URL}/api/v1/spool/{spool['id']}\",\n        json={\n            \"first_used\": first_used,\n            \"last_used\": last_used,\n            \"remaining_weight\": remaining_weight,\n            \"location\": location,\n            \"lot_nr\": lot_nr,\n            \"comment\": comment,\n            \"archived\": archived,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    used_weight = random_filament[\"weight\"] - remaining_weight\n    used_length = length_from_weight(\n        weight=used_weight,\n        density=random_filament[\"density\"],\n        diameter=random_filament[\"diameter\"],\n    )\n    remaining_length = length_from_weight(\n        weight=remaining_weight,\n        density=random_filament[\"density\"],\n        diameter=random_filament[\"diameter\"],\n    )\n\n    spool = result.json()\n    assert spool[\"first_used\"] == \"2023-01-01T10:00:00\"\n    assert spool[\"last_used\"] == \"2023-01-02T10:00:00\"\n    assert spool[\"remaining_weight\"] == pytest.approx(remaining_weight)\n    assert spool[\"used_weight\"] == pytest.approx(used_weight)\n    assert spool[\"remaining_length\"] == pytest.approx(remaining_length)\n    assert spool[\"used_length\"] == pytest.approx(used_length)\n    assert spool[\"location\"] == location\n    assert spool[\"lot_nr\"] == lot_nr\n    assert spool[\"comment\"] == comment\n    assert spool[\"archived\"] == archived\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\ndef test_update_spool_both_used_and_remaining_weight(random_filament: dict[str, Any]):\n    \"\"\"Test updating a spool in the database.\"\"\"\n    # Setup\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\"filament_id\": random_filament[\"id\"]},\n    )\n    result.raise_for_status()\n    spool = result.json()\n\n    # Execute\n    result = httpx.patch(\n        f\"{URL}/api/v1/spool/{spool['id']}\",\n        json={\n            \"remaining_weight\": 750,\n            \"used_weight\": 250,\n        },\n    )\n    assert result.status_code == 400  # Cannot update both used and remaining weight\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\ndef test_update_spool_not_found(random_filament: dict[str, Any]):\n    \"\"\"Test updating a spool that does not exist.\"\"\"\n    # Execute\n    result = httpx.patch(\n        f\"{URL}/api/v1/spool/123456789\",\n        json={\"filament_id\": random_filament[\"id\"]},\n    )\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"spool\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\n@pytest.mark.parametrize(\"use_weight\", [0, 0.05, -0.05, 1500])  # 1500 is big enough to use all filament\ndef test_use_spool_weight(random_filament: dict[str, Any], use_weight: float):\n    \"\"\"Test using a spool in the database.\"\"\"\n    # Setup\n    filament_net_weight = random_filament[\"weight\"]\n    start_weight = 1000\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": start_weight,\n        },\n    )\n    result.raise_for_status()\n    spool = result.json()\n\n    # Execute\n    result = httpx.put(\n        f\"{URL}/api/v1/spool/{spool['id']}/use\",\n        json={\n            \"use_weight\": use_weight,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    spool = result.json()\n    # remaining_weight should be clamped so it's never negative, but used_weight should not be clamped to the net weight\n    assert spool[\"used_weight\"] == pytest.approx(max(use_weight, 0))\n    assert spool[\"remaining_weight\"] == pytest.approx(min(max(start_weight - use_weight, 0), filament_net_weight))\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\n@pytest.mark.parametrize(\"use_length\", [0, 10, -10, 500e3])  # 500e3 is big enough to use all the filament\ndef test_use_spool_length(random_filament: dict[str, Any], use_length: float):\n    \"\"\"Test using a spool in the database.\"\"\"\n    # Setup\n    filament_net_weight = random_filament[\"weight\"]\n    start_weight = 1000\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": start_weight,\n        },\n    )\n    result.raise_for_status()\n    spool = result.json()\n\n    # Execute\n    result = httpx.put(\n        f\"{URL}/api/v1/spool/{spool['id']}/use\",\n        json={\n            \"use_length\": use_length,\n        },\n    )\n    result.raise_for_status()\n\n    # Verify\n    spool = result.json()\n    use_weight = (\n        random_filament[\"density\"] * (use_length * 1e-1) * math.pi * ((random_filament[\"diameter\"] * 1e-1 / 2) ** 2)\n    )\n    # remaining_weight should be clamped so it's never negative, but used_weight should not be clamped to the net weight\n    assert spool[\"used_weight\"] == pytest.approx(max(use_weight, 0))\n    assert spool[\"remaining_weight\"] == pytest.approx(min(max(start_weight - use_weight, 0), filament_net_weight))\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\ndef test_use_spool_weight_and_length(random_filament: dict[str, Any]):\n    \"\"\"Test using a spool in the database.\"\"\"\n    # Setup\n    result = httpx.post(\n        f\"{URL}/api/v1/spool\",\n        json={\"filament_id\": random_filament[\"id\"]},\n    )\n    result.raise_for_status()\n    spool = result.json()\n\n    # Execute\n    result = httpx.put(\n        f\"{URL}/api/v1/spool/{spool['id']}/use\",\n        json={\n            \"use_weight\": 0.05,\n            \"use_length\": 10,\n        },\n    )\n    assert result.status_code == 400  # Cannot use both weight and length\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()", "\n\ndef test_use_spool_not_found():\n    \"\"\"Test using a spool that does not exist.\"\"\"\n    # Execute\n    result = httpx.put(\n        f\"{URL}/api/v1/spool/123456789/use\",\n        json={\"use_weight\": 0.05},\n    )\n    assert result.status_code == 404\n    message = result.json()[\"message\"].lower()\n    assert \"spool\" in message\n    assert \"id\" in message\n    assert \"123456789\" in message", "\n\n@pytest.mark.asyncio()\nasync def test_use_spool_concurrent(random_filament: dict[str, Any]):\n    \"\"\"Test using a spool with many concurrent requests.\"\"\"\n    # Setup\n    start_weight = 1000\n    result = httpx.post(  # noqa: ASYNC100\n        f\"{URL}/api/v1/spool\",\n        json={", "        f\"{URL}/api/v1/spool\",\n        json={\n            \"filament_id\": random_filament[\"id\"],\n            \"remaining_weight\": start_weight,\n        },\n    )\n    result.raise_for_status()\n    spool = result.json()\n\n    # Execute", "\n    # Execute\n    requests = 100\n    used_weight = 0.5\n    async with httpx.AsyncClient() as client:\n        await asyncio.gather(\n            *(\n                client.put(\n                    f\"{URL}/api/v1/spool/{spool['id']}/use\",\n                    json={", "                    f\"{URL}/api/v1/spool/{spool['id']}/use\",\n                    json={\n                        \"use_weight\": used_weight,\n                    },\n                    timeout=60,\n                )\n                for _ in range(requests)\n            ),\n        )\n", "        )\n\n    # Verify\n    result = httpx.get(f\"{URL}/api/v1/spool/{spool['id']}\")  # noqa: ASYNC100\n    result.raise_for_status()\n    spool = result.json()\n    assert spool[\"remaining_weight\"] == pytest.approx(start_weight - (used_weight * requests))\n\n    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()  # noqa: ASYNC100", "    # Clean up\n    httpx.delete(f\"{URL}/api/v1/spool/{spool['id']}\").raise_for_status()  # noqa: ASYNC100\n"]}
{"filename": "tests_integration/tests/test_backup.py", "chunked_list": ["\"\"\"Integration tests for the Vendor API endpoint.\"\"\"\n\nimport httpx\n\nfrom .conftest import DbType, get_db_type\n\nURL = \"http://spoolman:8000\"\n\n\ndef test_backup():\n    \"\"\"Test triggering an automatic database backup.\"\"\"\n    if get_db_type() != DbType.SQLITE:\n        return\n\n    # Trigger backup\n    result = httpx.post(f\"{URL}/api/v1/backup\")\n    result.raise_for_status()", "\ndef test_backup():\n    \"\"\"Test triggering an automatic database backup.\"\"\"\n    if get_db_type() != DbType.SQLITE:\n        return\n\n    # Trigger backup\n    result = httpx.post(f\"{URL}/api/v1/backup\")\n    result.raise_for_status()\n", ""]}
{"filename": "tests_integration/tests/conftest.py", "chunked_list": ["\"\"\"Test fixtures for integration tests.\"\"\"\n\nimport math\nimport os\nimport time\nfrom enum import StrEnum\nfrom typing import Any\n\nimport httpx\nimport pytest", "import httpx\nimport pytest\n\nTIMEOUT = 10\n\nURL = \"http://spoolman:8000\"\n\n\nclass DbType(StrEnum):\n    \"\"\"Enum for database types.\"\"\"\n\n    SQLITE = \"sqlite\"\n    POSTGRES = \"postgres\"\n    MYSQL = \"mysql\"\n    COCKROACHDB = \"cockroachdb\"", "class DbType(StrEnum):\n    \"\"\"Enum for database types.\"\"\"\n\n    SQLITE = \"sqlite\"\n    POSTGRES = \"postgres\"\n    MYSQL = \"mysql\"\n    COCKROACHDB = \"cockroachdb\"\n\n\ndef get_db_type() -> DbType:\n    \"\"\"Return the database type from environment variables.\"\"\"\n    env_db_type = os.environ.get(\"DB_TYPE\")\n    if env_db_type is None:\n        raise RuntimeError(\"DB_TYPE environment variable not set\")\n    try:\n        db_type = DbType(env_db_type)\n    except ValueError as e:\n        raise RuntimeError(f\"Unknown database type: {env_db_type}\") from e\n    return db_type", "\ndef get_db_type() -> DbType:\n    \"\"\"Return the database type from environment variables.\"\"\"\n    env_db_type = os.environ.get(\"DB_TYPE\")\n    if env_db_type is None:\n        raise RuntimeError(\"DB_TYPE environment variable not set\")\n    try:\n        db_type = DbType(env_db_type)\n    except ValueError as e:\n        raise RuntimeError(f\"Unknown database type: {env_db_type}\") from e\n    return db_type", "\n\n@pytest.fixture(scope=\"session\", autouse=True)\ndef _wait_for_server():  # noqa: ANN202\n    \"\"\"Wait for the server to start up.\"\"\"\n    start_time = time.time()\n    while True:\n        try:\n            response = httpx.get(\"http://spoolman:8000\", timeout=1)\n            response.raise_for_status()\n        except httpx.HTTPError:  # noqa: PERF203\n            if time.time() - start_time > TIMEOUT:\n                raise\n        else:\n            break", "\n\n@pytest.fixture()\ndef random_vendor():\n    \"\"\"Return a random vendor.\"\"\"\n    # Add vendor\n    result = httpx.post(\n        f\"{URL}/api/v1/vendor\",\n        json={\"name\": \"John\"},\n    )\n    result.raise_for_status()\n\n    vendor = result.json()\n    yield vendor\n\n    # Delete vendor\n    httpx.delete(f\"{URL}/api/v1/vendor/{vendor['id']}\").raise_for_status()", "\n\n@pytest.fixture()\ndef random_filament(random_vendor: dict[str, Any]):\n    \"\"\"Return a random filament.\"\"\"\n    # Add filament\n    result = httpx.post(\n        f\"{URL}/api/v1/filament\",\n        json={\n            \"name\": \"Filament X\",\n            \"vendor_id\": random_vendor[\"id\"],\n            \"material\": \"PLA\",\n            \"price\": 100,\n            \"density\": 1.25,\n            \"diameter\": 1.75,\n            \"weight\": 1000,\n            \"spool_weight\": 250,\n            \"article_number\": \"123456789\",\n            \"comment\": \"abcdefgh\u00e5\u00e4\u00f6\",\n        },\n    )\n    result.raise_for_status()\n\n    filament = result.json()\n    yield filament\n\n    # Delete filament\n    httpx.delete(f\"{URL}/api/v1/filament/{filament['id']}\").raise_for_status()", "\n\ndef length_from_weight(*, weight: float, diameter: float, density: float) -> float:\n    \"\"\"Calculate the length of a piece of filament.\n\n    Args:\n        weight (float): Filament weight in g\n        diameter (float): Filament diameter in mm\n        density (float): Density of filament material in g/cm3\n\n    Returns:\n        float: Length in mm\n    \"\"\"\n    volume_cm3 = weight / density\n    volume_mm3 = volume_cm3 * 1000\n    return volume_mm3 / (math.pi * (diameter / 2) ** 2)", ""]}
