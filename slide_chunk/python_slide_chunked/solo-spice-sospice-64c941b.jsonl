{"filename": "sospice/__init__.py", "chunked_list": ["from ._version import __version__, __version_tuple__\nfrom .catalog.catalog import Catalog\nfrom .catalog.release import Release\nfrom .catalog.file_metadata import FileMetadata\nfrom .calibrate.uncertainties import spice_error\n"]}
{"filename": "sospice/tests/__init__.py", "chunked_list": [""]}
{"filename": "sospice/data/__init__.py", "chunked_list": [""]}
{"filename": "sospice/data/tests/__init__.py", "chunked_list": [""]}
{"filename": "sospice/util/rss.py", "chunked_list": ["import numpy as np\n\n\ndef rss(a, axis=None):\n    \"\"\"\n    Root sum square of array elements\n\n    Parameters\n    ----------\n    a: numpy.array\n        Input values\n    axis: None or int or tuple of ints\n        Axis or axes along which the root-sum-square is performed.\n    Return\n    ------\n    float\n        Root sum square of input values over a given axis\n    \"\"\"\n    return np.linalg.norm(a, axis=axis)", ""]}
{"filename": "sospice/util/__init__.py", "chunked_list": ["from .rss import rss\n"]}
{"filename": "sospice/util/tests/test_rss.py", "chunked_list": ["import numpy as np\nfrom ..rss import rss\n\n\ndef test_rss():\n    a = np.array([3, 4])\n    assert np.isclose(rss(a), 5.0)\n    a = np.array([[3, 4, 5], [5, 4, 3]])\n    assert np.isclose(rss(a), 10.0)\n    assert np.allclose(rss(a, axis=0), np.sqrt([34, 32, 34]))\n    assert np.allclose(rss(a, axis=1), np.sqrt([50, 50]))", ""]}
{"filename": "sospice/util/tests/__init__.py", "chunked_list": [""]}
{"filename": "sospice/catalog/catalog.py", "chunked_list": ["from dataclasses import dataclass\n\nimport pandas as pd\nfrom pathlib import Path\nfrom astropy.utils.data import download_file\n\nfrom .release import Release\nfrom .file_metadata import required_columns\n\n", "\n\n@dataclass\nclass Catalog(pd.DataFrame):\n    \"\"\"\n    A SPICE catalog, initialized (in that order) either from a filename, a release tag, or a pandas.DataFrame.\n\n    Parameters\n    ----------\n    filename: str\n        A file name (or URL) for the catalog\n    release_tag: str\n        A release tag. The catalog is fetched online and dowloaded to the astropy cache.\n    data_frame: pandas.DataFrame\n        A pandas DataFrame to be used as SPICE catalog. Some basic checks are made to ensure\n        that is can be used as a SPICE catalog.\n    update_cache: bool\n        Update cached catalog for the given release tag\n    \"\"\"\n\n    filename: str = None\n    release_tag: str = None\n    data_frame: pd.DataFrame = None\n    update_cache: bool = False\n\n    def __post_init__(self):\n        \"\"\"\n        Read catalog and update object\n        \"\"\"\n        self._normalize_arguments()\n        if self.release_tag is not None:\n            self._cache_release_catalog()\n        if self.filename is not None:\n            super().__init__(self.read_catalog())\n        else:\n            if self.data_frame is None:\n                self.data_frame = pd.DataFrame()\n            self._validate_data_frame()\n            super().__init__(self.data_frame)\n            del self.data_frame  # needed for memory usage?\n            self.data_frame = None\n\n    def _normalize_arguments(self):\n        \"\"\"\n        Prioritize filename then release tag then data frame\n        \"\"\"\n        if self.filename is not None:\n            self.release_tag = None\n            self.data_frame = None\n        elif self.release_tag is not None:\n            self.data_frame = None\n\n    def _cache_release_catalog(self):\n        \"\"\"\n        Used cached catalog or download release catalog to astropy cache\n        \"\"\"\n        if self.release_tag is None:\n            return\n        if self.release_tag == \"latest\":\n            self.release_tag = None\n        release = Release(self.release_tag)\n        assert release.exists\n        self.filename = download_file(release.catalog_url, cache=True)\n        self.release_tag = None\n\n    def _validate_data_frame(self):\n        \"\"\"\n        Check that the data_frame argument can be considered a valid SPICE catalog (or raise an exception)\n        \"\"\"\n        assert self.data_frame is not None\n        if self.data_frame.empty:\n            return True  # an empty data frame is valid\n        assert required_columns.issubset(self.data_frame.columns)\n\n    def read_catalog(self):\n        \"\"\"\n        Read SPICE FITS files catalog\n\n        Return\n        ------\n        pandas.DataFrame\n            Catalog\n        \"\"\"\n        if not Path(self.filename).exists():\n            raise RuntimeError(f\"File {self.filename} does not exist\")\n        df = pd.read_csv(\n            self.filename,\n            low_memory=False,\n        )\n        date_columns = [\"DATE-BEG\", \"DATE\", \"TIMAQUTC\"]\n        for date_column in date_columns:\n            df.loc[df[date_column] == \"MISSING\", date_column] = \"NaT\"\n            df[date_column] = pd.to_datetime(df[date_column], format=\"ISO8601\")\n        return df\n\n    @classmethod\n    def build_query_from_keywords(cls, **kwargs):\n        \"\"\"\n        Build a query from the provided parameters: exact keyword matches\n\n        Parameters\n        ----------\n        kwargs: dict\n            Parameters and their values\n\n        Return\n        ------\n        str\n            Query string for `pandas.DataFrame.query()`\n\n        Notes:\n\n        * does not work for dates\n        * keywords are converted to upper case (FITS keywords)\n        * ignores keywords with value None\n        \"\"\"\n        queries = list()\n        for key in kwargs:\n            value = kwargs[key]\n            if value is None:\n                continue\n            if isinstance(value, str):\n                query = f'{key.upper()} == \"{kwargs[key]}\"'\n            else:\n                query = f\"{key.upper()} == {kwargs[key]}\"\n            queries.append(query)\n        return \" and \".join(queries)\n\n    def find_files_by_keywords(self, **kwargs):\n        \"\"\"\n        Find files according to criteria on metadata: exact keyword matches\n\n        Parameters\n        ----------\n        kwargs: dict\n            Parameters and their values\n\n        Return\n        ------\n        Catalog\n            Matching files\n        \"\"\"\n        if self.empty or not kwargs:\n            return self\n        query = Catalog.build_query_from_keywords(**kwargs)\n        if query != \"\":\n            df = self.query(query)\n            return Catalog(data_frame=df)\n        else:\n            return self\n\n    def find_files_by_date_range(self, date_min=None, date_max=None):\n        \"\"\"\n        Find files in some date range.\n\n        Parameters\n        ----------\n        date_min:\n            Minimum date of a date range\n        date_max:\n            Maximum date of a date range\n\n        Return\n        ------\n        Catalog\n            Matching files\n        \"\"\"\n        if self.empty:\n            return self\n        df = self\n        if date_min is not None:\n            if type(date_min) is str:\n                date_min = pd.Timestamp(date_min)\n            df = df[df[\"DATE-BEG\"] >= date_min]\n        if date_max is not None:\n            if type(date_max) is str:\n                date_max = pd.Timestamp(date_max)\n            df = df[df[\"DATE-BEG\"] <= date_max]\n        return Catalog(data_frame=df)\n\n    def find_file_closest_to_date(self, date, level=\"L2\"):\n        \"\"\"\n        Find file closest to some given date\n\n        Parameters\n        ----------\n        date: datetime.datetime, pandas.Timestamp...\n            Date (compared to DATE-BEG)\n        level: str\n            Data level\n\n        Return\n        ------\n        pandas.Series\n            Matching file\n        \"\"\"\n        if date is None:\n            return pd.Series()\n        if type(date) is str:\n            date = pd.Timestamp(date)\n        df = self[self.LEVEL == level]\n        df.set_index(\"DATE-BEG\", inplace=True)\n        index = df.index.get_indexer([date], method=\"nearest\")\n        df.reset_index(inplace=True)\n        return df.iloc[index[0]]\n\n    def find_files(\n        self, query=None, date_min=None, date_max=None, closest_to_date=None, **kwargs\n    ):\n        \"\"\"\n        Find files according to different criteria on metadata.\n\n        Parameters\n        ----------\n        query: str\n            Generic pandas.DataFrame.query() string\n        date_min:\n            Minimum date of a date range\n        date_max:\n            Maximum date of a date range\n        closest_to_date: datetime.datetime, pandas.Timestamp...\n            Find the file closest to a date.\n        kwargs: dict\n            Other parameters and their values\n\n        Return\n        ------\n        pandas.DataFrame\n            Matching files\n\n        Notes:\n\n        * Filtering is done by keyword exact match (LEVEL, SOOPNAME, MISOSTDU...),\n          then using the generic query string, then by date range, then by closest date.\n        * Keywords are converted to upper case (FITS keywords), so they can be passed as lowercase arguments\n        * Selects LEVEL=\"L2\" by default; if you want all levels, please specify LEVEL=None\n        * Date arguments are compared to DATE-BEG.\n        \"\"\"\n        if self.empty:\n            return self\n        if \"LEVEL\" not in [k.upper() for k in kwargs.keys()]:\n            kwargs[\"LEVEL\"] = \"L2\"\n        df = self.find_files_by_keywords(**kwargs)\n        if query is not None:\n            df = Catalog(data_frame=df.query(query))\n        df = df.find_files_by_date_range(date_min, date_max)\n        if closest_to_date is not None:\n            df = (\n                df.find_file_closest_to_date(closest_to_date, level=kwargs[\"LEVEL\"])\n                .to_frame()\n                .T\n            )\n        return df", ""]}
{"filename": "sospice/catalog/file_metadata.py", "chunked_list": ["from dataclasses import dataclass\nfrom pathlib import Path\n\nimport pandas as pd\n\nfrom astropy.utils.data import download_file\nfrom parfive import Downloader\n\nfrom .release import Release\n", "from .release import Release\n\nrequired_columns = {\n    \"NAXIS1\",\n    \"NAXIS2\",\n    \"NAXIS3\",\n    \"NAXIS4\",\n    \"OBT_BEG\",\n    \"LEVEL\",\n    \"FILENAME\",", "    \"LEVEL\",\n    \"FILENAME\",\n    \"DATE-BEG\",\n    \"SPIOBSID\",\n    \"RASTERNO\",\n    \"STUDYTYP\",\n    \"MISOSTUD\",\n    \"XPOSURE\",\n    \"CRVAL1\",\n    \"CDELT1\",", "    \"CRVAL1\",\n    \"CDELT1\",\n    \"CRVAL2\",\n    \"CDELT2\",\n    \"STP\",\n    \"DSUN_AU\",\n    \"CROTA\",\n    \"OBS_ID\",\n    \"SOOPNAME\",\n    \"SOOPTYPE\",", "    \"SOOPNAME\",\n    \"SOOPTYPE\",\n    \"NWIN\",\n    \"DARKMAP\",\n    \"COMPLETE\",\n    \"SLIT_WID\",\n    \"DATE\",\n    \"PARENT\",\n    \"HGLT_OBS\",\n    \"HGLN_OBS\",", "    \"HGLT_OBS\",\n    \"HGLN_OBS\",\n    \"PRSTEP1\",\n    \"PRPROC1\",\n    \"PRPVER1\",\n    \"PRPARA1\",\n}\n\n\n@dataclass\nclass FileMetadata:\n    \"\"\"\n    A SPICE file entry in the SPICE catalog\n\n    Parameters\n    ----------\n    metadata: pandas.Series\n        File metadata\n    skip_validation: bool\n        Do no validate data\n    \"\"\"\n\n    metadata: pd.Series = None\n    skip_validation: bool = False\n\n    def __post_init__(self):\n        \"\"\"\n        Update object\n        \"\"\"\n        if not self.skip_validation:\n            self.validate()\n\n    def validate(self):\n        \"\"\"\n        Check file metadata\n        \"\"\"\n        assert self.metadata is not None\n        assert not self.metadata.empty\n        assert required_columns.issubset(self.metadata.keys())\n\n    def _get_file_url_from_base_url(self, base_url):\n        \"\"\"\n        Get URL for a file located under some base URL\n\n        Parameters\n        ----------\n        base_url: str\n            Base URL\n\n        Return\n        ------\n        str\n            File URL\n\n        Notes:\n\n        * There is no guarantee that the URL corresponds to an existing location\n        * The base URL can be a path on disk, but paths are built using \"/\"\n        and this might not work on all operating systems.\n        \"\"\"\n        if not base_url.endswith(\"/\"):\n            base_url += \"/\"\n        return base_url + self.metadata.FILE_PATH + \"/\" + self.metadata.FILENAME\n\n    def get_file_url(self, base_url=None, release=None):\n        \"\"\"\n        Get file URL, from a release, from some other online file tree, or from SOAR if no parameter has been provided\n\n        Parameters\n        ----------\n        base_url: str\n            Base URL for file\n        release: Release or str\n            Release to download file from. This can be a Release object, or a string for the release tag.\n\n        Return\n        ------\n        str\n            File URL\n        \"\"\"\n        if release is not None:\n            if type(release) is str:\n                release = Release(release)\n            url = self._get_file_url_from_base_url(release.url)\n        elif base_url is not None:\n            url = self._get_file_url_from_base_url(base_url)\n        else:\n            url = \"http://soar.esac.esa.int/soar-sl-tap/data\"\n            url += \"?retrieval_type=ALL_PRODUCTS\"\n            url += \"&QUERY=SELECT+filepath,filename+FROM+soar.v_sc_repository_file\"\n            url += f\"+WHERE+filename='{self.metadata.FILENAME}'\"\n        return url\n\n    def cache_file(self, base_url=None, release=None, update=False):\n        \"\"\"\n        Put file in local disk cache, from a release, from some other online\n        file tree, or from SOAR if no parameter has been provided\n\n        Parameters\n        ----------\n        base_url: str\n            Base URL for file\n        release: Release or str\n            Release to download file from\n        update: bool\n            Whether to update the cached file\n\n        Return\n        ------\n        Path\n            Cache file location\n\n        The cache is managed by `astropy.utils.data`.\n        \"\"\"\n        url = self.get_file_url(base_url=base_url, release=release)\n        cache = \"update\" if update else True\n        filename = download_file(url, cache=cache)\n        return Path(filename)\n\n    def download_file(\n        self, base_dir, base_url=None, release=None, keep_tree=True, downloader=None\n    ):\n        \"\"\"\n        Download file, from a release, from some other online file tree,\n        or from SOAR if no parameter has been provided\n\n        Parameters\n        ----------\n        base_dir: Path or str\n            Base directory to download file to\n        base_url: str\n            Base URL for file\n        release: Release or str\n            Release to download file from\n        keep_tree: bool\n            Keep tree directory structure (by level and date)\n        downloader: parfive.Downloader\n            If provided, enqueue file for download instead of downloading it.\n            To download enqueued files, run `downloader.download()`\n\n        Return\n        ------\n        parfive.Result\n            Download result (or None if file has only been enqueued)\n        \"\"\"\n        url = self.get_file_url(base_url=base_url, release=release)\n        if keep_tree:\n            destination = Path(base_dir) / self.metadata.FILE_PATH\n            destination.mkdir(parents=True, exist_ok=True)\n        else:\n            destination = Path(base_dir)\n        do_download = False\n        if downloader is None:\n            downloader = Downloader(overwrite=False)\n            do_download = True\n        downloader.enqueue_file(url, destination, self.metadata.FILENAME)\n        if do_download:\n            result = downloader.download()\n            return result\n        return None", "\n@dataclass\nclass FileMetadata:\n    \"\"\"\n    A SPICE file entry in the SPICE catalog\n\n    Parameters\n    ----------\n    metadata: pandas.Series\n        File metadata\n    skip_validation: bool\n        Do no validate data\n    \"\"\"\n\n    metadata: pd.Series = None\n    skip_validation: bool = False\n\n    def __post_init__(self):\n        \"\"\"\n        Update object\n        \"\"\"\n        if not self.skip_validation:\n            self.validate()\n\n    def validate(self):\n        \"\"\"\n        Check file metadata\n        \"\"\"\n        assert self.metadata is not None\n        assert not self.metadata.empty\n        assert required_columns.issubset(self.metadata.keys())\n\n    def _get_file_url_from_base_url(self, base_url):\n        \"\"\"\n        Get URL for a file located under some base URL\n\n        Parameters\n        ----------\n        base_url: str\n            Base URL\n\n        Return\n        ------\n        str\n            File URL\n\n        Notes:\n\n        * There is no guarantee that the URL corresponds to an existing location\n        * The base URL can be a path on disk, but paths are built using \"/\"\n        and this might not work on all operating systems.\n        \"\"\"\n        if not base_url.endswith(\"/\"):\n            base_url += \"/\"\n        return base_url + self.metadata.FILE_PATH + \"/\" + self.metadata.FILENAME\n\n    def get_file_url(self, base_url=None, release=None):\n        \"\"\"\n        Get file URL, from a release, from some other online file tree, or from SOAR if no parameter has been provided\n\n        Parameters\n        ----------\n        base_url: str\n            Base URL for file\n        release: Release or str\n            Release to download file from. This can be a Release object, or a string for the release tag.\n\n        Return\n        ------\n        str\n            File URL\n        \"\"\"\n        if release is not None:\n            if type(release) is str:\n                release = Release(release)\n            url = self._get_file_url_from_base_url(release.url)\n        elif base_url is not None:\n            url = self._get_file_url_from_base_url(base_url)\n        else:\n            url = \"http://soar.esac.esa.int/soar-sl-tap/data\"\n            url += \"?retrieval_type=ALL_PRODUCTS\"\n            url += \"&QUERY=SELECT+filepath,filename+FROM+soar.v_sc_repository_file\"\n            url += f\"+WHERE+filename='{self.metadata.FILENAME}'\"\n        return url\n\n    def cache_file(self, base_url=None, release=None, update=False):\n        \"\"\"\n        Put file in local disk cache, from a release, from some other online\n        file tree, or from SOAR if no parameter has been provided\n\n        Parameters\n        ----------\n        base_url: str\n            Base URL for file\n        release: Release or str\n            Release to download file from\n        update: bool\n            Whether to update the cached file\n\n        Return\n        ------\n        Path\n            Cache file location\n\n        The cache is managed by `astropy.utils.data`.\n        \"\"\"\n        url = self.get_file_url(base_url=base_url, release=release)\n        cache = \"update\" if update else True\n        filename = download_file(url, cache=cache)\n        return Path(filename)\n\n    def download_file(\n        self, base_dir, base_url=None, release=None, keep_tree=True, downloader=None\n    ):\n        \"\"\"\n        Download file, from a release, from some other online file tree,\n        or from SOAR if no parameter has been provided\n\n        Parameters\n        ----------\n        base_dir: Path or str\n            Base directory to download file to\n        base_url: str\n            Base URL for file\n        release: Release or str\n            Release to download file from\n        keep_tree: bool\n            Keep tree directory structure (by level and date)\n        downloader: parfive.Downloader\n            If provided, enqueue file for download instead of downloading it.\n            To download enqueued files, run `downloader.download()`\n\n        Return\n        ------\n        parfive.Result\n            Download result (or None if file has only been enqueued)\n        \"\"\"\n        url = self.get_file_url(base_url=base_url, release=release)\n        if keep_tree:\n            destination = Path(base_dir) / self.metadata.FILE_PATH\n            destination.mkdir(parents=True, exist_ok=True)\n        else:\n            destination = Path(base_dir)\n        do_download = False\n        if downloader is None:\n            downloader = Downloader(overwrite=False)\n            do_download = True\n        downloader.enqueue_file(url, destination, self.metadata.FILENAME)\n        if do_download:\n            result = downloader.download()\n            return result\n        return None", ""]}
{"filename": "sospice/catalog/__init__.py", "chunked_list": ["from .release import Release\nfrom .catalog import Catalog\nfrom .file_metadata import FileMetadata\n"]}
{"filename": "sospice/catalog/release.py", "chunked_list": ["from dataclasses import dataclass\nimport requests\n\n\n@dataclass\nclass Release:\n    tag: str = None\n    base_url: str = \"https://spice.osups.universite-paris-saclay.fr/spice-data/\"\n    _latest_tag: str = None\n\n    def __post_init__(self):\n        \"\"\"\n        Initialize object to latest release if no release tag set\n        \"\"\"\n        if self.tag is None:\n            self.tag = self.latest_tag\n\n    @property\n    def url(self):\n        \"\"\"\n        Return\n        ------\n        str\n            Release URL\n        \"\"\"\n        return f\"{self.base_url}release-{self.tag}/\"\n\n    @property\n    def catalog_url(self):\n        \"\"\"\n        Return\n        ------\n        str\n            Catalog URL for release\n        \"\"\"\n        return self.url + \"catalog.csv\"\n\n    @property\n    def latest_tag(self):\n        \"\"\"\n        Return\n        ------\n        str\n            Tag of latest release\n        \"\"\"\n        if self._latest_tag is None:\n            url = f\"{self.base_url}metadata/latest-release.txt\"\n            result = requests.get(url)\n            if not result.ok:\n                raise RuntimeError(\n                    \"Could not access URL for file with latest release tag\"\n                )\n            self._latest_tag = result.text.split(\"\\n\")[0]\n        return self._latest_tag\n\n    @property\n    def is_latest(self):\n        \"\"\"\n        Return\n        ------\n        bool\n            True is object corresponds to latest release\n        \"\"\"\n        return self.tag == self.latest_tag\n\n    @property\n    def exists(self):\n        \"\"\"\n        Return\n        ------\n        bool\n            True if release exists (is accessible online)\n        \"\"\"\n        result = requests.get(self.url)\n        return result.ok", "\n\ndef get_latest_release_tag():\n    \"\"\"\n    Return\n    ------\n    str\n        Latest available release tag\n    \"\"\"\n    release = Release()\n    return release.latest_tag", ""]}
{"filename": "sospice/catalog/tests/test_file_metadata.py", "chunked_list": ["import pytest\nfrom pathlib import Path\n\nimport pandas as pd\nfrom parfive import Downloader\nimport shutil\n\nfrom ..file_metadata import FileMetadata\nfrom .test_catalog import catalog2  # noqa: F401\nfrom .test_release import release2  # noqa: F401", "from .test_catalog import catalog2  # noqa: F401\nfrom .test_release import release2  # noqa: F401\n\n\n@pytest.fixture\ndef filename():  # noqa: F811\n    return \"solo_L2_spice-n-exp_20220305T072522_V01_100663707-014.fits\"\n\n\n@pytest.fixture\ndef file_metadata(catalog2, filename):  # noqa: F811\n    metadata = catalog2[catalog2.FILENAME == filename].iloc[0]\n    return FileMetadata(metadata)", "\n@pytest.fixture\ndef file_metadata(catalog2, filename):  # noqa: F811\n    metadata = catalog2[catalog2.FILENAME == filename].iloc[0]\n    return FileMetadata(metadata)\n\n\nclass TestFileMetadata:\n    def test_get_file_url(self, file_metadata, release2, filename):  # noqa: F811\n        expected = \"https://foobar/level2/2022/03/05/\" + filename\n        assert file_metadata.get_file_url(base_url=\"https://foobar/\") == expected\n        assert file_metadata.get_file_url(base_url=\"https://foobar\") == expected\n        expected = (\n            \"https://spice.osups.universite-paris-saclay.fr/spice-data/release-2.0/level2/2022/03/05/\"\n            + filename  # noqa: W503\n        )\n        assert file_metadata.get_file_url(release=release2) == expected\n        assert file_metadata.get_file_url(release=\"2.0\") == expected\n        expected = \"http://soar.esac.esa.int/soar-sl-tap/data?retrieval_type=ALL_PRODUCTS&QUERY=\"\n        expected += f\"SELECT+filepath,filename+FROM+soar.v_sc_repository_file+WHERE+filename='{filename}'\"\n        assert file_metadata.get_file_url() == expected\n\n    def test_cache_file(self, file_metadata, release2):  # noqa: F811\n        file_path = file_metadata.cache_file(release=release2)\n        assert file_path.exists()\n        now = pd.Timestamp(\"now\", tz=\"UTC\")\n        file_path = file_metadata.cache_file(release=release2, update=True)\n        assert file_path.exists()\n        mtime = pd.Timestamp(file_path.stat().st_mtime, unit=\"s\", tz=\"UTC\")\n        assert pd.Timestamp(mtime) >= now\n\n    def test_download_file(self, file_metadata, release2, filename):  # noqa: F811\n        base_dir = Path(\"./local/test_download_file\")\n        if base_dir.exists():\n            shutil.rmtree(base_dir)\n        result = file_metadata.download_file(\n            base_dir, release=release2, keep_tree=False\n        )\n        assert len(result) == 1\n        assert result[0] == (base_dir / filename).as_posix()\n        result = file_metadata.download_file(base_dir, release=release2)\n        expected = (base_dir / file_metadata.metadata.FILE_PATH / filename).as_posix()\n        assert len(result) == 1\n        assert result[0] == expected\n        downloader = Downloader(overwrite=False)\n        result = file_metadata.download_file(  # noqa: F841\n            base_dir, release=release2, downloader=downloader\n        )\n        assert result is None\n        assert downloader.queued_downloads == 1", ""]}
{"filename": "sospice/catalog/tests/test_catalog.py", "chunked_list": ["import pytest\nfrom datetime import datetime\nimport pandas as pd\n\n\nfrom ..catalog import Catalog\n\n\n@pytest.fixture\ndef catalog2():\n    return Catalog(release_tag=\"2.0\")", "@pytest.fixture\ndef catalog2():\n    return Catalog(release_tag=\"2.0\")\n\n\n@pytest.fixture\ndef catalog_latest():\n    return Catalog(release_tag=\"latest\")\n\n", "\n\n@pytest.fixture\ndef catalog_empty():\n    return Catalog()\n\n\n@pytest.fixture\ndef catalog_df():\n    df = pd.DataFrame(\n        {\n            \"NAXIS1\": [12, 15, 20],\n            \"NAXIS2\": [100, 101, 102],\n            \"NAXIS3\": [41, 44, 47],\n            \"NAXIS4\": [1, 1, 1],\n            \"OBT_BEG\": [0, 0, 0],\n            \"LEVEL\": [\"L2\", 0, 0],\n            \"FILENAME\": [0, 0, 0],\n            \"DATE-BEG\": [pd.Timestamp(\"2023-02-01T12:34\"), 0, 0],\n            \"SPIOBSID\": [0, 0, 0],\n            \"RASTERNO\": [0, 0, 0],\n            \"STUDYTYP\": [0, 0, 0],\n            \"MISOSTUD\": [0, 0, 0],\n            \"XPOSURE\": [0, 0, 0],\n            \"CRVAL1\": [0, 0, 0],\n            \"CDELT1\": [0, 0, 0],\n            \"CRVAL2\": [0, 0, 0],\n            \"CDELT2\": [0, 0, 0],\n            \"STP\": [0, 0, 0],\n            \"DSUN_AU\": [0, 0, 0],\n            \"CROTA\": [0, 0, 0],\n            \"OBS_ID\": [0, 0, 0],\n            \"SOOPNAME\": [0, 0, 0],\n            \"SOOPTYPE\": [0, 0, 0],\n            \"NWIN\": [0, 0, 0],\n            \"DARKMAP\": [0, 0, 0],\n            \"COMPLETE\": [0, 0, 0],\n            \"SLIT_WID\": [0, 0, 0],\n            \"DATE\": [0, 0, 0],\n            \"PARENT\": [0, 0, 0],\n            \"HGLT_OBS\": [0, 0, 0],\n            \"HGLN_OBS\": [0, 0, 0],\n            \"PRSTEP1\": [0, 0, 0],\n            \"PRPROC1\": [0, 0, 0],\n            \"PRPVER1\": [0, 0, 0],\n            \"PRPARA1\": [0, 0, 0],\n            \"proc_steps\": [\n                '[{\"PRPROC\": \"JPEG Compression (On-board)\"},'\n                ' {\"PRPROC\": \"spice_prep_dark_offset_correction.pro\",'\n                ' \"PRPVER\": \"1.3\", \"PRPARA\": \"dark_spiobsid=117440828\"}]',\n                0,\n                0,\n            ],\n        }\n    )\n    return Catalog(data_frame=df)", "def catalog_df():\n    df = pd.DataFrame(\n        {\n            \"NAXIS1\": [12, 15, 20],\n            \"NAXIS2\": [100, 101, 102],\n            \"NAXIS3\": [41, 44, 47],\n            \"NAXIS4\": [1, 1, 1],\n            \"OBT_BEG\": [0, 0, 0],\n            \"LEVEL\": [\"L2\", 0, 0],\n            \"FILENAME\": [0, 0, 0],\n            \"DATE-BEG\": [pd.Timestamp(\"2023-02-01T12:34\"), 0, 0],\n            \"SPIOBSID\": [0, 0, 0],\n            \"RASTERNO\": [0, 0, 0],\n            \"STUDYTYP\": [0, 0, 0],\n            \"MISOSTUD\": [0, 0, 0],\n            \"XPOSURE\": [0, 0, 0],\n            \"CRVAL1\": [0, 0, 0],\n            \"CDELT1\": [0, 0, 0],\n            \"CRVAL2\": [0, 0, 0],\n            \"CDELT2\": [0, 0, 0],\n            \"STP\": [0, 0, 0],\n            \"DSUN_AU\": [0, 0, 0],\n            \"CROTA\": [0, 0, 0],\n            \"OBS_ID\": [0, 0, 0],\n            \"SOOPNAME\": [0, 0, 0],\n            \"SOOPTYPE\": [0, 0, 0],\n            \"NWIN\": [0, 0, 0],\n            \"DARKMAP\": [0, 0, 0],\n            \"COMPLETE\": [0, 0, 0],\n            \"SLIT_WID\": [0, 0, 0],\n            \"DATE\": [0, 0, 0],\n            \"PARENT\": [0, 0, 0],\n            \"HGLT_OBS\": [0, 0, 0],\n            \"HGLN_OBS\": [0, 0, 0],\n            \"PRSTEP1\": [0, 0, 0],\n            \"PRPROC1\": [0, 0, 0],\n            \"PRPVER1\": [0, 0, 0],\n            \"PRPARA1\": [0, 0, 0],\n            \"proc_steps\": [\n                '[{\"PRPROC\": \"JPEG Compression (On-board)\"},'\n                ' {\"PRPROC\": \"spice_prep_dark_offset_correction.pro\",'\n                ' \"PRPVER\": \"1.3\", \"PRPARA\": \"dark_spiobsid=117440828\"}]',\n                0,\n                0,\n            ],\n        }\n    )\n    return Catalog(data_frame=df)", "\n\nclass TestCatalog:\n    def test_init_filename(self):\n        filename = \"wepocmwkx.fts\"\n        with pytest.raises(RuntimeError, match=\"does not exist\"):\n            catalog = Catalog(filename)  # noqa: F841\n\n    def test_init_release(self, catalog2, catalog_latest):\n        columns = {\n            \"NAXIS1\",\n            \"NAXIS2\",\n            \"NAXIS3\",\n            \"NAXIS4\",\n            \"OBT_BEG\",\n            \"LEVEL\",\n        }\n        assert columns.issubset(catalog2.columns)\n        assert len(catalog2) > 10000\n        assert columns.issubset(catalog_latest.columns)\n        assert len(catalog_latest) > 10000\n        assert catalog_latest._cache_release_catalog() is None\n\n    def test_init_empty(self, catalog_empty):\n        assert len(catalog_empty) == 0\n        assert len(catalog_empty.columns) == 0\n\n    def test_init_dataframe(self, catalog_df):\n        assert len(catalog_df) == 3\n        assert len(catalog_df.columns) == 36\n        assert catalog_df.iloc[1].NAXIS2 == 101\n\n    def test_find_files_by_keywords(self, catalog2):\n        result = catalog2.find_files_by_keywords()\n        assert len(result) == 15643\n        result = catalog2.find_files_by_keywords(level=None)\n        assert len(result) == 15643\n        result = catalog2.find_files_by_keywords(level=\"L2\")\n        assert len(result) == 7756\n        result = catalog2.find_files_by_keywords(level=\"L2\", nbin3=2)\n        assert len(result) == 201\n\n    def test_find_files_by_date_range(self, catalog2):\n        result = Catalog().find_files_by_date_range()\n        assert result.empty\n        result = catalog2.find_files_by_date_range()\n        assert len(result) == 15643\n        result = catalog2.find_files_by_date_range(date_min=\"2022-01-01\")\n        assert len(result) == 14039\n        assert result[\"DATE-BEG\"].min() > pd.Timestamp(\"2022-01-01\")\n        result = catalog2.find_files_by_date_range(\n            date_min=\"2022-01-01\", date_max=\"2022-03-01\"\n        )\n        assert len(result) == 1711\n        assert result[\"DATE-BEG\"].max() < pd.Timestamp(\"2022-03-01\")\n\n    def test_find_file_closest_to_date(self, catalog2):\n        expected_filename = \"solo_L2_spice-n-exp_20211204T120022_V02_83886365-000.fits\"\n        result = catalog2.find_file_closest_to_date(pd.Timestamp(\"2021-10-10\"))\n        assert result.FILENAME == expected_filename\n        result = catalog2.find_file_closest_to_date(datetime(2021, 10, 10))\n        assert result.FILENAME == expected_filename\n        result = catalog2.find_file_closest_to_date(\"2021-10-10\")\n        assert result.FILENAME == expected_filename\n        result = catalog2.find_file_closest_to_date(None)\n        assert result.empty\n\n    def test_find_files(self, catalog2):\n        result = Catalog().find_files()\n        assert result.empty\n        result = catalog2.find_files()\n        assert len(result) == 7756\n        result = catalog2.find_files(level=None)\n        assert len(result) == 15643\n        result = catalog2.find_files(query=\"NBIN3==2\")\n        assert len(result) == 201\n        expected_filename = \"solo_L2_spice-n-exp_20211204T120022_V02_83886365-000.fits\"\n        result = catalog2.find_files(closest_to_date=\"2021-10-10\")\n        assert len(result) == 1\n        assert result.iloc[0].FILENAME == expected_filename", ""]}
{"filename": "sospice/catalog/tests/__init__.py", "chunked_list": [""]}
{"filename": "sospice/catalog/tests/test_release.py", "chunked_list": ["import pytest\n\nfrom ..release import Release, get_latest_release_tag\n\n\n@pytest.fixture\ndef release2():\n    return Release(\"2.0\")\n\n\nclass TestRelease:\n    def test_init(self, release2):\n        assert release2.tag == \"2.0\"\n        assert release2.base_url.startswith(\n            \"https://spice.osups.universite-paris-saclay.fr\"\n        )\n        assert release2.url.endswith(\"2.0/\")\n        assert release2.catalog_url.endswith(\"/catalog.csv\")\n        assert release2.exists  # online access\n        assert not release2.is_latest  # online access\n\n    def test_latest(self):  # online access\n        release = Release()\n        assert release.tag != \"2.0\"\n        assert release.base_url.startswith(\n            \"https://spice.osups.universite-paris-saclay.fr\"\n        )\n        assert release.catalog_url.endswith(\"/catalog.csv\")\n        assert release.exists\n        assert release.is_latest\n\n    def test_get_latest(self):\n        assert get_latest_release_tag() != \"2.0\"", "\n\nclass TestRelease:\n    def test_init(self, release2):\n        assert release2.tag == \"2.0\"\n        assert release2.base_url.startswith(\n            \"https://spice.osups.universite-paris-saclay.fr\"\n        )\n        assert release2.url.endswith(\"2.0/\")\n        assert release2.catalog_url.endswith(\"/catalog.csv\")\n        assert release2.exists  # online access\n        assert not release2.is_latest  # online access\n\n    def test_latest(self):  # online access\n        release = Release()\n        assert release.tag != \"2.0\"\n        assert release.base_url.startswith(\n            \"https://spice.osups.universite-paris-saclay.fr\"\n        )\n        assert release.catalog_url.endswith(\"/catalog.csv\")\n        assert release.exists\n        assert release.is_latest\n\n    def test_get_latest(self):\n        assert get_latest_release_tag() != \"2.0\"", ""]}
{"filename": "sospice/instrument_modelling/study.py", "chunked_list": ["from dataclasses import dataclass\nimport astropy.units as u\n\n\n@dataclass\nclass Study:\n    \"\"\"\n    Study parameters\n    \"\"\"\n\n    slit: u.arcsec = None\n    bin_x: int = None  # bin over x or wavelength axis\n    bin_y: int = None\n    window_width: u.pix = None\n    exp_time: u.s = None\n    av_wavelength: u.m = None\n    radcal: u.ct / (u.W / u.m**2 / u.sr / u.nm) = None\n    level: str = None\n\n    def init_from_header(self, header):\n        \"\"\"\n        Initialize study parameters from FITS header\n\n        Parameters\n        ----------\n        header: astropy.io.fits.Header\n            FITS header\n        \"\"\"\n        # TODO use real slit width, not nominal slit width\n        self.slit = header[\"SLIT_WID\"] * u.arcsec\n        self.bin_x = header[\"NBIN3\"]  # bin factor in dispersion direction\n        self.bin_y = header[\"NBIN2\"]  # bin factor in slit direction\n        self.exp_time = header[\"XPOSURE\"] * u.s\n        self.window_width = header[\"NAXIS3\"] * u.pix\n        self.av_wavelength = (\n            (header[\"WAVEMIN\"] + header[\"WAVEMAX\"]) / 2 * 10 ** header[\"WAVEUNIT\"] * u.m\n        )\n        self.level = header[\"LEVEL\"]\n        if self.level == \"L2\":\n            self.radcal = header[\"RADCAL\"] * u.ct / (u.W / u.m**2 / u.sr / u.nm)\n        else:\n            self.radcal = None  # TODO or need to have a value of 1?\n\n    def __str__(self):\n        if self.slit is None:\n            return \"Non-initialized study\"\n        else:\n            return f\"\"\"\nSlit: {self.slit}\nBin: ({self.bin_x}, {self.bin_y})\nExposure time: {self.exp_time}\nWindow width: {self.window_width}\nAverage wavelength: {self.av_wavelength.to(u.nm)}\nRADCAL: {self.radcal}\n            \"\"\"", ""]}
{"filename": "sospice/instrument_modelling/__init__.py", "chunked_list": ["from .spice import Spice\nfrom .study import Study\nfrom .observation import Observation\n"]}
{"filename": "sospice/instrument_modelling/observation.py", "chunked_list": ["from dataclasses import dataclass\nimport numpy as np\nimport astropy.units as u\n\nfrom .spice import Spice\nfrom .study import Study\nfrom ..util import rss\n\n\n@dataclass\nclass Observation:\n    instrument: Spice()\n    study: Study()\n\n    @classmethod\n    def observation_from_spice_hdu(cls, hdu, verbose=True):\n        \"\"\"\n        Generate an Observation object from a SPICE L2 file HDU\n        \"\"\"\n        study = Study()\n        study.init_from_header(hdu.header)\n        if verbose:\n            print(f\"Getting observation parameters from {hdu.name}\")\n            print(study)\n        instrument = Spice()\n        observation = Observation(instrument, study)\n        return observation\n\n    @u.quantity_input\n    def av_dark_current(self, wvl: u.Angstrom = None):\n        \"\"\"\n        Average dark current in DN per macro-pixel over exposure time\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        float\n            Average dark current\n\n        TODO:\n        * Should depend on detector temperature.\n        * Actually non-Poissonian (need to look at real darks).\n        * Would depend on position (dark or hot pixels) in L1\n        \"\"\"\n        if wvl is None:\n            wvl = self.study.av_wavelength\n        return (\n            self.instrument.dark_current(wvl)\n            * self.study.exp_time  # noqa: W503\n            * self.study.bin_x  # noqa: W503\n            * self.study.bin_y  # noqa: W503\n        ).to(u.ct / u.pix)\n\n    @u.quantity_input\n    def av_background(self, wvl: u.Angstrom = None):\n        \"\"\"\n        Average background signal in DN per macro-pixel over exposure time\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        float\n            Average background\n        \"\"\"\n        if wvl is None:\n            wvl = self.study.av_wavelength\n        return (\n            self.instrument.background\n            * self.instrument.quantum_efficiency(wvl)  # noqa: W503\n            * self.study.exp_time  # noqa: W503\n            * self.study.bin_x  # noqa: W503\n            * self.study.bin_y  # noqa: W503\n            * self.instrument.gain(wvl)  # noqa: W503\n        ).to(u.ct / u.pix)\n\n    @property\n    def read_noise_width(self):\n        \"\"\"\n        Read noise distribution width in DN per macro-pixel\n        TODO make sure that this is a standard deviation and not a FWHM\n        \"\"\"\n        return self.instrument.read_noise * np.sqrt(self.study.bin_x * self.study.bin_y)\n\n    @u.quantity_input\n    def noise_effects(self, signal_mean: u.ct / u.pix, wvl: u.Angstrom = None):\n        \"\"\"\n        Return total (measured) signal increase and standard deviation due to noises\n\n        Parameters\n        ----------\n        signal_mean: Quantity\n            Measured signal mean, in DN/pix, excluding expected signal increase\n            due to average dark current and background (so this is not exactly\n            the measured signal).\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        float:\n            Average contribution of noise to measured signal\n        dict:\n            Noise standard deviations for the different components (and total\n            uncertainty resulting from them)\n\n        Negative values of the signal are considered to be 0 for the purpose of\n        computing the noise on the signal. However, the total uncertainty is\n        then set to |signal_mean| + RSS (other noises), to ensure that the\n        error bars are still compatible with expected fitted functions.\n        We suggest users to replace large negative values of the signal\n        (e.g. < -3 * RSS(other noises)) by NaNs.\n\n        \"\"\"\n        if wvl is None:\n            wvl = self.study.av_wavelength\n        av_dark_current = self.av_dark_current()\n        av_background = self.av_background()\n        av_constant_noise_level = av_dark_current + av_background\n        sigma = dict()\n        gain = self.instrument.gain(wvl)\n        sigma[\"Dark\"] = np.sqrt(av_dark_current.value) * u.ct / u.pix\n        sigma[\"Background\"] = np.sqrt(av_background * gain).value * u.ct / u.pix\n        sigma[\"Read\"] = self.read_noise_width\n        signal_mean_nonneg = np.maximum(signal_mean, 0)\n        sigma[\"Signal\"] = np.sqrt(signal_mean_nonneg * gain).value * u.ct / u.pix\n        sigma[\"Signal\"] *= self.instrument.noise_factor(wvl)\n        constant_noises = rss(\n            np.array(\n                [sigma[\"Dark\"].value, sigma[\"Background\"].value, sigma[\"Read\"].value]\n            )\n        )\n        sigma[\"Total\"] = (\n            rss(\n                np.array(\n                    [\n                        constant_noises * np.ones_like(signal_mean.value),\n                        sigma[\"Signal\"].value,\n                    ]\n                ),\n                axis=0,\n            )  # noqa: W503\n            * sigma[\"Signal\"].unit  # noqa: W503\n        )\n        where_neg = signal_mean < 0\n        sigma[\"Total\"][where_neg] = (\n            -signal_mean[where_neg] + constant_noises * signal_mean.unit\n        )\n        return av_constant_noise_level, sigma\n\n    @u.quantity_input\n    def noise_effects_from_l2(\n        self, data: u.W / u.m**2 / u.sr / u.nm, wvl: u.Angstrom\n    ):\n        \"\"\"\n        Return total (measured) signal increase and standard deviation due to noises\n\n        Parameters\n        ----------\n        data: Quantity\n            L2 data, in W / m2 / sr / nm\n        wvl: Quantity\n            Wavelength\n        Return\n        ------\n        float:\n            Average contribution of noise to measured signal\n        dict:\n            Noise standard deviations for the different components (and total)\n        \"\"\"\n        data_dn = data * self.study.radcal / u.pix\n        av_constant_noise_level, sigma = self.noise_effects(data_dn, wvl)\n        av_constant_noise_level /= self.study.radcal / u.pix\n        for component in sigma:\n            sigma[component] /= self.study.radcal / u.pix\n        return av_constant_noise_level, sigma", "\n@dataclass\nclass Observation:\n    instrument: Spice()\n    study: Study()\n\n    @classmethod\n    def observation_from_spice_hdu(cls, hdu, verbose=True):\n        \"\"\"\n        Generate an Observation object from a SPICE L2 file HDU\n        \"\"\"\n        study = Study()\n        study.init_from_header(hdu.header)\n        if verbose:\n            print(f\"Getting observation parameters from {hdu.name}\")\n            print(study)\n        instrument = Spice()\n        observation = Observation(instrument, study)\n        return observation\n\n    @u.quantity_input\n    def av_dark_current(self, wvl: u.Angstrom = None):\n        \"\"\"\n        Average dark current in DN per macro-pixel over exposure time\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        float\n            Average dark current\n\n        TODO:\n        * Should depend on detector temperature.\n        * Actually non-Poissonian (need to look at real darks).\n        * Would depend on position (dark or hot pixels) in L1\n        \"\"\"\n        if wvl is None:\n            wvl = self.study.av_wavelength\n        return (\n            self.instrument.dark_current(wvl)\n            * self.study.exp_time  # noqa: W503\n            * self.study.bin_x  # noqa: W503\n            * self.study.bin_y  # noqa: W503\n        ).to(u.ct / u.pix)\n\n    @u.quantity_input\n    def av_background(self, wvl: u.Angstrom = None):\n        \"\"\"\n        Average background signal in DN per macro-pixel over exposure time\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        float\n            Average background\n        \"\"\"\n        if wvl is None:\n            wvl = self.study.av_wavelength\n        return (\n            self.instrument.background\n            * self.instrument.quantum_efficiency(wvl)  # noqa: W503\n            * self.study.exp_time  # noqa: W503\n            * self.study.bin_x  # noqa: W503\n            * self.study.bin_y  # noqa: W503\n            * self.instrument.gain(wvl)  # noqa: W503\n        ).to(u.ct / u.pix)\n\n    @property\n    def read_noise_width(self):\n        \"\"\"\n        Read noise distribution width in DN per macro-pixel\n        TODO make sure that this is a standard deviation and not a FWHM\n        \"\"\"\n        return self.instrument.read_noise * np.sqrt(self.study.bin_x * self.study.bin_y)\n\n    @u.quantity_input\n    def noise_effects(self, signal_mean: u.ct / u.pix, wvl: u.Angstrom = None):\n        \"\"\"\n        Return total (measured) signal increase and standard deviation due to noises\n\n        Parameters\n        ----------\n        signal_mean: Quantity\n            Measured signal mean, in DN/pix, excluding expected signal increase\n            due to average dark current and background (so this is not exactly\n            the measured signal).\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        float:\n            Average contribution of noise to measured signal\n        dict:\n            Noise standard deviations for the different components (and total\n            uncertainty resulting from them)\n\n        Negative values of the signal are considered to be 0 for the purpose of\n        computing the noise on the signal. However, the total uncertainty is\n        then set to |signal_mean| + RSS (other noises), to ensure that the\n        error bars are still compatible with expected fitted functions.\n        We suggest users to replace large negative values of the signal\n        (e.g. < -3 * RSS(other noises)) by NaNs.\n\n        \"\"\"\n        if wvl is None:\n            wvl = self.study.av_wavelength\n        av_dark_current = self.av_dark_current()\n        av_background = self.av_background()\n        av_constant_noise_level = av_dark_current + av_background\n        sigma = dict()\n        gain = self.instrument.gain(wvl)\n        sigma[\"Dark\"] = np.sqrt(av_dark_current.value) * u.ct / u.pix\n        sigma[\"Background\"] = np.sqrt(av_background * gain).value * u.ct / u.pix\n        sigma[\"Read\"] = self.read_noise_width\n        signal_mean_nonneg = np.maximum(signal_mean, 0)\n        sigma[\"Signal\"] = np.sqrt(signal_mean_nonneg * gain).value * u.ct / u.pix\n        sigma[\"Signal\"] *= self.instrument.noise_factor(wvl)\n        constant_noises = rss(\n            np.array(\n                [sigma[\"Dark\"].value, sigma[\"Background\"].value, sigma[\"Read\"].value]\n            )\n        )\n        sigma[\"Total\"] = (\n            rss(\n                np.array(\n                    [\n                        constant_noises * np.ones_like(signal_mean.value),\n                        sigma[\"Signal\"].value,\n                    ]\n                ),\n                axis=0,\n            )  # noqa: W503\n            * sigma[\"Signal\"].unit  # noqa: W503\n        )\n        where_neg = signal_mean < 0\n        sigma[\"Total\"][where_neg] = (\n            -signal_mean[where_neg] + constant_noises * signal_mean.unit\n        )\n        return av_constant_noise_level, sigma\n\n    @u.quantity_input\n    def noise_effects_from_l2(\n        self, data: u.W / u.m**2 / u.sr / u.nm, wvl: u.Angstrom\n    ):\n        \"\"\"\n        Return total (measured) signal increase and standard deviation due to noises\n\n        Parameters\n        ----------\n        data: Quantity\n            L2 data, in W / m2 / sr / nm\n        wvl: Quantity\n            Wavelength\n        Return\n        ------\n        float:\n            Average contribution of noise to measured signal\n        dict:\n            Noise standard deviations for the different components (and total)\n        \"\"\"\n        data_dn = data * self.study.radcal / u.pix\n        av_constant_noise_level, sigma = self.noise_effects(data_dn, wvl)\n        av_constant_noise_level /= self.study.radcal / u.pix\n        for component in sigma:\n            sigma[component] /= self.study.radcal / u.pix\n        return av_constant_noise_level, sigma", ""]}
{"filename": "sospice/instrument_modelling/spice.py", "chunked_list": ["from dataclasses import dataclass\nfrom pathlib import Path\nimport numpy as np\nfrom scipy.io import readsav\nimport astropy.units as u\n\n\n@dataclass\nclass Spice:\n    # These values (Huang et al. 2023, doi:10.1051/0004-6361/202345988)\n    # are supposed to be the latest values presented by RAL.\n    # `astropy.units.ct` (counts) is used for DNs\n    read_noise = 6.9 * u.ct / u.pix\n    background = 0.0 * u.ph / u.s / u.pix  # 1.0 in SPICE-RAL-RP-0002\n    pix_x = 1.0 * u.arcsec / u.pix  # not used\n    pix_y = 1.0 * u.arcsec / u.pix  # not used except for PSF\n    pix_w = 0.0095 * u.nm / u.pix  # not used except for PSF\n    aeff_data = None  # Will be read from file when needed\n\n    @u.quantity_input\n    def effective_area(self, wvl: u.nm):\n        \"\"\"\n        Get the SPICE effective area for some wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        Quantity:\n            Effective area(s)\n        \"\"\"\n        wvl = wvl.to(u.nm).value\n        if self.aeff_data is None:\n            code_path = (Path(__file__) / \"..\" / \"..\").resolve()\n            aeff_file = code_path / \"data\" / \"calibration\" / \"effective_area.sav\"\n            self.aeff_data = readsav(aeff_file.as_posix())\n        # try interpolating for both second (1) and first (2) order\n        left_right = {\"left\": np.nan, \"right\": np.nan}\n        aeff1 = np.interp(\n            wvl, self.aeff_data[\"lam_1\"], self.aeff_data[\"net_resp_1\"], **left_right\n        )\n        aeff2 = np.interp(\n            wvl, self.aeff_data[\"lam_2\"], self.aeff_data[\"net_resp_2\"], **left_right\n        )\n        # choose where interpolation was done for the correct order\n        return np.where(np.isfinite(aeff2), aeff2, aeff1) * u.mm**2\n\n    @u.quantity_input\n    def quantum_efficiency(self, wvl: u.Angstrom):\n        \"\"\"\n        Get the SPICE detector quantum efficiency for some wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        Quantity:\n            Quantum efficiency(ies): number of detected photons / number of\n            incident photons\n\n        Not sure about the values for LW 2nd order, and on what wavelength\n        ranges the output should be NaN.\n        \"\"\"\n        wvl = wvl.to(u.Angstrom).value\n        # Source: Table 8.25 of SPICE-RAL-RP-0002 v10.0\n        qe_sw = np.interp(\n            wvl,\n            [703, 706, 770, 790],  # angstrom\n            [0.12, 0.12, 0.1, 0.1],  # electron/photon\n            left=np.nan,\n            right=np.nan,\n        )\n        qe_lw = 0.25  # electron/photon\n        return np.where((wvl > 703) & (wvl < 791), qe_sw, qe_lw)\n\n    @u.quantity_input\n    def which_detector(self, wvl: u.Angstrom):\n        \"\"\"\n        Determine which detector corresponds to some wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength\n\n        Return\n        ------\n        str\n            Detector name (None if not on a detector)\n        \"\"\"\n        wvl = wvl.to(u.Angstrom).value\n        if 703 < wvl < 791:\n            return \"SW\"\n        elif 970 < wvl < 1053:\n            return \"LW\"\n        else:\n            return None\n\n    @u.quantity_input\n    def gain(self, wvl: u.Angstrom):\n        \"\"\"\n        Detector gain as a function of wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength\n\n        Return\n        ------\n        float\n            Detector gain\n        \"\"\"\n        detector = self.which_detector(wvl)\n        if detector is None:\n            return np.nan * u.ct / u.ph\n        else:\n            return {\"SW\": 3.58, \"LW\": 0.57}[detector] * u.ct / u.ph\n\n    @u.quantity_input\n    def dark_current(self, wvl: u.Angstrom):\n        \"\"\"\n        Detector dark current as a function of wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength\n\n        Return\n        ------\n        float\n            Detector dark current\n        \"\"\"\n        detector = self.which_detector(wvl)\n        if detector is None:\n            return np.nan * u.ct / u.s / u.pix\n        else:\n            return {\"SW\": 0.89, \"LW\": 0.54}[detector] * u.ct / u.s / u.pix\n\n    @u.quantity_input\n    def noise_factor(self, wvl: u.Angstrom):\n        \"\"\"\n        Detector noise multiplication factor as a function of wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength\n\n        Return\n        ------\n        float\n            Noise multiplication factor\n        \"\"\"\n        detector = self.which_detector(wvl)\n        if detector is None:\n            return np.nan\n        else:\n            return {\"SW\": 1.0, \"LW\": 1.6}[detector]", "class Spice:\n    # These values (Huang et al. 2023, doi:10.1051/0004-6361/202345988)\n    # are supposed to be the latest values presented by RAL.\n    # `astropy.units.ct` (counts) is used for DNs\n    read_noise = 6.9 * u.ct / u.pix\n    background = 0.0 * u.ph / u.s / u.pix  # 1.0 in SPICE-RAL-RP-0002\n    pix_x = 1.0 * u.arcsec / u.pix  # not used\n    pix_y = 1.0 * u.arcsec / u.pix  # not used except for PSF\n    pix_w = 0.0095 * u.nm / u.pix  # not used except for PSF\n    aeff_data = None  # Will be read from file when needed\n\n    @u.quantity_input\n    def effective_area(self, wvl: u.nm):\n        \"\"\"\n        Get the SPICE effective area for some wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        Quantity:\n            Effective area(s)\n        \"\"\"\n        wvl = wvl.to(u.nm).value\n        if self.aeff_data is None:\n            code_path = (Path(__file__) / \"..\" / \"..\").resolve()\n            aeff_file = code_path / \"data\" / \"calibration\" / \"effective_area.sav\"\n            self.aeff_data = readsav(aeff_file.as_posix())\n        # try interpolating for both second (1) and first (2) order\n        left_right = {\"left\": np.nan, \"right\": np.nan}\n        aeff1 = np.interp(\n            wvl, self.aeff_data[\"lam_1\"], self.aeff_data[\"net_resp_1\"], **left_right\n        )\n        aeff2 = np.interp(\n            wvl, self.aeff_data[\"lam_2\"], self.aeff_data[\"net_resp_2\"], **left_right\n        )\n        # choose where interpolation was done for the correct order\n        return np.where(np.isfinite(aeff2), aeff2, aeff1) * u.mm**2\n\n    @u.quantity_input\n    def quantum_efficiency(self, wvl: u.Angstrom):\n        \"\"\"\n        Get the SPICE detector quantum efficiency for some wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength (or array of wavelengths)\n\n        Return\n        ------\n        Quantity:\n            Quantum efficiency(ies): number of detected photons / number of\n            incident photons\n\n        Not sure about the values for LW 2nd order, and on what wavelength\n        ranges the output should be NaN.\n        \"\"\"\n        wvl = wvl.to(u.Angstrom).value\n        # Source: Table 8.25 of SPICE-RAL-RP-0002 v10.0\n        qe_sw = np.interp(\n            wvl,\n            [703, 706, 770, 790],  # angstrom\n            [0.12, 0.12, 0.1, 0.1],  # electron/photon\n            left=np.nan,\n            right=np.nan,\n        )\n        qe_lw = 0.25  # electron/photon\n        return np.where((wvl > 703) & (wvl < 791), qe_sw, qe_lw)\n\n    @u.quantity_input\n    def which_detector(self, wvl: u.Angstrom):\n        \"\"\"\n        Determine which detector corresponds to some wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength\n\n        Return\n        ------\n        str\n            Detector name (None if not on a detector)\n        \"\"\"\n        wvl = wvl.to(u.Angstrom).value\n        if 703 < wvl < 791:\n            return \"SW\"\n        elif 970 < wvl < 1053:\n            return \"LW\"\n        else:\n            return None\n\n    @u.quantity_input\n    def gain(self, wvl: u.Angstrom):\n        \"\"\"\n        Detector gain as a function of wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength\n\n        Return\n        ------\n        float\n            Detector gain\n        \"\"\"\n        detector = self.which_detector(wvl)\n        if detector is None:\n            return np.nan * u.ct / u.ph\n        else:\n            return {\"SW\": 3.58, \"LW\": 0.57}[detector] * u.ct / u.ph\n\n    @u.quantity_input\n    def dark_current(self, wvl: u.Angstrom):\n        \"\"\"\n        Detector dark current as a function of wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength\n\n        Return\n        ------\n        float\n            Detector dark current\n        \"\"\"\n        detector = self.which_detector(wvl)\n        if detector is None:\n            return np.nan * u.ct / u.s / u.pix\n        else:\n            return {\"SW\": 0.89, \"LW\": 0.54}[detector] * u.ct / u.s / u.pix\n\n    @u.quantity_input\n    def noise_factor(self, wvl: u.Angstrom):\n        \"\"\"\n        Detector noise multiplication factor as a function of wavelength\n\n        Parameters\n        ----------\n        wvl: Quantity\n            Wavelength\n\n        Return\n        ------\n        float\n            Noise multiplication factor\n        \"\"\"\n        detector = self.which_detector(wvl)\n        if detector is None:\n            return np.nan\n        else:\n            return {\"SW\": 1.0, \"LW\": 1.6}[detector]", ""]}
{"filename": "sospice/instrument_modelling/tests/test_study.py", "chunked_list": ["import pytest\n\nimport astropy.units as u\n\nfrom ..study import Study\n\n\n@pytest.fixture\ndef empty_study():\n    return Study()", "def empty_study():\n    return Study()\n\n\n@pytest.fixture\ndef header():\n    return {\n        \"SLIT_WID\": 4.0,\n        \"NBIN3\": 1,\n        \"NBIN2\": 2,\n        \"XPOSURE\": 10.0,\n        \"NAXIS3\": 48,\n        \"WAVEMIN\": 769,\n        \"WAVEMAX\": 771,\n        \"WAVEUNIT\": -10,\n        \"LEVEL\": \"L2\",\n        \"RADCAL\": 1000.0,\n    }", "\n\n@pytest.fixture\ndef study(header):\n    s = Study()\n    s.init_from_header(header)\n    return s\n\n\nclass TestStudy:\n    def test_init(self, empty_study):\n        attributes = [\n            \"slit\",\n            \"bin_x\",\n            \"bin_y\",\n            \"window_width\",\n            \"exp_time\",\n            \"av_wavelength\",\n            \"radcal\",\n        ]\n        for attribute in attributes:\n            assert getattr(empty_study, attribute) is None\n\n    def test_init_from_header(self, study):\n        expected_values = {\n            \"slit\": 4 * u.arcsec,\n            \"bin_x\": 1,\n            \"bin_y\": 2,\n            \"window_width\": 48 * u.pix,\n            \"exp_time\": 10 * u.s,\n            \"av_wavelength\": 77 * u.nm,\n            \"radcal\": 1000 * u.ct * u.m**2 * u.nm * u.sr / u.W,\n        }\n        for attribute in expected_values:\n            assert u.isclose(getattr(study, attribute), expected_values[attribute])\n\n    def test___str__(self, empty_study, study):\n        assert str(empty_study) == \"Non-initialized study\"\n        assert type(str(study)) is str", "\nclass TestStudy:\n    def test_init(self, empty_study):\n        attributes = [\n            \"slit\",\n            \"bin_x\",\n            \"bin_y\",\n            \"window_width\",\n            \"exp_time\",\n            \"av_wavelength\",\n            \"radcal\",\n        ]\n        for attribute in attributes:\n            assert getattr(empty_study, attribute) is None\n\n    def test_init_from_header(self, study):\n        expected_values = {\n            \"slit\": 4 * u.arcsec,\n            \"bin_x\": 1,\n            \"bin_y\": 2,\n            \"window_width\": 48 * u.pix,\n            \"exp_time\": 10 * u.s,\n            \"av_wavelength\": 77 * u.nm,\n            \"radcal\": 1000 * u.ct * u.m**2 * u.nm * u.sr / u.W,\n        }\n        for attribute in expected_values:\n            assert u.isclose(getattr(study, attribute), expected_values[attribute])\n\n    def test___str__(self, empty_study, study):\n        assert str(empty_study) == \"Non-initialized study\"\n        assert type(str(study)) is str", ""]}
{"filename": "sospice/instrument_modelling/tests/test_observation.py", "chunked_list": ["import pytest\n\nfrom astropy.io import fits\nimport astropy.units as u\n\nfrom ..spice import Spice\nfrom ..study import Study\nfrom ..observation import Observation\n\n", "\n\n@pytest.fixture\ndef header():\n    return {\n        \"SLIT_WID\": 4.0,\n        \"NBIN3\": 1,\n        \"NBIN2\": 2,\n        \"XPOSURE\": 10.0,\n        \"NAXIS3\": 48,\n        \"WAVEMIN\": 769,\n        \"WAVEMAX\": 771,\n        \"WAVEUNIT\": -10,\n        \"LEVEL\": \"L2\",\n        \"RADCAL\": 1000.0,\n    }", "\n\n@pytest.fixture\ndef hdu():\n    url = \"https://spice.osups.universite-paris-saclay.fr/spice-data/release-3.0/level2/2022/04/02/solo_L2_spice-n-ras_20220402T111537_V06_100664002-000.fits\"\n    # with fits.open(url) as hdu_list:\n    hdu_list = fits.open(url)\n    hdu = hdu_list[2]  # Ne VIII window\n    yield hdu\n    hdu_list.close()", "\n\n@pytest.fixture\ndef observation(header):\n    instrument = Spice()\n    study = Study()\n    study.init_from_header(header)\n    return Observation(instrument, study)\n\n\nclass TestObservation:\n    def test_observation_from_spice_hdu(self, hdu):\n        observation = Observation.observation_from_spice_hdu(hdu)\n        assert type(observation.instrument) is Spice\n        assert type(observation.study) is Study\n\n    def test_av_dark_current(self, observation):\n        # Expected values in DN/ph for wavelengths in nm\n        expected = {\n            77: 17.8,\n            102.5: 10.8,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                observation.av_dark_current(wavelength * u.nm),\n                expected[wavelength] * u.ct / u.pix,\n            )\n\n    def test_av_background(self, observation):\n        # Expected values in DN/ph for wavelengths in nm\n        expected = {\n            77: 0,\n            102.5: 0,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                observation.av_background(wavelength * u.nm),\n                expected[wavelength] * u.ct / u.pix,\n            )\n\n    def test_read_noise_width(self, observation):\n        assert u.isclose(observation.read_noise_width, 9.75807358 * u.ct / u.pix)\n\n    def test_noise_effects_from_l2(self, observation):\n        specrad_unit = u.mW / u.m**2 / u.sr / u.nm\n        av_constant_noise_level, sigma = observation.noise_effects_from_l2(\n            0.1 * specrad_unit, 77 * u.nm\n        )\n        assert u.isclose(av_constant_noise_level, 17.8 * specrad_unit)\n        expected = {\n            \"Dark\": 4.219004621945797,\n            \"Background\": 0.0,\n            \"Read\": 9.758073580374356,\n            \"Signal\": 18.920887928424502,\n            \"Total\": 21.702995184996933,\n        }\n        for component in expected:\n            assert u.isclose(sigma[component], expected[component] * specrad_unit)", "\n\nclass TestObservation:\n    def test_observation_from_spice_hdu(self, hdu):\n        observation = Observation.observation_from_spice_hdu(hdu)\n        assert type(observation.instrument) is Spice\n        assert type(observation.study) is Study\n\n    def test_av_dark_current(self, observation):\n        # Expected values in DN/ph for wavelengths in nm\n        expected = {\n            77: 17.8,\n            102.5: 10.8,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                observation.av_dark_current(wavelength * u.nm),\n                expected[wavelength] * u.ct / u.pix,\n            )\n\n    def test_av_background(self, observation):\n        # Expected values in DN/ph for wavelengths in nm\n        expected = {\n            77: 0,\n            102.5: 0,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                observation.av_background(wavelength * u.nm),\n                expected[wavelength] * u.ct / u.pix,\n            )\n\n    def test_read_noise_width(self, observation):\n        assert u.isclose(observation.read_noise_width, 9.75807358 * u.ct / u.pix)\n\n    def test_noise_effects_from_l2(self, observation):\n        specrad_unit = u.mW / u.m**2 / u.sr / u.nm\n        av_constant_noise_level, sigma = observation.noise_effects_from_l2(\n            0.1 * specrad_unit, 77 * u.nm\n        )\n        assert u.isclose(av_constant_noise_level, 17.8 * specrad_unit)\n        expected = {\n            \"Dark\": 4.219004621945797,\n            \"Background\": 0.0,\n            \"Read\": 9.758073580374356,\n            \"Signal\": 18.920887928424502,\n            \"Total\": 21.702995184996933,\n        }\n        for component in expected:\n            assert u.isclose(sigma[component], expected[component] * specrad_unit)", ""]}
{"filename": "sospice/instrument_modelling/tests/__init__.py", "chunked_list": [""]}
{"filename": "sospice/instrument_modelling/tests/test_spice.py", "chunked_list": ["import pytest\n\nimport numpy as np\nimport astropy.units as u\n\nfrom ..spice import Spice\n\n\n@pytest.fixture\ndef spice():\n    return Spice()", "@pytest.fixture\ndef spice():\n    return Spice()\n\n\nclass TestSpice:\n    def test_init(self, spice):\n        assert spice.read_noise == 6.9 * u.ct / u.pix\n        assert spice.aeff_data is None\n\n    def test_effective_area(self, spice):\n        # Expected values in mm\u00b2 for wavelengths in nm\n        expected = {\n            20: np.nan,\n            77: 4.33579493,  # Ne VIII (SW)\n            102.6: 9.57706423,  # H Ly\u03b2 (LW)\n            52.1: 0.43514445,  # Si XII (LW, 2nd order)\n            200: np.nan,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                spice.effective_area(wavelength * u.nm),\n                expected[wavelength] * u.mm**2,\n                equal_nan=True,\n            )\n        assert u.allclose(\n            spice.effective_area([50, 80, 100] * u.nm),\n            [0.28686351, 5.50425673, 9.21953583] * u.mm**2,\n        )\n        assert spice.aeff_data is not None\n\n    def test_quantum_efficiency(self, spice):\n        # Expected values for wavelengths in nm\n        # Not sure about the value for 2nd order LW\n        expected = {\n            77: 0.1,\n            102.6: 0.25,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                spice.quantum_efficiency(wavelength * u.nm), expected[wavelength]\n            )\n\n    def test_which_detector(self, spice):\n        # Expected values for wavelengths in nm\n        expected = {\n            77: \"SW\",\n            102.6: \"LW\",\n        }\n        for wavelength in expected:\n            assert spice.which_detector(wavelength * u.nm) == expected[wavelength]\n        # Expected None values\n        expected_none = [70, 85, 106]\n        for wavelength in expected_none:\n            assert spice.which_detector(wavelength * u.nm) is None\n\n    def test_gain(self, spice):\n        # Expected values in DN/ph for wavelengths in nm\n        expected = {\n            20: np.nan,\n            77: 3.58,\n            102.6: 0.57,\n            200: np.nan,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                spice.gain(wavelength * u.nm),\n                expected[wavelength] * u.ct / u.ph,\n                equal_nan=True,\n            )\n\n    def test_dark_current(self, spice):\n        # Expected values in DN/s/pix for wavelengths in nm\n        expected = {\n            20: np.nan,\n            77: 0.89,\n            102.6: 0.54,\n            200: np.nan,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                spice.dark_current(wavelength * u.nm),\n                expected[wavelength] * u.ct / u.s / u.pix,\n                equal_nan=True,\n            )\n\n    def test_noise_factor(self, spice):\n        # Expected values in DN/s/pix for wavelengths in nm\n        expected = {\n            20: np.nan,\n            77: 1.0,\n            102.6: 1.6,\n            200: np.nan,\n        }\n        for wavelength in expected:\n            assert u.isclose(\n                spice.noise_factor(wavelength * u.nm),\n                expected[wavelength],\n                equal_nan=True,\n            )", ""]}
{"filename": "sospice/psf/__init__.py", "chunked_list": [""]}
{"filename": "sospice/psf/tests/__init__.py", "chunked_list": [""]}
{"filename": "sospice/calibrate/__init__.py", "chunked_list": ["from .uncertainties import spice_error\n"]}
{"filename": "sospice/calibrate/uncertainties.py", "chunked_list": ["import astropy.units as u\n\nfrom ..instrument_modelling import Spice, Study, Observation\n\n\ndef spice_error(hdu=None, data=None, header=None, verbose=True):\n    \"\"\"\n    Return total (measured) signal increase and standard deviation due to noises\n\n    Parameters\n    ----------\n    hdu: astropy.io.fits.hdu.image.ImageHDU\n        SPICE L2 FITS HDU\n    data: numpy.ndarray\n        SPICE L2 FITS data, assumed to be in W / m2 / sr / nm\n    header: astropy.io.fits.header.Header\n        SPICE L2 FITS header\n    verbose: bool\n        If True, displays details\n\n    Return\n    ------\n    float:\n        Average contribution of noise to measured signal\n    dict:\n        Noise standard deviations for the different components (and total)\n\n    Either hdu, or data and header should be provided.\n    \"\"\"\n    if data is None or header is None:\n        if hdu is None:\n            raise RuntimeError(\"Either hdu, or data and header should be provided\")\n        header = hdu.header\n        data = hdu.data\n    if header[\"LEVEL\"] != \"L2\":\n        raise RuntimeError(\"Level should be L2\")\n    data *= u.Unit(header[\"BUNIT\"])\n    print(data.unit)\n    study = Study()\n    study.init_from_header(header)\n    if verbose:\n        print(f\"Getting observation parameters from {header['EXTNAME']}\")\n        print(study)\n    instrument = Spice()\n    observation = Observation(instrument, study)\n    av_constant_noise_level, sigma = observation.noise_effects_from_l2(\n        data, study.av_wavelength\n    )\n    return av_constant_noise_level, sigma", ""]}
{"filename": "sospice/calibrate/tests/test_uncertainties.py", "chunked_list": ["import pytest\n\nfrom astropy.io import fits\nimport astropy.units as u\n\nfrom ..uncertainties import spice_error\n\n\nspecrad_unit = u.mW / u.m**2 / u.sr / u.nm\n", "specrad_unit = u.mW / u.m**2 / u.sr / u.nm\n\n\n@pytest.fixture\ndef hdus():\n    # all expected values in specrad_unit\n    hdus = [\n        {\n            \"url\": \"https://spice.osups.universite-paris-saclay.fr/spice-data/release-3.0/level2/2022/04/02/solo_L2_spice-n-ras_20220402T111537_V06_100664002-000.fits\",\n            \"hdu_index\": 2,  # Ne VIII window\n            \"expected_constant\": 42.9513921,\n            \"pixel_index\": (0, 25, 415, 80),\n            \"expected\": {\n                \"Dark\": 20.36091256,\n                \"Background\": 0.0,\n                \"Read\": 66.59878776,\n                \"Signal\": 168.60160232,\n                \"Total\": 182.41837621,\n            },\n        },\n        {  # File used for comparison with MPS' IDL code\n            \"url\": \"https://spice.osups.universite-paris-saclay.fr/spice-data/release-3.0/level2/2021/02/23/solo_L2_spice-n-ras_20210223T154400_V10_50331754-000.fits\",\n            \"hdu_index\": 2,  # Ly\u03b3 - C III\n            \"expected_constant\": 87.80646,\n            \"pixel_index\": (0, 25, 415, 80),\n            \"expected\": {\n                \"Dark\": 26.718655,\n                \"Background\": 0.0,\n                \"Read\": 56.098571,\n                \"Signal\": 61.990004,\n                \"Total\": 87.7707,\n            },\n        },\n    ]\n    for item in hdus:\n        item[\"hdu_list\"] = fits.open(item[\"url\"])\n    yield hdus\n    for item in hdus:\n        item[\"hdu_list\"].close()", "\n\nclass TestUncertainties:\n    def test_spice_error(self, hdus):\n        for item in hdus:\n            av_constant_noise_level, sigma = spice_error(\n                item[\"hdu_list\"][item[\"hdu_index\"]]\n            )\n        assert u.isclose(\n            av_constant_noise_level, item[\"expected_constant\"] * specrad_unit\n        )\n        for component in item[\"expected\"]:\n            pixel_index = (\n                () if len(sigma[component].shape) == 0 else item[\"pixel_index\"]\n            )\n            print(f\"{sigma[component][pixel_index]=}\")\n            assert u.isclose(\n                sigma[component][pixel_index],\n                item[\"expected\"][component] * specrad_unit,\n            )", ""]}
{"filename": "sospice/calibrate/tests/__init__.py", "chunked_list": [""]}
{"filename": "docs/source/conf.py", "chunked_list": ["# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the", "# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n# import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\nfrom datetime import datetime\n\n# from sospice import __version__", "\n# from sospice import __version__\nfrom setuptools_scm import get_version\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \"sospice\"\ncopyright = f\"{datetime.now().year}, SPICE consortium\"\nauthor = \"SPICE consortium\"", "copyright = f\"{datetime.now().year}, SPICE consortium\"\nauthor = \"SPICE consortium\"\n\n# The full version, including alpha/beta/rc tags\nrelease = get_version(root=\"../..\", relative_to=__file__)\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be", "\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"matplotlib.sphinxext.plot_directive\",\n    \"numpydoc\",\n    # \"sphinx_automodapi.automodapi\",\n    # \"sphinx_automodapi.smart_resolver\",\n    # \"sphinx_changelog\",", "    # \"sphinx_automodapi.smart_resolver\",\n    # \"sphinx_changelog\",\n    # \"sphinx_gallery.gen_gallery\",\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.autosummary\",\n    \"sphinx.ext.coverage\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.inheritance_diagram\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.mathjax\",", "    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.mathjax\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.viewcode\",\n    # \"sphinxext.opengraph\",\n    # \"sphinx_design\",\n    # \"sphinx_copybutton\",\n    # \"hoverxref.extension\",\n]", "    # \"hoverxref.extension\",\n]\n\nautosummary_generate = True  # Turn on sphinx.ext.autosummary\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.", "# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\"build\", \"htmlcov\", \"sospice.egg-info\", \"venv\", \"tests\"]\n\n# -- Options for intersphinx extension ---------------------------------------\nintersphinx_mapping = {\n    \"python\": (\n        \"https://docs.python.org/3/\",\n        (None, \"http://data.astropy.org/intersphinx/python3.inv\"),", "        \"https://docs.python.org/3/\",\n        (None, \"http://data.astropy.org/intersphinx/python3.inv\"),\n    ),\n    \"numpy\": (\n        \"https://docs.scipy.org/doc/numpy/\",\n        (None, \"http://data.astropy.org/intersphinx/numpy.inv\"),\n    ),\n    \"matplotlib\": (\n        \"https://matplotlib.org/\",\n        (None, \"http://data.astropy.org/intersphinx/matplotlib.inv\"),", "        \"https://matplotlib.org/\",\n        (None, \"http://data.astropy.org/intersphinx/matplotlib.inv\"),\n    ),\n    \"astropy\": (\"http://docs.astropy.org/en/stable/\", None),\n    \"sunpy\": (\"https://docs.sunpy.org/en/stable/\", None),\n    \"sunraster\": (\"https://docs.sunpy.org/projects/sunraster/en/stable/\", None),\n}\n\n# -- Options for HTML output -------------------------------------------------\n", "# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"sphinx_rtd_theme\"\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".", "# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n"]}
