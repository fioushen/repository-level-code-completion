{"filename": "libslub.py", "chunked_list": ["import os\nimport sys\n\n# We reload all modules everywhere so when we develop libslub in gdb\n# our changes are reflected as soon as we reimport this main script\nimport importlib\n\n# Add the root path\nmodule_path = os.path.dirname(os.path.abspath(os.path.realpath(__file__)))\nif module_path not in sys.path:\n    #print(\"DEBUG: adding module path...\")\n    sys.path.insert(0, module_path)", "module_path = os.path.dirname(os.path.abspath(os.path.realpath(__file__)))\nif module_path not in sys.path:\n    #print(\"DEBUG: adding module path...\")\n    sys.path.insert(0, module_path)\n#print(sys.path) # DEBUG\n\n# We need that after the above so it finds it\nimport libslub\nimportlib.reload(libslub)\n", "importlib.reload(libslub)\n"]}
{"filename": "libslub/pyslub.py", "chunked_list": ["import os\nimport sys\nimport importlib\nimport gdb\n\ntry:\n    import configparser  # py3\nexcept:\n    import ConfigParser as configparser  # py2\n", "\nimport libslub.frontend.frontend_gdb as fg\nimportlib.reload(fg)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.pydbg.debugger as d\nimportlib.reload(d)\nimport libslub.pydbg.pygdbpython as pgp\nimportlib.reload(pgp)\n\nclass pyslab:\n    \"\"\"Entry point of libslub\"\"\"\n\n    def __init__(self):\n\n        # Setup GDB debugger interface\n        debugger = pgp.pygdbpython()\n        self.dbg = d.pydbg(debugger)\n\n        config = configparser.SafeConfigParser()\n        path = os.path.abspath(os.path.dirname(__file__))\n        config_path = os.path.join(path, \"libslub.cfg\")\n        config.read(config_path)\n\n        try:\n            breakpoints_enabled = config.getboolean(\"Slab\", \"breakpoints_enabled\")\n        except configparser.NoOptionError:\n            breakpoints_enabled = False\n\n        self.sb = sb.sb(debugger=self.dbg, breakpoints_enabled=breakpoints_enabled)\n\n        # Register GDB commands\n        fg.frontend_gdb(self.sb)", "importlib.reload(pgp)\n\nclass pyslab:\n    \"\"\"Entry point of libslub\"\"\"\n\n    def __init__(self):\n\n        # Setup GDB debugger interface\n        debugger = pgp.pygdbpython()\n        self.dbg = d.pydbg(debugger)\n\n        config = configparser.SafeConfigParser()\n        path = os.path.abspath(os.path.dirname(__file__))\n        config_path = os.path.join(path, \"libslub.cfg\")\n        config.read(config_path)\n\n        try:\n            breakpoints_enabled = config.getboolean(\"Slab\", \"breakpoints_enabled\")\n        except configparser.NoOptionError:\n            breakpoints_enabled = False\n\n        self.sb = sb.sb(debugger=self.dbg, breakpoints_enabled=breakpoints_enabled)\n\n        # Register GDB commands\n        fg.frontend_gdb(self.sb)", ""]}
{"filename": "libslub/logger.py", "chunked_list": ["import logging\n\n# https://stackoverflow.com/questions/2183233/how-to-add-a-custom-loglevel-to-pythons-logging-facility\ndef trace(self, message, *args, **kws):\n    if self.isEnabledFor(logging.TRACE):\n        # Yes, logger takes its '*args' as 'args'.\n        self._log(logging.TRACE, message, args, **kws) \n\nclass MyFormatter(logging.Formatter):\n    \"\"\"Defines how we format logs in stdout and files\n    \"\"\"\n\n    # We use the TRACE level to check loaded files in gdb after reloading the script\n    # so is mainly useful during development\n    logging.TRACE = 5\n    logging.addLevelName(logging.TRACE, 'TRACE')\n    logging.Logger.trace = trace\n\n    FORMATS = {\n        logging.ERROR: \"(%(asctime)s) [!] %(msg)s\",\n        logging.WARNING: \"(%(asctime)s) WARNING: %(msg)s\",\n        logging.INFO: \"(%(asctime)s) [*] %(msg)s\",\n        logging.DEBUG: \"(%(asctime)s) DBG: %(msg)s\",\n        logging.TRACE: \"(%(asctime)s) TRACE: %(msg)s\",\n        \"DEFAULT\": \"%(asctime)s - %(msg)s\"\n    }\n\n    def format(self, record):\n        \"\"\"Hooked Formatter.format() method to modify its behaviour\n        \"\"\"\n\n        format_orig = self._style._fmt\n\n        self._style._fmt = self.FORMATS.get(record.levelno, self.FORMATS['DEFAULT'])\n        result = logging.Formatter.format(self, record)\n\n        self._style._fmt = format_orig\n\n        return result", "class MyFormatter(logging.Formatter):\n    \"\"\"Defines how we format logs in stdout and files\n    \"\"\"\n\n    # We use the TRACE level to check loaded files in gdb after reloading the script\n    # so is mainly useful during development\n    logging.TRACE = 5\n    logging.addLevelName(logging.TRACE, 'TRACE')\n    logging.Logger.trace = trace\n\n    FORMATS = {\n        logging.ERROR: \"(%(asctime)s) [!] %(msg)s\",\n        logging.WARNING: \"(%(asctime)s) WARNING: %(msg)s\",\n        logging.INFO: \"(%(asctime)s) [*] %(msg)s\",\n        logging.DEBUG: \"(%(asctime)s) DBG: %(msg)s\",\n        logging.TRACE: \"(%(asctime)s) TRACE: %(msg)s\",\n        \"DEFAULT\": \"%(asctime)s - %(msg)s\"\n    }\n\n    def format(self, record):\n        \"\"\"Hooked Formatter.format() method to modify its behaviour\n        \"\"\"\n\n        format_orig = self._style._fmt\n\n        self._style._fmt = self.FORMATS.get(record.levelno, self.FORMATS['DEFAULT'])\n        result = logging.Formatter.format(self, record)\n\n        self._style._fmt = format_orig\n\n        return result"]}
{"filename": "libslub/__init__.py", "chunked_list": ["import sys\nimport importlib\nimport logging\n\nimport libslub.logger as logger\nimportlib.reload(logger)\n\nimport libslub.pyslub as pyslub\nimportlib.reload(pyslub)\n\ntry:\n    log\nexcept:\n    log = logging.getLogger(\"libslub\")\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(logger.MyFormatter(datefmt=\"%H:%M:%S\"))\n    log.addHandler(handler)", "importlib.reload(pyslub)\n\ntry:\n    log\nexcept:\n    log = logging.getLogger(\"libslub\")\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(logger.MyFormatter(datefmt=\"%H:%M:%S\"))\n    log.addHandler(handler)\n", "\n# This allows changing the log level and reloading in gdb even if the logger was already defined\n# XXX - however this file is not reloaded early when we reload in gdb, so we need to re-source in gdb 2x\n# for the logger level to be changed atm\n#log.setLevel(logging.TRACE) # use for debugging reloading .py files only\n#log.setLevel(logging.DEBUG) # all other types of debugging\nlog.setLevel(logging.NOTSET)\n\nif log.isEnabledFor(logging.TRACE):\n    log.warning(f\"logging TRACE enabled\")\nelif log.isEnabledFor(logging.DEBUG):\n    log.warning(f\"logging DEBUG enabled\")", "if log.isEnabledFor(logging.TRACE):\n    log.warning(f\"logging TRACE enabled\")\nelif log.isEnabledFor(logging.DEBUG):\n    log.warning(f\"logging DEBUG enabled\")\n# elif log.isEnabledFor(logging.INFO):\n#     log.warning(f\"logging INFO enabled\")\n# elif log.isEnabledFor(logging.WARNING):\n#     log.warning(f\"logging WARNING enabled\")\n\nlog.trace(\"libslub/__init__.py\")", "\nlog.trace(\"libslub/__init__.py\")\n\npyslub.pyslab()\n"]}
{"filename": "libslub/pydbg/__init__.py", "chunked_list": [""]}
{"filename": "libslub/pydbg/pygdbpython.py", "chunked_list": ["import sys\nimport logging\nimport re\nimport importlib\nimport hexdump\nfrom pathlib import Path\nfrom functools import wraps\nimport gdb\n\nimport libslub.frontend.printutils as pu", "\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"pygdbpython.py\")\n\n# XXX - could have that into a helper.py instead?\ndef gdb_is_running(f):\n    \"\"\"Decorator to make sure gdb is running\n    \"\"\"\n\n    @wraps(f)\n    def _gdb_is_running(*args, **kwargs):\n        if gdb.selected_thread() is not None:\n            return f(*args, **kwargs)\n        else:\n            pu.print_error(\"GDB is not running.\")\n\n    return _gdb_is_running", "def gdb_is_running(f):\n    \"\"\"Decorator to make sure gdb is running\n    \"\"\"\n\n    @wraps(f)\n    def _gdb_is_running(*args, **kwargs):\n        if gdb.selected_thread() is not None:\n            return f(*args, **kwargs)\n        else:\n            pu.print_error(\"GDB is not running.\")\n\n    return _gdb_is_running", "\nclass pygdbpython:\n    \"\"\"Debugger bridge calling into gdb-specific APIs\n    \n    See debugger.py interface\n    \"\"\"\n\n    def __init__(self):\n        log.debug(\"pygdbpython.__init__()\")\n\n        self.inferior = None\n        self.SIZE_SZ = 0\n\n    #\n    # Methods from the debugger abstraction\n    #\n\n    @gdb_is_running\n    def execute(self, cmd, to_string=True):\n        \"\"\"See debugger.py interface\n        \"\"\"\n\n        log.debug(\"pygdbpython.execute()\")\n        return gdb.execute(cmd, to_string=to_string)\n\n    @gdb_is_running\n    def get_size_sz(self):\n        \"\"\"See debugger.py interface\n        \"\"\"\n        return 8 # hardcoded for now\n\n    @gdb_is_running\n    def read_memory(self, address, length):\n        \"\"\"See debugger.py interface\n        \"\"\"\n        \n        if log.level <= logging.DEBUG:\n            if type(address) == int:\n                printed_address = \"0x%x\" % address\n            else:\n                printed_address = str(address)\n            if type(length) == int:\n                printed_length = \"0x%x\" % length\n            else:\n                printed_length = str(length)\n            log.debug(f\"pygdbpython.read_memory({printed_address}, {printed_length})\")\n        if self.inferior is None:\n            self.inferior = self.get_inferior()\n\n        return self.inferior.read_memory(address, length)\n\n    @gdb_is_running\n    def parse_variable(self, variable=None):\n        \"\"\"See debugger.py interface\n        \"\"\"\n        log.debug(\"pygdbpython.parse_variable()\")\n\n        if variable is None:\n            pu.print_error(\"Please specify a variable to read\")\n            return None\n\n        evaluated = int(gdb.parse_and_eval(variable))\n        log.info(\"pygdbpython.parse_variable(): evaluated variable = 0x%x\" % evaluated)\n        if self.get_size_sz() == 4:\n            p = self.tohex(evaluated, 32)\n        elif self.get_size_sz() == 8:\n            p = self.tohex(evaluated, 64)\n        return int(p, 16)\n\n    @gdb_is_running\n    def print_hexdump(self, address, size, unit=8):\n        \"\"\"See debugger.py interface\n        \"\"\"\n\n        # See https://visualgdb.com/gdbreference/commands/x\n        if unit == 1:\n            #cmd = \"x/%dbx 0x%x\\n\" % (size, address)\n            try:\n                mem = self.read_memory(address, size)\n            except TypeError:\n                pu.print_error(\"Invalid address specified\")\n                return\n            except RuntimeError:\n                pu.print_error(\"Could not read address {0:#x}\".format(addr))\n                return\n            i = 0\n            for line in hexdump.hexdump(bytes(mem), result='generator'):\n                elts = line.split(\":\")\n                txt = \":\".join(elts[1:])\n                print(\"0x%x: %s\" % (address+i*0x10, txt))\n                i += 1\n            return\n        elif unit == 2:\n            cmd = \"x/%dhx 0x%x\\n\" % (size/2, address)\n        elif unit == 4:\n            cmd = \"x/%dwx 0x%x\\n\" % (size/4, address)\n        elif unit == 8:\n            cmd = \"x/%dgx 0x%x\\n\" % (size/8, address)\n        elif unit == \"dps\":\n            # XXX - call into dps_like_for_gdb.py command for now\n            # but we want to just add it to libslub maybe\n            cmd = \"dps 0x%x %d\\n\" % (address, size/self.get_size_sz())\n        else:\n            print(\"[!] Invalid unit specified\")\n            return\n        print(self.execute(cmd, to_string=True))\n        return\n\n    def parse_address(self, addresses):\n        \"\"\"See debugger.py interface\n\n        It should be able to handle gdb variables starting with $ or if we ommit it too\n        \"\"\"\n\n        log.debug(\"pygdbpython.parse_address()\")\n        resolved = []\n        if type(addresses) != list:\n            addresses = [addresses]\n        for item in addresses:\n            addr = None\n            try:\n                # This should parse most cases like integers,\n                # variables (exact name), registers (if we specify $ in front), as well\n                # as arithmetic with integers, variables and registers.\n                # i.e. as long as \"p ABC\" or \"x /x ABC\" works, it should work within here too\n                addr = self.parse_variable(item)\n                log.info(\"parsed address (default) = 0x%x\" % addr)\n            except:\n                # XXX - Not sure what this is for?\n                try:\n                    addr = self.parse_variable(\"&\" + item)\n                    log.info(\"parsed address (unknown) = 0x%x\" % addr)\n                except:\n                    # Parse registers if we don't specify the register, e.g. \"rdi\" instead of \"$rdi\"\n                    try:\n                        addr = self.parse_variable(\"$\" + item)\n                        log.info(\"parsed address (register) = 0x%x\" % addr)\n                    except:\n                        pu.print_error(f\"ERROR: Unable to parse {item}\")\n                        continue\n            if addr is not None:\n                resolved.append(addr)\n        return resolved\n\n    #\n    # gdb-specific methods\n    #\n\n    def get_inferior(self):\n        \"\"\"Get the gdb inferior, used for other gdb commands\n        \"\"\"\n\n        log.debug(\"pygdbpython.get_inferior()\")\n        try:\n            if self.inferior is None:\n                if len(gdb.inferiors()) == 0:\n                    pu.print_error(\"No gdb inferior could be found.\")\n                    return -1\n                else:\n                    self.inferior = gdb.inferiors()[0]\n                    return self.inferior\n            else:\n                return self.inferior\n        except AttributeError:\n            pu.print_error(\"This gdb's python support is too old.\")\n            raise Exception(\"sys.exit()\")\n\n    # XXX - move to generic helper shared by all debuggers?\n    def tohex(self, val, nbits):\n        \"\"\"Handle gdb adding extra char to hexadecimal values\n        \"\"\"\n\n        log.debug(\"pygdbpython.tohex()\")\n        result = hex((val + (1 << nbits)) % (1 << nbits))\n        # -1 because hex() only sometimes tacks on a L to hex values...\n        if result[-1] == \"L\":\n            return result[:-1]\n        else:\n            return result"]}
{"filename": "libslub/pydbg/debugger.py", "chunked_list": ["import importlib\n\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\n\nclass pydbg:\n    \"\"\"Python abstraction interface that allows calling into any specific debugger APIs\n\n    Any debugger implementation should implement the methods called on self.debugger\n    \"\"\"\n    \n    def __init__(self, debugger):\n        \"\"\"Initialize the debugger to be used for any future API\n        \"\"\"\n        self.debugger = debugger\n\n    def execute(self, cmd, to_string=True):\n        \"\"\"Execute a command in the debugger CLI\n        \"\"\"\n        return self.debugger.execute(cmd, to_string=to_string)\n\n\n    def get_size_sz(self):\n        \"\"\"Retrieve the size_t size for the current architecture\n        \"\"\"\n        return self.debugger.get_size_sz()\n\n    def read_memory(self, address, length):\n        \"\"\"Read bytes at the given address of the given length\n        \"\"\"\n        return self.debugger.read_memory(address, length)\n\n    def parse_variable(self, variable):\n        \"\"\"Parse and evaluate a debugger variable expression\n        \"\"\"\n        return self.debugger.parse_variable(variable)\n\n    def parse_address(self, addresses):\n        \"\"\"Parse one or more addresses or debugger variables\n\n        :param address: an address string containing hex, int, or debugger variable\n        :return: the resolved addresses as integers\n\n        It this should be able to handle: hex, decimal, program variables\n        with or without special characters (like $, &, etc.),\n        basic addition and subtraction of variables, etc.\n        \"\"\"\n        return self.debugger.parse_address(addresses)\n\n    def print_hexdump_chunk(self, sb, o, maxlen=0, off=0, debug=False, unit=8, verbose=1):\n        \"\"\"Hexdump chunk data to stdout\n        \n        :param sb: slab object\n        :param o: obj() object representing the chunk\n        :param maxlen: maximum amount of bytes to hexdump\n        :param off: offset into the chunk's data to hexdump (after the malloc_chunk header)\n        :param debug: debug enabled or not\n        :param unit: hexdump unit (e.g. 1, 2, 4, 8, \"dps\")\n        :param verbose: see ptchunk's ArgumentParser definition\n        \"\"\"\n\n        address = o.address + off\n        size = o.size - off\n        if size <= 0:\n            print(\"[!] Chunk corrupt? Bad size\")\n            return\n        print(\"0x%x bytes of object data:\" % size)\n        shown_size = size\n        if maxlen != 0:\n            if shown_size > maxlen:\n                shown_size = maxlen\n\n        self.print_hexdump(address, shown_size, unit=unit)\n\n    def print_hexdump(self, address, size, unit=8):\n        \"\"\"Hexdump data to stdout\n\n        :param address: starting address\n        :param size: number of bytes from the address\n        :param unit: hexdump unit (e.g. 1, 2, 4, 8, \"dps\")\n        \"\"\"\n\n        self.debugger.print_hexdump(address, size, unit=unit)", ""]}
{"filename": "libslub/frontend/frontend_gdb.py", "chunked_list": ["import logging\nimport importlib\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(f\"frontend_gdb.py\")\n\nimport libslub.frontend.commands.gdb.sbhelp as sbhelp\nimportlib.reload(sbhelp)\nimport libslub.frontend.commands.gdb.sbbreak as sbbreak\nimportlib.reload(sbbreak)", "import libslub.frontend.commands.gdb.sbbreak as sbbreak\nimportlib.reload(sbbreak)\nimport libslub.frontend.commands.gdb.sblist as sblist\nimportlib.reload(sblist)\nimport libslub.frontend.commands.gdb.sbtrace as sbtrace\nimportlib.reload(sbtrace)\nimport libslub.frontend.commands.gdb.sbwatch as sbwatch\nimportlib.reload(sbwatch)\nimport libslub.frontend.commands.gdb.sbcrosscache as sbcrosscache\nimportlib.reload(sbcrosscache)", "import libslub.frontend.commands.gdb.sbcrosscache as sbcrosscache\nimportlib.reload(sbcrosscache)\nimport libslub.frontend.commands.gdb.sbmeta as sbmeta\nimportlib.reload(sbmeta)\nimport libslub.frontend.commands.gdb.sbcache as sbcache\nimportlib.reload(sbcache)\nimport libslub.frontend.commands.gdb.sbslabdb as sbslabdb\nimportlib.reload(sbslabdb)\nimport libslub.frontend.commands.gdb.sbobject as sbobject\nimportlib.reload(sbobject)", "import libslub.frontend.commands.gdb.sbobject as sbobject\nimportlib.reload(sbobject)\n\nclass frontend_gdb:\n    \"\"\"Register commands with GDB\"\"\"\n\n    def __init__(self, sb):\n\n        # We share slab among all commands below\n\n        # The below dictates in what order they will be shown in gdb\n        cmds = []\n        cmds.append(sbcache.sbcache(sb))\n        cmds.append(sbobject.sbobject(sb))\n        cmds.append(sblist.sblist(sb))\n        cmds.append(sbmeta.sbmeta(sb))\n        cmds.append(sbslabdb.sbslabdb(sb))\n        cmds.append(sbcrosscache.sbcrosscache(sb))\n\n        if sb.breakpoints_enabled:\n            cmds.append(sbbreak.sbbreak(sb))\n            cmds.append(sbtrace.sbtrace(sb))\n            cmds.append(sbwatch.sbwatch(sb))\n\n        sbhelp.sbhelp(sb, cmds)", ""]}
{"filename": "libslub/frontend/__init__.py", "chunked_list": ["import logging\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"libslub/frontend/__init__.py\")"]}
{"filename": "libslub/frontend/helpers2.py", "chunked_list": ["import argparse\nimport struct\nimport sys\nimport traceback\nimport gdb\nimport shlex\nimport logging\nfrom functools import wraps, lru_cache\n\nlog = logging.getLogger(\"libslub\")", "\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sb.py\")\n\n# START GEF STUFF\n\n# GEF stuff. This is stuff I took from gef for now, that we could probably\n# replace with something from lib ptmalloc or whatever\n\ndef is_alive():\n    \"\"\"Check if GDB is running.\"\"\"\n    try:\n        return gdb.selected_inferior().pid > 0\n    except Exception:\n        return False\n    return False", "\ndef is_alive():\n    \"\"\"Check if GDB is running.\"\"\"\n    try:\n        return gdb.selected_inferior().pid > 0\n    except Exception:\n        return False\n    return False\n\n\ndef cached_lookup_type(_type):\n    try:\n        return gdb.lookup_type(_type).strip_typedefs()\n    except RuntimeError:\n        return None", "\n\ndef cached_lookup_type(_type):\n    try:\n        return gdb.lookup_type(_type).strip_typedefs()\n    except RuntimeError:\n        return None\n\n\ndef _ptr_width():\n    void = cached_lookup_type(\"void\")\n    if void is None:\n        uintptr_t = cached_lookup_type(\"uintptr_t\")\n        return uintptr_t.sizeof\n    else:\n        return void.pointer().sizeof", "\ndef _ptr_width():\n    void = cached_lookup_type(\"void\")\n    if void is None:\n        uintptr_t = cached_lookup_type(\"uintptr_t\")\n        return uintptr_t.sizeof\n    else:\n        return void.pointer().sizeof\n\n", "\n\n@lru_cache()\ndef is_64bit():\n    \"\"\"Checks if current target is 64bit.\"\"\"\n    return _ptr_width() == 8\n\n\n@lru_cache()\ndef is_32bit():\n    \"\"\"Checks if current target is 32bit.\"\"\"\n    return _ptr_width() == 4", "@lru_cache()\ndef is_32bit():\n    \"\"\"Checks if current target is 32bit.\"\"\"\n    return _ptr_width() == 4\n\n\ndef get_memory_alignment(in_bits=False):\n    \"\"\"Try to determine the size of a pointer on this system.\n    First, try to parse it out of the ELF header.\n    Next, use the size of `size_t`.\n    Finally, try the size of $pc.\n    If `in_bits` is set to True, the result is returned in bits, otherwise in\n    bytes.\"\"\"\n    if is_32bit():\n        return 4 if not in_bits else 32\n    elif is_64bit():\n        return 8 if not in_bits else 64\n\n    res = cached_lookup_type(\"size_t\")\n    if res is not None:\n        return res.sizeof if not in_bits else res.sizeof * 8\n\n    try:\n        return gdb.parse_and_eval(\"$pc\").type.sizeof\n    except:\n        pass\n    raise EnvironmentError(\"GEF is running under an unsupported mode\")", "\n\ndef style_byte(b, color=True):\n    sbyte = \"{:02x}\".format(b)\n    return sbyte\n\n\ndef hexdump(\n    source,\n    length=0x10,\n    separator=\".\",\n    show_raw=False,\n    show_symbol=False,\n    base=0x00,\n    pad=0,\n):\n    \"\"\"Return the hexdump of `src` argument.\n    @param source *MUST* be of type bytes or bytearray\n    @param length is the length of items per line\n    @param separator is the default character to use if one byte is not printable\n    @param show_raw if True, do not add the line nor the text translation\n    @param base is the start address of the block being hexdump\n    @return a string with the hexdump\"\"\"\n    result = []\n    align = get_memory_alignment() * 2 + 2 if is_alive() else 18\n\n    for i in range(0, len(source), length):\n        chunk = bytearray(source[i : i + length])\n        hexa = \" \".join([style_byte(b, color=not show_raw) for b in chunk])\n\n        if show_raw:\n            result.append(hexa)\n            continue\n\n        text = \"\".join([chr(b) if 0x20 <= b < 0x7F else separator for b in chunk])\n        if show_symbol:\n            sym = gdb_get_location_from_symbol(base + i)\n            sym = \"<{:s}+{:04x}>\".format(*sym) if sym else \"\"\n        else:\n            sym = \"\"\n\n        result.append(\n            \"{padding}{addr:#0{aw}x} {sym} {data:<{dw}} {text}\".format(\n                padding=\" \" * pad,\n                aw=align,\n                addr=base + i,\n                sym=sym,\n                dw=3 * length,\n                data=hexa,\n                text=text,\n            )\n        )\n    return \"\\n\".join(result)", "\n\n# END GEF STUFF\n\ndef get_breakpoint_list():\n    \"\"\"return a itemized list of breakpoints\"\"\"\n    break_list = gdb.execute(\"info breakpoints\", to_string=True)\n    breakpoints = []\n    for line in break_list.split(\"\\n\"):\n        if not len(line) or line.startswith(\"Num\"):\n            continue\n\n        if line.startswith(\"No breakpoints\"):\n            break\n\n        items = list(filter(None, line.split(\" \")))\n        # Skip \"breakpoint already hit N times\"\n        if \"breakpoint\" in items[0]:\n            continue\n        num = items[0]\n        try:\n            int(num)\n            # could be useful if later a multiple breakpoint is encountered\n            prev_num = num\n        except:\n            try:\n                float(num)\n                # multiple breakpoint detected\n            except:\n                continue\n        if len(items) != 7 and len(items) != 9:\n            continue\n        if len(items) == 7:\n            # multiple breakpoint needs to use previously saved bp num\n            num = prev_num\n            address = items[2]\n            function = items[4]\n            source = items[6]\n        elif len(items) == 9:\n            address = items[4]\n            function = items[6]\n            source = items[8]\n        breakpoints.append(\n            {\"id\": num, \"address\": address, \"function\": function, \"location\": source}\n        )\n\n    return breakpoints", "\n\ndef find_existing_breakpoints(location, single=False):\n    source_bp = False\n    address_bp = False\n    if \":\" in location:\n        source_bp = True\n    elif location.startswith(\"0x\"):\n        address_bp = True\n\n    breakpoints = get_breakpoint_list()\n    if not len(breakpoints):\n        return None\n    bps = []\n    for bp in breakpoints:\n        if source_bp:\n            if bp[\"location\"].endswith(location):\n                bps.append(bp)\n        elif address_bp:\n            if bp[\"address\"] == location:\n                bps.append(bp)\n        else:\n            if bp[\"function\"] == location:\n                bps.append(bp)\n    if len(bps):\n        if single:\n            return bps[0]\n        return bps\n    return None", "\n\ndef delete_breakpoint(bp):\n    log.debug(f'deleting breakpoint {bp[\"id\"]}')\n    gdb.execute(f'd br {bp[\"id\"]}')\n\n\ndef delete_breakpoints(bps):\n    for bp in bps:\n        delete_breakpoint(bp)", "\n\ndef clear_existing_breakpoints(name):\n    \"\"\"TODO: Docstring for clear_existing_breakpoints.\n    :returns: TODO\n\n    \"\"\"\n\n    bps = find_existing_breakpoints(name)\n    if bps:\n        delete_breakpoints(bps)"]}
{"filename": "libslub/frontend/printutils.py", "chunked_list": ["# taken from https://github.com/cloudburst/libheap/blob/master/libheap/frontend/printutils.py\n\nfrom __future__ import print_function\n\nimport re\n\ncolors_enabled = True\n\n# bash color support, taken from pwndbg\nNORMAL = \"\\x1b[0m\"", "# bash color support, taken from pwndbg\nNORMAL = \"\\x1b[0m\"\nBLACK = \"\\x1b[30m\"\nRED = \"\\x1b[31m\"\nGREEN = \"\\x1b[32m\"\nYELLOW = \"\\x1b[33m\"\nBLUE = \"\\x1b[34m\"\nPURPLE = \"\\x1b[35m\"\nCYAN = \"\\x1b[36m\"\nLIGHT_GREY = LIGHT_GRAY = \"\\x1b[37m\"", "CYAN = \"\\x1b[36m\"\nLIGHT_GREY = LIGHT_GRAY = \"\\x1b[37m\"\nFOREGROUND = \"\\x1b[39m\"\nGREY = GRAY = \"\\x1b[90m\"\nLIGHT_RED = \"\\x1b[91m\"\nLIGHT_GREEN = \"\\x1b[92m\"\nLIGHT_YELLOW = \"\\x1b[93m\"\nLIGHT_BLUE = \"\\x1b[94m\"\nLIGHT_PURPLE = \"\\x1b[95m\"\nLIGHT_CYAN = \"\\x1b[96m\"", "LIGHT_PURPLE = \"\\x1b[95m\"\nLIGHT_CYAN = \"\\x1b[96m\"\nWHITE = \"\\x1b[97m\"\nBOLD = \"\\x1b[1m\"\nUNDERLINE = \"\\x1b[4m\"\n\n\ndef none(x):\n    return str(x)\n", "\n\ndef normal(x):\n    return colorize(x, NORMAL)\n\n\ndef black(x):\n    return colorize(x, BLACK)\n\n\ndef red(x):\n    return colorize(x, RED)", "\n\ndef red(x):\n    return colorize(x, RED)\n\n\ndef green(x):\n    return colorize(x, GREEN)\n\n\ndef yellow(x):\n    return colorize(x, YELLOW)", "\n\ndef yellow(x):\n    return colorize(x, YELLOW)\n\n\ndef blue(x):\n    return colorize(x, BLUE)\n\n\ndef purple(x):\n    return colorize(x, PURPLE)", "\n\ndef purple(x):\n    return colorize(x, PURPLE)\n\n\ndef cyan(x):\n    return colorize(x, CYAN)\n\n\ndef foreground(x):\n    return colorize(x, FOREGROUND)", "\n\ndef foreground(x):\n    return colorize(x, FOREGROUND)\n\n\ndef gray(x):\n    return colorize(x, GRAY)\n\n\ndef light_red(x):\n    return colorize(x, LIGHT_RED)", "\n\ndef light_red(x):\n    return colorize(x, LIGHT_RED)\n\n\ndef light_green(x):\n    return colorize(x, LIGHT_GREEN)\n\n\ndef light_yellow(x):\n    return colorize(x, LIGHT_YELLOW)", "\n\ndef light_yellow(x):\n    return colorize(x, LIGHT_YELLOW)\n\n\ndef light_blue(x):\n    return colorize(x, LIGHT_BLUE)\n\n\ndef light_purple(x):\n    return colorize(x, LIGHT_PURPLE)", "\n\ndef light_purple(x):\n    return colorize(x, LIGHT_PURPLE)\n\n\ndef light_cyan(x):\n    return colorize(x, LIGHT_CYAN)\n\n\ndef light_gray(x):\n    return colorize(x, LIGHT_GRAY)", "\n\ndef light_gray(x):\n    return colorize(x, LIGHT_GRAY)\n\n\ndef white(x):\n    return colorize(x, WHITE)\n\n\ndef bold(x):\n    return colorize(x, BOLD)", "\n\ndef bold(x):\n    return colorize(x, BOLD)\n\n\ndef underline(x):\n    return colorize(x, UNDERLINE)\n\n\ndef colorize(x, color):\n    if colors_enabled:\n        return color + terminateWith(str(x), color) + NORMAL\n    else:\n        return x", "\n\ndef colorize(x, color):\n    if colors_enabled:\n        return color + terminateWith(str(x), color) + NORMAL\n    else:\n        return x\n\n\ndef terminateWith(x, color):\n    return re.sub('\\x1b\\\\[0m', NORMAL + color, x)", "\ndef terminateWith(x, color):\n    return re.sub('\\x1b\\\\[0m', NORMAL + color, x)\n\n\ndef print_debug(s, end='\\n'):\n    debug = \"[#] {0}\".format(s)\n    color = LIGHT_PURPLE\n    debug = colorize(debug, color)\n    print(debug, end=end)", "\ndef print_error(s, end=\"\\n\"):\n    error = \"[!] {0}\".format(s)\n    color = RED\n    error = colorize(error, color)\n    print(error, end=end)\n\n\ndef print_title(s, end=\"\\n\"):\n    print(color_title(s), end=end)", "def print_title(s, end=\"\\n\"):\n    print(color_title(s), end=end)\n\n\ndef print_title_wide(s, end=\"\\n\"):\n    width = 80\n    lwidth = (width-len(s))/2\n    rwidth = (width-len(s))/2\n    title = '{:=<{lwidth}}{}{:=<{rwidth}}'.format(\n            '', s, '', lwidth=lwidth, rwidth=rwidth)\n    print(color_title(title), end=end)", "\n\ndef print_header(s, end=\"\"):\n    color = YELLOW\n    s = colorize(s, color)\n    print(s, end=end)\n\n\ndef print_footer(s, end=\"\"):\n    color = PURPLE\n    s = colorize(s, color)\n    print(s, end=end)", "def print_footer(s, end=\"\"):\n    color = PURPLE\n    s = colorize(s, color)\n    print(s, end=end)\n\n\ndef print_value(s, end=\"\"):\n    print(color_value(s), end=end)\n\n\ndef color_header(s):\n    color = YELLOW\n    return colorize(s, color)", "\n\ndef color_header(s):\n    color = YELLOW\n    return colorize(s, color)\n\ndef color_title(s):\n    color = GREEN + UNDERLINE\n    return colorize(s, color)\n", "\n\ndef color_value(s):\n    color = BLUE\n    return colorize(s, color)\n\n\ndef color_footer(s):\n    color = PURPLE\n    return colorize(s, color)", ""]}
{"filename": "libslub/frontend/helpers.py", "chunked_list": ["import sys\nimport traceback\nimport argparse\nimport struct\nfrom functools import wraps\n\ndef show_last_exception():\n    \"\"\"Taken from gef. Let us see proper backtraces from python exceptions\"\"\"\n\n    PYTHON_MAJOR = sys.version_info[0]\n    horizontal_line = \"-\"\n    right_arrow = \"->\"\n    down_arrow = \"\\\\->\"\n\n    print(\"\")\n    exc_type, exc_value, exc_traceback = sys.exc_info()\n    print(\" Exception raised \".center(80, horizontal_line))\n    print(\"{}: {}\".format(exc_type.__name__, exc_value))\n    print(\" Detailed stacktrace \".center(80, horizontal_line))\n    for fs in traceback.extract_tb(exc_traceback)[::-1]:\n        if PYTHON_MAJOR == 2:\n            filename, lineno, method, code = fs\n        else:\n            try:\n                filename, lineno, method, code = (\n                    fs.filename,\n                    fs.lineno,\n                    fs.name,\n                    fs.line,\n                )\n            except:\n                filename, lineno, method, code = fs\n\n        print(\n            \"\"\"{} File \"{}\", line {:d}, in {}()\"\"\".format(\n                down_arrow, filename, lineno, method\n            )\n        )\n        print(\"   {}    {}\".format(right_arrow, code))", "\ndef is_ascii(s):\n    return all(c < 128 and c > 1 for c in s)\n\ndef hms_string(sec_elapsed):\n    h = int(sec_elapsed / (60 * 60))\n    m = int((sec_elapsed % (60 * 60)) / 60)\n    s = int(sec_elapsed % 60)\n    if h == 0:\n        if m == 0:\n            return \"{:>02}s\".format(s)\n        else:\n            return \"{:>02}m{:>02}s\".format(m, s)\n    else:\n        return \"{}h{:>02}m{:>02}s\".format(h, m, s)", "\n# https://stackoverflow.com/questions/2556108/rreplace-how-to-replace-the-last-occurrence-of-an-expression-in-a-string\ndef rreplace(s, old, new, occurrence):\n    li = s.rsplit(old, occurrence)\n    return new.join(li)\n\ndef prepare_list(L):\n    return rreplace(', '.join([str(x) for x in L]), ',', ' or', 1)\n\ndef string_to_int(num):\n    \"\"\"Convert an integer or hex integer string to an int\n    :returns: converted integer\n\n    especially helpful for using ArgumentParser()\n    \"\"\"\n    if num.find(\"0x\") != -1:\n        return int(num, 16)\n    else:\n        return int(num)", "\ndef string_to_int(num):\n    \"\"\"Convert an integer or hex integer string to an int\n    :returns: converted integer\n\n    especially helpful for using ArgumentParser()\n    \"\"\"\n    if num.find(\"0x\") != -1:\n        return int(num, 16)\n    else:\n        return int(num)", "\ndef catch_exceptions(f):\n    \"Decorator to catch exceptions\"\n\n    @wraps(f)\n    def _catch_exceptions(*args, **kwargs):\n        try:\n            f(*args, **kwargs)\n        except Exception:\n            show_last_exception()\n    return _catch_exceptions ", "\ndef check_positive(value):\n    try:\n        ivalue = int(value)\n    except:\n        raise argparse.ArgumentTypeError(\"%s is an invalid positive int value\" % value)\n    if ivalue <= 0:\n        raise argparse.ArgumentTypeError(\"%s is an invalid positive int value\" % value)\n    return ivalue\n\ndef check_count_value(value):\n    if value == \"unlimited\":\n        return None # unlimited\n    try:\n        ivalue = int(value)\n    except:\n        raise argparse.ArgumentTypeError(\"%s is an invalid int value\" % value)\n    if ivalue == 0:\n        return None # unlimited\n\n    return ivalue", "\ndef check_count_value(value):\n    if value == \"unlimited\":\n        return None # unlimited\n    try:\n        ivalue = int(value)\n    except:\n        raise argparse.ArgumentTypeError(\"%s is an invalid int value\" % value)\n    if ivalue == 0:\n        return None # unlimited\n\n    return ivalue", "\ndef check_count_value_positive(value):\n    if value == \"unlimited\":\n        return None # unlimited\n    try:\n        ivalue = int(value)\n    except:\n        raise argparse.ArgumentTypeError(\"%s is an invalid int value\" % value)\n    if ivalue < 0:\n        raise argparse.ArgumentTypeError(\"%s needs to be positive int value\" % value)\n    if ivalue == 0:\n        return None # unlimited\n\n    return ivalue", "\n\nhexdump_units = [1, 2, 4, 8, \"dps\"]\ndef check_hexdump_unit(value):\n    \"\"\"Especially helpful for using ArgumentParser()\n    \"\"\"\n    if value == \"dps\":\n        return value\n    \n    try:\n        ivalue = int(value)\n    except:\n        raise argparse.ArgumentTypeError(\"%s is not a valid hexdump unit\" % value)\n    if ivalue not in hexdump_units:\n        raise argparse.ArgumentTypeError(\"%s is not a valid hexdump unit\" % value)\n    return ivalue", "\n\ndef swap64(i):\n    return struct.unpack(\"<Q\", struct.pack(\">Q\", i))[0]"]}
{"filename": "libslub/frontend/commands/__init__.py", "chunked_list": [""]}
{"filename": "libslub/frontend/commands/gdb/sbmeta.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport binascii\nimport struct\nimport sys\nimport logging\nimport pprint\nimport re\nimport pickle", "import re\nimport pickle\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd", "importlib.reload(h)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbmeta.py\")\n\nmeta_cache = {}\nbacktrace_ignore = set([])\n", "backtrace_ignore = set([])\n\ncolorize_table = {\n    \"red\": pu.red,\n    \"green\": pu.green,\n    \"yellow\": pu.yellow,\n    \"blue\": pu.blue,\n    \"purple\": pu.purple,\n    \"cyan\": pu.cyan,\n    \"gray\": pu.gray,", "    \"cyan\": pu.cyan,\n    \"gray\": pu.gray,\n    \"lightred\": pu.light_red,\n    \"lightgreen\": pu.light_green,\n    \"lightyellow\": pu.light_yellow,\n    \"lightblue\": pu.light_blue,\n    \"lightpurple\": pu.light_purple,\n    \"lightcyan\": pu.light_cyan,\n    \"lightgray\": pu.light_gray,\n    \"white\": pu.white,", "    \"lightgray\": pu.light_gray,\n    \"white\": pu.white,\n    \"black\": pu.black,\n}\n\nMETADATA_DB = \"metadata.pickle\"\ndef save_metadata_to_file(filename):\n    \"\"\"During development, we reload libslub and lose the metadata database\n    so this allows saving it easily into a file before doing so\n    \"\"\"\n    d = {}\n    d[\"meta_cache\"] = meta_cache\n    d[\"backtrace_ignore\"] = backtrace_ignore\n    pickle.dump(d, open(filename, \"wb\"))", "\ndef load_metadata_from_file(filename):\n    \"\"\"During development, we reload libslub and lose the metadata database\n    so this allows reloading it easily from a file\n    \"\"\"\n    global meta_cache, backtrace_ignore\n    d = pickle.load(open(filename, \"rb\"))\n    meta_cache = d[\"meta_cache\"]\n    backtrace_ignore = d[\"backtrace_ignore\"]\n\ndef get_metadata(address, list_metadata=[]):\n    \"\"\"\n    :param address: the address to retrieve metatada from\n    :param list_metadata: If a list, the list of metadata to retrieve (even empty list).\n                          If the \"all\" string, means to retrieve all metadata\n    :return: the following L, suffix, epilog, colorize_func\n    \"\"\"\n\n    L = [] # used for json output\n    suffix = \"\" # used for one-line output\n    epilog = \"\" # used for verbose output\n    colorize_func = str # do not colorize by default\n\n    if address not in meta_cache:\n        epilog += \"chunk address not found in metadata database\\n\"\n        return None, suffix, epilog, colorize_func\n\n    # This allows calling get_metadata() by not specifying any metadata\n    # but meaning we want to retrieve them all\n    if list_metadata == \"all\":\n        list_metadata = list(meta_cache[address].keys())\n        if \"backtrace\" in list_metadata:\n            # enforce retrieving all the functions from the backtrace\n            list_metadata.remove(\"backtrace\")\n            list_metadata.append(\"backtrace:-1\")\n\n    opened = False\n    for key in list_metadata:\n        param = None\n        if \":\" in key:\n            key, param = key.split(\":\")\n        if key not in meta_cache[address]:\n            if key != \"color\":\n                suffix += \" | N/A\"\n                epilog += \"'%s' key not found in metadata database\\n\" % key\n                opened = True\n                L.append(None)\n            continue\n        if key == \"backtrace\":\n            if param == None:\n                funcs_list = get_first_function(address)\n            else:\n                funcs_list = get_functions(address, max_len=int(param))\n            if funcs_list == None:\n                suffix += \" | N/A\"\n            elif len(funcs_list) == 0:\n                # XXX - atm if we failed to parse the functions from the debugger\n                # we will also show \"filtered\" even if it is not the case\n                suffix += \" | filtered\"\n            else:\n                suffix += \" | %s\" % \",\".join(funcs_list)\n            epilog += \"%s\" % meta_cache[address][\"backtrace\"][\"raw\"]\n            L.append(funcs_list)\n            opened = True\n        elif key == \"color\":\n            color = meta_cache[address][key]\n            colorize_func = colorize_table[color]\n        else:\n            suffix += \" | %s\" % meta_cache[address][key]\n            epilog += \"%s\\n\" % meta_cache[address][key]\n            L.append(meta_cache[address][key])\n            opened = True\n    if opened:\n        suffix += \" |\"\n\n    return L, suffix, epilog, colorize_func", "\ndef get_metadata(address, list_metadata=[]):\n    \"\"\"\n    :param address: the address to retrieve metatada from\n    :param list_metadata: If a list, the list of metadata to retrieve (even empty list).\n                          If the \"all\" string, means to retrieve all metadata\n    :return: the following L, suffix, epilog, colorize_func\n    \"\"\"\n\n    L = [] # used for json output\n    suffix = \"\" # used for one-line output\n    epilog = \"\" # used for verbose output\n    colorize_func = str # do not colorize by default\n\n    if address not in meta_cache:\n        epilog += \"chunk address not found in metadata database\\n\"\n        return None, suffix, epilog, colorize_func\n\n    # This allows calling get_metadata() by not specifying any metadata\n    # but meaning we want to retrieve them all\n    if list_metadata == \"all\":\n        list_metadata = list(meta_cache[address].keys())\n        if \"backtrace\" in list_metadata:\n            # enforce retrieving all the functions from the backtrace\n            list_metadata.remove(\"backtrace\")\n            list_metadata.append(\"backtrace:-1\")\n\n    opened = False\n    for key in list_metadata:\n        param = None\n        if \":\" in key:\n            key, param = key.split(\":\")\n        if key not in meta_cache[address]:\n            if key != \"color\":\n                suffix += \" | N/A\"\n                epilog += \"'%s' key not found in metadata database\\n\" % key\n                opened = True\n                L.append(None)\n            continue\n        if key == \"backtrace\":\n            if param == None:\n                funcs_list = get_first_function(address)\n            else:\n                funcs_list = get_functions(address, max_len=int(param))\n            if funcs_list == None:\n                suffix += \" | N/A\"\n            elif len(funcs_list) == 0:\n                # XXX - atm if we failed to parse the functions from the debugger\n                # we will also show \"filtered\" even if it is not the case\n                suffix += \" | filtered\"\n            else:\n                suffix += \" | %s\" % \",\".join(funcs_list)\n            epilog += \"%s\" % meta_cache[address][\"backtrace\"][\"raw\"]\n            L.append(funcs_list)\n            opened = True\n        elif key == \"color\":\n            color = meta_cache[address][key]\n            colorize_func = colorize_table[color]\n        else:\n            suffix += \" | %s\" % meta_cache[address][key]\n            epilog += \"%s\\n\" % meta_cache[address][key]\n            L.append(meta_cache[address][key])\n            opened = True\n    if opened:\n        suffix += \" |\"\n\n    return L, suffix, epilog, colorize_func", "\ndef get_first_function(address):\n    return get_functions(address, max_len=1)\n\ndef get_functions(address, max_len=None):\n    L = []\n    if address not in meta_cache:\n        return None\n    if \"backtrace\" not in meta_cache[address]:\n        return None\n    funcs = meta_cache[address][\"backtrace\"][\"funcs\"]\n    for f in funcs:\n        if f in backtrace_ignore:\n            continue\n        L.append(f)\n        if max_len != None and len(L) == max_len:\n            break\n    return L", "\nclass sbmeta(sbcmd.sbcmd):\n    \"\"\"Command to manage metadata for a given address\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbmeta.__init__()\")\n        super(sbmeta, self).__init__(sb, \"sbmeta\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Handle metadata associated with object/chunk addresses\"\"\", \n            formatter_class=argparse.RawTextHelpFormatter,\n            add_help=False,\n            epilog=\"\"\"NOTE: use 'sbmeta <action> -h' to get more usage info\"\"\")\n        self.parser.add_argument(\n            \"-v\", \"--verbose\", dest=\"verbose\", action=\"count\", default=0,\n            help=\"Use verbose output (multiple for more verbosity)\"\n        )\n        self.parser.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n\n        actions = self.parser.add_subparsers(\n            help=\"Action to perform\", \n            dest=\"action\"\n        )\n\n        add_parser = actions.add_parser(\n            \"add\",\n            help=\"\"\"Save metadata for a given chunk address\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"The saved metadata can then be shown in any other commands like \n'sbcache', etc.\n\nE.g.\n  sbmeta add mem-0x10 tag \"service_user struct\"\n  sbmeta add 0xdead0030 color green\n  sbmeta add 0xdead0030 backtrace\"\"\"\n        )\n        add_parser.add_argument(\n            'address', \n            help='Address to link the metadata to'\n        )\n        add_parser.add_argument(\n            'key', \n            help='Key name of the metadata (e.g. \"backtrace\", \"color\", \"tag\" or any name)'\n        )\n        add_parser.add_argument(\n            'value', nargs=\"?\",\n            help='Value of the metadata, associated with the key (required except when adding a \"backtrace\")'\n        )\n        add_parser.add_argument(\n            '--append', dest=\"append\", action=\"store_true\",\n            help='Append value if the key/value already exist instead of overwriting previous value'\n        )\n        \n        del_parser = actions.add_parser(\n            \"del\", \n            help=\"\"\"Delete metadata associated with a given chunk address\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"E.g.\n  sbmeta del mem-0x10\n  sbmeta del 0xdead0030\"\"\"\n        )\n        del_parser.add_argument('address', help='Address to remove the metadata for')\n        \n        list_parser = actions.add_parser(\n            \"list\", \n            help=\"\"\"List metadata for a chunk address or all chunk addresses (debugging)\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"E.g.\n  sbmeta list mem-0x10\n  sbmeta list 0xdead0030 -M backtrace\n  sbmeta list\n  sbmeta list -vvvv\n  sbmeta list -M \"tag, backtrace:3\"\"\"\n        )\n        list_parser.add_argument(\n            'address', nargs=\"?\", \n            help='Address to remove the metadata for'\n        )\n        list_parser.add_argument(\n            \"-M\", \"--metadata\", dest=\"metadata\", type=str, default=None,\n            help=\"Comma separated list of metadata to print\"\n        )\n\n        config_parser = actions.add_parser(\n            \"config\", \n            help=\"Configure general metadata behaviour\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"E.g.\n  sbmeta config ignore backtrace _nl_make_l10nflist __GI___libc_free\"\"\"\n        )\n        config_parser.add_argument(\n            'feature',  \n            help='Feature to configure (e.g. \"ignore\")'\n        )\n        config_parser.add_argument(\n            'key', \n            help='Key name of the metadata (e.g. \"backtrace\")'\n        )\n        config_parser.add_argument(\n            'values', nargs=\"+\",\n            help='Values of the metadata, associated with the key (e.g. list of function to ignore in a backtrace)'\n        )\n\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n        # allows to save metadata to file during development/debugging\n        self.parser.add_argument(\n            \"-S\", \"--save-db\", dest=\"save\", action=\"store_true\", default=False,\n            help=argparse.SUPPRESS\n        )\n        # allows to load metadata from file during development/debugging\n        self.parser.add_argument(\n            \"-L\", \"--load-db\", dest=\"load\", action=\"store_true\", default=False,\n            help=argparse.SUPPRESS\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbmeta.invoke()\")\n\n        if self.args.action is None and not self.args.save and not self.args.load:\n            pu.print_error(\"WARNING: requires an action\")\n            self.parser.print_help()\n            return\n\n        if self.args.action == \"list\" \\\n        or self.args.action == \"add\" \\\n        or self.args.action == \"del\":\n            address = None\n            if self.args.address != None:\n                addresses = self.dbg.parse_address(self.args.address)\n                if len(addresses) == 0:\n                    pu.print_error(\"WARNING: No valid address supplied\")\n                    self.parser.print_help()\n                    return\n                address = addresses[0]\n \n        if self.args.action == \"list\":\n            self.list_metadata(address)\n            return\n\n        if self.args.action == \"del\":\n            self.delete_metadata(address)\n            return\n\n        if self.args.action == \"config\":\n            self.configure_metadata(self.args.feature, self.args.key, self.args.values)\n            return\n\n        if self.args.action == \"add\":\n            self.add_metadata(address, self.args.key, self.args.value, self.args.append)\n            return\n\n        if self.args.save:\n            if self.args.verbose >= 0: # always print since debugging feature\n                print(\"Saving metadata database to file...\")\n            save_metadata_to_file(METADATA_DB)\n            return\n\n        if self.args.load:\n            if self.args.verbose >= 0: # always print since debugging feature\n                print(\"Loading metadata database from file...\")\n            load_metadata_from_file(METADATA_DB)\n            return\n\n    def list_metadata(self, address):\n        \"\"\"Show the metadata database for all addresses or a given address\n\n        if verbose == 0, shows single-line entries (no \"backtrace\" if not requested)\n        if verbose == 1, shows single-line entries (all keys)\n        if verbose == 2, shows multi-line entries (no \"backtrace\" if not requested)\n        if verbose == 3, shows multi-line entries (all keys)\n        \"\"\"\n\n        if len(meta_cache) != 0:\n            pu.print_header(\"Metadata database\", end=None)\n\n            if self.args.metadata == None:\n                # if no metadata provided by user, we get them all\n                list_metadata = []\n                for k, d in meta_cache.items():\n                    for k2, d2 in d.items():\n                        if k2 not in list_metadata:\n                            list_metadata.append(k2)\n                if self.args.verbose == 0 and \"backtrace\" in list_metadata:\n                    list_metadata.remove(\"backtrace\")\n            else:\n                list_metadata = [e.strip() for e in self.args.metadata.split(\",\")]\n\n            if self.args.verbose <= 1:\n                print(\"| address | \", end=\"\")\n                print(\" | \".join(list_metadata), end=\"\")\n                print(\" |\")\n                for k, d in meta_cache.items():\n                    if address == None or k == address:\n                        L, s, e, colorize_func = get_metadata(k, list_metadata=list_metadata)\n                        addr = colorize_func(f\"0x{k:x}\")\n                        print(f\"| {addr}\", end=\"\")\n                        print(s)\n            else:\n                for k, d in meta_cache.items():\n                    if address == None or k == address:\n                        L, s, e, colorize_func = get_metadata(k, list_metadata=list_metadata)\n                        addr = colorize_func(f\"0x{k:x}\")\n                        print(f\"{addr}:\")\n                        print(e)\n        else:\n            pu.print_header(\"Metadata database\", end=None)\n            print(\"N/A\")\n        \n        print(\"\")\n        \n        if len(backtrace_ignore) != 0:\n            pu.print_header(\"Function ignore list for backtraces\", end=None)\n            pprint.pprint(backtrace_ignore)\n        else:\n            pu.print_header(\"Function ignore list for backtraces\", end=None)\n            print(\"N/A\")\n\n    def configure_metadata(self, feature, key, values):\n        \"\"\"Save given metadata (key, values) for a given feature (e.g. \"backtrace\")\n\n        :param feature: name of the feature (e.g. \"ignore\")\n        :param key: name of the metadata (e.g. \"backtrace\")\n        :param values: list of values to associate to the key\n        \"\"\"\n\n        if self.args.verbose >= 1:\n            print(\"Configuring metadata database...\")\n        if key == \"backtrace\":\n            if feature == \"ignore\":\n                backtrace_ignore.update(values)\n            else:\n                pu.print_error(\"WARNING: Unsupported feature\")\n                return\n        else:\n            pu.print_error(\"WARNING: Unsupported key\")\n            return\n\n    def delete_metadata(self, address):\n        \"\"\"Delete metadata for a given chunk's address\n        \"\"\"\n\n        if address not in meta_cache:\n            return\n\n        if self.args.verbose >= 1:\n            print(f\"Deleting metadata for {address} from database...\")\n        del meta_cache[address]\n\n    def add_metadata(self, address, key, value, append=False):\n        \"\"\"Save given metadata (key, value) for a given chunk's address\n        E.g. key = \"tag\" and value is an associated user-defined tag\n        \"\"\"\n\n        if self.args.verbose >= 1:\n            print(\"Adding to metadata database...\")\n        if key == \"backtrace\":\n            result = self.dbg.get_backtrace()\n        elif key == \"color\":\n            if value not in colorize_table:\n                pu.print_error(f\"ERROR: Unsupported color. Need one of: {', '.join(colorize_table.keys())}\")\n                return\n            result = value\n        else:\n            result = value\n\n        if address not in meta_cache:\n            meta_cache[address] = {}\n        if key != \"backtrace\" and key != \"color\":\n            if append is True and key in meta_cache[address].keys():\n                result = meta_cache[address][key] + \" ; \" + result\n        meta_cache[address][key] = result", "\n"]}
{"filename": "libslub/frontend/commands/gdb/sbobject.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport binascii\nimport struct\nimport sys\nimport logging\nimport os\nimport importlib\nimport gdb", "import importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.kmem_cache as kc\nimportlib.reload(kc)\nimport libslub.slub.obj as obj\nimportlib.reload(obj)\nimport libslub.slub.sb as sb", "importlib.reload(obj)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.commands.gdb.sbmeta as sbmeta\nimportlib.reload(sbmeta)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n", "#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbobject.py\")\n\nclass sbobject(sbcmd.sbcmd):\n    \"\"\"Command to print information about objects aka chunk(s) inside a memory region\n    associated with a slab.\n    \n    There are a couple of quirks to know. Other commands can share lots of\n    arguments and features with the \"sbobject\" command. It would have make\n    sense to inherit the other command classes from the \"sbobject\" class, however we \n    would have the same problem as with the \"sbcmd\" where we can't reload the \n    \"sbobject.py\" file without restarting gdb. This would have been annoying so \n    we work around that by having some methods of the \"sbobject\" class defined as \n    static methods and we just call into these from the other command classes\n    This is less \"clean\" but eases a lot development.\n    \"\"\"\n\n    search_types = [\"string\", \"byte\", \"word\", \"dword\", \"qword\"]\n\n    def __init__(self, sb):\n        log.debug(\"sbobject.__init__()\")\n        super(sbobject, self).__init__(sb, \"sbobject\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Print the metadata and contents of one or more objects/chunks \n\nCan provide you with a summary of a chunk (one-line) or more verbose information \nin multiple lines (e.g. hexdump of the object contents). \nYou can also list information of multiple chunks, search chunks, etc.\n\"\"\", \n            add_help=False, \n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"E.g.\nsbobject mem-0x10 -v -x -M \"tag, backtrace\"\nsbobject mem-0x10 -M \"backtrace:5\"\n\nAllocated/free flag: M=allocated, F=freed\"\"\")\n\n        sbobject.add_arguments(self)\n    \n    @staticmethod\n    def add_arguments(self):\n        \"\"\"Most arguments are shared by the \"sbobject\" commands and other commands.\n        This function allows to initialize them in other commands too\n        \n        E.g. if we created a \"sbcache\" class, we will add arguments later\n        after we create our own parser\n\n        Note that it is a static method but it has self as a first\n        argument to make it easier to read its implementation\n        \"\"\"\n        if self.name == \"sbobject\":\n            group = self.parser\n        else:\n            group = self.parser.add_argument_group(\"generic optional arguments\")\n        if self.name == \"sbobject\":\n            self.parser.add_argument(\n                \"addresses\", nargs=\"*\", default=None,\n                help=\"Address(es) to object(s)/chunk(s) in a memory region associated with a slab\"\n            )\n        self.parser.add_argument(\n            \"-n\",\n            dest=\"name\",\n            default=None, # None means search in all slab caches\n            help=\"The slab cache name (e.g. kmalloc-64). Use \\\"sblist\\\" to get them all\",\n        )\n        group.add_argument(\n            \"-v\", \"--verbose\", dest=\"verbose\", action=\"count\", default=0,\n            help=\"Use verbose output (multiple for more verbosity)\"\n        )\n        group.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n        if self.name == \"sbobject\":\n            group.add_argument(\n                \"-c\", \"--count\", dest=\"count\", type=h.check_count_value, default=1,\n                help=\"\"\"Number of objects/chunks to print linearly (also supports \"unlimited\"/0\nor negative numbers to print objects/chunks going backwards)\"\"\"\n            )\n        group.add_argument(\n            \"-x\", \"--hexdump\", dest=\"hexdump\", action=\"store_true\", default=False,\n            help=\"Hexdump the object/chunk contents\"\n        )\n        group.add_argument(\n            \"-X\", dest=\"hexdump_unit\", type=h.check_hexdump_unit, default=1,\n            help=f\"Specify hexdump unit ({h.prepare_list(h.hexdump_units)}) when using -x (default: %(default)s)\"\n        )\n        group.add_argument(\n            \"-m\", \"--maxbytes\", dest=\"maxbytes\", type=h.string_to_int, default=0,\n            help=\"Max bytes to dump with -x\"\n        )\n        if self.name == \"sbobject\" or self.name == \"sbcache\":\n            group.add_argument(\n                \"-N\", dest=\"no_newline\", action=\"store_true\", default=False,\n                help=\"Do not output the trailing newline (summary representation)\"\n            )\n        group.add_argument(\n            \"-p\", dest=\"print_offset\", type=h.string_to_int, default=0,\n            help=\"Print data inside at given offset (summary representation)\"\n        )\n        group.add_argument(\n            \"-M\", \"--metadata\", dest=\"metadata\", type=str, default=None,\n            help=\"Comma separated list of metadata to print (previously stored with the 'sbmeta' command)\"\n        )\n        if self.name == \"sbobject\" or self.name == \"sbcache\":\n            group.add_argument(\n                \"-I\", \"--highlight-types\", dest=\"highlight_types\", type=str, default=None,\n                help=\"Comma separated list of chunk types (M, F) for objects/chunks we want to highlight in the output\"\n            )\n        group.add_argument(\n            \"-H\", \"--highlight-addresses\", dest=\"highlight_addresses\", type=str, default=None,\n            help=\"Comma separated list of addresses for objects/chunks we want to highlight in the output\"\n        )\n        group.add_argument(\n            \"-G\", \"--highlight-metadata\", dest=\"highlight_metadata\", type=str, default=None,\n            help=\"\"\"Comma separated list of metadata (previously stored with the 'sbmeta' command) \nfor objects/chunks we want to highlight in the output\"\"\"\n        )\n        group.add_argument(\n            \"--highlight-only\", dest=\"highlight_only\", action=\"store_true\", default=False,\n            help=\"Only show the highlighted objects/chunks (instead of just '*' them)\"\n        )\n        if self.name != \"sbfree\":\n            group.add_argument(\n                \"--use-cache\", dest=\"use_cache\", action=\"store_true\", default=False,\n                help=\"\"\"Do not fetch any internal slab data if you know they haven't changed since\nlast time they were cached\"\"\"\n            )\n        group.add_argument(\n            \"-s\", \"--search\", dest=\"search_value\", type=str, default=None,\n            help=\"Search a value and show match/no match\"\n        )\n        group.add_argument(\n            \"-S\", \"--search-type\", dest=\"search_type\", type=str, default=\"string\",\n            help=f\"Specify search type ({h.prepare_list(sbobject.search_types)}) when using -s (default: %(default)s)\"\n        )\n        group.add_argument(\n            \"--match-only\", dest=\"match_only\", action=\"store_true\", default=False,\n            help=\"Only show the matched chunks (instead of just show match/no match)\"\n        )\n        group.add_argument(\n            \"--skip-header\", dest=\"skip_header\", action=\"store_true\", default=False,\n            help=\"Don't include chunk header contents in search results\"\n        )\n        group.add_argument(\n            \"--depth\", dest=\"search_depth\", type=h.string_to_int, default=0,\n            help=\"How far into each chunk to search, starting from chunk header address\"\n        )\n        group.add_argument(\n            \"--cmds\", dest=\"commands\", type=str, default=None,\n            help=\"\"\"Semi-colon separated list of debugger commands to be executed for each chunk that is displayed \n('@' is replaced by the chunk address)\"\"\"\n        )\n        group.add_argument(\n            \"--object-info\", dest=\"object_info\", action=\"store_true\", default=False,\n            help=\"Show object info such as its slab/cpu/node/etc. (summary representation)\"\n        )\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n        # Debug and force printing stuff\n        self.parser.add_argument(\n            \"-d\", \"--debug\", dest=\"debug\", action=\"store_true\", default=False,\n            help=argparse.SUPPRESS\n        )\n        group.add_argument(\n            \"-o\", \"--address-offset\", dest=\"address_offset\", action=\"store_true\", default=False,\n            help=\"Print offsets from the first printed chunk instead of addresses\"\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbobject.invoke()\")\n\n        self.sb.cache.update_all(name=self.args.name, show_status=self.args.debug, use_cache=self.args.use_cache)\n\n        log.debug(\"sbobject.invoke() (2)\")\n\n        sbobject.prepare_args_if_negative_count(self)\n\n        ret = sbobject.parse_arguments(self)\n        if ret == None:\n            return\n        addresses, highlight_addresses, highlight_metadata, highlight_types = ret\n\n        # we enforced updating the cache once above so no need to do it for every chunk\n        chunks = sbobject.parse_many2(\n            self, \n            addresses, \n            highlight_addresses=highlight_addresses, \n            highlight_metadata=highlight_metadata, \n            highlight_types=highlight_types, \n            use_cache=True,\n            is_region=True,\n        )\n\n    @staticmethod \n    def prepare_args_if_negative_count(self):\n        \"\"\"This is a little bit of a hack. The idea is to handle cases\n        where the user wants to print N chunks going backwards.\n        We are going to list all the chunks in the memory region associated with\n        a slab until we find all the addresses requested and then craft new arguments \n        as if the user requested to print from new addresses N chunks before the requested\n        addresses before calling parse_many2()\n        \"\"\"\n\n        self.args.reverse = False\n        # Nothing to do if the count is positive or unlimited\n        if self.args.count == None or self.args.count >= 0:\n            return\n        # We are making the count positive\n        self.args.count = self.args.count*-1\n        # And we print N chunks before the requested chunk + the actual chunk\n        self.args.count += 1\n        \n        addresses = self.dbg.parse_address(self.args.addresses)\n        if len(addresses) == 0:\n            pu.print_error(\"WARNING: No valid address supplied\")\n            self.parser.print_help()\n            return\n\n        # We will fill it with new addresses later below\n        self.args.addresses = []\n\n        # In what slab caches to look for objects?\n        name = self.args.name\n        if name != None and name in self.sb.cache.slab_caches.keys():\n            kmem_caches = [self.sb.cache.slab_caches[name]]\n        elif name == None:\n            kmem_caches = list(self.sb.cache.slab_caches.values())\n\n        # Prepare arguments for \"sbobject\" format\n        # i.e. for every address, get the new address N chunks before\n        for addr in addresses:\n            ret = obj.obj.is_object_address_in_slab_caches(kmem_caches, addr)\n            if ret is None and name != None:\n                pu.print_error(f\"WARNING: Could not find {addr:#x} in slab cache, skipping\")\n                continue\n            (index, objects_list) = ret\n            index -= (self.args.count-1)\n            if index < 0:\n                pu.print_error(f\"WARNING: Reaching beginning of memory region with {addr:#x}\")\n                index = 0\n            self.args.addresses.append(f\"{objects_list[index].address:#x}\")\n\n    @staticmethod\n    def parse_arguments(self):\n        log.debug(\"sbobject.parse_arguments()\")\n        addresses = []\n        if not self.args.addresses:\n            print(\"WARNING: No address supplied?\")\n            #self.parser.print_help()\n            return None\n        else:\n            addresses = self.dbg.parse_address(self.args.addresses)\n            if len(addresses) == 0:\n                pu.print_error(\"WARNING: No valid address supplied\")\n                #self.parser.print_help()\n                return None\n\n        if self.args.hexdump_unit not in h.hexdump_units:\n            pu.print_error(\"Wrong hexdump unit specified\")\n            #self.parser.print_help()\n            return None\n\n        if self.args.name != None and self.args.name not in self.sb.cache.slab_caches.keys():\n            pu.print_error(f\"Wrong slab cache name specified {self.args.name}\")\n            #self.parser.print_help()\n            return None\n\n        if self.args.search_type not in sbobject.search_types:\n            pu.print_error(f\"Wrong search type specified {self.args.search_type}\")\n            #self.parser.print_help()\n            return None\n        if self.args.search_type != \"string\" and not self.args.search_value.startswith(\"0x\"):\n            pu.print_error(\"Wrong search value for specified type\")\n            #self.parser.print_help()\n            return None\n\n        highlight_addresses = []\n        if self.args.highlight_addresses:\n            list_highlight_addresses = [e.strip() for e in self.args.highlight_addresses.split(\",\")]\n            highlight_addresses = self.dbg.parse_address(list_highlight_addresses)\n            if len(highlight_addresses) == 0:\n                pu.print_error(\"WARNING: No valid address to highlight supplied\")\n                #self.parser.print_help()\n                return None\n        highlight_metadata = []\n        if self.args.highlight_metadata:\n            highlight_metadata = [e.strip() for e in self.args.highlight_metadata.split(\",\")]\n\n        # some commands inheriting sbobject arguments don't support highlighting types\n        try:\n            highlight_types = self.args.highlight_types\n        except AttributeError:\n            highlight_types = None\n        if highlight_types:\n            highlight_types = [e.strip() for e in highlight_types.split(\",\")]\n            for e in highlight_types:\n                if e not in [\"M\", \"F\"]:\n                    pu.print_error(\"WARNING: Invalid type to highlight supplied\")\n                    #self.parser.print_help()\n                    return None\n        else:\n            highlight_types = []\n        \n        return addresses, highlight_addresses, highlight_metadata, highlight_types\n\n    @staticmethod\n    def parse_many2(self,\n        addresses, \n        highlight_addresses=[], \n        highlight_metadata=[], \n        highlight_types=[],\n        inuse=None,\n        main_slab_freelist=None,\n        allow_invalid=False,\n        separate_addresses_non_verbose=True,\n        header_once=None,\n        count_handle=None,\n        count_printed=None,\n        use_cache=False, \n        is_region=False,\n        is_freelist=False,\n    ):\n        \"\"\"Most arguments are shared by \"sbobject\" and other commands.\n        This function allows for other commands to call into \"sbobject\"\n\n        :param inuse: True if we know it is an inuse chunk (i.e. not in any bin) (not required)\n        :param main_slab_freelist: True if we know all the chunks are in the cpu main slab freelist,\n                        False if we know they are NOT in the cpu main slab freelist. \n                        None otherwise.\n        :param allow_invalid: sometimes these structures will be used for\n                              that isn't actually a complete chunk, like a freebin, in these cases we\n                              still wanted to be able to parse so that we can access the forward and\n                              backward pointers, so shouldn't complain about their being invalid size\n        :param separate_addresses_non_verbose: False to avoid a separation when printing\n                                               one-line chunks, like in feelists\n        :param header_once: string to print before printing the first chunk, or None if not needed\n        :param count_handle: maximum number of chunks to handle per address, even if not printed, or None if unlimited\n        :param count_printed: maximum number of chunks to print in total for all addresses, or None if unlimited.\n                              Only useful if handling a freebin.\n        :return: the list of objects found\n\n        Note that it is a static method but it has self as a first\n        argument to make it easier to read its implementation\n        \"\"\"\n\n        hexdump_unit = self.args.hexdump_unit\n        count = self.args.count\n        search_depth = self.args.search_depth\n        skip_header = self.args.skip_header\n        print_offset = self.args.print_offset\n        metadata = self.args.metadata\n        verbose = self.args.verbose\n        no_newline = self.args.no_newline\n        debug = self.args.debug\n        hexdump = self.args.hexdump\n        maxbytes = self.args.maxbytes\n        commands = self.args.commands\n        address_offset = self.args.address_offset\n\n        name = self.args.name\n\n        search_value = self.args.search_value\n        search_type = self.args.search_type\n        match_only = self.args.match_only\n\n        highlight_only = self.args.highlight_only\n        object_info = self.args.object_info\n\n        # In what slab caches to look for objects?\n        if name != None and name in self.sb.cache.slab_caches.keys():\n            kmem_caches = [self.sb.cache.slab_caches[name]]\n        elif name == None:\n            kmem_caches = list(self.sb.cache.slab_caches.values())\n\n        all_chunks = []\n        chunks = None\n        for address in addresses:\n            if chunks is not None and len(chunks) > 0 and \\\n            (separate_addresses_non_verbose or verbose > 0):\n                print(\"-\" * 60)\n\n            if count_printed == None:\n                count_linear = count\n            elif count == None:\n                count_linear = count_printed\n            else:\n                count_linear = min(count_printed, count)\n\n            ret = obj.obj.is_object_address_in_slab_caches(kmem_caches, address)\n            if ret is None:\n                return\n            (index, objects_list) = ret\n\n            chunks = sbobject.parse_many(\n                objects_list, \n                index, \n                self.sb, \n                self.dbg, \n                count_linear, \n                count_handle, \n                search_depth,\n                skip_header, \n                hexdump_unit, \n                search_value, \n                search_type, \n                match_only, \n                print_offset, \n                verbose,\n                no_newline,\n                debug, \n                hexdump, \n                maxbytes, \n                metadata,\n                highlight_types=highlight_types,\n                highlight_addresses=highlight_addresses,\n                highlight_metadata=highlight_metadata,\n                highlight_only=highlight_only,\n                inuse=inuse, \n                allow_invalid=allow_invalid,\n                header_once=header_once, \n                commands=commands,\n                use_cache=use_cache,\n                address_offset=address_offset,\n                name=name,\n                is_region=is_region,\n                is_freelist=is_freelist,\n                object_info=object_info,\n            )\n            if chunks is not None and len(chunks) > 0:\n                all_chunks.extend(chunks)\n                if count_printed != None:\n                    count_printed -= len(chunks)\n                header_once = None\n            if count_printed == 0:\n                break\n        return all_chunks\n\n    # XXX - probably sb can just have the debugger\n    @staticmethod\n    def parse_many(\n        objects_list, \n        index, \n        sb, \n        dbg=None, \n        count=1, \n        count_handle=None, \n        search_depth=0, \n        skip_header=False, \n        hexdump_unit=1, \n        search_value=None,\n        search_type=None, \n        match_only=False, \n        print_offset=0, \n        verbose=0, \n        no_newline=False,\n        debug=False, \n        hexdump=False, \n        maxbytes=0, \n        metadata=None,\n        highlight_types=[], \n        highlight_addresses=[], \n        highlight_metadata=[], \n        highlight_only=False, \n        inuse=None, \n        allow_invalid=False,\n        header_once=None, \n        commands=None,\n        use_cache=False, \n        address_offset=False, \n        name=None,\n        indent=\"\",\n        is_region=False,\n        is_freelist=False,\n        object_info=False,\n    ):\n        \"\"\"Parse many chunks starting from a given address and show them based\n        passed arguments\n\n        :param objects_list: list of objects (linear view for memory regions or freelist)\n        :param index: index in objects_list[] to start parsing from\n        :param sb: slab object (libslub constants and helpers)\n        :param dbg: pydbg object (debugger interface)\n        :param count: see sbobject's ArgumentParser definition\n                      maximum number of chunks to print, or None if unlimited\n        :param count_handle: maximum number of chunks to handle per address, even if not printed, or None if unlimited\n        :param search_depth: see sbobject's ArgumentParser definition\n        :param skip_header: see sbobject's ArgumentParser definition\n        :param hexdump_unit: see sbobject's ArgumentParser definition\n        :param search_value: see sbobject's ArgumentParser definition\n        :param search_type: see sbobject's ArgumentParser definition\n        :param match_only: see sbobject's ArgumentParser definition\n        :param print_offset: see sbobject's ArgumentParser definition\n        :param verbose: see sbobject's ArgumentParser definition\n        :param no_newline: see sbobject's ArgumentParser definition\n        :param debug: see sbobject's ArgumentParser definition\n        :param hexdump: see sbobject's ArgumentParser definition\n        :param maxbytes: see sbobject's ArgumentParser definition\n        :param metadata: see sbobject's ArgumentParser definition\n        :param highlight_types: list of types. highlight chunks with matching type with a '*' e.g. to be used by 'ptlist'\n        :param highlight_addresses: list of addresses. highlight chunks with matching address with a '*' e.g. to be used by 'ptlist'\n        :param highlight_metadata: list of metadata. highlight chunks with matching metadata with a '*' e.g. to be used by 'ptlist'\n        :param highlight_only: see sbobject's ArgumentParser definition\n        :param inuse: True if we know all the chunks are inuse (i.e. not in any bin)\n                      False if we know they are NOT in inuse.\n                      None otherwise.\n                      Useful to specify when parsing a regular bin\n        :param allow_invalid: sometimes these structures will be used for\n                              that isn't actually a complete chunk, like a freebin, in these cases we\n                              still wanted to be able to parse so that we can access the forward and\n                              backward pointers, so shouldn't complain about their being invalid size\n        :param header_once: string to print before printing the first chunk, or None if not needed\n        :param commands: see sbobject's ArgumentParser definition\n        :param use_cache: see sbobject's ArgumentParser definition\n        :param address_offset: see sbobject's ArgumentParser definition\n        :param name: see sbobject's ArgumentParser definition\n\n        :return: the list of malloc_chunk being parsed and already shown\n        \"\"\"\n        chunks = []\n        if len(objects_list) == 0 or index >= len(objects_list):\n            return chunks\n\n        highlight_types = set(highlight_types)\n        for t in highlight_types:\n            if t != \"M\" and t != \"F\":\n                print(\"ERROR: invalid chunk type provided, should not happen\")\n                return []\n        highlight_addresses = set(highlight_addresses)\n        highlight_metadata = set(highlight_metadata)\n        highlight_metadata_found = set([])\n\n        count_objects = len(objects_list)\n\n        o = objects_list[index]\n        first_address = o.address\n        dump_offset = 0\n        while True:\n            prefix = \"\" # used for one-line output\n            suffix = \"\" # used for one-line output\n            epilog = \"\" # used for verbose output\n\n            if object_info:\n                show_slab_cache = name is None\n                suffix += f\" ({o.info(show_slab_cache=show_slab_cache)})\"\n\n            colorize_func = str # do not colorize by default\n            if metadata is not None:\n                opened = False\n                list_metadata = [e.strip() for e in metadata.split(\",\")]\n                L, s, e, colorize_func = sbmeta.get_metadata(o.address, list_metadata=list_metadata)\n                suffix += s\n                epilog += e\n                o.metadata = L # save so we can easily export to json later\n\n            if search_value is not None:\n                if not dbg.search_chunk(\n                    sb, o, search_value, search_type=search_type,\n                    depth=search_depth, skip=skip_header\n                ):\n                    found_match = False\n                    suffix += \" [NO MATCH]\"\n                else:\n                    suffix += pu.light_green(\" [MATCH]\")\n                    found_match = True\n\n            # XXX - the current representation is not really generic as we print the first short\n            # as an ID and the second 2 bytes as 2 characters. We may want to support passing the\n            # format string as an argument but this is already useful\n            if print_offset != 0:\n                mem = dbg.read_memory(\n                    o.address + print_offset, 4\n                )\n                (id_, desc) = struct.unpack_from(\"<H2s\", mem, 0x0)\n                if h.is_ascii(desc):\n                    suffix += \" 0x%04x %s\" % (id_, str(desc, encoding=\"utf-8\"))\n                else:\n                    suffix += \" 0x%04x hex(%s)\" % (\n                        id_,\n                        str(binascii.hexlify(desc), encoding=\"utf-8\"),\n                    )\n\n            if is_region:\n                if index == 0:\n                    suffix += \" (region start)\"\n                elif index == count_objects-1:\n                    suffix += \" (region end)\"\n            if is_freelist:\n                suffix += f\" [{index+1:#d}]\"\n\n            # Only print the chunk type for non verbose\n            printed = False\n            if verbose == 0:\n                found_highlight = False\n                # Only highlight chunks for non verbose\n                if o.address in highlight_addresses:\n                    found_highlight = True\n                    highlight_addresses.remove(o.address)\n                if (o.inuse is True and \"M\" in highlight_types) or \\\n                    (o.inuse is False and \"F\" in highlight_types):\n                    found_highlight = True\n                if len(highlight_metadata) > 0:\n                    # We retrieve all metadata since we want to highlight chunks containing any of the\n                    # metadata, even if we don't show some of the metadata\n                    _, s, _, _ = sbmeta.get_metadata(o.address, list_metadata=\"all\")\n                    for m in highlight_metadata:\n                        # we check in the one-line output as it should have less non-useful information\n                        if m in s:\n                            found_highlight = True\n                            highlight_metadata_found.add(m)\n                if found_highlight:\n                    prefix += \"* \"\n                if (not highlight_only or found_highlight) \\\n                    and (not match_only or found_match):\n                    if header_once != None:\n                        print(indent + header_once)\n                        header_once = None\n                    if no_newline:\n                        print(indent + prefix + o.to_string(colorize_func=colorize_func) + suffix, end=\"\")\n                    else:\n                        print(indent + prefix + o.to_string(colorize_func=colorize_func) + suffix)\n                    printed = True\n            elif verbose >= 1 and (not match_only or found_match):\n                if header_once != None:\n                    print(indent + header_once)\n                    header_once = None\n                print(indent + o)\n                printed = True\n            if printed:\n                if hexdump:\n                    dbg.print_hexdump_chunk(sb, o, maxlen=maxbytes, off=dump_offset, unit=hexdump_unit, verbose=verbose)\n                if verbose >= 1 and epilog:\n                    print(indent + epilog, end=\"\")\n                if commands:\n                    for command in commands.split(\";\"):\n                        formatted_command = command.replace(\"@\", f\"{o.address:#x}\")\n                        if no_newline:\n                            print(indent + dbg.execute(formatted_command), end=\"\")\n                        else:\n                            print(indent + dbg.execute(formatted_command))\n                chunks.append(o)\n                if count != None:\n                    count -= 1\n            if count_handle != None:\n                count_handle -= 1\n            index += 1\n            if count != 0 and count_handle != 0:\n                if printed and (verbose >= 1 or hexdump):\n                    print(indent+\"--\")\n                if index == count_objects:\n                    # Only print the chunk type for non verbose\n                    print(\"Stopping due to end of memory region\")\n                    break\n                o = objects_list[index]\n            else:\n                break\n\n        # XXX - can't really show that atm as we have lots of memory regions\n        # each associated with a given slab, so would spam messages\n        #if len(highlight_addresses) != 0:\n        #    pu.print_error(\"WARNING: Could not find these chunk addresses: %s\" % (\", \".join([\"0x%x\" % x for x in highlight_addresses])))\n        #if len(highlight_metadata-highlight_metadata_found) != 0:\n        #    pu.print_error(\"WARNING: Could not find these metadata: %s\" % (\", \".join(list(highlight_metadata-highlight_metadata_found))))\n\n        return chunks"]}
{"filename": "libslub/frontend/commands/gdb/sbbreak.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport struct\nimport sys\nimport logging\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu", "\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n", "#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbbreak.py\")\n\nclass sbbreak(sbcmd.sbcmd):\n    \"\"\"Command to start/stop breaking on object allocations for a slab cache\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbbreak.__init__()\")\n        super(sbbreak, self).__init__(sb, \"sbbreak\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Start/stop breaking on object allocations for a slab cache\n\nSetup break points for the specified slab names\"\"\", \n            add_help=False,\n            formatter_class=argparse.RawTextHelpFormatter,\n        )\n        self.parser.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n\n        self.parser.add_argument(\n            \"names\", nargs=\"*\", default=[],\n            help=\"Slab names (e.g. 'kmalloc-1k')\"\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbbreak.invoke()\")\n\n        for name in self.args.names:\n            slab_cache = sb.sb.find_slab_cache(name)\n            if slab_cache is None:\n                print(\"Slab cache '%s' not found\" % name)\n                return\n\n            if name in self.sb.break_caches:\n                print(\"Stopped breaking slab cache '%s'\" % name)\n                self.sb.break_caches.remove(name)\n            else:\n                print(\"Started breaking slab cache '%s'\" % name)\n                self.sb.break_caches.append(name)\n            self.sb.breakpoints.update_breakpoints()"]}
{"filename": "libslub/frontend/commands/gdb/sbhelp.py", "chunked_list": ["from __future__ import print_function\n\nimport sys\nimport logging\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.sb as sb", "importlib.reload(pu)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbhelp.py\")", "log = logging.getLogger(\"libslub\")\nlog.trace(\"sbhelp.py\")\n\nclass sbhelp(sbcmd.sbcmd):\n    \"\"\"Command to list all available commands\"\"\"\n\n    def __init__(self, sb, commands=[]):\n        log.debug(\"sbhelp.__init__()\")\n        super(sbhelp, self).__init__(sb, \"sbhelp\")\n\n        self.cmds = commands\n\n    @h.catch_exceptions\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n\n        Print the usage of all the commands\n        \"\"\"\n\n        pu.print_header(\"{:<20}\".format(\"sbhelp\"), end=\"\")\n        print(\"List all libslub commands\")\n        for cmd in self.cmds:\n            if cmd.parser != None:\n                # Only keep the first line of the description which should be short\n                description = cmd.parser.description.split(\"\\n\")[0]\n            elif cmd.description != None:\n                description = cmd.description\n            else:\n                description = \"Unknown\"\n            pu.print_header(\"{:<20}\".format(cmd.name), end=\"\")\n            print(description)\n        print(\"Note: Use a command name with -h to get additional help\")\n        print(\"Note: Modify libslub.cfg if you want to enable or disable sbbreak/sbtrace/sbwatch commands (may crash GDB due to broken finish)\")"]}
{"filename": "libslub/frontend/commands/gdb/sbcache.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport struct\nimport sys\nimport logging\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu", "\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.slub.kmem_cache as kc\nimportlib.reload(kc)\nimport libslub.frontend.commands.gdb.sbobject as sbobject", "importlib.reload(kc)\nimport libslub.frontend.commands.gdb.sbobject as sbobject\nimportlib.reload(sbobject)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbcache.py\")\n\nclass sbcache(sbcmd.sbcmd):\n    \"\"\"Command to print the metadata and contents of one or all slab cache(s)\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbcache.__init__()\")\n        super(sbcache, self).__init__(sb, \"sbcache\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Print the metadata and contents of one or all slab cache(s)\n\nIf you don't specify any slab cache name, it will print all of them but it will take some time to parse structures in memory\"\"\", \n            add_help=False,\n            formatter_class=argparse.RawTextHelpFormatter,\n        )\n        # \"sbobject\" also has this argument but default for \n        # \"sbcache\" is to show unlimited number of chunks\n        self.parser.add_argument(\n            \"-c\", \"--count\", dest=\"count\", type=h.check_count_value_positive, default=None,\n            help=\"\"\"Number of chunks to print linearly in each slab or in each freelist\"\"\"\n        )\n        # XXX - is it a feature we want for filtering too?\n        #self.parser.add_argument(\n        #    \"-C\", \"--count-slab\", dest=\"count_slab\", type=h.check_count_value_positive, default=None,\n        #    help=\"\"\"Number of slabs to print for each cpu\"\"\"\n        #)\n        self.parser.add_argument(\n            \"--cpu\", dest=\"cpu\", type=int, default=None,\n            help=\"\"\"Show CPU specified only, instead of all slabs (Ignore node's partial slabs and full slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--main-slab\", dest=\"main_slab\", action=\"store_true\", default=None,\n            help=\"\"\"Show main slabs for CPUs only, instead of all slabs (Ignore CPU partial slabs, node's partial slabs and full slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--partial-slab\", dest=\"partial_slab\", action=\"store_true\", default=None,\n            help=\"\"\"Show partial slabs for CPUs only, instead of all slabs (Ignore CPU main slabs, node's partial slabs and full slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--node-slab\", dest=\"node_slab\", action=\"store_true\", default=None,\n            help=\"\"\"Show partial slabs for nodes only, instead of all slabs (Ignore CPU main/partial slabs and node's full slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--full-slab\", dest=\"full_slab\", action=\"store_true\", default=None,\n            help=\"\"\"Show full slabs only, instead of all slabs (Ignore CPU main and partial slabs, node's partial slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--show-freelist\", dest=\"show_freelist\", action=\"store_true\", default=None,\n            help=\"\"\"Show the freelists for each slab (not shown by default)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--show-lockless-freelist\", dest=\"show_lockless_freelist\", action=\"store_true\", default=None,\n            help=\"\"\"Show the freelist associated to a CPU for the main slab (not shown by default)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--show-region\", dest=\"show_region\", action=\"store_true\", default=None,\n            help=\"\"\"Show the objects in the memory region for each slab (not shown by default)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--hide-title\", dest=\"hide_title\", action=\"store_true\", default=False,\n            help=\"\"\"Hide the \"region:\" or \"freelist:\" titles (shown by default) when showing regions or freelists\"\"\"\n        )\n        self.parser.add_argument(\n            \"--object-only\", dest=\"object_only\", action=\"store_true\", default=None,\n            help=\"\"\"Do not show structures' fields and show objects only (still requires --show-freelist and/or --show-region)\"\"\"\n        )\n        # other arguments are implemented in the \"sbobject\" command\n        # and will be shown after the above\n        sbobject.sbobject.add_arguments(self)\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbcache.invoke()\")\n\n        self.sb.cache.update_all(name=self.args.name, show_status=self.args.debug, use_cache=self.args.use_cache)\n        self.args.use_cache = True # we can use the cache from now on\n\n        log.debug(\"sbcache.invoke() (2)\")\n\n        # Prepare fake arguments for \"sbobject\" format\n        self.args.addresses = [\"0x0\"] # won't use it until we parse actual memory regions\n                                      # where we will parse cached memory regions directly at that time anyway\n        ret = sbobject.sbobject.parse_arguments(self)\n        if ret == None:\n            return\n        addresses, self.highlight_addresses, self.highlight_metadata, self.highlight_types = ret\n\n        # this is not a real user argument but is used internally to know if we need to print stuff\n        self.output_filtered = False\n        self.cpu_filtered = False\n        if self.args.main_slab is True or self.args.partial_slab is True \\\n            or self.args.node_slab is True or self.args.full_slab is True:\n            self.output_filtered = True\n        if self.args.cpu is not None:\n            self.cpu_filtered = True\n        if self.args.cpu is not None and (self.args.node_slab is True or self.args.full_slab is True) \\\n            and self.args.main_slab is not True and self.args.partial_slab is not True:\n            print(\"WARNING: --cpu will be ignored\")\n\n        name = self.args.name\n        if name != None and name in self.sb.cache.slab_caches.keys():\n            self.sb.cache.slab_caches[name].print(cmd=self)\n        elif name == None:\n            for name, kmem_cache in self.sb.cache.slab_caches.items():\n                kmem_cache.print(cmd=self)\n        return", "\nclass sbcache(sbcmd.sbcmd):\n    \"\"\"Command to print the metadata and contents of one or all slab cache(s)\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbcache.__init__()\")\n        super(sbcache, self).__init__(sb, \"sbcache\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Print the metadata and contents of one or all slab cache(s)\n\nIf you don't specify any slab cache name, it will print all of them but it will take some time to parse structures in memory\"\"\", \n            add_help=False,\n            formatter_class=argparse.RawTextHelpFormatter,\n        )\n        # \"sbobject\" also has this argument but default for \n        # \"sbcache\" is to show unlimited number of chunks\n        self.parser.add_argument(\n            \"-c\", \"--count\", dest=\"count\", type=h.check_count_value_positive, default=None,\n            help=\"\"\"Number of chunks to print linearly in each slab or in each freelist\"\"\"\n        )\n        # XXX - is it a feature we want for filtering too?\n        #self.parser.add_argument(\n        #    \"-C\", \"--count-slab\", dest=\"count_slab\", type=h.check_count_value_positive, default=None,\n        #    help=\"\"\"Number of slabs to print for each cpu\"\"\"\n        #)\n        self.parser.add_argument(\n            \"--cpu\", dest=\"cpu\", type=int, default=None,\n            help=\"\"\"Show CPU specified only, instead of all slabs (Ignore node's partial slabs and full slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--main-slab\", dest=\"main_slab\", action=\"store_true\", default=None,\n            help=\"\"\"Show main slabs for CPUs only, instead of all slabs (Ignore CPU partial slabs, node's partial slabs and full slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--partial-slab\", dest=\"partial_slab\", action=\"store_true\", default=None,\n            help=\"\"\"Show partial slabs for CPUs only, instead of all slabs (Ignore CPU main slabs, node's partial slabs and full slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--node-slab\", dest=\"node_slab\", action=\"store_true\", default=None,\n            help=\"\"\"Show partial slabs for nodes only, instead of all slabs (Ignore CPU main/partial slabs and node's full slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--full-slab\", dest=\"full_slab\", action=\"store_true\", default=None,\n            help=\"\"\"Show full slabs only, instead of all slabs (Ignore CPU main and partial slabs, node's partial slabs)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--show-freelist\", dest=\"show_freelist\", action=\"store_true\", default=None,\n            help=\"\"\"Show the freelists for each slab (not shown by default)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--show-lockless-freelist\", dest=\"show_lockless_freelist\", action=\"store_true\", default=None,\n            help=\"\"\"Show the freelist associated to a CPU for the main slab (not shown by default)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--show-region\", dest=\"show_region\", action=\"store_true\", default=None,\n            help=\"\"\"Show the objects in the memory region for each slab (not shown by default)\"\"\"\n        )\n        self.parser.add_argument(\n            \"--hide-title\", dest=\"hide_title\", action=\"store_true\", default=False,\n            help=\"\"\"Hide the \"region:\" or \"freelist:\" titles (shown by default) when showing regions or freelists\"\"\"\n        )\n        self.parser.add_argument(\n            \"--object-only\", dest=\"object_only\", action=\"store_true\", default=None,\n            help=\"\"\"Do not show structures' fields and show objects only (still requires --show-freelist and/or --show-region)\"\"\"\n        )\n        # other arguments are implemented in the \"sbobject\" command\n        # and will be shown after the above\n        sbobject.sbobject.add_arguments(self)\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbcache.invoke()\")\n\n        self.sb.cache.update_all(name=self.args.name, show_status=self.args.debug, use_cache=self.args.use_cache)\n        self.args.use_cache = True # we can use the cache from now on\n\n        log.debug(\"sbcache.invoke() (2)\")\n\n        # Prepare fake arguments for \"sbobject\" format\n        self.args.addresses = [\"0x0\"] # won't use it until we parse actual memory regions\n                                      # where we will parse cached memory regions directly at that time anyway\n        ret = sbobject.sbobject.parse_arguments(self)\n        if ret == None:\n            return\n        addresses, self.highlight_addresses, self.highlight_metadata, self.highlight_types = ret\n\n        # this is not a real user argument but is used internally to know if we need to print stuff\n        self.output_filtered = False\n        self.cpu_filtered = False\n        if self.args.main_slab is True or self.args.partial_slab is True \\\n            or self.args.node_slab is True or self.args.full_slab is True:\n            self.output_filtered = True\n        if self.args.cpu is not None:\n            self.cpu_filtered = True\n        if self.args.cpu is not None and (self.args.node_slab is True or self.args.full_slab is True) \\\n            and self.args.main_slab is not True and self.args.partial_slab is not True:\n            print(\"WARNING: --cpu will be ignored\")\n\n        name = self.args.name\n        if name != None and name in self.sb.cache.slab_caches.keys():\n            self.sb.cache.slab_caches[name].print(cmd=self)\n        elif name == None:\n            for name, kmem_cache in self.sb.cache.slab_caches.items():\n                kmem_cache.print(cmd=self)\n        return"]}
{"filename": "libslub/frontend/commands/gdb/sbcmd.py", "chunked_list": ["# Note: We can't importlib.reload() this file atm because\n# otherwise we get an \"super(type, obj): obj must be an instance \n# or subtype of type\" when instanciating\n# several classes inheriting from the same ptcmd class.\n# See https://thomas-cokelaer.info/blog/2011/09/382/\n# This file should not change much anyway but if we modify it, we need to restart gdb\n# entirely instead of reloading libslub only\n\nimport logging\nimport shlex", "import logging\nimport shlex\nfrom functools import wraps\nimport gdb\n\nfrom libslub.frontend import printutils as pu\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbcmd.py\")\n\nclass sbcmd(gdb.Command):\n    \"\"\"This is a super class with convenience methods shared by all the commands to:\n    - parse the command's arguments/options\n    - set/reset a logging level (debugging only)\n    \"\"\"\n\n    def __init__(self, sb, name):\n        self.sb = sb\n        \n        if self.sb.dbg is None:\n            pu.print_error(\"Please specify a debugger\")\n            raise Exception(\"sys.exit()\")\n\n        self.name = name\n        self.old_level = None\n        self.parser = None      # ArgumentParser\n        self.description = None # Only use if not in the parser\n\n        super(sbcmd, self).__init__(name, gdb.COMMAND_DATA, gdb.COMPLETE_NONE)\n\n    @property\n    def version(self):\n        \"\"\"Easily access the version string without going through the slab object\"\"\"\n        return self.sb.version\n\n    @property\n    def dbg(self):\n        \"\"\"Easily access the pydbg object without going through the slab object\"\"\"\n        return self.sb.dbg\n\n    @property\n    def cache(self):\n        \"\"\"Easily access the cache object without going through the slab object\"\"\"\n        return self.sb.cache\n\n    def set_loglevel(self, loglevel):\n        \"\"\"Change the logging level. This is changed temporarily for the duration\n        of the command since reset_loglevel() is called at the end after the command is executed\n        \"\"\"\n        if loglevel != None:\n            numeric_level = getattr(logging, loglevel.upper(), None)\n            if not isinstance(numeric_level, int):\n                print(\"WARNING: Invalid log level: %s\" % loglevel)\n                return\n            self.old_level = log.getEffectiveLevel()\n            #print(\"old loglevel: %d\" % self.old_level)\n            #print(\"new loglevel: %d\" % numeric_level)\n            log.setLevel(numeric_level)\n\n    def reset_loglevel(self):\n        \"\"\"Reset the logging level to the previous one\"\"\"\n        if self.old_level != None:\n            #print(\"restore loglevel: %d\" % self.old_level)\n            log.setLevel(self.old_level)\n            self.old_level = None\n\n    def init_and_cleanup(f):\n        \"\"\"Decorator for a command's invoke() method\n\n        This allows:\n        - not having to duplicate the argument parsing in all commands\n        - not having to reset the log level before each of the \"return\"\n          in the invoke() of each command\n        \"\"\"\n\n        @wraps(f)\n        def _init_and_cleanup(self, arg, from_tty):\n            try:\n                self.args = self.parser.parse_args(shlex.split(arg))\n            except SystemExit as e:\n                # If we specified an unsupported argument/option, argparse will try to call sys.exit()\n                # which will trigger such an exception, so we can safely catch it to avoid error messages\n                # in gdb\n                #h.show_last_exception()\n                #raise e\n                return\n            if self.args.help:\n                self.parser.print_help()\n                return\n            self.set_loglevel(self.args.loglevel)\n            f(self, arg, from_tty) # Call actual invoke()\n            self.reset_loglevel()\n        return _init_and_cleanup", "log.trace(\"sbcmd.py\")\n\nclass sbcmd(gdb.Command):\n    \"\"\"This is a super class with convenience methods shared by all the commands to:\n    - parse the command's arguments/options\n    - set/reset a logging level (debugging only)\n    \"\"\"\n\n    def __init__(self, sb, name):\n        self.sb = sb\n        \n        if self.sb.dbg is None:\n            pu.print_error(\"Please specify a debugger\")\n            raise Exception(\"sys.exit()\")\n\n        self.name = name\n        self.old_level = None\n        self.parser = None      # ArgumentParser\n        self.description = None # Only use if not in the parser\n\n        super(sbcmd, self).__init__(name, gdb.COMMAND_DATA, gdb.COMPLETE_NONE)\n\n    @property\n    def version(self):\n        \"\"\"Easily access the version string without going through the slab object\"\"\"\n        return self.sb.version\n\n    @property\n    def dbg(self):\n        \"\"\"Easily access the pydbg object without going through the slab object\"\"\"\n        return self.sb.dbg\n\n    @property\n    def cache(self):\n        \"\"\"Easily access the cache object without going through the slab object\"\"\"\n        return self.sb.cache\n\n    def set_loglevel(self, loglevel):\n        \"\"\"Change the logging level. This is changed temporarily for the duration\n        of the command since reset_loglevel() is called at the end after the command is executed\n        \"\"\"\n        if loglevel != None:\n            numeric_level = getattr(logging, loglevel.upper(), None)\n            if not isinstance(numeric_level, int):\n                print(\"WARNING: Invalid log level: %s\" % loglevel)\n                return\n            self.old_level = log.getEffectiveLevel()\n            #print(\"old loglevel: %d\" % self.old_level)\n            #print(\"new loglevel: %d\" % numeric_level)\n            log.setLevel(numeric_level)\n\n    def reset_loglevel(self):\n        \"\"\"Reset the logging level to the previous one\"\"\"\n        if self.old_level != None:\n            #print(\"restore loglevel: %d\" % self.old_level)\n            log.setLevel(self.old_level)\n            self.old_level = None\n\n    def init_and_cleanup(f):\n        \"\"\"Decorator for a command's invoke() method\n\n        This allows:\n        - not having to duplicate the argument parsing in all commands\n        - not having to reset the log level before each of the \"return\"\n          in the invoke() of each command\n        \"\"\"\n\n        @wraps(f)\n        def _init_and_cleanup(self, arg, from_tty):\n            try:\n                self.args = self.parser.parse_args(shlex.split(arg))\n            except SystemExit as e:\n                # If we specified an unsupported argument/option, argparse will try to call sys.exit()\n                # which will trigger such an exception, so we can safely catch it to avoid error messages\n                # in gdb\n                #h.show_last_exception()\n                #raise e\n                return\n            if self.args.help:\n                self.parser.print_help()\n                return\n            self.set_loglevel(self.args.loglevel)\n            f(self, arg, from_tty) # Call actual invoke()\n            self.reset_loglevel()\n        return _init_and_cleanup"]}
{"filename": "libslub/frontend/commands/gdb/sbslabdb.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport binascii\nimport struct\nimport sys\nimport logging\nimport pprint\nimport re\nimport pickle", "import re\nimport pickle\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.slub.sb as sb", "importlib.reload(h)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbslabdb.py\")\n\n# The actual database of slabs and associated chunk addresses", "\n# The actual database of slabs and associated chunk addresses\n# that are tracked as part of the \"add\" and \"del\" commands\nslab_db = {}\n\n# just a cache to avoid querying structure in memory each time\n# but we will query it again if the address we \"add\" or \"delete\"\n# is not there\ncached_info = {}\n", "cached_info = {}\n\nSLAB_DB = \"slabdb.pickle\"\ndef save_slab_db_to_file(filename):\n    \"\"\"During development, we reload libslub and lose the slab database\n    so this allows saving it easily into a file before doing so\n    \"\"\"\n    d = {}\n    d[\"slab_db\"] = slab_db\n    pickle.dump(d, open(filename, \"wb\"))", "\ndef load_slab_db_from_file(filename):\n    \"\"\"During development, we reload libslub and lose the slab database\n    so this allows reloading it easily from a file\n    \"\"\"\n    global slab_db\n    d = pickle.load(open(filename, \"rb\"))\n    slab_db = d[\"slab_db\"]\n\nclass sbslabdb(sbcmd.sbcmd):\n    \"\"\"Command to add/delete known slab addresses when they are created/deleted\n    \n    This is an alternative way to save slab addresses to \"sbwatch\" since gdb breakpoints in Python\n    crash gdb a lot...\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbslabdb.__init__()\")\n        super(sbslabdb, self).__init__(sb, \"sbslabdb\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Handle saving slab addresses associated with object/chunk addresses\"\"\", \n            formatter_class=argparse.RawTextHelpFormatter,\n            add_help=False,\n            epilog=\"\"\"This is particularly useful to be able to track full slabs\n\nNOTE: use 'sbslabdb <action> -h' to get more usage info\"\"\")\n        self.parser.add_argument(\n            \"-v\", \"--verbose\", dest=\"verbose\", action=\"count\", default=0,\n            help=\"Use verbose output (multiple for more verbosity)\"\n        )\n        self.parser.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n\n        actions = self.parser.add_subparsers(\n            help=\"Action to perform\", \n            dest=\"action\"\n        )\n\n        add_parser = actions.add_parser(\n            \"add\",\n            help=\"\"\"Add slab address to the list\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"XXX\"\"\"\n        )\n        add_parser.add_argument(\n            'cache', \n            help='slab cache (e.g. \"kmalloc-1k\")'\n        )\n        \n        add_parser.add_argument(\n            'address', \n            help='Chunk address to add'\n        )\n        \n        del_parser = actions.add_parser(\n            \"del\", \n            help=\"\"\"Delete slab address from the list\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"XXX\"\"\"\n        )\n        del_parser.add_argument(\n            'cache', \n            help='slab cache (e.g. \"kmalloc-1k\")'\n        )\n        del_parser.add_argument(\n            'address', \n            help='Chunk address to remove'\n        )\n        \n        list_parser = actions.add_parser(\n            \"list\", \n            help=\"\"\"List all the slab addresses from the list (debugging)\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"XXX\"\"\"\n        )\n\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n        # allows to save the slab db to file during development/debugging\n        self.parser.add_argument(\n            \"-S\", \"--save-db\", dest=\"save\", action=\"store_true\", default=False,\n            help=argparse.SUPPRESS\n        )\n        # allows to load the slab db from file during development/debugging\n        self.parser.add_argument(\n            \"-L\", \"--load-db\", dest=\"load\", action=\"store_true\", default=False,\n            help=argparse.SUPPRESS\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbslabdb.invoke()\")\n\n        if self.args.action is None and not self.args.save and not self.args.load:\n            pu.print_error(\"WARNING: requires an action\")\n            self.parser.print_help()\n            return\n \n        if self.args.action == \"list\":\n            for cache_name, d in slab_db.items():\n                print(f\"slab cache: {cache_name}\")\n                for slab_addr, L in d.items():\n                    print(f\"\\tslab @ {slab_addr:#x}\")\n                    for addr in L:\n                        print(f\"\\t\\t- {addr:#x}\")\n            return\n\n        if self.args.save:\n            if self.args.verbose >= 0: # always print since debugging feature\n                print(\"Saving slabs database to file...\")\n            save_slab_db_to_file(SLAB_DB)\n            return\n\n        if self.args.load:\n            if self.args.verbose >= 0: # always print since debugging feature\n                print(\"Loading slabs database from file...\")\n            load_slab_db_from_file(SLAB_DB)\n            return\n\n        address = None\n        if self.args.address != None:\n            addresses = self.dbg.parse_address(self.args.address)\n            if len(addresses) == 0:\n                pu.print_error(\"WARNING: No valid address supplied\")\n                self.parser.print_help()\n                return\n            address = addresses[0]\n\n        if not self.args.cache:\n            pu.print_error(\"WARNING: No valid cache name supplied\")\n            self.parser.print_help()\n            return\n\n        if self.args.action == \"del\":\n            if self.args.cache not in slab_db.keys():\n                log.debug(f\"Warning: tried to remove from non-tracked cache: {self.args.cache}\")\n                return\n            slab_addr = self.get_slab_address2(address, self.args.cache)\n            if not slab_addr:\n                log.debug(f\"Warning: tried to remove chunk address: {address:#x} from non-existing slab in cache: {self.args.cache}\")\n                return\n            if slab_addr not in slab_db[self.args.cache].keys():\n                log.debug(f\"Warning: tried to remove chunk address: {address:#x} from non-tracked slab in cache: {self.args.cache}\")\n                return\n            if address not in slab_db[self.args.cache][slab_addr]:\n                log.debug(f\"Warning: tried to remove non-existing chunk address: {address:#x} from slab address: {slab_addr:#x} in cache: {self.args.cache}\")\n                return\n            slab_db[self.args.cache][slab_addr].remove(address)\n            if len(slab_db[self.args.cache][slab_addr]) == 0:\n                del slab_db[self.args.cache][slab_addr]\n            return\n\n        if self.args.action == \"add\":\n            if self.args.cache not in slab_db.keys():\n                slab_db[self.args.cache] = {}\n            slab_addr = self.get_slab_address2(address, self.args.cache)\n            if not slab_addr:\n                log.debug(f\"Warning: tried to add chunk address: {address:#x} from non-existing slab in cache: {self.args.cache}\")\n                return\n            if slab_addr not in slab_db[self.args.cache].keys():\n                slab_db[self.args.cache][slab_addr] = set([])\n            if address in slab_db[self.args.cache][slab_addr]:\n                log.debug(f\"Warning: tried to add existing chunk address: {address:#x} to slab @ {slab_addr:#x} and cache: {self.args.cache}\")\n            else:\n                slab_db[self.args.cache][slab_addr].add(address)\n            return\n\n    def get_slab_address2(self, chunk_addr, cache_name):\n        global cached_info\n\n        # Check our local cache first\n        log.debug(\"Checking\")\n        if cache_name in cached_info.keys():\n            for page_addr, (region_start, region_end) in cached_info[cache_name].items():\n                if chunk_addr >= region_start and chunk_addr < region_end:\n                    return page_addr\n\n        # Not found in our cache, so query structures and memory to update our cache\n        log.debug(\"Updating cache\")\n        cached_info[cache_name] = self.sb.get_slab_cache_memory_pages_ranges(name=self.args.cache, dict_enabled=True)\n        \n        # And check again\n        log.debug(\"Checking again\")\n        for page_addr, (region_start, region_end) in cached_info[cache_name].items():\n            if chunk_addr >= region_start and chunk_addr < region_end:\n                return page_addr\n\n        log.debug(\"Not found\")\n        return None", "\nclass sbslabdb(sbcmd.sbcmd):\n    \"\"\"Command to add/delete known slab addresses when they are created/deleted\n    \n    This is an alternative way to save slab addresses to \"sbwatch\" since gdb breakpoints in Python\n    crash gdb a lot...\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbslabdb.__init__()\")\n        super(sbslabdb, self).__init__(sb, \"sbslabdb\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Handle saving slab addresses associated with object/chunk addresses\"\"\", \n            formatter_class=argparse.RawTextHelpFormatter,\n            add_help=False,\n            epilog=\"\"\"This is particularly useful to be able to track full slabs\n\nNOTE: use 'sbslabdb <action> -h' to get more usage info\"\"\")\n        self.parser.add_argument(\n            \"-v\", \"--verbose\", dest=\"verbose\", action=\"count\", default=0,\n            help=\"Use verbose output (multiple for more verbosity)\"\n        )\n        self.parser.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n\n        actions = self.parser.add_subparsers(\n            help=\"Action to perform\", \n            dest=\"action\"\n        )\n\n        add_parser = actions.add_parser(\n            \"add\",\n            help=\"\"\"Add slab address to the list\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"XXX\"\"\"\n        )\n        add_parser.add_argument(\n            'cache', \n            help='slab cache (e.g. \"kmalloc-1k\")'\n        )\n        \n        add_parser.add_argument(\n            'address', \n            help='Chunk address to add'\n        )\n        \n        del_parser = actions.add_parser(\n            \"del\", \n            help=\"\"\"Delete slab address from the list\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"XXX\"\"\"\n        )\n        del_parser.add_argument(\n            'cache', \n            help='slab cache (e.g. \"kmalloc-1k\")'\n        )\n        del_parser.add_argument(\n            'address', \n            help='Chunk address to remove'\n        )\n        \n        list_parser = actions.add_parser(\n            \"list\", \n            help=\"\"\"List all the slab addresses from the list (debugging)\"\"\",\n            formatter_class=argparse.RawTextHelpFormatter,\n            epilog=\"\"\"XXX\"\"\"\n        )\n\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n        # allows to save the slab db to file during development/debugging\n        self.parser.add_argument(\n            \"-S\", \"--save-db\", dest=\"save\", action=\"store_true\", default=False,\n            help=argparse.SUPPRESS\n        )\n        # allows to load the slab db from file during development/debugging\n        self.parser.add_argument(\n            \"-L\", \"--load-db\", dest=\"load\", action=\"store_true\", default=False,\n            help=argparse.SUPPRESS\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbslabdb.invoke()\")\n\n        if self.args.action is None and not self.args.save and not self.args.load:\n            pu.print_error(\"WARNING: requires an action\")\n            self.parser.print_help()\n            return\n \n        if self.args.action == \"list\":\n            for cache_name, d in slab_db.items():\n                print(f\"slab cache: {cache_name}\")\n                for slab_addr, L in d.items():\n                    print(f\"\\tslab @ {slab_addr:#x}\")\n                    for addr in L:\n                        print(f\"\\t\\t- {addr:#x}\")\n            return\n\n        if self.args.save:\n            if self.args.verbose >= 0: # always print since debugging feature\n                print(\"Saving slabs database to file...\")\n            save_slab_db_to_file(SLAB_DB)\n            return\n\n        if self.args.load:\n            if self.args.verbose >= 0: # always print since debugging feature\n                print(\"Loading slabs database from file...\")\n            load_slab_db_from_file(SLAB_DB)\n            return\n\n        address = None\n        if self.args.address != None:\n            addresses = self.dbg.parse_address(self.args.address)\n            if len(addresses) == 0:\n                pu.print_error(\"WARNING: No valid address supplied\")\n                self.parser.print_help()\n                return\n            address = addresses[0]\n\n        if not self.args.cache:\n            pu.print_error(\"WARNING: No valid cache name supplied\")\n            self.parser.print_help()\n            return\n\n        if self.args.action == \"del\":\n            if self.args.cache not in slab_db.keys():\n                log.debug(f\"Warning: tried to remove from non-tracked cache: {self.args.cache}\")\n                return\n            slab_addr = self.get_slab_address2(address, self.args.cache)\n            if not slab_addr:\n                log.debug(f\"Warning: tried to remove chunk address: {address:#x} from non-existing slab in cache: {self.args.cache}\")\n                return\n            if slab_addr not in slab_db[self.args.cache].keys():\n                log.debug(f\"Warning: tried to remove chunk address: {address:#x} from non-tracked slab in cache: {self.args.cache}\")\n                return\n            if address not in slab_db[self.args.cache][slab_addr]:\n                log.debug(f\"Warning: tried to remove non-existing chunk address: {address:#x} from slab address: {slab_addr:#x} in cache: {self.args.cache}\")\n                return\n            slab_db[self.args.cache][slab_addr].remove(address)\n            if len(slab_db[self.args.cache][slab_addr]) == 0:\n                del slab_db[self.args.cache][slab_addr]\n            return\n\n        if self.args.action == \"add\":\n            if self.args.cache not in slab_db.keys():\n                slab_db[self.args.cache] = {}\n            slab_addr = self.get_slab_address2(address, self.args.cache)\n            if not slab_addr:\n                log.debug(f\"Warning: tried to add chunk address: {address:#x} from non-existing slab in cache: {self.args.cache}\")\n                return\n            if slab_addr not in slab_db[self.args.cache].keys():\n                slab_db[self.args.cache][slab_addr] = set([])\n            if address in slab_db[self.args.cache][slab_addr]:\n                log.debug(f\"Warning: tried to add existing chunk address: {address:#x} to slab @ {slab_addr:#x} and cache: {self.args.cache}\")\n            else:\n                slab_db[self.args.cache][slab_addr].add(address)\n            return\n\n    def get_slab_address2(self, chunk_addr, cache_name):\n        global cached_info\n\n        # Check our local cache first\n        log.debug(\"Checking\")\n        if cache_name in cached_info.keys():\n            for page_addr, (region_start, region_end) in cached_info[cache_name].items():\n                if chunk_addr >= region_start and chunk_addr < region_end:\n                    return page_addr\n\n        # Not found in our cache, so query structures and memory to update our cache\n        log.debug(\"Updating cache\")\n        cached_info[cache_name] = self.sb.get_slab_cache_memory_pages_ranges(name=self.args.cache, dict_enabled=True)\n        \n        # And check again\n        log.debug(\"Checking again\")\n        for page_addr, (region_start, region_end) in cached_info[cache_name].items():\n            if chunk_addr >= region_start and chunk_addr < region_end:\n                return page_addr\n\n        log.debug(\"Not found\")\n        return None"]}
{"filename": "libslub/frontend/commands/gdb/__init__.py", "chunked_list": [""]}
{"filename": "libslub/frontend/commands/gdb/sblist.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport struct\nimport sys\nimport logging\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu", "\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n", "#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sblist.py\")\n\nclass sblist(sbcmd.sbcmd):\n    \"\"\"Command to show information about all the slab caches on the system\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sblist.__init__()\")\n        super(sblist, self).__init__(sb, \"sblist\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Show information about all the slab caches on the system\n\nEquivalent to \"cat /proc/slabinfo\" in userland.\"\"\", \n            add_help=False,\n            formatter_class=argparse.RawTextHelpFormatter,\n        )\n        self.parser.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n        self.parser.add_argument(\n            \"-p\",\n            dest=\"pattern\",\n            default=None,\n            help=\"Only show caches that contain that pattern\",\n        )\n        self.parser.add_argument(\n            \"-k\",\n            dest=\"kmalloc\",\n            default=False,\n            action=\"store_true\",\n            help=\"Only show most usual caches (kmalloc-8, ... kmalloc-8k)\",\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sblist.invoke()\")\n        \n        page_type = gdb.lookup_type(\"struct page\")\n\n        print(\"name                    objs inuse slabs size obj_size objs_per_slab pages_per_slab\")\n        \n        # Each slab_cache is a dictionary matching the kmem_cache structure of the current slab cache\n        # struct kmem_cache {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/slub_def.h#L90\n        for slab_cache in sb.sb.iter_slab_caches():\n            \n            name = slab_cache[\"name\"].string() # Name (only for display!)\n            \n            # skip if don't want to see them all\n            if self.args.pattern and self.args.pattern not in name:\n                continue\n            if self.args.kmalloc and name not in sb.sb.kmalloc_caches:\n                continue\n            \n            size = int(slab_cache[\"size\"]) # The size of an object including metadata\n            obj_size = int(slab_cache[\"object_size\"]) # The size of an object without metadata\n            cnt_objs, cnt_inuse, cnt_slabs = 0, 0, 0\n\n            # Get the gdb.Value representing the current kmem_cache_cpu\n            cpu_cache = self.sb.get_current_slab_cache_cpu(slab_cache)\n            \n            # kmem_cache_cpu->page == The slab from which we are allocating\n            # struct page {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/mm_types.h#L70\n            if cpu_cache[\"page\"]: \n                cnt_objs = cnt_inuse = int(cpu_cache[\"page\"][\"objects\"]) & self.sb.UNSIGNED_INT\n                # kmem_cache_cpu->freelist == Pointer to next available object\n                if cpu_cache[\"freelist\"]:\n                    cnt_inuse -= len(\n                        list(sb.sb.walk_freelist(slab_cache, cpu_cache[\"freelist\"]))\n                    )\n                cnt_slabs += 1\n\n            # kmem_cache_cpu->partial == Partially allocated frozen slabs\n            # struct page {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/mm_types.h#L70\n            if cpu_cache[\"partial\"]:\n                slab = cpu_cache[\"partial\"]\n                while slab:\n                    cnt_objs += int(slab[\"objects\"]) & self.sb.UNSIGNED_INT # number of chunks in that slab\n                    cnt_inuse += int(slab[\"inuse\"]) & self.sb.UNSIGNED_INT # number of allocated chunks in that slab\n                    cnt_slabs += 1\n                    slab = slab.dereference()[\"next\"] # next partial slab\n\n            # kmem_cache->node == The slab lists for all objects\n            # struct kmem_cache_node {: https://elixir.bootlin.com/linux/v5.15/source/mm/slab.h#L533\n            node_cache = slab_cache[\"node\"].dereference().dereference()\n            for slab in self.sb.for_each_entry(page_type, node_cache[\"partial\"], \"lru\"):\n                cnt_objs += int(slab[\"objects\"]) & self.sb.UNSIGNED_INT\n                cnt_inuse += int(slab[\"inuse\"]) & self.sb.UNSIGNED_INT\n                cnt_slabs += 1\n\n            # Word size structure that can be atomically updated or read and that\n            # contains both the order and the number of objects that a slab of the\n            # given order would contain.\n            # struct kmem_cache_order_objects {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/slub_def.h#L83\n            oo = slab_cache[\"oo\"][\"x\"]\n            # https://elixir.bootlin.com/linux/v5.15/source/mm/slub.c#L412 and https://elixir.bootlin.com/linux/v5.15/source/mm/slub.c#L252\n            objs_per_slab = oo & ((1 << 16) - 1)\n            # https://elixir.bootlin.com/linux/v5.15/source/mm/slub.c#L407 and https://elixir.bootlin.com/linux/v5.15/source/mm/slub.c#L251\n            pages_per_slab = 2 ** (oo >> 16)\n\n            print(\n                \"%-23s %4d %5d %5d %4d %8d %13d %14d\"\n                % (\n                    name,\n                    cnt_objs,\n                    cnt_inuse,\n                    cnt_slabs,\n                    size,\n                    obj_size,\n                    objs_per_slab,\n                    pages_per_slab,\n                )\n            )\n\n        # XXX - could be displayed only if we use -v\n        print(\"\")\n        print(\"name: slab cache name used for display\")\n        print(\"objs: total number of chunks in that slab cache\")\n        print(\"inuse: number of allocated chunks in that slab cache\")\n        print(\"slabs: number of slabs allocated for that slab cache\")\n        print(\"size: chunk size (with metadata)\")\n        print(\"obj_size: object size (without metadata)\")\n        print(\"objs_per_slab: number of objects per slab\")\n        print(\"pages_per_slab: number of pages per slab\")", "        "]}
{"filename": "libslub/frontend/commands/gdb/sbwatch.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport struct\nimport sys\nimport logging\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu", "\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n", "#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbwatch.py\")\n\nclass sbwatch(sbcmd.sbcmd):\n    \"\"\"Command to start/stop watching full-slabs for a slab cache\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbwatch.__init__()\")\n        super(sbwatch, self).__init__(sb, \"sbwatch\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Start/stop watching full-slabs for a slab cache\n\nSetup break points for the specified slab names\n\nIt is recommended to enable it when analyzing objects allocated/freed.\n\nThis is required in order to be able to list objects allocated in full slabs \nsince otherwise the SLUB allocator won't know them until they are not in a \nfull-slabs anymore\"\"\",\n            add_help=False,\n            formatter_class=argparse.RawTextHelpFormatter,\n        )\n        self.parser.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n\n        self.parser.add_argument(\n            \"names\", nargs=\"*\", default=[],\n            help=\"Slab names (e.g. 'kmalloc-1k')\"\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbwatch.invoke()\")\n\n        for name in self.args.names:\n            slab_cache = sb.sb.find_slab_cache(name)\n            if slab_cache is None:\n                print(\"Slab cache '%s' not found\" % name)\n                return\n\n            if name in self.sb.watch_caches:\n                print(\"Stopped watching slab cache '%s'\" % name)\n                self.sb.watch_caches.remove(name)\n            else:\n                print(\"Started watching slab cache '%s'\" % name)\n                self.sb.watch_caches.append(name)\n            self.sb.breakpoints.update_breakpoints()"]}
{"filename": "libslub/frontend/commands/gdb/sbtrace.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport struct\nimport sys\nimport logging\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu", "\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n", "#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbtrace.py\")\n\nclass sbtrace(sbcmd.sbcmd):\n    \"\"\"Command to start/stop tracing object allocations for a slab cache\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbtrace.__init__()\")\n        super(sbtrace, self).__init__(sb, \"sbtrace\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Start/stop tracing object allocations for a slab cache\n\nSetup break points for the specified slab names\"\"\", \n            add_help=False,\n            formatter_class=argparse.RawTextHelpFormatter,\n        )\n        self.parser.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n\n        self.parser.add_argument(\n            \"names\", nargs=\"*\", default=[],\n            help=\"Slab names (e.g. 'kmalloc-1k')\"\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbtrace.invoke()\")\n\n        for name in self.args.names:\n            slab_cache = sb.sb.find_slab_cache(name)\n            if slab_cache is None:\n                print(\"Slab cache '%s' not found\" % name)\n                return\n\n            if name in self.sb.trace_caches:\n                print(\"Stopped tracing slab cache '%s'\" % name)\n                self.sb.trace_caches.remove(name)\n            else:\n                print(\"Started tracing slab cache '%s'\" % name)\n                self.sb.trace_caches.append(name)\n            self.sb.breakpoints.update_breakpoints()"]}
{"filename": "libslub/frontend/commands/gdb/sbcrosscache.py", "chunked_list": ["from __future__ import print_function\n\nimport argparse\nimport struct\nimport sys\nimport logging\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu", "\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.commands.gdb.sbcmd as sbcmd\n#importlib.reload(sbcmd)\n", "#importlib.reload(sbcmd)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbcrosscache.py\")\n\nclass sbcrosscache(sbcmd.sbcmd):\n    \"\"\"Command to identify adjacent memory regions from two different slabs\"\"\"\n\n    def __init__(self, sb):\n        log.debug(\"sbcrosscache.__init__()\")\n        super(sbcrosscache, self).__init__(sb, \"sbcrosscache\")\n\n        self.parser = argparse.ArgumentParser(\n            description=\"\"\"Identify adjacent memory regions from two different slabs\n\nThis is particularly useful when you want to do cross cache attacks.\"\"\", \n            add_help=False,\n            formatter_class=argparse.RawTextHelpFormatter,\n        )\n        self.parser.add_argument(\n            \"-h\", \"--help\", dest=\"help\", action=\"store_true\", default=False,\n            help=\"Show this help\"\n        )\n        # allows to enable a different log level during development/debugging\n        self.parser.add_argument(\n            \"--loglevel\", dest=\"loglevel\", default=None,\n            help=argparse.SUPPRESS\n        )\n\n        self.parser.add_argument(\n            \"slab_cache_a\", default=None,\n            help=\"First slab cache name (e.g. 'kmalloc-64')\"\n        )\n\n        self.parser.add_argument(\n            \"slab_cache_b\", default=None,\n            help=\"Second slab cache name (e.g. 'kmalloc-96')\"\n        )\n\n    @h.catch_exceptions\n    @sbcmd.sbcmd.init_and_cleanup\n    def invoke(self, arg, from_tty):\n        \"\"\"Inherited from gdb.Command\n        See https://sourceware.org/gdb/current/onlinedocs/gdb/Commands-In-Python.html\n        \"\"\"\n\n        log.debug(\"sbcrosscache.invoke()\")\n\n        slab_cache_a = self.args.slab_cache_a\n        slab_cache_b = self.args.slab_cache_b\n\n        a = sb.sb.find_slab_cache(slab_cache_a)\n        if a is None:\n            print(\"Slab cache '%s' not found\" % slab_cache_a)\n            return\n\n        b = sb.sb.find_slab_cache(slab_cache_b)\n        if a is None:\n            print(\"Slab cache '%s' not found\" % slab_cache_b)\n            return\n\n        a_pages = self.sb.get_slab_cache_memory_pages(a)\n        b_pages = self.sb.get_slab_cache_memory_pages(b)\n\n        a_pages.sort()\n        b_pages.sort()\n\n        for a_page in a_pages:\n            if a_page < b_pages[0] - 4096 or a_page > b_pages[-1] + 4096:\n                continue\n            first = True\n            for b_page in b_pages:\n                if a_page == b_page - 4096:\n                    if first:\n                        print(\"---\")\n                        first = False\n                        print(f\"0x{a_page:08x} - {slab_cache_a}\")\n                    print(f\"0x{b_page:08x} - {slab_cache_b}\")\n                elif a_page == b_page + 4096:\n                    if first:\n                        print(\"---\")\n                        first = False\n                    print(f\"0x{b_page:08x} - {slab_cache_b}\")\n                    print(f\"0x{a_page:08x} - {slab_cache_a}\")\n            pass"]}
{"filename": "libslub/frontend/breakpoints/__init__.py", "chunked_list": [""]}
{"filename": "libslub/frontend/breakpoints/gdb/slab_free.py", "chunked_list": ["import argparse\nimport struct\nimport sys\nimport traceback\nimport gdb\nimport shlex\nimport importlib\nimport logging\nfrom functools import wraps, lru_cache\n", "from functools import wraps, lru_cache\n\nimport libslub.frontend.helpers2 as h2\nimportlib.reload(h2)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(f\"slab_free.py\")\n\nclass DiscardSlab(gdb.Breakpoint):\n    \"\"\"Track slab destructions/frees\n    \"\"\"\n    def __init__(self, sb):\n        h2.clear_existing_breakpoints(\"discard_slab\")\n        super(DiscardSlab, self).__init__(\"discard_slab\", internal=sb.bps_hidden)\n        self.sb = sb\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        name = slab_cache[\"name\"].string()\n        page = gdb.selected_frame().read_var(\"page\")\n        addr = int(page) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_slab_free(name, addr)\n        return False # continue execution", "log.trace(f\"slab_free.py\")\n\nclass DiscardSlab(gdb.Breakpoint):\n    \"\"\"Track slab destructions/frees\n    \"\"\"\n    def __init__(self, sb):\n        h2.clear_existing_breakpoints(\"discard_slab\")\n        super(DiscardSlab, self).__init__(\"discard_slab\", internal=sb.bps_hidden)\n        self.sb = sb\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        name = slab_cache[\"name\"].string()\n        page = gdb.selected_frame().read_var(\"page\")\n        addr = int(page) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_slab_free(name, addr)\n        return False # continue execution"]}
{"filename": "libslub/frontend/breakpoints/gdb/breakpoints.py", "chunked_list": ["import argparse\nimport struct\nimport sys\nimport traceback\nimport gdb\nimport shlex\nimport importlib\nimport logging\nfrom functools import wraps, lru_cache\n", "from functools import wraps, lru_cache\n\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\nimport libslub.frontend.helpers2 as h2\nimportlib.reload(h2)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.breakpoints.gdb.slab_alloc as slab_alloc\nimportlib.reload(slab_alloc)", "import libslub.frontend.breakpoints.gdb.slab_alloc as slab_alloc\nimportlib.reload(slab_alloc)\nimport libslub.frontend.breakpoints.gdb.slab_free as slab_free\nimportlib.reload(slab_free)\nimport libslub.frontend.breakpoints.gdb.obj_alloc as obj_alloc\nimportlib.reload(obj_alloc)\nimport libslub.frontend.breakpoints.gdb.obj_free as obj_free\nimportlib.reload(obj_free)\n\nlog = logging.getLogger(\"libslub\")", "\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"breakpoints.py\")\n\nclass breakpoints:\n\n    def __init__(self, sb):\n        \"\"\"\n        Holds all the breakpoints that are useful to trace/log SLUB allocator internal behaviours\n        such as when a new slab is created or when objects are allocated on a given slab\n        \"\"\"\n        log.debug(\"breakpoints.__init__()\")\n\n        self.sb = sb\n\n        # XXX - Some breakpoints do not work well in some environments\n        # or crash gdb so enable the ones that work for you :)\n\n        #self.obj_alloc_bp = obj_alloc.KmemCacheAlloc(self.sb)\n        self.obj_alloc_bp = obj_alloc.KmemCacheAllocReturned(self.sb)\n        \n        #self.obj_free_bp = obj_free.KmemCacheFree(self.sb)\n        self.obj_free_bp = obj_free.KmemCacheFreeReturned(self.sb)\n        \n        #self.slab_alloc_bp = slab_alloc.NewSlab(self)\n        #self.slab_alloc_bp = slab_alloc.AllocateSlab(self.sb)\n        self.slab_alloc_bp = slab_alloc.AllocateSlabReturned(self.sb)\n        \n        self.slab_free_bp = slab_free.DiscardSlab(self.sb)\n\n        self.update_breakpoints()\n\n    def update_breakpoints(self):\n        enabled = bool(self.sb.trace_caches) or bool(self.sb.break_caches)\n        self.obj_alloc_bp.enabled = enabled\n        self.obj_free_bp.enabled = enabled\n\n        enabled = bool(self.sb.watch_caches)\n        self.slab_alloc_bp.enabled = enabled\n        self.slab_free_bp.enabled = enabled"]}
{"filename": "libslub/frontend/breakpoints/gdb/__init__.py", "chunked_list": [""]}
{"filename": "libslub/frontend/breakpoints/gdb/obj_free.py", "chunked_list": ["import argparse\nimport struct\nimport sys\nimport traceback\nimport gdb\nimport shlex\nimport importlib\nimport logging\nfrom functools import wraps, lru_cache\n", "from functools import wraps, lru_cache\n\nimport libslub.frontend.helpers2 as h2\nimportlib.reload(h2)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(f\"obj_free.py\")\n\nclass KmemCacheFreeFinish(gdb.FinishBreakpoint):\n    \"\"\"Method 1 to track object frees on a given slab associated with a slab cache\n\n    See KmemCacheFree()\n\n    NOTE: if gdb crashes when you use this FinishBreakpoint, you may want\n    to use the normal Breakpoint in Method 2 below instead\n    \"\"\"\n    def __init__(self, sb, name, addr):\n        frame = gdb.newest_frame().older()\n        super(KmemCacheFreeFinish, self).__init__(frame, internal=sb.bps_hidden)\n        self.sb = sb\n        self.name = name\n        self.addr = addr\n\n    def stop(self):\n        self.sb.notify_obj_free(self.name, self.addr)\n        if self.name in self.sb.break_caches:\n            return True\n        return False # continue execution", "log.trace(f\"obj_free.py\")\n\nclass KmemCacheFreeFinish(gdb.FinishBreakpoint):\n    \"\"\"Method 1 to track object frees on a given slab associated with a slab cache\n\n    See KmemCacheFree()\n\n    NOTE: if gdb crashes when you use this FinishBreakpoint, you may want\n    to use the normal Breakpoint in Method 2 below instead\n    \"\"\"\n    def __init__(self, sb, name, addr):\n        frame = gdb.newest_frame().older()\n        super(KmemCacheFreeFinish, self).__init__(frame, internal=sb.bps_hidden)\n        self.sb = sb\n        self.name = name\n        self.addr = addr\n\n    def stop(self):\n        self.sb.notify_obj_free(self.name, self.addr)\n        if self.name in self.sb.break_caches:\n            return True\n        return False # continue execution", "\nclass KmemCacheFree(gdb.Breakpoint):\n    \"\"\"Method 1 to track object frees on a given slab associated with a slab cache\n    \n    An invisible breakpoint for intercepting kmem_cache_free calls\n    \"\"\"\n    def __init__(self, sb):\n        h2.clear_existing_breakpoints(\"kmem_cache_free\")\n        super(KmemCacheFree, self).__init__(\"kmem_cache_free\", internal=sb.bps_hidden)\n        self.sb = sb\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        name = slab_cache[\"name\"].string()\n        x = gdb.selected_frame().read_var(\"x\")\n        addr = int(x) & sb.sb.UNSIGNED_LONG\n        if name in self.sb.trace_caches or name in self.sb.break_caches:\n            KmemCacheFreeFinish(self.sb, name, addr)", "\nclass KmemCacheFreeReturned(gdb.Breakpoint):\n    \"\"\"Method 2 to track object frees on a given slab associated with a slab cache\"\"\"\n    def __init__(self, sb):\n        # ubuntu 22.04 - kernel 5.15.0-27\n        bp_address = \"mm/slub.c:3509\"\n        h2.clear_existing_breakpoints(bp_address)\n        super(KmemCacheFreeReturned, self).__init__(bp_address, internal=sb.bps_hidden)\n        self.sb = sb\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        name = slab_cache[\"name\"].string()\n        x = gdb.selected_frame().read_var(\"x\")\n        addr = int(x) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_obj_free(name, addr)\n        if self.name in self.sb.break_caches:\n            return True\n        return False # continue execution"]}
{"filename": "libslub/frontend/breakpoints/gdb/slab_alloc.py", "chunked_list": ["import argparse\nimport struct\nimport sys\nimport traceback\nimport gdb\nimport shlex\nimport importlib\nimport logging\nfrom functools import wraps, lru_cache\n", "from functools import wraps, lru_cache\n\nimport libslub.frontend.helpers2 as h2\nimportlib.reload(h2)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(f\"slab_alloc.py\")\n", "log.trace(f\"slab_alloc.py\")\n\n# You may have to choose which method works best for your environment\n#\n# allocate_slab() is the function we are interested to track since it returns the struct page*\n# for the newly allocated slab\n#\n# The following call trace exists:\n# __slab_alloc()                  - return address of new_slab() hooked in method 3\n#    |- new_slab()                - hooked + finish by method 1", "# __slab_alloc()                  - return address of new_slab() hooked in method 3\n#    |- new_slab()                - hooked + finish by method 1\n#       |- allocate_slab()        - hooked + finish by method 2\n\nclass NewSlabFinish(gdb.FinishBreakpoint):\n    \"\"\"Method 1 to track slab allocations\n\n    See NewSlab()\n\n    NOTE: if gdb crashes when you use this FinishBreakpoint, you may want\n    to use the normal Breakpoint in Method 3 below instead\n    \"\"\"\n    def __init__(self, sb, name):\n        frame = gdb.newest_frame().older()\n        super(NewSlabFinish, self).__init__(frame, internal=sb.bps_hidden)\n        self.sb = sb\n        self.name = name\n\n    def stop(self):\n        # self.return_value is only valid for functions with debug symbols\n        # enabled... which doesn't seem to work for this function in stock\n        # Ubuntu for instance.\n        addr = int(self.return_value) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_slab_alloc(self.name, addr)\n        return False # continue execution", "\nclass NewSlab(gdb.Breakpoint):\n    \"\"\"Method 1 to track slab allocations\"\"\"\n    def __init__(self, sb):\n        h2.clear_existing_breakpoints(\"new_slab\")\n        super(NewSlab, self).__init__(\"new_slab\", internal=sb.bps_hidden)\n        self.sb = sb\n\n        # This register is used to read the slab_cache variable in the event\n        # that this symbol is optimized out by the compiler... this is normally\n        # the first argument to the function so it should be in rdi, but it may\n        # change...\n        # XXX - add ARM support\n        self.register = \"rdi\"\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        if str(slab_cache) == \"<optimized out>\":\n            kmem_cache = gdb.lookup_type(\"struct kmem_cache\")\n            # print(\"Found slab at: 0x%x\" % entry)\n            slab_cache_addr = gdb.selected_frame().read_register(self.register)\n            entry = gdb.Value(slab_cache_addr)\n            slab_cache = entry.cast(kmem_cache.pointer())\n        name = slab_cache[\"name\"].string()\n        if name in self.sb.watch_caches:\n            NewSlabFinish(self.sb, name)\n        return False # continue execution", "\nclass NewSlabFinish(gdb.FinishBreakpoint):\n    \"\"\"Method 2 to track slab allocations\n\n    See AllocateSlab()\n\n    NOTE: if gdb crashes when you use this FinishBreakpoint, you may want\n    to use the normal Breakpoint in Method 3 below instead\n    \"\"\"\n    \n    def __init__(self, sb, name):\n        # frame = gdb.newest_frame()\n        frame = gdb.newest_frame().older()\n        super(NewSlabFinish, self).__init__(frame, internal=sb.bps_hidden)\n        self.sb = sb\n        self.name = name\n\n    def stop(self):\n        print(\"NewSlabFinish.stop()\")\n        addr = int(self.return_value) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_slab_alloc(self.name, addr)\n        return False # continue execution", "\n# This function works more reliably on Ubuntu\n# XXX - if we assume the gdb session has lx tools we could parse lx-version to\n# try to work some of it out....\nclass AllocateSlab(gdb.Breakpoint):\n    \"\"\"Method 2 to track slab allocations\"\"\"\n    def __init__(self, sb):\n        h2.clear_existing_breakpoints(\"allocate_slab\")\n        super(AllocateSlab, self).__init__(\"allocate_slab\", internal=sb.bps_hidden)\n        self.sb = sb\n\n        # This register is used to read the slab_cache variable in the event\n        # that this symbol is optimized out by the compiler... this is normally\n        # the first argument to the function so it should be in rdi, but it may\n        # change...\n        # XXX - add ARM support\n        self.register = \"rdi\"\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        if str(slab_cache) == \"<optimized out>\":\n            kmem_cache = gdb.lookup_type(\"struct kmem_cache\")\n            # print(\"Found slab at: 0x%x\" % entry)\n            slab_cache_addr = gdb.selected_frame().read_register(self.register)\n            entry = gdb.Value(slab_cache_addr)\n            slab_cache = entry.cast(kmem_cache.pointer())\n        name = slab_cache[\"name\"].string()\n        if name in self.sb.watch_caches:\n            NewSlabFinish(self.sb, name)\n        return False # continue execution", "\n# XXX - I am using this technique because the original seems to be broken, in\n# so far as the finish breakpoint never hits from inside python.\n# If you need to change this, find \"new_slab_objects()\" or \"___slab_alloc()\" \n# and look for the location where there is an assignment `page = new_slab()`. Ex:\n# ```\n# static inline void *new_slab_objects(struct kmem_cache *s, gfp_t flags,\n# int node, struct kmem_cache_cpu **pc)\n# {\n# void *freelist;", "# {\n# void *freelist;\n# struct kmem_cache_cpu *c = *pc;\n# struct page *page;\n#\n# WARN_ON_ONCE(s->ctor && (flags & __GFP_ZERO));\n#\n# freelist = get_partial(s, flags, node, c);\n#\n# if (freelist)", "#\n# if (freelist)\n# return freelist;\n#\n# page = new_slab(s, flags, node);\n# if (page) {                                           // breakpoint here\n# ```\nclass AllocateSlabReturned(gdb.Breakpoint):\n    \"\"\"Method 3 to track slab allocations\"\"\"\n    def __init__(self, sb):\n        log.debug(\"AllocateSlabReturned.__init__()\")\n        # ubuntu 21.10 - kernel 5.13.0-40\n        #bp_address = \"mm/slub.c:2603\"\n        # ubuntu 22.04 - kernel 5.15.0-27\n        bp_address = \"mm/slub.c:3002\"\n        h2.clear_existing_breakpoints(bp_address)\n        super(AllocateSlabReturned, self).__init__(bp_address, internal=sb.bps_hidden)\n        self.sb = sb\n\n    def stop(self):\n        log.debug(\"AllocateSlabReturned.stop()\")\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        name = slab_cache[\"name\"].string()\n        addr = gdb.selected_frame().read_var(\"page\")\n        addr = int(addr) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_slab_alloc(name, addr)\n        return False # continue execution"]}
{"filename": "libslub/frontend/breakpoints/gdb/obj_alloc.py", "chunked_list": ["import argparse\nimport struct\nimport sys\nimport traceback\nimport gdb\nimport shlex\nimport importlib\nimport logging\nfrom functools import wraps, lru_cache\n", "from functools import wraps, lru_cache\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(f\"obj_alloc.py\")\n\nimport libslub.frontend.helpers2 as h2\nimportlib.reload(h2)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\n\nclass KmemCacheAllocFinish(gdb.FinishBreakpoint):\n    \"\"\"Method 1 to track object allocations on a given slab associated with a slab cache\n\n    See KmemCacheAlloc()\n\n    NOTE: if gdb crashes when you use this FinishBreakpoint, you may want\n    to use the normal Breakpoint in Method 2 below instead\n    \"\"\"\n\n    def __init__(self, sb, name):\n        super(KmemCacheAllocFinish, self).__init__(internal=sb.bps_hidden)\n        self.sb = sb\n        self.name = name\n\n    def stop(self):\n        addr = int(self.return_value) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_obj_alloc(self.name, addr)\n        if self.name in self.sb.break_caches:\n            return True\n        return False # continue execution", "importlib.reload(sb)\n\nclass KmemCacheAllocFinish(gdb.FinishBreakpoint):\n    \"\"\"Method 1 to track object allocations on a given slab associated with a slab cache\n\n    See KmemCacheAlloc()\n\n    NOTE: if gdb crashes when you use this FinishBreakpoint, you may want\n    to use the normal Breakpoint in Method 2 below instead\n    \"\"\"\n\n    def __init__(self, sb, name):\n        super(KmemCacheAllocFinish, self).__init__(internal=sb.bps_hidden)\n        self.sb = sb\n        self.name = name\n\n    def stop(self):\n        addr = int(self.return_value) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_obj_alloc(self.name, addr)\n        if self.name in self.sb.break_caches:\n            return True\n        return False # continue execution", "\nclass KmemCacheAlloc(gdb.Breakpoint):\n    \"\"\"Method 1 to track object allocations on a given slab associated with a slab cache\n    \n    An invisible breakpoint for intercepting kmem_cache_alloc calls\n    \"\"\"\n\n    def __init__(self, command):\n        h2.clear_existing_breakpoints(\"kmem_cache_alloc\")\n        super(KmemCacheAlloc, self).__init__(\"kmem_cache_alloc\", internal=sb.bps_hidden)\n        self.sb = sb\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        try:\n            name = slab_cache[\"name\"].string()\n        except:\n            print(\"Warning: can't track object allocation\")\n            return False\n        if name in self.sb.trace_caches or name in self.sb.break_caches:\n            KmemCacheAllocFinish(self.sb, name)\n        return False # continue execution", "\n# void *kmem_cache_alloc(struct kmem_cache *s, gfp_t gfpflags)\n# {\n# \tvoid *ret = slab_alloc(s, gfpflags, _RET_IP_, s->object_size);\n#\n# \ttrace_kmem_cache_alloc(_RET_IP_, ret, s->object_size,           // breakpoint here\n# \t\t\t\ts->size, gfpflags);\n#\n# \treturn ret;\n# }\nclass KmemCacheAllocReturned(gdb.Breakpoint):\n    \"\"\"Method 2 to track object allocations on a given slab associated with a slab cache\"\"\"\n    def __init__(self, sb):\n        # ubuntu 22.04 - kernel 5.15.0-27\n        bp_address = \"mm/slub.c:3228\"\n        h2.clear_existing_breakpoints(bp_address)\n        super(KmemCacheAllocReturned, self).__init__(bp_address, internal=sb.bps_hidden)\n        self.sb = sb\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        name = slab_cache[\"name\"].string()\n        addr = gdb.selected_frame().read_var(\"ret\")\n        addr = int(addr) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_obj_alloc(name, addr)\n        if name in self.sb.break_caches:\n            return True\n        return False # continue execution", "# \treturn ret;\n# }\nclass KmemCacheAllocReturned(gdb.Breakpoint):\n    \"\"\"Method 2 to track object allocations on a given slab associated with a slab cache\"\"\"\n    def __init__(self, sb):\n        # ubuntu 22.04 - kernel 5.15.0-27\n        bp_address = \"mm/slub.c:3228\"\n        h2.clear_existing_breakpoints(bp_address)\n        super(KmemCacheAllocReturned, self).__init__(bp_address, internal=sb.bps_hidden)\n        self.sb = sb\n\n    def stop(self):\n        slab_cache = gdb.selected_frame().read_var(\"s\")\n        name = slab_cache[\"name\"].string()\n        addr = gdb.selected_frame().read_var(\"ret\")\n        addr = int(addr) & sb.sb.UNSIGNED_LONG\n        self.sb.notify_obj_alloc(name, addr)\n        if name in self.sb.break_caches:\n            return True\n        return False # continue execution"]}
{"filename": "libslub/slub/kmem_cache_cpu.py", "chunked_list": ["import struct\nimport sys\nimport importlib\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.heap_structure as hs\nimportlib.reload(hs)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)", "import libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.slub.page as p\nimportlib.reload(p)\nimport libslub.slub.obj as obj\nimportlib.reload(obj)\nimport libslub.frontend.commands.gdb.sbobject as sbobject\nimportlib.reload(sbobject)\n\n\nclass kmem_cache_cpu(hs.heap_structure):\n    \"\"\"python representation of a struct kmem_cache_cpu\n    \n    struct kmem_cache_cpu {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/slub_def.h#L48\n    \"\"\"\n\n    def __init__(self, sb, cpu_id, kmem_cache, value=None, address=None):\n        \"\"\"\n        Parse kmem_cache_cpu's data and initialize the kmem_cache_cpu object\n\n        :param sb: slab object holding all our useful info\n        :param value: gdb.Value of type kmem_cache_cpu with structure's content read from the debugger (represented by a dictionary)\n        :param address: address for a kmem_cache_cpu where to read the structure's content from the debugger (not supported yet)\n        \"\"\"\n\n        super(kmem_cache_cpu, self).__init__(sb)\n\n        # kmem_cache_cpu structure's fields can be looked up directly from the gdb.Value\n        self.value = value # gdb.Value representing the kmem_cache_cpu\n        self.kmem_cache = kmem_cache # kmem_cache object\n\n        self.init(cpu_id)\n\n    def init(self, cpu_id):\n\n        # our own abstraction fields\n        self.cpu_id = cpu_id # CPU index in the kmem_cache\n        self.address = int(self.value.address) & sb.sb.UNSIGNED_LONG\n        self.fp = int(self.value[\"freelist\"]) & sb.sb.UNSIGNED_LONG # freelist head address\n        freelist_addresses = list(sb.sb.walk_freelist(self.kmem_cache.value, self.fp)) # list of addresses\n        self.freelist = []\n        for address in freelist_addresses:\n            # we pass None as the page as it is not built yet but we'll update it after creating the main slab\n            o = obj.obj(self.sb, address, self.kmem_cache, self, None, None, inuse=False)\n            self.freelist.append(o)\n\n        # the slab from which we are allocating for that cpu core\n        self.main_slab = None\n        if self.value[\"page\"]:\n            self.main_slab = p.page(self.sb, self.kmem_cache, self, None, sb.SlabType.MAIN_SLAB, value=self.value[\"page\"].dereference(), is_main_slab=True)\n\n        # update the main freelist's objects \"page\"\n        for o in self.freelist:\n            o.page = self.main_slab\n\n        # the partial slabs\n        self.partial_slabs = []\n        slab_ptr = self.value[\"partial\"]\n        slab_count = 0\n        while slab_ptr:\n            slab_count += 1\n            slab = slab_ptr.dereference()\n            slab_ptr = slab[\"next\"]\n        slab_index = 1\n        slab_ptr = self.value[\"partial\"]\n        while slab_ptr:\n            slab = slab_ptr.dereference()\n            partial_slab = p.page(self.sb, self.kmem_cache, self, None, sb.SlabType.PARTIAL_SLAB, index=slab_index, count=slab_count, value=slab)\n            self.partial_slabs.append(partial_slab)\n            slab_ptr = slab[\"next\"]\n            slab_index += 1\n\n    def print(self, verbose=0, use_cache=False, indent=0, cmd=None):\n        \"\"\"Pretty printer for the kmem_cache_cpu supporting different level of verbosity\n\n        :param verbose: 0 for non-verbose. 1 for more verbose. 2 for even more verbose.\n        :param use_cache: True if we want to use the cached information from the cache object.\n                          False if we want to fetch the data again\n        :param cmd: cmd.args == arguments so we know what options have been passed by the user\n                     e.g. to print hexdump of objects/chunks, highlight chunks, etc.\n        \"\"\"\n\n        if cmd.args.object_only is not True:\n            txt = \" \"*indent\n            title = \"struct kmem_cache_cpu @ 0x%x (cpu %d) {\" % (self.address, self.cpu_id)\n            txt += pu.color_title(title)\n            txt += \"\\n\"\n            print(txt, end=\"\")\n\n        # print the objects in the the main freelist\n        # it only make sense if we want to show the main slab as are chunked from that main slab\n        if cmd.output_filtered is False or cmd.args.main_slab is True or cmd.args.show_lockless_freelist:\n            if cmd.args.object_only is not True:\n                txt = \"{:s}  {:8} = \".format(\" \"*indent, \"freelist\")\n                txt += pu.color_value(\"{:#x}\".format(self.fp))\n                txt += \" ({:#d} elements)\".format(len(self.freelist))\n                txt += \"\\n\"\n                print(txt, end=\"\")\n\n            if cmd.args.show_lockless_freelist:\n                if cmd.args.object_only is True and cmd.args.hide_title is False:\n                    txt = pu.color_value(\"{:s}  lockless freelist:\").format(\" \"*indent)\n                    txt += \"\\n\"\n                    print(txt, end=\"\")\n                # Prepare arguments for \"sbobject\" format\n                # i.e. the chunks to print are from the freelist\n\n                # The amount of printed addresses will be limited by \n                # parse_many()'s \"count\" argument\n                if cmd.args.count == None:\n                    count = len(self.freelist)\n                else:\n                    count = cmd.args.count\n\n                sbobject.sbobject.parse_many(\n                    self.freelist, \n                    0, \n                    cmd.sb, \n                    cmd.dbg, \n                    None, # count\n                    count, # count_handle\n                    cmd.args.search_depth,\n                    cmd.args.skip_header, \n                    cmd.args.hexdump_unit, \n                    cmd.args.search_value, \n                    cmd.args.search_type, \n                    cmd.args.match_only, \n                    cmd.args.print_offset, \n                    cmd.args.verbose, \n                    cmd.args.no_newline,\n                    cmd.args.debug, \n                    cmd.args.hexdump, \n                    cmd.args.maxbytes, \n                    cmd.args.metadata,\n                    highlight_types=cmd.highlight_types,\n                    highlight_addresses=cmd.highlight_addresses,\n                    highlight_metadata=cmd.highlight_metadata,\n                    highlight_only=cmd.args.highlight_only,\n                    commands=cmd.args.commands,\n                    use_cache=cmd.args.use_cache,\n                    address_offset=cmd.args.address_offset,\n                    name=cmd.args.name,\n                    indent=\" \"*(indent+4),\n                    is_freelist=True,\n                    object_info=cmd.args.object_info,\n                )\n\n        if cmd.output_filtered is False or cmd.args.main_slab is True:\n            self.main_slab.print(name=\"page\", indent=indent+2, cmd=cmd)\n        if cmd.output_filtered is False or cmd.args.partial_slab is True:\n            for partial_slab in self.partial_slabs:\n                partial_slab.print(name=\"partial\", indent=indent+2, cmd=cmd)", "\n\nclass kmem_cache_cpu(hs.heap_structure):\n    \"\"\"python representation of a struct kmem_cache_cpu\n    \n    struct kmem_cache_cpu {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/slub_def.h#L48\n    \"\"\"\n\n    def __init__(self, sb, cpu_id, kmem_cache, value=None, address=None):\n        \"\"\"\n        Parse kmem_cache_cpu's data and initialize the kmem_cache_cpu object\n\n        :param sb: slab object holding all our useful info\n        :param value: gdb.Value of type kmem_cache_cpu with structure's content read from the debugger (represented by a dictionary)\n        :param address: address for a kmem_cache_cpu where to read the structure's content from the debugger (not supported yet)\n        \"\"\"\n\n        super(kmem_cache_cpu, self).__init__(sb)\n\n        # kmem_cache_cpu structure's fields can be looked up directly from the gdb.Value\n        self.value = value # gdb.Value representing the kmem_cache_cpu\n        self.kmem_cache = kmem_cache # kmem_cache object\n\n        self.init(cpu_id)\n\n    def init(self, cpu_id):\n\n        # our own abstraction fields\n        self.cpu_id = cpu_id # CPU index in the kmem_cache\n        self.address = int(self.value.address) & sb.sb.UNSIGNED_LONG\n        self.fp = int(self.value[\"freelist\"]) & sb.sb.UNSIGNED_LONG # freelist head address\n        freelist_addresses = list(sb.sb.walk_freelist(self.kmem_cache.value, self.fp)) # list of addresses\n        self.freelist = []\n        for address in freelist_addresses:\n            # we pass None as the page as it is not built yet but we'll update it after creating the main slab\n            o = obj.obj(self.sb, address, self.kmem_cache, self, None, None, inuse=False)\n            self.freelist.append(o)\n\n        # the slab from which we are allocating for that cpu core\n        self.main_slab = None\n        if self.value[\"page\"]:\n            self.main_slab = p.page(self.sb, self.kmem_cache, self, None, sb.SlabType.MAIN_SLAB, value=self.value[\"page\"].dereference(), is_main_slab=True)\n\n        # update the main freelist's objects \"page\"\n        for o in self.freelist:\n            o.page = self.main_slab\n\n        # the partial slabs\n        self.partial_slabs = []\n        slab_ptr = self.value[\"partial\"]\n        slab_count = 0\n        while slab_ptr:\n            slab_count += 1\n            slab = slab_ptr.dereference()\n            slab_ptr = slab[\"next\"]\n        slab_index = 1\n        slab_ptr = self.value[\"partial\"]\n        while slab_ptr:\n            slab = slab_ptr.dereference()\n            partial_slab = p.page(self.sb, self.kmem_cache, self, None, sb.SlabType.PARTIAL_SLAB, index=slab_index, count=slab_count, value=slab)\n            self.partial_slabs.append(partial_slab)\n            slab_ptr = slab[\"next\"]\n            slab_index += 1\n\n    def print(self, verbose=0, use_cache=False, indent=0, cmd=None):\n        \"\"\"Pretty printer for the kmem_cache_cpu supporting different level of verbosity\n\n        :param verbose: 0 for non-verbose. 1 for more verbose. 2 for even more verbose.\n        :param use_cache: True if we want to use the cached information from the cache object.\n                          False if we want to fetch the data again\n        :param cmd: cmd.args == arguments so we know what options have been passed by the user\n                     e.g. to print hexdump of objects/chunks, highlight chunks, etc.\n        \"\"\"\n\n        if cmd.args.object_only is not True:\n            txt = \" \"*indent\n            title = \"struct kmem_cache_cpu @ 0x%x (cpu %d) {\" % (self.address, self.cpu_id)\n            txt += pu.color_title(title)\n            txt += \"\\n\"\n            print(txt, end=\"\")\n\n        # print the objects in the the main freelist\n        # it only make sense if we want to show the main slab as are chunked from that main slab\n        if cmd.output_filtered is False or cmd.args.main_slab is True or cmd.args.show_lockless_freelist:\n            if cmd.args.object_only is not True:\n                txt = \"{:s}  {:8} = \".format(\" \"*indent, \"freelist\")\n                txt += pu.color_value(\"{:#x}\".format(self.fp))\n                txt += \" ({:#d} elements)\".format(len(self.freelist))\n                txt += \"\\n\"\n                print(txt, end=\"\")\n\n            if cmd.args.show_lockless_freelist:\n                if cmd.args.object_only is True and cmd.args.hide_title is False:\n                    txt = pu.color_value(\"{:s}  lockless freelist:\").format(\" \"*indent)\n                    txt += \"\\n\"\n                    print(txt, end=\"\")\n                # Prepare arguments for \"sbobject\" format\n                # i.e. the chunks to print are from the freelist\n\n                # The amount of printed addresses will be limited by \n                # parse_many()'s \"count\" argument\n                if cmd.args.count == None:\n                    count = len(self.freelist)\n                else:\n                    count = cmd.args.count\n\n                sbobject.sbobject.parse_many(\n                    self.freelist, \n                    0, \n                    cmd.sb, \n                    cmd.dbg, \n                    None, # count\n                    count, # count_handle\n                    cmd.args.search_depth,\n                    cmd.args.skip_header, \n                    cmd.args.hexdump_unit, \n                    cmd.args.search_value, \n                    cmd.args.search_type, \n                    cmd.args.match_only, \n                    cmd.args.print_offset, \n                    cmd.args.verbose, \n                    cmd.args.no_newline,\n                    cmd.args.debug, \n                    cmd.args.hexdump, \n                    cmd.args.maxbytes, \n                    cmd.args.metadata,\n                    highlight_types=cmd.highlight_types,\n                    highlight_addresses=cmd.highlight_addresses,\n                    highlight_metadata=cmd.highlight_metadata,\n                    highlight_only=cmd.args.highlight_only,\n                    commands=cmd.args.commands,\n                    use_cache=cmd.args.use_cache,\n                    address_offset=cmd.args.address_offset,\n                    name=cmd.args.name,\n                    indent=\" \"*(indent+4),\n                    is_freelist=True,\n                    object_info=cmd.args.object_info,\n                )\n\n        if cmd.output_filtered is False or cmd.args.main_slab is True:\n            self.main_slab.print(name=\"page\", indent=indent+2, cmd=cmd)\n        if cmd.output_filtered is False or cmd.args.partial_slab is True:\n            for partial_slab in self.partial_slabs:\n                partial_slab.print(name=\"partial\", indent=indent+2, cmd=cmd)"]}
{"filename": "libslub/slub/obj.py", "chunked_list": ["from operator import index\nimport struct\nimport sys\nimport importlib\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.heap_structure as hs\nimportlib.reload(hs)\nimport libslub.slub.sb as sb", "importlib.reload(hs)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.slub.kmem_cache as kc\nimportlib.reload(kc)\n\nclass obj(hs.heap_structure):\n    \"\"\"python representation of a chunk/object\n    \n    This is not associated to any structure since the object is dependent on the actual data being manipulated\n    and not on the SLAB allocator but we track it here to ease manipulating them\n    \"\"\"\n\n    def __init__(self, sb, address, kmem_cache, kmem_cache_cpu, kmem_cache_node, page, inuse=None):\n        \"\"\"\n\n        :param sb: slab object holding all our useful info\n        :param address: chunk/object address\n        :param kmem_cache: kmem_cache Python object\n        :param kmem_cache_cpu: kmem_cache_cpu Python object\n        :param page: page Python object\n        :param inuse: True if we know it is inuse. False if we know it is in a freelist. None if we don't know.\n        \"\"\"\n\n        super(obj, self).__init__(sb)\n\n        self.kmem_cache = kmem_cache # kmem_cache Python object\n        self.kmem_cache_cpu = kmem_cache_cpu # kmem_cache_cpu Python object or None\n        self.kmem_cache_node = kmem_cache_node # kmem_cache_node Python object or None\n        self.page = page # page Python object\n        self.address = address # address of the chunk/object in memory\n\n        self.init(inuse)\n\n    def init(self, inuse):\n\n        # our own abstraction fields\n        self.size = self.kmem_cache.size\n        if inuse is None:\n            self.inuse = True\n            if self.page.is_main_slab:\n                cpu_freelist = self.kmem_cache_cpu.freelist\n            else:\n                cpu_freelist = [] # not applicable\n            for o in self.page.freelist:\n                if self.address == o.address:\n                    self.inuse = False\n                    break\n            if self.inuse is True:\n                for o in cpu_freelist:\n                    if self.address == o.address:\n                        self.inuse = False\n        else:\n            self.inuse = inuse\n\n    def __str__(self):\n        \"\"\"Pretty printer for the obj\n        \"\"\"\n        return self.to_string()\n\n    def to_string(self, name=\"\", verbose=0, use_cache=False, indent=0, colorize_func=str):\n        \"\"\"Pretty printer for the obj supporting different level of verbosity\n\n        :param verbose: 0 for non-verbose. 1 for more verbose. 2 for even more verbose.\n        :param use_cache: True if we want to use the cached information from the cache object.\n                          False if we want to fetch the data again\n        \"\"\"\n\n        txt = \"\"\n        if self.inuse:\n            t = \"M\"\n        else:\n            t = \"F\"\n        address = \"{:#x}\".format(self.address)\n        txt += \"{:s}{:s} {:s}\".format(\" \"*indent, colorize_func(address), t)\n        \n        return txt\n\n    def info(self, show_slab_cache=False):\n        txt = \"\"\n        if show_slab_cache:\n            txt += f\"{self.kmem_cache.name} \"\n        if self.kmem_cache_cpu is not None:\n            txt += f\"cpu{self.kmem_cache_cpu.cpu_id} \"\n            if self.page.type == sb.SlabType.MAIN_SLAB:\n                txt += \"main \"\n            elif self.page.type == sb.SlabType.PARTIAL_SLAB:\n                txt += \"partial \"\n        elif self.kmem_cache_node is not None:\n            txt += f\"node{self.kmem_cache_node.node_id} \"\n            if self.page.type == sb.SlabType.NODE_SLAB:\n                txt += f\"partial \"\n        else:\n            if self.page.type == sb.SlabType.FULL_SLAB:\n                txt += f\"full \"\n        if self.page.count != 0:\n            txt += f\"{self.page.index}/{self.page.count}\"\n        else:\n            txt = txt[:-1] # remove ending space\n        return txt\n\n    \n    @staticmethod\n    def indexof(address, list_objects):\n        \"\"\"Helper to quickly find if a given address is the start of a given chunk/object in a list of obj()\n\n        @param address: an integer address\n        @param list_objects: a list of obj()\n        @param the index of the obj() starting at address if found, or -1 if not found\n        \"\"\"\n        \n        for index, obj in enumerate(list_objects):\n            if address == obj.address:\n                return index\n        return -1\n        \n    @staticmethod\n    def is_object_address_in_slab_caches(kmem_caches, address):\n        \"\"\"Check if a given address is in one of the memory regions in a given slab cache or multiple slab caches\n        @param kmem_caches: a single kmem_cache Python object representing a slab cache or a list of them\n        @param address: address we want to check if it is a chunk/object in that slab cache\n        @param return a tuple (index, objects_list) where objects_list is the list of obj()\n               where the chunk/object address was found and index is the index in objects_list\n               where it was found. If it is not found, it returns None instead of the tuple\n        \"\"\"\n\n        if type(kmem_caches) == kc.kmem_cache:\n            kmem_caches = [kmem_caches]\n        elif type(kmem_caches) == list:\n            pass\n        else:\n            pu.print_error(\"Invalid kmem_caches type passed to is_object_address_in_slab_cache(), should not happen\")\n            return None\n\n        for kmem_cache in kmem_caches:\n            for kmem_cache_cpu in kmem_cache.kmem_cache_cpu_list:\n                main_slab = kmem_cache_cpu.main_slab\n                # sometimes, a cpu has no slab especially (e.g. with threadripper)\n                if main_slab != None:\n                    index = obj.indexof(address, main_slab.objects_list)\n                    if index >= 0:\n                        return index, main_slab.objects_list\n                for partial_slab in kmem_cache_cpu.partial_slabs:\n                    index = obj.indexof(address, partial_slab.objects_list)\n                    if index >= 0:\n                        return index, partial_slab.objects_list\n            for kmem_cache_node in kmem_cache.kmem_cache_node_list:\n                for partial_slab in kmem_cache_node.partial_slabs:\n                    index = obj.indexof(address, partial_slab.objects_list)\n                    if index >= 0:\n                        return index, partial_slab.objects_list\n            for full_slab in kmem_cache.full_slabs:\n                index = obj.indexof(address, full_slab.objects_list)\n                if index >= 0:\n                    return index, full_slab.objects_list\n        return None"]}
{"filename": "libslub/slub/page.py", "chunked_list": ["from operator import index\nimport struct\nimport sys\nimport importlib\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.heap_structure as hs\nimportlib.reload(hs)\nimport libslub.slub.sb as sb", "importlib.reload(hs)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.slub.obj as obj\nimportlib.reload(obj)\nimport libslub.frontend.commands.gdb.sbobject as sbobject\nimportlib.reload(sbobject)\n\nclass page(hs.heap_structure):\n    \"\"\"python representation of a struct page\n    \n    struct page {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/mm_types.h#L70\n    \"\"\"\n\n    def __init__(self, sb, kmem_cache, kmem_cache_cpu, kmem_cache_node, type, index=0, count=0, value=None, address=None, is_main_slab=False):\n        \"\"\"\n        Parse page's data and initialize the page object\n\n        :param sb: slab object holding all our useful info\n        :param value: gdb.Value of type page with structure's content read from the debugger (represented by a dictionary)\n        :param address: address for a page where to read the structure's content from the debugger (not supported yet)\n        \"\"\"\n\n        super(page, self).__init__(sb)\n\n        # page structure's fields can be looked up directly from the gdb.Value\n        self.value = value # gdb.Value representing the page\n        self.kmem_cache = kmem_cache # kmem_cache Python object\n        self.kmem_cache_cpu = kmem_cache_cpu # kmem_cache_cpu Python object or None\n        self.kmem_cache_node = kmem_cache_node # kmem_cache_node Python object or None\n        self.type = type   # SlabType enum representing the slab type\n\n        self.init(index, count, is_main_slab)\n\n    def init(self, index, count, is_main_slab):\n\n        # our own abstraction fields\n        self.address = int(self.value.address) & sb.sb.UNSIGNED_LONG\n        self.index = index # index in the slab linked list (struct page*)\n        self.count = count # count of slabs in the linked list (struct page*)\n        self.is_main_slab = is_main_slab # boolean to indicate if main slab associated with given cpu\n        self.objects = int(self.value[\"objects\"]) & sb.sb.UNSIGNED_INT\n        self.inuse = int(self.value[\"inuse\"]) & sb.sb.UNSIGNED_INT\n        self.frozen = int(self.value[\"frozen\"])\n        self.fp = int(self.value[\"freelist\"]) & sb.sb.UNSIGNED_LONG # freelist head address\n        kmem_cache_value = self.value[\"slab_cache\"].dereference() # gdb.Value representing the parent kmem_cache\n        \n        freelist_addresses = list(sb.sb.walk_freelist(kmem_cache_value, self.fp)) # list of addresses\n        self.freelist = []\n        for address in freelist_addresses:\n            o = obj.obj(self.sb, address, self.kmem_cache, self.kmem_cache_cpu, self.kmem_cache_node, self, inuse=False)\n            self.freelist.append(o)\n        \n        self.region_start = self.sb.page_addr(self.address)\n        self.region_end = self.region_start + self.objects*int(kmem_cache_value[\"size\"])\n        \n        object_addresses = list(sb.sb.walk_linear_memory_region(kmem_cache_value, self.value, self.region_start))\n        self.objects_list = []\n        for address in object_addresses:\n            found = False\n            # have unique obj() shared between freelist and objects_list\n\n            # is it the main slab and is the object in the main freelist\n            if self.is_main_slab:\n                for o in self.kmem_cache_cpu.freelist:\n                    if address == o.address:\n                        self.objects_list.append(o)\n                        found = True\n                        break\n            if found is True:\n                continue\n            # is the object tracked in the slab's free list?\n            try:\n                index = freelist_addresses.index(address)\n            except ValueError:\n                pass\n            else:\n                self.objects_list.append(self.freelist[index])\n                found = True\n            if found is True:\n                continue\n            # not in any freelist, so creating obj()\n            o = obj.obj(self.sb, address, self.kmem_cache, self.kmem_cache_cpu, self.kmem_cache_node, self, inuse=True)\n            self.objects_list.append(o)\n\n    def print(self, name=\"\", verbose=0, use_cache=False, indent=0, cmd=None):\n        \"\"\"Pretty printer for the page supporting different level of verbosity\n\n        :param verbose: 0 for non-verbose. 1 for more verbose. 2 for even more verbose.\n        :param use_cache: True if we want to use the cached information from the cache object.\n                          False if we want to fetch the data again\n        :param cmd: cmd.args == arguments so we know what options have been passed by the user\n                     e.g. to print hexdump of objects/chunks, highlight chunks, etc.\n        \"\"\"\n\n        if cmd.args.object_only is not True:\n            txt = \" \"*indent\n            if name:\n                txt += \"{:8} = \".format(name)\n            if self.is_main_slab:\n                title = \"struct page @ 0x%x {\" % (self.address)\n            else:\n                title = \"struct page @ 0x%x (%d/%d) {\" % (self.address, self.index, self.count)\n            txt += pu.color_title(title)\n            txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"objects\")\n            txt += pu.color_value(\"{:#d}\".format(self.objects))\n\n            if self.is_main_slab:\n                txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"inuse\")\n                txt += pu.color_value(\"{:#d}\".format(self.inuse))\n                # the inuse value is kind of a lie in this case\n                txt += \" (real = {:#d})\".format(self.inuse-len(self.kmem_cache_cpu.freelist))\n            else: # partial slab, full slab, etc.\n                txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"inuse\")\n                txt += pu.color_value(\"{:#d}\".format(self.inuse))\n            txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"frozen\")\n            txt += pu.color_value(\"{:#d}\".format(self.frozen))\n\n            txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"freelist\")\n            txt += pu.color_value(\"{:#x}\".format(self.fp))\n            txt += \" ({:#d} elements)\".format(len(self.freelist))\n            txt += \"\\n\"\n            print(txt, end=\"\")\n\n        if cmd.args.show_freelist:\n            if cmd.args.object_only is True and cmd.args.hide_title is False:\n                txt = pu.color_value(\"{:s}regular freelist:\").format(\" \"*indent)\n                txt += \"\\n\"\n                print(txt, end=\"\")\n            # print the objects in the the freelist\n\n            # Prepare arguments for \"sbobject\" format\n            # i.e. the chunks to print are from the freelist\n\n            # The amount of printed addresses will be limited by \n            # parse_many()'s \"count\" argument\n            if cmd.args.count == None:\n                count = len(self.freelist)\n            else:\n                count = cmd.args.count\n\n            sbobject.sbobject.parse_many(\n                self.freelist, \n                0, \n                cmd.sb, \n                cmd.dbg, \n                None, # count\n                count, # count_handle,\n                cmd.args.search_depth,\n                cmd.args.skip_header, \n                cmd.args.hexdump_unit, \n                cmd.args.search_value, \n                cmd.args.search_type, \n                cmd.args.match_only, \n                cmd.args.print_offset, \n                cmd.args.verbose, \n                cmd.args.no_newline,\n                cmd.args.debug, \n                cmd.args.hexdump, \n                cmd.args.maxbytes, \n                cmd.args.metadata,\n                highlight_types=cmd.highlight_types,\n                highlight_addresses=cmd.highlight_addresses,\n                highlight_metadata=cmd.highlight_metadata,\n                highlight_only=cmd.args.highlight_only,\n                commands=cmd.args.commands,\n                use_cache=cmd.args.use_cache,\n                address_offset=cmd.args.address_offset,\n                name=cmd.args.name,\n                indent=\" \"*(indent+4),\n                is_freelist=True,\n                object_info=cmd.args.object_info,\n            )\n\n        if cmd.args.object_only is not True:\n            txt = \"{:s}  region   @ {:#x}-{:#x}\".format(\" \"*indent, self.region_start, self.region_end)\n            txt += \" ({:#d} elements)\".format(len(self.objects_list))\n            txt += \"\\n\"\n            print(txt, end=\"\")\n\n        if cmd.args.show_region:\n            if cmd.args.object_only is True and cmd.args.hide_title is False:\n                txt = pu.color_value(\"{:s}  region:\").format(\" \"*indent)\n                txt += \"\\n\"\n                print(txt, end=\"\")\n            # print the linear objects in the the slab\n            if cmd.args.count == None:\n                count = len(self.objects_list)\n            else:\n                count = cmd.args.count\n\n            sbobject.sbobject.parse_many(\n                self.objects_list, \n                0, \n                cmd.sb, \n                cmd.dbg, \n                None, # count \n                count, # count_handle\n                cmd.args.search_depth,\n                cmd.args.skip_header, \n                cmd.args.hexdump_unit, \n                cmd.args.search_value, \n                cmd.args.search_type, \n                cmd.args.match_only, \n                cmd.args.print_offset, \n                cmd.args.verbose, \n                cmd.args.no_newline,\n                cmd.args.debug, \n                cmd.args.hexdump, \n                cmd.args.maxbytes, \n                cmd.args.metadata,\n                highlight_types=cmd.highlight_types,\n                highlight_addresses=cmd.highlight_addresses,\n                highlight_metadata=cmd.highlight_metadata,\n                highlight_only=cmd.args.highlight_only,\n                commands=cmd.args.commands,\n                use_cache=cmd.args.use_cache,\n                address_offset=cmd.args.address_offset,\n                name=cmd.args.name,\n                indent=\" \"*(indent+4),\n                is_region=True,\n                object_info=cmd.args.object_info,\n            )", "class page(hs.heap_structure):\n    \"\"\"python representation of a struct page\n    \n    struct page {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/mm_types.h#L70\n    \"\"\"\n\n    def __init__(self, sb, kmem_cache, kmem_cache_cpu, kmem_cache_node, type, index=0, count=0, value=None, address=None, is_main_slab=False):\n        \"\"\"\n        Parse page's data and initialize the page object\n\n        :param sb: slab object holding all our useful info\n        :param value: gdb.Value of type page with structure's content read from the debugger (represented by a dictionary)\n        :param address: address for a page where to read the structure's content from the debugger (not supported yet)\n        \"\"\"\n\n        super(page, self).__init__(sb)\n\n        # page structure's fields can be looked up directly from the gdb.Value\n        self.value = value # gdb.Value representing the page\n        self.kmem_cache = kmem_cache # kmem_cache Python object\n        self.kmem_cache_cpu = kmem_cache_cpu # kmem_cache_cpu Python object or None\n        self.kmem_cache_node = kmem_cache_node # kmem_cache_node Python object or None\n        self.type = type   # SlabType enum representing the slab type\n\n        self.init(index, count, is_main_slab)\n\n    def init(self, index, count, is_main_slab):\n\n        # our own abstraction fields\n        self.address = int(self.value.address) & sb.sb.UNSIGNED_LONG\n        self.index = index # index in the slab linked list (struct page*)\n        self.count = count # count of slabs in the linked list (struct page*)\n        self.is_main_slab = is_main_slab # boolean to indicate if main slab associated with given cpu\n        self.objects = int(self.value[\"objects\"]) & sb.sb.UNSIGNED_INT\n        self.inuse = int(self.value[\"inuse\"]) & sb.sb.UNSIGNED_INT\n        self.frozen = int(self.value[\"frozen\"])\n        self.fp = int(self.value[\"freelist\"]) & sb.sb.UNSIGNED_LONG # freelist head address\n        kmem_cache_value = self.value[\"slab_cache\"].dereference() # gdb.Value representing the parent kmem_cache\n        \n        freelist_addresses = list(sb.sb.walk_freelist(kmem_cache_value, self.fp)) # list of addresses\n        self.freelist = []\n        for address in freelist_addresses:\n            o = obj.obj(self.sb, address, self.kmem_cache, self.kmem_cache_cpu, self.kmem_cache_node, self, inuse=False)\n            self.freelist.append(o)\n        \n        self.region_start = self.sb.page_addr(self.address)\n        self.region_end = self.region_start + self.objects*int(kmem_cache_value[\"size\"])\n        \n        object_addresses = list(sb.sb.walk_linear_memory_region(kmem_cache_value, self.value, self.region_start))\n        self.objects_list = []\n        for address in object_addresses:\n            found = False\n            # have unique obj() shared between freelist and objects_list\n\n            # is it the main slab and is the object in the main freelist\n            if self.is_main_slab:\n                for o in self.kmem_cache_cpu.freelist:\n                    if address == o.address:\n                        self.objects_list.append(o)\n                        found = True\n                        break\n            if found is True:\n                continue\n            # is the object tracked in the slab's free list?\n            try:\n                index = freelist_addresses.index(address)\n            except ValueError:\n                pass\n            else:\n                self.objects_list.append(self.freelist[index])\n                found = True\n            if found is True:\n                continue\n            # not in any freelist, so creating obj()\n            o = obj.obj(self.sb, address, self.kmem_cache, self.kmem_cache_cpu, self.kmem_cache_node, self, inuse=True)\n            self.objects_list.append(o)\n\n    def print(self, name=\"\", verbose=0, use_cache=False, indent=0, cmd=None):\n        \"\"\"Pretty printer for the page supporting different level of verbosity\n\n        :param verbose: 0 for non-verbose. 1 for more verbose. 2 for even more verbose.\n        :param use_cache: True if we want to use the cached information from the cache object.\n                          False if we want to fetch the data again\n        :param cmd: cmd.args == arguments so we know what options have been passed by the user\n                     e.g. to print hexdump of objects/chunks, highlight chunks, etc.\n        \"\"\"\n\n        if cmd.args.object_only is not True:\n            txt = \" \"*indent\n            if name:\n                txt += \"{:8} = \".format(name)\n            if self.is_main_slab:\n                title = \"struct page @ 0x%x {\" % (self.address)\n            else:\n                title = \"struct page @ 0x%x (%d/%d) {\" % (self.address, self.index, self.count)\n            txt += pu.color_title(title)\n            txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"objects\")\n            txt += pu.color_value(\"{:#d}\".format(self.objects))\n\n            if self.is_main_slab:\n                txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"inuse\")\n                txt += pu.color_value(\"{:#d}\".format(self.inuse))\n                # the inuse value is kind of a lie in this case\n                txt += \" (real = {:#d})\".format(self.inuse-len(self.kmem_cache_cpu.freelist))\n            else: # partial slab, full slab, etc.\n                txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"inuse\")\n                txt += pu.color_value(\"{:#d}\".format(self.inuse))\n            txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"frozen\")\n            txt += pu.color_value(\"{:#d}\".format(self.frozen))\n\n            txt += \"\\n{:s}  {:8} = \".format(\" \"*indent, \"freelist\")\n            txt += pu.color_value(\"{:#x}\".format(self.fp))\n            txt += \" ({:#d} elements)\".format(len(self.freelist))\n            txt += \"\\n\"\n            print(txt, end=\"\")\n\n        if cmd.args.show_freelist:\n            if cmd.args.object_only is True and cmd.args.hide_title is False:\n                txt = pu.color_value(\"{:s}regular freelist:\").format(\" \"*indent)\n                txt += \"\\n\"\n                print(txt, end=\"\")\n            # print the objects in the the freelist\n\n            # Prepare arguments for \"sbobject\" format\n            # i.e. the chunks to print are from the freelist\n\n            # The amount of printed addresses will be limited by \n            # parse_many()'s \"count\" argument\n            if cmd.args.count == None:\n                count = len(self.freelist)\n            else:\n                count = cmd.args.count\n\n            sbobject.sbobject.parse_many(\n                self.freelist, \n                0, \n                cmd.sb, \n                cmd.dbg, \n                None, # count\n                count, # count_handle,\n                cmd.args.search_depth,\n                cmd.args.skip_header, \n                cmd.args.hexdump_unit, \n                cmd.args.search_value, \n                cmd.args.search_type, \n                cmd.args.match_only, \n                cmd.args.print_offset, \n                cmd.args.verbose, \n                cmd.args.no_newline,\n                cmd.args.debug, \n                cmd.args.hexdump, \n                cmd.args.maxbytes, \n                cmd.args.metadata,\n                highlight_types=cmd.highlight_types,\n                highlight_addresses=cmd.highlight_addresses,\n                highlight_metadata=cmd.highlight_metadata,\n                highlight_only=cmd.args.highlight_only,\n                commands=cmd.args.commands,\n                use_cache=cmd.args.use_cache,\n                address_offset=cmd.args.address_offset,\n                name=cmd.args.name,\n                indent=\" \"*(indent+4),\n                is_freelist=True,\n                object_info=cmd.args.object_info,\n            )\n\n        if cmd.args.object_only is not True:\n            txt = \"{:s}  region   @ {:#x}-{:#x}\".format(\" \"*indent, self.region_start, self.region_end)\n            txt += \" ({:#d} elements)\".format(len(self.objects_list))\n            txt += \"\\n\"\n            print(txt, end=\"\")\n\n        if cmd.args.show_region:\n            if cmd.args.object_only is True and cmd.args.hide_title is False:\n                txt = pu.color_value(\"{:s}  region:\").format(\" \"*indent)\n                txt += \"\\n\"\n                print(txt, end=\"\")\n            # print the linear objects in the the slab\n            if cmd.args.count == None:\n                count = len(self.objects_list)\n            else:\n                count = cmd.args.count\n\n            sbobject.sbobject.parse_many(\n                self.objects_list, \n                0, \n                cmd.sb, \n                cmd.dbg, \n                None, # count \n                count, # count_handle\n                cmd.args.search_depth,\n                cmd.args.skip_header, \n                cmd.args.hexdump_unit, \n                cmd.args.search_value, \n                cmd.args.search_type, \n                cmd.args.match_only, \n                cmd.args.print_offset, \n                cmd.args.verbose, \n                cmd.args.no_newline,\n                cmd.args.debug, \n                cmd.args.hexdump, \n                cmd.args.maxbytes, \n                cmd.args.metadata,\n                highlight_types=cmd.highlight_types,\n                highlight_addresses=cmd.highlight_addresses,\n                highlight_metadata=cmd.highlight_metadata,\n                highlight_only=cmd.args.highlight_only,\n                commands=cmd.args.commands,\n                use_cache=cmd.args.use_cache,\n                address_offset=cmd.args.address_offset,\n                name=cmd.args.name,\n                indent=\" \"*(indent+4),\n                is_region=True,\n                object_info=cmd.args.object_info,\n            )"]}
{"filename": "libslub/slub/sb.py", "chunked_list": ["import struct\nimport sys\nimport logging\nimport importlib\nimport gdb\nfrom enum import Enum\n\nimport libslub.frontend.printutils as pu\n\nimportlib.reload(pu)", "\nimportlib.reload(pu)\nimport libslub.frontend.helpers as h\n\nimportlib.reload(h)\nimport libslub.frontend.helpers2 as h2\n\nimportlib.reload(h2)\nimport libslub.frontend.breakpoints.gdb.breakpoints as breakpoints\n", "import libslub.frontend.breakpoints.gdb.breakpoints as breakpoints\n\nimportlib.reload(breakpoints)\n# XXX - may be want to move the sbslabdb stuff in the sbcache command so sb.py does not rely on sbslabdb.py\nimport libslub.frontend.commands.gdb.sbslabdb as sbslabdb\n\nimportlib.reload(sbslabdb)\nimport libslub.slub.cache as c\n\nimportlib.reload(c)", "\nimportlib.reload(c)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sb.py\")\n\n\nclass SlabType(Enum):\n    MAIN_SLAB = 0\n    PARTIAL_SLAB = 1\n    NODE_SLAB = 2  # partial slab in node\n    FULL_SLAB = 3  # full slab in node", "\n\n# XXX - some methods in this helper class could be changed to fetch information from the cache instead of fetching it from\n# memory again\nclass sb:\n    UNSIGNED_INT = 0xFFFFFFFF\n    UNSIGNED_LONG = 0xFFFFFFFFFFFFFFFF\n    TYPE_CODE_HAS_FIELDS = [gdb.TYPE_CODE_STRUCT, gdb.TYPE_CODE_UNION]\n\n    # XXX - move to sblist.py?\n    kmalloc_caches = [\n        \"kmalloc-%s\" % n\n        for n in [\n            \"8\",\n            \"16\",\n            \"32\",\n            \"64\",\n            \"96\",\n            \"128\",\n            \"192\",\n            \"256\",\n            \"512\",\n            \"1k\",\n            \"2k\",\n            \"4k\",\n            \"8k\",\n        ]\n    ]\n\n    FLAGS = {\n        0x00000100: \"SLAB_DEBUG_FREE\",\n        0x00000400: \"SLAB_RED_ZONE\",\n        0x00000800: \"SLAB_POISON\",\n        0x00002000: \"SLAB_HWCACHE_ALIGN\",\n        0x00004000: \"SLAB_CACHE_DMA\",\n        0x00008000: \"SLAB_CACHE_DMA32\",\n        0x00010000: \"SLAB_STORE_USER\",\n        0x00020000: \"SLAB_RECLAIM_ACCOUNT\",\n        0x00040000: \"SLAB_PANIC\",\n        0x00080000: \"SLAB_DESTROY_BY_RCU\",\n        0x00100000: \"SLAB_MEM_SPREAD\",\n        0x00200000: \"SLAB_TRACE\",\n        0x00400000: \"SLAB_DEBUG_OBJECTS\",\n        0x00800000: \"SLAB_NOLEAKTRACE\",\n        0x01000000: \"SLAB_NOTRACK\",\n        0x02000000: \"SLAB_FAILSLAB\",\n        0x40000000: \"__CMPXCHG_DOUBLE\",\n        0x80000000: \"__OBJECT_POISON\",\n    }\n\n    def __init__(self, SIZE_SZ=None, debugger=None, breakpoints_enabled=False):\n        \"\"\"\n        :param debugger: the pydbg object\n\n        Internally, everything is kept as gdb.Value\n        \"\"\"\n\n        self.SIZE_SZ = SIZE_SZ\n        self.dbg = debugger\n        self.breakpoints_enabled = breakpoints_enabled\n        self.node_num = self._get_node_num()  # number of NUMA node\n        self.arch = self.get_arch()\n        self._check_slub()\n\n        self.cpu_num = gdb.lookup_global_symbol(\"nr_cpu_ids\").value()\n        self.per_cpu_offset = gdb.lookup_global_symbol(\"__per_cpu_offset\").value()\n        try:\n            self.memstart_addr = gdb.lookup_global_symbol(\"memstart_addr\").value()\n        except Exception:\n            self.memstart_addr = None\n\n        # Defines if the breakpoints used for tracking should be hidden to the user\n        # as used for \"internal\" in https://sourceware.org/gdb/onlinedocs/gdb/Breakpoints-In-Python.html\n        self.bps_hidden = True  # set to False for debugging only\n\n        # List of cache names (e.g. \"kmalloc-1k\") to track object allocations/frees\n        # for logging purpose or for breaking in the debugger\n        self.trace_caches = []\n        self.break_caches = []\n        # List of cache names (e.g. \"kmalloc-1k\") to track slab allocations/frees so\n        # we can list the full-slabs contents since they are not tracked by SLUB\n        self.watch_caches = []\n        # List of slab addresses (struct page*) for previously allocated slabs that we\n        # managed to track. This is so we can list the full-slabs contents when needed\n        self.slabs_list = []\n        if self.breakpoints_enabled:\n            self.breakpoints = breakpoints.breakpoints(self)\n\n        self.cache = c.cache(self)\n\n        self.set_globals(SIZE_SZ=self.SIZE_SZ)\n\n    def set_globals(self, SIZE_SZ=None):\n        if SIZE_SZ is None:\n            if self.dbg is None:\n                pu.print_error(\"Please specify a SIZE_SZ value or run in debugger.\")\n                raise Exception(\"sys.exit()\")\n\n            self.SIZE_SZ = self.dbg.get_size_sz()\n            if self.SIZE_SZ is None:\n                pu.print_error(\"error fetching size\")\n                raise Exception(\"sys.exit()\")\n        else:\n            self.SIZE_SZ = SIZE_SZ\n\n    def _get_node_num(self):\n        \"\"\"\n        get the number of NUMA nodes in the hardware\n        reference:\n        https://futurewei-cloud.github.io/ARM-Datacenter/qemu/how-to-configure-qemu-numa-nodes/\n        https://elixir.bootlin.com/linux/v4.15/source/include/linux/nodemask.h#L433\n        \"\"\"\n        node_states = gdb.lookup_global_symbol(\"node_states\").value()\n        node_mask = node_states[1][\"bits\"][0]  # 1 means N_ONLINE\n        return bin(node_mask).count(\"1\")\n\n    def _check_slub(self):\n        \"\"\"\n        make sure the target kernel is compiled with SLUB, not SLAB or SLOB\n        \"\"\"\n        allocator = \"SLOB\"\n        kmem_cache = gdb.lookup_type(\"struct kmem_cache\")\n        for field in gdb.types.deep_items(kmem_cache):\n            name = field[0]\n            if name == \"batchcount\":\n                allocator = \"SLAB\"\n                break\n            elif name == \"inuse\":\n                allocator = \"SLUB\"\n                break\n        if allocator != \"SLUB\":\n            raise ValueError(\"slabdbg does not support allocator: %s\" % allocator)\n\n    def get_arch(self):\n        \"\"\"Return the binary's architecture.\"\"\"\n        if h2.is_alive():\n            arch = gdb.selected_frame().architecture()\n            return arch.name()\n\n        arch_str = gdb.execute(\"show architecture\", to_string=True).strip()\n        if (\n            \"The target architecture is set automatically (currently \" in arch_str\n            or 'The target architecture is set to \"auto\" (currently ' in arch_str\n        ):\n            # architecture can be auto detected\n            arch_str = arch_str.split(\"(currently \", 1)[1]\n            arch_str = arch_str.split(\")\", 1)[0]\n        elif \"The target architecture is assumed to be \" in arch_str:\n            # architecture can be assumed\n            arch_str = arch_str.replace(\"The target architecture is assumed to be \", \"\")\n        else:\n            # unknown, we throw an exception to be safe\n            raise RuntimeError(\"Unknown architecture: {}\".format(arch_str))\n        return arch_str\n\n    @staticmethod\n    def get_field_bitpos(type, member):\n        \"\"\"XXX\"\"\"\n\n        for field in type.fields():\n            if field.name == member:\n                return field.bitpos\n            if field.type.code in sb.TYPE_CODE_HAS_FIELDS:\n                bitpos = sb.get_field_bitpos(field.type, member)\n                if bitpos is not None:\n                    return field.bitpos + bitpos\n        return None\n\n    @staticmethod\n    def for_each_entry(type, head, member):\n        \"\"\"Iterator for a linked list pointed by head (i.e. starting address) where each element\n        of the linked list is of the \"type\" type and the next element being found at the \"member\"\n        member of the \"type\" type.\n\n        @param type: a gdb.Type (e.g. representing \"struct kmem_cache\") to cast elements in the linked list pointed by head\n        @param head: a gdb.Value for a \"struct list_head\" (linked list) represented by a dictionary (so having the \"next\" and \"prev\" keys)\n        @param member: the name of the linked list pointed by head in the provided type\n                       e.g. \"struct kmem_cache\" has its linked list named \"list\"\n\n        @return: iterator returning the gdb.Type casted objects found at the different elements\n                 in the linked list pointed by head\n        \"\"\"\n\n        void_p = gdb.lookup_type(\"void\").pointer()  # type represents a void*\n        offset = sb.get_field_bitpos(type, member) // 8\n\n        pos = head[\"next\"].dereference()\n        while pos.address != head.address:\n            entry = gdb.Value(pos.address.cast(void_p) - offset)\n            # print(entry)\n            # print(entry.cast(type.pointer()).dereference())\n            # print(\"Found list entry: 0x%x\" % entry)\n            # Cast the gdb.Value address to the right type and return that as a dictionary\n            yield entry.cast(type.pointer()).dereference()\n            pos = pos[\"next\"].dereference()\n\n    @staticmethod\n    def iter_slab_caches():\n        \"\"\"Iterator for the \"struct list_head slab_caches\" which is a linked list of \"struct kmem_cache*\"\n        representing all the slab caches on the system.\n\n        struct kmem_cache* kmem_cache: https://elixir.bootlin.com/linux/v5.15/source/mm/slab_common.c#L38\n\n        @return: iterator returning the the different \"struct kmem_cache\" elements (represented as dictionaries)\n                 part of the \"list\" linked list of the \"struct kmem_cache\" structure, which head starts\n                 at the \"slab_caches\" global.\n        \"\"\"\n\n        # The \"kmem_cache\" type as a dictionary\n        # struct kmem_cache {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/slub_def.h#L90\n        # lookup_type(), see https://sourceware.org/gdb/onlinedocs/gdb/Types-In-Python.html\n        kmem_cache_type = gdb.lookup_type(\"struct kmem_cache\")\n\n        # The head of the list for all slab caches on the system (e.g. \"kmalloc-64\", etc.)\n        # https://elixir.bootlin.com/linux/v5.15/source/mm/slab.h#L72\n        # lookup_global_symbol(), see https://sourceware.org/gdb/onlinedocs/gdb/Symbols-In-Python.html\n        slab_caches = gdb.lookup_global_symbol(\"slab_caches\").value()\n\n        return sb.for_each_entry(kmem_cache_type, slab_caches, \"list\")\n\n    @staticmethod\n    def find_slab_cache(name):\n        for slab_cache in sb.iter_slab_caches():\n            if slab_cache[\"name\"].string() == name:\n                return slab_cache\n        return None\n\n    @staticmethod\n    def get_cache_names():\n        for slab_cache in sb.iter_slab_caches():\n            yield slab_cache[\"name\"].string()\n\n    @staticmethod\n    def get_flags_list(flags):\n        return [sb.FLAGS[x] for x in sb.FLAGS if flags & x == x]\n\n    @staticmethod\n    def freelist_ptr(slab_cache, freelist, freelist_addr):\n        \"\"\"Return a possibly decoded freelist value\n\n        This function only actually does anything if the random member is found\n        in the slab_cache, otherwise we assume that freelist coding isn't\n        supported\n\n        Note: At some point in additional bit diffusion technique was added,\n        which changes the way there encoding is done... we need a way to test\n        for this probably. apossibly decoding it twice and seeing which one is\n        a valid address? See XXX below..\n\n        https://patchwork.kernel.org/project/linux-mm/patch/202003051623.AF4F8CB@keescook/\n\n        Newer versions of the linux kernel encode this pointer\n\n        See freelist_ptr in slub.c for implementation:\n\n        static inline void *freelist_ptr(const struct kmem_cache *s, void *ptr,\n                         unsigned long ptr_addr)\n        {\n        #ifdef CONFIG_SLAB_FREELIST_HARDENED\n            /*\n            return (void *)((unsigned long)ptr ^ s->random ^\n                    swab((unsigned long)kasan_reset_tag((void *)ptr_addr)));\n        #else\n            return ptr;\n        #endif\n        }\n\n        ptr_addr is the address of the ptr in the kmem_cache structure itself.\n        \"\"\"\n\n        # Not sure how to check for keys in gdb.Value struct... so try instead\n        try:\n            random = int(slab_cache[\"random\"])\n        except Exception:\n            return freelist\n\n        # print(\"Freelist address: 0x%x\" % freelist_addr)\n        random = int(slab_cache[\"random\"])\n        decoded = (\n            random\n            ^ int(freelist.cast(gdb.lookup_type(\"unsigned long\")))\n            ^ h.swap64(freelist_addr)\n        )\n        # XXX To solve the swap64() possibly not existing, we could check if\n        # the decoded address lives inside the slab cache page, since all of\n        # the objects should be inside of it...\n        return decoded\n\n    @staticmethod\n    def walk_linear_memory_region(slab_cache, slab, region_start):\n        \"\"\"Iterator returns each object/chunk address in the slab memory region\n\n        @param slab_cache: slab cache (gdb.Value) associated with a given slab. The reason we pas it is because it contains\n               fields to know the size of objects, etc.\n        @param slab: slab (gdb.Value) we want to get the objects/chunks from its memory region\n        @param region_start: start address of the memory region holding the objects/chunks for that slab\n        @return: iterator returns each object/chunk address in the slab memory region\n        \"\"\"\n\n        objects = int(slab[\"objects\"]) & sb.UNSIGNED_INT\n        size = int(slab_cache[\"size\"])\n\n        for address in range(region_start, region_start + objects * size, size):\n            yield address\n\n    @staticmethod\n    def walk_freelist(slab_cache, freelist):\n        \"\"\"Iterator return each object address in the slab's free list\n\n        @param slab_cache: slab cache associated with a given slab. The reason we pas it is because it contains\n                offsets and random values used to find the next element in the freelist\n        @param freelist: address of the head of the freelist\n        @return: iterator returns each object address in the slab's free list\n        \"\"\"\n\n        void = gdb.lookup_type(\"void\").pointer().pointer()\n        offset = int(slab_cache[\"offset\"])\n\n        # Stop when we encounter a NULL pointer\n        while freelist:\n            address = int(freelist) & sb.UNSIGNED_LONG\n            yield address\n            freelist = gdb.Value(address + offset).cast(void).dereference()\n            freelist = sb.freelist_ptr(slab_cache, freelist, address + offset)\n\n    # XXX - move to class: kmem_cache_cpu\n    def get_current_slab_cache_cpu(self, slab_cache):\n        \"\"\"\n        See https://elixir.bootlin.com/linux/v5.15/source/include/linux/slub_def.h#L91\n\n        @return a gdb.Value representing the current kmem_cache_cpu for that slab cache\n        i.e. representing kmem_cache->cpu_slab\n\n        NOTE: The gdb.Value represents a structure and is a simple dictionary\n        see https://sourceware.org/gdb/onlinedocs/gdb/Values-From-Inferior.html\n        \"\"\"\n\n        void_p = gdb.lookup_type(\"void\").pointer()  # type represents a void*\n        kmem_cache_cpu = gdb.lookup_type(\n            \"struct kmem_cache_cpu\"\n        ).pointer()  # type represents a kmem_cache_cpu*\n\n        # selected_thread(), see: https://sourceware.org/gdb/onlinedocs/gdb/Threads-In-Python.html\n        current_cpu = gdb.selected_thread().num - 1\n\n        cpu_offset = self.per_cpu_offset[current_cpu]\n        cpu_slab = gdb.Value(slab_cache[\"cpu_slab\"].cast(void_p) + cpu_offset)\n        return cpu_slab.cast(kmem_cache_cpu).dereference()\n\n    # XXX - move to class: kmem_cache_cpu\n    def get_all_slab_cache_cpus(self, slab_cache):\n        \"\"\"\n        See https://elixir.bootlin.com/linux/v5.15/source/include/linux/slub_def.h#L91\n\n        @return a list of all the gdb.Value representing all the kmem_cache_cpu for that slab cache\n        i.e. representing the different kmem_cache->cpu_slab\n\n        NOTE: The gdb.Value represents a structure and is a simple dictionary\n        see https://sourceware.org/gdb/onlinedocs/gdb/Values-From-Inferior.html\n        \"\"\"\n\n        void_p = gdb.lookup_type(\"void\").pointer()  # type represents a void*\n        kmem_cache_cpu = gdb.lookup_type(\n            \"struct kmem_cache_cpu\"\n        ).pointer()  # type represents a kmem_cache_cpu*\n\n        offset = slab_cache[\"cpu_slab\"]\n        result = []\n        for cpu_idx in range(self.cpu_num):\n            cpu_offset = self.per_cpu_offset[cpu_idx]\n            cpu_slab = gdb.Value(offset.cast(void_p) + cpu_offset)\n            cpu_slab = cpu_slab.cast(kmem_cache_cpu).dereference()\n            result.append(cpu_slab)\n        return result\n\n    def notify_obj_alloc(self, name, addr):\n        \"\"\"Called when a breakpoint tracking objects allocations in a given slab hits\"\"\"\n        if name in self.trace_caches:\n            print(\"Object 0x%x allocated in %s\" % (addr, name))\n\n    def notify_obj_free(self, name, addr):\n        \"\"\"Called when a breakpoint tracking objects frees in a given slab hits\"\"\"\n        if name in self.trace_caches:\n            print(\"Object 0x%x freed in %s\" % (addr, name))\n\n    def notify_slab_alloc(self, name, addr):\n        \"\"\"Called when a breakpoint tracking slabs allocations hits\"\"\"\n        if name in self.watch_caches:\n            print(\"Slab 0x%x allocated in %s\" % (addr, name))\n            self.slabs_list.append(addr)\n\n    def notify_slab_free(self, name, addr):\n        \"\"\"Called when a breakpoint tracking slabs frees hits\"\"\"\n        if name in self.watch_caches:\n            if addr in self.slabs_list:\n                print(\"Slab 0x%x freed in %s\" % (addr, name))\n                self.slabs_list.remove(addr)\n\n    # XXX - move to the actual slab object that matches the structure\n    def get_full_slabs(self, slab_cache_name):\n        \"\"\"Yield all tracked slab allocations that are determined to be full\n        for a given slab cache\n\n        @slab_cache_name: the slab cache name we want the full slabs of (e.g. \"kmalloc-1k\")\n        @return: Yield all the gdb.Value for the slab caches that are full (i.e. dictionaries\n                 representing the \"struct page*\" type)\n        \"\"\"\n\n        # We rely on breakpoints to keep track of allocations/frees of slabs,\n        # and keep them inside of slabs_list. This lets us view full slabs that\n        # would otherwise not be accessible.\n        if slab_cache_name in self.watch_caches:\n            yield from sb.full_slab_from_list(self.slabs_list, slab_cache_name)\n\n        # Alternatively, we rely on the sbslabdb command being used by us to track certain slabs\n        # associated with certain chunks address we want to track the slabs of\n        if slab_cache_name in sbslabdb.slab_db.keys():\n            yield from sb.full_slab_from_list(\n                sbslabdb.slab_db[slab_cache_name].keys(), slab_cache_name\n            )\n\n    @staticmethod\n    def full_slab_from_list(slabs_list, slab_cache_name):\n        \"\"\"Yield all tracked slab allocations that are determined to be full\n        for a given slab cache\n\n        @slabs_list: the list of struct page* addresses for certain slabs we tracked previously\n        @slab_cache_name: the slab cache name we want the full slabs of (e.g. \"kmalloc-1k\")\n        @return: Yield all the gdb.Value for the slab caches that are full (i.e. dictionaries\n                 representing the \"struct page*\" type)\n\n        We make sure that each slab in the\n        list is not on the free list (implying non-full), is not frozen\n        (implying it's not associated with this specific CPU at the moment?),\n        and the name matches whatever cache we are interested in\n        \"\"\"\n        page_type = gdb.lookup_type(\"struct page\").pointer()\n        for addr in slabs_list:\n            slab = gdb.Value(addr).cast(page_type)\n            slab_cache = slab[\"slab_cache\"]\n            if (\n                int(slab_cache) != 0x0\n                and slab_cache[\"name\"].string() == slab_cache_name\n                and int(slab[\"frozen\"]) == 0\n                and not slab[\"freelist\"]\n            ):\n                yield slab.dereference()\n\n    def page_addr(self, page):\n        \"\"\"XXX - I dont entirely understand why this is necessary\n\n        Comes from arch/x86/include/asm/page_64_types.h\n        #define __PAGE_OFFSET_BASE_L4 _AC(0xffff888000000000, UL)\n\n        \"\"\"\n        # Some configurations it stored in this variable, but it isnt queriable\n        # foo = gdb.lookup_global_symbol(\"__ro_after_init\").value()\n        if \"x86-64\" in self.arch:\n            offset = (page - 0xFFFFEA0000000000) >> 6 << 0xC\n            return (\n                # 0xFFFF880000000000 + offset\n                0xFFFF888000000000\n                + offset\n            )  # this value depends on kernel version if could be 0xFFFF888000000000\n        else:\n            memstart_addr = int(self.memstart_addr) & sb.UNSIGNED_LONG\n            addr = (memstart_addr >> 6) & sb.UNSIGNED_LONG\n            addr = (addr & 0xFFFFFFFFFF000000) & sb.UNSIGNED_LONG\n            addr = (0xFFFFFFBDC0000000 - addr) & sb.UNSIGNED_LONG\n            addr = (page - addr) & sb.UNSIGNED_LONG\n            addr = (addr >> 6 << 0xC) & sb.UNSIGNED_LONG\n            addr = (addr - memstart_addr) & sb.UNSIGNED_LONG\n            return addr | 0xFFFFFFC000000000\n\n    def get_slabs(self, slab_cache):\n        \"\"\"Collect a full list of all the slabs associated with a slab cache\"\"\"\n\n        pages = []  # these are actual \"struct page*\" (gdb.Value) representing a slab\n\n        cpu_cache_list = self.get_all_slab_cache_cpus(slab_cache)\n\n        for cpu_id, cpu_cache in enumerate(cpu_cache_list):\n            if cpu_cache[\"page\"]:\n                slab = cpu_cache[\"page\"].dereference()\n                pages.append(slab)\n\n            if cpu_cache[\"partial\"]:\n                slab_ptr = cpu_cache[\"partial\"]\n                while slab_ptr:\n                    slab = slab_ptr.dereference()\n                    pages.append(slab)\n                    slab_ptr = slab[\"next\"]\n\n        for node_id in range(self.node_num):\n            node_cache = slab_cache[\"node\"][node_id]\n            page = gdb.lookup_type(\"struct page\")\n            partials = list(self.for_each_entry(page, node_cache[\"partial\"], \"lru\"))\n            if partials:\n                for slab in partials:\n                    pages.append(slab)\n\n        fulls = list(self.get_full_slabs(slab_cache))\n        if fulls:\n            for slab in fulls:\n                pages.append(slab)\n\n        return pages\n\n    def get_slab_cache_memory_pages(self, slab_cache):\n        \"\"\"Collect a full list of all memory pages holding chunks associated with a slab cache\n\n        Similar to get_slab_cache_memory_pages_ranges() but returning start addresses\"\"\"\n\n        pages = self.get_slabs(\n            slab_cache\n        )  # these are actual \"struct page*\" (gdb.Value) representing a slab\n        page_addrs = []  # these are memory pages ranges holding chunks\n\n        for page in pages:\n            address = int(page.address) & sb.UNSIGNED_LONG\n            page_addrs.append(self.page_addr(address))\n\n        return page_addrs\n\n    def get_slab_cache_memory_pages_ranges(self, name=None, dict_enabled=False):\n        \"\"\"Collect a full list of all memory pages ranges holding chunks associated with one or several slab caches\n\n        @param name: slab cache name if known (optional)\n\n        Similar to get_slab_cache_memory_pages() but returning ranges\"\"\"\n\n        if dict_enabled is True:\n            page_addrs = (\n                {}\n            )  # key = page* address, and value = array for memory pages ranges holding chunks\n        else:\n            page_addrs = []  # these are memory pages ranges holding chunks\n\n        if not name:\n            slab_caches = sb.iter_slab_caches()\n        else:\n            slab_cache = sb.find_slab_cache(name)\n            if slab_cache is None:\n                print(\"Slab cache '%s' not found\" % name)\n                return None\n            slab_caches = [slab_cache]\n\n        for slab_cache in slab_caches:\n            pages = self.get_slabs(\n                slab_cache\n            )  # these are actual \"struct page*\" (gdb.Value) representing a slab\n\n            for page in pages:\n                objects = int(page[\"objects\"]) & sb.UNSIGNED_INT\n                size = int(slab_cache[\"size\"])\n                address = int(page.address) & sb.UNSIGNED_LONG\n                page_addr = self.page_addr(address)\n                page_end = page_addr + objects * size\n                if dict_enabled is True:\n                    page_addrs[address] = (page_addr, page_end)\n                else:\n                    page_addrs.append((page_addr, page_end))\n\n        return page_addrs\n\n    def get_slab_address(self, chunk_addr, name=None):\n        \"\"\"Get the slab address (struct page*) holding a given chunk address\n\n        @param chunk_addr: a chunk address we are looking for\n        @param name: slab cache name if known (optional)\n        @return the slab address (struct page*) holding that chunk\"\"\"\n\n        if not name:\n            slab_caches = sb.iter_slab_caches()\n        else:\n            slab_cache = sb.find_slab_cache(name)\n            if slab_cache is None:\n                print(\"Slab cache '%s' not found\" % name)\n                return None\n            slab_caches = [slab_cache]\n\n        for slab_cache in slab_caches:\n            pages = self.get_slabs(\n                slab_cache\n            )  # these are actual \"struct page*\" (gdb.Value) representing a slab\n\n            for page in pages:\n                objects = int(page[\"objects\"]) & sb.UNSIGNED_INT\n                size = int(slab_cache[\"size\"])\n                address = int(page.address) & sb.UNSIGNED_LONG\n                page_addr = self.page_addr(address)\n                page_end = page_addr + objects * size\n                if chunk_addr >= page_addr and chunk_addr < page_end:\n                    return address\n\n        return None\n\n    @staticmethod\n    def print_slab_cache_pages(name, pages):\n        pages.sort()\n        last_page = 0\n        print(f\"{name} has {len(pages)} memory pages:\")\n        for page in pages:\n            if last_page == page - 4096:\n                print(f\"0x{page:08x}*\")\n            else:\n                print(f\"0x{page:08x}\")\n            last_page = page\n\n    @staticmethod\n    def print_slab_cache_pages_ranges(name, pages):\n        pages.sort()\n        last_page = 0\n        print(f\"{name} has {len(pages)} memory pages:\")\n        for start_addr, end_addr in pages:\n            if last_page == start_addr - 4096:\n                print(f\"0x{start_addr:08x}-0x{end_addr:08x}*\")\n            else:\n                print(f\"0x{start_addr:08x}-0x{end_addr:08x}\")\n            last_page = start_addr", ""]}
{"filename": "libslub/slub/cache.py", "chunked_list": ["import struct\nimport sys\nimport logging\nimport importlib\nimport time\n\nimport libslub.slub.kmem_cache as kc\nimportlib.reload(kc)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)", "import libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.frontend.helpers as h\nimportlib.reload(h)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"cache.py\")\n\nclass cache:\n    \"\"\"Hold cached information such as our own classes representing slab structures, \n    as well as objects/chunk's addresses in the respective freelists.\n\n    Since browsing all these big structures and arrays can be slow in gdb, we cache\n    them in this class.\"\"\"\n\n    def __init__(self, sb):\n        self.sb = sb\n\n        # each key is a slab cache name (e.g. \"kmalloc-1k\")\n        # each value is a kmem_cache class holding all the useful information\n        self.slab_caches = {}\n\n    def update_kmem_cache(self, name=None, show_status=False, use_cache=False):\n        \"\"\"Update the kmem_cache object\n        \n        :param name: slab cache name (e.g. \"kmalloc-1k\")\n        \"\"\"\n\n        log.debug(\"cache.update_kmem_cache()\")\n\n        # nothing to update if we use the cache\n        if use_cache:\n            return\n\n        if name is None:\n            slab_caches = sb.sb.iter_slab_caches()\n            print(\"Fetching all slab caches, this will take a while... (use -n to specify a slab cache)\")\n        else:\n            slab_cache = sb.sb.find_slab_cache(name)\n            if slab_cache is None:\n                print(\"Slab cache '%s' not found\" % name)\n                return\n            slab_caches = [slab_cache]\n\n        start_time = time.time()\n        for slab_cache in slab_caches:\n            kmem_cache = kc.kmem_cache(self.sb, value=slab_cache)\n            if show_status:\n                print(f\"Caching slab cache: {kmem_cache.name}\")\n            self.slab_caches[kmem_cache.name] = kmem_cache\n        end_time = time.time()\n        if name is None:\n            print(\"Fetched in %s\" % h.hms_string(end_time-start_time))\n    \n    def update_all(self, name=None, show_status=False, use_cache=False):\n        self.update_kmem_cache(name=name, show_status=show_status, use_cache=use_cache)", "class cache:\n    \"\"\"Hold cached information such as our own classes representing slab structures, \n    as well as objects/chunk's addresses in the respective freelists.\n\n    Since browsing all these big structures and arrays can be slow in gdb, we cache\n    them in this class.\"\"\"\n\n    def __init__(self, sb):\n        self.sb = sb\n\n        # each key is a slab cache name (e.g. \"kmalloc-1k\")\n        # each value is a kmem_cache class holding all the useful information\n        self.slab_caches = {}\n\n    def update_kmem_cache(self, name=None, show_status=False, use_cache=False):\n        \"\"\"Update the kmem_cache object\n        \n        :param name: slab cache name (e.g. \"kmalloc-1k\")\n        \"\"\"\n\n        log.debug(\"cache.update_kmem_cache()\")\n\n        # nothing to update if we use the cache\n        if use_cache:\n            return\n\n        if name is None:\n            slab_caches = sb.sb.iter_slab_caches()\n            print(\"Fetching all slab caches, this will take a while... (use -n to specify a slab cache)\")\n        else:\n            slab_cache = sb.sb.find_slab_cache(name)\n            if slab_cache is None:\n                print(\"Slab cache '%s' not found\" % name)\n                return\n            slab_caches = [slab_cache]\n\n        start_time = time.time()\n        for slab_cache in slab_caches:\n            kmem_cache = kc.kmem_cache(self.sb, value=slab_cache)\n            if show_status:\n                print(f\"Caching slab cache: {kmem_cache.name}\")\n            self.slab_caches[kmem_cache.name] = kmem_cache\n        end_time = time.time()\n        if name is None:\n            print(\"Fetched in %s\" % h.hms_string(end_time-start_time))\n    \n    def update_all(self, name=None, show_status=False, use_cache=False):\n        self.update_kmem_cache(name=name, show_status=show_status, use_cache=use_cache)", ""]}
{"filename": "libslub/slub/kmem_cache_node.py", "chunked_list": ["import struct\nimport sys\nimport importlib\nimport gdb\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.heap_structure as hs\nimportlib.reload(hs)\nimport libslub.slub.sb as sb", "importlib.reload(hs)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.slub.page as p\nimportlib.reload(p)\n\nclass kmem_cache_node(hs.heap_structure):\n    \"\"\"python representation of a struct kmem_cache_node\n    \n    struct kmem_cache_node {: https://elixir.bootlin.com/linux/v5.15/source/mm/slab.h#L533\n    \"\"\"\n\n    def __init__(self, sb, node_id, kmem_cache, value=None, address=None):\n        \"\"\"\n        Parse kmem_cache_node's data and initialize the kmem_cache_node object\n\n        :param sb: slab object holding all our useful info\n        :param value: gdb.Value of type kmem_cache_node with structure's content read from the debugger (represented by a dictionary)\n        :param address: address for a kmem_cache_node where to read the structure's content from the debugger (not supported yet)\n        \"\"\"\n\n        super(kmem_cache_node, self).__init__(sb)\n\n        # kmem_cache_node structure's fields can be looked up directly from the gdb.Value\n        self.value = value # gdb.Value representing the kmem_cache_node\n        self.kmem_cache = kmem_cache # kmem_cache object\n\n        self.init(node_id)\n\n    def init(self, node_id):\n\n        # our own abstraction fields\n        self.node_id = node_id # node index in the kmem_cache\n        self.address = int(self.value.address) & sb.sb.UNSIGNED_LONG\n        \n        self.partial_slabs = [] # list of kmem_cache_cpu objects for that kmem_cache\n        # browse the list of gdb.Value (representing the kmem_cache_cpu->node[node_id].partial linked list of struct page*)\n        page_type = gdb.lookup_type(\"struct page\")\n        partial_slabs_values = list(self.sb.for_each_entry(page_type, self.value[\"partial\"], \"lru\"))\n        slab_count = len(partial_slabs_values)\n        for slab_index, slab_value in enumerate(partial_slabs_values):\n            partial_slab = p.page(self.sb, self.kmem_cache, None, self, sb.SlabType.NODE_SLAB, index=slab_index+1, count=slab_count, value=slab_value)\n            self.partial_slabs.append(partial_slab)\n\n    def print(self, verbose=0, use_cache=False, indent=0, cmd=None):\n        \"\"\"Pretty printer for the kmem_cache_node supporting different level of verbosity\n\n        :param verbose: 0 for non-verbose. 1 for more verbose. 2 for even more verbose.\n        :param use_cache: True if we want to use the cached information from the cache object.\n                          False if we want to fetch the data again\n        :param cmd: cmd.args == arguments so we know what options have been passed by the user\n                     e.g. to print hexdump of objects/chunks, highlight chunks, etc.\n        \"\"\"\n\n        if cmd.args.object_only is not True:\n            txt = \" \"*indent\n            title = \"struct kmem_cache_node @ 0x%x (node %d) {\" % (self.address, self.node_id)\n            txt += pu.color_title(title)\n            txt += \"\\n\"\n            print(txt, end=\"\")\n\n        if len(self.partial_slabs) == 0:\n            if cmd.args.object_only is not True:\n                print(\"{:s}  partial = (none)\".format(\" \"*indent))\n        else:\n            for partial_slab in self.partial_slabs:\n                partial_slab.print(name=\"partial\", indent=indent+2, cmd=cmd)"]}
{"filename": "libslub/slub/__init__.py", "chunked_list": ["import logging\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"slab/__init__.py\")"]}
{"filename": "libslub/slub/kmem_cache.py", "chunked_list": ["import struct\nimport sys\nimport importlib\nimport logging\n\nimport libslub.frontend.printutils as pu\nimportlib.reload(pu)\nimport libslub.slub.heap_structure as hs\nimportlib.reload(hs)\nimport libslub.slub.sb as sb", "importlib.reload(hs)\nimport libslub.slub.sb as sb\nimportlib.reload(sb)\nimport libslub.slub.kmem_cache_cpu as kcc\nimportlib.reload(kcc)\nimport libslub.slub.kmem_cache_node as kcn\nimportlib.reload(kcn)\nimport libslub.slub.page as p\nimportlib.reload(p)\n", "importlib.reload(p)\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"sbcache.py\")\n\nclass kmem_cache(hs.heap_structure):\n    \"\"\"python representation of a struct kmem_cache\n    \n    struct kmem_cache {: https://elixir.bootlin.com/linux/v5.15/source/include/linux/slub_def.h#L90\"\"\"\n\n    def __init__(self, sb, value=None, address=None):\n        \"\"\"\n        Parse kmem_cache's data and initialize the kmem_cache object\n\n        :param sb: slab object holding all our useful info\n        :param value: gdb.Value of type kmem_cache with structure's content read from the debugger (represented by a dictionary)\n        :param address: address for a kmem_cache where to read the structure's content from the debugger (not supported yet)\n        \"\"\"\n\n        super(kmem_cache, self).__init__(sb)\n\n        # kmem_cache structure's fields can be looked up directly from the gdb.Value\n        self.value = value # gdb.Value representing the kmem_cache\n\n        self.init()\n\n    def init(self):\n\n        # our own abstraction fields\n        self.address = int(self.value.address) & sb.sb.UNSIGNED_LONG\n        self.name = self.value[\"name\"].string() # slab cache name (e.g. \"kmalloc-1k\")\n        log.debug(f\"kmem_cache.init({self.name})\")\n        self.flags = int(self.value[\"flags\"]) & sb.sb.UNSIGNED_LONG\n        self.offset = int(self.value[\"offset\"]) # Free pointer offset\n        self.size = int(self.value[\"size\"]) # The size of an object including metadata\n        self.object_size = int(self.value[\"object_size\"]) # The size of an object without metadata\n\n        self.kmem_cache_cpu_list = [] # list of kmem_cache_cpu objects for that kmem_cache\n        # browse the list of gdb.Value (representing the kmem_cache_cpu structure linked list for that kmem_cache)\n        for cpu_id, cache_cpu_value in enumerate(self.sb.get_all_slab_cache_cpus(self.value)):\n            kmem_cache_cpu = kcc.kmem_cache_cpu(self.sb, cpu_id, self, cache_cpu_value)\n            self.kmem_cache_cpu_list.append(kmem_cache_cpu)\n\n\n        self.kmem_cache_node_list = [] # list of kmem_cache_node objects for that kmem_cache\n        for node_id in range(self.sb.node_num):\n            node_value = self.value[\"node\"][node_id] # gdb.value representing kmem_cache->node[node_id] (struct kmem_cache_node *)\n            kmem_cache_node = kcn.kmem_cache_node(self.sb, node_id, kmem_cache=self, value=node_value)\n            self.kmem_cache_node_list.append(kmem_cache_node)\n\n        # NOTE: There will only be full slabs if one of the following condition is met:\n        # - there is/was a watch on a given slab. See 'slab watch' command logic for details\n        # - slabs were logged with the sbslabdb command\n        # XXX - Ideally we would need to track the full slabs per kmem_cache_node\n        # but we don't have that granularity yet\n        self.full_slabs = [] # the full slabs\n        full_slabs_values = list(self.sb.get_full_slabs(self.name))\n        slab_count = len(full_slabs_values)\n        for slab_index, full_slab_value in enumerate(full_slabs_values):\n            full_slab = p.page(self.sb, self, None, None, sb.SlabType.FULL_SLAB, index=slab_index+1, count=slab_count, value=full_slab_value)\n            self.full_slabs.append(full_slab)\n\n    def print(self, verbose=0, use_cache=False, cmd=None):\n        \"\"\"Pretty printer for the kmem_cache supporting different level of verbosity\n\n        :param verbose: 0 for non-verbose. 1 for more verbose. 2 for even more verbose.\n        :param use_cache: True if we want to use the cached information from the cache object.\n                          False if we want to fetch the data again\n        :param cmd: cmd.args == arguments so we know what options have been passed by the user\n                     e.g. to print hexdump of objects/chunks, highlight chunks, etc.\n        \"\"\"\n\n        if cmd.args.object_only is not True:\n            title = \"struct kmem_cache @ 0x%x {\" % self.address\n            txt = pu.color_title(title)\n            txt += \"\\n  {:11} = \".format(\"name\")\n            txt += pu.color_value(\"{:s}\".format(self.name))\n            txt += \"\\n  {:11} = \".format(\"flags\")\n            flags_list = sb.sb.get_flags_list(self.flags)\n            if flags_list:\n                txt += pu.color_value(\"{:s}\".format(\" | \".join(flags_list)))\n            else:\n                txt += pu.color_value(\"(none)\")\n\n            txt += \"\\n  {:11} = \".format(\"offset\")\n            txt += pu.color_value(\"{:#x}\".format(self.offset))\n            txt += \"\\n  {:11} = \".format(\"size\")\n            txt += pu.color_value(\"{:#d} ({:#x})\".format(self.size, self.size))\n            txt += \"\\n  {:11} = \".format(\"object_size\")\n            txt += pu.color_value(\"{:#d} ({:#x})\".format(self.object_size, self.object_size))\n            txt += \"\\n\"\n            print(txt, end=\"\")\n\n        for kmem_cache_cpu in self.kmem_cache_cpu_list:\n            # do not print when a cpu has no slab,\n            # especially useful with threadripper\n            if kmem_cache_cpu.main_slab == None:\n                continue\n            if (cmd.output_filtered is False or cmd.args.main_slab is True or cmd.args.partial_slab is True) and \\\n                (cmd.args.cpu is None or int(cmd.args.cpu) == kmem_cache_cpu.cpu_id):\n                kmem_cache_cpu.print(indent=2, cmd=cmd)\n\n        for kmem_cache_node in self.kmem_cache_node_list:\n            if (cmd.cpu_filtered is False and cmd.output_filtered is False) or cmd.args.node_slab is True:\n                kmem_cache_node.print(indent=2, cmd=cmd)\n\n        if (cmd.cpu_filtered is False and cmd.output_filtered is False) or cmd.args.full_slab is True:\n            # XXX - Ideally we would need to track the full slabs per kmem_cache_node\n            # but we don't have that granularity yet\n            if cmd.args.object_only is not True:\n                txt = \"  \"\n                title = \"struct kmem_cache_node @ unknown {\"\n                txt += pu.color_title(title)\n                txt += \"\\n\"\n                print(txt, end=\"\")\n            if len(self.full_slabs) == 0:\n                if cmd.args.object_only is not True:\n                    print(\"    {:8} = (none)\".format(\"full\"))\n            else:\n                for full_slab in self.full_slabs:\n                    full_slab.print(name=\"full\", indent=4, cmd=cmd)"]}
{"filename": "libslub/slub/heap_structure.py", "chunked_list": ["import logging\nimport struct\n\nlog = logging.getLogger(\"libslub\")\nlog.trace(\"heap_structure.py\")\n\nclass heap_structure(object):\n    \"\"\"Represent a general structure. Can be inherited by any structure like malloc_chunk.\n    Allow factoring of functions used by many structures, so we don't duplicate code.\n    \"\"\"\n\n    def __init__(self, sb):\n        log.trace(\"heap_structure.__init__()\")\n        self.sb = sb\n        self.initOK = True\n        self.dbg = self.sb.dbg\n\n    def validate_address(self, address):\n        \"\"\"Valid that a given address can actually be used as chunk address\n        \"\"\"\n        log.trace(\"heap_structure.validate_address()\")\n\n        if address is None or address == 0 or type(address) != int:\n            print(\"Invalid address\")\n            #raise Exception(\"Invalid address\")\n            self.initOK = False\n            self.address = None\n            return False\n        else:\n            self.address = address\n        return True"]}
