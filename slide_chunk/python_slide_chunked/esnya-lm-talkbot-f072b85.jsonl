{"filename": "setup.py", "chunked_list": ["from setuptools import setup\n\nimport talkbot\n\nsetup(\n    name=\"talkbot\",\n    version=talkbot.__version__,\n)\n", ""]}
{"filename": "talkbot/chat_engine.py", "chunked_list": ["\"\"\"Chat Engine component.\"\"\"\n\nimport asyncio\nimport json\nimport math\nimport os\nimport random\nimport re\nimport time\nfrom datetime import date", "import time\nfrom datetime import date\nfrom functools import lru_cache\nfrom typing import Any\n\nimport requests\nimport torch\nimport zmq\nfrom transformers import AutoModelForCausalLM, T5Tokenizer\n", "from transformers import AutoModelForCausalLM, T5Tokenizer\n\nfrom .utilities.config import Config\nfrom .utilities.constants import ComponentState\nfrom .utilities.message import (\n    AssistantMessage,\n    TextMessage,\n    UserMessage,\n    is_text_message,\n    is_user_message,", "    is_text_message,\n    is_user_message,\n    update_busy_time,\n)\nfrom .utilities.socket import get_sockets, send_state\n\n\ndef is_valid_message(message) -> bool:\n    \"\"\"Check if a message is valid.\"\"\"\n    return set(message.keys()) == {\"role\", \"content\"}", "    \"\"\"Check if a message is valid.\"\"\"\n    return set(message.keys()) == {\"role\", \"content\"}\n\n\n@lru_cache(maxsize=1)\ndef load_model(\n    model_name: str, tokenizer_name: str, device: str, fp16: bool\n) -> tuple[T5Tokenizer, AutoModelForCausalLM]:\n    \"\"\"Load model.\"\"\"\n    tokenizer: T5Tokenizer = T5Tokenizer.from_pretrained(  # type: ignore", "    \"\"\"Load model.\"\"\"\n    tokenizer: T5Tokenizer = T5Tokenizer.from_pretrained(  # type: ignore\n        tokenizer_name or model_name,\n        use_fast=False,\n    )\n    tokenizer.do_lower_case = True  # type: ignore\n\n    model: AutoModelForCausalLM = AutoModelForCausalLM.from_pretrained(model_name).to(device)  # type: ignore\n    if fp16:\n        model = model.half()", "    if fp16:\n        model = model.half()\n    model.eval()\n\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n    return (tokenizer, model)\n\n", "\n\nasync def chat_engine(config: Config = Config()):\n    \"\"\"Chat Engine component.\"\"\"\n    logger = config.get_logger(\"ChatEngine\")\n    logger.info(\"Initializing\")\n\n    with get_sockets(\n        config,\n        1,", "        config,\n        1,\n    ) as (write_socket, read_socket):\n        model_name = config.get(\"chat_engine.model\")\n        tokenizer_name = config.get(\"chat_engine.tokenizer\", model_name)\n        device = config.get(\"chat_engine.device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n        logger.info(\"Loading model: %s (%s)\", model_name, device)\n        load_model(model_name, tokenizer_name, device, config.get(\"chat_engine.fp16\", False))\n\n        def _get_history_filename() -> str:", "\n        def _get_history_filename() -> str:\n            \"\"\"Get the history filename.\"\"\"\n            model_name = config.get(\"chat_engine.model\", \"history\")\n            pattern = r\"checkpoint.*|-pruned.*\"\n            model_name = re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", model_name).strip(\"_\")\n            model_name = re.sub(pattern, \"\", model_name)\n            default = f\"history/{model_name}.jsonl\" if model_name else \"history.jsonl\"\n            return config.get(\"chat_engine.history.file\", default)\n", "            return config.get(\"chat_engine.history.file\", default)\n\n        def _parse_history_line(line: str) -> TextMessage | None:\n            \"\"\"Parse a line from the history file.\"\"\"\n            try:\n                message = json.loads(line)\n                if not is_text_message(message):\n                    return None\n                return message\n            except json.JSONDecodeError:", "                return message\n            except json.JSONDecodeError:\n                return None\n\n        _history: list[TextMessage] = []\n\n        def _get_chat_history() -> list[TextMessage]:\n            \"\"\"Get the chat history.\"\"\"\n            nonlocal _history\n            if not _history:", "            nonlocal _history\n            if not _history:\n                if os.path.exists(_get_history_filename()):\n                    with open(_get_history_filename(), \"r\", encoding=\"utf-8\") as file:\n                        _history = [message for message in [_parse_history_line(line) for line in file] if message]\n                else:\n                    _history = []\n\n            return _history\n", "            return _history\n\n        def _append_history(message: TextMessage) -> None:\n            \"\"\"Append a message to the history file.\"\"\"\n            nonlocal _history\n            if not is_valid_message(message):\n                raise TypeError(f\"Invalid message: {message}\")\n\n            _history.append(message)\n            with open(_get_history_filename(), \"a+\", encoding=\"utf-8\") as file:", "            _history.append(message)\n            with open(_get_history_filename(), \"a+\", encoding=\"utf-8\") as file:\n                file.write(json.dumps(message, ensure_ascii=False))\n                file.write(\"\\n\")\n\n        def _format_messages(messages: list[TextMessage]) -> list[str]:\n            \"\"\"Format messages for the model.\"\"\"\n            return [\n                config.get(f\"chat_engine.message_formats.{message['role']}\", \"{}\").format(message[\"content\"])\n                for message in messages", "                config.get(f\"chat_engine.message_formats.{message['role']}\", \"{}\").format(message[\"content\"])\n                for message in messages\n                if message[\"role\"] != \"system\"\n            ]\n\n        @torch.no_grad()\n        def _generate(\n            received_message: list[TextMessage],\n            history: list[TextMessage],\n        ) -> str | None:", "            history: list[TextMessage],\n        ) -> str | None:\n            \"\"\"Generate a response from the model.\"\"\"\n            tokenizer_name = config.get(\"chat_engine.tokenizer\", model_name)\n            device = config.get(\n                \"chat_engine.device\",\n                \"cuda\" if torch.cuda.is_available() else \"cpu\",\n            )\n            logger.debug(\"Loading model: %s (%s)\", model_name, device)\n            (tokenizer, model) = load_model(model_name, tokenizer_name, device, config.get(\"chat_engine.fp16\", False))", "            logger.debug(\"Loading model: %s (%s)\", model_name, device)\n            (tokenizer, model) = load_model(model_name, tokenizer_name, device, config.get(\"chat_engine.fp16\", False))\n\n            input_text = config.get(\"chat_engine.message_separator\", \"\").join(\n                _format_messages(history + received_message) + config.get(\"chat_engine.suffix_messages\", [])\n            )\n\n            logger.info(\"Generating from: %s\", input_text)\n\n            logger.debug(\"Encoding\")", "\n            logger.debug(\"Encoding\")\n            input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", add_special_tokens=False).to(  # type: ignore\n                model.device  # type: ignore\n            )\n            logger.debug(\"Generating: input={%s}\", tokenizer.batch_decode(input_ids))\n            generation_config: dict[str, Any] = config.get(\n                \"chat_engine.generation_config\",\n                dict[str, Any](),\n            )", "                dict[str, Any](),\n            )\n            output_ids = model.generate(  # type: ignore\n                input_ids,\n                **generation_config,\n            )\n            loss = model(output_ids, labels=output_ids).loss.item()  # type: ignore\n            logger.info(\"Loss: %s\", loss)\n            if math.isnan(loss) or loss > config.get(\"chat_engine.max_loss\", 10):\n                return None", "            if math.isnan(loss) or loss > config.get(\"chat_engine.max_loss\", 10):\n                return None\n\n            output_token_count = len(output_ids[0]) - len(input_ids[0])\n            logger.debug(\"Decoding %s tokens: %s\", output_token_count, tokenizer.batch_decode(output_ids))\n            output_text = tokenizer.decode(output_ids[0][len(input_ids[0]) :])\n\n            logger.debug(\"Formatting\")\n            end_match = re.search(config.get(\"chat_engine.stop_pattern\", \"</s>\"), output_text)\n            logger.debug(end_match)", "            end_match = re.search(config.get(\"chat_engine.stop_pattern\", \"</s>\"), output_text)\n            logger.debug(end_match)\n            content = output_text[: end_match.start()] if end_match else output_text\n\n            max_length = config.get(\"chat_engine.content_max_length\")\n            if max_length and len(content) > max_length:\n                return None\n\n            return content\n", "            return content\n\n        async def _process_command(message: AssistantMessage) -> str | None:\n            \"\"\"Process a command.\"\"\"\n            try:\n                if not message[\"role\"] == \"assistant\":\n                    return\n\n                match = re.search(r\"(?<=<req>) *[A-Z]+\", message[\"content\"])\n                if not match:", "                match = re.search(r\"(?<=<req>) *[A-Z]+\", message[\"content\"])\n                if not match:\n                    return None\n                command = match.group(0).strip()\n\n                timeout = config.get(\"chat_engine.command.http_timeout\")\n\n                match (command):\n                    case \"DATE\":\n                        return f\"{date.today()}\"", "                    case \"DATE\":\n                        return f\"{date.today()}\"\n                    case \"WEATHER\":\n                        res = requests.get(\n                            \"https://weather.tsukumijima.net/api/forecast?city=130010\",\n                            timeout=timeout,\n                        ).json()\n                        weather = (\n                            res[\"forecasts\"][0][\"dateLabel\"] + \"\u306e\" + res[\"title\"] + \"\u306f\" + res[\"forecasts\"][0][\"telop\"]\n                        )", "                            res[\"forecasts\"][0][\"dateLabel\"] + \"\u306e\" + res[\"title\"] + \"\u306f\" + res[\"forecasts\"][0][\"telop\"]\n                        )\n                        await _add_assistant_message(weather)\n                        return weather\n                    case \"NEWS\":\n                        rss = requests.get(\n                            \"https://www.nhk.or.jp/rss/news/cat0.xml\",\n                            timeout=timeout,\n                        ).text\n                        titles = re.findall(r\"(?<=<title>).*(?=</title>)\", rss)[1:]", "                        ).text\n                        titles = re.findall(r\"(?<=<title>).*(?=</title>)\", rss)[1:]\n                        random.shuffle(titles)\n                        title = titles[0]\n                        await _add_assistant_message(title + \" \uff08NHK\u30cb\u30e5\u30fc\u30b9\uff09\")\n                        return title\n                return None\n            except requests.HTTPError as err:\n                logger.error(err)\n                return None", "                logger.error(err)\n                return None\n\n        async def _add_assistant_message(content: str) -> AssistantMessage:\n            assistant_message_json = AssistantMessage(\n                role=\"assistant\",\n                content=content,\n            )\n            _append_history(assistant_message_json)\n            logger.info(assistant_message_json)", "            _append_history(assistant_message_json)\n            logger.info(assistant_message_json)\n            await write_socket.send_json(assistant_message_json)\n            return assistant_message_json\n\n        async def _process_messages(messages: list[TextMessage]) -> AssistantMessage | None:\n            max_history_count = config.get(\"chat_engine.history.max_count\") or 0\n            history = _get_chat_history()[-max_history_count:] if max_history_count else []\n\n            for message in messages:", "\n            for message in messages:\n                logger.info(\"Message: %s\", message)\n                _append_history(message)\n\n            for _ in range(0, 10):\n                logger.info(\"Generating\")\n\n                content = await asyncio.to_thread(\n                    _generate,", "                content = await asyncio.to_thread(\n                    _generate,\n                    messages,\n                    history,\n                )\n                if content:\n                    return await _add_assistant_message(content)\n\n                logger.warning(\"Failed to generate\")\n", "                logger.warning(\"Failed to generate\")\n\n            return None\n\n        prev_time = time.time()\n        message_buffer: list[TextMessage] = []\n        last_stt_busy_time = 0\n        last_tts_busy_time = 0\n        logger.info(\"Started\")\n        await send_state(write_socket, \"ChatEngine\", ComponentState.READY)", "        logger.info(\"Started\")\n        await send_state(write_socket, \"ChatEngine\", ComponentState.READY)\n        while not write_socket.closed and not read_socket.closed:\n            while True:\n                try:\n                    message = await read_socket.recv_json()\n                    if is_user_message(message):\n                        message_buffer.append(message)\n                    else:\n                        last_stt_busy_time = update_busy_time(message, \"AudioToMessage\", last_stt_busy_time)", "                    else:\n                        last_stt_busy_time = update_busy_time(message, \"AudioToMessage\", last_stt_busy_time)\n                        last_tts_busy_time = update_busy_time(message, \"MessageToSpeak\", last_tts_busy_time)\n                except zmq.error.Again:\n                    break\n\n            current_time = time.time()\n\n            if (\n                message_buffer", "            if (\n                message_buffer\n                and current_time - prev_time >= config.get(\"chat_engine.min_interval\", 30)\n                and time.time() - last_stt_busy_time > config.get(\"global.busy_timeout\", 30)\n                and time.time() - last_tts_busy_time > config.get(\"global.busy_timeout\", 30)\n            ):\n                await send_state(write_socket, \"ChatEngine\", ComponentState.BUSY)\n\n                prev_time = current_time\n", "                prev_time = current_time\n\n                assistant_message = await _process_messages(message_buffer)\n                message_buffer = []\n\n                if not assistant_message:\n                    continue\n\n                command_result = await _process_command(assistant_message)\n                if command_result:", "                command_result = await _process_command(assistant_message)\n                if command_result:\n                    await _process_messages([UserMessage(role=\"user\", content=\"<res>\" + command_result)])\n\n                await send_state(write_socket, \"ChatEngine\", ComponentState.READY)\n\n                await asyncio.sleep(config.get(\"chat_engine.sleep_after_completion\", 0))\n\n                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()", "                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()\n            else:\n                await asyncio.sleep(1)\n"]}
{"filename": "talkbot/__main__.py", "chunked_list": ["\"\"\"Talkbot main entry point.\"\"\"\n\nimport asyncio\nimport signal\nfrom typing import Any, Callable, Coroutine\n\nfrom .audio_to_message import audio_to_message\nfrom .bridge import bridge\nfrom .chat_engine import chat_engine\nfrom .console import console", "from .chat_engine import chat_engine\nfrom .console import console\nfrom .message_stream import message_stream\nfrom .message_to_speak import message_to_speak\nfrom .neos_connector import neos_connector\nfrom .prune import prune\nfrom .train import train\nfrom .utilities.asyncargh import AsyncArghParser\nfrom .utilities.config import Config\n", "from .utilities.config import Config\n\nCOMPONENTS: list[Callable[..., Coroutine[Any, Any, Any]]] = [\n    neos_connector,\n    audio_to_message,\n    message_to_speak,\n    chat_engine,\n    message_stream,\n]\n", "]\n\n\nasync def run(config: Config = Config()):\n    \"\"\"Talkbot main entry point.\"\"\"\n    tasks = [asyncio.create_task(component(config=config)) for component in COMPONENTS]\n\n    if not tasks:\n        raise ValueError(\"No components to run\")\n", "\n    await asyncio.gather(*tasks)\n\n\nasync def run_bridge(\n    config1: Config = Config(),\n    config2: Config = Config(),\n    sleep: float = 10.0,\n    no_whisper: bool = False,\n):", "    no_whisper: bool = False,\n):\n    \"\"\"Run a bridge between two talkbots.\"\"\"\n    tasks = [\n        bridge(config1=config1, config2=config2, sleep=sleep),\n        *[(component(config=config1)) for component in COMPONENTS if not no_whisper or component != audio_to_message],\n        *[(component(config=config2)) for component in COMPONENTS if component != audio_to_message],\n    ]\n\n    await asyncio.gather(*[asyncio.create_task(task) for task in tasks])", "\n    await asyncio.gather(*[asyncio.create_task(task) for task in tasks])\n\n\ndef _on_sigint(*_):\n    \"\"\"Handle SIGINT.\"\"\"\n    for task in asyncio.all_tasks():\n        task.cancel()\n\n", "\n\nsignal.signal(signal.SIGINT, _on_sigint)\n\nparser = AsyncArghParser()\nparser.add_async_commands(COMPONENTS)\nparser.add_async_commands([run])\nparser.add_async_commands([console])\nparser.add_async_commands([train])\nparser.add_async_commands([prune])", "parser.add_async_commands([train])\nparser.add_async_commands([prune])\nparser.add_async_commands([run_bridge])\nparser.set_async_default_command(run)\nparser.dispatch()\n"]}
{"filename": "talkbot/train.py", "chunked_list": ["\"\"\"Train a model for chatbot.\"\"\"\n\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    DataCollatorForLanguageModeling,\n    GPT2LMHeadModel,\n    T5Tokenizer,\n    Trainer,", "    T5Tokenizer,\n    Trainer,\n    TrainerCallback,\n    TrainingArguments,\n)\n\nfrom .utilities.config import Config\n\n\nasync def train(config: Config = Config()) -> None:", "\nasync def train(config: Config = Config()) -> None:\n    \"\"\"Train a model for chatbot.\"\"\"\n\n    logger = config.get_logger(\"Train\")\n\n    if torch.cuda.is_available():\n        logger.info(\"Initializing CUDA...\")\n        torch.cuda.init()\n        logger.info(\"CUDA initialized\")", "\n    logger.info(\"Loading base model...\")\n    model: GPT2LMHeadModel = AutoModelForCausalLM.from_pretrained(config.get(\"train.base_model\"))\n    logger.info(\"Base model loaded\")\n\n    logger.info(\"Loading tokenizer...\")\n    tokenizer = T5Tokenizer.from_pretrained(config.get(\"train.base_model\", required=True))\n    tokenizer.do_lower_case = True\n    logger.info(\"Tokenizer loaded\")\n", "    logger.info(\"Tokenizer loaded\")\n\n    logger.info(\"Adding special tokens...\")\n    tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<user>\", \"<ai>\", \"<req>\", \"<res>\"]})\n    logger.info(tokenizer.special_tokens_map)\n    model.resize_token_embeddings(len(tokenizer))\n    logger.info(\"Special tokens added\")\n\n    logger.info(\"Generating training dataset...\")\n", "    logger.info(\"Generating training dataset...\")\n\n    dataset = []\n    with open(config.get(\"train.csv_file\", required=True), \"r\", encoding=\"utf-8\") as src:\n        logger.info(\"Loading training data: (header=%s)\", next(src))\n        for i, line in enumerate(src, 1):\n            if not line:\n                continue\n            try:\n                prompt, completion = [\n                    col.strip(\"\u300c\u300d\\n\\t \u3001\u3002,.\").replace(\"\u300c\", \"\u300e\").replace(\"\u300d\", \"\u300f\") for col in line.split(\",\")\n                ]\n                if not prompt or not completion:\n                    continue\n                dataset.append((f\"<user>{prompt}\", f\"<ai>{completion}\"))\n            except Exception as err:\n                logger.fatal(\"Failed to parse line (%d): %s\", i + 1, line)\n                logger.fatal(err)\n                raise", "\n    if config.get(\"train.generate_pairs\", True):\n        logger.info(\"Generating pairs...\")\n        for i in range(len(dataset) - 1):\n            left_prompt, left_completion = dataset[i]\n            right_prompt, right_completion = dataset[i + 1]\n            dataset.append((left_prompt + left_completion + right_prompt, right_completion))\n\n    logger.debug(\"Dataset: %s\", dataset)\n", "    logger.debug(\"Dataset: %s\", dataset)\n\n    train_dataset: Dataset = Dataset.from_dict(\n        tokenizer.batch_encode_plus(dataset, padding=True, truncation=True, return_tensors=\"pt\")\n    )\n\n    logger.info(\"Training dataset generated: %s\", train_dataset)\n\n    logger.info(\"Initializing trainer...\")\n    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, **config.get(\"train.data_collator\", {}))", "    logger.info(\"Initializing trainer...\")\n    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, **config.get(\"train.data_collator\", {}))\n\n    training_args = TrainingArguments(**config.get(\"train.training_args\", {}))\n\n    generation_config = config.get(\"chat_engine.generation_config\", {})\n\n    class Callback(TrainerCallback):\n        \"\"\"Callback to test the model after each epoch.\"\"\"\n\n        def on_epoch_end(self, *args, **kwargs):\n            \"\"\"Test the model after each epoch.\"\"\"\n\n            for text in config.get(\"train.test_inputs\", []):\n                input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n                output_ids = model.generate(input_ids, **generation_config)\n                logger.info(tokenizer.decode(output_ids[0], skip_special_tokens=False))", "\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        data_collator=data_collator,\n        train_dataset=train_dataset,  # type: ignore\n        callbacks=[Callback()],\n    )\n    logger.info(\"Trainer initialized\")\n", "    logger.info(\"Trainer initialized\")\n\n    logger.info(\"Saving tokenizer...\")\n    tokenizer.save_pretrained(config.get(\"train.training_args.output_dir\"))\n    logger.info(\"Tokenizer saved\")\n\n    logger.info(\"Training...\")\n    trainer.train()\n    logger.info(\"Training completed\")\n", "    logger.info(\"Training completed\")\n\n    logger.info(\"Saving models...\")\n    trainer.save_state()\n    trainer.save_model()\n    logger.info(\"Model saved\")\n\n    logger.info(\"Saving tokenizer...\")\n    tokenizer.save_pretrained(config.get(\"train.training_args.output_dir\"))\n    logger.info(\"Tokenizer saved\")", "    tokenizer.save_pretrained(config.get(\"train.training_args.output_dir\"))\n    logger.info(\"Tokenizer saved\")\n"]}
{"filename": "talkbot/audio_to_message.py", "chunked_list": ["\"\"\"Audio To Message component.\"\"\"\n\nimport asyncio\nimport math\nfrom functools import lru_cache\nfrom typing import Any, TypedDict, TypeGuard\n\nimport numpy as np\nimport pyaudio\nimport torch", "import pyaudio\nimport torch\nimport whisper\nimport zmq\nfrom pyannote.audio.pipelines import VoiceActivityDetection\nfrom pyannote.core.annotation import Annotation\nfrom whisper.audio import N_SAMPLES, SAMPLE_RATE\n\nfrom .utilities.audio import get_device_by_name, get_pa, open_stream\nfrom .utilities.config import Config", "from .utilities.audio import get_device_by_name, get_pa, open_stream\nfrom .utilities.config import Config\nfrom .utilities.constants import ComponentState\nfrom .utilities.message import UserMessage, is_busy, update_busy_time\nfrom .utilities.socket import get_sockets, send_state\n\n\nclass DecodingResultSegment(TypedDict):\n    \"\"\"Decoding result segment.\"\"\"\n\n    text: str\n    compression_ratio: float\n    avg_logprob: float\n    no_speech_prob: float\n    temperature: float", "\n\ndef is_whisper_result_segment(value) -> TypeGuard[DecodingResultSegment]:\n    return isinstance(value, dict) and \"text\" in value\n\n\nasync def async_read_mic_input(stream: pyaudio.Stream, chunk: int) -> np.ndarray:\n    \"\"\"Read a chunk of audio from the microphone input stream.\"\"\"\n    data = await asyncio.to_thread(stream.read, chunk)\n    return np.frombuffer(data, dtype=np.float32)", "    data = await asyncio.to_thread(stream.read, chunk)\n    return np.frombuffer(data, dtype=np.float32)\n\n\nasync def audio_to_message(config: Config = Config()) -> None:\n    \"\"\"Convert audio to text messages.\"\"\"\n    logger = config.get_logger(\"AudioToMessage\")\n    logger.info(\"Initializing...\")\n\n    @lru_cache(maxsize=1)\n    def load_model(model_name: str | None = None, device: str | None = None):\n        logger.info(\"Loading model %s (%s) ...\", model_name, device)\n\n        if device == \"cuda\" and not torch.cuda.is_initialized():\n            logger.info(\"Initializing CUDA...\")\n            torch.cuda.init()\n\n        return whisper.load_model(model_name or \"base\", device=device)", "\n    @lru_cache(maxsize=1)\n    def load_model(model_name: str | None = None, device: str | None = None):\n        logger.info(\"Loading model %s (%s) ...\", model_name, device)\n\n        if device == \"cuda\" and not torch.cuda.is_initialized():\n            logger.info(\"Initializing CUDA...\")\n            torch.cuda.init()\n\n        return whisper.load_model(model_name or \"base\", device=device)", "\n    load_model(\n        config.get(\"audio_to_message.whisper.model\", \"base\"),\n        config.get(\n            \"audio_to_message.whisper.device\",\n            \"cuda\" if torch.cuda.is_available() else \"cpu\",\n        ),\n    )\n\n    logger.info(\"Loading VAD pipeline\")", "\n    logger.info(\"Loading VAD pipeline\")\n    vad_pipeline = VoiceActivityDetection(**config.get(\"audio_to_message.vad.pipeline\", {}))\n    vad_pipeline.instantiate(config.get(\"audio_to_message.vad.hyper_parameters\", {}))\n\n    def filter_segment(\n        segment: Any,\n    ) -> TypeGuard[DecodingResultSegment]:\n        if not is_whisper_result_segment(segment):\n            return False\n\n        text: str = segment[\"text\"]\n        compression_ratio: float = segment[\"compression_ratio\"]\n        avg_logprob: float = segment[\"avg_logprob\"]\n        no_speech_prob: float = segment[\"no_speech_prob\"]\n        temperature: float = segment[\"temperature\"]\n        logger.info(\n            \"Seg: comp=%.3f logprob=%.3f no_speech=%.3f temp=%.3f %s\",\n            compression_ratio,\n            avg_logprob,\n            no_speech_prob,\n            temperature,\n            text,\n        )\n        return (\n            bool(text)\n            and text not in config.get(\"audio_to_message.whisper.blacklist\", [])\n            and math.isfinite(compression_ratio * avg_logprob * no_speech_prob)\n            and temperature <= config.get(\"audio_to_message.whisper.max_temperature\", 1.0)\n        )", "\n    _initial_prompt: str | None = None\n\n    def transcribe(data: np.ndarray) -> list[str] | None:\n        nonlocal _initial_prompt\n\n        if np.max(data) - np.min(data) <= config.get(\"audio_to_message.min_volume\", 0.01):\n            return None\n\n        model = load_model(\n            config.get(\"audio_to_message.whisper.model\", \"base\"),\n            config.get(\n                \"audio_to_message.whisper.device\",\n                \"cuda\" if torch.cuda.is_available() else \"cpu\",\n            ),\n        )\n        logger.info(\"Transcribing: frames=%d\", data.size)\n        result = whisper.transcribe(\n            model, data, initial_prompt=_initial_prompt, **config.get(\"audio_to_message.whisper.decode_config\", {})\n        )\n\n        segments = [segment.get(\"text\") for segment in result[\"segments\"] if filter_segment(segment)]\n        if segments:\n            _initial_prompt = (_initial_prompt or \"\") + \" \".join(segments)\n\n        prompt_length: int = config.get(\"audio_to_message.whisper.prompt_length\") or 0\n        if prompt_length is None or prompt_length == 0:\n            _initial_prompt = None\n        else:\n            _initial_prompt = ((_initial_prompt or \"\") + \"\\n\")[-prompt_length:]\n\n        return segments", "\n    buffer = np.empty((0,), np.float32)\n\n    device_name: str | None = config.get(\"audio_to_message.input_device.name\")\n    device_index = 0\n    if device_name is not None:\n        device_index = get_device_by_name(device_name, min_input_channels=1)\n\n    def stream_callback(in_data: bytes, frame_count: int, time_info, status):\n        nonlocal buffer\n\n        audio_data = np.frombuffer(in_data, dtype=np.float32)\n        buffer = np.concatenate((buffer, audio_data))\n\n        return (audio_data, pyaudio.paContinue)", "    def stream_callback(in_data: bytes, frame_count: int, time_info, status):\n        nonlocal buffer\n\n        audio_data = np.frombuffer(in_data, dtype=np.float32)\n        buffer = np.concatenate((buffer, audio_data))\n\n        return (audio_data, pyaudio.paContinue)\n\n    _stream_frames_per_buffer = config.get(\"audio_to_message.input_device.frames_per_buffer\", 1024)\n    with get_sockets(config, 0.5) as (write_socket, read_socket), open_stream(\n        format=pyaudio.paFloat32,\n        channels=1,\n        rate=SAMPLE_RATE,\n        input=True,\n        input_device_index=device_index,\n        frames_per_buffer=_stream_frames_per_buffer,\n        stream_callback=stream_callback,\n    ) as stream:\n        last_busy_time = 0.0\n        logger.info(\"Initialized\")\n        stream.start_stream()\n        logger.info(\"Started: recording device i %s\", get_pa().get_device_info_by_index(device_index))\n        await send_state(write_socket, \"AudioToMessage\", ComponentState.READY)\n        while not write_socket.closed and not read_socket.closed:\n            try:\n                message = await read_socket.recv_json()\n                last_busy_time = update_busy_time(message, \"ChatEngine\", last_busy_time)\n            except zmq.error.Again:\n                pass\n\n            if buffer.size <= 1:\n                continue\n\n            silence_duration = config.get(\"message_to_message.silence_duration\", 1.0)\n\n            max_buffer_size: int = config.get(\"audio_to_message.max_buffer_size\", N_SAMPLES)\n\n            if is_busy(last_busy_time, config.get(\"global.busy_timeout\", 30.0)):\n                await asyncio.sleep(1)\n                continue\n\n            try:\n                vad: Annotation = vad_pipeline(\n                    {\"waveform\": torch.from_numpy(buffer.reshape((1, -1))), \"sample_rate\": SAMPLE_RATE}\n                )\n                timeline = vad.get_timeline(False)\n                segments: list[tuple[(int, int)]] = [\n                    (max(int((seg.start - 0.5) * SAMPLE_RATE), 0), int(math.ceil((seg.end + 0.5) * SAMPLE_RATE)))\n                    for seg in timeline  # type: ignore\n                ]\n\n                if len(segments) == 0:\n                    continue\n\n                left = segments[0][0]\n                right = segments[-2][1] if len(segments) >= 2 else segments[-1][1]\n                if (\n                    len(segments) >= 2\n                    or right - left >= max_buffer_size\n                    or buffer.size - right >= silence_duration * SAMPLE_RATE\n                ):\n                    await send_state(write_socket, \"AudioToMessage\", ComponentState.BUSY)\n                    results = await asyncio.to_thread(transcribe, buffer[left:right])\n                    buffer = buffer[right:]\n                    if results:\n                        for text in results:\n                            await write_socket.send_json(\n                                UserMessage(\n                                    role=\"user\",\n                                    content=text,\n                                )\n                            )\n                    await send_state(write_socket, \"AudioToMessage\", ComponentState.READY)\n\n                    if torch.cuda.is_available():\n                        torch.cuda.empty_cache()\n                elif left > 0:\n                    buffer = buffer[left:]\n            except (RuntimeError, ValueError) as err:\n                logger.error(\"%s: %s\", type(err), err, exc_info=True)\n                buffer = np.empty((0,), np.float32)\n                continue", "    _stream_frames_per_buffer = config.get(\"audio_to_message.input_device.frames_per_buffer\", 1024)\n    with get_sockets(config, 0.5) as (write_socket, read_socket), open_stream(\n        format=pyaudio.paFloat32,\n        channels=1,\n        rate=SAMPLE_RATE,\n        input=True,\n        input_device_index=device_index,\n        frames_per_buffer=_stream_frames_per_buffer,\n        stream_callback=stream_callback,\n    ) as stream:\n        last_busy_time = 0.0\n        logger.info(\"Initialized\")\n        stream.start_stream()\n        logger.info(\"Started: recording device i %s\", get_pa().get_device_info_by_index(device_index))\n        await send_state(write_socket, \"AudioToMessage\", ComponentState.READY)\n        while not write_socket.closed and not read_socket.closed:\n            try:\n                message = await read_socket.recv_json()\n                last_busy_time = update_busy_time(message, \"ChatEngine\", last_busy_time)\n            except zmq.error.Again:\n                pass\n\n            if buffer.size <= 1:\n                continue\n\n            silence_duration = config.get(\"message_to_message.silence_duration\", 1.0)\n\n            max_buffer_size: int = config.get(\"audio_to_message.max_buffer_size\", N_SAMPLES)\n\n            if is_busy(last_busy_time, config.get(\"global.busy_timeout\", 30.0)):\n                await asyncio.sleep(1)\n                continue\n\n            try:\n                vad: Annotation = vad_pipeline(\n                    {\"waveform\": torch.from_numpy(buffer.reshape((1, -1))), \"sample_rate\": SAMPLE_RATE}\n                )\n                timeline = vad.get_timeline(False)\n                segments: list[tuple[(int, int)]] = [\n                    (max(int((seg.start - 0.5) * SAMPLE_RATE), 0), int(math.ceil((seg.end + 0.5) * SAMPLE_RATE)))\n                    for seg in timeline  # type: ignore\n                ]\n\n                if len(segments) == 0:\n                    continue\n\n                left = segments[0][0]\n                right = segments[-2][1] if len(segments) >= 2 else segments[-1][1]\n                if (\n                    len(segments) >= 2\n                    or right - left >= max_buffer_size\n                    or buffer.size - right >= silence_duration * SAMPLE_RATE\n                ):\n                    await send_state(write_socket, \"AudioToMessage\", ComponentState.BUSY)\n                    results = await asyncio.to_thread(transcribe, buffer[left:right])\n                    buffer = buffer[right:]\n                    if results:\n                        for text in results:\n                            await write_socket.send_json(\n                                UserMessage(\n                                    role=\"user\",\n                                    content=text,\n                                )\n                            )\n                    await send_state(write_socket, \"AudioToMessage\", ComponentState.READY)\n\n                    if torch.cuda.is_available():\n                        torch.cuda.empty_cache()\n                elif left > 0:\n                    buffer = buffer[left:]\n            except (RuntimeError, ValueError) as err:\n                logger.error(\"%s: %s\", type(err), err, exc_info=True)\n                buffer = np.empty((0,), np.float32)\n                continue", "\n    logger.info(\"Terminated\")\n"]}
{"filename": "talkbot/neos_connector.py", "chunked_list": ["\"\"\"Neos Connector component\"\"\"\n\nimport time\n\nimport zmq\nfrom websockets.exceptions import ConnectionClosedError\nfrom websockets.server import WebSocketServerProtocol, serve\n\nfrom talkbot.utilities.message import is_state_message\n", "from talkbot.utilities.message import is_state_message\n\nfrom .utilities.config import Config\nfrom .utilities.constants import ComponentState\nfrom .utilities.socket import get_read_socket\n\n\nasync def neos_connector(config: Config = Config()):\n    \"\"\"Connects to Neos and sends messages to the chat engine.\"\"\"\n", "    \"\"\"Connects to Neos and sends messages to the chat engine.\"\"\"\n\n    logger = config.get_logger(\"NeosConnector\")\n    logger.info(\"Initializing\")\n\n    ws_connections: set[WebSocketServerProtocol] = set()\n\n    async def _handle_socket(websocket: WebSocketServerProtocol):\n        await websocket.send(\"ready\")\n        ws_connections.add(websocket)\n        try:\n            await websocket.wait_closed()\n        finally:\n            ws_connections.remove(websocket)", "        await websocket.send(\"ready\")\n        ws_connections.add(websocket)\n        try:\n            await websocket.wait_closed()\n        finally:\n            ws_connections.remove(websocket)\n\n    async def _ws_broadcast(message: str):\n        logger.info(\"Expression: %s\", message)\n        for connection in ws_connections:\n            try:\n                await connection.send(message)\n            except ConnectionClosedError as e:\n                logger.error(e)\n                ws_connections.remove(connection)", "        logger.info(\"Expression: %s\", message)\n        for connection in ws_connections:\n            try:\n                await connection.send(message)\n            except ConnectionClosedError as e:\n                logger.error(e)\n                ws_connections.remove(connection)\n\n    component_status: dict[str, ComponentState] = {}\n    component_status_update_time: dict[str, float] = {}", "    component_status: dict[str, ComponentState] = {}\n    component_status_update_time: dict[str, float] = {}\n\n    def is_busy(component: str):\n        state = component_status.get(component, ComponentState.READY)\n        time_passed = component and time.time() - component_status_update_time.get(component, 0)\n        state_timeout = config.get(\"neos_connector.expressions.state_timeout\", 30)\n        return state == ComponentState.BUSY and time_passed < state_timeout\n\n    def get_expression():\n        on_busy = config.get(\"neos_connector.expressions.on_busy\", {})\n        for component, expression in on_busy.items():\n            if is_busy(component):\n                return expression\n        return config.get(\"neos_connector.expressions.default\", required=True)", "\n    def get_expression():\n        on_busy = config.get(\"neos_connector.expressions.on_busy\", {})\n        for component, expression in on_busy.items():\n            if is_busy(component):\n                return expression\n        return config.get(\"neos_connector.expressions.default\", required=True)\n\n    async with serve(\n        _handle_socket,", "    async with serve(\n        _handle_socket,\n        config.get(\"neos_connector.websocket.host\"),\n        config.get(\"neos_connector.websocket.port\"),\n    ) as server:\n        with get_read_socket(config, config.get(\"neos_connector.max_interval\")) as read_socket:\n            logger.info(\"Initialized\")\n            logger.info(\"Started\")\n            while not read_socket.closed and server.is_serving():\n                await _ws_broadcast(get_expression())\n\n                try:\n                    message = await read_socket.recv_json()\n                    if not is_state_message(message):\n                        continue\n\n                    component = message.get(\"component\", \"unknown\")\n                    state = ComponentState(message.get(\"state\")) or ComponentState.READY\n                    component_status[component] = state\n                    component_status_update_time[component] = time.time()\n\n                    logger.debug(\n                        \"Status Updated: %s, %s\",\n                        component_status,\n                        component_status_update_time,\n                    )\n                except zmq.error.Again:\n                    pass", "\n        logger.info(\"Terminated\")\n"]}
{"filename": "talkbot/console.py", "chunked_list": ["\"\"\"Console for TalkBot.\"\"\"\n\nfrom transformers import AutoTokenizer\n\nfrom .utilities.audio import list_device_info, list_host_api_info\nfrom .utilities.config import Config\nfrom .utilities.socket import get_write_socket\nfrom .utilities.voicevox import speakers\n\n", "\n\nasync def console(config: Config = Config()):\n    \"\"\"Console component.\"\"\"\n    with get_write_socket(config) as socket:\n        role = \"user\"\n        while True:\n            match (input(f\"{role}> \")):\n                case value if value in [\"\\\\quit\", \"\\\\q\"]:\n                    break", "                case value if value in [\"\\\\quit\", \"\\\\q\"]:\n                    break\n                case value if value in [\"\\\\user\", \"\\\\u\"]:\n                    role = \"user\"\n                case value if value in [\"\\\\system\", \"\\\\s\"]:\n                    role = \"system\"\n                case value if value in [\"\\\\api\", \"\\\\a\"]:\n                    print(list_host_api_info(), sep=\"\\n\")\n                case value if value in [\"\\\\output\", \"\\\\o\"]:\n                    print(", "                case value if value in [\"\\\\output\", \"\\\\o\"]:\n                    print(\n                        [info for info in list_device_info() if int(info[\"maxOutputChannels\"]) > 0],\n                        sep=\"\\n\",\n                    )\n                case value if value in [\"\\\\input\", \"\\\\i\"]:\n                    print(\n                        [info for info in list_device_info() if int(info[\"maxInputChannels\"]) > 0],\n                        sep=\"\\n\",\n                    )", "                        sep=\"\\n\",\n                    )\n                case value if value in [\"\\\\voice\", \"\\\\v\"]:\n                    print(await speakers())\n                case value if value in [\"\\\\t\", \"\\\\tokens\"]:\n                    tokenizer = AutoTokenizer.from_pretrained(\n                        config.get(\"chat_engine.tokenizer\", config.get(\"chat_engine.model\")),\n                    )\n                    print(tokenizer.special_tokens_map)\n                case value if value.startswith(\"\\\\e \") or value.startswith(\"\\\\encode \"):", "                    print(tokenizer.special_tokens_map)\n                case value if value.startswith(\"\\\\e \") or value.startswith(\"\\\\encode \"):\n                    _, text = value.split(\" \", 1)\n                    print(\n                        AutoTokenizer.from_pretrained(\n                            config.get(\"chat_engine.tokenizer\", config.get(\"chat_engine.model\"))\n                        ).encode(text, add_special_tokens=False)\n                    )\n                case value:\n                    message = {", "                case value:\n                    message = {\n                        \"role\": role,\n                        \"content\": value,\n                    }\n                    await socket.send_json(message)\n"]}
{"filename": "talkbot/bridge.py", "chunked_list": ["\"\"\"Bridge between two talkbots.\"\"\"\n\nimport re\nimport time\n\nimport zmq.asyncio\n\nfrom .utilities.config import Config\nfrom .utilities.message import AssistantMessage, UserMessage, is_assistant_message\nfrom .utilities.socket import Socket, get_sockets", "from .utilities.message import AssistantMessage, UserMessage, is_assistant_message\nfrom .utilities.socket import Socket, get_sockets\n\n\nasync def bridge(config1: Config = Config(), config2: Config = Config(), sleep: float = 10.0):\n    \"\"\"Bridge between two talkbots.\"\"\"\n    logger = config1.get_logger(\"Bridge\")\n    logger.info(\"Initializing\")\n\n    async def _bridge(", "\n    async def _bridge(\n        read: Socket,\n        write: Socket,\n        remove_pattern: str,\n        log_format: str,\n        sleep: float,\n    ):\n        \"\"\"Bridge from socket1 to socket2.\"\"\"\n        start_time = time.time()", "        \"\"\"Bridge from socket1 to socket2.\"\"\"\n        start_time = time.time()\n        messages: list[UserMessage] = []\n\n        def append_message(message: AssistantMessage):\n            messages.append(\n                UserMessage(\n                    role=\"user\",\n                    content=re.sub(\n                        remove_pattern,\n                        \"\",\n                        message[\"content\"],\n                    ),\n                )\n            )\n            logger.info(log_format.format(message[\"content\"]))", "\n        while time.time() - start_time < sleep:\n            try:\n                message = await read.recv_json()\n                if is_assistant_message(message):\n                    append_message(message)\n            except zmq.error.Again:\n                pass\n\n        for msg in messages or [{\"role\": \"user\", \"content\": \" \"}]:\n            await write.send_json(msg)", "\n        for msg in messages or [{\"role\": \"user\", \"content\": \" \"}]:\n            await write.send_json(msg)\n\n    with get_sockets(config1, sleep) as (write_socket1, read_socket1), get_sockets(config2, sleep) as (\n        write_socket2,\n        read_socket2,\n    ):\n        logger.info(\"Initialized\")\n        logger.info(\"Started\")\n        while not (write_socket1.closed or write_socket2.closed or read_socket1.closed or read_socket2.closed):\n            logger.info(\"1 >>> 2\")\n            await _bridge(\n                read_socket1,\n                write_socket2,\n                config1.get(\"message_to_speak.remove_pattern\", \"\"),\n                \"\u300c{}\u300d\",\n                sleep,\n            )\n            logger.info(\"1 <<< 2\")\n            await _bridge(\n                read_socket2,\n                write_socket1,\n                config2.get(\"message_to_speak.remove_pattern\", \"\"),\n                \"\u300e{}\u300f\",\n                sleep,\n            )", "\n    logger.info(\"Terminated\")\n"]}
{"filename": "talkbot/__init__.py", "chunked_list": ["\"\"\"Talkbot components.\"\"\"\n\n__version__ = \"0.1.0\"\n\n"]}
{"filename": "talkbot/message_to_speak.py", "chunked_list": ["\"\"\"Message to speak\"\"\"\n\nimport asyncio\nimport os\nimport re\nfrom abc import ABC, abstractmethod\nfrom contextlib import AbstractContextManager\n\nimport numpy as np\nimport pyaudio", "import numpy as np\nimport pyaudio\nimport zmq\n\nfrom talkbot.utilities.message import is_assistant_message\n\nfrom .utilities.audio import get_device_by_name, get_pa\nfrom .utilities.config import Config\nfrom .utilities.constants import ComponentState\nfrom .utilities.socket import Socket, get_context, send_state", "from .utilities.constants import ComponentState\nfrom .utilities.socket import Socket, get_context, send_state\nfrom .utilities.voicevox import audio_query, synthesis, version\n\n\nclass MessageToSpeak(AbstractContextManager, ABC):\n    def __init__(self, config: Config = Config()):\n        self.config = config\n        logger = self.logger = config.get_logger(\"MessageToSpeak\")\n", "        logger = self.logger = config.get_logger(\"MessageToSpeak\")\n\n        \"\"\"Message to speak component\"\"\"\n\n        logger.info(\"Initializing\")\n\n        self.english_kana_dict: dict[str, str] = {}\n\n        english_kana_dict_filename = config.get(\"message_to_speak.english_kana_dict\")\n        if english_kana_dict_filename and os.path.exists(english_kana_dict_filename):", "        english_kana_dict_filename = config.get(\"message_to_speak.english_kana_dict\")\n        if english_kana_dict_filename and os.path.exists(english_kana_dict_filename):\n            logger.info(\"Loading English to Kana dictionary\")\n            with open(english_kana_dict_filename, \"r\", encoding=\"utf-8\") as file:\n                next(file)\n                self.english_kana_dict = {\n                    col[0].strip().lower(): col[1].strip()\n                    for col in (line.split(\",\") for line in file.readlines() if line and not line.startswith(\"#\"))\n                    if len(col) >= 2\n                }", "                    if len(col) >= 2\n                }\n                logger.info(\"Loaded English to Kana dictionary (%d entries)\", len(self.english_kana_dict))\n\n        logger.info(\"Initialized\")\n\n    def _stream_format(self):\n        return {\n            \"format\": pyaudio.paInt16,\n            \"channels\": 1,", "            \"format\": pyaudio.paInt16,\n            \"channels\": 1,\n            \"rate\": 24000,\n        }\n\n    def __enter__(self):\n        self.write_socket: Socket = get_context().socket(zmq.PUB)  # type: ignore\n        self.write_socket.connect(self.config.get(\"message_stream.write\", \"\"))\n\n        self.read_socket: Socket = get_context().socket(zmq.SUB)  # type: ignore", "\n        self.read_socket: Socket = get_context().socket(zmq.SUB)  # type: ignore\n        self.read_socket.connect(self.config.get(\"message_stream.read\", \"\"))\n        self.read_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n\n        device_name = self.config.get(\"message_to_speak.output_device.name\")\n        output_device_index = 0 if device_name is None else get_device_by_name(device_name, min_output_channels=1)\n        self.logger.debug(\n            \"Playing on: %s\",\n            get_pa().get_device_info_by_index(output_device_index),", "            \"Playing on: %s\",\n            get_pa().get_device_info_by_index(output_device_index),\n        )\n        self.stream = get_pa().open(\n            output_device_index=output_device_index,\n            output=True,\n            **self._stream_format(),\n        )\n\n        return self", "\n        return self\n\n    def __exit__(self, *args):\n        self.write_socket.close()\n        self.read_socket.close()\n        self.stream.close()\n\n    async def play(self, data: bytes):\n        await asyncio.to_thread(self.stream.write, data)", "    async def play(self, data: bytes):\n        await asyncio.to_thread(self.stream.write, data)\n\n    async def run(self):\n        logger = self.logger\n        config = self.config\n        write_socket = self.write_socket\n        read_socket = self.read_socket\n\n        logger.info(\"Started\")", "\n        logger.info(\"Started\")\n        await send_state(write_socket, \"MessageToSpeak\", ComponentState.READY)\n\n        while not write_socket.closed and not read_socket.closed:\n            message = await read_socket.recv_json()\n            if not is_assistant_message(message):\n                continue\n\n            match = re.search(", "\n            match = re.search(\n                config.get(\"message_to_speak.talk_pattern\", r\"(.+)\"),\n                message[\"content\"],\n                re.MULTILINE,\n            )\n\n            if not match:\n                continue\n", "                continue\n\n            text = match.group(1)\n\n            remove_pattern = config.get(\"message_to_speak.remove_pattern\")\n            if remove_pattern:\n                text = re.sub(remove_pattern, \"\", text)\n\n            if self.english_kana_dict:\n                text = re.sub(", "            if self.english_kana_dict:\n                text = re.sub(\n                    \"[a-zA-Z]+\",\n                    lambda m: self.english_kana_dict.get(m.group(0).lower(), m.group(0)),\n                    text,\n                )\n\n            if not text:\n                continue\n", "                continue\n\n            await self.play_text(text)\n\n        logger.info(\"Terminated\")\n\n    @abstractmethod\n    async def play_text(self, text: str):\n        raise NotImplementedError()\n", "        raise NotImplementedError()\n\n\nclass MessageToVoicevox(MessageToSpeak):\n    async def run(self):\n        self.logger.info(\"VOICEVOX version: %s\", await version())\n        await super().run()\n\n    async def play_text(self, text: str):\n        config = self.config", "    async def play_text(self, text: str):\n        config = self.config\n        logger = self.logger\n\n        speaker = config.get(\"message_to_speak.voicevox.speaker\", 1)\n        segments = re.split(config.get(\"message_to_speak.split_pattern\", r\"\u3002\"), text)\n\n        prev_task: asyncio.Task | None = None\n        for segment in segments:\n            if not segment:", "        for segment in segments:\n            if not segment:\n                continue\n\n            logger.info(\"Query: %s\", segment)\n\n            query = await audio_query(segment, speaker)\n            logger.info(\"Synthesis: %d\", speaker)\n\n            data = await synthesis(query, speaker)", "\n            data = await synthesis(query, speaker)\n\n            if prev_task:\n                await prev_task\n\n            await send_state(self.write_socket, \"MessageToSpeak\", ComponentState.BUSY)\n            prev_task = asyncio.create_task(self.play(data[44:]))\n\n        if prev_task:", "\n        if prev_task:\n            await prev_task\n        await send_state(self.write_socket, \"MessageToSpeak\", ComponentState.READY)\n\n\nclass MessageToRVC(MessageToVoicevox):\n    def __init__(self, config: Config = Config()):\n        from hf_rvc import RVCFeatureExtractor, RVCModel\n", "        from hf_rvc import RVCFeatureExtractor, RVCModel\n\n        super().__init__(config)\n\n        self.logger.info(\"Loading RVC model\")\n\n        device = \"cpu\"\n\n        rvc_model_path = config.get(\"message_to_speak.rvc.model\", True)\n        rvc_model = RVCModel.from_pretrained(rvc_model_path)", "        rvc_model_path = config.get(\"message_to_speak.rvc.model\", True)\n        rvc_model = RVCModel.from_pretrained(rvc_model_path)\n        assert isinstance(rvc_model, RVCModel)\n        if self.config.get(\"message_to_speak.rvc.fp16\", device != \"cpu\"):\n            rvc_model = rvc_model.half()\n            self.fp16 = True\n        else:\n            self.fp16 = False\n\n        rvc_model = rvc_model.to(device)", "\n        rvc_model = rvc_model.to(device)\n        rvc_model.vits = rvc_model.vits.to(device)\n        self.rvc_model = rvc_model\n\n        feature_extractor = RVCFeatureExtractor.from_pretrained(rvc_model_path)\n        assert isinstance(feature_extractor, RVCFeatureExtractor)\n        self.rvc_feature_extractor = feature_extractor\n\n    def _stream_format(self):", "\n    def _stream_format(self):\n        return {\n            \"format\": pyaudio.paFloat32,\n            \"channels\": 1,\n            \"rate\": 48000,\n        }\n\n    async def play_text(self, text: str):\n        import torch", "    async def play_text(self, text: str):\n        import torch\n\n        await super().play_text(text)\n        torch.cuda.empty_cache()\n\n    async def play(self, data: bytes):\n        import resampy\n        import torch\n", "        import torch\n\n        if len(data) == 0:\n            return\n        with torch.no_grad():\n            resampled = resampy.resample(np.frombuffer(data, np.int16), 24000, 16000, axis=0)\n            self.rvc_feature_extractor.set_f0_method(self.config.get(\"message_to_speak.rvc.f0_method\", \"pm\"))\n            features = self.rvc_feature_extractor(\n                resampled,\n                f0_up_key=int(self.config.get(\"message_to_speak.rvc.f0_up_key\", 0)),", "                resampled,\n                f0_up_key=int(self.config.get(\"message_to_speak.rvc.f0_up_key\", 0)),\n                sampling_rate=16000,\n                return_tensors=\"pt\",\n            )\n            dtype = torch.float16 if self.fp16 else torch.float32\n            rvc_output = await asyncio.to_thread(\n                self.rvc_model,\n                input_values=features.input_values.to(self.rvc_model.device, dtype=dtype),\n                f0=features.f0.to(self.rvc_model.device, dtype=dtype),", "                input_values=features.input_values.to(self.rvc_model.device, dtype=dtype),\n                f0=features.f0.to(self.rvc_model.device, dtype=dtype),\n                f0_coarse=features.f0_coarse.to(self.rvc_model.device),\n            )\n\n            await super().play(\n                (rvc_output.cpu().float().numpy() * self.config.get(\"message_to_speak.rvc.volume\", 1.0)).tobytes()\n            )\n\n", "\n\ndef get_class_by_name(name: str) -> type[MessageToSpeak]:\n    match name:\n        case \"rvc\":\n            return MessageToRVC\n        case \"voicevox\":\n            return MessageToVoicevox\n        case _:\n            raise ValueError(f\"Unknown engine: {name}\")", "        case _:\n            raise ValueError(f\"Unknown engine: {name}\")\n\n\nasync def message_to_speak(config: Config = Config()) -> None:\n    Impl = get_class_by_name(config.get(\"message_to_speak.engine\", \"voicevox\"))\n\n    with Impl(config) as message_to_speak:\n        await message_to_speak.run()\n", "        await message_to_speak.run()\n"]}
{"filename": "talkbot/prune.py", "chunked_list": ["\"\"\"Prune a model to reduce its size.\"\"\"\n\nfrom torch.nn.utils.prune import l1_unstructured, remove\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    PreTrainedTokenizer,\n    PreTrainedTokenizerFast,\n)\n", ")\n\n\nasync def prune(src_model: str, save_dir: str, amount: float = 0.5):\n    \"\"\"Prune a model to reduce its size.\"\"\"\n\n    model: AutoModelForCausalLM = AutoModelForCausalLM.from_pretrained(src_model)\n    tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(src_model)\n\n    l1_unstructured(model.transformer.wte, name=\"weight\", amount=amount)", "\n    l1_unstructured(model.transformer.wte, name=\"weight\", amount=amount)\n    remove(model.transformer.wte, \"weight\")\n\n    tokenizer.save_pretrained(save_dir)\n    model.save_pretrained(save_dir)\n"]}
{"filename": "talkbot/message_stream.py", "chunked_list": ["\"\"\"MessageStream component.\"\"\"\n\nfrom typing import NoReturn\n\nimport zmq\nimport zmq.asyncio\n\nfrom .utilities.config import Config\nfrom .utilities.socket import get_context\n", "from .utilities.socket import get_context\n\n\nasync def message_stream(config: Config = Config()) -> NoReturn:\n    \"\"\"MessageStream component.\"\"\"\n    logger = config.get_logger(\"MessageStream\")\n\n    logger.info(\"Initializing\")\n\n    context = get_context()\n    with context.socket(zmq.SUB) as sub_socket, context.socket(zmq.PUB) as pub_socket:\n        sub_socket.bind(config.get(\"message_stream.write\", required=True))\n        sub_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n\n        pub_socket.bind(config.get(\"message_stream.read\", required=True))\n\n        logger.info(\"Started\")\n\n        while True:\n            message = await sub_socket.recv_json()  # type: ignore\n            logger.debug(\"Message: %s\", message)\n            await pub_socket.send_json(message)  # type: ignore", "\n    context = get_context()\n    with context.socket(zmq.SUB) as sub_socket, context.socket(zmq.PUB) as pub_socket:\n        sub_socket.bind(config.get(\"message_stream.write\", required=True))\n        sub_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n\n        pub_socket.bind(config.get(\"message_stream.read\", required=True))\n\n        logger.info(\"Started\")\n\n        while True:\n            message = await sub_socket.recv_json()  # type: ignore\n            logger.debug(\"Message: %s\", message)\n            await pub_socket.send_json(message)  # type: ignore", ""]}
{"filename": "talkbot/utilities/asyncargh.py", "chunked_list": ["\"\"\"A module that allows async functions to be used as commands with argh.\"\"\"\n\nimport asyncio\nfrom typing import Any, Callable, Coroutine, List, TypeVar\n\nfrom argh import ArghParser\nfrom argh.assembling import ATTR_NAME, _extract_command_meta_from_func\n\nT = TypeVar(\"T\")\n", "T = TypeVar(\"T\")\n\n\ndef wrap_async(async_func: Callable[..., Coroutine[Any, Any, T]]) -> Callable[..., T]:\n    \"\"\"Wrap an async function so that it can be used as a command.\"\"\"\n\n    def wrapper(*args, **kwargs: Any) -> T:\n        return asyncio.run(async_func(*args, **kwargs))\n\n    setattr(wrapper, \"__wrapped__\", async_func)\n\n    cmd_name, _ = _extract_command_meta_from_func(async_func)\n    setattr(wrapper, ATTR_NAME, cmd_name)\n    setattr(wrapper, \"__doc__\", async_func.__doc__)\n\n    return wrapper", "\n\nclass AsyncArghParser(ArghParser):\n    \"\"\"A subclass of ArghParser that allows async functions to be added as commands.\"\"\"\n\n    def add_async_commands(self, commands: List[Callable[..., Coroutine[Any, Any, Any]]], *args, **kwargs) -> None:\n        \"\"\"Add a list of async functions as commands.\"\"\"\n        self.add_commands([wrap_async(func) for func in commands], *args, **kwargs)\n\n    def set_async_default_command(self, command: Callable[..., Coroutine[Any, Any, Any]]) -> None:\n        \"\"\"Set the default command to an async function.\"\"\"\n        self.set_default_command(wrap_async(command))", ""]}
{"filename": "talkbot/utilities/voicevox.py", "chunked_list": ["\"\"\"VoiceVox Core API wrapper.\"\"\"\n\nimport asyncio\nimport requests\n\nBASE_URL = \"http://localhost:50021\"\n\n\nasync def voicevox_post(\n    path: str,", "async def voicevox_post(\n    path: str,\n    params: dict | None = None,\n    data: bytes | None = None,\n    json: dict | None = None,\n    timeout: int | None = None,\n):\n    \"\"\"POST request to VoiceVox Core.\"\"\"\n    return await asyncio.to_thread(\n        requests.post, f\"{BASE_URL}{path}\", params=params, data=data, json=json, timeout=timeout", "    return await asyncio.to_thread(\n        requests.post, f\"{BASE_URL}{path}\", params=params, data=data, json=json, timeout=timeout\n    )\n\n\nasync def voicevox_get(path: str, params: dict | None = None, timeout: int | None = None):\n    \"\"\"GET request to VoiceVox Core.\"\"\"\n    return await asyncio.to_thread(requests.get, f\"{BASE_URL}{path}\", params=params, timeout=timeout)\n\n", "\n\nasync def version() -> str:\n    \"\"\"Get VoiceVox Core version.\"\"\"\n    return (await voicevox_get(\"/version\")).json()\n\n\nasync def engine_versions() -> str:\n    \"\"\"Get VoiceVox Core engine versions.\"\"\"\n    return (await voicevox_get(\"/engine_versions\")).json()", "    \"\"\"Get VoiceVox Core engine versions.\"\"\"\n    return (await voicevox_get(\"/engine_versions\")).json()\n\n\nasync def speakers() -> dict:\n    \"\"\"Get VoiceVox Core speakers.\"\"\"\n    return (await voicevox_get(\"/speakers\")).json()\n\n\nasync def audio_query(text: str, speaker: int = 1) -> dict:", "\nasync def audio_query(text: str, speaker: int = 1) -> dict:\n    \"\"\"Get VoiceVox Core audio query.\"\"\"\n    return (await voicevox_post(\"/audio_query\", params={\"text\": text, \"speaker\": speaker})).json()\n\n\nasync def synthesis(query: dict, speaker: int = 1) -> bytes:\n    \"\"\"Get VoiceVox Core synthesis.\"\"\"\n    return (await voicevox_post(\"/synthesis\", params={\"speaker\": speaker}, json=query)).content\n", "    return (await voicevox_post(\"/synthesis\", params={\"speaker\": speaker}, json=query)).content\n"]}
{"filename": "talkbot/utilities/config.py", "chunked_list": ["\"\"\"A module for loading and accessing configuration data from YAML files.\"\"\"\n\nimport logging.config\nimport os\nfrom logging import Logger\nfrom typing import Any, TypeVar, overload\n\nimport yaml\nfrom pydotenv import Environment\n", "from pydotenv import Environment\n\nT = TypeVar(\"T\")\n\n\nclass Config:\n    \"\"\"A class for loading and accessing configuration data from YAML files.\"\"\"\n\n    def __init__(self, *filepaths: str | None):\n        \"\"\"Initialize the Config object.\"\"\"\n        env = Environment().get(\"ENV\", \"development\")\n        self._filepaths = [\n            filepath\n            for filepath in [\n                \"config/default.yml\",\n                f\"config/{env}.yml\",\n                \"config/local.yml\",\n                f\"config/{env}-local.yml\",\n            ]\n            if os.path.isfile(filepath)\n        ]\n        if filepaths:\n            self._filepaths.extend([filepath for filepath in filepaths if filepath and os.path.isfile(filepath)])\n\n        self._config_data: dict[str, Any] = {}\n        self._timestamps: dict[str, float] = {}\n\n    def _load_yaml_file(self, filepath: str) -> dict:\n        if not os.path.isfile(filepath):\n            return {}\n\n        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n            return yaml.safe_load(file)\n\n    def _check_and_update(self, filepath: str) -> None:\n        timestamp = os.path.getmtime(filepath)\n\n        if filepath not in self._timestamps or self._timestamps[filepath] != timestamp:\n            self._config_data[filepath] = self._load_yaml_file(filepath)\n            self._timestamps[filepath] = timestamp\n\n    @overload\n    def get(self, path: str) -> Any | None:\n        pass\n\n    @overload\n    def get(self, path: str, default=None, required=True) -> Any:\n        pass\n\n    @overload\n    def get(self, path: str, default: T) -> T:\n        pass\n\n    def get(self, path: str, default: Any = None, required=False) -> Any:\n        \"\"\"Get a value from the configuration data.\"\"\"\n        keys = path.split(\".\")\n        result = None\n\n        for filepath in reversed(self._filepaths):\n            self._check_and_update(filepath)\n            config_data = self._config_data.get(filepath, {})\n            current = config_data\n\n            for key in keys:\n                if not current or key not in current:\n                    break\n                current = current[key]\n            else:\n                if result is None:\n                    result = current\n                elif isinstance(result, dict) and isinstance(current, dict):\n                    result = self._deep_merge(result, current)\n\n        if result is None:\n            if required:\n                raise KeyError(f\"Missing required configuration value: {path}\")\n            else:\n                return default\n\n        return result\n\n    def _deep_merge(self, source: dict, destination: dict) -> dict:\n        \"\"\"Recursively merge two dictionaries.\"\"\"\n        for key, value in source.items():\n            if isinstance(value, dict):\n                destination[key] = self._deep_merge(destination.get(key, {}), value)\n            else:\n                destination[key] = value\n        return destination\n\n    def get_logger(self, name: str | None = None) -> Logger:\n        \"\"\"Get a logger from the configuration data.\"\"\"\n        logging.config.dictConfig(self.get(\"log\", dict[str, Any]()))\n        return logging.getLogger(name)\n\n    @classmethod\n    def get_instance(cls):\n        \"\"\"Get the singleton instance of the Config class.\"\"\"\n        if not hasattr(cls, \"_instance\"):\n            cls._instance = Config()\n        return cls._instance", ""]}
{"filename": "talkbot/utilities/audio.py", "chunked_list": ["\"\"\"Utilities for working with audio.\"\"\"\n\nimport atexit\nimport signal\nimport threading\nfrom contextlib import contextmanager\nfrom typing import List\n\nimport numpy as np\nimport pyaudio", "import numpy as np\nimport pyaudio\nfrom numpy.typing import ArrayLike\n\n\ndef get_device_by_name(device_name: str, min_input_channels: int = 0, min_output_channels: int = 0) -> int:\n    \"\"\"Get the index of the first matched device.\"\"\"\n    for i, info in enumerate(list_device_info()):\n        if (\n            device_name in str(info[\"name\"])\n            and int(info[\"maxOutputChannels\"]) >= min_output_channels\n            and int(info[\"maxInputChannels\"]) >= min_input_channels\n        ):\n            return i\n\n    raise ValueError(f\"No output device found with name containing '{device_name}'\")", "\n\ndef list_device_info() -> List[dict]:\n    \"\"\"Get a list of device info dictionaries.\"\"\"\n    return [get_pa().get_device_info_by_index(i) for i in range(get_pa().get_device_count())]  # type: ignore\n\n\ndef list_host_api_info() -> List[dict]:\n    \"\"\"Get a list of host API info dictionaries.\"\"\"\n    return [get_pa().get_host_api_info_by_index(i) for i in range(get_pa().get_host_api_count())]  # type: ignore", "\n\ndef get_volume_range(audio_data: ArrayLike) -> float:\n    \"\"\"Get the range of the audio data.\"\"\"\n    return np.max(audio_data) - np.min(audio_data)\n\n\n_pa_local = threading.local()\n\n\ndef get_pa() -> pyaudio.PyAudio:\n    \"\"\"Get a thread-local instance of pyaudio.PyAudio.\"\"\"\n    if not hasattr(_pa_local, \"pa\"):\n        _pa_local.pa = pyaudio.PyAudio()\n        atexit.register(_pa_local.pa.terminate)\n    return _pa_local.pa", "\n\ndef get_pa() -> pyaudio.PyAudio:\n    \"\"\"Get a thread-local instance of pyaudio.PyAudio.\"\"\"\n    if not hasattr(_pa_local, \"pa\"):\n        _pa_local.pa = pyaudio.PyAudio()\n        atexit.register(_pa_local.pa.terminate)\n    return _pa_local.pa\n\n", "\n\n@contextmanager\ndef open_stream(\n    *args,\n    **kwargs,\n):\n    \"\"\"Open a stream.\"\"\"\n    stream = get_pa().open(*args, **kwargs)\n    yield stream\n    stream.stop_stream()", "\n\ndef _on_sigint(*_):\n    \"\"\"Handle SIGINT.\"\"\"\n    if hasattr(\"_pa_local\", \"pa\"):\n        _pa_local.pa.terminate()\n\n\nsignal.signal(signal.SIGINT, _on_sigint)\n", "signal.signal(signal.SIGINT, _on_sigint)\n"]}
{"filename": "talkbot/utilities/message.py", "chunked_list": ["\"\"\"Message types.\"\"\"\n\nimport time\nfrom typing import Any, Literal, TypedDict, TypeGuard\n\nfrom .constants import ComponentState\n\n\nclass UserMessage(TypedDict):\n    \"\"\"A message from the user.\"\"\"\n\n    role: Literal[\"user\"]\n    content: str", "class UserMessage(TypedDict):\n    \"\"\"A message from the user.\"\"\"\n\n    role: Literal[\"user\"]\n    content: str\n\n\nclass AssistantMessage(TypedDict):\n    \"\"\"A message from the assistant.\"\"\"\n\n    role: Literal[\"assistant\"]\n    content: str", "\n\nclass SystemMessage(TypedDict):\n    \"\"\"A message from the system.\"\"\"\n\n    role: Literal[\"system\"]\n    content: str\n\n\nclass StateMessage(TypedDict):\n    \"\"\"Message for local status.\"\"\"\n\n    role: Literal[\"state\"]\n    component: str\n    state: int", "\nclass StateMessage(TypedDict):\n    \"\"\"Message for local status.\"\"\"\n\n    role: Literal[\"state\"]\n    component: str\n    state: int\n\n\nMessage = UserMessage | AssistantMessage | SystemMessage | StateMessage", "\nMessage = UserMessage | AssistantMessage | SystemMessage | StateMessage\n\"\"\"A message from the user, assistant, or system.\"\"\"\n\nTextMessage = UserMessage | AssistantMessage | SystemMessage\n\"\"\"A message from the user, assistant, or system that contains text.\"\"\"\n\n\ndef is_message(message: Any) -> TypeGuard[Message]:\n    \"\"\"Check if a message is a message.\"\"\"\n    return isinstance(message, dict) and \"role\" in message", "def is_message(message: Any) -> TypeGuard[Message]:\n    \"\"\"Check if a message is a message.\"\"\"\n    return isinstance(message, dict) and \"role\" in message\n\n\ndef is_text_message(message: Any) -> TypeGuard[TextMessage]:\n    \"\"\"Check if a message is a text message.\"\"\"\n    return is_message(message) and message[\"role\"] in (\"user\", \"assistant\", \"system\")\n\n\ndef is_user_message(message: Any) -> TypeGuard[UserMessage]:\n    \"\"\"Check if a message is a user message.\"\"\"\n    return is_text_message(message) and message[\"role\"] == \"user\"", "\n\ndef is_user_message(message: Any) -> TypeGuard[UserMessage]:\n    \"\"\"Check if a message is a user message.\"\"\"\n    return is_text_message(message) and message[\"role\"] == \"user\"\n\n\ndef is_assistant_message(message: Any) -> TypeGuard[AssistantMessage]:\n    \"\"\"Check if a message is an assistant message.\"\"\"\n    return is_text_message(message) and message[\"role\"] == \"assistant\"", "\n\ndef is_state_message(message: Any) -> TypeGuard[StateMessage]:\n    \"\"\"Check if a message is a state message.\"\"\"\n    return is_message(message) and message[\"role\"] == \"state\"\n\n\ndef update_busy_time(message: Any, component: str, current_value: float) -> float:\n    \"\"\"Get the busy time of a message.\"\"\"\n    if not is_message(message):\n        return current_value\n\n    if message[\"role\"] != \"state\":\n        return current_value\n\n    if message[\"component\"] != component:\n        return current_value\n\n    return time.time() if ComponentState(message[\"state\"]) == ComponentState.BUSY else 0", "\n\ndef is_busy(busy_time: float, timeout: float) -> bool:\n    \"\"\"Check if a component is busy.\"\"\"\n    return time.time() - busy_time < timeout\n"]}
{"filename": "talkbot/utilities/__init__.py", "chunked_list": ["\"\"\"Utiliy functions for the talkbot package.\"\"\"\n"]}
{"filename": "talkbot/utilities/constants.py", "chunked_list": ["\"\"\"Constants for the TalkBot project.\"\"\"\n\nfrom enum import Enum\n\n\nclass ComponentState(Enum):\n    \"\"\"Enum for the state of a component.\"\"\"\n\n    READY = 0\n    \"\"\"The component is ready to process messages.\"\"\"\n\n    BUSY = 1\n    \"\"\"The component is busy processing messages.\"\"\"", ""]}
{"filename": "talkbot/utilities/socket.py", "chunked_list": ["\"\"\"Provide utilities for working with ZMQ sockets.\"\"\"\n\nimport asyncio\nimport atexit\nimport signal\nimport sys\nimport threading\nfrom abc import ABC\nfrom contextlib import contextmanager\nfrom typing import Any, Awaitable, Iterator, TypeVar", "from contextlib import contextmanager\nfrom typing import Any, Awaitable, Iterator, TypeVar\n\nimport zmq\nimport zmq.asyncio\n\nfrom .config import Config\nfrom .constants import ComponentState\nfrom .message import StateMessage\n\nif sys.platform == \"win32\":\n    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())", "from .message import StateMessage\n\nif sys.platform == \"win32\":\n    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n\n_local = threading.local()\n\nT = TypeVar(\"T\")\nJsonValue = list[Any] | str | int | float | dict[Any, Any]\n", "JsonValue = list[Any] | str | int | float | dict[Any, Any]\n\n\nclass Socket(ABC, zmq.asyncio.Socket):\n    \"\"\"A socket that can send and receive JSON messages.\"\"\"\n\n    def send_json(self, obj: Any, flags: int | None = None, **kwargs: Any) -> Awaitable[None]:  # type: ignore\n        \"\"\"Send a JSON-serializable object as a message.\"\"\"\n        raise NotImplementedError()\n\n    def recv_json(self, flags: int | None = None, **kwargs: Any) -> Awaitable[JsonValue]:  # type: ignore\n        \"\"\"Receive a JSON-serializable object as a message.\"\"\"\n        raise NotImplementedError()", "\n\ndef get_context() -> zmq.asyncio.Context:\n    \"\"\"Return a context for creating sockets.\"\"\"\n    if not hasattr(_local, \"context\"):\n        _local.context = zmq.asyncio.Context()\n        atexit.register(_local.context.term)\n    return _local.context\n\n\ndef _on_sigint(*_):\n    \"\"\"Handle SIGINT.\"\"\"\n    if hasattr(_local, \"context\"):\n        _local.context.term()", "\n\ndef _on_sigint(*_):\n    \"\"\"Handle SIGINT.\"\"\"\n    if hasattr(_local, \"context\"):\n        _local.context.term()\n\n\nsignal.signal(signal.SIGINT, _on_sigint)\n", "signal.signal(signal.SIGINT, _on_sigint)\n\n\n@contextmanager\ndef get_write_socket(config: Config) -> Iterator[Socket]:\n    \"\"\"Return a socket that sends messages to the message stream.\"\"\"\n    context = get_context()\n    with context.socket(zmq.PUB) as socket:\n        socket.connect(config.get(\"message_stream.write\", \"\"))\n        yield socket  # type: ignore", "\n\n@contextmanager\ndef get_read_socket(config: Config, timeout: float | None = None) -> Iterator[Socket]:\n    \"\"\"Return a socket that receives messages from the message stream.\"\"\"\n    context = get_context()\n    with context.socket(zmq.SUB) as socket:\n        socket.connect(config.get(\"message_stream.read\", \"\"))\n        socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n        if timeout is not None:\n            socket.setsockopt(zmq.RCVTIMEO, int(timeout * 1000))\n        yield socket  # type: ignore", "\n\n@contextmanager\ndef get_sockets(\n    config: Config,\n    timeout: float | None = None,\n) -> Iterator[tuple[Socket, Socket]]:\n    \"\"\"Return a tuple of (write_socket, read_socket).\"\"\"\n    with get_write_socket(config) as write_socket, get_read_socket(config, timeout) as read_socket:\n        yield write_socket, read_socket", "\n\nasync def send_state(write_socket: Socket, component: str, state: ComponentState):\n    \"\"\"Send a state message to the message stream.\"\"\"\n    await write_socket.send_json(\n        StateMessage(\n            role=\"state\",\n            component=component,\n            state=state.value,\n        )", "            state=state.value,\n        )\n    )\n"]}
{"filename": "tests/__init__.py", "chunked_list": [""]}
{"filename": "tests/utilities/__init__.py", "chunked_list": [""]}
{"filename": "tests/utilities/test_config.py", "chunked_list": ["\"\"\"Tests for the Config class.\"\"\"\n\nimport unittest\n\nfrom talkbot.utilities.config import Config\n\n\nclass TestConfig(unittest.TestCase):\n    \"\"\"Tests for the Config class.\"\"\"\n\n    def test_get(self) -> None:\n        \"\"\"Test the get method.\"\"\"\n        config = Config(\"tests/config/test1.yml\", \"tests/config/test2.yml\")\n\n        self.assertEqual(config.get(\"database.host\"), \"example2.com\")\n        self.assertEqual(config.get(\"database.port\"), 1234)\n        self.assertEqual(config.get(\"database.user\"), \"user2\")\n        self.assertEqual(config.get(\"database.password\"), \"pass1\")\n\n        self.assertEqual(config.get(\"extra.key\"), \"value\")\n        self.assertIsNone(config.get(\"extra.unknown\"))\n\n        self.assertEqual(config.get(\"log.version\"), 1)\n        self.assertIsNone(config.get(\"log.unknown\"))\n\n    def test_get_with_default(self) -> None:\n        \"\"\"Test the get method with a default value.\"\"\"\n\n        config = Config(\"config/test1.yml\", \"config/test2.yml\")\n\n        self.assertEqual(config.get(\"extra.unknown\", \"default_value\"), \"default_value\")", ""]}
