{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\nwith open(\"requirements.txt\") as f:\n    required = f.read().splitlines()\n\n\nsetup(\n    name=\"llm_oracle\",\n    version=\"0.0.6\",\n    description=\"\",", "    version=\"0.0.6\",\n    description=\"\",\n    url=\"https://github.com/sshh12/llm_oracle\",\n    author=\"Shrivu Shankar\",\n    license=\"MIT\",\n    packages=find_packages(),\n    include_package_data=True,\n    install_requires=required,\n)\n", ")\n"]}
{"filename": "llm_oracle/text_utils.py", "chunked_list": ["import datetime\n\nTIME_UNITS = {\"year\": 365, \"month\": 31, \"week\": 7, \"day\": 1}\n\n\ndef future_date_to_string(raw_date: datetime.datetime) -> str:\n    date = raw_date.replace(tzinfo=None)\n    s = date.isoformat()[:10]\n    days_from_now = (date - datetime.datetime.now()).days\n    rel = None\n    for unit, unit_days in TIME_UNITS.items():\n        if days_from_now > unit_days:\n            rel = f\"~ {days_from_now/unit_days:.1f} {unit}s\"\n            break\n    return f\"{s} (in {rel})\"", "\n\ndef world_state_to_string() -> str:\n    state = {\"current_date\": datetime.datetime.now().isoformat()[:10]}\n    return \"\\n\".join([f\"{k}: {v}\" for k, v in state.items()])\n"]}
{"filename": "llm_oracle/llm.py", "chunked_list": ["from langchain.chat_models import ChatOpenAI\nfrom langchain.chat_models.base import BaseChatModel\n\nLLMModel = BaseChatModel\n\ndefault_fast_llm_options = dict(model_name=\"gpt-3.5-turbo\", request_timeout=120, max_retries=10, temperature=0.5)\ndefault_llm_options = dict(model_name=\"gpt-4\", request_timeout=120, max_retries=10, temperature=0.5)\n\n\ndef get_default_fast_llm() -> LLMModel:\n    chat = ChatOpenAI(**default_fast_llm_options)\n    return chat", "\ndef get_default_fast_llm() -> LLMModel:\n    chat = ChatOpenAI(**default_fast_llm_options)\n    return chat\n\n\ndef get_default_llm() -> LLMModel:\n    chat = ChatOpenAI(**default_llm_options)\n    return chat\n", ""]}
{"filename": "llm_oracle/__init__.py", "chunked_list": [""]}
{"filename": "llm_oracle/processing_utils.py", "chunked_list": ["from typing import Callable, Any, Optional\nimport datetime\nimport hashlib\nimport pickle\nimport re\nimport os\n\nMAX_CACHE_VAL_LEN = 20\n\ncache_options = dict(cache=True, cache_dir=\"cache\")", "\ncache_options = dict(cache=True, cache_dir=\"cache\")\n\n\ndef hash_str(val: str) -> str:\n    return str(int(hashlib.md5(val.encode(\"utf-8\")).hexdigest(), 16))\n\n\ndef cache_func(func: Callable) -> Callable:\n    \"\"\"\n    Basic cache to save $$$ on API calls.\n\n    Caches based on `str` and `int` args only. Cache is done only for a single calendar day.\n    \"\"\"\n\n    def wrap(*args, **kwargs):\n        os.makedirs(cache_options[\"cache_dir\"], exist_ok=True)\n        args = [*args] + list(kwargs.values())\n        cache_val = re.sub(\"[^\\w\\d]\", \"\", repr([arg for arg in args if isinstance(arg, str) or isinstance(arg, int)]))\n        if len(cache_val) > MAX_CACHE_VAL_LEN:\n            cache_val = hash_str(cache_val)\n        date_key = datetime.datetime.now().isoformat()[:10].replace(\"-\", \"_\")\n        cache_key = f\"{func.__name__}_{date_key}_{cache_val}\"\n        cache_fn = os.path.join(cache_options[\"cache_dir\"], cache_key)\n        if os.path.exists(cache_fn) and cache_options[\"cache\"]:\n            with open(cache_fn, \"rb\") as f:\n                return pickle.load(f)\n        else:\n            result = func(*args, **kwargs)\n            with open(cache_fn, \"wb\") as f:\n                pickle.dump(result, f)\n            return result\n\n    return wrap", "def cache_func(func: Callable) -> Callable:\n    \"\"\"\n    Basic cache to save $$$ on API calls.\n\n    Caches based on `str` and `int` args only. Cache is done only for a single calendar day.\n    \"\"\"\n\n    def wrap(*args, **kwargs):\n        os.makedirs(cache_options[\"cache_dir\"], exist_ok=True)\n        args = [*args] + list(kwargs.values())\n        cache_val = re.sub(\"[^\\w\\d]\", \"\", repr([arg for arg in args if isinstance(arg, str) or isinstance(arg, int)]))\n        if len(cache_val) > MAX_CACHE_VAL_LEN:\n            cache_val = hash_str(cache_val)\n        date_key = datetime.datetime.now().isoformat()[:10].replace(\"-\", \"_\")\n        cache_key = f\"{func.__name__}_{date_key}_{cache_val}\"\n        cache_fn = os.path.join(cache_options[\"cache_dir\"], cache_key)\n        if os.path.exists(cache_fn) and cache_options[\"cache\"]:\n            with open(cache_fn, \"rb\") as f:\n                return pickle.load(f)\n        else:\n            result = func(*args, **kwargs)\n            with open(cache_fn, \"wb\") as f:\n                pickle.dump(result, f)\n            return result\n\n    return wrap", "\n\ndef run_with_retries(func: Callable, default_val: Optional[Any] = None, retries: Optional[int] = 3) -> Any:\n    attempts = 0\n    while True:\n        try:\n            attempts += 1\n            return func()\n        except Exception as e:\n            print(\"run_with_retries\", func, e)\n            if attempts > retries:\n                break\n    return default_val", ""]}
{"filename": "llm_oracle/link_scraping.py", "chunked_list": ["from typing import List, Optional\nimport requests\nimport os\nfrom bs4 import BeautifulSoup\n\nfrom llm_oracle import processing_utils\n\nMAX_LINK_LEN = 120\n\n", "\n\n@processing_utils.cache_func\ndef scrape_text(url: str, retries: Optional[int] = 2, use_proxy: bool = True) -> str:\n    try:\n        if use_proxy:\n            resp = requests.get(\n                url=\"https://app.scrapingbee.com/api/v1/\",\n                params={\n                    \"api_key\": os.environ[\"SCRAPINGBEE_API_KEY\"],\n                    \"url\": url,\n                    \"premium_proxy\": \"true\",\n                    \"country_code\": \"us\",\n                },\n            )\n        else:\n            resp = requests.get(\n                url,\n                headers={\n                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\"\n                },\n            )\n    except RuntimeError as e:\n        if retries > 0:\n            return scrape_text(url, retries=retries - 1)\n        else:\n            raise e\n    return resp.text", "\n\ndef _element_to_text(element) -> str:\n    elem_text = element.get_text()\n    lines = (line.strip() for line in elem_text.splitlines())\n    parts = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n    text = \"\\n\".join(c for c in parts if c)\n\n    links = []\n    for link in element.find_all(\"a\", href=True):\n        if len(link[\"href\"]) <= MAX_LINK_LEN:\n            links.append(link[\"href\"])\n\n    return text + \"\\n\\nLinks: \" + \" \".join(list(set(links)))", "\n\ndef _chunk_element(element, max_size: int) -> List[str]:\n    text = _element_to_text(element)\n    if len(text) == 0:\n        return []\n    if len(text) <= max_size:\n        return [text]\n    else:\n        chunks = []\n        for child in element.findChildren(recursive=False):\n            chunks.extend(_chunk_element(child, max_size))\n        return chunks", "\n\ndef _merge_text_chunks(vals: List[str], max_size: int) -> List[str]:\n    combined_strings = []\n    current_string = \"\"\n\n    for s in vals:\n        if len(current_string) + len(s) <= max_size:\n            current_string += s\n        else:\n            combined_strings.append(current_string)\n            current_string = s\n\n    if current_string:\n        combined_strings.append(current_string)\n\n    return combined_strings", "\n\ndef chunk_and_strip_html(raw_html: str, max_size: int) -> List[str]:\n    soup = BeautifulSoup(raw_html, features=\"html.parser\")\n\n    for script in soup([\"script\", \"style\"]):\n        script.extract()\n\n    chunks = _chunk_element(soup, max_size)\n    chunks = _merge_text_chunks(chunks, max_size)\n    return chunks", ""]}
{"filename": "llm_oracle/tools/__init__.py", "chunked_list": [""]}
{"filename": "llm_oracle/tools/read_link.py", "chunked_list": ["from typing import Optional, List\n\nfrom langchain.agents import Tool\n\nfrom llm_oracle.link_scraping import scrape_text, chunk_and_strip_html\nfrom llm_oracle import llm, processing_utils\n\nCHUNK_SIZE = 4000\n\nSUMMARIZE_PROMPT = \"\"\"", "\nSUMMARIZE_PROMPT = \"\"\"\n```\n{chunk}\n```\n\nUsing the above text from scraping a website, create a very detailed summary of the information.\n\nInclude key statistics, dates, numbers, and other details.\n", "Include key statistics, dates, numbers, and other details.\n\nNote: This will be used to answer \"{ask}\"\n\"\"\"\n\nSUMMARIZE_CHUNKS_PROMPT = \"\"\"\n```\n{chunks}\n```\n", "```\n\nUsing the above text from scraping a website, create a very detailed summary of the information and provide information about \"{ask}\".\n\nInclude key statistics, dates, numbers, and other details.\n\"\"\"\n\n\n@processing_utils.cache_func\ndef _summarize_chunk(model: llm.LLMModel, chunk: str, ask: str) -> str:\n    return model.call_as_llm(SUMMARIZE_PROMPT.format(chunk=chunk, ask=ask))", "@processing_utils.cache_func\ndef _summarize_chunk(model: llm.LLMModel, chunk: str, ask: str) -> str:\n    return model.call_as_llm(SUMMARIZE_PROMPT.format(chunk=chunk, ask=ask))\n\n\ndef _summarize_chunks(model: llm.LLMModel, chunks: List[str], ask: str) -> str:\n    return model.call_as_llm(SUMMARIZE_CHUNKS_PROMPT.format(chunks=\"\\n\\n\".join(chunks), ask=ask))\n\n\ndef summarize_chunks(model: llm.LLMModel, chunks: List[str], ask: str) -> str:\n    summary_chunks = []\n    for chunk in chunks:\n        summary_chunks.append(_summarize_chunk(model, chunk, ask))\n    return _summarize_chunks(model, summary_chunks, ask)", "\ndef summarize_chunks(model: llm.LLMModel, chunks: List[str], ask: str) -> str:\n    summary_chunks = []\n    for chunk in chunks:\n        summary_chunks.append(_summarize_chunk(model, chunk, ask))\n    return _summarize_chunks(model, summary_chunks, ask)\n\n\nclass ReadLinkWrapper:\n    def __init__(self, summary_model: Optional[llm.LLMModel] = None, use_proxy: bool = True):\n        if summary_model is None:\n            self.summary_model = llm.get_default_fast_llm()\n        else:\n            self.summary_model = summary_model\n        self.use_proxy = use_proxy\n\n    def run(self, query: str) -> str:\n        if query.endswith(\".pdf\"):\n            return \"Cannot read links that end in pdf\"\n        try:\n            url, ask = query.split(\", \")\n        except ValueError:\n            return 'input was in the wrong format, it should be \"url, question\"'\n        chunks = chunk_and_strip_html(scrape_text(url, use_proxy=self.use_proxy), CHUNK_SIZE)\n        return summarize_chunks(self.summary_model, chunks, ask)", "class ReadLinkWrapper:\n    def __init__(self, summary_model: Optional[llm.LLMModel] = None, use_proxy: bool = True):\n        if summary_model is None:\n            self.summary_model = llm.get_default_fast_llm()\n        else:\n            self.summary_model = summary_model\n        self.use_proxy = use_proxy\n\n    def run(self, query: str) -> str:\n        if query.endswith(\".pdf\"):\n            return \"Cannot read links that end in pdf\"\n        try:\n            url, ask = query.split(\", \")\n        except ValueError:\n            return 'input was in the wrong format, it should be \"url, question\"'\n        chunks = chunk_and_strip_html(scrape_text(url, use_proxy=self.use_proxy), CHUNK_SIZE)\n        return summarize_chunks(self.summary_model, chunks, ask)", "\n\ndef get_read_link_tool(**kwargs) -> Tool:\n    read_link = ReadLinkWrapper(**kwargs)\n    return Tool(\n        name=\"Read Link\",\n        func=read_link.run,\n        description='useful to read and extract the contents of any link. the input should be \"url, question\", e.g. \"https://en.wikipedia.org/wiki/2023_in_the_United_States, list of events in april 2023\"',\n    )\n", ""]}
{"filename": "llm_oracle/tools/search.py", "chunked_list": ["from langchain.utilities import GoogleSerperAPIWrapper\nfrom langchain.agents import Tool\n\nfrom llm_oracle import processing_utils\n\n\nclass GoogleSerperSearchWrapper(GoogleSerperAPIWrapper):\n    @processing_utils.cache_func\n    def run(self, query: str) -> str:\n        return super().run(query)\n\n    def _parse_results(self, results: dict) -> str:\n        snippets = []\n\n        if results.get(\"answerBox\"):\n            answer_box = results.get(\"answerBox\", {})\n            if answer_box.get(\"answer\"):\n                return answer_box.get(\"answer\")\n            elif answer_box.get(\"snippet\"):\n                return answer_box.get(\"snippet\").replace(\"\\n\", \" \")\n            elif answer_box.get(\"snippetHighlighted\"):\n                return \", \".join(answer_box.get(\"snippetHighlighted\"))\n\n        if results.get(\"knowledgeGraph\"):\n            kg = results.get(\"knowledgeGraph\", {})\n            title = kg.get(\"title\")\n            entity_type = kg.get(\"type\")\n            if entity_type:\n                snippets.append(f\"{title}: {entity_type}.\")\n            description = kg.get(\"description\")\n            if description:\n                snippets.append(description)\n            for attribute, value in kg.get(\"attributes\", {}).items():\n                snippets.append(f\"{title} {attribute}: {value}.\")\n\n        for result in results[\"organic\"][: self.k]:\n            if \"snippet\" in result:\n                snippets.append(f'{result[\"title\"]}: {result[\"snippet\"]} (link {result[\"link\"]})')\n            for attribute, value in result.get(\"attributes\", {}).items():\n                snippets.append(f'{result[\"title\"]}: {attribute} = {value}.')\n\n        if len(snippets) == 0:\n            return \"No good results found\"\n\n        return \"\\n\\n\".join(snippets)", "\n\ndef get_search_tool(**kwargs) -> Tool:\n    search = GoogleSerperSearchWrapper(**kwargs)\n    return Tool(\n        name=\"Search Term\",\n        func=search.run,\n        description=\"useful for when you need to find information about general things, names, usernames, places, etc. the input should be a search term\",\n    )\n", ""]}
{"filename": "llm_oracle/agents/base.py", "chunked_list": ["from typing import List, Dict\nfrom abc import ABC, abstractmethod\n\nfrom llm_oracle.markets.base import MarketEvent\n\n\nclass OracleAgent(ABC):\n    @abstractmethod\n    def predict_event_probability(self, event: MarketEvent) -> float:\n        return", ""]}
{"filename": "llm_oracle/agents/agent_tools.py", "chunked_list": ["from typing import Optional, List, Dict\n\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.agents import AgentType, initialize_agent, load_tools\nfrom langchain.input import print_text\nfrom langchain.callbacks.base import CallbackManager\n\nfrom llm_oracle import llm\nfrom llm_oracle.tools.search import get_search_tool\nfrom llm_oracle.tools.read_link import get_read_link_tool", "from llm_oracle.tools.search import get_search_tool\nfrom llm_oracle.tools.read_link import get_read_link_tool\nfrom llm_oracle.agents.base import OracleAgent\nfrom llm_oracle.agents.output import OUTPUT_PROMPT_P10, parse_p10_output, OUTPUT_PROMPT_LIKELY, parse_likely_output\nfrom llm_oracle.markets.base import MarketEvent\n\n\nTOOL_V1_QUESTION = f\"\"\"\nPredict the outcome of the following event.\n", "Predict the outcome of the following event.\n\n{{event_text}}\n\nRespond with:\n* What you learned might know about this.\n* Arguments for the event\n* Arguments against the event\n\n{OUTPUT_PROMPT_P10}", "\n{OUTPUT_PROMPT_P10}\n\"\"\"\n\nTOOL_V1_PREFIX = \"\"\"\nYou are an expert forecasting analyst with tons knowledge and skill in making calibrated conclusions. \n\nYou never say \"I don't know\" and you are very thorough at using tools to perform the need research and investigation.\n\nYou always investigate both sides of an argument.", "\nYou always investigate both sides of an argument.\n\nYou always keep in mind that old sources might be outdated and no longer accurate.\n\nGiven the users prediction question, answer to the best of your ability and follow their instructions. \n\nYou have access to the following tools:\n\"\"\"\n", "\"\"\"\n\nTOOL_V1_FORMAT_INSTRUCTIONS = \"\"\"The way you use the tools is by specifying a json blob.\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n\nThe only values that should be in the \"action\" field are: {tool_names}\n\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n\n```", "\n```\n{{{{\n  \"action\": $TOOL_NAME,\n  \"action_input\": $INPUT\n}}}}\n```\n\nALWAYS use the following format:\n", "ALWAYS use the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction:\n```\n$JSON_BLOB\n```\nObservation: the result of the action\n... (this Thought/Action/Observation can repeat N times)", "Observation: the result of the action\n... (this Thought/Action/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\"\"\"\n\nTOOL_V1_SUFFIX = \"\"\"\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\n\"\"\"\n\n\nclass ToolAgentv1(OracleAgent):\n    def __init__(\n        self,\n        verbose: Optional[bool] = True,\n        model: Optional[llm.BaseChatModel] = None,\n        tool_model: Optional[llm.BaseChatModel] = None,\n        callback_manager: Optional[CallbackManager] = None,\n        use_proxy: Optional[bool] = True,\n    ):\n        self.model = model or llm.get_default_llm()\n        self.tool_model = tool_model or llm.get_default_fast_llm()\n        self.verbose = verbose\n        self.callback_manager = callback_manager\n        self.use_proxy = use_proxy\n\n    def get_tools(self) -> List:\n        return [\n            get_search_tool(),\n            get_read_link_tool(summary_model=self.tool_model, use_proxy=self.use_proxy),\n        ] + load_tools([\"wolfram-alpha\", \"llm-math\"], llm=self.model)\n\n    def get_agent_kwargs(self) -> Dict:\n        return {\n            \"prefix\": TOOL_V1_PREFIX,\n            \"suffix\": TOOL_V1_SUFFIX,\n            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n        }\n\n    def get_chain_prompt(self) -> str:\n        return TOOL_V1_QUESTION\n\n    def parse_output(self, result: str) -> float:\n        return parse_p10_output(result)\n\n    def predict_event_probability(self, event: MarketEvent) -> float:\n        memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n        agent_chain = initialize_agent(\n            self.get_tools(),\n            self.model,\n            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n            verbose=True,\n            memory=memory,\n            agent_kwargs=self.get_agent_kwargs(),\n            callback_manager=self.callback_manager,\n        )\n\n        event_text = event.to_text()\n        if self.verbose:\n            print_text(event_text + \"\\n\", \"green\")\n\n        result = agent_chain.run(input=self.get_chain_prompt().format(event_text=event_text))\n        if self.verbose:\n            print_text(result + \"\\n\", \"yellow\")\n        return self.parse_output(result)", "\n\nclass ToolAgentv1(OracleAgent):\n    def __init__(\n        self,\n        verbose: Optional[bool] = True,\n        model: Optional[llm.BaseChatModel] = None,\n        tool_model: Optional[llm.BaseChatModel] = None,\n        callback_manager: Optional[CallbackManager] = None,\n        use_proxy: Optional[bool] = True,\n    ):\n        self.model = model or llm.get_default_llm()\n        self.tool_model = tool_model or llm.get_default_fast_llm()\n        self.verbose = verbose\n        self.callback_manager = callback_manager\n        self.use_proxy = use_proxy\n\n    def get_tools(self) -> List:\n        return [\n            get_search_tool(),\n            get_read_link_tool(summary_model=self.tool_model, use_proxy=self.use_proxy),\n        ] + load_tools([\"wolfram-alpha\", \"llm-math\"], llm=self.model)\n\n    def get_agent_kwargs(self) -> Dict:\n        return {\n            \"prefix\": TOOL_V1_PREFIX,\n            \"suffix\": TOOL_V1_SUFFIX,\n            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n        }\n\n    def get_chain_prompt(self) -> str:\n        return TOOL_V1_QUESTION\n\n    def parse_output(self, result: str) -> float:\n        return parse_p10_output(result)\n\n    def predict_event_probability(self, event: MarketEvent) -> float:\n        memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n        agent_chain = initialize_agent(\n            self.get_tools(),\n            self.model,\n            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n            verbose=True,\n            memory=memory,\n            agent_kwargs=self.get_agent_kwargs(),\n            callback_manager=self.callback_manager,\n        )\n\n        event_text = event.to_text()\n        if self.verbose:\n            print_text(event_text + \"\\n\", \"green\")\n\n        result = agent_chain.run(input=self.get_chain_prompt().format(event_text=event_text))\n        if self.verbose:\n            print_text(result + \"\\n\", \"yellow\")\n        return self.parse_output(result)", "\n\nTOOL_V2_QUESTION = f\"\"\"\nPredict the outcome of the following event.\n\n{{event_text}}\n\nRespond with:\n* What you learned about this\n* Arguments for the event", "* What you learned about this\n* Arguments for the event\n* Rebuttal to your arguments for the event\n* Arguments against the event\n* Rebuttal to your arguments against the event\n\n{OUTPUT_PROMPT_P10}\n\"\"\"\n\nTOOL_V2_PREFIX = \"\"\"", "\nTOOL_V2_PREFIX = \"\"\"\nYou are an expert forecasting analyst with the ability to make well calibrated predictions about the future. \n\nYou never say \"I don't know\" and you are very thorough at using tools to perform the need research and investigation.\n\nYou always investigate both sides of an argument and weights the facts by validity of your sources.\n\nYou always keep in mind that old sources might be outdated and no longer accurate.\n", "You always keep in mind that old sources might be outdated and no longer accurate.\n\nGiven the users prediction question, answer to the best of your ability and follow their instructions. \n\nYou have access to the following tools:\n\"\"\"\n\n\nclass ToolAgentv2(ToolAgentv1):\n    def get_agent_kwargs(self) -> Dict:\n        return {\n            \"prefix\": TOOL_V2_PREFIX,\n            \"suffix\": TOOL_V1_SUFFIX,\n            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n        }\n\n    def get_chain_prompt(self) -> str:\n        return TOOL_V2_QUESTION", "class ToolAgentv2(ToolAgentv1):\n    def get_agent_kwargs(self) -> Dict:\n        return {\n            \"prefix\": TOOL_V2_PREFIX,\n            \"suffix\": TOOL_V1_SUFFIX,\n            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n        }\n\n    def get_chain_prompt(self) -> str:\n        return TOOL_V2_QUESTION", "\n\nTOOL_V3_QUESTION = f\"\"\"\nPredict the outcome of the following event.\n\n{{event_text}}\n\nRespond with:\n* What you learned about this\n* Arguments for the event", "* What you learned about this\n* Arguments for the event\n* Rebuttal to your arguments for the event\n* Arguments against the event\n* Rebuttal to your arguments against the event\n\n{OUTPUT_PROMPT_LIKELY}\n\"\"\"\n\n\nclass ToolAgentv3(ToolAgentv1):\n    def get_agent_kwargs(self) -> Dict:\n        return {\n            \"prefix\": TOOL_V2_PREFIX,\n            \"suffix\": TOOL_V1_SUFFIX,\n            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n        }\n\n    def get_chain_prompt(self) -> str:\n        return TOOL_V3_QUESTION\n\n    def parse_output(self, result: str) -> float:\n        return parse_likely_output(result)", "\n\nclass ToolAgentv3(ToolAgentv1):\n    def get_agent_kwargs(self) -> Dict:\n        return {\n            \"prefix\": TOOL_V2_PREFIX,\n            \"suffix\": TOOL_V1_SUFFIX,\n            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n        }\n\n    def get_chain_prompt(self) -> str:\n        return TOOL_V3_QUESTION\n\n    def parse_output(self, result: str) -> float:\n        return parse_likely_output(result)", ""]}
{"filename": "llm_oracle/agents/agent_basic.py", "chunked_list": ["from typing import Optional, Callable\n\nfrom langchain.schema import HumanMessage, SystemMessage\nfrom langchain.input import print_text\n\nfrom llm_oracle import llm\nfrom llm_oracle.agents.base import OracleAgent\nfrom llm_oracle.agents.output import OUTPUT_PROMPT_P10, parse_p10_output, OUTPUT_PROMPT_LIKELY, parse_likely_output\nfrom llm_oracle.markets.base import MarketEvent\n", "from llm_oracle.markets.base import MarketEvent\n\n\nPROMPT_SYSTEM_BASIC_AGENT_V1 = \"\"\"\nYou are an expert analyst with tons of already knowledge. You already know everything and you never say \"I don't know\".\n\nGiven the users prediction question, answer to the best of your ability and follow their instructions.\n\"\"\"\n\nPROMPT_HUMAN_BASIC_AGENT_V1 = f\"\"\"", "\nPROMPT_HUMAN_BASIC_AGENT_V1 = f\"\"\"\nPredict the outcome of the following event.\n\n{{event_text}}\n\nRespond with what you already might know about this.\n\n{OUTPUT_PROMPT_P10}\n\"\"\"", "{OUTPUT_PROMPT_P10}\n\"\"\"\n\n\nclass BasicAgentv1(OracleAgent):\n    def __init__(\n        self,\n        verbose: Optional[bool] = True,\n        model: Optional[llm.BaseChatModel] = None,\n        output_callback: Optional[Callable[[str], None]] = None,\n    ):\n        self.model = model or llm.get_default_llm()\n        self.verbose = verbose\n        self.output_callback = output_callback\n\n    def get_system_prompt(self) -> str:\n        return PROMPT_SYSTEM_BASIC_AGENT_V1\n\n    def get_human_prompt(self) -> str:\n        return PROMPT_HUMAN_BASIC_AGENT_V1\n\n    def parse_output(self, result: str) -> float:\n        return parse_p10_output(result)\n\n    def predict_event_probability(self, event: MarketEvent) -> float:\n        event_text = event.to_text()\n        if self.verbose:\n            print_text(event_text + \"\\n\", \"green\")\n        human_message = self.get_human_prompt().format(event_text=event_text)\n        result = self.model([SystemMessage(content=self.get_system_prompt()), HumanMessage(content=human_message)])\n        if self.output_callback:\n            self.output_callback(result.content)\n        if self.verbose:\n            print_text(result.content + \"\\n\", \"yellow\")\n        return self.parse_output(result.content)", "\n\nPROMPT_HUMAN_BASIC_AGENT_V2 = f\"\"\"\nPredict the outcome of the following event.\n\n{{event_text}}\n\nRespond with:\n* What you learned might know about this.\n* Arguments for the event", "* What you learned might know about this.\n* Arguments for the event\n* Arguments against the event\n\n{OUTPUT_PROMPT_P10}\n\"\"\"\n\n\nclass BasicAgentv2(BasicAgentv1):\n    def get_system_prompt(self) -> str:\n        return PROMPT_SYSTEM_BASIC_AGENT_V1\n\n    def get_human_prompt(self) -> str:\n        return PROMPT_HUMAN_BASIC_AGENT_V2", "class BasicAgentv2(BasicAgentv1):\n    def get_system_prompt(self) -> str:\n        return PROMPT_SYSTEM_BASIC_AGENT_V1\n\n    def get_human_prompt(self) -> str:\n        return PROMPT_HUMAN_BASIC_AGENT_V2\n\n\nPROMPT_HUMAN_BASIC_AGENT_V3 = f\"\"\"\nPredict the outcome of the following event.", "PROMPT_HUMAN_BASIC_AGENT_V3 = f\"\"\"\nPredict the outcome of the following event.\n\n{{event_text}}\n\nRespond with:\n* What you learned might know about this.\n* Arguments for the event\n* Arguments against the event\n", "* Arguments against the event\n\n{OUTPUT_PROMPT_LIKELY}\n\"\"\"\n\n\nclass BasicAgentv3(BasicAgentv1):\n    def get_system_prompt(self) -> str:\n        return PROMPT_SYSTEM_BASIC_AGENT_V1\n\n    def get_human_prompt(self) -> str:\n        return PROMPT_HUMAN_BASIC_AGENT_V3\n\n    def parse_output(self, result: str) -> float:\n        return parse_likely_output(result)", ""]}
{"filename": "llm_oracle/agents/__init__.py", "chunked_list": [""]}
{"filename": "llm_oracle/agents/output.py", "chunked_list": ["import re\n\n\nOUTPUT_PROMPT_P10 = \"\"\"\nFinally, output a score between 0 and 10 (0 = high confident no or P(event) = 0%, 5 = unsure, 10 = high confident yes or P(event) = 100%).\n\nYou must use the format \"score=...\", e.g. score=3 or score=7. Use whole numbers. If you have a probability p [0.0, 1.0], then score = int(p*10).\n\"\"\"\n\nOUTPUT_PROMPT_P10_SCORE_REGEXES = [r\"[Ss]core\\s*=\\s*(\\d+)\", r\"[Ss]core\\s*of\\s*(\\d+)\"]", "\nOUTPUT_PROMPT_P10_SCORE_REGEXES = [r\"[Ss]core\\s*=\\s*(\\d+)\", r\"[Ss]core\\s*of\\s*(\\d+)\"]\n\n\ndef parse_p10_output(output: str) -> float:\n    for regex in OUTPUT_PROMPT_P10_SCORE_REGEXES:\n        score_match = re.search(regex, output)\n        if score_match:\n            return int(score_match.group(1)) / 10\n    raise ValueError(output)", "\n\nOUTPUT_PROMPT_LIKELY = \"\"\"\nFinally, output a prediction from VERY_UNLIKELY to VERY_LIKELY.\n\nHere are the probabilities of each token:\n- VERY_UNLIKELY: 0% - 10%\n- UNLIKELY: 10% - 30%\n- SOMEWHAT_UNLIKELY: 30% - 45%\n- EVEN: 45% - 55%", "- SOMEWHAT_UNLIKELY: 30% - 45%\n- EVEN: 45% - 55%\n- SOMEWHAT_LIKELY: 55% - 70%\n- LIKELY: 70% - 90%\n- VERY_UNLIKELY: 90% - 100%\n\nYou must respond with exactly one of the tokens above like `prediction=SOMEWHAT_UNLIKELY` or `prediction=SOMEWHAT_LIKELY`.\n\"\"\"\n\nLIKELY_MAPPINGS = {", "\nLIKELY_MAPPINGS = {\n    \"VERY_UNLIKELY\": 0.05,\n    \"VERY_LIKELY\": 0.95,\n    \"SOMEWHAT_UNLIKELY\": 0.37,\n    \"SOMEWHAT_LIKELY\": 0.62,\n    \"UNLIKELY\": 0.2,\n    \"LIKELY\": 0.8,\n    \"EVEN\": 0.5,\n}", "    \"EVEN\": 0.5,\n}\n\n\ndef parse_likely_output(output: str) -> float:\n    for k, p in LIKELY_MAPPINGS.items():\n        if k in output:\n            return p\n    for k, p in LIKELY_MAPPINGS.items():\n        if k.lower().replace(\"_\", \"\") in output.lower().replace(\" \", \"\"):\n            return p\n    raise ValueError(output)", ""]}
{"filename": "llm_oracle/markets/custom.py", "chunked_list": ["from typing import List, Dict, Optional\nimport datetime\n\nfrom llm_oracle.markets.base import Market, MarketEvent\nfrom llm_oracle import text_utils, processing_utils\n\n\nclass CustomEvent(MarketEvent):\n    def __init__(self, question: str, close_date: datetime.datetime, prior: Optional[float] = 0.5):\n        self.question = question\n        self.close_date = close_date\n        self.prior = prior\n\n    def to_text(self, *args, **kwargs) -> str:\n        text = [\"Prediction Market\"]\n        text.append(f'Will the following statement resolve to yes by the close date: \"{self.question}\"')\n        end_date = self.get_end_date()\n        if end_date is not None:\n            text.append(f\"close_date: {text_utils.future_date_to_string(self.get_end_date())}\")\n        text.append(text_utils.world_state_to_string())\n        return \"\\n\".join(text)\n\n    def get_title(self) -> str:\n        return self.question\n\n    def get_end_date(self) -> datetime.datetime:\n        return self.close_date\n\n    def get_market_probability(self) -> float:\n        return self.prior\n\n    def get_universal_id(self) -> str:\n        return \"custom:\" + processing_utils.hash_str(repr([self.question, self.close_date]))\n\n    def to_dict(self) -> Dict:\n        return {\"question\": self.question, \"close_date\": self.close_date}\n\n    def is_active(self) -> bool:\n        return True\n\n    def get_market_result(self) -> Optional[float]:\n        raise NotImplementedError()", "\n\nclass CustomMarket(Market):\n    def __init__(self, events: List[MarketEvent]):\n        self.events = events\n\n    def search(self, *args, **kwargs) -> List[Dict]:\n        return [event.to_dict() for event in self.events]\n\n    def get_event(self, event_id: str) -> CustomEvent:\n        return self.events[int(event_id)]", ""]}
{"filename": "llm_oracle/markets/base.py", "chunked_list": ["from typing import List, Dict, Optional\nimport datetime\nfrom abc import ABC, abstractmethod\n\n\nclass MarketEvent(ABC):\n    @abstractmethod\n    def to_text(self, *args, **kwargs) -> str:\n        return\n\n    @abstractmethod\n    def get_end_date(self) -> datetime.datetime:\n        return\n\n    @abstractmethod\n    def get_market_probability(self) -> float:\n        return\n\n    @abstractmethod\n    def get_market_result(self) -> Optional[float]:\n        return\n\n    @abstractmethod\n    def get_title(self) -> str:\n        return\n\n    @abstractmethod\n    def get_universal_id(self) -> str:\n        return\n\n    @abstractmethod\n    def is_active(self) -> bool:\n        return", "\n\nclass Market(ABC):\n    @abstractmethod\n    def search(self, *args, **kwargs) -> List[Dict]:\n        return\n\n    @abstractmethod\n    def get_event(self, event_id: str) -> MarketEvent:\n        return", ""]}
{"filename": "llm_oracle/markets/kalshi.py", "chunked_list": ["from typing import List, Dict, Optional\nimport requests\nimport datetime\nimport dateparser\nimport kalshi_python\n\nfrom llm_oracle.markets.base import Market, MarketEvent\nfrom llm_oracle import text_utils\n\nconfig = kalshi_python.Configuration()", "\nconfig = kalshi_python.Configuration()\n\n\nclass KalshiEvent(MarketEvent):\n    def __init__(self, resp_json: Dict):\n        self.resp_json = resp_json\n\n    def to_text(self, *args, **kwargs) -> str:\n        text = [\"Kalshi Market\"]\n        for key in [\"title\", \"category\", \"subtitle\", \"can_close_early\"]:\n            text.append(f\"{key}: {self.resp_json[key]}\")\n        text.append(f\"close_date: {text_utils.future_date_to_string(self.get_end_date())}\")\n        text.append(text_utils.world_state_to_string())\n        return \"\\n\".join(text)\n\n    def get_title(self) -> str:\n        return self.resp_json[\"title\"]\n\n    def get_end_date(self) -> datetime.datetime:\n        return dateparser.parse(self.resp_json[\"close_time\"])\n\n    def get_market_probability(self) -> float:\n        return self.resp_json[\"last_price\"] / 100\n\n    def get_universal_id(self) -> str:\n        return \"kalshi2:\" + self.resp_json[\"ticker\"]\n\n    def is_active(self) -> bool:\n        return self.resp_json[\"status\"] == \"active\"\n\n    def get_market_result(self) -> Optional[float]:\n        result = self.resp_json.get(\"result\")\n        if result is None or result not in {\"yes\", \"no\"}:\n            return None\n        else:\n            return 1.0 if result == \"yes\" else 0.0", "\n\nclass KalshiMarket(Market):\n    def __init__(self, email: str, password: str):\n        self.session = kalshi_python.ApiInstance(\n            email=email,\n            password=password,\n            configuration=config,\n        )\n\n    def search(self, *args, **kwargs) -> List[Dict]:\n        return self.session.get_markets(*args, **kwargs).to_dict()[\"markets\"]\n\n    def get_event(self, event_id: str) -> KalshiEvent:\n        return KalshiEvent(self.session.get_market(event_id).to_dict()[\"market\"])", ""]}
{"filename": "llm_oracle/markets/manifold.py", "chunked_list": ["from typing import List, Dict, Optional\nimport datetime\n\nfrom pymanifold import ManifoldClient, LiteMarket\n\nfrom llm_oracle.markets.base import Market, MarketEvent\nfrom llm_oracle import text_utils\n\n\ndef _content_to_text(node: Dict) -> str:\n    text = []\n    if \"content\" in node:\n        for content in node[\"content\"]:\n            text.append(_content_to_text(content))\n    if \"text\" in node:\n        text.append(node[\"text\"])\n    return \"\\n\".join(text)", "\ndef _content_to_text(node: Dict) -> str:\n    text = []\n    if \"content\" in node:\n        for content in node[\"content\"]:\n            text.append(_content_to_text(content))\n    if \"text\" in node:\n        text.append(node[\"text\"])\n    return \"\\n\".join(text)\n", "\n\nclass ManifoldEvent(MarketEvent):\n    def __init__(self, event_market: LiteMarket):\n        self.event_market = event_market\n\n    def to_text(self, *args, **kwargs) -> str:\n        text = [\"Manifold Market\"]\n        text.append(f\"question: {self.event_market.question}\")\n        text.append(f\"close_date: {text_utils.future_date_to_string(self.get_end_date())}\")\n        text.append(text_utils.world_state_to_string())\n        text.append(f\"description: \\n```\\n{self.get_description().strip()[:2000]}\\n```\")\n        return \"\\n\".join(text)\n\n    def get_description(self) -> str:\n        if self.event_market.description is None:\n            return \"\"\n        return _content_to_text(self.event_market.description)\n\n    def get_title(self) -> str:\n        return self.event_market.question\n\n    def get_end_date(self) -> datetime.datetime:\n        return datetime.datetime.fromtimestamp(self.event_market.closeTime / 1000)\n\n    def get_market_probability(self) -> float:\n        return self.event_market.probability\n\n    def get_universal_id(self) -> str:\n        return \"manifold2:\" + self.event_market.id\n\n    def is_active(self) -> bool:\n        return not self.event_market.isResolved\n\n    def get_market_result(self) -> Optional[float]:\n        res_p = self.event_market.resolutionProbability\n        return None if res_p is None else float(res_p)", "\n\nclass ManifoldMarket(Market):\n    def __init__(self, **kwargs):\n        self.client = ManifoldClient(**kwargs)\n\n    def search(self, *args, **kwargs) -> List[Dict]:\n        return [dict(m.__dict__) for m in self.client.list_markets(*args, **kwargs)]\n\n    def get_event(self, event_id: str) -> ManifoldEvent:\n        if \"-\" in event_id:\n            me = self.client.get_market_by_slug(event_id)\n        else:\n            me = self.client.get_market_by_id(event_id)\n        return ManifoldEvent(me)", ""]}
{"filename": "llm_oracle/markets/__init__.py", "chunked_list": [""]}
{"filename": "examples/predict_markets.py", "chunked_list": ["from llm_oracle.markets.kalshi import KalshiMarket\nfrom llm_oracle.markets.custom import CustomMarket, CustomEvent\nfrom llm_oracle.markets.manifold import ManifoldMarket\nfrom llm_oracle.agents.agent_basic import BasicAgentv1, BasicAgentv2, BasicAgentv3\nfrom llm_oracle.agents.agent_tools import ToolAgentv1, ToolAgentv2, ToolAgentv3\nimport datetime\nimport os\n\nmanifold_market = ManifoldMarket()\nkalshi_market = KalshiMarket(email=os.environ[\"KALSHI_EMAIL\"], password=os.environ[\"KALSHI_PASSWORD\"])", "manifold_market = ManifoldMarket()\nkalshi_market = KalshiMarket(email=os.environ[\"KALSHI_EMAIL\"], password=os.environ[\"KALSHI_PASSWORD\"])\n\nkalshi_event_ids = [\n    \"GTEMP-23-P1.02\",\n    \"NPPC-24DEC31\",\n    \"BIDENVNEBRASKA-24DEC31\",\n    \"TIKTOKBAN-23DEC31\",\n    \"SFFA-COMPLETE\",\n    \"COIN-23DEC31\",", "    \"SFFA-COMPLETE\",\n    \"COIN-23DEC31\",\n    \"HURCTOTMAJ-23DEC01-T3\",\n    \"SCOTUSN-23\",\n    \"MOON-25\",\n]\n\nmanifold_event_ids = [\n    \"will-lex-fridman-interview-ai-by-20\",\n    \"will-biden-be-the-2024-democratic-n\",", "    \"will-lex-fridman-interview-ai-by-20\",\n    \"will-biden-be-the-2024-democratic-n\",\n    \"will-a-nuclear-weapon-be-detonated-b71e74f6a8e4\",\n]\n\ncustom_market = CustomMarket(\n    [\n        CustomEvent(\n            \"Will a humanity be replaced by AI by 2050?\",\n            datetime.datetime(2050, 1, 1),", "            \"Will a humanity be replaced by AI by 2050?\",\n            datetime.datetime(2050, 1, 1),\n        ),\n        CustomEvent(\n            \"Will a random number that I pull from a uniform distribution [0, 100] be greater or equal to 99?\",\n            datetime.datetime(2025, 1, 1),\n        ),\n    ]\n)\n", ")\n\n\nEVENTS = (\n    [kalshi_market.get_event(kid) for kid in kalshi_event_ids]\n    + [manifold_market.get_event(mid) for mid in manifold_event_ids]\n    + custom_market.events\n)\n\nAGENTS = {", "\nAGENTS = {\n    \"basic_v1\": BasicAgentv1(),\n    \"basic_v2\": BasicAgentv2(),\n    \"basic_v3\": BasicAgentv3(),\n    \"tool_v1\": ToolAgentv1(),\n    \"tool_v2\": ToolAgentv2(),\n    \"tool_v3\": ToolAgentv3(),\n}\n", "}\n\n\nfor event in EVENTS:\n    if not event.is_active():\n        continue\n    title = event.get_title()\n    event_uid = event.get_universal_id()\n    market_p = event.get_market_probability()\n    for agent_name, agent in AGENTS.items():\n        p = agent.predict_event_probability(event)\n        with open(\"predictions.tsv\", \"a\") as f:\n            f.write(f\"{event_uid}\\t{title}\\t{market_p}\\t{agent_name}\\t{p}\\n\")", ""]}
