{"filename": "setup.py", "chunked_list": ["import setuptools\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as f:\n    long_description = f.read()\n\n\n__version__ = \"0.0.0\"\n\nREPO_NAME = \"Chicken-Disease-Classification--Project\"\nAUTHOR_USER_NAME = \"entbappy\"", "REPO_NAME = \"Chicken-Disease-Classification--Project\"\nAUTHOR_USER_NAME = \"entbappy\"\nSRC_REPO = \"cnnClassifier\"\nAUTHOR_EMAIL = \"entbappy73@gmail.com\"\n\n\nsetuptools.setup(\n    name=SRC_REPO,\n    version=__version__,\n    author=AUTHOR_USER_NAME,", "    version=__version__,\n    author=AUTHOR_USER_NAME,\n    author_email=AUTHOR_EMAIL,\n    description=\"A small python package for CNN app\",\n    long_description=long_description,\n    long_description_content=\"text/markdown\",\n    url=f\"https://github.com/{AUTHOR_USER_NAME}/{REPO_NAME}\",\n    project_urls={\n        \"Bug Tracker\": f\"https://github.com/{AUTHOR_USER_NAME}/{REPO_NAME}/issues\",\n    },", "        \"Bug Tracker\": f\"https://github.com/{AUTHOR_USER_NAME}/{REPO_NAME}/issues\",\n    },\n    package_dir={\"\": \"src\"},\n    packages=setuptools.find_packages(where=\"src\")\n)"]}
{"filename": "main.py", "chunked_list": ["from cnnClassifier import logger\nfrom cnnClassifier.pipeline.stage_01_data_ingestion import DataIngestionTrainingPipeline\nfrom cnnClassifier.pipeline.stage_02_prepare_base_model import PrepareBaseModelTrainingPipeline\nfrom cnnClassifier.pipeline.stage_03_training import ModelTrainingPipeline\nfrom cnnClassifier.pipeline.stage_04_evaluation import EvaluationPipeline\n\n\nSTAGE_NAME = \"Data Ingestion stage\"\ntry:\n   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\") \n   data_ingestion = DataIngestionTrainingPipeline()\n   data_ingestion.main()\n   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\nexcept Exception as e:\n        logger.exception(e)\n        raise e", "try:\n   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\") \n   data_ingestion = DataIngestionTrainingPipeline()\n   data_ingestion.main()\n   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\nexcept Exception as e:\n        logger.exception(e)\n        raise e\n\n", "\n\n\n\nSTAGE_NAME = \"Prepare base model\"\ntry: \n   logger.info(f\"*******************\")\n   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n   prepare_base_model = PrepareBaseModelTrainingPipeline()\n   prepare_base_model.main()\n   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\nexcept Exception as e:\n        logger.exception(e)\n        raise e", "\n\n\n\nSTAGE_NAME = \"Training\"\ntry: \n   logger.info(f\"*******************\")\n   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n   model_trainer = ModelTrainingPipeline()\n   model_trainer.main()\n   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\nexcept Exception as e:\n        logger.exception(e)\n        raise e", "\n\n\n\n\n\nSTAGE_NAME = \"Evaluation stage\"\ntry:\n   logger.info(f\"*******************\")\n   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n   model_evalution = EvaluationPipeline()\n   model_evalution.main()\n   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n\nexcept Exception as e:\n        logger.exception(e)\n        raise e", "\n\n\n\n"]}
{"filename": "app.py", "chunked_list": ["from flask import Flask, request, jsonify, render_template\nimport os\nfrom flask_cors import CORS, cross_origin\nfrom cnnClassifier.utils.common import decodeImage\nfrom cnnClassifier.pipeline.predict import PredictionPipeline\n\n\nos.putenv('LANG', 'en_US.UTF-8')\nos.putenv('LC_ALL', 'en_US.UTF-8')\n", "os.putenv('LC_ALL', 'en_US.UTF-8')\n\napp = Flask(__name__)\nCORS(app)\n\n\nclass ClientApp:\n    def __init__(self):\n        self.filename = \"inputImage.jpg\"\n        self.classifier = PredictionPipeline(self.filename)", "\n\n@app.route(\"/\", methods=['GET'])\n@cross_origin()\ndef home():\n    return render_template('index.html')\n\n\n@app.route(\"/train\", methods=['GET','POST'])\n@cross_origin()\ndef trainRoute():\n    os.system(\"python main.py\")\n    return \"Training done successfully!\"", "@app.route(\"/train\", methods=['GET','POST'])\n@cross_origin()\ndef trainRoute():\n    os.system(\"python main.py\")\n    return \"Training done successfully!\"\n\n\n\n@app.route(\"/predict\", methods=['POST'])\n@cross_origin()\ndef predictRoute():\n    image = request.json['image']\n    decodeImage(image, clApp.filename)\n    result = clApp.classifier.predict()\n    return jsonify(result)", "@app.route(\"/predict\", methods=['POST'])\n@cross_origin()\ndef predictRoute():\n    image = request.json['image']\n    decodeImage(image, clApp.filename)\n    result = clApp.classifier.predict()\n    return jsonify(result)\n\n\nif __name__ == \"__main__\":\n    clApp = ClientApp()\n    # app.run(host='0.0.0.0', port=8080) #local host\n    # app.run(host='0.0.0.0', port=8080) #for AWS\n    app.run(host='0.0.0.0', port=80) #for AZURE", "\nif __name__ == \"__main__\":\n    clApp = ClientApp()\n    # app.run(host='0.0.0.0', port=8080) #local host\n    # app.run(host='0.0.0.0', port=8080) #for AWS\n    app.run(host='0.0.0.0', port=80) #for AZURE\n\n"]}
{"filename": "template.py", "chunked_list": ["import os\nfrom pathlib import Path\nimport logging\n\nlogging.basicConfig(level=logging.INFO, format='[%(asctime)s]: %(message)s:')\n\n\nproject_name = \"cnnClassifier\"\n\nlist_of_files = [", "\nlist_of_files = [\n    \".github/workflows/.gitkeep\",\n    f\"src/{project_name}/__init__.py\",\n    f\"src/{project_name}/components/__init__.py\",\n    f\"src/{project_name}/utils/__init__.py\",\n    f\"src/{project_name}/config/__init__.py\",\n    f\"src/{project_name}/config/configuration.py\",\n    f\"src/{project_name}/pipeline/__init__.py\",\n    f\"src/{project_name}/entity/__init__.py\",", "    f\"src/{project_name}/pipeline/__init__.py\",\n    f\"src/{project_name}/entity/__init__.py\",\n    f\"src/{project_name}/constants/__init__.py\",\n    \"config/config.yaml\",\n    \"dvc.yaml\",\n    \"params.yaml\",\n    \"requirements.txt\",\n    \"setup.py\",\n    \"research/trials.ipynb\",\n    \"templates/index.html\"", "    \"research/trials.ipynb\",\n    \"templates/index.html\"\n\n\n]\n\n\nfor filepath in list_of_files:\n    filepath = Path(filepath)\n    filedir, filename = os.path.split(filepath)\n\n\n    if filedir !=\"\":\n        os.makedirs(filedir, exist_ok=True)\n        logging.info(f\"Creating directory; {filedir} for the file: {filename}\")\n\n    if (not os.path.exists(filepath)) or (os.path.getsize(filepath) == 0):\n        with open(filepath, \"w\") as f:\n            pass\n            logging.info(f\"Creating empty file: {filepath}\")\n\n\n    else:\n        logging.info(f\"{filename} is already exists\")"]}
{"filename": "src/cnnClassifier/__init__.py", "chunked_list": ["import os\nimport sys\nimport logging\n\nlogging_str = \"[%(asctime)s: %(levelname)s: %(module)s: %(message)s]\"\n\nlog_dir = \"logs\"\nlog_filepath = os.path.join(log_dir,\"running_logs.log\")\nos.makedirs(log_dir, exist_ok=True)\n", "os.makedirs(log_dir, exist_ok=True)\n\n\nlogging.basicConfig(\n    level= logging.INFO,\n    format= logging_str,\n\n    handlers=[\n        logging.FileHandler(log_filepath),\n        logging.StreamHandler(sys.stdout)", "        logging.FileHandler(log_filepath),\n        logging.StreamHandler(sys.stdout)\n    ]\n)\n\nlogger = logging.getLogger(\"cnnClassifierLogger\")\n\n"]}
{"filename": "src/cnnClassifier/components/evaluation.py", "chunked_list": ["import tensorflow as tf\nfrom pathlib import Path\nfrom cnnClassifier.entity.config_entity import EvaluationConfig\nfrom cnnClassifier.utils.common import save_json\n\n\n\nclass Evaluation:\n    def __init__(self, config: EvaluationConfig):\n        self.config = config\n\n    \n    def _valid_generator(self):\n\n        datagenerator_kwargs = dict(\n            rescale = 1./255,\n            validation_split=0.30\n        )\n\n        dataflow_kwargs = dict(\n            target_size=self.config.params_image_size[:-1],\n            batch_size=self.config.params_batch_size,\n            interpolation=\"bilinear\"\n        )\n\n        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n            **datagenerator_kwargs\n        )\n\n        self.valid_generator = valid_datagenerator.flow_from_directory(\n            directory=self.config.training_data,\n            subset=\"validation\",\n            shuffle=False,\n            **dataflow_kwargs\n        )\n\n    \n    @staticmethod\n    def load_model(path: Path) -> tf.keras.Model:\n        return tf.keras.models.load_model(path)\n    \n\n    def evaluation(self):\n        model = self.load_model(self.config.path_of_model)\n        self._valid_generator()\n        self.score = model.evaluate(self.valid_generator)\n\n    \n    def save_score(self):\n        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n        save_json(path=Path(\"scores.json\"), data=scores)", "\n    \n\n    "]}
{"filename": "src/cnnClassifier/components/__init__.py", "chunked_list": [""]}
{"filename": "src/cnnClassifier/components/prepare_base_model.py", "chunked_list": ["import os\nimport urllib.request as request\nfrom zipfile import ZipFile\nimport tensorflow as tf\nfrom pathlib import Path\nfrom cnnClassifier.entity.config_entity import PrepareBaseModelConfig\n\nclass PrepareBaseModel:\n    def __init__(self, config: PrepareBaseModelConfig):\n        self.config = config\n\n\n    \n    def get_base_model(self):\n        self.model = tf.keras.applications.vgg16.VGG16(\n            input_shape=self.config.params_image_size,\n            weights=self.config.params_weights,\n            include_top=self.config.params_include_top\n        )\n\n        self.save_model(path=self.config.base_model_path, model=self.model)\n\n\n    \n    @staticmethod\n    def _prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate):\n        if freeze_all:\n            for layer in model.layers:\n                model.trainable = False\n        elif (freeze_till is not None) and (freeze_till > 0):\n            for layer in model.layers[:-freeze_till]:\n                model.trainable = False\n\n        flatten_in = tf.keras.layers.Flatten()(model.output)\n        prediction = tf.keras.layers.Dense(\n            units=classes,\n            activation=\"softmax\"\n        )(flatten_in)\n\n        full_model = tf.keras.models.Model(\n            inputs=model.input,\n            outputs=prediction\n        )\n\n        full_model.compile(\n            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n            loss=tf.keras.losses.CategoricalCrossentropy(),\n            metrics=[\"accuracy\"]\n        )\n\n        full_model.summary()\n        return full_model\n    \n\n    def update_base_model(self):\n        self.full_model = self._prepare_full_model(\n            model=self.model,\n            classes=self.config.params_classes,\n            freeze_all=True,\n            freeze_till=None,\n            learning_rate=self.config.params_learning_rate\n        )\n\n        self.save_model(path=self.config.updated_base_model_path, model=self.full_model)\n\n    \n    @staticmethod\n    def save_model(path: Path, model: tf.keras.Model):\n        model.save(path)", "\n    \n\n\n"]}
{"filename": "src/cnnClassifier/components/training.py", "chunked_list": ["from cnnClassifier.entity.config_entity import TrainingConfig\nimport tensorflow as tf\nfrom pathlib import Path\n\n\nclass Training:\n    def __init__(self, config: TrainingConfig):\n        self.config = config\n    \n    def get_base_model(self):\n        self.model = tf.keras.models.load_model(\n            self.config.updated_base_model_path\n        )\n    \n    def train_valid_generator(self):\n\n        datagenerator_kwargs = dict(\n            rescale = 1./255,\n            validation_split=0.20\n        )\n\n        dataflow_kwargs = dict(\n            target_size=self.config.params_image_size[:-1],\n            batch_size=self.config.params_batch_size,\n            interpolation=\"bilinear\"\n        )\n\n        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n            **datagenerator_kwargs\n        )\n\n        self.valid_generator = valid_datagenerator.flow_from_directory(\n            directory=self.config.training_data,\n            subset=\"validation\",\n            shuffle=False,\n            **dataflow_kwargs\n        )\n\n        if self.config.params_is_augmentation:\n            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n                rotation_range=40,\n                horizontal_flip=True,\n                width_shift_range=0.2,\n                height_shift_range=0.2,\n                shear_range=0.2,\n                zoom_range=0.2,\n                **datagenerator_kwargs\n            )\n        else:\n            train_datagenerator = valid_datagenerator\n\n        self.train_generator = train_datagenerator.flow_from_directory(\n            directory=self.config.training_data,\n            subset=\"training\",\n            shuffle=True,\n            **dataflow_kwargs\n        )\n\n    @staticmethod\n    def save_model(path: Path, model: tf.keras.Model):\n        model.save(path)\n\n\n    def train(self, callback_list: list):\n        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n\n        self.model.fit(\n            self.train_generator,\n            epochs=self.config.params_epochs,\n            steps_per_epoch=self.steps_per_epoch,\n            validation_steps=self.validation_steps,\n            validation_data=self.valid_generator,\n            callbacks=callback_list\n        )\n\n        self.save_model(\n            path=self.config.trained_model_path,\n            model=self.model\n        )", "\n"]}
{"filename": "src/cnnClassifier/components/prepare_callbacks.py", "chunked_list": ["import os\nimport urllib.request as request\nfrom zipfile import ZipFile\nimport tensorflow as tf\nimport time\nfrom cnnClassifier.entity.config_entity import PrepareCallbacksConfig\n\n\nclass PrepareCallback:\n    def __init__(self, config: PrepareCallbacksConfig):\n        self.config = config\n\n\n    \n    @property\n    def _create_tb_callbacks(self):\n        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n        tb_running_log_dir = os.path.join(\n            self.config.tensorboard_root_log_dir,\n            f\"tb_logs_at_{timestamp}\",\n        )\n        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n    \n\n    @property\n    def _create_ckpt_callbacks(self):\n        return tf.keras.callbacks.ModelCheckpoint(\n            filepath=self.config.checkpoint_model_filepath,\n            save_best_only=True\n        )\n\n\n    def get_tb_ckpt_callbacks(self):\n        return [\n            self._create_tb_callbacks,\n            self._create_ckpt_callbacks\n        ]", "class PrepareCallback:\n    def __init__(self, config: PrepareCallbacksConfig):\n        self.config = config\n\n\n    \n    @property\n    def _create_tb_callbacks(self):\n        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n        tb_running_log_dir = os.path.join(\n            self.config.tensorboard_root_log_dir,\n            f\"tb_logs_at_{timestamp}\",\n        )\n        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n    \n\n    @property\n    def _create_ckpt_callbacks(self):\n        return tf.keras.callbacks.ModelCheckpoint(\n            filepath=self.config.checkpoint_model_filepath,\n            save_best_only=True\n        )\n\n\n    def get_tb_ckpt_callbacks(self):\n        return [\n            self._create_tb_callbacks,\n            self._create_ckpt_callbacks\n        ]", ""]}
{"filename": "src/cnnClassifier/components/data_ingestion.py", "chunked_list": ["import os\nimport urllib.request as request\nimport zipfile\nfrom cnnClassifier import logger\nfrom cnnClassifier.utils.common import get_size\nfrom cnnClassifier.entity.config_entity import DataIngestionConfig\nfrom pathlib import Path\n\n\nclass DataIngestion:\n    def __init__(self, config: DataIngestionConfig):\n        self.config = config\n\n\n    \n    def download_file(self):\n        if not os.path.exists(self.config.local_data_file):\n            filename, headers = request.urlretrieve(\n                url = self.config.source_URL,\n                filename = self.config.local_data_file\n            )\n            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n        else:\n            logger.info(f\"File already exists of size: {get_size(Path(self.config.local_data_file))}\")  \n\n\n    \n    def extract_zip_file(self):\n        \"\"\"\n        zip_file_path: str\n        Extracts the zip file into the data directory\n        Function returns None\n        \"\"\"\n        unzip_path = self.config.unzip_dir\n        os.makedirs(unzip_path, exist_ok=True)\n        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n            zip_ref.extractall(unzip_path)", "\nclass DataIngestion:\n    def __init__(self, config: DataIngestionConfig):\n        self.config = config\n\n\n    \n    def download_file(self):\n        if not os.path.exists(self.config.local_data_file):\n            filename, headers = request.urlretrieve(\n                url = self.config.source_URL,\n                filename = self.config.local_data_file\n            )\n            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n        else:\n            logger.info(f\"File already exists of size: {get_size(Path(self.config.local_data_file))}\")  \n\n\n    \n    def extract_zip_file(self):\n        \"\"\"\n        zip_file_path: str\n        Extracts the zip file into the data directory\n        Function returns None\n        \"\"\"\n        unzip_path = self.config.unzip_dir\n        os.makedirs(unzip_path, exist_ok=True)\n        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n            zip_ref.extractall(unzip_path)", "\n"]}
{"filename": "src/cnnClassifier/entity/config_entity.py", "chunked_list": ["from dataclasses import dataclass\nfrom pathlib import Path\n\n\n@dataclass(frozen=True)\nclass DataIngestionConfig:\n    root_dir: Path\n    source_URL: str\n    local_data_file: Path\n    unzip_dir: Path", "\n\n@dataclass(frozen=True)\nclass PrepareBaseModelConfig:\n    root_dir: Path\n    base_model_path: Path\n    updated_base_model_path: Path\n    params_image_size: list\n    params_learning_rate: float\n    params_include_top: bool\n    params_weights: str\n    params_classes: int", "\n\n\n@dataclass(frozen=True)\nclass PrepareCallbacksConfig:\n    root_dir: Path\n    tensorboard_root_log_dir: Path\n    checkpoint_model_filepath: Path\n\n", "\n\n\n@dataclass(frozen=True)\nclass TrainingConfig:\n    root_dir: Path\n    trained_model_path: Path\n    updated_base_model_path: Path\n    training_data: Path\n    params_epochs: int\n    params_batch_size: int\n    params_is_augmentation: bool\n    params_image_size: list", "\n\n\n@dataclass(frozen=True)\nclass EvaluationConfig:\n    path_of_model: Path\n    training_data: Path\n    all_params: dict\n    params_image_size: list\n    params_batch_size: int", ""]}
{"filename": "src/cnnClassifier/entity/__init__.py", "chunked_list": [""]}
{"filename": "src/cnnClassifier/utils/__init__.py", "chunked_list": [""]}
{"filename": "src/cnnClassifier/utils/common.py", "chunked_list": ["import os\nfrom box.exceptions import BoxValueError\nimport yaml\nfrom cnnClassifier import logger\nimport json\nimport joblib\nfrom ensure import ensure_annotations\nfrom box import ConfigBox\nfrom pathlib import Path\nfrom typing import Any", "from pathlib import Path\nfrom typing import Any\nimport base64\n\n\n\n@ensure_annotations\ndef read_yaml(path_to_yaml: Path) -> ConfigBox:\n    \"\"\"reads yaml file and returns\n\n    Args:\n        path_to_yaml (str): path like input\n\n    Raises:\n        ValueError: if yaml file is empty\n        e: empty file\n\n    Returns:\n        ConfigBox: ConfigBox type\n    \"\"\"\n    try:\n        with open(path_to_yaml) as yaml_file:\n            content = yaml.safe_load(yaml_file)\n            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n            return ConfigBox(content)\n    except BoxValueError:\n        raise ValueError(\"yaml file is empty\")\n    except Exception as e:\n        raise e", "    \n\n\n@ensure_annotations\ndef create_directories(path_to_directories: list, verbose=True):\n    \"\"\"create list of directories\n\n    Args:\n        path_to_directories (list): list of path of directories\n        ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n    \"\"\"\n    for path in path_to_directories:\n        os.makedirs(path, exist_ok=True)\n        if verbose:\n            logger.info(f\"created directory at: {path}\")", "\n\n@ensure_annotations\ndef save_json(path: Path, data: dict):\n    \"\"\"save json data\n\n    Args:\n        path (Path): path to json file\n        data (dict): data to be saved in json file\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(data, f, indent=4)\n\n    logger.info(f\"json file saved at: {path}\")", "\n\n\n\n@ensure_annotations\ndef load_json(path: Path) -> ConfigBox:\n    \"\"\"load json files data\n\n    Args:\n        path (Path): path to json file\n\n    Returns:\n        ConfigBox: data as class attributes instead of dict\n    \"\"\"\n    with open(path) as f:\n        content = json.load(f)\n\n    logger.info(f\"json file loaded succesfully from: {path}\")\n    return ConfigBox(content)", "\n\n@ensure_annotations\ndef save_bin(data: Any, path: Path):\n    \"\"\"save binary file\n\n    Args:\n        data (Any): data to be saved as binary\n        path (Path): path to binary file\n    \"\"\"\n    joblib.dump(value=data, filename=path)\n    logger.info(f\"binary file saved at: {path}\")", "\n\n@ensure_annotations\ndef load_bin(path: Path) -> Any:\n    \"\"\"load binary data\n\n    Args:\n        path (Path): path to binary file\n\n    Returns:\n        Any: object stored in the file\n    \"\"\"\n    data = joblib.load(path)\n    logger.info(f\"binary file loaded from: {path}\")\n    return data", "\n@ensure_annotations\ndef get_size(path: Path) -> str:\n    \"\"\"get size in KB\n\n    Args:\n        path (Path): path of the file\n\n    Returns:\n        str: size in KB\n    \"\"\"\n    size_in_kb = round(os.path.getsize(path)/1024)\n    return f\"~ {size_in_kb} KB\"", "\n\ndef decodeImage(imgstring, fileName):\n    imgdata = base64.b64decode(imgstring)\n    with open(fileName, 'wb') as f:\n        f.write(imgdata)\n        f.close()\n\n\ndef encodeImageIntoBase64(croppedImagePath):\n    with open(croppedImagePath, \"rb\") as f:\n        return base64.b64encode(f.read())", "\ndef encodeImageIntoBase64(croppedImagePath):\n    with open(croppedImagePath, \"rb\") as f:\n        return base64.b64encode(f.read())\n\n"]}
{"filename": "src/cnnClassifier/config/__init__.py", "chunked_list": [""]}
{"filename": "src/cnnClassifier/config/configuration.py", "chunked_list": ["from cnnClassifier.constants import *\nimport os\nfrom pathlib import Path\nfrom cnnClassifier.utils.common import read_yaml, create_directories\nfrom cnnClassifier.entity.config_entity import (DataIngestionConfig,\n                                                PrepareBaseModelConfig,\n                                                PrepareCallbacksConfig,\n                                                TrainingConfig,\n                                                EvaluationConfig)\n", "                                                EvaluationConfig)\n\n\n\nclass ConfigurationManager:\n    def __init__(\n        self,\n        config_filepath = CONFIG_FILE_PATH,\n        params_filepath = PARAMS_FILE_PATH):\n\n        self.config = read_yaml(config_filepath)\n        self.params = read_yaml(params_filepath)\n\n        create_directories([self.config.artifacts_root])\n\n\n    \n    def get_data_ingestion_config(self) -> DataIngestionConfig:\n        config = self.config.data_ingestion\n\n        create_directories([config.root_dir])\n\n        data_ingestion_config = DataIngestionConfig(\n            root_dir=config.root_dir,\n            source_URL=config.source_URL,\n            local_data_file=config.local_data_file,\n            unzip_dir=config.unzip_dir \n        )\n\n        return data_ingestion_config\n    \n\n\n    \n    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n        config = self.config.prepare_base_model\n        \n        create_directories([config.root_dir])\n\n        prepare_base_model_config = PrepareBaseModelConfig(\n            root_dir=Path(config.root_dir),\n            base_model_path=Path(config.base_model_path),\n            updated_base_model_path=Path(config.updated_base_model_path),\n            params_image_size=self.params.IMAGE_SIZE,\n            params_learning_rate=self.params.LEARNING_RATE,\n            params_include_top=self.params.INCLUDE_TOP,\n            params_weights=self.params.WEIGHTS,\n            params_classes=self.params.CLASSES\n        )\n\n        return prepare_base_model_config\n    \n\n\n    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n        config = self.config.prepare_callbacks\n        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n        create_directories([\n            Path(model_ckpt_dir),\n            Path(config.tensorboard_root_log_dir)\n        ])\n\n        prepare_callback_config = PrepareCallbacksConfig(\n            root_dir=Path(config.root_dir),\n            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n        )\n\n        return prepare_callback_config\n    \n\n\n    def get_training_config(self) -> TrainingConfig:\n        training = self.config.training\n        prepare_base_model = self.config.prepare_base_model\n        params = self.params\n        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chicken-fecal-images\")\n        create_directories([\n            Path(training.root_dir)\n        ])\n\n        training_config = TrainingConfig(\n            root_dir=Path(training.root_dir),\n            trained_model_path=Path(training.trained_model_path),\n            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n            training_data=Path(training_data),\n            params_epochs=params.EPOCHS,\n            params_batch_size=params.BATCH_SIZE,\n            params_is_augmentation=params.AUGMENTATION,\n            params_image_size=params.IMAGE_SIZE\n        )\n\n        return training_config\n    \n\n\n\n    def get_validation_config(self) -> EvaluationConfig:\n        eval_config = EvaluationConfig(\n            path_of_model=Path(\"artifacts/training/model.h5\"),\n            training_data=Path(\"artifacts/data_ingestion/Chicken-fecal-images\"),\n            all_params=self.params,\n            params_image_size=self.params.IMAGE_SIZE,\n            params_batch_size=self.params.BATCH_SIZE\n        )\n        return eval_config", "\n      "]}
{"filename": "src/cnnClassifier/pipeline/predict.py", "chunked_list": ["import numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\nimport os\n\n\n\nclass PredictionPipeline:\n    def __init__(self,filename):\n        self.filename =filename\n\n\n    \n    def predict(self):\n        # load model\n        model = load_model(os.path.join(\"artifacts\",\"training\", \"model.h5\"))\n\n        imagename = self.filename\n        test_image = image.load_img(imagename, target_size = (224,224))\n        test_image = image.img_to_array(test_image)\n        test_image = np.expand_dims(test_image, axis = 0)\n        result = np.argmax(model.predict(test_image), axis=1)\n        print(result)\n\n        if result[0] == 1:\n            prediction = 'Healthy'\n            return [{ \"image\" : prediction}]\n        else:\n            prediction = 'Coccidiosis'\n            return [{ \"image\" : prediction}]", ""]}
{"filename": "src/cnnClassifier/pipeline/stage_02_prepare_base_model.py", "chunked_list": ["from cnnClassifier.config.configuration import ConfigurationManager\nfrom cnnClassifier.components.prepare_base_model import PrepareBaseModel\nfrom cnnClassifier import logger\n\n\nSTAGE_NAME = \"Prepare base model\"\n\nclass PrepareBaseModelTrainingPipeline:\n    def __init__(self):\n        pass\n\n    def main(self):\n        config = ConfigurationManager()\n        prepare_base_model_config = config.get_prepare_base_model_config()\n        prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n        prepare_base_model.get_base_model()\n        prepare_base_model.update_base_model()", "\n\n\n\n\nif __name__ == '__main__':\n    try:\n        logger.info(f\"*******************\")\n        logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n        obj = PrepareBaseModelTrainingPipeline()\n        obj.main()\n        logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n    except Exception as e:\n        logger.exception(e)\n        raise e", "\n\n"]}
{"filename": "src/cnnClassifier/pipeline/__init__.py", "chunked_list": [""]}
{"filename": "src/cnnClassifier/pipeline/stage_01_data_ingestion.py", "chunked_list": ["from cnnClassifier.config.configuration import ConfigurationManager\nfrom cnnClassifier.components.data_ingestion import DataIngestion\nfrom cnnClassifier import logger\n\n\nSTAGE_NAME = \"Data Ingestion stage\"\n\nclass DataIngestionTrainingPipeline:\n    def __init__(self):\n        pass\n\n    def main(self):\n        config = ConfigurationManager()\n        data_ingestion_config = config.get_data_ingestion_config()\n        data_ingestion = DataIngestion(config=data_ingestion_config)\n        data_ingestion.download_file()\n        data_ingestion.extract_zip_file()", "\n\n\n\nif __name__ == '__main__':\n    try:\n        logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n        obj = DataIngestionTrainingPipeline()\n        obj.main()\n        logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n    except Exception as e:\n        logger.exception(e)\n        raise e", "\n"]}
{"filename": "src/cnnClassifier/pipeline/stage_03_training.py", "chunked_list": ["from cnnClassifier.config.configuration import ConfigurationManager\nfrom cnnClassifier.components.prepare_callbacks import PrepareCallback\nfrom cnnClassifier.components.training import Training\nfrom cnnClassifier import logger\n\n\n\nSTAGE_NAME = \"Training\"\n\n\nclass ModelTrainingPipeline:\n    def __init__(self):\n        pass\n\n    def main(self):\n        config = ConfigurationManager()\n        prepare_callbacks_config = config.get_prepare_callback_config()\n        prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n        callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n\n\n        training_config = config.get_training_config()\n        training = Training(config=training_config)\n        training.get_base_model()\n        training.train_valid_generator()\n        training.train(\n            callback_list=callback_list\n        )", "\n\nclass ModelTrainingPipeline:\n    def __init__(self):\n        pass\n\n    def main(self):\n        config = ConfigurationManager()\n        prepare_callbacks_config = config.get_prepare_callback_config()\n        prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n        callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n\n\n        training_config = config.get_training_config()\n        training = Training(config=training_config)\n        training.get_base_model()\n        training.train_valid_generator()\n        training.train(\n            callback_list=callback_list\n        )", "\n\n\n\nif __name__ == '__main__':\n    try:\n        logger.info(f\"*******************\")\n        logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n        obj = ModelTrainingPipeline()\n        obj.main()\n        logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n    except Exception as e:\n        logger.exception(e)\n        raise e", "        \n"]}
{"filename": "src/cnnClassifier/pipeline/stage_04_evaluation.py", "chunked_list": ["from cnnClassifier.config.configuration import ConfigurationManager\nfrom cnnClassifier.components.evaluation import Evaluation\nfrom cnnClassifier import logger\n\n\n\n\nSTAGE_NAME = \"Evaluation stage\"\n\n\nclass EvaluationPipeline:\n    def __init__(self):\n        pass\n\n    def main(self):\n        config = ConfigurationManager()\n        val_config = config.get_validation_config()\n        evaluation = Evaluation(val_config)\n        evaluation.evaluation()\n        evaluation.save_score()", "\n\nclass EvaluationPipeline:\n    def __init__(self):\n        pass\n\n    def main(self):\n        config = ConfigurationManager()\n        val_config = config.get_validation_config()\n        evaluation = Evaluation(val_config)\n        evaluation.evaluation()\n        evaluation.save_score()", "\n\n\nif __name__ == '__main__':\n    try:\n        logger.info(f\"*******************\")\n        logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n        obj = EvaluationPipeline()\n        obj.main()\n        logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n    except Exception as e:\n        logger.exception(e)\n        raise e", "            "]}
{"filename": "src/cnnClassifier/constants/__init__.py", "chunked_list": ["from pathlib import Path\n\nCONFIG_FILE_PATH = Path(\"config/config.yaml\")\nPARAMS_FILE_PATH = Path(\"params.yaml\")"]}
