{"filename": "setup.py", "chunked_list": ["from setuptools import setup\n\nfrom pybind11.setup_helpers import build_ext, intree_extensions\n\n\next_modules = intree_extensions([\"src/endf/_records.cpp\"])\n\nsetup(\n    ext_modules=ext_modules,\n    cmdclass={\"build_ext\": build_ext},", "    ext_modules=ext_modules,\n    cmdclass={\"build_ext\": build_ext},\n)\n"]}
{"filename": "doc/source/conf.py", "chunked_list": ["# Configuration file for the Sphinx documentation builder.\n#\n# For the full list of built-in configuration values, see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Project information -----------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\n\nfrom importlib.metadata import version as metadata_version\n", "from importlib.metadata import version as metadata_version\n\nproject = 'ENDF Python Interface'\ncopyright = '2023, Paul Romano'\nauthor = 'Paul Romano'\n\nrelease = metadata_version('endf')\nversion = '.'.join(release.split('.')[:2])\n\n# -- General configuration ---------------------------------------------------", "\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\n\nextensions = [\n    'sphinx.ext.autodoc',\n    'sphinx.ext.autosummary',\n    'sphinx.ext.intersphinx',\n    'sphinx.ext.napoleon',\n    'sphinx.ext.viewcode',", "    'sphinx.ext.napoleon',\n    'sphinx.ext.viewcode',\n    'sphinx_autodoc_typehints',\n    'sphinx_design',\n]\n\ntemplates_path = ['_templates']\nexclude_patterns = []\n\nintersphinx_mapping = {", "\nintersphinx_mapping = {\n    'python': ('https://docs.python.org/3', None),\n    'numpy': ('https://numpy.org/doc/stable/', None),\n}\n\n# -- Options for HTML output -------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\n\nhtml_theme = 'pydata_sphinx_theme'", "\nhtml_theme = 'pydata_sphinx_theme'\nhtml_static_path = ['_static']\n\nhtml_theme_options = {\n    \"github_url\": \"https://github.com/paulromano/endf-python\",\n    #\"navbar_end\": [\"navbar-icon-links\"],\n    \"show_toc_level\": 3,\n    \"logo\": {\"text\": project}\n}", "    \"logo\": {\"text\": project}\n}\n\nnapoleon_use_rtype = False\n\n# TODO: Using ivar results in better looking documentation, but it breaks\n# cross-references to attributes which is annoying. Figure out a way to get it\n# to work with cross-references\n\n#napoleon_use_ivar = True", "\n#napoleon_use_ivar = True\n\n# -- Options for LaTeX output ------------------------------------------------\nlatex_domain_indices = False\n"]}
{"filename": "tests/test_material.py", "chunked_list": ["# SPDX-FileCopyrightText: Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom pathlib import Path\n\nimport pytest\nimport endf\n\n\n@pytest.fixture\ndef am244():\n    filename = Path(__file__).with_name('n-095_Am_244.endf')\n    return endf.Material(filename)", "\n@pytest.fixture\ndef am244():\n    filename = Path(__file__).with_name('n-095_Am_244.endf')\n    return endf.Material(filename)\n\n\ndef test_init_file():\n    filename = Path(__file__).with_name('n-095_Am_244.endf')\n    with open(filename) as fh:\n        am244 = endf.Material(fh)\n    assert am244.MAT == 9552", "\n\ndef test_sections(am244):\n    assert isinstance(am244.sections, list)\n    for mf_mt in am244.sections:\n        assert len(mf_mt) == 2\n\n\ndef test_section_text(am244):\n    for key, value in am244.section_text.items():\n        assert isinstance(key, tuple)\n        assert isinstance(value, str)", "def test_section_text(am244):\n    for key, value in am244.section_text.items():\n        assert isinstance(key, tuple)\n        assert isinstance(value, str)\n\n\ndef test_section_data(am244):\n    # Spot check metadata in MF=1, MT=451\n    metadata = am244.section_data[1, 451]\n    assert metadata['ZSYMAM'].strip() == '95-Am-244'\n    assert metadata['EMAX'] == pytest.approx(20.0e6)\n\n    # Spot check cross section data in MF=4\n    capture = am244.section_data[3, 102]\n    assert capture['QM'] == pytest.approx(6052990.0)\n\n    # Indexing Material directly is same as indexing section_data\n    assert am244[3, 102] is am244.section_data[3, 102]", "\n\ndef test_contains(am244):\n    assert (3, 102) in am244\n    assert (102, 3) not in am244\n\n\ndef test_repr(am244):\n    assert '95-Am-244' in repr(am244)\n    assert 'ENDF/B' in repr(am244)", "\n\ndef test_interpret(am244):\n    am244_high_level = am244.interpret()\n    assert isinstance(am244_high_level, endf.IncidentNeutron)\n"]}
{"filename": "src/endf/mf40.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .mf33 import parse_mf33_subsection\nfrom .records import get_head_record, get_cont_record\n\n\ndef parse_mf40(file_obj: TextIO) -> dict:\n    \"\"\"Parse covariances of radionuclide production from MF=40\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Radionuclide production covariance data\n\n    \"\"\"\n    ZA, AWR, LIS, _, NS, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LIS': LIS, 'NS': NS, 'subsections': []}\n    for _ in range(NS):\n        QM, QI, IZAP, LFS, _, NL = get_cont_record(file_obj)\n        subsection = {'QM': QM, 'QI': QI, 'IZAP': IZAP, 'LFS': LFS, 'NL': NL}\n        subsection['subsubsections'] = []\n        for _ in range(NL):\n            # Each sub-subsection has same format as in MF=33\n            subsubsection = parse_mf33_subsection(file_obj)\n            subsection['subsubsections'].append(subsubsection)\n\n        data['subsections'].append(subsection)\n\n    return data", "\ndef parse_mf40(file_obj: TextIO) -> dict:\n    \"\"\"Parse covariances of radionuclide production from MF=40\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Radionuclide production covariance data\n\n    \"\"\"\n    ZA, AWR, LIS, _, NS, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LIS': LIS, 'NS': NS, 'subsections': []}\n    for _ in range(NS):\n        QM, QI, IZAP, LFS, _, NL = get_cont_record(file_obj)\n        subsection = {'QM': QM, 'QI': QI, 'IZAP': IZAP, 'LFS': LFS, 'NL': NL}\n        subsection['subsubsections'] = []\n        for _ in range(NL):\n            # Each sub-subsection has same format as in MF=33\n            subsubsection = parse_mf33_subsection(file_obj)\n            subsection['subsubsections'].append(subsubsection)\n\n        data['subsections'].append(subsection)\n\n    return data", ""]}
{"filename": "src/endf/mf4.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom __future__ import annotations\nfrom typing import TextIO\nfrom warnings import warn\n\nimport numpy as np\nfrom numpy.polynomial import Legendre\n", "from numpy.polynomial import Legendre\n\nfrom .records import get_head_record, get_cont_record, get_tab2_record, \\\n    get_tab1_record, get_list_record\n\n\ndef parse_mf4(file_obj: TextIO) -> dict:\n    # Read first two records\n    ZA, AWR, LVT, LTT, _, _ = get_head_record(file_obj)\n    _, _, LI, LCT, NK, NM = get_cont_record(file_obj)\n\n    # initialize dictionary for angular distribution\n    data = {'ZA': ZA, 'AWR': AWR, 'LTT': LTT, 'LI': LI, 'LCT': LCT}\n\n    # Check for obsolete energy transformation matrix. If present, just skip\n    # it and keep reading\n    if LVT > 0:\n        warn('Obsolete energy transformation matrix in MF=4 angular distribution.')\n        for _ in range((NK + 5)//6):\n            file_obj.readline()\n\n    def legendre_data(file_obj):\n        data = {}\n        params, data['E_int'] = get_tab2_record(file_obj)\n        n_energy = params[5]\n\n        energy = np.zeros(n_energy)\n        a_l = []\n        for i in range(n_energy):\n            items, al = get_list_record(file_obj)\n            data['T'] = items[0]\n            energy[i] = items[1]\n            data['LT'] = items[2]\n            coefficients = np.array(al)\n            a_l.append(coefficients)\n        data['a_l'] = a_l\n        data['E'] = energy\n        return data\n\n    def tabulated_data(file_obj):\n        data = {}\n        params, data['E_int'] = get_tab2_record(file_obj)\n        n_energy = params[5]\n\n        energy = np.zeros(n_energy)\n        mu = []\n        for i in range(n_energy):\n            params, f = get_tab1_record(file_obj)\n            data['T'] = params[0]\n            energy[i] = params[1]\n            data['LT'] = params[2]\n            mu.append(f)\n        data['E'] = energy\n        data['mu'] = mu\n        return data\n\n    if LTT == 0 and LI == 1:\n        # Purely isotropic\n        pass\n\n    elif LTT == 1 and LI == 0:\n        # Legendre polynomial coefficients\n        data['legendre'] = legendre_data(file_obj)\n\n    elif LTT == 2 and LI == 0:\n        # Tabulated probability distribution\n        data['tabulated'] = tabulated_data(file_obj)\n\n    elif LTT == 3 and LI == 0:\n        # Legendre for low energies / tabulated for high energies\n        data['legendre'] = legendre_data(file_obj)\n        data['tabulated'] = tabulated_data(file_obj)\n\n    return data", "\n\nclass AngleDistribution:\n    \"\"\"Angle distribution as a function of incoming energy\n\n    Parameters\n    ----------\n    energy\n        Incoming energies in eV at which distributions exist\n    mu\n        Distribution of scattering cosines corresponding to each incoming energy\n\n    Attributes\n    ----------\n    energy\n        Incoming energies in eV at which distributions exist\n    mu\n        Distribution of scattering cosines corresponding to each incoming energy\n\n    \"\"\"\n\n    def __init__(self, energy, mu):\n        self.energy = energy\n        self.mu = mu\n\n    @classmethod\n    def from_dict(cls, data: dict) -> AngleDistribution:\n        LTT = data['LTT']\n        LI = data['LI']\n        if LTT == 0 and LI == 1:\n            # Purely isotropic\n            # TODO: Use uniform here\n            energy = []\n            mu = []\n        elif LTT == 1 and LI == 0:\n            energy = data['legendre']['E']\n            mu = []\n            for a_l in data['legendre']['a_l']:\n                coef = np.insert(a_l, 0, 1.0)\n                mu.append(Legendre(coef))\n        elif LTT == 2 and LI == 0:\n            energy = data['tabulated']['E']\n            mu = data['tabulated']['mu']\n        elif LTT == 3 and LI == 0:\n            # Get Legendre first\n            energy_leg = data['legendre']['E']\n            mu_leg = []\n            for a_l in data['legendre']['a_l']:\n                coef = np.insert(a_l, 0, 1.0)\n                mu_leg.append(Legendre(coef))\n\n            # Then get tabulated\n            energy_tab = data['tabulated']['E']\n            mu_tab = data['tabulated']['mu']\n\n            # Combine\n            energy = np.hstack((energy_leg, energy_tab))\n            mu = mu_leg + mu_tab\n\n        return cls(energy, mu)", "\n"]}
{"filename": "src/endf/mf2.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nimport numpy as np\n\nfrom .records import get_head_record, get_cont_record, get_tab1_record, \\\n    get_list_record\n", "    get_list_record\n\n\n\ndef parse_mf2(file_obj: TextIO) -> dict:\n    \"\"\"Parse resonance parameters from MF=2, MT=151\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Resonance parameter data\n\n    \"\"\"\n    # Determine whether discrete or continuous representation\n    ZA, AWR, _, _, NIS, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NIS': NIS}\n\n    data['isotopes'] = []\n    for _ in range(NIS):\n        ZAI, ABN, _, LFW, NER, _ = get_cont_record(file_obj)\n        iso = {'ZAI': ZAI, 'ABN': ABN, 'LFW': LFW, 'NER': NER}\n\n        iso['ranges'] = []\n        for _ in range(NER):\n            EL, EH, LRU, LRF, NRO, NAPS = get_cont_record(file_obj)\n            rrange = {'EL': EL, 'EH': EH, 'LRU': LRU,\n                      'LRF': LRF, 'NRO': NRO, 'NAPS': NAPS}\n\n            if LRF == 0:\n                # Read spin and scattering radius\n                SPI, AP, _, _, NLS, _ = get_cont_record(file_obj)\n                rrange['SPI'] = SPI\n                rrange['AP'] = AP\n                rrange['NLS'] = NLS\n            elif LRU in (0, 1):\n                # resolved resonance region\n                rrange.update(_FORMALISMS[LRF].dict_from_endf(file_obj, NRO))\n            elif LRF == 2:\n                # unresolved resonance region\n                rrange.update(Unresolved.dict_from_endf(file_obj, LFW, LRF, NRO))\n            iso['ranges'].append(rrange)\n\n        data['isotopes'].append(iso)\n\n    return data", "\n\nclass MLBW:\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, NRO: int) -> dict:\n        # Read energy-dependent scattering radius if present\n        data = {}\n        if NRO != 0:\n            _, data['APE'] = get_tab1_record(file_obj)\n\n        # Other scatter radius parameters\n        SPI, AP, _, _, NLS, _ = get_cont_record(file_obj)\n        data['SPI'] = SPI\n        data['AP'] = AP\n        data['NLS'] = NLS\n\n        # Read resonance widths, J values, etc\n        data['sections'] = []\n        for l in range(NLS):\n            (AWRI, QX, L, LRX, _, NRS), values = get_list_record(file_obj)\n            section = {'AWRI': AWRI, 'QX': QX, 'L': L, 'LRX': LRX, 'NRS': NRS}\n            section['ER'] = values[0::6]\n            section['AJ'] = values[1::6]\n            section['GT'] = values[2::6]\n            section['GN'] = values[3::6]\n            section['GG'] = values[4::6]\n            section['GF'] = values[5::6]\n            data['sections'].append(section)\n\n        return data", "\n\nclass SLBW(MLBW):\n    ...\n\n\nclass ReichMoore:\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, NRO: int) -> dict:\n        # Read energy-dependent scattering radius if present\n        data = {}\n        if NRO != 0:\n            _, data['APE'] = get_tab1_record(file_obj)\n\n        # Other scatter radius parameters\n        SPI, AP, LAD, _, NLS, NLSC = get_cont_record(file_obj)\n        data['SPI'] = SPI\n        data['AP'] = AP\n        data['LAD'] = LAD\n        data['NLS'] = NLS\n        data['NLSC'] = NLSC\n\n        # Read resonance widths, J values, etc\n        data['sections'] = []\n        for l in range(NLS):\n            (AWRI, APL, L, _, _, NRS), values = get_list_record(file_obj)\n            section = {'AWRI': AWRI, 'APL': APL, 'L': L, 'NRS': NRS}\n            section['ER'] = values[0::6]\n            section['AJ'] = values[1::6]\n            section['GN'] = values[2::6]\n            section['GG'] = values[3::6]\n            section['GFA'] = values[4::6]\n            section['GFB'] = values[5::6]\n            data['sections'].append(section)\n\n        return data", "\n\nclass AdlerAdler:\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, NRO: int) -> dict:\n        raise NotImplementedError\n\n\nclass RMatrixLimited:\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, NRO: int) -> dict:\n        _, _, IFG, KRM, NJS, KRL = get_cont_record(file_obj)\n        data = {'IFG': IFG, 'KRM': KRM, 'NJS': NJS, 'KRL': KRL}\n\n        # Read particle-pair data\n        items, values = get_list_record(file_obj)\n        data['NPP'] = NPP = items[2]\n        data['particle_pairs'] = pp = {}\n        pp['MA'] = values[::12]\n        pp['MB'] = values[1::12]\n        pp['ZA'] = values[2::12]\n        pp['ZB'] = values[3::12]\n        pp['IA'] = values[4::12]\n        pp['IB'] = values[5::12]\n        pp['Q'] = values[6::12]\n        pp['PNT'] = values[7::12]\n        pp['SHF'] = values[8::12]\n        pp['MT'] = values[9::12]\n        pp['PA'] = values[10::12]\n        pp['PB'] = values[11::12]\n\n        # loop over spin groups\n        data['spin_groups'] = spin_groups = []\n        for i in range(NJS):\n            (AJ, PJ, KBK, KPS, _, NCH), values = get_list_record(file_obj)\n            spin_group = {'AJ': AJ, 'PJ': PJ, 'KBK': KBK, 'KPS': KPS, 'NCH': NCH}\n            spin_group['channels'] = channels = {}\n            channels['PPI'] = values[::6]\n            channels['L'] = values[1::6]\n            channels['SCH'] = values[2::6]\n            channels['BND'] = values[3::6]\n            channels['APE'] = values[4::6]\n            channels['APT'] = values[5::6]\n\n            # Read resonance energies and widths\n            (*_, NRS, _, NX), values = get_list_record(file_obj)\n            spin_group['NRS'] = NRS\n            spin_group['NX'] = NX\n            spin_group['ER'] = values[::NCH + 1]\n\n            # Read widths into a matrix and transpose\n            GAM = []\n            for j in range(NRS):\n                GAM.append(values[1 + (NCH + 1)*j:(NCH + 1)*(j + 1)])\n            GAM = np.array(GAM).reshape(NRS, NCH)\n            spin_group['GAM'] = GAM.T\n\n            # Optional extension (Background R-Matrix)\n            if KBK > 0:\n                (_, _, LCH, LBK, _, _), values = get_list_record(file_obj)\n                spin_group['LCH'] = LCH\n                spin_group['LBK'] = LBK\n                if LBK == 1:\n                    _, spin_group['RBR'] = get_tab1_record(file_obj)\n                    _, spin_group['RBI'] = get_tab1_record(file_obj)\n                elif LBK in (2, 3):\n                    (ED, EU, *_), values = get_list_record(file_obj)\n                    spin_group['ED'] = ED\n                    spin_group['EU'] = EU\n\n            # Optional extension (Tabulated phase shifts)\n            if KPS > 0:\n                items, values = get_list_record(file_obj)\n                spin_group['LPS'] = LPS = items[4]\n                if LPS == 1:\n                    _, spin_group['PSR'] = get_tab1_record(file_obj)\n                    _, spin_group['PSI'] = get_tab1_record(file_obj)\n\n            spin_groups.append(spin_group)\n\n        return data", "class RMatrixLimited:\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, NRO: int) -> dict:\n        _, _, IFG, KRM, NJS, KRL = get_cont_record(file_obj)\n        data = {'IFG': IFG, 'KRM': KRM, 'NJS': NJS, 'KRL': KRL}\n\n        # Read particle-pair data\n        items, values = get_list_record(file_obj)\n        data['NPP'] = NPP = items[2]\n        data['particle_pairs'] = pp = {}\n        pp['MA'] = values[::12]\n        pp['MB'] = values[1::12]\n        pp['ZA'] = values[2::12]\n        pp['ZB'] = values[3::12]\n        pp['IA'] = values[4::12]\n        pp['IB'] = values[5::12]\n        pp['Q'] = values[6::12]\n        pp['PNT'] = values[7::12]\n        pp['SHF'] = values[8::12]\n        pp['MT'] = values[9::12]\n        pp['PA'] = values[10::12]\n        pp['PB'] = values[11::12]\n\n        # loop over spin groups\n        data['spin_groups'] = spin_groups = []\n        for i in range(NJS):\n            (AJ, PJ, KBK, KPS, _, NCH), values = get_list_record(file_obj)\n            spin_group = {'AJ': AJ, 'PJ': PJ, 'KBK': KBK, 'KPS': KPS, 'NCH': NCH}\n            spin_group['channels'] = channels = {}\n            channels['PPI'] = values[::6]\n            channels['L'] = values[1::6]\n            channels['SCH'] = values[2::6]\n            channels['BND'] = values[3::6]\n            channels['APE'] = values[4::6]\n            channels['APT'] = values[5::6]\n\n            # Read resonance energies and widths\n            (*_, NRS, _, NX), values = get_list_record(file_obj)\n            spin_group['NRS'] = NRS\n            spin_group['NX'] = NX\n            spin_group['ER'] = values[::NCH + 1]\n\n            # Read widths into a matrix and transpose\n            GAM = []\n            for j in range(NRS):\n                GAM.append(values[1 + (NCH + 1)*j:(NCH + 1)*(j + 1)])\n            GAM = np.array(GAM).reshape(NRS, NCH)\n            spin_group['GAM'] = GAM.T\n\n            # Optional extension (Background R-Matrix)\n            if KBK > 0:\n                (_, _, LCH, LBK, _, _), values = get_list_record(file_obj)\n                spin_group['LCH'] = LCH\n                spin_group['LBK'] = LBK\n                if LBK == 1:\n                    _, spin_group['RBR'] = get_tab1_record(file_obj)\n                    _, spin_group['RBI'] = get_tab1_record(file_obj)\n                elif LBK in (2, 3):\n                    (ED, EU, *_), values = get_list_record(file_obj)\n                    spin_group['ED'] = ED\n                    spin_group['EU'] = EU\n\n            # Optional extension (Tabulated phase shifts)\n            if KPS > 0:\n                items, values = get_list_record(file_obj)\n                spin_group['LPS'] = LPS = items[4]\n                if LPS == 1:\n                    _, spin_group['PSR'] = get_tab1_record(file_obj)\n                    _, spin_group['PSI'] = get_tab1_record(file_obj)\n\n            spin_groups.append(spin_group)\n\n        return data", "\n\nclass Unresolved:\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, LFW: int, LRF: int, NRO: int) -> dict:\n        # Read energy-dependent scattering radius if present\n        data = {}\n        if NRO != 0:\n            _, data['APE'] = get_tab1_record(file_obj)\n\n        # Get SPI, AP, and LSSF\n        if not (LFW == 1 and LRF == 1):\n            SPI, AP, LSSF, _, NLS, _ = get_cont_record(file_obj)\n            data.update({'SPI': SPI, 'AP': AP, 'LSSF': LSSF, 'NLS': NLS})\n\n        if LFW == 0 and LRF == 1:\n            # Case A -- fission widths not given, all parameters are\n            # energy-independent\n            data['ranges'] = []\n            for _ in range(NLS):\n                (AWRI, _, L, _, _, NJS), values = get_list_record(file_obj)\n                rrange = {'AWRI': AWRI, 'L': L, 'NJS': NJS}\n                rrange['D'] = values[::6]\n                rrange['AJ'] = values[1::6]\n                rrange['AMUN'] = values[2::6]\n                rrange['GNO'] = values[3::6]\n                rrange['GG'] = values[4::6]\n                data['ranges'].append(rrange)\n\n        elif LFW == 1 and LRF == 1:\n            # Case B -- fission widths given, only fission widths are\n            # energy-dependent\n            (SPI, AP, LSSF, _, NE, NLS), ES = get_list_record(file_obj)\n            data.update({'SPI': SPI, 'AP': AP, 'LSSF': LSSF,\n                         'NE': NE, 'NLS': NLS, 'ES': ES})\n\n            data['ranges'] = []\n            for _ in range(NLS):\n                AWRI, _, L, _, NJS, _ = get_cont_record(file_obj)\n                rrange = {'AWRI': AWRI, 'L': L, 'NJS': NJS}\n                rrange['parameters'] = []\n                for j in range(NJS):\n                    items, values = get_list_record(file_obj)\n                    rrange['parameters'].append({\n                        'MUF': items[3], 'D': values[0], 'AJ': values[1],\n                        'AMUN': values[2], 'GN0': values[3], 'GG': values[4],\n                        'GF': values[6:]\n                    })\n                data['ranges'].append(rrange)\n\n        elif LRF == 2:\n            # Case C -- all parameters are energy-dependent\n            data['ranges'] = []\n            for _ in range(NLS):\n                AWRI, _, L, _, NJS, _ = get_cont_record(file_obj)\n                rrange = {'AWRI': AWRI, 'L': L, 'NJS': NJS}\n                rrange['parameters'] = []\n                for _ in range(NJS):\n                    (AJ, _, INT, _, _, NE), values = get_list_record(file_obj)\n                    rrange['parameters'].append({\n                        'AJ': AJ, 'INT': INT, 'NE': NE,\n                        'AMUX': values[2],\n                        'AMUN': values[3],\n                        'AMUF': values[5],\n                        'E': values[6::6],\n                        'D': values[7::6],\n                        'GX': values[8::6],\n                        'GN0': values[9::6],\n                        'GG': values[10::6],\n                        'GF': values[11::6]\n                    })\n                data['ranges'].append(rrange)\n\n        return data", "\n\n_FORMALISMS = {\n    1: SLBW,\n    2: MLBW,\n    3: ReichMoore,\n    4: AdlerAdler,\n    7: RMatrixLimited\n}\n", "}\n"]}
{"filename": "src/endf/incident_neutron.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom __future__ import annotations\nfrom typing import Union, List\n\nimport numpy as np\n\nfrom .data import gnds_name, temperature_str, ATOMIC_SYMBOL, EV_PER_MEV\nfrom .material import Material", "from .data import gnds_name, temperature_str, ATOMIC_SYMBOL, EV_PER_MEV\nfrom .material import Material\nfrom .fileutils import PathLike\nfrom .function import Tabulated1D\nfrom .reaction import Reaction, REACTION_MT\nfrom . import ace\n\n\nSUM_RULES = {\n    1: [2, 3],", "SUM_RULES = {\n    1: [2, 3],\n    3: [4, 5, 11, 16, 17, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35,\n        36, 37, 41, 42, 44, 45, 152, 153, 154, 156, 157, 158, 159, 160,\n        161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n        173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185,\n        186, 187, 188, 189, 190, 194, 195, 196, 198, 199, 200],\n    4: list(range(50, 92)),\n    16: list(range(875, 892)),\n    18: [19, 20, 21, 38],", "    16: list(range(875, 892)),\n    18: [19, 20, 21, 38],\n    27: [18, 101],\n    101: [102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114,\n        115, 116, 117, 155, 182, 191, 192, 193, 197],\n    103: list(range(600, 650)),\n    104: list(range(650, 700)),\n    105: list(range(700, 750)),\n    106: list(range(750, 800)),\n    107: list(range(800, 850))", "    106: list(range(750, 800)),\n    107: list(range(800, 850))\n}\n\n\nclass IncidentNeutron:\n    \"\"\"Continuous-energy neutron interaction data.\n\n    This class stores data derived from an ENDF-6 format neutron interaction\n    sublibrary.\n\n    Parameters\n    ----------\n    atomic_number : int\n        Number of protons in the target nucleus\n    mass_number : int\n        Number of nucleons in the target nucleus\n    metastable : int\n        Metastable state of the target nucleus. A value of zero indicates the\n        ground state.\n\n    Attributes\n    ----------\n    atomic_number : int\n        Number of protons in the target nucleus\n    atomic_symbol : str\n        Atomic symbol of the nuclide, e.g., 'Zr'\n    mass_number : int\n        Number of nucleons in the target nucleus\n    metastable : int\n        Metastable state of the target nucleus. A value of zero indicates the\n        ground state.\n    name : str\n        Name of the nuclide using the GNDS naming convention\n    reactions : dict\n        Contains the cross sections, secondary angle and energy distributions,\n        and other associated data for each reaction. The keys are the MT values\n        and the values are Reaction objects.\n    \"\"\"\n\n    def __init__(self, atomic_number: int, mass_number: int, metastable: int = 0):\n        self.atomic_number = atomic_number\n        self.mass_number = mass_number\n        self.metastable = metastable\n        self.reactions = {}\n\n    @classmethod\n    def from_endf(cls, filename_or_mat: Union[PathLike, Material]) -> IncidentNeutron:\n        \"\"\"Generate incident neutron data from an ENDF file\n\n        Parameters\n        ----------\n        filename_or_mat\n            Path to ENDF-6 formatted file or material object\n\n        Returns\n        -------\n        Incident neutron data\n\n        \"\"\"\n        if not isinstance(filename_or_mat, Material):\n            material = Material(filename_or_mat)\n        else:\n            material = filename_or_mat\n\n        # Determine atomic number, mass number, and metastable state\n        metadata = material[1, 451]\n        Z, A = divmod(metadata['ZA'], 1000)\n        data = cls(Z, A, metadata['LISO'])\n\n        # Read each reaction\n        for MF, MT in material.sections:\n            if MF == 3:\n                data.reactions[MT] = Reaction.from_endf(MT, material)\n        return data\n\n    @classmethod\n    def from_ace(\n        cls,\n        filename_or_table: Union[PathLike, ace.Table],\n        metastable_scheme: str = 'mcnp'\n    ) -> IncidentNeutron:\n        \"\"\"Generate incident neutron continuous-energy data from an ACE table\n\n        Parameters\n        ----------\n        ace_or_filename\n            ACE table to read from. If the value is a string, it is assumed to\n            be the filename for the ACE file.\n        metastable_scheme : {'mcnp', 'nndc'}\n            Determine how ZAID identifiers are to be interpreted in the case of\n            a metastable nuclide. Because the normal ZAID (=1000*Z + A) does not\n            encode metastable information, different conventions are used among\n            different libraries. In MCNP libraries, the convention is to add 400\n            for a metastable nuclide except for Am242m, for which 95242 is\n            metastable and 95642 (or 1095242 in newer libraries) is the ground\n            state. For NNDC libraries, ZAID is given as 1000*Z + A + 100*m.\n\n        Returns\n        -------\n        Incident neutron continuous-energy data\n        \"\"\"\n        # First obtain the data for the first provided ACE table/file\n        if isinstance(filename_or_table, ace.Table):\n            table = filename_or_table\n        else:\n            table = ace.get_table(filename_or_table)\n\n        # If mass number hasn't been specified, make an educated guess\n        zaid, xs = table.name.split('.')\n        if not xs.endswith('c'):\n            raise TypeError(f\"{table} is not a continuous-energy neutron ACE table.\")\n        name, _, Z, mass_number, metastable = \\\n            ace.get_metadata(int(zaid), metastable_scheme)\n\n        # Get string of temperature to use as a dictionary key\n        strT = temperature_str(table.temperature)\n\n        # Create IncidentNeutron object (reactions will be added after)\n        data = cls(Z, mass_number, metastable)\n\n        # Read energy grid\n        n_energy = table.nxs[3]\n        i = table.jxs[1]\n        energy = table.xss[i : i + n_energy]*EV_PER_MEV\n        total_xs = table.xss[i + n_energy : i + 2*n_energy]\n        absorption_xs = table.xss[i + 2*n_energy : i + 3*n_energy]\n        heating_number = table.xss[i + 4*n_energy : i + 5*n_energy]*EV_PER_MEV\n\n        # Create redundant reaction for total (MT=1)\n        xs = {strT: Tabulated1D(energy, total_xs)}\n        data.reactions[1] = Reaction(1, xs, redundant=True)\n\n        # Create redundant reaction for absorption (MT=101)\n        if np.count_nonzero(absorption_xs) > 0:\n            xs = {strT: Tabulated1D(energy, absorption_xs)}\n            data.reactions[101] = Reaction(101, xs, redundant=True)\n\n        # Create redundant reaction for heating (MT=301)\n        xs = {strT: Tabulated1D(energy, heating_number*total_xs)}\n        data.reactions[301] = Reaction(301, xs, redundant=True)\n\n        # Read each reaction\n        n_reaction = table.nxs[4] + 1\n        for i in range(n_reaction):\n            rx = Reaction.from_ace(table, i)\n            data.reactions[rx.MT] = rx\n\n        # Make sure redundant cross sections that are present in an ACE file get\n        # marked as such\n        for rx in data:\n            mts = data._get_reaction_components(rx.MT)\n            if mts != [rx.MT]:\n                rx.redundant = True\n            if rx.MT in (203, 204, 205, 206, 207, 444):\n                rx.redundant = True\n\n        return data\n\n    def __contains__(self, MT: int):\n        return MT in self.reactions\n\n    def __getitem__(self, MT_or_name: int) -> Reaction:\n        if isinstance(MT_or_name, str):\n            if MT_or_name in REACTION_MT:\n                MT = REACTION_MT[MT_or_name]\n            elif f'({MT_or_name})' in REACTION_MT:\n                MT = REACTION_MT[f'({MT_or_name})']\n            else:\n                raise ValueError(f\"No reaction with label {MT_or_name}\")\n        else:\n            MT = MT_or_name\n\n        if MT in self.reactions:\n            return self.reactions[MT]\n        else:\n            # TODO: Try to create a redundant cross section\n            raise ValueError(f\"No reaction with {MT=}\")\n\n    def __repr__(self) -> str:\n        return f\"<IncidentNeutron: {self.name}, {len(self.reactions)} reactions>\"\n\n    def __iter__(self):\n        return iter(self.reactions.values())\n\n    @property\n    def name(self) -> str:\n        return gnds_name(self.atomic_number, self.mass_number, self.metastable)\n\n    @property\n    def atomic_symbol(self) -> str:\n        return ATOMIC_SYMBOL[self.atomic_number]\n\n    def _get_reaction_components(self, MT: int) -> List[int]:\n        \"\"\"Determine what reactions make up redundant reaction.\n\n        Parameters\n        ----------\n        mt : int\n            ENDF MT number of the reaction to find components of.\n\n        Returns\n        -------\n        mts : list of int\n            ENDF MT numbers of reactions that make up the redundant reaction and\n            have cross sections provided.\n\n        \"\"\"\n        mts = []\n        if MT in SUM_RULES:\n            for MT_i in SUM_RULES[MT]:\n                mts += self._get_reaction_components(MT_i)\n        if mts:\n            return mts\n        else:\n            return [MT] if MT in self else []", ""]}
{"filename": "src/endf/fileutils.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nimport os\nfrom typing import Union\n\n# Type for arguments that accept file paths\nPathLike = Union[str, bytes, os.PathLike]\n", ""]}
{"filename": "src/endf/mf14.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nimport numpy as np\n\nfrom .records import get_head_record, get_cont_record, get_tab2_record, \\\n    get_list_record, get_tab1_record\n", "    get_list_record, get_tab1_record\n\n\ndef parse_mf14(file_obj: TextIO) -> dict:\n    \"\"\"Parse photon angular distributions from MF=14\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Photon angular distribution data\n\n    \"\"\"\n    ZA, AWR, LI, LTT, NK, NI = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LI': LI, 'NK': NK}\n\n    # If all photons are isotropic, exit early\n    if LI == 1:\n        return data\n\n    data['LTT'] = LTT\n    data['NI'] = NI\n    data['subsections'] = []\n\n    # Subsections for isotropic photons\n    for i in range(NI):\n        EG, ES, *_ = get_cont_record(file_obj)\n        data['subsections'].append({'EG': EG, 'ES': ES})\n\n    # Subsections for anisotropic photons\n    for i in range(NI, NK):\n        (EG, ES, _, _, NR, NE), E_int = get_tab2_record(file_obj)\n        subsec = {'EG': EG, 'ES': ES, 'NE': NE, 'E_int': E_int}\n        subsec['E'] = np.empty(NE)\n        if LTT == 1:\n            # Legendre coefficient representation\n            subsec['NL'] = np.empty(NE)\n            subsec['a_lk'] = []\n            for i in range(NE):\n                (_, E, _, _, NL, _ ), a_lk = get_list_record(file_obj)\n                subsec['E'][i] = E\n                subsec['NL'][i] = NL\n                subsec['a_lk'].append(a_lk)\n        elif LTT == 2:\n            # Tabulated angular distribution\n            subsec['p_k'] = []\n            for i in range(NE):\n                (_, E, *_), p_k = get_tab1_record(file_obj)\n                subsec['E'][i] = E\n                subsec['p_k'].append(p_k)\n\n        data['subsections'].append(subsec)\n\n    return data", ""]}
{"filename": "src/endf/mf5.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom abc import ABC\nfrom typing import TextIO\n\nimport numpy as np\n\nfrom .records import get_tab1_record, get_tab2_record, get_head_record\n", "from .records import get_tab1_record, get_tab2_record, get_head_record\n\n\ndef parse_mf5(file_obj: TextIO) -> dict:\n    ZA, AWR, _, _, NK, _ = get_head_record(file_obj)\n\n    data = {'ZA': ZA, 'AWR': AWR, 'NK': NK}\n    data['subsections'] = []\n    for _ in range(NK):\n        subsection = {}\n        params, applicability = get_tab1_record(file_obj)\n        subsection['LF'] = LF = params[3]\n        subsection['p'] = applicability\n        if LF == 1:\n            dist = ArbitraryTabulated.dict_from_endf(file_obj, params)\n        elif LF == 5:\n            dist = GeneralEvaporation.dict_from_endf(file_obj, params)\n        elif LF == 7:\n            dist = MaxwellEnergy.dict_from_endf(file_obj, params)\n        elif LF == 9:\n            dist = Evaporation.dict_from_endf(file_obj, params)\n        elif LF == 11:\n            dist = WattEnergy.dict_from_endf(file_obj, params)\n        elif LF == 12:\n            dist = MadlandNix.dict_from_endf(file_obj, params)\n\n        subsection['distribution'] = dist\n        data['subsections'].append(subsection)\n\n    return data", "\n\n\nclass EnergyDistribution(ABC):\n    \"\"\"Abstract superclass for all energy distributions.\"\"\"\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def from_endf(file_obj: TextIO, params: list):\n        \"\"\"Generate energy distribution from MF=5 data\n\n        Parameters\n        ----------\n        file_obj : file-like object\n            ENDF file positioned at the start of a section for an energy\n            distribution.\n        params : list\n            List of parameters at the start of the energy distribution that\n            includes the LF value indicating what type of energy distribution is\n            present.\n\n        Returns\n        -------\n        A sub-class of :class:`EnergyDistribution`\n\n        \"\"\"\n        LF = params[3]\n        if LF == 1:\n            return ArbitraryTabulated.from_endf(file_obj, params)\n        elif LF == 5:\n            return GeneralEvaporation.from_endf(file_obj, params)\n        elif LF == 7:\n            return MaxwellEnergy.from_endf(file_obj, params)\n        elif LF == 9:\n            return Evaporation.from_endf(file_obj, params)\n        elif LF == 11:\n            return WattEnergy.from_endf(file_obj, params)\n        elif LF == 12:\n            return MadlandNix.from_endf(file_obj, params)\n\n    @staticmethod\n    def from_dict(subsection: dict):\n        LF = subsection['LF']\n        data = subsection['distribution']\n        if LF == 1:\n            return ArbitraryTabulated.from_dict(data)\n        elif LF == 5:\n            return GeneralEvaporation.from_dict(data)\n        elif LF == 7:\n            return MaxwellEnergy.from_dict(data)\n        elif LF == 9:\n            return Evaporation.from_dict(data)\n        elif LF == 11:\n            return WattEnergy.from_dict(data)\n        elif LF == 12:\n            return MadlandNix.from_dict(data)", "\n\nclass ArbitraryTabulated(EnergyDistribution):\n    r\"\"\"Arbitrary tabulated function given in ENDF MF=5, LF=1 represented as\n\n    .. math::\n         f(E \\rightarrow E') = g(E \\rightarrow E')\n\n    Parameters\n    ----------\n    energy : numpy.ndarray\n        Array of incident neutron energies\n    pdf : list of openmc.data.Tabulated1D\n        Tabulated outgoing energy distribution probability density functions\n\n    Attributes\n    ----------\n    energy : numpy.ndarray\n        Array of incident neutron energies\n    pdf : list of openmc.data.Tabulated1D\n        Tabulated outgoing energy distribution probability density functions\n\n    \"\"\"\n\n    def __init__(self, energy, pdf):\n        super().__init__()\n        self.energy = energy\n        self.pdf = pdf\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, params: list) -> dict:\n        \"\"\"Parse arbitrary tabulated distribution (LF=1)\n\n        Parameters\n        ----------\n        file_obj : file-like object\n            ENDF file positioned at the start of a section for an energy\n            distribution.\n\n        Returns\n        -------\n        dict\n            Arbitrary tabulated distribution data\n\n        \"\"\"\n        data = {}\n        params, data['E_int'] = get_tab2_record(file_obj)\n        n_energies = params[5]\n\n        energy = np.zeros(n_energies)\n        pdf = []\n        for j in range(n_energies):\n            params, func = get_tab1_record(file_obj)\n            energy[j] = params[1]\n            pdf.append(func)\n        data['E'] = energy\n        data['g'] = pdf\n        return data\n\n    @classmethod\n    def from_endf(cls, file_obj: TextIO, params: list):\n        data = cls.dict_from_endf(file_obj, params)\n        return cls(data['E'], data['g'])\n\n    @classmethod\n    def from_dict(cls, data: dict):\n        return cls(data['E'], data['g'])", "\n\n\nclass GeneralEvaporation(EnergyDistribution):\n    r\"\"\"General evaporation spectrum given in ENDF MF=5, LF=5 represented as\n\n    .. math::\n        f(E \\rightarrow E') = g(E'/\\theta(E))\n\n    Parameters\n    ----------\n    theta : openmc.data.Tabulated1D\n        Tabulated function of incident neutron energy :math:`E`\n    g : openmc.data.Tabulated1D\n        Tabulated function of :math:`x = E'/\\theta(E)`\n    u : float\n        Constant introduced to define the proper upper limit for the final\n        particle energy such that :math:`0 \\le E' \\le E - U`\n\n    Attributes\n    ----------\n    theta : openmc.data.Tabulated1D\n        Tabulated function of incident neutron energy :math:`E`\n    g : openmc.data.Tabulated1D\n        Tabulated function of :math:`x = E'/\\theta(E)`\n    u : float\n        Constant introduced to define the proper upper limit for the final\n        particle energy such that :math:`0 \\le E' \\le E - U`\n\n    \"\"\"\n\n    def __init__(self, theta, g, u):\n        super().__init__()\n        self.theta = theta\n        self.g = g\n        self.u = u\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, params: list) -> dict:\n        \"\"\"Parse general evaporation spectrum (MF=5)\n\n        Parameters\n        ----------\n        file_obj : file-like object\n            ENDF file positioned at the start of a section for an energy\n            distribution.\n        params : list\n            List of parameters at the start of the energy distribution that\n            includes the LF value indicating what type of energy distribution is\n            present.\n\n        Returns\n        -------\n        openmc.data.GeneralEvaporation\n            General evaporation spectrum\n\n        \"\"\"\n        _, theta = get_tab1_record(file_obj)\n        _, g = get_tab1_record(file_obj)\n        return {'U': params[0], 'theta': theta, 'g': g}\n\n    @classmethod\n    def from_endf(cls, file_obj: TextIO, params: list):\n        data = cls.dict_from_endf(file_obj, params)\n        return cls(data['theta'], data['g'], data['U'])\n\n    @classmethod\n    def from_dict(cls, data: dict):\n        return cls(data['theta'], data['g'], data['U'])", "\n\nclass MaxwellEnergy(EnergyDistribution):\n    r\"\"\"Simple Maxwellian fission spectrum represented as\n\n    .. math::\n        f(E \\rightarrow E') = \\frac{\\sqrt{E'}}{I} e^{-E'/\\theta(E)}\n\n    Parameters\n    ----------\n    theta : openmc.data.Tabulated1D\n        Tabulated function of incident neutron energy\n    u : float\n        Constant introduced to define the proper upper limit for the final\n        particle energy such that :math:`0 \\le E' \\le E - U`\n\n    Attributes\n    ----------\n    theta : openmc.data.Tabulated1D\n        Tabulated function of incident neutron energy\n    u : float\n        Constant introduced to define the proper upper limit for the final\n        particle energy such that :math:`0 \\le E' \\le E - U`\n\n    \"\"\"\n\n    def __init__(self, theta, u):\n        super().__init__()\n        self.theta = theta\n        self.u = u\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, params: list) -> dict:\n        \"\"\"Parse Maxwellian fission spectrum (LF=7)\n\n        Parameters\n        ----------\n        file_obj : file-like object\n            ENDF file positioned at the start of a section for an energy\n            distribution.\n        params : list\n            List of parameters at the start of the energy distribution that\n            includes the LF value indicating what type of energy distribution is\n            present.\n\n        Returns\n        -------\n        dict\n            Maxwellian distribution data\n\n        \"\"\"\n        _, theta = get_tab1_record(file_obj)\n        return {'U': params[0], 'theta': theta}\n\n    @classmethod\n    def from_dict(cls, data: dict):\n        return cls(data['theta'], data['U'])", "\n\nclass Evaporation(EnergyDistribution):\n    r\"\"\"Evaporation spectrum represented as\n\n    .. math::\n        f(E \\rightarrow E') = \\frac{E'}{I} e^{-E'/\\theta(E)}\n\n    Parameters\n    ----------\n    theta : openmc.data.Tabulated1D\n        Tabulated function of incident neutron energy\n    u : float\n        Constant introduced to define the proper upper limit for the final\n        particle energy such that :math:`0 \\le E' \\le E - U`\n\n    Attributes\n    ----------\n    theta : openmc.data.Tabulated1D\n        Tabulated function of incident neutron energy\n    u : float\n        Constant introduced to define the proper upper limit for the final\n        particle energy such that :math:`0 \\le E' \\le E - U`\n\n    \"\"\"\n\n    def __init__(self, theta, u):\n        super().__init__()\n        self.theta = theta\n        self.u = u\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, params: list) -> dict:\n        \"\"\"Parse evaporation spectrum (LF=9)\n\n        Parameters\n        ----------\n        file_obj : file-like object\n            ENDF file positioned at the start of a section for an energy\n            distribution.\n        params : list\n            List of parameters at the start of the energy distribution that\n            includes the LF value indicating what type of energy distribution is\n            present.\n\n        Returns\n        -------\n        data\n            Evaporation spectrum data\n\n        \"\"\"\n        _, theta = get_tab1_record(file_obj)\n        return {'U': params[0], 'theta': theta}\n\n    @classmethod\n    def from_endf(cls, file_obj: TextIO, params: list):\n        data = cls.dict_from_endf(file_obj, params)\n        return cls(data['theta'], data['U'])\n\n    @classmethod\n    def from_dict(cls, data: dict):\n        return cls(data['theta'], data['U'])", "\n\nclass WattEnergy(EnergyDistribution):\n    r\"\"\"Energy-dependent Watt spectrum represented as\n\n    .. math::\n        f(E \\rightarrow E') = \\frac{e^{-E'/a}}{I} \\sinh \\left ( \\sqrt{bE'}\n        \\right )\n\n    Parameters\n    ----------\n    a, b : openmc.data.Tabulated1D\n        Energy-dependent parameters tabulated as function of incident neutron\n        energy\n    u : float\n        Constant introduced to define the proper upper limit for the final\n        particle energy such that :math:`0 \\le E' \\le E - U`\n\n    Attributes\n    ----------\n    a, b : openmc.data.Tabulated1D\n        Energy-dependent parameters tabulated as function of incident neutron\n        energy\n    u : float\n        Constant introduced to define the proper upper limit for the final\n        particle energy such that :math:`0 \\le E' \\le E - U`\n\n    \"\"\"\n\n    def __init__(self, a, b, u):\n        super().__init__()\n        self.a = a\n        self.b = b\n        self.u = u\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, params: list) -> dict:\n        \"\"\"Parse energy-dependent Watt spectrum (MF=11)\n\n        Parameters\n        ----------\n        file_obj : file-like object\n            ENDF file positioned at the start of a section for an energy\n            distribution.\n        params : list\n            List of parameters at the start of the energy distribution that\n            includes the LF value indicating what type of energy distribution is\n            present.\n\n        Returns\n        -------\n        data\n            Watt fission spectrum data\n\n        \"\"\"\n        _, a = get_tab1_record(file_obj)\n        _, b = get_tab1_record(file_obj)\n        return {'U': params[0], 'a': a, 'b': b}\n\n    @classmethod\n    def from_endf(cls, file_obj: TextIO, params: list):\n        data = cls.dict_from_endf(file_obj, params)\n        return cls(data['a'], data['b'], data['U'])\n\n    @classmethod\n    def from_dict(cls, data: dict):\n        return cls(data['a'], data['b'], data['U'])", "\nclass MadlandNix(EnergyDistribution):\n    r\"\"\"Energy-dependent fission neutron spectrum (Madland and Nix) given in\n    ENDF MF=5, LF=12 represented as\n\n    .. math::\n        f(E \\rightarrow E') = \\frac{1}{2} [ g(E', E_F(L)) + g(E', E_F(H))]\n\n    where\n\n    .. math::\n        g(E',E_F) = \\frac{1}{3\\sqrt{E_F T_M}} \\left [ u_2^{3/2} E_1 (u_2) -\n        u_1^{3/2} E_1 (u_1) + \\gamma \\left ( \\frac{3}{2}, u_2 \\right ) - \\gamma\n        \\left ( \\frac{3}{2}, u_1 \\right ) \\right ] \\\\ u_1 = \\left ( \\sqrt{E'} -\n        \\sqrt{E_F} \\right )^2 / T_M \\\\ u_2 = \\left ( \\sqrt{E'} + \\sqrt{E_F}\n        \\right )^2 / T_M.\n\n    Parameters\n    ----------\n    efl, efh : float\n        Constants which represent the average kinetic energy per nucleon of the\n        fission fragment (efl = light, efh = heavy)\n    tm : openmc.data.Tabulated1D\n        Parameter tabulated as a function of incident neutron energy\n\n    Attributes\n    ----------\n    efl, efh : float\n        Constants which represent the average kinetic energy per nucleon of the\n        fission fragment (efl = light, efh = heavy)\n    tm : openmc.data.Tabulated1D\n        Parameter tabulated as a function of incident neutron energy\n\n    \"\"\"\n\n    def __init__(self, efl, efh, tm):\n        super().__init__()\n        self.efl = efl\n        self.efh = efh\n        self.tm = tm\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO, params: list) -> dict:\n        \"\"\"Parse Madland-Nix fission spectrum (LF=12)\n\n        Parameters\n        ----------\n        file_obj : file-like object\n            ENDF file positioned at the start of a section for an energy\n            distribution.\n        params : list\n            List of parameters at the start of the energy distribution that\n            includes the LF value indicating what type of energy distribution is\n            present.\n\n        Returns\n        -------\n        data\n            Madland-Nix fission spectrum data\n\n        \"\"\"\n        _, T_M = get_tab1_record(file_obj)\n        return {'EFL': params[0], 'EFH': params[1], 'T_M': T_M}\n\n    @classmethod\n    def from_endf(cls, file_obj: TextIO, params: list):\n        data = cls.dict_from_endf(file_obj, params)\n        return cls(data['EFL'], data['EFH'], data['T_M'])\n\n    @classmethod\n    def from_dict(cls, data: dict):\n        return cls(data['EFL'], data['EFH'], data['T_M'])", "\n\nclass LevelInelastic:\n    r\"\"\"Level inelastic scattering\n\n    Parameters\n    ----------\n    threshold : float\n        Energy threshold in the laboratory system, :math:`(A + 1)/A * |Q|`\n    mass_ratio : float\n        :math:`(A/(A + 1))^2`\n\n    Attributes\n    ----------\n    threshold : float\n        Energy threshold in the laboratory system, :math:`(A + 1)/A * |Q|`\n    mass_ratio : float\n        :math:`(A/(A + 1))^2`\n\n    \"\"\"\n\n    def __init__(self, threshold, mass_ratio):\n        self.threshold = threshold\n        self.mass_ratio = mass_ratio", ""]}
{"filename": "src/endf/mf3.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .records import get_head_record, get_tab1_record\n\n\ndef parse_mf3(file_obj: TextIO) -> dict:\n    \"\"\"Parse reaction cross sections from MF=3\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Cross section data\n\n    \"\"\"\n    ZA, AWR, *_ = get_head_record(file_obj)\n    params, xs = get_tab1_record(file_obj)\n    return {\n        'ZA': ZA,\n        'AWR': AWR,\n        'QM': params[0],\n        'QI': params[1],\n        'LR': params[3],\n        'sigma': xs\n    }", "def parse_mf3(file_obj: TextIO) -> dict:\n    \"\"\"Parse reaction cross sections from MF=3\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Cross section data\n\n    \"\"\"\n    ZA, AWR, *_ = get_head_record(file_obj)\n    params, xs = get_tab1_record(file_obj)\n    return {\n        'ZA': ZA,\n        'AWR': AWR,\n        'QM': params[0],\n        'QI': params[1],\n        'LR': params[3],\n        'sigma': xs\n    }", ""]}
{"filename": "src/endf/mf15.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nimport numpy as np\n\nfrom .records import get_head_record, get_tab1_record, get_tab2_record\n\n\ndef parse_mf15(file_obj: TextIO) -> dict:\n    \"\"\"Parse continuous photon energy spectra from MF=15\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Continuous photon energy spectra data\n\n    \"\"\"\n    ZA, AWR, _, _, NC, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NC': NC}\n    data['subsections'] = []\n    for j in range(NC):\n        # Read probability for j-th partial distribution\n        params, p = get_tab1_record(file_obj)\n        LF = params[3]\n        subsec = {'LF': LF, 'p': p}\n\n        # Read tabulated distributions\n        (*_, NE), subsec['E_int'] = get_tab2_record(file_obj)\n        subsec['NE'] = NE\n        subsec['E'] = np.empty(NE)\n        subsec['g'] = []\n        for i in range(NE):\n            (_, E, _, _), g = get_tab1_record(file_obj)\n            subsec['E'][i] = E\n            subsec['g'].append(g)\n        data['subsections'].append(subsec)\n\n    return data", "\n\ndef parse_mf15(file_obj: TextIO) -> dict:\n    \"\"\"Parse continuous photon energy spectra from MF=15\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Continuous photon energy spectra data\n\n    \"\"\"\n    ZA, AWR, _, _, NC, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NC': NC}\n    data['subsections'] = []\n    for j in range(NC):\n        # Read probability for j-th partial distribution\n        params, p = get_tab1_record(file_obj)\n        LF = params[3]\n        subsec = {'LF': LF, 'p': p}\n\n        # Read tabulated distributions\n        (*_, NE), subsec['E_int'] = get_tab2_record(file_obj)\n        subsec['NE'] = NE\n        subsec['E'] = np.empty(NE)\n        subsec['g'] = []\n        for i in range(NE):\n            (_, E, _, _), g = get_tab1_record(file_obj)\n            subsec['E'][i] = E\n            subsec['g'].append(g)\n        data['subsections'].append(subsec)\n\n    return data", ""]}
{"filename": "src/endf/mf6.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nimport numpy as np\n\nfrom .records import get_tab2_record, get_list_record, get_head_record, \\\n    get_tab1_record, get_cont_record\n", "    get_tab1_record, get_cont_record\n\n\ndef parse_mf6(file_obj: TextIO) -> dict:\n    \"\"\"Parse product energy-angle distributions from MF=6\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Product energy-angle distribution data\n\n    \"\"\"\n    # Read HEAD record\n    ZA, AWR, JP, LCT, NK, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'JP': JP, 'LCT': LCT, 'NK': NK}\n\n    data['products'] = products = []\n    for i in range(NK):\n        # Get yield for this product\n        (ZAP, AWP, LIP, LAW), y_i = get_tab1_record(file_obj)\n        ZAP = int(ZAP)\n\n        p = {'ZAP': ZAP, 'AWP': AWP, 'LIP': LIP, 'LAW': LAW, 'y_i': y_i}\n\n        if LAW < 0:\n            # Distribution given elsewhere\n            pass\n        elif LAW == 0:\n            # No distribution given\n            pass\n        elif LAW == 1:\n            # Continuum energy-angle distribution\n            p['distribution'] = ContinuumEnergyAngle.dict_from_endf(file_obj)\n\n        elif LAW == 2:\n            # Discrete two-body scattering\n            p['distribution'] = DiscreteTwoBodyScattering.dict_from_endf(file_obj)\n        elif LAW == 3:\n            # Isotropic discrete emission\n            pass\n\n        elif LAW == 4:\n            # Discrete two-body recoil\n            pass\n\n        elif LAW == 5:\n            # Charged particle elastic scattering\n            p['distribution'] = ChargedParticleElasticScattering.dict_from_endf(file_obj)\n\n        elif LAW == 6:\n            # N-body phase-space distribution\n            p['distribution'] = NBodyPhaseSpace.dict_from_endf(file_obj)\n\n        elif LAW == 7:\n            # Laboratory energy-angle distribution\n            p['distribution'] = LaboratoryAngleEnergy.dict_from_endf(file_obj)\n\n        products.append(p)\n\n    return data", "\n\nclass ContinuumEnergyAngle:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO) -> dict:\n        params, E_int = get_tab2_record(file_obj)\n        _, _, LANG, LEP, NR, NE = params\n\n        data = {'LANG': LANG, 'LEP': LEP, 'NR': NR, 'NE': NE, 'E_int': E_int}\n\n        data['E'] = np.zeros(NE)\n        data['distribution'] = []\n        for i in range(NE):\n            items, values = get_list_record(file_obj)\n            _, E_i, ND, NA, NW, NEP = items\n            dist = {'ND': ND, 'NA': NA, 'NW': NW, 'NEP': NEP}\n            data['E'][i] = E_i\n            values = np.asarray(values)\n            values.shape = (NEP, NA + 2)\n            dist[\"E'\"] = values[:, 0]\n            dist['b'] = values[:, 1:]\n            data['distribution'].append(dist)\n\n        return data", "\n\nclass UncorrelatedAngleEnergy:\n    def __init__(self):\n        pass\n\n\nclass DiscreteTwoBodyScattering:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO) -> dict:\n        params, E_int = get_tab2_record(file_obj)\n        *_, NR, NE = params\n        data = {'NR': NR, 'NE': NE, 'E_int': E_int}\n\n        data['E'] = np.zeros(NE)\n        data['distribution'] = []\n        for i in range(NE):\n            items, values = get_list_record(file_obj)\n            _, E_i, LANG, _, NW, NL = items\n            dist = {'LANG': LANG, 'NW': NW, 'NL': NL}\n            data['E'][i] = E_i\n            data['A_l'] = np.asarray(values)\n            data['distribution'].append(dist)", "\n\nclass ChargedParticleElasticScattering:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO) -> dict:\n        (SPI, _, LIDP, _, NR, NE), E_int = get_tab2_record(file_obj)\n        data = {'SPI': SPI, 'LIDP': LIDP, 'NE': NE, 'E_int': E_int}\n\n        # Read distribution data for each incident energy\n        data['distribution'] = []\n        for _ in range(NE):\n            (_, E, LTP, _, NW, NL), A = get_list_record(file_obj)\n            dist = {'E': E, 'LTP': LTP, 'NW': NW, 'NL': NL, 'A': A}\n            data['distribution'].append(dist)\n\n        return data", "\n\nclass NBodyPhaseSpace:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO) -> dict:\n        APSX, *_, NPSX = get_cont_record(file_obj)\n        return {'APSX': APSX, 'NPSX': NPSX}", "\n\nclass LaboratoryAngleEnergy:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def dict_from_endf(file_obj: TextIO) -> dict:\n        # Read top-level TAB2 record\n        (*_, NR, NE), E_int = get_tab2_record(file_obj)\n        data = {'NE': NE, 'E_int': E_int}\n\n        data['distribution'] = []\n        for _ in range(NE):\n            # Read TAB2 record for the i-th incident energy\n            (_, E, _, _, NRM, NMU), mu_int = get_tab2_record(file_obj)\n            dist = {'E': E, 'NRM': NRM, 'NMU': NMU, 'mu_int': mu_int}\n\n            dist['mu'] = []\n            for _ in range(NMU):\n                # Read TAB1 record for the j-th outgoing cosine\n                (_, mu, *_), f = get_tab1_record(file_obj)\n                dist['mu'].append({'mu': mu, 'f': f})\n\n            data['distribution'].append(dist)\n\n        return data", ""]}
{"filename": "src/endf/reaction.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 OpenMC contributors and Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom __future__ import annotations\nfrom copy import deepcopy\nfrom typing import List, Tuple\nfrom warnings import warn\n\nimport numpy as np\nfrom numpy.polynomial import Polynomial", "import numpy as np\nfrom numpy.polynomial import Polynomial\n\nfrom .data import gnds_name, temperature_str, ATOMIC_SYMBOL, EV_PER_MEV\nfrom .material import Material\nfrom .function import Tabulated1D\nfrom .mf4 import AngleDistribution\nfrom .mf5 import EnergyDistribution, LevelInelastic\nfrom .mf6 import UncorrelatedAngleEnergy\nfrom .product import Product", "from .mf6 import UncorrelatedAngleEnergy\nfrom .product import Product\nfrom . import ace\n\n\nREACTION_NAME = {\n    1: '(n,total)', 2: '(n,elastic)', 4: '(n,level)',\n    5: '(n,misc)', 11: '(n,2nd)', 16: '(n,2n)', 17: '(n,3n)',\n    18: '(n,fission)', 19: '(n,f)', 20: '(n,nf)', 21: '(n,2nf)',\n    22: '(n,na)', 23: '(n,n3a)', 24: '(n,2na)', 25: '(n,3na)',", "    18: '(n,fission)', 19: '(n,f)', 20: '(n,nf)', 21: '(n,2nf)',\n    22: '(n,na)', 23: '(n,n3a)', 24: '(n,2na)', 25: '(n,3na)',\n    27: '(n,absorption)', 28: '(n,np)', 29: '(n,n2a)',\n    30: '(n,2n2a)', 32: '(n,nd)', 33: '(n,nt)', 34: '(n,n3He)',\n    35: '(n,nd2a)', 36: '(n,nt2a)', 37: '(n,4n)', 38: '(n,3nf)',\n    41: '(n,2np)', 42: '(n,3np)', 44: '(n,n2p)', 45: '(n,npa)',\n    91: '(n,nc)', 101: '(n,disappear)', 102: '(n,gamma)',\n    103: '(n,p)', 104: '(n,d)', 105: '(n,t)', 106: '(n,3He)',\n    107: '(n,a)', 108: '(n,2a)', 109: '(n,3a)', 111: '(n,2p)',\n    112: '(n,pa)', 113: '(n,t2a)', 114: '(n,d2a)', 115: '(n,pd)',", "    107: '(n,a)', 108: '(n,2a)', 109: '(n,3a)', 111: '(n,2p)',\n    112: '(n,pa)', 113: '(n,t2a)', 114: '(n,d2a)', 115: '(n,pd)',\n    116: '(n,pt)', 117: '(n,da)', 152: '(n,5n)', 153: '(n,6n)',\n    154: '(n,2nt)', 155: '(n,ta)', 156: '(n,4np)', 157: '(n,3nd)',\n    158: '(n,nda)', 159: '(n,2npa)', 160: '(n,7n)', 161: '(n,8n)',\n    162: '(n,5np)', 163: '(n,6np)', 164: '(n,7np)', 165: '(n,4na)',\n    166: '(n,5na)', 167: '(n,6na)', 168: '(n,7na)', 169: '(n,4nd)',\n    170: '(n,5nd)', 171: '(n,6nd)', 172: '(n,3nt)', 173: '(n,4nt)',\n    174: '(n,5nt)', 175: '(n,6nt)', 176: '(n,2n3He)',\n    177: '(n,3n3He)', 178: '(n,4n3He)', 179: '(n,3n2p)',", "    174: '(n,5nt)', 175: '(n,6nt)', 176: '(n,2n3He)',\n    177: '(n,3n3He)', 178: '(n,4n3He)', 179: '(n,3n2p)',\n    180: '(n,3n2a)', 181: '(n,3npa)', 182: '(n,dt)',\n    183: '(n,npd)', 184: '(n,npt)', 185: '(n,ndt)',\n    186: '(n,np3He)', 187: '(n,nd3He)', 188: '(n,nt3He)',\n    189: '(n,nta)', 190: '(n,2n2p)', 191: '(n,p3He)',\n    192: '(n,d3He)', 193: '(n,3Hea)', 194: '(n,4n2p)',\n    195: '(n,4n2a)', 196: '(n,4npa)', 197: '(n,3p)',\n    198: '(n,n3p)', 199: '(n,3n2pa)', 200: '(n,5n2p)', 203: '(n,Xp)',\n    204: '(n,Xd)', 205: '(n,Xt)', 206: '(n,X3He)', 207: '(n,Xa)',", "    198: '(n,n3p)', 199: '(n,3n2pa)', 200: '(n,5n2p)', 203: '(n,Xp)',\n    204: '(n,Xd)', 205: '(n,Xt)', 206: '(n,X3He)', 207: '(n,Xa)',\n    301: 'heating', 444: 'damage-energy',\n    649: '(n,pc)', 699: '(n,dc)', 749: '(n,tc)', 799: '(n,3Hec)',\n    849: '(n,ac)', 891: '(n,2nc)'\n}\nREACTION_NAME.update({i: f'(n,n{i - 50})' for i in range(51, 91)})\nREACTION_NAME.update({i: f'(n,p{i - 600})' for i in range(600, 649)})\nREACTION_NAME.update({i: f'(n,d{i - 650})' for i in range(650, 699)})\nREACTION_NAME.update({i: f'(n,t{i - 700})' for i in range(700, 749)})", "REACTION_NAME.update({i: f'(n,d{i - 650})' for i in range(650, 699)})\nREACTION_NAME.update({i: f'(n,t{i - 700})' for i in range(700, 749)})\nREACTION_NAME.update({i: f'(n,3He{i - 750})' for i in range(750, 799)})\nREACTION_NAME.update({i: f'(n,a{i - 800})' for i in range(800, 849)})\nREACTION_NAME.update({i: f'(n,2n{i - 875})' for i in range(875, 891)})\n\nREACTION_MT = {name: mt for mt, name in REACTION_NAME.items()}\nREACTION_MT['total'] = 1\nREACTION_MT['elastic'] = 2\nREACTION_MT['fission'] = 18", "REACTION_MT['elastic'] = 2\nREACTION_MT['fission'] = 18\nREACTION_MT['absorption'] = 27\nREACTION_MT['capture'] = 102\n\nFISSION_MTS = (18, 19, 20, 21, 38)\n\n\ndef _get_products(material: Material, MT: int) -> List[Product]:\n    \"\"\"Generate products from MF=6 in an ENDF evaluation\n\n    Parameters\n    ----------\n    material\n        ENDF material to read from\n    MT\n        The MT value of the reaction to get products for\n\n    Returns\n    -------\n    Products of the reaction\n\n    \"\"\"\n    product_data = material[6, MT]\n    products = []\n    for data in product_data['products']:\n        # Determine name of particle\n        ZA = data['ZAP']\n        if ZA == 0:\n            name = 'photon'\n        elif ZA == 1:\n            name = 'neutron'\n        elif ZA == 1000:\n            name = 'electron'\n        else:\n            Z, A = divmod(ZA, 1000)\n            name = gnds_name(Z, A)\n\n        y_i = data['y_i']\n\n        # TODO: Read distributions\n        LAW = data['LAW']\n\n        products.append(Product(name, y_i))\n\n    return products", "def _get_products(material: Material, MT: int) -> List[Product]:\n    \"\"\"Generate products from MF=6 in an ENDF evaluation\n\n    Parameters\n    ----------\n    material\n        ENDF material to read from\n    MT\n        The MT value of the reaction to get products for\n\n    Returns\n    -------\n    Products of the reaction\n\n    \"\"\"\n    product_data = material[6, MT]\n    products = []\n    for data in product_data['products']:\n        # Determine name of particle\n        ZA = data['ZAP']\n        if ZA == 0:\n            name = 'photon'\n        elif ZA == 1:\n            name = 'neutron'\n        elif ZA == 1000:\n            name = 'electron'\n        else:\n            Z, A = divmod(ZA, 1000)\n            name = gnds_name(Z, A)\n\n        y_i = data['y_i']\n\n        # TODO: Read distributions\n        LAW = data['LAW']\n\n        products.append(Product(name, y_i))\n\n    return products", "\n\ndef _get_fission_products_endf(material: Material, MT: int) -> Tuple[List[Product], List[Product]]:\n    \"\"\"Generate fission products from an ENDF evaluation\n\n    Parameters\n    ----------\n    ev : openmc.data.endf.Evaluation\n\n    Returns\n    -------\n    products : list of openmc.data.Product\n        Prompt and delayed fission neutrons\n    derived_products : list of openmc.data.Product\n        \"Total\" fission neutron\n\n    \"\"\"\n    products = []\n    derived_products = []\n\n    if (1, 456) in material:\n        # Prompt nu values\n        data = material[1, 456]\n        LNU = data['LNU']\n        if LNU == 1:\n            # Polynomial representation\n            yield_ = Polynomial(data['C'])\n        elif LNU == 2:\n            # Tabulated representation\n            yield_ = data['nu']\n\n        prompt_neutron = Product('neutron', yield_=yield_)\n        products.append(prompt_neutron)\n\n    if (1, 452) in material:\n        # Total nu values\n        data = material[1, 452]\n        if data['LNU'] == 1:\n            # Polynomial representation\n            yield_ = Polynomial(data['C'])\n        elif data['LNU'] == 2:\n            # Tabulated representation\n            yield_ = data['nu']\n\n        total_neutron = Product('neutron', yield_=yield_)\n        total_neutron.emission_mode = 'total'\n\n        if (1, 456) in material:\n            derived_products.append(total_neutron)\n        else:\n            products.append(total_neutron)\n\n    if (1, 455) in material:\n        data = material[1, 455]\n        if data['LDG'] == 0:\n            # Delayed-group constants energy independent\n            decay_constants = data['lambda']\n            for constant in data['lambda']:\n                delayed_neutron = Product('neutron')\n                delayed_neutron.emission_mode = 'delayed'\n                delayed_neutron.decay_rate = constant\n                products.append(delayed_neutron)\n        elif data['LDG'] == 1:\n            # Delayed-group constants energy dependent\n            raise NotImplementedError('Delayed neutron with energy-dependent '\n                                      'group constants.')\n\n        # In MF=1, MT=455, the delayed-group abundances are actually not\n        # specified if the group constants are energy-independent. In this case,\n        # the abundances must be inferred from MF=5, MT=455 where multiple\n        # energy distributions are given.\n        if data['LNU'] == 1:\n            # Nu represented as polynomial\n            for neutron in products[-6:]:\n                neutron.yield_ = Polynomial(data['C'])\n        elif data['LNU'] == 2:\n            # Nu represented by tabulation\n            for neutron in products[-6:]:\n                neutron.yield_ = deepcopy(data['nu'])\n\n        if (5, 455) in material:\n            mf5_data = material[5, 455]\n            NK = mf5_data['NK']\n            if NK > 1 and len(decay_constants) == 1:\n                # If only one precursor group is listed in MF=1, MT=455, use the\n                # energy spectra from MF=5 to split them into different groups\n                for _ in range(NK - 1):\n                    products.append(deepcopy(products[1]))\n            elif NK != len(decay_constants):\n                raise ValueError(\n                    'Number of delayed neutron fission spectra ({}) does not '\n                    'match number of delayed neutron precursors ({}).'.format(\n                        NK, len(decay_constants)))\n            for i, subsection in enumerate(mf5_data['subsections']):\n                dist = UncorrelatedAngleEnergy()\n                dist.energy = EnergyDistribution.from_dict(subsection)\n\n                delayed_neutron = products[1 + i]\n                yield_ = delayed_neutron.yield_\n\n                # Here we handle the fact that the delayed neutron yield is the\n                # product of the total delayed neutron yield and the\n                # \"applicability\" of the energy distribution law in file 5.\n                applicability = subsection['p']\n                if isinstance(yield_, Tabulated1D):\n                    if np.all(applicability.y == applicability.y[0]):\n                        yield_.y *= applicability.y[0]\n                    else:\n                        # Get union energy grid and ensure energies are within\n                        # interpolable range of both functions\n                        max_energy = min(yield_.x[-1], applicability.x[-1])\n                        energy = np.union1d(yield_.x, applicability.x)\n                        energy = energy[energy <= max_energy]\n\n                        # Calculate group yield\n                        group_yield = yield_(energy) * applicability(energy)\n                        delayed_neutron.yield_ = Tabulated1D(energy, group_yield)\n                elif isinstance(yield_, Polynomial):\n                    if len(yield_) == 1:\n                        delayed_neutron.yield_ = deepcopy(applicability)\n                        delayed_neutron.yield_.y *= yield_.coef[0]\n                    else:\n                        if np.all(applicability.y == applicability.y[0]):\n                            yield_.coef[0] *= applicability.y[0]\n                        else:\n                            raise NotImplementedError(\n                                'Total delayed neutron yield and delayed group '\n                                'probability are both energy-dependent.')\n\n                delayed_neutron.distribution.append(dist)\n\n    return products, derived_products", "\n\ndef _get_activation_products(material: Material, MT: int, xs: Tabulated1D) -> List[Product]:\n    \"\"\"Generate activation products from an ENDF evaluation\n\n    Parameters\n    ----------\n    material\n        ENDF material to read from\n    MT\n        The MT value of the reaction to get products for\n    xs\n        Cross section for the reaction\n\n    Returns\n    -------\n    Activation products\n\n    \"\"\"\n    # Determine if file 9/10 are present\n    data = material[8, MT]\n    present = {9: False, 10: False}\n    for subsection in data['subsections']:\n        if subsection['LMF'] == 9:\n            present[9] = True\n        elif subsection['LMF'] == 10:\n            present[10] = True\n\n    products = []\n\n    for MF in (9, 10):\n        if not present[MF]:\n            continue\n\n        data = material[MF, MT]\n        for level in data['levels']:\n            # Determine what the product is\n            Z, A = divmod(level['IZAP'], 1000)\n            excited_state = level['LFS']\n\n            # Get GNDS name for product\n            symbol = ATOMIC_SYMBOL[Z]\n            if excited_state > 0:\n                name = f'{symbol}{A}_e{excited_state}'\n            else:\n                name = f'{symbol}{A}'\n\n            if MF == 9:\n                yield_ = level['Y']\n            else:\n                # Re-interpolate production cross section and neutron cross\n                # section to union energy grid\n                production_xs = level['sigma']\n                energy = np.union1d(production_xs.x, xs.x)\n                prod_xs = production_xs(energy)\n                neutron_xs = xs(energy)\n                idx = np.where(neutron_xs > 0)\n\n                # Calculate yield as ratio\n                yield_ = np.zeros_like(energy)\n                yield_[idx] = prod_xs[idx] / neutron_xs[idx]\n                yield_ = Tabulated1D(energy, yield_)\n\n            p = Product(name, yield_)\n            products.append(p)\n\n    return products", "\n\nclass Reaction:\n    \"\"\"A nuclear reaction\n\n    This class represents a single reaction channel for a nuclide with\n    an associated cross section and, if present, a secondary angle and energy\n    distribution.\n\n    Parameters\n    ----------\n    mt : int\n        The ENDF MT number for this reaction.\n    xs : dict\n        Microscopic cross section for this reaction as a function of incident\n        energy; these cross sections are provided in a dictionary where the key\n        is the temperature of the cross section set.\n    products : list\n        Reaction products\n    q_reaction : float\n        The reaction Q-value in [eV].\n    q_massdiff : float\n        The mass-difference Q value in [eV].\n    redundant : bool\n        Indicates whether or not this is a redundant reaction\n\n    Attributes\n    ----------\n    MT : int\n        The ENDF MT number for this reaction.\n    products : list\n        Reaction products\n    q_reaction : float\n        The reaction Q-value in [eV].\n    q_massdiff : float\n        The mass-difference Q value in [eV].\n    redundant : bool\n        Indicates whether or not this is a redundant reaction\n    xs : dict\n        Microscopic cross section for this reaction as a function of incident\n        energy; these cross sections are provided in a dictionary where the key\n        is the temperature of the cross section set.\n\n    \"\"\"\n    def __init__(self, MT: int, xs: dict = None, products: List[Product] = None,\n                 q_reaction: float = 0.0, q_massdiff: float = 0.0,\n                 redundant: bool = False):\n        self.MT = MT\n        self.xs = xs\n        self.products = products\n        self.q_reaction = q_reaction\n        self.q_massdiff = q_massdiff\n        self.redundant = redundant\n\n    @classmethod\n    def from_endf(cls, MT: int, material: Material) -> Reaction:\n        \"\"\"Generate reaction from ENDF file\n\n        Parameters\n        ----------\n        MT\n            MT value of the reaction\n        material\n            ENDF\n\n        \"\"\"\n        # Get reaction cross section and Q values from MF=3\n        rx = material[3, MT]\n        q_massdiff = rx['QM']\n        q_reaction = rx['QI']\n        # TODO: Do something with breakup reaction flag\n        xs = {'0K': rx['sigma']}\n\n        # Get fission product yields (nu) as well as delayed neutron energy\n        # distributions\n        products = []\n        if MT in FISSION_MTS:\n            products, derived_products = _get_fission_products_endf(material, MT)\n            # TODO: Store derived products somewhere\n\n        if (6, MT) in material:\n            # Product angle-energy distribution\n            for product in _get_products(material, MT):\n                # If fission neutrons were already added from MF=1 data, copy\n                # the distribution to the existing products. Otherwise, add the\n                # product to the reaction.\n                if MT in FISSION_MTS and product.name == 'neutron':\n                    products[0].applicability = product.applicability\n                    products[0].distribution = product.distribution\n                else:\n                    products.append(product)\n\n        elif (4, MT) in material or (5, MT) in material:\n            # Uncorrelated angle-energy distribution\n            neutron = Product('neutron')\n\n            # Note that the energy distribution for MT=455 is read in\n            # _get_fission_products_endf rather than here\n            if (5, MT) in material:\n                data = material[5, MT]\n                for subsection in data['subsections']:\n                    dist = UncorrelatedAngleEnergy()\n                    dist.energy = EnergyDistribution.from_dict(subsection)\n\n                    neutron.applicability.append(subsection['p'])\n                    neutron.distribution.append(dist)\n            elif MT == 2:\n                # Elastic scattering -- no energy distribution is given since it\n                # can be calulcated analytically\n                dist = UncorrelatedAngleEnergy()\n                neutron.distribution.append(dist)\n            elif MT >= 51 and MT < 91:\n                # Level inelastic scattering -- no energy distribution is given\n                # since it can be calculated analytically. Here we determine the\n                # necessary parameters to create a LevelInelastic object\n                dist = UncorrelatedAngleEnergy()\n\n                A = material[1, 451]['AWR']\n                threshold = (A + 1.)/A*abs(q_reaction)\n                mass_ratio = (A/(A + 1.))**2\n                dist.energy = LevelInelastic(threshold, mass_ratio)\n\n                neutron.distribution.append(dist)\n\n            if (4, MT) in material:\n                data = material[4, MT]\n                for dist in neutron.distribution:\n                    dist.angle = AngleDistribution.from_dict(data)\n\n            if MT in FISSION_MTS and (5, MT) in material:\n                # For fission reactions,\n                products[0].applicability = neutron.applicability\n                products[0].distribution = neutron.distribution\n            else:\n                products.append(neutron)\n\n        if (8, MT) in material:\n            for act_product in _get_activation_products(material, MT, rx['sigma']):\n                # Check if product already exists from MF=6 and if it does, just\n                # overwrite the existing yield.\n                for product in products:\n                    if act_product.name == product.name:\n                        product.yield_ = act_product.yield_\n                        break\n                else:\n                    products.append(act_product)\n\n        return cls(MT, xs, products, q_reaction, q_massdiff)\n\n    @classmethod\n    def from_ace(cls, table: ace.Table, i_reaction: int):\n        \"\"\"Generate incident neutron continuous-energy data from an ACE table\n\n        Parameters\n        ----------\n        table\n            ACE table to read from\n        i_reaction\n            Index of the reaction in the ACE table\n\n        Returns\n        -------\n        Reaction data\n\n        \"\"\"\n        # Get nuclide energy grid\n        n_grid = table.nxs[3]\n        grid = table.xss[table.jxs[1]:table.jxs[1] + n_grid]*EV_PER_MEV\n\n        # Convert temperature to a string for indexing data\n        strT = temperature_str(table.temperature)\n\n        if i_reaction > 0:\n            # Get MT value\n            MT = int(table.xss[table.jxs[3] + i_reaction - 1])\n\n            # Get Q-value of reaction\n            q_reaction = table.xss[table.jxs[4] + i_reaction - 1]*EV_PER_MEV\n\n            # ==================================================================\n            # CROSS SECTION\n\n            # Get locator for cross-section data\n            loc = int(table.xss[table.jxs[6] + i_reaction - 1])\n\n            # Determine starting index on energy grid\n            threshold_idx = int(table.xss[table.jxs[7] + loc - 1]) - 1\n\n            # Determine number of energies in reaction\n            n_energy = int(table.xss[table.jxs[7] + loc])\n            energy = grid[threshold_idx:threshold_idx + n_energy]\n\n            # Read reaction cross section\n            xs = table.xss[table.jxs[7] + loc + 1:table.jxs[7] + loc + 1 + n_energy]\n\n            # For damage energy production, convert to eV\n            if MT == 444:\n                xs *= EV_PER_MEV\n\n            # Warn about negative cross sections\n            if np.any(xs < 0.0):\n                warn(f\"Negative cross sections found for {MT=} in {table.name}.\")\n\n            tabulated_xs = {strT: Tabulated1D(energy, xs)}\n            rx = Reaction(MT, tabulated_xs, q_reaction=q_reaction)\n\n            # ==================================================================\n            # YIELD AND ANGLE-ENERGY DISTRIBUTION\n\n            # TODO: Read yield and angle-energy distribution\n\n        else:\n            # Elastic scattering\n            mt = 2\n\n            # Get elastic cross section values\n            elastic_xs = table.xss[table.jxs[1] + 3*n_grid:table.jxs[1] + 4*n_grid]\n\n            # Warn about negative elastic scattering cross section\n            if np.any(elastic_xs < 0.0):\n                warn(f\"Negative elastic scattering cross section found for {table.name}.\")\n\n            xs = {strT: Tabulated1D(grid, elastic_xs)}\n\n            # No energy distribution for elastic scattering\n            # TODO: Create product\n\n            rx = Reaction(2, xs)\n\n        # ======================================================================\n        # ANGLE DISTRIBUTION (FOR UNCORRELATED)\n\n        # TODO: Read angular distribution\n\n        # ======================================================================\n        # PHOTON PRODUCTION\n\n        # TODO: Read photon production\n\n        return rx\n\n\n    def __repr__(self):\n        name = REACTION_NAME.get(self.MT)\n        if name is not None:\n            return f\"<Reaction: MT={self.MT} {name}>\"\n        else:\n            return f\"<Reaction: MT={self.MT}>\"", ""]}
{"filename": "src/endf/mf8.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nimport numpy as np\n\nfrom .records import get_head_record, get_list_record, get_tab1_record, get_cont_record\n\n\ndef parse_mf8(file_obj: TextIO) -> dict:\n    \"\"\"Parse radioactive nuclide production data from MF=8\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Radioactive nuclide production data\n    \"\"\"\n    ZA, AWR, LIS, LISO, NS, NO = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LIS': LIS, 'LISO': LISO, 'NS': NS, 'NO': NO}\n\n    data['subsections'] = []\n    for _ in range(NS):\n        if NO == 0:\n            (ZAP, ELFS, LMF, LFS, _, _), values = get_list_record(file_obj)\n            ND = len(values) // 6\n            subsection = {'ZAP': ZAP, 'ELFS': ELFS, 'LMF': LMF, 'LFS': LFS, 'ND': ND}\n            subsection['HL'] = values[::6]\n            subsection['RTYP'] = values[1::6]\n            subsection['ZAN'] = values[2::6]\n            subsection['BR'] = values[3::6]\n            subsection['END'] = values[4::6]\n            subsection['CT'] = values[5::6]\n        elif NO == 1:\n            ZAP, ELFS, LMF, LFS, _, _ = get_cont_record(file_obj)\n            subsection = {'ZAP': ZAP, 'ELFS': ELFS, 'LMF': LMF, 'LFS': LFS}\n        data['subsections'].append(subsection)\n\n    return data", "\n\ndef parse_mf8(file_obj: TextIO) -> dict:\n    \"\"\"Parse radioactive nuclide production data from MF=8\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Radioactive nuclide production data\n    \"\"\"\n    ZA, AWR, LIS, LISO, NS, NO = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LIS': LIS, 'LISO': LISO, 'NS': NS, 'NO': NO}\n\n    data['subsections'] = []\n    for _ in range(NS):\n        if NO == 0:\n            (ZAP, ELFS, LMF, LFS, _, _), values = get_list_record(file_obj)\n            ND = len(values) // 6\n            subsection = {'ZAP': ZAP, 'ELFS': ELFS, 'LMF': LMF, 'LFS': LFS, 'ND': ND}\n            subsection['HL'] = values[::6]\n            subsection['RTYP'] = values[1::6]\n            subsection['ZAN'] = values[2::6]\n            subsection['BR'] = values[3::6]\n            subsection['END'] = values[4::6]\n            subsection['CT'] = values[5::6]\n        elif NO == 1:\n            ZAP, ELFS, LMF, LFS, _, _ = get_cont_record(file_obj)\n            subsection = {'ZAP': ZAP, 'ELFS': ELFS, 'LMF': LMF, 'LFS': LFS}\n        data['subsections'].append(subsection)\n\n    return data", "\n\ndef parse_mf8_mt454(file_obj: TextIO) -> dict:\n    \"\"\"Parse fission product yield data from MF=8, MT=454 / MT=459\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Fission product yield data\n\n    \"\"\"\n\n    # Determine number of energies\n    items = get_head_record(file_obj)\n    data = {'ZA': items[0], 'AWR': items[1], 'LE': items[2] - 1}\n    data['yields'] = []\n    for i in range(data['LE'] + 1):\n        # Determine i-th energy and number of products\n        (E, _, I, _, NN, NFP), values = get_list_record(file_obj)\n        yield_data = {'E': E, 'NN': NN, 'NFP': NFP}\n        yield_data['LE' if i == 0 else 'I'] = I\n\n        # Get yields for i-th energy\n        yield_data['products'] = products = []\n        for j in range(NFP):\n            ZAFP = values[4*j]\n            FPS = values[4*j + 1]\n            Y = (values[4*j + 2], values[4*j + 3])\n            products.append({'ZAFP': ZAFP, 'FPS': FPS, 'Y': Y})\n\n        data['yields'].append(yield_data)\n\n    return data", "\n\ndef parse_mf8_mt457(file_obj: TextIO) -> dict:\n    \"\"\"Parse radioactive decay data from MF=8, MT=457\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Radioactive decay data\n\n    \"\"\"\n    # Get head record\n    ZA, AWR, LIS, LISO, NST, NSP = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LIS': LIS, 'LISO': LISO, 'NST': NST, 'NSP': NSP}\n\n    # Check if nuclide is stable\n    if NST == 1:\n        get_list_record(file_obj)\n        (SPI, PAR, *_), values = get_list_record(file_obj)\n        data['SPI'] = SPI\n        data['PAR'] = PAR\n        return data\n\n    # Half-life and decay energies\n    items, values = get_list_record(file_obj)\n    data['T1/2'] = (items[0], items[1])\n    data['NC'] = NC = items[4]//2\n    data['Ex'] = list(zip(values[::2], values[1::2]))\n\n    items, values = get_list_record(file_obj)\n    data['SPI'], data['PAR'], *_ = items\n\n    # Decay mode information\n    data['NDK'] = NDK = items[5]  # Number of decay modes\n    data['modes'] = []\n    for i in range(NDK):\n        RTYP = values[6*i]\n        RFS = values[6*i + 1]\n        Q = tuple(values[6*i + 2:6*i + 4])\n        BR = tuple(values[6*i + 4:6*(i + 1)])\n        mode = {'RTYP': RTYP, 'RFS': RFS, 'Q': Q, 'BR': BR}\n        data['modes'].append(mode)\n\n    # Read spectra\n    data['spectra'] = []\n    for i in range(NSP):\n        items, values = get_list_record(file_obj)\n        _, STYP, LCON, LCOV, _, NER = items\n        spectrum = {'STYP': STYP, 'LCON': LCON, 'LCOV': LCOV, 'NER': NER}\n\n        # Decay radiation type\n        spectrum['FD'] = tuple(values[0:2])\n        spectrum['ER_AV'] = tuple(values[2:4])\n        spectrum['FC'] = tuple(values[4:6])\n\n        if LCON != 1:\n            # Information about discrete spectrum\n            spectrum['discrete'] = []\n            for j in range(NER):\n                items, values = get_list_record(file_obj)\n                discrete = {}\n                discrete['ER'] = tuple(items[0:2])\n                discrete['RTYP'] = values[0]\n                discrete['TYPE'] = values[1]\n                if STYP == 0:\n                    discrete['RI'] = tuple(values[2:4])\n                    discrete['RIS'] = tuple(values[4:6])\n                    discrete['RICC'] = tuple(values[6:8])\n                    discrete['RICK'] = tuple(values[8:10])\n                    discrete['RICL'] = tuple(values[10:12])\n                spectrum['discrete'].append(discrete)\n\n        if LCON != 0:\n            # Read continuous spectrum\n            params, RP = get_tab1_record(file_obj)\n            spectrum['continuous'] = {'RTYP': params[0], 'RP': RP}\n\n        # Read continuous covariance (Ek, Fk) table\n        if LCOV not in (0, 2) and LCON != 0:\n            items, values = get_list_record(file_obj)\n            covar_continuous = {'LB': items[3]}\n            covar_continuous['Ek'] = np.array(values[::2])\n            covar_continuous['Fk'] = np.array(values[1::2])\n            spectrum['continuous_covariance'] = covar_continuous\n\n        if LCOV not in (0, 1):\n            (_, _, LS, LB, NE, NERP), values = get_list_record(file_obj)\n            covar_discrete = {'LS': LS, 'LB': LB, 'NE': NE, 'NERP': NERP}\n            covar_discrete['Ek'] = np.array(values[:NERP])\n            covar_discrete['Fkk'] = np.array(values[NERP:])\n            # TODO: Reorder and shape Fkk based on the packing order described\n            # in section 8.4 of the ENDF manual\n            spectrum['discrete_covariance'] = covar_discrete\n\n        # Add spectrum to list\n        data['spectra'].append(spectrum)\n\n    return data", ""]}
{"filename": "src/endf/mf23.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .records import get_head_record, get_tab1_record\n\n\ndef parse_mf23(file_obj: TextIO) -> dict:\n    \"\"\"Parse photon cross sections from MF=23\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Photon cross section data\n\n    \"\"\"\n    ZA, AWR, *_ = get_head_record(file_obj)\n    params, xs = get_tab1_record(file_obj)\n    return {\n        'ZA': ZA,\n        'AWR': AWR,\n        'EPE': params[0],\n        'EFL': params[1],\n        'sigma': xs\n    }", "def parse_mf23(file_obj: TextIO) -> dict:\n    \"\"\"Parse photon cross sections from MF=23\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Photon cross section data\n\n    \"\"\"\n    ZA, AWR, *_ = get_head_record(file_obj)\n    params, xs = get_tab1_record(file_obj)\n    return {\n        'ZA': ZA,\n        'AWR': AWR,\n        'EPE': params[0],\n        'EFL': params[1],\n        'sigma': xs\n    }", ""]}
{"filename": "src/endf/records.py", "chunked_list": ["import re\nfrom typing import TextIO, Tuple\n\nimport numpy as np\n\nfrom .function import Tabulated1D, Tabulated2D\nfrom ._records import float_endf\n\nENDF_FLOAT_RE = re.compile(r'([\\s\\-\\+]?\\d*\\.\\d+)([\\+\\-]) ?(\\d+)')\n", "ENDF_FLOAT_RE = re.compile(r'([\\s\\-\\+]?\\d*\\.\\d+)([\\+\\-]) ?(\\d+)')\n\n\ndef py_float_endf(s: str) -> float:\n    \"\"\"Convert string of floating point number in ENDF to float.\n\n    The ENDF-6 format uses an 'e-less' floating point number format,\n    e.g. -1.23481+10. Trying to convert using the float built-in won't work\n    because of the lack of an 'e'. This function allows such strings to be\n    converted while still allowing numbers that are not in exponential notation\n    to be converted as well.\n\n    Parameters\n    ----------\n    s : str\n        Floating-point number from an ENDF file\n\n    Returns\n    -------\n    float\n        The number\n\n    \"\"\"\n    return float(ENDF_FLOAT_RE.sub(r'\\1e\\2\\3', s))", "\n\ndef int_endf(s: str) -> int:\n    \"\"\"Convert string of integer number in ENDF to int.\n\n    The ENDF-6 format technically allows integers to be represented by a field\n    of all blanks. This function acts like int(s) except when s is a string of\n    all whitespace, in which case zero is returned.\n\n    Parameters\n    ----------\n    s : str\n        Integer or spaces\n\n    Returns\n    -------\n    integer\n        The number or 0\n    \"\"\"\n    return 0 if s.isspace() else int(s)", "\n\ndef get_text_record(file_obj) -> str:\n    \"\"\"Return data from a TEXT record in an ENDF-6 file.\n\n    Parameters\n    ----------\n    file_obj : file-like object\n        ENDF-6 file to read from\n\n    Returns\n    -------\n    str\n        Text within the TEXT record\n\n    \"\"\"\n    return file_obj.readline()[:66]", "\n\ndef get_cont_record(file_obj, skip_c=False):\n    \"\"\"Return data from a CONT record in an ENDF-6 file.\n\n    Parameters\n    ----------\n    file_obj : file-like object\n        ENDF-6 file to read from\n    skip_c : bool\n        Determine whether to skip the first two quantities (C1, C2) of the CONT\n        record.\n\n    Returns\n    -------\n    tuple\n        The six items within the CONT record\n\n    \"\"\"\n    line = file_obj.readline()\n    if skip_c:\n        C1 = None\n        C2 = None\n    else:\n        C1 = float_endf(line[:11])\n        C2 = float_endf(line[11:22])\n    L1 = int_endf(line[22:33])\n    L2 = int_endf(line[33:44])\n    N1 = int_endf(line[44:55])\n    N2 = int_endf(line[55:66])\n    return (C1, C2, L1, L2, N1, N2)", "\n\ndef get_head_record(file_obj):\n    \"\"\"Return data from a HEAD record in an ENDF-6 file.\n\n    Parameters\n    ----------\n    file_obj : file-like object\n        ENDF-6 file to read from\n\n    Returns\n    -------\n    tuple\n        The six items within the HEAD record\n\n    \"\"\"\n    line = file_obj.readline()\n    ZA = int(float_endf(line[:11]))\n    AWR = float_endf(line[11:22])\n    L1 = int_endf(line[22:33])\n    L2 = int_endf(line[33:44])\n    N1 = int_endf(line[44:55])\n    N2 = int_endf(line[55:66])\n    return (ZA, AWR, L1, L2, N1, N2)", "\n\ndef get_list_record(file_obj: TextIO) -> Tuple[list, np.ndarray]:\n    \"\"\"Return data from a LIST record in an ENDF-6 file.\n\n    Parameters\n    ----------\n    file_obj : file-like object\n        ENDF-6 file to read from\n\n    Returns\n    -------\n    list\n        The six items within the header\n    numpy.ndarray\n        The values within the list\n\n    \"\"\"\n    # determine how many items are in list\n    items = get_cont_record(file_obj)\n    NPL = items[4]\n\n    # read items\n    b = np.empty(NPL)\n    for i in range((NPL - 1)//6 + 1):\n        line = file_obj.readline()\n        n = min(6, NPL - 6*i)\n        for j in range(n):\n            b[6*i + j] = float_endf(line[11*j:11*(j + 1)])\n\n    return (items, b)", "\n\ndef get_tab1_record(file_obj):\n    \"\"\"Return data from a TAB1 record in an ENDF-6 file.\n\n    Parameters\n    ----------\n    file_obj : file-like object\n        ENDF-6 file to read from\n\n    Returns\n    -------\n    list\n        The six items within the header\n    openmc.data.Tabulated1D\n        The tabulated function\n\n    \"\"\"\n    # Determine how many interpolation regions and total points there are\n    line = file_obj.readline()\n    C1 = float_endf(line[:11])\n    C2 = float_endf(line[11:22])\n    L1 = int_endf(line[22:33])\n    L2 = int_endf(line[33:44])\n    n_regions = int_endf(line[44:55])\n    n_pairs = int_endf(line[55:66])\n    params = [C1, C2, L1, L2]\n\n    # Read the interpolation region data, namely NBT and INT\n    breakpoints = np.zeros(n_regions, dtype=int)\n    interpolation = np.zeros(n_regions, dtype=int)\n    m = 0\n    for i in range((n_regions - 1)//3 + 1):\n        line = file_obj.readline()\n        to_read = min(3, n_regions - m)\n        for j in range(to_read):\n            breakpoints[m] = int_endf(line[0:11])\n            interpolation[m] = int_endf(line[11:22])\n            line = line[22:]\n            m += 1\n\n    # Read tabulated pairs x(n) and y(n)\n    x = np.zeros(n_pairs)\n    y = np.zeros(n_pairs)\n    m = 0\n    for i in range((n_pairs - 1)//3 + 1):\n        line = file_obj.readline()\n        to_read = min(3, n_pairs - m)\n        for j in range(to_read):\n            x[m] = float_endf(line[:11])\n            y[m] = float_endf(line[11:22])\n            line = line[22:]\n            m += 1\n\n    return params, Tabulated1D(x, y, breakpoints, interpolation)", "\n\ndef get_tab2_record(file_obj):\n    # Determine how many interpolation regions and total points there are\n    params = get_cont_record(file_obj)\n    n_regions = params[4]\n\n    # Read the interpolation region data, namely NBT and INT\n    breakpoints = np.zeros(n_regions, dtype=int)\n    interpolation = np.zeros(n_regions, dtype=int)\n    m = 0\n    for _ in range((n_regions - 1)//3 + 1):\n        line = file_obj.readline()\n        to_read = min(3, n_regions - m)\n        for _ in range(to_read):\n            breakpoints[m] = int(line[0:11])\n            interpolation[m] = int(line[11:22])\n            line = line[22:]\n            m += 1\n\n    return params, Tabulated2D(breakpoints, interpolation)", "\n\ndef get_intg_record(file_obj):\n    \"\"\"\n    Return data from an INTG record in an ENDF-6 file. Used to store the\n    covariance matrix in a compact format.\n\n    Parameters\n    ----------\n    file_obj : file-like object\n        ENDF-6 file to read from\n\n    Returns\n    -------\n    numpy.ndarray\n        The correlation matrix described in the INTG record\n    \"\"\"\n    # determine how many items are in list and NDIGIT\n    items = get_cont_record(file_obj)\n    ndigit = items[2]\n    npar = items[3]    # Number of parameters\n    nlines = items[4]  # Lines to read\n    NROW_RULES = {2: 18, 3: 12, 4: 11, 5: 9, 6: 8}\n    nrow = NROW_RULES[ndigit]\n\n    # read lines and build correlation matrix\n    corr = np.identity(npar)\n    for i in range(nlines):\n        line = file_obj.readline()\n        ii = int_endf(line[:5]) - 1  # -1 to account for 0 indexing\n        jj = int_endf(line[5:10]) - 1\n        factor = 10**ndigit\n        for j in range(nrow):\n            if jj+j >= ii:\n                break\n            element = int_endf(line[11+(ndigit+1)*j:11+(ndigit+1)*(j+1)])\n            if element > 0:\n                corr[ii, jj] = (element+0.5)/factor\n            elif element < 0:\n                corr[ii, jj] = (element-0.5)/factor\n\n    # Symmetrize the correlation matrix\n    corr = corr + corr.T - np.diag(corr.diagonal())\n    return corr", ""]}
{"filename": "src/endf/mf28.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .records import get_head_record, get_list_record\n\n\ndef parse_mf28(file_obj: TextIO) -> dict:\n    \"\"\"Parse atomic relaxation data from MF=27\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Atomic relaxation data\n\n    \"\"\"\n    ZA, AWR, _, _, NSS, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NSS': NSS, 'shells': []}\n    for _ in range(NSS):\n        # Read LIST record for each shell\n        (SUBI, _, _, _, NW, NTR), values = get_list_record(file_obj)\n        shell = {'SUBI': SUBI, 'NTR': NTR}\n        shell['EBI'] = values[0]\n        shell['ELN'] = values[1]\n        shell['SUBJ'] = values[6::6]\n        shell['SUBK'] = values[7::6]\n        shell['ETR'] = values[8::6]\n        shell['FTR'] = values[9::6]\n        data['shells'].append(shell)\n    return data", "def parse_mf28(file_obj: TextIO) -> dict:\n    \"\"\"Parse atomic relaxation data from MF=27\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Atomic relaxation data\n\n    \"\"\"\n    ZA, AWR, _, _, NSS, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NSS': NSS, 'shells': []}\n    for _ in range(NSS):\n        # Read LIST record for each shell\n        (SUBI, _, _, _, NW, NTR), values = get_list_record(file_obj)\n        shell = {'SUBI': SUBI, 'NTR': NTR}\n        shell['EBI'] = values[0]\n        shell['ELN'] = values[1]\n        shell['SUBJ'] = values[6::6]\n        shell['SUBK'] = values[7::6]\n        shell['ETR'] = values[8::6]\n        shell['FTR'] = values[9::6]\n        data['shells'].append(shell)\n    return data", ""]}
{"filename": "src/endf/mf13.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .records import get_head_record, get_tab1_record\n\n\ndef parse_mf13(file_obj: TextIO) -> dict:\n    \"\"\"Parse photon production cross sections from MF=13\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Photon production cross section data\n\n    \"\"\"\n    ZA, AWR, _, _, NK, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NK': NK}\n\n    # Read total photon production\n    if NK > 1:\n        _, data['sigma_total'] = get_tab1_record(file_obj)\n\n    # Read production cross sections for each photon\n    data['photons'] = []\n    for k in range(NK):\n        (EG, ES, LP, LF), sigma = get_tab1_record(file_obj)\n        photon = {'EG': EG, 'ES': ES, 'LP': LP, 'LF': LF, 'sigma': sigma}\n        data['photons'].append(photon)\n\n    return data", "def parse_mf13(file_obj: TextIO) -> dict:\n    \"\"\"Parse photon production cross sections from MF=13\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Photon production cross section data\n\n    \"\"\"\n    ZA, AWR, _, _, NK, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NK': NK}\n\n    # Read total photon production\n    if NK > 1:\n        _, data['sigma_total'] = get_tab1_record(file_obj)\n\n    # Read production cross sections for each photon\n    data['photons'] = []\n    for k in range(NK):\n        (EG, ES, LP, LF), sigma = get_tab1_record(file_obj)\n        photon = {'EG': EG, 'ES': ES, 'LP': LP, 'LF': LF, 'sigma': sigma}\n        data['photons'].append(photon)\n\n    return data", ""]}
{"filename": "src/endf/mf27.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .records import get_head_record, get_tab1_record\n\n\ndef parse_mf27(file_obj: TextIO) -> dict:\n    \"\"\"Parse atomic form factors / scattering functions from MF=27\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Atomic form factor or scattering function data\n\n    \"\"\"\n    ZA, AWR, *_ = get_head_record(file_obj)\n    params, H = get_tab1_record(file_obj)\n    return {'ZA': ZA, 'AWR': AWR, 'Z': params[1], 'H': H}", "def parse_mf27(file_obj: TextIO) -> dict:\n    \"\"\"Parse atomic form factors / scattering functions from MF=27\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Atomic form factor or scattering function data\n\n    \"\"\"\n    ZA, AWR, *_ = get_head_record(file_obj)\n    params, H = get_tab1_record(file_obj)\n    return {'ZA': ZA, 'AWR': AWR, 'Z': params[1], 'H': H}", ""]}
{"filename": "src/endf/function.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 OpenMC contributors and Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom collections.abc import Iterable\nfrom math import exp, log\n\nimport numpy as np\n\nfrom .data import EV_PER_MEV\n", "from .data import EV_PER_MEV\n\n\nclass Tabulated1D:\n    \"\"\"A one-dimensional tabulated function.\n\n    This class mirrors the TAB1 type from the ENDF-6 format. A tabulated\n    function is specified by tabulated (x,y) pairs along with interpolation\n    rules that determine the values between tabulated pairs.\n\n    Once an object has been created, it can be used as though it were an actual\n    function, e.g.:\n\n    >>> f = Tabulated1D([0, 10], [4, 5])\n    >>> [f(xi) for xi in numpy.linspace(0, 10, 5)]\n    [4.0, 4.25, 4.5, 4.75, 5.0]\n\n    Parameters\n    ----------\n    x : Iterable of float\n        Independent variable\n    y : Iterable of float\n        Dependent variable\n    breakpoints : Iterable of int\n        Breakpoints for interpolation regions\n    interpolation : Iterable of int\n        Interpolation scheme identification number, e.g., 3 means y is linear in\n        ln(x).\n\n    Attributes\n    ----------\n    x : Iterable of float\n        Independent variable\n    y : Iterable of float\n        Dependent variable\n    breakpoints : Iterable of int\n        Breakpoints for interpolation regions\n    interpolation : Iterable of int\n        Interpolation scheme identification number, e.g., 3 means y is linear in\n        ln(x).\n    n_regions : int\n        Number of interpolation regions\n    n_pairs : int\n        Number of tabulated (x,y) pairs\n\n    \"\"\"\n\n    def __init__(self, x, y, breakpoints=None, interpolation=None):\n        if breakpoints is None or interpolation is None:\n            # Single linear-linear interpolation region by default\n            self.breakpoints = np.array([len(x)])\n            self.interpolation = np.array([2])\n        else:\n            self.breakpoints = np.asarray(breakpoints, dtype=int)\n            self.interpolation = np.asarray(interpolation, dtype=int)\n\n        self.x = np.asarray(x)\n        self.y = np.asarray(y)\n\n    def __repr__(self):\n        return f\"<Tabulated1D: {self.x.size} points, {self.breakpoints.size} regions>\"\n\n    def __call__(self, x):\n        # Check if input is scalar\n        if not isinstance(x, Iterable):\n            return self._interpolate_scalar(x)\n\n        x = np.array(x)\n\n        # Create output array\n        y = np.zeros_like(x)\n\n        # Get indices for interpolation\n        idx = np.searchsorted(self.x, x, side='right') - 1\n\n        # Loop over interpolation regions\n        for k in range(len(self.breakpoints)):\n            # Get indices for the begining and ending of this region\n            i_begin = self.breakpoints[k-1] - 1 if k > 0 else 0\n            i_end = self.breakpoints[k] - 1\n\n            # Figure out which idx values lie within this region\n            contained = (idx >= i_begin) & (idx < i_end)\n\n            xk = x[contained]                 # x values in this region\n            xi = self.x[idx[contained]]       # low edge of corresponding bins\n            xi1 = self.x[idx[contained] + 1]  # high edge of corresponding bins\n            yi = self.y[idx[contained]]\n            yi1 = self.y[idx[contained] + 1]\n\n            if self.interpolation[k] == 1:\n                # Histogram\n                y[contained] = yi\n\n            elif self.interpolation[k] == 2:\n                # Linear-linear\n                y[contained] = yi + (xk - xi)/(xi1 - xi)*(yi1 - yi)\n\n            elif self.interpolation[k] == 3:\n                # Linear-log\n                y[contained] = yi + np.log(xk/xi)/np.log(xi1/xi)*(yi1 - yi)\n\n            elif self.interpolation[k] == 4:\n                # Log-linear\n                y[contained] = yi*np.exp((xk - xi)/(xi1 - xi)*np.log(yi1/yi))\n\n            elif self.interpolation[k] == 5:\n                # Log-log\n                y[contained] = (yi*np.exp(np.log(xk/xi)/np.log(xi1/xi)\n                                *np.log(yi1/yi)))\n\n        # In some cases, x values might be outside the tabulated region due only\n        # to precision, so we check if they're close and set them equal if so.\n        y[np.isclose(x, self.x[0], atol=1e-14)] = self.y[0]\n        y[np.isclose(x, self.x[-1], atol=1e-14)] = self.y[-1]\n\n        return y\n\n    def _interpolate_scalar(self, x):\n        if x <= self._x[0]:\n            return self._y[0]\n        elif x >= self._x[-1]:\n            return self._y[-1]\n\n        # Get the index for interpolation\n        idx = np.searchsorted(self._x, x, side='right') - 1\n\n        # Loop over interpolation regions\n        for b, p in zip(self.breakpoints, self.interpolation):\n            if idx < b - 1:\n                break\n\n        xi = self._x[idx]       # low edge of the corresponding bin\n        xi1 = self._x[idx + 1]  # high edge of the corresponding bin\n        yi = self._y[idx]\n        yi1 = self._y[idx + 1]\n\n        if p == 1:\n            # Histogram\n            return yi\n\n        elif p == 2:\n            # Linear-linear\n            return yi + (x - xi)/(xi1 - xi)*(yi1 - yi)\n\n        elif p == 3:\n            # Linear-log\n            return yi + log(x/xi)/log(xi1/xi)*(yi1 - yi)\n\n        elif p == 4:\n            # Log-linear\n            return yi*exp((x - xi)/(xi1 - xi)*log(yi1/yi))\n\n        elif p == 5:\n            # Log-log\n            return yi*exp(log(x/xi)/log(xi1/xi)*log(yi1/yi))\n\n    def __len__(self):\n        return len(self.x)\n\n    @property\n    def x(self):\n        return self._x\n\n    @property\n    def y(self):\n        return self._y\n\n    @property\n    def breakpoints(self):\n        return self._breakpoints\n\n    @property\n    def interpolation(self):\n        return self._interpolation\n\n    @property\n    def n_pairs(self):\n        return len(self.x)\n\n    @property\n    def n_regions(self):\n        return len(self.breakpoints)\n\n    @x.setter\n    def x(self, x):\n        self._x = x\n\n    @y.setter\n    def y(self, y):\n        self._y = y\n\n    @breakpoints.setter\n    def breakpoints(self, breakpoints):\n        self._breakpoints = breakpoints\n\n    @interpolation.setter\n    def interpolation(self, interpolation):\n        self._interpolation = interpolation\n\n    def integral(self):\n        \"\"\"Integral of the tabulated function over its tabulated range.\n\n        Returns\n        -------\n        numpy.ndarray\n            Array of same length as the tabulated data that represents partial\n            integrals from the bottom of the range to each tabulated point.\n\n        \"\"\"\n\n        # Create output array\n        partial_sum = np.zeros(len(self.x) - 1)\n\n        i_low = 0\n        for k in range(len(self.breakpoints)):\n            # Determine which x values are within this interpolation range\n            i_high = self.breakpoints[k] - 1\n\n            # Get x values and bounding (x,y) pairs\n            x0 = self.x[i_low:i_high]\n            x1 = self.x[i_low + 1:i_high + 1]\n            y0 = self.y[i_low:i_high]\n            y1 = self.y[i_low + 1:i_high + 1]\n\n            if self.interpolation[k] == 1:\n                # Histogram\n                partial_sum[i_low:i_high] = y0*(x1 - x0)\n\n            elif self.interpolation[k] == 2:\n                # Linear-linear\n                m = (y1 - y0)/(x1 - x0)\n                partial_sum[i_low:i_high] = (y0 - m*x0)*(x1 - x0) + \\\n                                            m*(x1**2 - x0**2)/2\n\n            elif self.interpolation[k] == 3:\n                # Linear-log\n                logx = np.log(x1/x0)\n                m = (y1 - y0)/logx\n                partial_sum[i_low:i_high] = y0 + m*(x1*(logx - 1) + x0)\n\n            elif self.interpolation[k] == 4:\n                # Log-linear\n                m = np.log(y1/y0)/(x1 - x0)\n                partial_sum[i_low:i_high] = y0/m*(np.exp(m*(x1 - x0)) - 1)\n\n            elif self.interpolation[k] == 5:\n                # Log-log\n                m = np.log(y1/y0)/np.log(x1/x0)\n                partial_sum[i_low:i_high] = y0/((m + 1)*x0**m)*(\n                    x1**(m + 1) - x0**(m + 1))\n\n            i_low = i_high\n\n        return np.concatenate(([0.], np.cumsum(partial_sum)))\n\n    @classmethod\n    def from_ace(cls, ace, idx=0, convert_units=True):\n        \"\"\"Create a Tabulated1D object from an ACE table.\n\n        Parameters\n        ----------\n        ace : openmc.data.ace.Table\n            An ACE table\n        idx : int\n            Offset to read from in XSS array (default of zero)\n        convert_units : bool\n            If the abscissa represents energy, indicate whether to convert MeV\n            to eV.\n\n        Returns\n        -------\n        openmc.data.Tabulated1D\n            Tabulated data object\n\n        \"\"\"\n\n        # Get number of regions and pairs\n        n_regions = int(ace.xss[idx])\n        n_pairs = int(ace.xss[idx + 1 + 2*n_regions])\n\n        # Get interpolation information\n        idx += 1\n        if n_regions > 0:\n            breakpoints = ace.xss[idx:idx + n_regions].astype(int)\n            interpolation = ace.xss[idx + n_regions:idx + 2*n_regions].astype(int)\n        else:\n            # 0 regions implies linear-linear interpolation by default\n            breakpoints = np.array([n_pairs])\n            interpolation = np.array([2])\n\n        # Get (x,y) pairs\n        idx += 2*n_regions + 1\n        x = ace.xss[idx:idx + n_pairs].copy()\n        y = ace.xss[idx + n_pairs:idx + 2*n_pairs].copy()\n\n        if convert_units:\n            x *= EV_PER_MEV\n\n        return Tabulated1D(x, y, breakpoints, interpolation)", "\n\nclass Tabulated2D:\n    \"\"\"Metadata for a two-dimensional function.\n\n    This is a dummy class that is not really used other than to store the\n    interpolation information for a two-dimensional function. Once we refactor\n    to adopt GNDS-like data containers, this will probably be removed or\n    extended.\n\n    Parameters\n    ----------\n    breakpoints : Iterable of int\n        Breakpoints for interpolation regions\n    interpolation : Iterable of int\n        Interpolation scheme identification number, e.g., 3 means y is linear in\n        ln(x).\n\n    \"\"\"\n    def __init__(self, breakpoints, interpolation):\n        self.breakpoints = breakpoints\n        self.interpolation = interpolation", ""]}
{"filename": "src/endf/__init__.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom importlib.metadata import version, PackageNotFoundError\n\nfrom .material import *\nfrom .incident_neutron import *\nfrom .function import *\nfrom .product import *\nfrom .reaction import *", "from .product import *\nfrom .reaction import *\nfrom . import ace\n\ntry:\n    __version__ = version(\"endf\")\nexcept PackageNotFoundError:\n    # package is not installed\n    pass\n", ""]}
{"filename": "src/endf/mf34.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nimport numpy as np\n\nfrom .records import get_head_record, get_cont_record, get_list_record\n\n\ndef parse_mf34(file_obj: TextIO, MT: int) -> dict:\n    \"\"\"Parse covariances of angular distributions from MF=34\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n    MT\n        Reaction number\n\n    Returns\n    -------\n    dict\n        Angular distribution covariance data\n\n    \"\"\"\n    ZA, AWR, _, LTT, _, NMT1 = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LTT': LTT, 'NMT1': NMT1, 'subsections': []}\n    for _ in range(NMT1):\n        _, _, MAT1, MT1, NL, NL1 = get_cont_record(file_obj)\n        if MT1 == 0 or MT == MT1:\n            NSS = NL*(NL + 1)//2\n        else:\n            NSS = NL*NL1\n        subsection = {'MAT1': MAT1, 'MT1': MT1, 'NL': NL, 'NSS': NSS}\n        subsection['L'] = np.empty(NSS)\n        subsection['L1'] = np.empty(NSS)\n        subsection['NI'] = np.empty(NSS)\n        subsection['subsubsections'] = []\n\n        for n in range(NSS):\n            _, _, L, L1, LCT, NI = get_cont_record(file_obj)\n            subsection['L'][n] = L\n            subsection['L1'][n] = L1\n            subsection['NI'][n] = NI\n            if n == 0:\n                subsection['LCT'] = LCT\n\n            subsub = {\n                'LS': np.empty(NI),\n                'LB': np.empty(NI),\n                'NT': np.empty(NI),\n                'NE': np.empty(NI),\n                'Data': []\n            }\n            for m in range(NI):\n                (_, _, LS, LB, NT, NE), values = get_list_record(file_obj)\n                subsub['LS'][m] = LS\n                subsub['LB'][m] = LS\n                subsub['NT'][m] = NT\n                subsub['NE'][m] = NE\n                subsub['Data'].append(values)\n            subsection['subsubsections'].append(subsub)\n\n    return data", "\n\ndef parse_mf34(file_obj: TextIO, MT: int) -> dict:\n    \"\"\"Parse covariances of angular distributions from MF=34\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n    MT\n        Reaction number\n\n    Returns\n    -------\n    dict\n        Angular distribution covariance data\n\n    \"\"\"\n    ZA, AWR, _, LTT, _, NMT1 = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LTT': LTT, 'NMT1': NMT1, 'subsections': []}\n    for _ in range(NMT1):\n        _, _, MAT1, MT1, NL, NL1 = get_cont_record(file_obj)\n        if MT1 == 0 or MT == MT1:\n            NSS = NL*(NL + 1)//2\n        else:\n            NSS = NL*NL1\n        subsection = {'MAT1': MAT1, 'MT1': MT1, 'NL': NL, 'NSS': NSS}\n        subsection['L'] = np.empty(NSS)\n        subsection['L1'] = np.empty(NSS)\n        subsection['NI'] = np.empty(NSS)\n        subsection['subsubsections'] = []\n\n        for n in range(NSS):\n            _, _, L, L1, LCT, NI = get_cont_record(file_obj)\n            subsection['L'][n] = L\n            subsection['L1'][n] = L1\n            subsection['NI'][n] = NI\n            if n == 0:\n                subsection['LCT'] = LCT\n\n            subsub = {\n                'LS': np.empty(NI),\n                'LB': np.empty(NI),\n                'NT': np.empty(NI),\n                'NE': np.empty(NI),\n                'Data': []\n            }\n            for m in range(NI):\n                (_, _, LS, LB, NT, NE), values = get_list_record(file_obj)\n                subsub['LS'][m] = LS\n                subsub['LB'][m] = LS\n                subsub['NT'][m] = NT\n                subsub['NE'][m] = NE\n                subsub['Data'].append(values)\n            subsection['subsubsections'].append(subsub)\n\n    return data", ""]}
{"filename": "src/endf/mf7.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .records import get_head_record, get_tab1_record, get_list_record, \\\n    get_tab2_record\n\n\ndef parse_mf7_mt2(file_obj: TextIO) -> dict:\n    \"\"\"Parse elastic thermal scattering data from MF=7, MT=2\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Thermal scattering data\n\n    \"\"\"\n\n    # Read coherent/incoherent elastic data\n\n    # Define helper functions to avoid duplication\n    def get_coherent_elastic(file_obj):\n        # Get structure factor at first temperature\n        params, S = get_tab1_record(file_obj)\n        T, _, LT, *_ = params\n        temp_data = [{'T': T, 'LT': LT, 'S': S}]\n\n        # Get structure factor for subsequent temperatures\n        for _ in range(LT):\n            params, S = get_list_record(file_obj)\n            T, _, LI, *_ = params\n            temp_data.append({'T': T, 'LI': LI, 'S': S})\n\n        return temp_data\n\n    def get_incoherent_elastic(file_obj):\n        params, W = get_tab1_record(file_obj)\n        return {'SB': params[0], 'W': W}\n\n    ZA, AWR, LHTR, *_ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LHTR': LHTR}\n\n    if LHTR == 1:\n        # coherent elastic\n        data['coherent'] = get_coherent_elastic(file_obj)\n    elif LHTR == 2:\n        # incoherent elastic\n        data['incoherent'] = get_incoherent_elastic(file_obj)\n    elif LHTR == 3:\n        # mixed coherent / incoherent elastic\n        data['coherent'] = get_coherent_elastic(file_obj)\n        data['incoherent'] = get_incoherent_elastic(file_obj)\n\n    return data", "\ndef parse_mf7_mt2(file_obj: TextIO) -> dict:\n    \"\"\"Parse elastic thermal scattering data from MF=7, MT=2\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Thermal scattering data\n\n    \"\"\"\n\n    # Read coherent/incoherent elastic data\n\n    # Define helper functions to avoid duplication\n    def get_coherent_elastic(file_obj):\n        # Get structure factor at first temperature\n        params, S = get_tab1_record(file_obj)\n        T, _, LT, *_ = params\n        temp_data = [{'T': T, 'LT': LT, 'S': S}]\n\n        # Get structure factor for subsequent temperatures\n        for _ in range(LT):\n            params, S = get_list_record(file_obj)\n            T, _, LI, *_ = params\n            temp_data.append({'T': T, 'LI': LI, 'S': S})\n\n        return temp_data\n\n    def get_incoherent_elastic(file_obj):\n        params, W = get_tab1_record(file_obj)\n        return {'SB': params[0], 'W': W}\n\n    ZA, AWR, LHTR, *_ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LHTR': LHTR}\n\n    if LHTR == 1:\n        # coherent elastic\n        data['coherent'] = get_coherent_elastic(file_obj)\n    elif LHTR == 2:\n        # incoherent elastic\n        data['incoherent'] = get_incoherent_elastic(file_obj)\n    elif LHTR == 3:\n        # mixed coherent / incoherent elastic\n        data['coherent'] = get_coherent_elastic(file_obj)\n        data['incoherent'] = get_incoherent_elastic(file_obj)\n\n    return data", "\n\ndef parse_mf7_mt4(file_obj: TextIO) -> dict:\n    \"\"\"Parse inelastic thermal scattering data from MF=7, MT=4\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Thermal scattering data\n\n    \"\"\"\n\n    # Read incoherent inelastic data\n    ZA, AWR, _, LAT, LASYM, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LAT': LAT, 'LASYM': LASYM}\n\n    # Get information about principal atom\n    params, B = get_list_record(file_obj)\n    _, _, LLN, _, NI, NS = params\n    data['LLN'] = LLN\n    data['NI'] = NI\n    data['NS'] = NS\n    data['B'] = B\n\n    # Get S(alpha,beta,T)\n    kTs = []\n    if data['B'][0] > 0.0:\n        params, data['beta_int'] = get_tab2_record(file_obj)\n        data['NB'] = NB = params[5]\n        data['beta_data'] = []\n        for i in range(NB):\n            params, S = get_tab1_record(file_obj)\n            T, beta, LT, *_ = params\n            temp_data = [{'T': T, 'beta': beta, 'LT': LT, 'S': S}]\n            for _ in range(LT):\n                params, S = get_list_record(file_obj)\n                T, beta, LI, *_ = params\n                temp_data.append({'T': T, 'beta': beta, 'LT': LT, 'S': S})\n            data['beta_data'].append(temp_data)\n\n    # Get effective temperature for each atom\n    _, Teff = get_tab1_record(file_obj)\n    data['Teff'] = [Teff]\n    for i in range(NS):\n        if data['B'][6*(i + 1)] == 0.0:\n            _, Teff = get_tab1_record(file_obj)\n            data['Teff'].append(Teff)\n\n    return data", "\n\ndef parse_mf7_mt451(file_obj: TextIO) -> dict:\n    \"\"\"Parse thermal scattering generalized information file from MF=7, MT=451\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Thermal scattering data\n\n    \"\"\"\n    # Read basic data from first record\n    ZA, AWR, NA, *_ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NA': NA}\n\n    # Read all other parameters from list record\n    data['elements'] = []\n    for _ in range(NA):\n        params, values = get_list_record(file_obj)\n        element = {\n            'NAS': params[2],\n            'NI': params[5],\n            'ZAI': values[::6],\n            'LISI': values[1::6],\n            'AFI': values[2::6],\n            'AWRI': values[3::6],\n            'SFI': values[4::6],\n        }\n        data['elements'].append(element)\n\n    return data", ""]}
{"filename": "src/endf/product.py", "chunked_list": ["import numpy as np\nfrom numpy.polynomial import Polynomial\n\nfrom .function import Tabulated1D\n\n\nclass Product:\n    \"\"\"Secondary particle emitted in a nuclear reaction\n\n    Parameters\n    ----------\n    name\n        The particle type of the reaction product. Defaults to 'neutron'.\n    yield_\n        Yield of secondary particle in the reaction.\n    distribution\n        Distributions of energy and angle of product.\n    applicability\n        Probability of sampling a given distribution for this product.\n\n    Attributes\n    ----------\n    applicability : Iterable of openmc.data.Tabulated1D\n        Probability of sampling a given distribution for this product.\n    decay_rate : float\n        Decay rate in inverse seconds\n    distribution : Iterable of AngleEnergy\n        Distributions of energy and angle of product.\n    emission_mode : {'prompt', 'delayed', 'total'}\n        Indicate whether the particle is emitted immediately or whether it\n        results from the decay of reaction product (e.g., neutron emitted from a\n        delayed neutron precursor). A special value of 'total' is used when the\n        yield represents particles from prompt and delayed sources.\n    name : str\n        The particle type of the reaction product\n    yield_\n        Yield of secondary particle in the reaction.\n\n    \"\"\"\n\n    def __init__(self, name: str = 'neutron', yield_=None,\n                 distribution=None, applicability=None):\n        self.name = name\n        if yield_ is None:\n            self.yield_ = Polynomial((1,))  # 0-order polynomial, i.e., a constant\n        else:\n            self.yield_ = yield_\n        self.decay_rate = 0.0\n        if distribution is None:\n            self.distribution = []\n        else:\n            self.distribution = distribution\n        if applicability is None:\n            self.applicability = []\n        else:\n            self.applicability = applicability\n        self.emission_mode = 'prompt'\n\n    def __repr__(self):\n        if isinstance(self.yield_, Tabulated1D):\n            if np.all(self.yield_.y == self.yield_.y[0]):\n                return \"<Product: {}, emission={}, yield={}>\".format(\n                    self.name, self.emission_mode, self.yield_.y[0])\n            else:\n                return \"<Product: {}, emission={}, yield=tabulated>\".format(\n                    self.name, self.emission_mode)\n        else:\n            return \"<Product: {}, emission={}, yield=polynomial>\".format(\n                self.name, self.emission_mode)", ""]}
{"filename": "src/endf/data.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nimport re\nfrom typing import Tuple\n\n# Dictionary to give element symbols from IUPAC names\n# (and some common mispellings)\nELEMENT_SYMBOL = {\n    'neutron': 'n', 'hydrogen': 'H', 'helium': 'He',", "ELEMENT_SYMBOL = {\n    'neutron': 'n', 'hydrogen': 'H', 'helium': 'He',\n    'lithium': 'Li', 'beryllium': 'Be', 'boron': 'B',\n    'carbon': 'C', 'nitrogen': 'N', 'oxygen': 'O', 'fluorine': 'F',\n    'neon': 'Ne', 'sodium': 'Na', 'magnesium': 'Mg',\n    'aluminium': 'Al', 'aluminum': 'Al', 'silicon': 'Si',\n    'phosphorus': 'P', 'sulfur': 'S', 'sulphur': 'S',\n    'chlorine': 'Cl', 'argon': 'Ar', 'potassium': 'K',\n    'calcium': 'Ca', 'scandium': 'Sc', 'titanium': 'Ti',\n    'vanadium': 'V', 'chromium': 'Cr', 'manganese': 'Mn',", "    'calcium': 'Ca', 'scandium': 'Sc', 'titanium': 'Ti',\n    'vanadium': 'V', 'chromium': 'Cr', 'manganese': 'Mn',\n    'iron': 'Fe', 'cobalt': 'Co', 'nickel': 'Ni', 'copper': 'Cu',\n    'zinc': 'Zn', 'gallium': 'Ga', 'germanium': 'Ge',\n    'arsenic': 'As', 'selenium': 'Se', 'bromine': 'Br',\n    'krypton': 'Kr', 'rubidium': 'Rb', 'strontium': 'Sr',\n    'yttrium': 'Y', 'zirconium': 'Zr', 'niobium': 'Nb',\n    'molybdenum': 'Mo', 'technetium': 'Tc', 'ruthenium': 'Ru',\n    'rhodium': 'Rh', 'palladium': 'Pd', 'silver': 'Ag',\n    'cadmium': 'Cd', 'indium': 'In', 'tin': 'Sn', 'antimony': 'Sb',", "    'rhodium': 'Rh', 'palladium': 'Pd', 'silver': 'Ag',\n    'cadmium': 'Cd', 'indium': 'In', 'tin': 'Sn', 'antimony': 'Sb',\n    'tellurium': 'Te', 'iodine': 'I', 'xenon': 'Xe',\n    'caesium': 'Cs', 'cesium': 'Cs', 'barium': 'Ba',\n    'lanthanum': 'La', 'cerium': 'Ce', 'praseodymium': 'Pr',\n    'neodymium': 'Nd', 'promethium': 'Pm', 'samarium': 'Sm',\n    'europium': 'Eu', 'gadolinium': 'Gd', 'terbium': 'Tb',\n    'dysprosium': 'Dy', 'holmium': 'Ho', 'erbium': 'Er',\n    'thulium': 'Tm', 'ytterbium': 'Yb', 'lutetium': 'Lu',\n    'hafnium': 'Hf', 'tantalum': 'Ta', 'tungsten': 'W',", "    'thulium': 'Tm', 'ytterbium': 'Yb', 'lutetium': 'Lu',\n    'hafnium': 'Hf', 'tantalum': 'Ta', 'tungsten': 'W',\n    'wolfram': 'W', 'rhenium': 'Re', 'osmium': 'Os',\n    'iridium': 'Ir', 'platinum': 'Pt', 'gold': 'Au',\n    'mercury': 'Hg', 'thallium': 'Tl', 'lead': 'Pb',\n    'bismuth': 'Bi', 'polonium': 'Po', 'astatine': 'At',\n    'radon': 'Rn', 'francium': 'Fr', 'radium': 'Ra',\n    'actinium': 'Ac', 'thorium': 'Th', 'protactinium': 'Pa',\n    'uranium': 'U', 'neptunium': 'Np', 'plutonium': 'Pu',\n    'americium': 'Am', 'curium': 'Cm', 'berkelium': 'Bk',", "    'uranium': 'U', 'neptunium': 'Np', 'plutonium': 'Pu',\n    'americium': 'Am', 'curium': 'Cm', 'berkelium': 'Bk',\n    'californium': 'Cf', 'einsteinium': 'Es', 'fermium': 'Fm',\n    'mendelevium': 'Md', 'nobelium': 'No', 'lawrencium': 'Lr',\n    'rutherfordium': 'Rf', 'dubnium': 'Db', 'seaborgium': 'Sg',\n    'bohrium': 'Bh', 'hassium': 'Hs', 'meitnerium': 'Mt',\n    'darmstadtium': 'Ds', 'roentgenium': 'Rg', 'copernicium': 'Cn',\n    'nihonium': 'Nh', 'flerovium': 'Fl', 'moscovium': 'Mc',\n    'livermorium': 'Lv', 'tennessine': 'Ts', 'oganesson': 'Og'\n}", "    'livermorium': 'Lv', 'tennessine': 'Ts', 'oganesson': 'Og'\n}\n\nATOMIC_SYMBOL = {\n    0: 'n', 1: 'H', 2: 'He', 3: 'Li', 4: 'Be', 5: 'B', 6: 'C',\n    7: 'N', 8: 'O', 9: 'F', 10: 'Ne', 11: 'Na', 12: 'Mg', 13: 'Al',\n    14: 'Si', 15: 'P', 16: 'S', 17: 'Cl', 18: 'Ar', 19: 'K',\n    20: 'Ca', 21: 'Sc', 22: 'Ti', 23: 'V', 24: 'Cr', 25: 'Mn',\n    26: 'Fe', 27: 'Co', 28: 'Ni', 29: 'Cu', 30: 'Zn', 31: 'Ga',\n    32: 'Ge', 33: 'As', 34: 'Se', 35: 'Br', 36: 'Kr', 37: 'Rb',", "    26: 'Fe', 27: 'Co', 28: 'Ni', 29: 'Cu', 30: 'Zn', 31: 'Ga',\n    32: 'Ge', 33: 'As', 34: 'Se', 35: 'Br', 36: 'Kr', 37: 'Rb',\n    38: 'Sr', 39: 'Y', 40: 'Zr', 41: 'Nb', 42: 'Mo', 43: 'Tc',\n    44: 'Ru', 45: 'Rh', 46: 'Pd', 47: 'Ag', 48: 'Cd', 49: 'In',\n    50: 'Sn', 51: 'Sb', 52: 'Te', 53: 'I', 54: 'Xe', 55: 'Cs',\n    56: 'Ba', 57: 'La', 58: 'Ce', 59: 'Pr', 60: 'Nd', 61: 'Pm',\n    62: 'Sm', 63: 'Eu', 64: 'Gd', 65: 'Tb', 66: 'Dy', 67: 'Ho',\n    68: 'Er', 69: 'Tm', 70: 'Yb', 71: 'Lu', 72: 'Hf', 73: 'Ta',\n    74: 'W', 75: 'Re', 76: 'Os', 77: 'Ir', 78: 'Pt', 79: 'Au',\n    80: 'Hg', 81: 'Tl', 82: 'Pb', 83: 'Bi', 84: 'Po', 85: 'At',", "    74: 'W', 75: 'Re', 76: 'Os', 77: 'Ir', 78: 'Pt', 79: 'Au',\n    80: 'Hg', 81: 'Tl', 82: 'Pb', 83: 'Bi', 84: 'Po', 85: 'At',\n    86: 'Rn', 87: 'Fr', 88: 'Ra', 89: 'Ac', 90: 'Th', 91: 'Pa',\n    92: 'U', 93: 'Np', 94: 'Pu', 95: 'Am', 96: 'Cm', 97: 'Bk',\n    98: 'Cf', 99: 'Es', 100: 'Fm', 101: 'Md', 102: 'No',\n    103: 'Lr', 104: 'Rf', 105: 'Db', 106: 'Sg', 107: 'Bh',\n    108: 'Hs', 109: 'Mt', 110: 'Ds', 111: 'Rg', 112: 'Cn',\n    113: 'Nh', 114: 'Fl', 115: 'Mc', 116: 'Lv', 117: 'Ts',\n    118: 'Og'\n}", "    118: 'Og'\n}\nATOMIC_NUMBER = {value: key for key, value in ATOMIC_SYMBOL.items()}\n\n# Boltzmann constant in [eV/K]\nK_BOLTZMANN = 8.617333262e-5\n\nEV_PER_MEV = 1.0e6\n\n# Regex for GNDS nuclide names (used in zam function)", "\n# Regex for GNDS nuclide names (used in zam function)\n_GNDS_NAME_RE = re.compile(r'([A-Zn][a-z]*)(\\d+)((?:_[em]\\d+)?)')\n\n\ndef gnds_name(Z: int, A: int, m: int = 0) -> str:\n    \"\"\"Return nuclide name using GNDS convention\n\n    Parameters\n    ----------\n    Z\n        Atomic number\n    A\n        Mass number\n    m\n        Metastable state\n\n    Returns\n    -------\n    Nuclide name in GNDS convention, e.g., 'Am242_m1'\n\n    \"\"\"\n    if m > 0:\n        return f'{ATOMIC_SYMBOL[Z]}{A}_m{m}'\n    return f'{ATOMIC_SYMBOL[Z]}{A}'", "\n\ndef zam(name: str) -> Tuple[int, int, int]:\n    \"\"\"Return tuple of (atomic number, mass number, metastable state)\n\n    Parameters\n    ----------\n    name\n        Name of nuclide using GNDS convention, e.g., 'Am242_m1'\n\n    Returns\n    -------\n    Atomic number, mass number, and metastable state\n\n    \"\"\"\n    try:\n        symbol, A, state = _GNDS_NAME_RE.match(name).groups()\n    except AttributeError:\n        raise ValueError(f\"'{name}' does not appear to be a nuclide name in \"\n                         \"GNDS format\")\n\n    if symbol not in ATOMIC_NUMBER:\n        raise ValueError(f\"'{symbol}' is not a recognized element symbol\")\n\n    metastable = int(state[2:]) if state else 0\n    return (ATOMIC_NUMBER[symbol], int(A), metastable)", "\n\ndef temperature_str(T: float) -> str:\n    \"\"\"Return temperature as a string\n\n    Parameters\n    ----------\n    T\n        Temperature in [K]\n\n    Returns\n    -------\n    String representation of temperature, e.g., '294K'\n\n    \"\"\"\n    return \"{}K\".format(int(round(T)))", ""]}
{"filename": "src/endf/mf26.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\nfrom warnings import warn\n\nfrom .mf6 import ContinuumEnergyAngle, DiscreteTwoBodyScattering\nfrom .records import get_head_record, get_tab1_record\n\n\ndef parse_mf26(file_obj: TextIO) -> dict:\n    \"\"\"Parse secondary distributions for atomic data from MF=26\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Secondary distribution data\n\n    \"\"\"\n    ZA, AWR, _, _, NK, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NK': NK}\n\n    data['products'] = products = []\n    for i in range(NK):\n        # Get yield for this product\n        (ZAP, AWI, _, LAW), y = get_tab1_record(file_obj)\n        ZAP = int(ZAP)\n\n        p = {'ZAP': ZAP, 'AWI': AWI, 'LAW': LAW, 'y': y}\n\n        if LAW == 1:\n            # Continuum energy-angle distribution\n            p['distribution'] = ContinuumEnergyAngle.dict_from_endf(file_obj)\n\n        elif LAW == 2:\n            # Discrete two-body scattering\n            p['distribution'] = DiscreteTwoBodyScattering.dict_from_endf(file_obj)\n\n        elif LAW == 8:\n            # Energy transfer for excitation\n            _, ET = get_tab1_record(file_obj)\n            p['distribution'] = {'ET': ET}\n\n        else:\n            warn(f'Unrecognized {LAW=} in MF=26')\n\n        products.append(p)\n\n    return data", "\n\ndef parse_mf26(file_obj: TextIO) -> dict:\n    \"\"\"Parse secondary distributions for atomic data from MF=26\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Secondary distribution data\n\n    \"\"\"\n    ZA, AWR, _, _, NK, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'NK': NK}\n\n    data['products'] = products = []\n    for i in range(NK):\n        # Get yield for this product\n        (ZAP, AWI, _, LAW), y = get_tab1_record(file_obj)\n        ZAP = int(ZAP)\n\n        p = {'ZAP': ZAP, 'AWI': AWI, 'LAW': LAW, 'y': y}\n\n        if LAW == 1:\n            # Continuum energy-angle distribution\n            p['distribution'] = ContinuumEnergyAngle.dict_from_endf(file_obj)\n\n        elif LAW == 2:\n            # Discrete two-body scattering\n            p['distribution'] = DiscreteTwoBodyScattering.dict_from_endf(file_obj)\n\n        elif LAW == 8:\n            # Energy transfer for excitation\n            _, ET = get_tab1_record(file_obj)\n            p['distribution'] = {'ET': ET}\n\n        else:\n            warn(f'Unrecognized {LAW=} in MF=26')\n\n        products.append(p)\n\n    return data", ""]}
{"filename": "src/endf/ace.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 OpenMC contributors and Paul Romano\n# SPDX-License-Identifier: MIT\n\n\"\"\"This module is for reading ACE-format cross sections. ACE stands for \"A\nCompact ENDF\" format and originated from work on MCNP_. It is used in a number\nof other Monte Carlo particle transport codes.\n\nACE-format cross sections are typically generated from ENDF_ files through a\ncross section processing program like NJOY_. The ENDF data consists of tabulated\nthermal data, ENDF/B resonance parameters, distribution parameters in the", "cross section processing program like NJOY_. The ENDF data consists of tabulated\nthermal data, ENDF/B resonance parameters, distribution parameters in the\nunresolved resonance region, and tabulated data in the fast region. After the\nENDF data has been reconstructed and Doppler-broadened, the ACER module\ngenerates ACE-format cross sections.\n\n.. _MCNP: https://laws.lanl.gov/vhosts/mcnp.lanl.gov/\n.. _NJOY: http://t2.lanl.gov/codes.shtml\n.. _ENDF: http://www.nndc.bnl.gov/endf\n", ".. _ENDF: http://www.nndc.bnl.gov/endf\n\n\"\"\"\n\nfrom __future__ import annotations\nfrom collections import OrderedDict\nimport enum\nfrom pathlib import Path\nimport struct\nfrom typing import Tuple, List, Union, Optional, Iterable, TextIO, Any", "import struct\nfrom typing import Tuple, List, Union, Optional, Iterable, TextIO, Any\n\nimport numpy as np\n\nfrom .data import ATOMIC_SYMBOL, gnds_name, EV_PER_MEV, K_BOLTZMANN\nfrom .fileutils import PathLike\nfrom .records import ENDF_FLOAT_RE\nimport endf\n", "import endf\n\n\ndef get_metadata(zaid: int, metastable_scheme: str = 'nndc') -> Tuple[str, str, int, int, int]:\n    \"\"\"Return basic identifying data for a nuclide with a given ZAID.\n\n    Parameters\n    ----------\n    zaid\n        ZAID (1000*Z + A) obtained from a library\n    metastable_scheme : {'nndc', 'mcnp'}\n        Determine how ZAID identifiers are to be interpreted in the case of\n        a metastable nuclide. Because the normal ZAID (=1000*Z + A) does not\n        encode metastable information, different conventions are used among\n        different libraries. In MCNP libraries, the convention is to add 400\n        for a metastable nuclide except for Am242m, for which 95242 is\n        metastable and 95642 (or 1095242 in newer libraries) is the ground\n        state. For NNDC libraries, ZAID is given as 1000*Z + A + 100*m.\n\n    Returns\n    -------\n    name : str\n        Name of the table\n    element : str\n        The atomic symbol of the isotope in the table; e.g., Zr.\n    Z : int\n        Number of protons in the nucleus\n    mass_number : int\n        Number of nucleons in the nucleus\n    metastable : int\n        Metastable state of the nucleus. A value of zero indicates ground state.\n\n    \"\"\"\n\n    Z = zaid // 1000\n    mass_number = zaid % 1000\n\n    if metastable_scheme == 'mcnp':\n        if zaid > 1000000:\n            # New SZA format\n            Z = Z % 1000\n            if zaid == 1095242:\n                metastable = 0\n            else:\n                metastable = zaid // 1000000\n        else:\n            if zaid == 95242:\n                metastable = 1\n            elif zaid == 95642:\n                metastable = 0\n            else:\n                metastable = 1 if mass_number > 300 else 0\n    elif metastable_scheme == 'nndc':\n        metastable = 1 if mass_number > 300 else 0\n\n    while mass_number > 3 * Z:\n        mass_number -= 100\n\n    # Determine name\n    element = ATOMIC_SYMBOL[Z]\n    name = gnds_name(Z, mass_number, metastable)\n\n    return (name, element, Z, mass_number, metastable)", "\n\ndef ascii_to_binary(ascii_file: PathLike, binary_file: PathLike):\n    \"\"\"Convert an ACE file in ASCII format (type 1) to binary format (type 2).\n\n    Parameters\n    ----------\n    ascii_file\n        Filename of ASCII ACE file\n    binary_file\n        Filename of binary ACE file to be written\n\n    \"\"\"\n\n    # Read data from ASCII file\n    with open(str(ascii_file), 'r') as ascii_file:\n        lines = ascii_file.readlines()\n\n    # Set default record length\n    record_length = 4096\n\n    # Open binary file\n    with open(str(binary_file), 'wb') as binary_file:\n        idx = 0\n        while idx < len(lines):\n            # check if it's a > 2.0.0 version header\n            if lines[idx].split()[0][1] == '.':\n                if lines[idx + 1].split()[3] == '3':\n                    idx = idx + 3\n                else:\n                    raise NotImplementedError('Only backwards compatible ACE'\n                                              'headers currently supported')\n            # Read/write header block\n            hz = lines[idx][:10].encode()\n            aw0 = float(lines[idx][10:22])\n            tz = float(lines[idx][22:34])\n            hd = lines[idx][35:45].encode()\n            hk = lines[idx + 1][:70].encode()\n            hm = lines[idx + 1][70:80].encode()\n            binary_file.write(struct.pack(str('=10sdd10s70s10s'),\n                              hz, aw0, tz, hd, hk, hm))\n\n            # Read/write IZ/AW pairs\n            data = ' '.join(lines[idx + 2:idx + 6]).split()\n            iz = np.array(data[::2], dtype=int)\n            aw = np.array(data[1::2], dtype=float)\n            izaw = [item for sublist in zip(iz, aw) for item in sublist]\n            binary_file.write(struct.pack(str('=' + 16*'id'), *izaw))\n\n            # Read/write NXS and JXS arrays. Null bytes are added at the end so\n            # that XSS will start at the second record\n            nxs = [int(x) for x in ' '.join(lines[idx + 6:idx + 8]).split()]\n            jxs = [int(x) for x in ' '.join(lines[idx + 8:idx + 12]).split()]\n            binary_file.write(struct.pack(str('=16i32i{}x'.format(record_length - 500)),\n                                          *(nxs + jxs)))\n\n            # Read/write XSS array. Null bytes are added to form a complete record\n            # at the end of the file\n            n_lines = (nxs[0] + 3)//4\n            start = idx + _ACE_HEADER_SIZE\n            xss = np.fromstring(' '.join(lines[start:start + n_lines]), sep=' ')\n            extra_bytes = record_length - ((len(xss)*8 - 1) % record_length + 1)\n            binary_file.write(struct.pack(str('={}d{}x'.format(\n                nxs[0], extra_bytes)), *xss))\n\n            # Advance to next table in file\n            idx += _ACE_HEADER_SIZE + n_lines", "\n\ndef get_table(filename: PathLike, name: str = None):\n    \"\"\"Read a single table from an ACE file\n\n    Parameters\n    ----------\n    filename : str\n        Path of the ACE library to load table from\n    name : str, optional\n        Name of table to load, e.g. '92235.71c'\n\n    Returns\n    -------\n    endf.ace.Table\n        ACE table with specified name. If no name is specified, the first table\n        in the file is returned.\n\n    \"\"\"\n    tables = get_tables(filename, name)\n    if name is not None and not tables:\n        raise ValueError(f'Could not find ACE table with name: {name}')\n    return tables[0]", "\n\n# The beginning of an ASCII ACE file consists of 12 lines that include the name,\n# atomic weight ratio, iz/aw pairs, and the NXS and JXS arrays\n_ACE_HEADER_SIZE = 12\n\n\ndef get_tables(\n    filename: PathLike,\n    table_names: Optional[Union[str, Iterable[str]]] = None,\n    verbose: bool = False\n):\n    \"\"\"Get all tables from an ACE-formatted file.\n\n    Parameters\n    ----------\n    filename : str\n        Path of the ACE library file to load.\n    table_names : None, str, or iterable, optional\n        Tables from the file to read in.  If None, reads in all of the\n        tables. If str, reads in only the single table of a matching name.\n    verbose : bool, optional\n        Determines whether output is printed to the stdout when reading a\n        Library\n\n    Attributes\n    ----------\n    tables : list\n        List of :class:`Table` instances\n\n    \"\"\"\n    if isinstance(table_names, str):\n        table_names = [table_names]\n    if table_names is not None:\n        table_names = set(table_names)\n\n    tables = []\n\n    # Determine whether file is ASCII or binary\n    filename = str(filename)\n    try:\n        fh = open(filename, 'rb')\n        # Grab 10 lines of the library\n        sb = b''.join([fh.readline() for i in range(10)])\n\n        # Try to decode it with ascii\n        sb.decode('ascii')\n\n        # No exception so proceed with ASCII - reopen in non-binary\n        fh.close()\n        with open(filename, 'r') as fh:\n            return _read_ascii(fh, table_names, verbose)\n    except UnicodeDecodeError:\n        fh.close()\n        with open(filename, 'rb') as fh:\n            return _read_binary(fh, table_names, verbose)", "\n\ndef _read_binary(ace_file, table_names, verbose=False, recl_length=4096, entries=512):\n    \"\"\"Read a binary (Type 2) ACE table.\n\n    Parameters\n    ----------\n    ace_file : file\n        Open ACE file\n    table_names : None, str, or iterable\n        Tables from the file to read in.  If None, reads in all of the\n        tables. If str, reads in only the single table of a matching name.\n    verbose : str, optional\n        Whether to display what tables are being read. Defaults to False.\n    recl_length : int, optional\n        Fortran record length in binary file. Default value is 4096 bytes.\n    entries : int, optional\n        Number of entries per record. The default is 512 corresponding to a\n        record length of 4096 bytes with double precision data.\n\n    \"\"\"\n    tables = []\n    while True:\n        start_position = ace_file.tell()\n\n        # Check for end-of-file\n        if len(ace_file.read(1)) == 0:\n            return tables\n        ace_file.seek(start_position)\n\n        # Read name, atomic mass ratio, temperature, date, comment, and\n        # material\n        name, atomic_weight_ratio, kT, *_ = \\\n            struct.unpack('=10sdd10s70s10s', ace_file.read(116))\n        name = name.decode().strip()\n\n        # Read ZAID/awr combinations\n        data = struct.unpack('=' + 16*'id', ace_file.read(192))\n        pairs = list(zip(data[::2], data[1::2]))\n\n        # Read NXS\n        nxs = list(struct.unpack('=16i', ace_file.read(64)))\n\n        # Determine length of XSS and number of records\n        length = nxs[0]\n        n_records = (length + entries - 1)//entries\n\n        # verify that we are supposed to read this table in\n        if (table_names is not None) and (name not in table_names):\n            ace_file.seek(start_position + recl_length*(n_records + 1))\n            continue\n\n        if verbose:\n            kelvin = round(kT * EV_PER_MEV / K_BOLTZMANN)\n            print(f\"Loading nuclide {name} at {kelvin} K\")\n\n        # Read JXS\n        jxs = list(struct.unpack('=32i', ace_file.read(128)))\n\n        # Read XSS\n        ace_file.seek(start_position + recl_length)\n        xss = list(struct.unpack(f'={length}d', ace_file.read(length*8)))\n\n        # Insert zeros at beginning of NXS, JXS, and XSS arrays so that the\n        # indexing will be the same as Fortran. This makes it easier to\n        # follow the ACE format specification.\n        nxs.insert(0, 0)\n        nxs = np.array(nxs, dtype=int)\n\n        jxs.insert(0, 0)\n        jxs = np.array(jxs, dtype=int)\n\n        xss.insert(0, 0.0)\n        xss = np.array(xss)\n\n        # Create ACE table with data read in\n        table = Table(name, atomic_weight_ratio, kT, pairs, nxs, jxs, xss)\n        tables.append(table)\n\n        # Advance to next record\n        ace_file.seek(start_position + recl_length*(n_records + 1))", "\n\ndef _read_ascii(\n    ace_file: TextIO,\n    table_names: Optional[Union[str, Iterable[str]]] = None,\n    verbose: bool = False\n):\n    \"\"\"Read an ASCII (Type 1) ACE table.\n\n    Parameters\n    ----------\n    ace_file : file\n        Open ACE file\n    table_names : None, str, or iterable\n        Tables from the file to read in.  If None, reads in all of the\n        tables. If str, reads in only the single table of a matching name.\n    verbose : str, optional\n        Whether to display what tables are being read. Defaults to False.\n\n    \"\"\"\n    tables = []\n    tables_seen = set()\n\n    lines = [ace_file.readline() for i in range(_ACE_HEADER_SIZE + 1)]\n\n    while len(lines) != 0 and lines[0].strip() != '':\n        # Read name of table, atomic mass ratio, and temperature. If first\n        # line is empty, we are at end of file\n\n        # check if it's a 2.0 style header\n        if lines[0].split()[0][1] == '.':\n            words = lines[0].split()\n            name = words[1]\n            words = lines[1].split()\n            atomic_weight_ratio = float(words[0])\n            kT = float(words[1])\n            commentlines = int(words[3])\n            for _ in range(commentlines):\n                lines.pop(0)\n                lines.append(ace_file.readline())\n        else:\n            words = lines[0].split()\n            name = words[0]\n            atomic_weight_ratio = float(words[1])\n            kT = float(words[2])\n\n        datastr = ' '.join(lines[2:6]).split()\n        pairs = list(zip(map(int, datastr[::2]),\n                            map(float, datastr[1::2])))\n\n        datastr = '0 ' + ' '.join(lines[6:8])\n        nxs = np.fromstring(datastr, sep=' ', dtype=int)\n\n        # Detemrine number of lines in the XSS array; each line consists of\n        # four values\n        n_lines = (nxs[1] + 3)//4\n\n        # Ensure that we have more tables to read in\n        if (table_names is not None) and (table_names <= tables_seen):\n            break\n        tables_seen.add(name)\n\n        # verify that we are supposed to read this table in\n        if (table_names is not None) and (name not in table_names):\n            for _ in range(n_lines - 1):\n                ace_file.readline()\n            lines = [ace_file.readline() for i in range(_ACE_HEADER_SIZE + 1)]\n            continue\n\n        # Read lines corresponding to this table\n        lines += [ace_file.readline() for i in range(n_lines - 1)]\n\n        if verbose:\n            kelvin = round(kT * EV_PER_MEV / K_BOLTZMANN)\n            print(f\"Loading nuclide {name} at {kelvin} K\")\n\n        # Insert zeros at beginning of NXS, JXS, and XSS arrays so that the\n        # indexing will be the same as Fortran. This makes it easier to\n        # follow the ACE format specification.\n        datastr = '0 ' + ' '.join(lines[8:_ACE_HEADER_SIZE])\n        jxs = np.fromstring(datastr, dtype=int, sep=' ')\n\n        datastr = '0.0 ' + ''.join(lines[_ACE_HEADER_SIZE:_ACE_HEADER_SIZE + n_lines])\n        xss = np.fromstring(datastr, sep=' ')\n\n        # When NJOY writes an ACE file, any values less than 1e-100 actually\n        # get written without the 'e'. Thus, what we do here is check\n        # whether the xss array is of the right size (if a number like\n        # 1.0-120 is encountered, np.fromstring won't capture any numbers\n        # after it). If it's too short, then we apply the ENDF float regular\n        # expression. We don't do this by default because it's expensive!\n        if xss.size != nxs[1] + 1:\n            datastr = ENDF_FLOAT_RE.sub(r'\\1e\\2\\3', datastr)\n            xss = np.fromstring(datastr, sep=' ')\n            assert xss.size == nxs[1] + 1\n\n        table = Table(name, atomic_weight_ratio, kT, pairs, nxs, jxs, xss)\n        tables.append(table)\n\n        # Read all data blocks\n        lines = [ace_file.readline() for i in range(_ACE_HEADER_SIZE + 1)]\n\n    return tables", "\n\nclass TableType(enum.Enum):\n    \"\"\"Type of ACE data table.\"\"\"\n    NEUTRON_CONTINUOUS = 'c'\n    NEUTRON_DISCRETE = 'd'\n    THERMAL_SCATTERING = 't'\n    DOSIMETRY = 'y'\n    PHOTOATOMIC = 'p'\n    PHOTONUCLEAR = 'u'\n    PROTON = 'h'\n    DEUTERON = 'o'\n    TRITON = 'r'\n    HELIUM3 = 's'\n    ALPHA = 'a'\n\n    @classmethod\n    def from_suffix(cls, suffix: str) -> TableType:\n        \"\"\"Determine ACE table type from a suffix.\n\n        Parameters\n        ----------\n        suffix : str\n            Single letter ACE table designator, e.g., 'c'\n\n        Returns\n        -------\n        TableType\n            ACE table type\n\n        \"\"\"\n        for member in cls:\n            if suffix.endswith(member.value):\n                return member\n        raise ValueError(f\"Suffix '{suffix}' has no corresponding ACE table type.\")", "\n\nclass Table:\n    \"\"\"ACE cross section table\n\n    Parameters\n    ----------\n    name : str\n        Full ACE table identifier, e.g., '92235.70c'.\n    atomic_weight_ratio : float\n        Atomic mass ratio of the target nuclide.\n    kT : float\n        Temperature of the target nuclide in [MeV]\n    pairs : list of tuple\n        16 pairs of ZAIDs and atomic weight ratios. Used for thermal scattering\n        tables to indicate what isotopes scattering is applied to.\n    nxs : numpy.ndarray\n        Array that defines various lengths with in the table\n    jxs : numpy.ndarray\n        Array that gives locations in the ``xss`` array for various blocks of\n        data\n    xss : numpy.ndarray\n        Raw data for the ACE table\n\n    Attributes\n    ----------\n    data_type : TableType\n        Type of the ACE data\n    temperature : float\n        Temperature of the target nuclide in [K]\n    zaid : int\n        ZAID identifier of the table, e.g., 92235\n    nxs : numpy.ndarray\n        Array that defines various lengths with in the table\n    jxs : numpy.ndarray\n        Array that gives locations in the ``xss`` array for various blocks of\n        data\n    xss : numpy.ndarray\n        Raw data for the ACE table\n\n    \"\"\"\n    def __init__(self, name: str, atomic_weight_ratio: float, kT: float,\n                 pairs: List[Tuple[int, float]],\n                 nxs: np.ndarray, jxs: np.ndarray, xss: np.ndarray):\n        self.name = name\n        self.atomic_weight_ratio = atomic_weight_ratio\n        self.kT = kT\n        self.pairs = pairs\n        self.nxs = nxs\n        self.jxs = jxs\n        self.xss = xss\n\n    @property\n    def zaid(self) -> int:\n        return int(self.name.split('.')[0])\n\n    @property\n    def data_type(self) -> TableType:\n        xs = self.name.split('.')[1]\n        return TableType.from_suffix(xs[-1])\n\n    @property\n    def temperature(self) -> float:\n        return self.kT * EV_PER_MEV / K_BOLTZMANN\n\n    def __repr__(self) -> str:\n        return f\"<ACE Table: {self.name} at {self.temperature:.1f} K>\"\n\n    def interpret(self, **kwargs) -> Any:\n        \"\"\"Get high-level interface class for the ACE table\n\n        Parameters\n        ----------\n        **kwargs\n            Keyword-arguments passed to the high-level interface class\n\n        Returns\n        -------\n        Instance of a high-level interface class, e.g.,\n        :class:`endf.IncidentNeutron`.\n\n        \"\"\"\n        if self.data_type == TableType.NEUTRON_CONTINUOUS:\n            return endf.IncidentNeutron.from_ace(self, **kwargs)\n        else:\n            raise NotImplementedError(f\"No class implemented for {self.data_type}\")", "\n\ndef get_libraries_from_xsdir(path: PathLike) -> List[Path]:\n    \"\"\"Determine paths to ACE files from an MCNP xsdir file.\n\n    Parameters\n    ----------\n    path\n        Path to xsdir file\n\n    Returns\n    -------\n    List of paths to ACE libraries\n    \"\"\"\n    xsdir = Path(path)\n\n    # Find 'directory' section\n    with open(path, 'r') as fh:\n        lines = fh.readlines()\n    for index, line in enumerate(lines):\n        if line.strip().lower() == 'directory':\n            break\n    else:\n        raise RuntimeError(\"Could not find 'directory' section in MCNP xsdir file\")\n\n    # Handle continuation lines indicated by '+' at end of line\n    lines = lines[index + 1:]\n    continue_lines = [i for i, line in enumerate(lines)\n                      if line.strip().endswith('+')]\n    for i in reversed(continue_lines):\n        lines[i] = lines[i].strip()[:-1] + lines.pop(i + 1)\n\n    # Create list of ACE libraries\n    libraries = {}\n    for line in lines:\n        words = line.split()\n        if len(words) < 3:\n            continue\n\n        lib = (xsdir.parent / words[2]).resolve()\n        if lib not in libraries:\n            # Value in dictionary is not used, so we just assign None. Below a\n            # list is created from the keys alone\n            libraries[lib] = None\n\n    return list(libraries.keys())", "\n\ndef get_libraries_from_xsdata(path: PathLike) -> List[Path]:\n    \"\"\"Determine paths to ACE files from a Serpent xsdata file.\n\n    Parameters\n    ----------\n    path\n        Path to xsdata file\n\n    Returns\n    -------\n    List of paths to ACE libraries\n    \"\"\"\n    xsdata = Path(path)\n    with open(xsdata, 'r') as xsdata_file:\n        # As in get_libraries_from_xsdir, we use a dict for O(1) membership\n        # check while retaining insertion order\n        libraries = OrderedDict()\n        for line in xsdata_file:\n            words = line.split()\n            if len(words) >= 9:\n                lib = (xsdata.parent / words[8]).resolve()\n                if lib not in libraries:\n                    libraries[lib] = None\n    return list(libraries.keys())", ""]}
{"filename": "src/endf/mf1.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nimport numpy as np\n\nfrom .records import get_head_record, get_cont_record, get_text_record, \\\n    get_list_record, get_tab1_record, get_tab2_record\n", "    get_list_record, get_tab1_record, get_tab2_record\n\n\ndef parse_mf1_mt451(file_obj: TextIO) -> dict:\n    \"\"\"Parse descriptive data and directory from MF=1, MT=451\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Descriptive data\n\n    \"\"\"\n    # Information about target/projectile\n    ZA, AWR, LRP, LFI, NLIB, NMOD = get_head_record(file_obj)\n    data = {\n        'ZA': ZA, 'AWR': AWR, 'LRP': LRP,\n        'LFI': LFI, 'NLIB': NLIB, 'NMOD': NMOD\n    }\n\n    # Control record 1\n    ELIS, STA, LIS, LISO, _, NFOR = get_cont_record(file_obj)\n    data['ELIS'] = ELIS\n    data['STA'] = STA\n    data['LIS'] = LIS\n    data['LISO'] = LISO\n    data['NFOR'] = NFOR\n\n    # Control record 2\n    AWI, EMAX, LREL, _, NSUB, NVER = get_cont_record(file_obj)\n    data['AWI'] = AWI\n    data['EMAX'] = EMAX\n    data['LREL'] = LREL\n    data['NSUB'] = NSUB\n    data['NVER'] = NVER\n\n    # Control record 3\n    TEMP, _, LDRV, _, NWD, NXC = get_cont_record(file_obj)\n    data['TEMP'] = TEMP\n    data['LDRV'] = LDRV\n    data['NWD'] = NWD\n    data['NXC'] = NXC\n\n    # Text records\n    text = [get_text_record(file_obj) for i in range(NWD)]\n    if len(text) >= 5:\n        data['ZSYMAM'] = text[0][0:11]\n        data['ALAB'] = text[0][11:22]\n        data['EDATE'] = text[0][22:32]\n        data['AUTH'] = text[0][32:66]\n        data['REF'] = text[1][1:22]\n        data['DDATE'] = text[1][22:32]\n        data['RDATE'] = text[1][33:43]\n        data['ENDATE'] = text[1][55:63]\n        data['HSUB'] = text[2:5]\n        data['description'] = text[5:]\n    else:\n        data['ZSYMAM'] = None\n\n    # File numbers, reaction designations, and number of records\n    data['section_list'] = []\n    for _ in range(NXC):\n        _, _, mf, mt, nc, mod = get_cont_record(file_obj, skip_c=True)\n        data['section_list'].append((mf, mt, nc, mod))\n\n    return data", "\n\ndef parse_mf1_mt452(file_obj: TextIO) -> dict:\n    \"\"\"Parse number of neutrons per fission from MF=1, MT=452/456\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Data on number of neutrons per fission\n\n    \"\"\"\n    # Determine representation from HEAD record\n    ZA, AWR, _, LNU, _, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LNU': LNU}\n\n    if LNU == 1:\n        # Polynomial representation\n        _, data['C'] = get_list_record(file_obj)\n    elif LNU == 2:\n        # Tabulated representation\n        _, data['nu'] = get_tab1_record(file_obj)\n\n    return data", "\n\ndef parse_mf1_mt455(file_obj: TextIO) -> dict:\n    \"\"\"Parse delayed neutron data from MF=1, MT=455\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Delayed neutron data\n\n    \"\"\"\n    ZA, AWR, LDG, LNU, _, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LDG': LDG, 'LNU': LNU}\n\n    if LDG == 0:\n        # Delayed-group constants energy independent\n        _, data['lambda'] = get_list_record(file_obj)\n    elif LDG == 1:\n        # Delayed-group constants energy dependent\n        params, data['E_int'] = get_tab2_record(file_obj)\n        NE = params[5]\n\n        data['constants'] = []\n        for _ in range(NE):\n            (_, E, *_), values = get_list_record(file_obj)\n            data['constants'].append({\n                'E': E, 'lambda': values[::2], 'alpha': values[1::2]\n            })\n\n    # In MF=1, MT=455, the delayed-group abundances are actually not\n    # specified if the group constants are energy-independent. In this case,\n    # the abundances must be inferred from MF=5, MT=455 where multiple\n    # energy distributions are given.\n    if LNU == 1:\n        # Nu represented as polynomial\n        _, data['C'] = get_list_record(file_obj)\n    elif LNU == 2:\n        # Nu represented by tabulation\n        _, data['nu'] = get_tab1_record(file_obj)\n\n    return data", "\n\ndef parse_mf1_mt458(file_obj: TextIO) -> dict:\n    \"\"\"Parse components of fission energy release from MF=1, MT=458\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Components of fission energy release\n\n    \"\"\"\n    # Read first record and check whether any components appear as\n    # tabulated functions\n    ZA, AWR, _, LFC, _, NFC = get_cont_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LFC': LFC}\n\n    # Parse the ENDF LIST into an array.\n    items, values = get_list_record(file_obj)\n    data['NPLY'] = items[3]\n\n    components = ('EFR', 'ENP', 'END', 'EGP', 'EGD', 'EB', 'ENU', 'ER', 'ET')\n\n    # Associate each set of values and uncertainties with its label.\n    for i, name in enumerate(components):\n        coeffs = values[2*i::18]\n        deltas = values[2*i + 1::18]\n        data[name] = list(zip(coeffs, deltas))\n\n    # Check for tabulated data\n    if LFC == 1:\n        data['NFC'] = NFC\n        for _ in range(NFC):\n            # Get tabulated function\n            (_, _, LDRV, IFC), EIFC = get_tab1_record(file_obj)\n\n            # Determine which component it is and replace in dictionary\n            name = components[IFC]\n            data[name] = {'LDRV': LDRV, 'EIFC': EIFC}\n\n    return data", "\n\ndef parse_mf1_mt460(file_obj: TextIO) -> dict:\n    \"\"\"Parse delayed photon data from MF=1, MT=460\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Delayed photon data\n\n    \"\"\"\n    ZA, AWR, LO, _, NG, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LO': LO}\n    if LO == 1:\n        data['NG'] = NG\n        # Read energy and time dependence for each photon\n        data['E'] = np.empty(NG)\n        data['T'] = []\n        for i in range(NG):\n            (E, *_), T = get_tab1_record(file_obj)\n            data['E'][i] = E\n            data['T'].append(T)\n    elif LO == 2:\n        # Read decay constants for precursors\n        _, data['lambda'] = get_list_record(file_obj)\n\n    return data", ""]}
{"filename": "src/endf/mf9.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .records import get_head_record, get_tab1_record\n\n\ndef parse_mf9_mf10(file_obj: TextIO, MF: int) -> dict:\n    \"\"\"Parse radionuclide production data from MF=9 or MF=10\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n    MF\n        File number\n\n    Returns\n    -------\n    dict\n        Radionuclide production data\n\n    \"\"\"\n    ZA, AWR, LIS, _, NS, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LIS': LIS, 'NS': NS}\n    data['levels'] = []\n    for _ in range(NS):\n        # Determine what the product is\n        (QM, QI, IZAP, LFS), func = get_tab1_record(file_obj)\n        level_data = {'QM': QM, 'QI': QI, 'IZAP': IZAP, 'LFS': LFS}\n        if MF == 9:\n            level_data['Y'] = func\n        else:\n            level_data['sigma'] = func\n        data['levels'].append(level_data)\n\n    return data", "def parse_mf9_mf10(file_obj: TextIO, MF: int) -> dict:\n    \"\"\"Parse radionuclide production data from MF=9 or MF=10\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n    MF\n        File number\n\n    Returns\n    -------\n    dict\n        Radionuclide production data\n\n    \"\"\"\n    ZA, AWR, LIS, _, NS, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LIS': LIS, 'NS': NS}\n    data['levels'] = []\n    for _ in range(NS):\n        # Determine what the product is\n        (QM, QI, IZAP, LFS), func = get_tab1_record(file_obj)\n        level_data = {'QM': QM, 'QI': QI, 'IZAP': IZAP, 'LFS': LFS}\n        if MF == 9:\n            level_data['Y'] = func\n        else:\n            level_data['sigma'] = func\n        data['levels'].append(level_data)\n\n    return data", ""]}
{"filename": "src/endf/mf33.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\n\nfrom .records import get_head_record, get_cont_record, get_list_record\n\n\ndef parse_mf33_subsection(file_obj) -> dict:\n    XMF1, XLFS1, MAT1, MT1, NC, NI = get_cont_record(file_obj)\n    subsection = {'XMF1': XMF1, 'XLFS1': XLFS1, 'MAT1': MAT1, 'MT1': MT1,\n                  'NC': NC, 'NI': NI}\n\n    subsection['nc_subsections'] = []\n    for _ in range(NC):\n        LTY = get_cont_record(file_obj)[3]\n        if LTY == 0:\n            (E1, E2, *_, NCI), values = get_list_record(file_obj)\n            subsub = {'LTY': LTY, 'E1': E1, 'E2': E2, 'NCI': NCI}\n            subsub['CI'] = values[::2]\n            subsub['XMTI'] = values[1::2]\n            subsection['nc_subsections'].append(subsub)\n        else:\n            (E1, E2, MATS, MTS, _, NEI), values = get_list_record(file_obj)\n            subsub = {'LTY': LTY, 'E1': E1, 'E2': E2, 'MATS': MATS,\n                        'MTS': MTS, 'NEI': NEI}\n            subsub['XMFS'] = values[0]\n            subsub['XLFSS'] = values[1]\n            subsub['EI'] = values[2::2]\n            subsub['WEI'] = values[3::2]\n        subsection['nc_subsections'].append(subsub)\n\n    subsection['ni_subsections'] = []\n    for _ in range(NI):\n        # Look ahead to determine LB\n        pos = file_obj.tell()\n        LB = get_cont_record(file_obj)[3]\n        file_obj.seek(pos)\n\n        if 0 <= LB <= 4:\n            (_, _, LT, LB, NT, NP), values = get_list_record(file_obj)\n            subsub = {'LT': LT, 'LB': LB, 'NT': NT, 'NP': NP}\n            k_array = values[:NT - NP]\n            subsub['Ek'] = k_array[::2]\n            subsub['Fk'] = k_array[1::2]\n            l_array = values[NT - NP:]\n            subsub['El'] = l_array[::2]\n            subsub['Fl'] = l_array[1::2]\n        elif LB == 5:\n            (_, _, LS, LB, NT, NE), values = get_list_record(file_obj)\n            subsub = {'LS': LS, 'LB': LB, 'NT': NT, 'NE': NE}\n            subsub['Ek'] = values[:NE]\n            # TODO: Reoder/reshape values for Fk,k' matrix\n            subsub['Fkk'] = values[NE:]\n        elif LB == 6:\n            (_, _, _, LB, NT, NER), values = get_list_record(file_obj)\n            NEC = (NT - 1)//NER\n            subsub = {'LB': LB, 'NT': NT, 'NER': NER, 'NEC': NEC}\n            subsub['ER'] = values[:NER]\n            subsub['EC'] = values[NER:NER + NEC]\n            # TODO: Reorder/reshape values for Fkl matrix\n            subsub['Fkl'] = values[NER + NEC:]\n        elif LB in (8, 9):\n            (_, _, LT, LB, NT, NP), values = get_list_record(file_obj)\n            subsub = {'LT': LT, 'LB': LB, 'NT': NT, 'NP': NP}\n            subsub['Ek'] = values[::2]\n            subsub['Fk'] = values[1::2]\n        else:\n            raise ValueError(f\"Unrecognized {LB=}\")\n\n        subsection['ni_subsections'].append(subsub)\n\n    return subsection", "def parse_mf33_subsection(file_obj) -> dict:\n    XMF1, XLFS1, MAT1, MT1, NC, NI = get_cont_record(file_obj)\n    subsection = {'XMF1': XMF1, 'XLFS1': XLFS1, 'MAT1': MAT1, 'MT1': MT1,\n                  'NC': NC, 'NI': NI}\n\n    subsection['nc_subsections'] = []\n    for _ in range(NC):\n        LTY = get_cont_record(file_obj)[3]\n        if LTY == 0:\n            (E1, E2, *_, NCI), values = get_list_record(file_obj)\n            subsub = {'LTY': LTY, 'E1': E1, 'E2': E2, 'NCI': NCI}\n            subsub['CI'] = values[::2]\n            subsub['XMTI'] = values[1::2]\n            subsection['nc_subsections'].append(subsub)\n        else:\n            (E1, E2, MATS, MTS, _, NEI), values = get_list_record(file_obj)\n            subsub = {'LTY': LTY, 'E1': E1, 'E2': E2, 'MATS': MATS,\n                        'MTS': MTS, 'NEI': NEI}\n            subsub['XMFS'] = values[0]\n            subsub['XLFSS'] = values[1]\n            subsub['EI'] = values[2::2]\n            subsub['WEI'] = values[3::2]\n        subsection['nc_subsections'].append(subsub)\n\n    subsection['ni_subsections'] = []\n    for _ in range(NI):\n        # Look ahead to determine LB\n        pos = file_obj.tell()\n        LB = get_cont_record(file_obj)[3]\n        file_obj.seek(pos)\n\n        if 0 <= LB <= 4:\n            (_, _, LT, LB, NT, NP), values = get_list_record(file_obj)\n            subsub = {'LT': LT, 'LB': LB, 'NT': NT, 'NP': NP}\n            k_array = values[:NT - NP]\n            subsub['Ek'] = k_array[::2]\n            subsub['Fk'] = k_array[1::2]\n            l_array = values[NT - NP:]\n            subsub['El'] = l_array[::2]\n            subsub['Fl'] = l_array[1::2]\n        elif LB == 5:\n            (_, _, LS, LB, NT, NE), values = get_list_record(file_obj)\n            subsub = {'LS': LS, 'LB': LB, 'NT': NT, 'NE': NE}\n            subsub['Ek'] = values[:NE]\n            # TODO: Reoder/reshape values for Fk,k' matrix\n            subsub['Fkk'] = values[NE:]\n        elif LB == 6:\n            (_, _, _, LB, NT, NER), values = get_list_record(file_obj)\n            NEC = (NT - 1)//NER\n            subsub = {'LB': LB, 'NT': NT, 'NER': NER, 'NEC': NEC}\n            subsub['ER'] = values[:NER]\n            subsub['EC'] = values[NER:NER + NEC]\n            # TODO: Reorder/reshape values for Fkl matrix\n            subsub['Fkl'] = values[NER + NEC:]\n        elif LB in (8, 9):\n            (_, _, LT, LB, NT, NP), values = get_list_record(file_obj)\n            subsub = {'LT': LT, 'LB': LB, 'NT': NT, 'NP': NP}\n            subsub['Ek'] = values[::2]\n            subsub['Fk'] = values[1::2]\n        else:\n            raise ValueError(f\"Unrecognized {LB=}\")\n\n        subsection['ni_subsections'].append(subsub)\n\n    return subsection", "\n\ndef parse_mf33(file_obj: TextIO) -> dict:\n    \"\"\"Parse covariances of neutron cross sections from MF=33\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Cross section covariance data\n\n    \"\"\"\n    ZA, AWR, _, MTL, _, NL = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'MTL': MTL, 'NL': NL, 'subsections': []}\n    for _ in range(NL):\n        subsection = parse_mf33_subsection(file_obj)\n        data['subsections'].append(subsection)\n\n    return data", ""]}
{"filename": "src/endf/mf12.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 Paul Romano\n# SPDX-License-Identifier: MIT\n\nfrom typing import TextIO\nfrom warnings import warn\n\nfrom .records import get_head_record, get_tab1_record, get_list_record\n\n\ndef parse_mf12(file_obj: TextIO) -> dict:\n    \"\"\"Parse photon production multiplicities from MF=12\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Photon production multiplicity / transition probability data\n\n    \"\"\"\n    ZA, AWR, LO, LG, NK, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LO': LO, 'NK': NK}\n\n    if LO == 1:\n        # Multiplicities given -- start by reading total yield\n        if NK > 1:\n            _, data['Y'] = get_tab1_record(file_obj)\n\n        # Read multiplicities\n        data['multiplicities'] = []\n        for k in range(NK):\n            (Eg, ES, LP, LF), y = get_tab1_record(file_obj)\n            data_k = {'Eg': Eg, 'ES': ES, 'LP': LP, 'LF': LF, 'y': y}\n            data['multiplicities'].append(data_k)\n\n    elif LO == 2:\n        # Store whether simple (LG=1) or complex (LG=2) transitions\n        data['LG'] = LG\n\n        # Get transition probability data\n        (ES_NS, _, LP, _, _, NT), values = get_list_record(file_obj)\n        data['ES_NS'] = ES_NS\n        data['LP'] = LP\n        data['NT'] = NT\n        data['transitions'] = transition = []\n        for i in range(NT):\n            if LG == 1:\n                ES, TP = values[2*i : 2*(i + 1)]\n                transition.append({'ES': ES, 'TP': TP})\n            elif LG == 2:\n                ES, TP, GP = values[3*i : 3*(i + 1)]\n                transition.append({'ES': ES, 'TP': TP, 'GP': GP})\n    else:\n        warn(f\"Unrecognized LO value: {LO}\")\n\n    return data", "\ndef parse_mf12(file_obj: TextIO) -> dict:\n    \"\"\"Parse photon production multiplicities from MF=12\n\n    Parameters\n    ----------\n    file_obj\n        File-like object to read from\n\n    Returns\n    -------\n    dict\n        Photon production multiplicity / transition probability data\n\n    \"\"\"\n    ZA, AWR, LO, LG, NK, _ = get_head_record(file_obj)\n    data = {'ZA': ZA, 'AWR': AWR, 'LO': LO, 'NK': NK}\n\n    if LO == 1:\n        # Multiplicities given -- start by reading total yield\n        if NK > 1:\n            _, data['Y'] = get_tab1_record(file_obj)\n\n        # Read multiplicities\n        data['multiplicities'] = []\n        for k in range(NK):\n            (Eg, ES, LP, LF), y = get_tab1_record(file_obj)\n            data_k = {'Eg': Eg, 'ES': ES, 'LP': LP, 'LF': LF, 'y': y}\n            data['multiplicities'].append(data_k)\n\n    elif LO == 2:\n        # Store whether simple (LG=1) or complex (LG=2) transitions\n        data['LG'] = LG\n\n        # Get transition probability data\n        (ES_NS, _, LP, _, _, NT), values = get_list_record(file_obj)\n        data['ES_NS'] = ES_NS\n        data['LP'] = LP\n        data['NT'] = NT\n        data['transitions'] = transition = []\n        for i in range(NT):\n            if LG == 1:\n                ES, TP = values[2*i : 2*(i + 1)]\n                transition.append({'ES': ES, 'TP': TP})\n            elif LG == 2:\n                ES, TP, GP = values[3*i : 3*(i + 1)]\n                transition.append({'ES': ES, 'TP': TP, 'GP': GP})\n    else:\n        warn(f\"Unrecognized LO value: {LO}\")\n\n    return data", ""]}
{"filename": "src/endf/material.py", "chunked_list": ["# SPDX-FileCopyrightText: 2023 OpenMC contributors and Paul Romano\n# SPDX-License-Identifier: MIT\n\n\"\"\"Module for parsing and manipulating data from ENDF files.\n\nAll the classes and functions in this module are based on the ENDF-102 report\ntitled \"ENDF-6 Formats Manual: Data Formats and Procedures for the Evaluated\nNuclear Data Files\". The version from January 2018 can be found at\nhttps://doi.org/10.2172/1425114.\n", "https://doi.org/10.2172/1425114.\n\n\"\"\"\nimport io\nfrom typing import List, Tuple, Any, Union, TextIO, Optional\nfrom warnings import warn\n\nimport endf\nfrom .fileutils import PathLike\nfrom .mf1 import parse_mf1_mt451, parse_mf1_mt452, parse_mf1_mt455, \\", "from .fileutils import PathLike\nfrom .mf1 import parse_mf1_mt451, parse_mf1_mt452, parse_mf1_mt455, \\\n    parse_mf1_mt458, parse_mf1_mt460\nfrom .mf2 import parse_mf2\nfrom .mf3 import parse_mf3\nfrom .mf4 import parse_mf4\nfrom .mf5 import parse_mf5\nfrom .mf6 import parse_mf6\nfrom .mf7 import parse_mf7_mt2, parse_mf7_mt4, parse_mf7_mt451\nfrom .mf8 import parse_mf8, parse_mf8_mt454, parse_mf8_mt457", "from .mf7 import parse_mf7_mt2, parse_mf7_mt4, parse_mf7_mt451\nfrom .mf8 import parse_mf8, parse_mf8_mt454, parse_mf8_mt457\nfrom .mf9 import parse_mf9_mf10\nfrom .mf12 import parse_mf12\nfrom .mf13 import parse_mf13\nfrom .mf14 import parse_mf14\nfrom .mf15 import parse_mf15\nfrom .mf23 import parse_mf23\nfrom .mf26 import parse_mf26\nfrom .mf27 import parse_mf27", "from .mf26 import parse_mf26\nfrom .mf27 import parse_mf27\nfrom .mf28 import parse_mf28\nfrom .mf33 import parse_mf33\nfrom .mf34 import parse_mf34\nfrom .mf40 import parse_mf40\n\n\n_LIBRARY = {\n    0: 'ENDF/B',", "_LIBRARY = {\n    0: 'ENDF/B',\n    1: 'ENDF/A',\n    2: 'JEFF',\n    3: 'EFF',\n    4: 'ENDF/B High Energy',\n    5: 'CENDL',\n    6: 'JENDL',\n    17: 'TENDL',\n    18: 'ROSFOND',", "    17: 'TENDL',\n    18: 'ROSFOND',\n    21: 'SG-23',\n    31: 'INDL/V',\n    32: 'INDL/A',\n    33: 'FENDL',\n    34: 'IRDF',\n    35: 'BROND',\n    36: 'INGDB-90',\n    37: 'FENDL/A',", "    36: 'INGDB-90',\n    37: 'FENDL/A',\n    38: 'IAEA/PD',\n    41: 'BROND'\n}\n\n_SUBLIBRARY = {\n    0: 'Photo-nuclear data',\n    1: 'Photo-induced fission product yields',\n    3: 'Photo-atomic data',", "    1: 'Photo-induced fission product yields',\n    3: 'Photo-atomic data',\n    4: 'Radioactive decay data',\n    5: 'Spontaneous fission product yields',\n    6: 'Atomic relaxation data',\n    10: 'Incident-neutron data',\n    11: 'Neutron-induced fission product yields',\n    12: 'Thermal neutron scattering data',\n    19: 'Neutron standards',\n    113: 'Electro-atomic data',", "    19: 'Neutron standards',\n    113: 'Electro-atomic data',\n    10010: 'Incident-proton data',\n    10011: 'Proton-induced fission product yields',\n    10020: 'Incident-deuteron data',\n    10030: 'Incident-triton data',\n    20030: 'Incident-helion (3He) data',\n    20040: 'Incident-alpha data'\n}\n", "}\n\n\n\nclass Material:\n    \"\"\"ENDF material with multiple files/sections\n\n    Parameters\n    ----------\n    filename_or_obj\n        Path to ENDF file to read or an open file positioned at the start of an\n        ENDF material\n    encoding\n        Encoding of the ENDF-6 formatted file\n\n    Attributes\n    ----------\n    MAT\n        ENDF material number\n    sections\n        List of (MF, MT) sections\n    section_text\n        Dictionary mapping (MF, MT) to corresponding section of the ENDF file.\n    section_data\n        Dictionary mapping (MF, MT) to a dictionary representing the\n        corresponding section of the ENDF file.\n\n    \"\"\"\n    # TODO: Remove need to list properties here\n    MAT: int\n    sections: List[Tuple[int, int]]\n    section_text: dict\n    section_data: dict\n\n    def __init__(self, filename_or_obj: Union[PathLike, TextIO], encoding: Optional[str] = None):\n        if isinstance(filename_or_obj, PathLike.__args__):\n            fh = open(str(filename_or_obj), 'r', encoding=encoding)\n            need_to_close = True\n        else:\n            fh = filename_or_obj\n            need_to_close = False\n        self.section_text = {}\n\n        # Skip TPID record. Evaluators sometimes put in TPID records that are\n        # ill-formated because they lack MF/MT values or put them in the wrong\n        # columns.\n        if fh.tell() == 0:\n            fh.readline()\n        MF = 0\n\n        # Determine MAT number for this material\n        while MF == 0:\n            position = fh.tell()\n            line = fh.readline()\n            MF = int(line[70:72])\n        self.MAT = int(line[66:70])\n        fh.seek(position)\n\n        while True:\n            # Find next section\n            while True:\n                position = fh.tell()\n                line = fh.readline()\n                MAT = int(line[66:70])\n                MF = int(line[70:72])\n                MT = int(line[72:75])\n                if MT > 0 or MAT == 0:\n                    fh.seek(position)\n                    break\n\n            # If end of material reached, exit loop\n            if MAT == 0:\n                fh.readline()\n                break\n\n            section_text = ''\n            while True:\n                line = fh.readline()\n                if line[72:75] == '  0':\n                    break\n                else:\n                    section_text += line\n            self.section_text[MF, MT] = section_text\n\n        if need_to_close:\n            fh.close()\n\n        self.section_data = {}\n        for (MF, MT), text in self.section_text.items():\n            file_obj = io.StringIO(text)\n            if MF == 1 and MT == 451:\n                self.section_data[MF, MT] = parse_mf1_mt451(file_obj)\n            elif MF == 1 and MT in (452, 456):\n                self.section_data[MF, MT] = parse_mf1_mt452(file_obj)\n            elif MF == 1 and MT == 455:\n                self.section_data[MF, MT] = parse_mf1_mt455(file_obj)\n            elif MF == 1 and MT == 458:\n                self.section_data[MF, MT] = parse_mf1_mt458(file_obj)\n            elif MF == 1 and MT == 460:\n                self.section_data[MF, MT] = parse_mf1_mt460(file_obj)\n            elif MF == 2 and MT == 151:\n                self.section_data[MF, MT] = parse_mf2(file_obj)\n            elif MF == 3:\n                self.section_data[MF, MT] = parse_mf3(file_obj)\n            elif MF == 4:\n                self.section_data[MF, MT] = parse_mf4(file_obj)\n            elif MF == 5:\n                self.section_data[MF, MT] = parse_mf5(file_obj)\n            elif MF == 6:\n                self.section_data[MF, MT] = parse_mf6(file_obj)\n            elif MF == 7 and MT == 2:\n                self.section_data[MF, MT] = parse_mf7_mt2(file_obj)\n            elif MF == 7 and MT == 4:\n                self.section_data[MF, MT] = parse_mf7_mt4(file_obj)\n            elif MF == 7 and MT == 451:\n                self.section_data[MF, MT] = parse_mf7_mt451(file_obj)\n            elif MF == 8 and MT in (454, 459):\n                self.section_data[MF, MT] = parse_mf8_mt454(file_obj)\n            elif MF == 8 and MT == 457:\n                self.section_data[MF, MT] = parse_mf8_mt457(file_obj)\n            elif MF == 8:\n                self.section_data[MF, MT] = parse_mf8(file_obj)\n            elif MF in (9, 10):\n                self.section_data[MF, MT] = parse_mf9_mf10(file_obj, MF)\n            elif MF == 12:\n                self.section_data[MF, MT] = parse_mf12(file_obj)\n            elif MF == 13:\n                self.section_data[MF, MT] = parse_mf13(file_obj)\n            elif MF == 14:\n                self.section_data[MF, MT] = parse_mf14(file_obj)\n            elif MF == 15:\n                self.section_data[MF, MT] = parse_mf15(file_obj)\n            elif MF == 23:\n                self.section_data[MF, MT] = parse_mf23(file_obj)\n            elif MF == 26:\n                self.section_data[MF, MT] = parse_mf26(file_obj)\n            elif MF == 27:\n                self.section_data[MF, MT] = parse_mf27(file_obj)\n            elif MF == 28:\n                self.section_data[MF, MT] = parse_mf28(file_obj)\n            elif MF == 33:\n                self.section_data[MF, MT] = parse_mf33(file_obj)\n            elif MF == 34:\n                self.section_data[MF, MT] = parse_mf34(file_obj, MT)\n            elif MF == 40:\n                self.section_data[MF, MT] = parse_mf40(file_obj)\n            else:\n                warn(f\"{MF=}, {MT=} ignored\")\n\n    def __contains__(self, mf_mt: Tuple[int, int]) -> bool:\n        return mf_mt in self.section_data\n\n    def __getitem__(self, mf_mt: Tuple[int, int]) -> dict:\n        return self.section_data[mf_mt]\n\n    def __setitem__(self, key: Tuple[int, int], value):\n        self.section_data[key] = value\n\n    def __repr__(self) -> str:\n        metadata = self.section_data[1, 451]\n        name = metadata['ZSYMAM'].replace(' ', '')\n        return '<{} for {} {}>'.format(_SUBLIBRARY[metadata['NSUB']], name,\n                                       _LIBRARY[metadata['NLIB']])\n\n    @property\n    def sections(self) -> List[Tuple[int, int]]:\n        return list(self.section_text.keys())\n\n    def interpret(self) -> Any:\n        \"\"\"Get high-level interface class for the ENDF material\n\n        Returns\n        -------\n        Instance of a high-level interface class, e.g.,\n        :class:`endf.IncidentNeutron`.\n\n        \"\"\"\n        NSUB = self.section_data[1, 451]['NSUB']\n        if NSUB == 10:\n            return endf.IncidentNeutron.from_endf(self)\n        else:\n            raise NotImplementedError(f\"No class implemented for {NSUB=}\")", "\n\ndef get_materials(filename: PathLike, encoding: Optional[str] = None) -> List[Material]:\n    \"\"\"Return a list of all materials within an ENDF file.\n\n    Parameters\n    ----------\n    filename\n        Path to ENDF-6 formatted file\n    encoding\n        Encoding of the ENDF-6 formatted file\n\n    Returns\n    -------\n    A list of ENDF materials\n\n    \"\"\"\n    materials = []\n    with open(str(filename), 'r', encoding=encoding) as fh:\n        while True:\n            pos = fh.tell()\n            line = fh.readline()\n            if line[66:70] == '  -1':\n                break\n            fh.seek(pos)\n            materials.append(Material(fh))\n    return materials", ""]}
