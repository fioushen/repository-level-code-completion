{"filename": "Step2-Modality-Specific-Information-Disentanglement/main.py", "chunked_list": ["import torch\nimport numpy as np\nimport torch.optim as optim\nfrom options.Options import Options_x\nfrom dataset.dataset_lits_train import Lits_DataSet\nfrom dataset.dataset_lits_val import Val_DataSet\nfrom Model.networks import RUnet\nfrom torch.utils.data import DataLoader\nfrom setting.common import adjust_learning_rate\nfrom setting import logger, util", "from setting.common import adjust_learning_rate\nfrom setting import logger, util\nfrom setting.metrics import LossAverage, DiceLoss\nimport os\nimport time\nfrom test import test_all\nfrom collections import OrderedDict\n\n\ndef val(val_dataloader, epoch):\n    since = time.time()\n\n    Loss = LossAverage()\n    DICE_Loss = LossAverage()\n    BCE_Loss = LossAverage()\n\n    for i, (DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt) in enumerate(val_dataloader):  # inner loop within one epoch\n        b, c, l, w, e = DCE0.shape[0], DCE0.shape[1], DCE0.shape[2], DCE0.shape[3], DCE0.shape[4]\n\n        DCE0 = DCE0.view(-1, 1, l, w, e).to(device)\n        DCE = DCE.view(-1, 1, l, w, e).to(device)\n        sub = sub.view(-1, 1, l, w, e).to(device)\n        ADC = ADC.view(-1, 1, l, w, e).to(device)\n        T2W = T2W.view(-1, 1, l, w, e).to(device)\n        ADC_syn = ADC_syn.view(-1, 1, l, w, e).to(device)\n        T2W_syn = T2W_syn.view(-1, 1, l, w, e).to(device)\n        gt = gt.view(-1, 1, l, w, e).to(device)\n\n        pred = model(torch.cat((DCE, sub, ADC, T2W), dim=1))\n\n        Dice_loss = dice_loss(pred, gt)\n        Bce_loss = bce_loss(pred, gt)\n        loss = Bce_loss + 5 * Dice_loss\n\n        Loss.update(loss.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss.item(), DCE0.size(0))\n\n        pred_adc = model(torch.cat((DCE, sub, ADC_syn, T2W), dim=1))\n\n        Dice_loss1 = dice_loss(pred_adc, gt)\n        Bce_loss1 = bce_loss(pred_adc, gt)\n        loss1 = Bce_loss1 + 5 * Dice_loss1\n\n        Loss.update(loss1.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss1.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss1.item(), DCE0.size(0))\n\n        pred_t2 = model(torch.cat((DCE, sub, ADC, T2W_syn), dim=1))\n\n        Dice_loss2 = dice_loss(pred_t2, gt)\n        Bce_loss2 = bce_loss(pred_t2, gt)\n        loss2 = Bce_loss2 + 5 * Dice_loss2\n\n        Loss.update(loss2.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss2.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss2.item(), DCE0.size(0))\n\n        pred_all = model(torch.cat((DCE, sub, ADC_syn, T2W_syn), dim=1))\n\n        Dice_loss3 = dice_loss(pred_all, gt)\n        Bce_loss3 = bce_loss(pred_all, gt)\n        loss3 = Bce_loss3 + 5 * Dice_loss3\n\n        Loss.update(loss3.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss3.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss3.item(), DCE0.size(0))\n\n    time_elapsed = time.time() - since\n    print(\"=======Val Epoch:{}======Learning_rate:{}======Validate complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})", "\ndef val(val_dataloader, epoch):\n    since = time.time()\n\n    Loss = LossAverage()\n    DICE_Loss = LossAverage()\n    BCE_Loss = LossAverage()\n\n    for i, (DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt) in enumerate(val_dataloader):  # inner loop within one epoch\n        b, c, l, w, e = DCE0.shape[0], DCE0.shape[1], DCE0.shape[2], DCE0.shape[3], DCE0.shape[4]\n\n        DCE0 = DCE0.view(-1, 1, l, w, e).to(device)\n        DCE = DCE.view(-1, 1, l, w, e).to(device)\n        sub = sub.view(-1, 1, l, w, e).to(device)\n        ADC = ADC.view(-1, 1, l, w, e).to(device)\n        T2W = T2W.view(-1, 1, l, w, e).to(device)\n        ADC_syn = ADC_syn.view(-1, 1, l, w, e).to(device)\n        T2W_syn = T2W_syn.view(-1, 1, l, w, e).to(device)\n        gt = gt.view(-1, 1, l, w, e).to(device)\n\n        pred = model(torch.cat((DCE, sub, ADC, T2W), dim=1))\n\n        Dice_loss = dice_loss(pred, gt)\n        Bce_loss = bce_loss(pred, gt)\n        loss = Bce_loss + 5 * Dice_loss\n\n        Loss.update(loss.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss.item(), DCE0.size(0))\n\n        pred_adc = model(torch.cat((DCE, sub, ADC_syn, T2W), dim=1))\n\n        Dice_loss1 = dice_loss(pred_adc, gt)\n        Bce_loss1 = bce_loss(pred_adc, gt)\n        loss1 = Bce_loss1 + 5 * Dice_loss1\n\n        Loss.update(loss1.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss1.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss1.item(), DCE0.size(0))\n\n        pred_t2 = model(torch.cat((DCE, sub, ADC, T2W_syn), dim=1))\n\n        Dice_loss2 = dice_loss(pred_t2, gt)\n        Bce_loss2 = bce_loss(pred_t2, gt)\n        loss2 = Bce_loss2 + 5 * Dice_loss2\n\n        Loss.update(loss2.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss2.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss2.item(), DCE0.size(0))\n\n        pred_all = model(torch.cat((DCE, sub, ADC_syn, T2W_syn), dim=1))\n\n        Dice_loss3 = dice_loss(pred_all, gt)\n        Bce_loss3 = bce_loss(pred_all, gt)\n        loss3 = Bce_loss3 + 5 * Dice_loss3\n\n        Loss.update(loss3.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss3.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss3.item(), DCE0.size(0))\n\n    time_elapsed = time.time() - since\n    print(\"=======Val Epoch:{}======Learning_rate:{}======Validate complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})", "\n\ndef train(train_dataloader, epoch):\n    since = time.time()\n\n    Loss = LossAverage()\n    DICE_Loss = LossAverage()\n    BCE_Loss = LossAverage()\n\n    model.train()\n\n    for i, (DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt) in enumerate(train_dataloader):\n        b, c, l, w, e = DCE0.shape[0], DCE0.shape[1], DCE0.shape[2], DCE0.shape[3], DCE0.shape[4]\n\n        DCE0 = DCE0.view(-1, 1, l, w, e).to(device)\n        DCE = DCE.view(-1, 1, l, w, e).to(device)\n        sub = sub.view(-1, 1, l, w, e).to(device)\n        ADC = ADC.view(-1, 1, l, w, e).to(device)\n        T2W = T2W.view(-1, 1, l, w, e).to(device)\n        ADC_syn = ADC_syn.view(-1, 1, l, w, e).to(device)\n        T2W_syn = T2W_syn.view(-1, 1, l, w, e).to(device)\n        gt = gt.view(-1, 1, l, w, e).to(device)\n\n        pred = model(torch.cat((DCE, sub, ADC, T2W), dim=1))\n\n        Dice_loss = dice_loss(pred, gt)\n        Bce_loss = bce_loss(pred, gt)\n        loss = Bce_loss + 5 * Dice_loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        Loss.update(loss.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss.item(), DCE0.size(0))\n\n        pred_adc = model(torch.cat((DCE, sub, ADC_syn, T2W), dim=1))\n\n        Dice_loss1 = dice_loss(pred_adc, gt)\n        Bce_loss1 = bce_loss(pred_adc, gt)\n        loss1 = Bce_loss1 + 5 * Dice_loss1\n\n        optimizer.zero_grad()\n        loss1.backward()\n        optimizer.step()\n        Loss.update(loss1.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss1.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss1.item(), DCE0.size(0))\n\n        pred_t2 = model(torch.cat((DCE, sub, ADC, T2W_syn), dim=1))\n\n        Dice_loss2 = dice_loss(pred_t2, gt)\n        Bce_loss2 = bce_loss(pred_t2, gt)\n        loss2 = Bce_loss2 + 5 * Dice_loss2\n\n        optimizer.zero_grad()\n        loss2.backward()\n        optimizer.step()\n        Loss.update(loss2.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss2.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss2.item(), DCE0.size(0))\n\n        pred_all = model(torch.cat((DCE, sub, ADC_syn, T2W_syn), dim=1))\n\n        Dice_loss3 = dice_loss(pred_all, gt)\n        Bce_loss3 = bce_loss(pred_all, gt)\n        loss3 = Bce_loss3 + 5 * Dice_loss3\n\n        optimizer.zero_grad()\n        loss3.backward()\n        optimizer.step()\n        Loss.update(loss3.item(), DCE0.size(0))\n        DICE_Loss.update(Dice_loss3.item(), DCE0.size(0))\n        BCE_Loss.update(Bce_loss3.item(), DCE0.size(0))\n\n        adjust_learning_rate(optimizer, epoch, opt)\n\n    time_elapsed = time.time() - since\n    print(\"=======Train Epoch:{}======Learning_rate:{}======Train complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})", "\n\nif __name__ == '__main__':\n    opt = Options_x().parse()\n    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n    print(\"using {} device.\".format(device))\n\n    model = RUnet(num_cls=1).to(device)\n\n    save_path = opt.checkpoints_dir\n    dice_loss = DiceLoss()\n    bce_loss = torch.nn.BCEWithLogitsLoss()\n\n    save_result_path = os.path.join(save_path, opt.task_name)\n    util.mkdir(save_result_path)\n\n    optimizer = optim.Adam(model.parameters(), lr=opt.lr, weight_decay=1e-5)\n    model_save_path = os.path.join(save_result_path, 'model')\n    util.mkdir(model_save_path)\n    logger_save_path = os.path.join(save_result_path, 'logger')\n    util.mkdir(logger_save_path)\n\n    log_train = logger.Train_Logger(logger_save_path, \"train_log\")\n    log_val = logger.Val_Logger(logger_save_path, \"val_log\")\n\n    train_dataset = Lits_DataSet(opt.datapath, opt.patch_size)\n    val_dataset = Val_DataSet(opt.datapath, opt.patch_size)\n\n    train_dataloader = DataLoader(dataset=train_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n    val_dataloader = DataLoader(dataset=val_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n\n    types = ['train', 'val']\n    val_dice_loss = 99\n    best_epoch = 0\n\n    for epoch in range(opt.epoch):\n        epoch = epoch + 1\n        for type in types:\n            if type == 'train':\n                train_log = train(train_dataloader, epoch)\n                log_train.update(epoch, train_log)\n            elif type == 'val':\n                val_log = val(val_dataloader, epoch)\n                log_val.update(epoch, val_log)\n                if val_log['DICE_Loss'] < val_dice_loss:\n                    best_epoch = epoch\n                    val_dice_loss = val_log['DICE_Loss']\n                    state = {'model': model.state_dict(), 'epoch': best_epoch}\n                    torch.save(state, os.path.join(model_save_path, 'best_model.pth'))\n\n        state = {'model': model.state_dict(), 'epoch': epoch}\n        torch.save(state, os.path.join(model_save_path, 'latest_model.pth'))\n\n        if epoch % opt.model_save_fre == 0:\n            torch.save(state, os.path.join(model_save_path, 'model_' + np.str(epoch) + '.pth'))\n\n        torch.cuda.empty_cache()\n\n    test_all('best_model.pth')", "\n\n\n\n\n\n\n\n\n", "\n\n\n\n\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/test.py", "chunked_list": ["import torch\nimport gc\nimport numpy as np\nimport SimpleITK as sitk\nfrom options.Options import Options_x\nfrom tqdm import tqdm\nfrom Model.networks import RUnet\nfrom torch.utils.data import DataLoader\nfrom setting import logger, util\nfrom setting.metrics import seg_metric", "from setting import logger, util\nfrom setting.metrics import seg_metric\nimport os\nfrom dataset.dataset_lits_test import Test_all_Datasets, Recompone_tool\nfrom collections import OrderedDict\n\n\ndef load(file):\n    itkimage = sitk.ReadImage(file)\n    image = sitk.GetArrayFromImage(itkimage)\n    return image", "\n\ndef test_all(model_name, flag):\n    opt = Options_x().parse()  # get training options\n    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n    print(\"using {} device.\".format(device))\n\n    model = RUnet().to(device)\n\n    ckpt = torch.load(opt.checkpoints_dir + '/' + opt.task_name + '/model/' + model_name, map_location=device)\n    model.load_state_dict(ckpt['model'])\n\n    save_result_path = os.path.join(opt.checkpoints_dir, opt.task_name, 'test_all_result')\n    util.mkdir(save_result_path)\n    model.eval()\n\n    save_excel_path = os.path.join(save_result_path, flag)\n    util.mkdir(save_excel_path)\n    log_test = logger.Test_Logger(save_excel_path, \"results_train\")\n\n    cut_param = {'patch_s': opt.patch_size[0], 'patch_h': opt.patch_size[1], 'patch_w': opt.patch_size[2],\n                 'stride_s': opt.patch_stride[0], 'stride_h': opt.patch_stride[1], 'stride_w': opt.patch_stride[2]}\n    datasets = Test_all_Datasets(opt.datapath, cut_param, flag)\n\n    for img_dataset, original_shape, new_shape, mask, file_idx in datasets:\n        save_tool = Recompone_tool(original_shape, new_shape, cut_param)\n        save_prob_tool = Recompone_tool(original_shape, new_shape, cut_param)\n        dataloader = DataLoader(img_dataset, batch_size=opt.test_batch, num_workers=opt.num_threads, shuffle=False)\n        with torch.no_grad():\n            for pre, pos, sub, adc, t2w, gt in tqdm(dataloader):\n                pos, sub, adc, t2w, gt = pos.to(device), sub.to(device), adc.to(device), t2w.to(device), gt.to(device)\n\n                pos = pos.unsqueeze(1).type(torch.float32)\n                sub = sub.unsqueeze(1).type(torch.float32)\n                adc = adc.unsqueeze(1).type(torch.float32)\n                t2w = t2w.unsqueeze(1).type(torch.float32)\n\n                output = model(pos, sub, adc, t2w)\n\n                probility = output.type(torch.float32)\n                seg = (output >= 0.5).type(torch.float32)\n\n                save_prob_tool.add_result(probility.detach().cpu())\n                save_tool.add_result(seg.detach().cpu())\n\n        probility = save_prob_tool.recompone_overlap()\n        pred = save_tool.recompone_overlap()\n\n        recon = (pred.numpy() > 0.5).astype(np.uint16) * mask.astype(np.uint16)\n        gt = load(os.path.join(opt.datapath, file_idx, 'GT.nii.gz'))\n        DSC, PPV, SEN, ASD = seg_metric(recon, gt)\n        index_results = OrderedDict({'DSC': DSC, 'PPV': PPV, 'SEN': SEN, 'ASD': ASD})\n        log_test.update(file_idx, index_results)\n\n        Pred = sitk.GetImageFromArray(np.array(recon))\n        prob_img = sitk.GetImageFromArray(np.array(probility))\n\n        result_save_path = os.path.join(save_result_path, flag, file_idx)\n        util.mkdir(result_save_path)\n\n        sitk.WriteImage(Pred, os.path.join(result_save_path, 'pred.nii.gz'))\n        sitk.WriteImage(prob_img, os.path.join(result_save_path, 'probility.nii.gz'))\n\n        del pred, recon, Pred, save_tool, save_prob_tool, prob_img, probility, gt\n        gc.collect()\n        torch.cuda.empty_cache()", "\n\nif __name__ == '__main__':\n    for flag_in in ['all_true', 'fake_adc', 'fake_t2', 'all_fake']:\n        test_all('best_model.pth', flag_in)\n\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/weights_init.py", "chunked_list": ["from torch.nn import init\n\n\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('Linear') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_xavier(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.xavier_normal(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.xavier_normal(m.weight.data, gain=1)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('Linear') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_orthogonal(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef init_weights(net, init_type='normal'):\n    # print('initialization method [%s]' % init_type)\n    if init_type == 'normal':\n        net.apply(weights_init_normal)\n    elif init_type == 'xavier':\n        net.apply(weights_init_xavier)\n    elif init_type == 'kaiming':\n        net.apply(weights_init_kaiming)\n    elif init_type == 'orthogonal':\n        net.apply(weights_init_orthogonal)\n    else:\n        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)", ""]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/metrics.py", "chunked_list": ["import torch.nn as nn\nimport torch\nimport numpy as np\nimport sys\nfrom scipy.ndimage import morphology\n\nsys.dont_write_bytecode = True\n\n\nclass LossAverage(object):\n    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = round(self.sum / self.count, 4)", "\nclass LossAverage(object):\n    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = round(self.sum / self.count, 4)", "\n\nclass DiceLoss(nn.Module):\n    \"\"\"\n    define the dice loss\n    \"\"\"\n\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, input, target):\n        smooth = 1.\n        iflat = input.contiguous().view(-1)\n        tflat = target.contiguous().view(-1)\n        intersection = (iflat * tflat).sum()\n\n        A_sum = torch.sum(iflat * iflat)\n        B_sum = torch.sum(tflat * tflat)\n\n        return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth))", "\n\n\"\"\"dice coefficient\"\"\"\n\n\ndef dice(pre, gt, tid=1):\n    pre = pre == tid  # make it boolean\n    gt = gt == tid  # make it boolean\n    pre = np.asarray(pre).astype(np.bool)\n    gt = np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    dsc = (2. * intersection.sum() + 1e-07) / (pre.sum() + gt.sum() + 1e-07)\n\n    return dsc", "\n\n\"\"\"positive predictive value\"\"\"\n\n\ndef pospreval(pre, gt, tid=1):\n    pre = pre == tid  # make it boolean\n    gt = gt == tid  # make it boolean\n    pre = np.asarray(pre).astype(np.bool)\n    gt = np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    ppv = (1.0 * intersection.sum() + 1e-07) / (pre.sum() + 1e-07)\n\n    return ppv", "\n\n\"\"\"sensitivity\"\"\"\n\n\ndef sensitivity(pre, gt, tid=1):\n    pre = pre == tid  # make it boolean\n    gt = gt == tid  # make it boolean\n    pre = np.asarray(pre).astype(np.bool)\n    gt = np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    sen = (1.0 * intersection.sum() + 1e-07) / (gt.sum() + 1e-07)\n\n    return sen", "\n\n\"\"\"specificity\"\"\"\n\n\ndef specificity(pre, gt):\n    pre = pre == 0  # make it boolean\n    gt = gt == 0  # make it boolean\n    pre = np.asarray(pre).astype(np.bool)\n    gt = np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    spe = (1.0 * intersection.sum() + 1e-07) / (gt.sum() + 1e-07)\n\n    return spe", "\n\n\"\"\"average surface distance\"\"\"\n\n\ndef surfd(pre, gt, tid=1, sampling=1, connectivity=1):\n    pre = pre == tid  # make it boolean\n    gt = gt == tid  # make it boolean\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    input_1 = np.atleast_1d(pre.astype(np.bool))\n    input_2 = np.atleast_1d(gt.astype(np.bool))\n\n    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n\n    S = np.logical_xor(input_1, morphology.binary_erosion(input_1, conn))\n    Sprime = np.logical_xor(input_2, morphology.binary_erosion(input_2, conn))\n\n    dta = morphology.distance_transform_edt(~S, sampling)\n    dtb = morphology.distance_transform_edt(~Sprime, sampling)\n\n    sds = np.concatenate([np.ravel(dta[Sprime != 0]), np.ravel(dtb[S != 0])])\n    return sds", "\n\ndef asd(pre, gt, tid=1, sampling=1, connectivity=1):\n    sds = surfd(pre, gt, tid=tid, sampling=sampling, connectivity=connectivity)\n    dis = sds.mean()\n    return dis\n\n\ndef seg_metric(pre, gt):\n    mask = (pre > 0.5)\n    gt = (gt > 0.5)\n    ASD = asd(mask, gt)\n    DSC = dice(mask, gt)\n    SEN = sensitivity(mask, gt)\n    PPV = pospreval(mask, gt)\n\n    return DSC, PPV, SEN, ASD", "def seg_metric(pre, gt):\n    mask = (pre > 0.5)\n    gt = (gt > 0.5)\n    ASD = asd(mask, gt)\n    DSC = dice(mask, gt)\n    SEN = sensitivity(mask, gt)\n    PPV = pospreval(mask, gt)\n\n    return DSC, PPV, SEN, ASD\n", ""]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/logger.py", "chunked_list": ["import pandas as pd\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch, random\nimport numpy as np\nfrom collections import OrderedDict\n\n\nclass Train_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, epoch, train_log):\n        item = OrderedDict({'epoch': epoch})\n        item.update(train_log)\n\n        print(\"\\033[0;33mTrain:\\033[0m\", train_log)\n        self.update_csv(item)\n        self.update_tensorboard(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\n    def update_tensorboard(self, item):\n        if self.summary is None:\n            self.summary = SummaryWriter('%s/' % self.save_path)\n        epoch = item['epoch']\n        for key, value in item.items():\n            if key != 'epoch': self.summary.add_scalar(key, value, epoch)", "\n\nclass Val_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, epoch, val_log):\n        item = OrderedDict({'epoch': epoch})\n        item.update(val_log)\n\n        print(\"\\033[0;33mValidate:\\033[0m\", val_log)\n        self.update_csv(item)\n        self.update_tensorboard(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\n    def update_tensorboard(self, item):\n        if self.summary is None:\n            self.summary = SummaryWriter('%s/' % self.save_path)\n        epoch = item['epoch']\n        for key, value in item.items():\n            if key != 'epoch': self.summary.add_scalar(key, value, epoch)", "\n\nclass Test_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, name, log):\n        item = OrderedDict({'img_name': name})\n        item.update(log)\n        print(\"\\033[0;33mTest:\\033[0m\", log)\n        self.update_csv(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)", "\n\ndef setpu_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    random.seed(seed)\n\n\ndef dict_round(dic, num):\n    for key, value in dic.items():\n        dic[key] = round(value, num)\n    return dic", "\n\ndef dict_round(dic, num):\n    for key, value in dic.items():\n        dic[key] = round(value, num)\n    return dic\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/util.py", "chunked_list": ["\"\"\"This module contains simple helper functions \"\"\"\nfrom __future__ import print_function\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport os\n\n\ndef tensor2im(input_image, imtype=np.uint8):\n    \"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"\n    if not isinstance(input_image, np.ndarray):\n        if isinstance(input_image, torch.Tensor):\n            image_tensor = input_image.data\n        else:\n            return input_image\n        image_numpy = image_tensor[0].cpu().float().numpy()\n        if image_numpy.shape[0] == 1:\n            image_numpy = np.tile(image_numpy, (3, 1, 1))\n        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n    else:\n        image_numpy = input_image\n    return image_numpy.astype(imtype)", "def tensor2im(input_image, imtype=np.uint8):\n    \"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"\n    if not isinstance(input_image, np.ndarray):\n        if isinstance(input_image, torch.Tensor):\n            image_tensor = input_image.data\n        else:\n            return input_image\n        image_numpy = image_tensor[0].cpu().float().numpy()\n        if image_numpy.shape[0] == 1:\n            image_numpy = np.tile(image_numpy, (3, 1, 1))\n        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n    else:\n        image_numpy = input_image\n    return image_numpy.astype(imtype)", "\n\ndef diagnose_network(net, name='network'):\n    \"\"\"Calculate and print the mean of average absolute(gradients)\n\n    Parameters:\n        net (torch network) -- Torch network\n        name (str) -- the name of the network\n    \"\"\"\n    mean = 0.0\n    count = 0\n    for param in net.parameters():\n        if param.grad is not None:\n            mean += torch.mean(torch.abs(param.grad.data))\n            count += 1\n    if count > 0:\n        mean = mean / count\n    print(name)\n    print(mean)", "\n\ndef save_image(image_numpy, image_path, aspect_ratio=1.0):\n    \"\"\"Save a numpy image to the disk\n\n    Parameters:\n        image_numpy (numpy array) -- input numpy array\n        image_path (str)          -- the path of the image\n    \"\"\"\n\n    image_pil = Image.fromarray(image_numpy)\n    h, w, _ = image_numpy.shape\n\n    if aspect_ratio > 1.0:\n        image_pil = image_pil.resize((h, int(w * aspect_ratio)), Image.BICUBIC)\n    if aspect_ratio < 1.0:\n        image_pil = image_pil.resize((int(h / aspect_ratio), w), Image.BICUBIC)\n    image_pil.save(image_path)", "\n\ndef print_numpy(x, val=True, shp=False):\n    \"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"\n    x = x.astype(np.float64)\n    if shp:\n        print('shape,', x.shape)\n    if val:\n        x = x.flatten()\n        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))", "\n\ndef mkdirs(paths):\n    \"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)", "\n\ndef mkdir(path):\n    \"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"\n    \n    if not os.path.exists(path):\n        os.makedirs(path)", ""]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/common.py", "chunked_list": ["import SimpleITK as sitk\nimport numpy as np\nimport math\n\n\ndef normalization(img):\n    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n    return out\n\n\ndef normalization_test (img):\n    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n    return out, np.max(img), np.min(img)", "\n\ndef normalization_test (img):\n    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n    return out, np.max(img), np.min(img)\n\ndef center_crop_3d(img, label, slice_num=16):\n    if img.shape[0] < slice_num:\n        return None\n    left_x = img.shape[0]//2 - slice_num//2\n    right_x = img.shape[0]//2 + slice_num//2\n\n    crop_img = img[left_x:right_x]\n    crop_label = label[left_x:right_x]\n    return crop_img, crop_label", "\ndef load_file_name_list(file_path):\n    file_name_list = []\n    with open(file_path, 'r') as file_to_read:\n        while True:\n            lines = file_to_read.readline().strip()\n            if not lines:\n                break\n                pass\n            file_name_list.append(lines)\n            pass\n    return file_name_list", "\n\ndef MaskContour(image, position='xy', line=1):\n    itkimage = sitk.GetImageFromArray(image)\n    if position == 'xy':\n        erode_m = [line, line, 0]\n    elif position == 'yz':\n        erode_m = [0, line, line]\n    elif position == 'zx':\n        erode_m = [line, 0, line]\n    else:\n        erode_m = [line, line, 0]\n\n    mask = sitk.GetArrayFromImage(sitk.BinaryErode(itkimage, erode_m))\n    boundary = image - mask\n    out = sitk.GetImageFromArray(boundary)\n    return out", "\n\ndef print_network(net):\n    num_params = 0\n    for param in net.parameters():\n        num_params += param.numel()\n    print(net)\n    print('Total number of parameters: %d' % num_params)\n\ndef adjust_learning_rate(optimizer, epoch, opt):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n    lr = opt.lr * (0.5 ** (epoch // opt.step))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr", "\ndef adjust_learning_rate(optimizer, epoch, opt):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n    lr = opt.lr * (0.5 ** (epoch // opt.step))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\ndef adjust_learning_rate_V2(optimizer, lr):\n    \"\"\"Sets the learning rate to a fixed number\"\"\"\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr", "        \n        \n        \ndef get_mse(img1, img2):\n    mse = np.mean( (img1 - img2) ** 2 )\n\n    return mse\n\n\ndef get_psnr(img1, img2):\n    mse = np.mean( (img1 - img2) ** 2 )\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1.0\n    return 10 * math.log10(PIXEL_MAX / math.sqrt(mse))", "\ndef get_psnr(img1, img2):\n    mse = np.mean( (img1 - img2) ** 2 )\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1.0\n    return 10 * math.log10(PIXEL_MAX / math.sqrt(mse))\n\n'''\ndef get_ssim(img1,img2):", "'''\ndef get_ssim(img1,img2):\n    n=img1.shape[0]\n    out = 0\n    for i in range(n):\n        out+=structural_similarity(img1[i].squeeze(),img2[i].squeeze())\n        \n    return out/n\n'''    \n    ", "'''    \n    \n\ndef save_result(low_dose, high_dose, output, i, epoch):\n    def save_img(img, name):\n        img = sitk.GetImageFromArray(img)\n        sitk.WriteImage(img, 'result/image/'+name+'.nii.gz')\n        \n    save_img(low_dose, 'low_dose_epoch_'+str(epoch) + \"_\" + str(i))\n    save_img(high_dose, 'high_dose_epoch_'+str(epoch) + \"_\" + str(i))\n    save_img(output, 'output_epoch_'+str(epoch) + \"_\" + str(i))", "\n\ndef de_normalization(img,max_x,min_x):\n    return img*(max_x - min_x) + min_x"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/options/BasicOptions.py", "chunked_list": ["import argparse\nimport os\nfrom setting import util\nimport torch\n\n\nclass BaseOptions():\n    \"\"\"This class defines options used during both training and test time.\n\n    It also implements several helper functions such as parsing, printing, and saving the options.\n    It also gathers additional options defined in <modify_commandline_options> functions in both dataset class and model class.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"\n        self.initialized = False\n\n    def initialize(self, parser):\n        \"\"\"Define the common options that are used in both training and test.\"\"\"\n        # basic parameters\n        \n        parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n        parser.add_argument('--num_threads', default=1, type=int, help='# threads for loading data')\n        \n        parser.add_argument('--batch_size', type=int, default=1, help='input train batch size')\n        parser.add_argument('--test_batch', type=int, default=1, help='input test batch size')\n        parser.add_argument('--epoch', type=int, default=400, help='number of epochs with the initial learning rate')\n        parser.add_argument('--step', type=int, default=50, help='number of epochs to adjust learning rate')\n        parser.add_argument('--datapath', default=r'/data', help='path of the raw data')\n        parser.add_argument('--lr', type=float, default=0.005, help='initial learning rate of net for adam')\n        parser.add_argument('--model_save_fre', type=int, default=50, help='frequency of saving model') \n        parser.add_argument('--test_fre', type=int, default=600, help='frequency of testing the model')\n        parser.add_argument('--patch_size', type=int, default=(32,128,128), help='the size of crop patch')\n        parser.add_argument('--patch_stride', type=int, default=(8,64,64), help='the stride of patch')\n        parser.add_argument('--task_name', type=str, default='MultiModal_Parametric', help='the current task name')\n        self.initialized = True\n        return parser\n\n    def gather_options(self):\n        \"\"\"Initialize our parser with basic options(only once).\n        Add additional model-specific and dataset-specific options.\n        These options are defined in the <modify_commandline_options> function\n        in model and dataset classes.\n        \"\"\"\n        if not self.initialized:  # check if it has been initialized\n            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n            parser = self.initialize(parser)\n\n        # get the basic options\n        opt, _ = parser.parse_known_args()\n        # save and return the parser\n        self.parser = parser\n        return parser.parse_args()\n\n    def print_options(self, opt):\n        \"\"\"Print and save options\n\n        It will print both current options and default values(if different).\n        It will save options into a text file / [checkpoints_dir] / opt.txt\n        \"\"\"\n        message = ''\n        message += '----------------- Options ---------------\\n'\n        for k, v in sorted(vars(opt).items()):\n            comment = ''\n            default = self.parser.get_default(k)\n            if v != default:\n                comment = '\\t[default: %s]' % str(default)\n            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n        message += '----------------- End -------------------'\n        print(message)\n\n        # save to the disk\n        expr_dir = os.path.join(opt.checkpoints_dir, 'model_parameter_list')\n        util.mkdirs(expr_dir)\n        file_name = os.path.join(expr_dir, '{train_opt.txt')\n        with open(file_name, 'wt') as opt_file:\n            opt_file.write(message)\n            opt_file.write('\\n')\n\n    def parse(self):\n        \"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"\n        opt = self.gather_options()\n        opt.isTrain = self.isTrain   # train or test\n\n        self.print_options(opt)\n\n        self.opt = opt\n        return self.opt", "\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/options/Options.py", "chunked_list": ["from options.BasicOptions import BaseOptions\n\n\nclass Options_x(BaseOptions):\n    \"\"\"This class includes training options.\n\n    It also includes shared options defined in BaseOptions.\n    \"\"\"\n\n    def initialize(self, parser):\n        parser = BaseOptions.initialize(self, parser)\n        parser.add_argument('--name', type=str, default='Tumor_seg', help='name_of_the_project')\n        self.isTrain = True\n        return parser", ""]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/dataset/dataset_lits_test.py", "chunked_list": ["import numpy as np\nimport torch, os\nfrom torch.utils.data import Dataset\nimport random\nimport SimpleITK as sitk\n\n\ndef min_max_normalization(img):\n    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n    return out", "\n\ndef normalization(img, lmin=1, rmax=None, dividend=None, quantile=None):\n    newimg = img.copy()\n    newimg = newimg.astype(np.float32)\n    if quantile is not None:\n        maxval = round(np.percentile(newimg, 100 - quantile))\n        minval = round(np.percentile(newimg, quantile))\n        newimg[newimg >= maxval] = maxval\n        newimg[newimg <= minval] = minval\n\n    if lmin is not None:\n        newimg[newimg < lmin] = lmin\n    if rmax is not None:\n        newimg[newimg > rmax] = rmax\n\n    minval = np.min(newimg)\n    if dividend is None:\n        maxval = np.max(newimg)\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n    else:\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n    return newimg", "\n\ndef load(file):\n    itkimage = sitk.ReadImage(file)\n    image = sitk.GetArrayFromImage(itkimage)\n    return image\n\n\ndef maskcor_extract_3d(mask, padding=(5, 5, 5)):\n    p = np.where(mask > 0)\n    a = np.zeros([3, 2], dtype=np.int)\n    for i in range(3):\n        s = p[i].min()\n        e = p[i].max() + 1\n\n        ss = s - padding[i]\n        ee = e + padding[i]\n        if ss < 0:\n            ss = 0\n        if ee > mask.shape[i]:\n            ee = mask.shape[i]\n\n        a[i, 0] = ss\n        a[i, 1] = ee\n    return a", "def maskcor_extract_3d(mask, padding=(5, 5, 5)):\n    p = np.where(mask > 0)\n    a = np.zeros([3, 2], dtype=np.int)\n    for i in range(3):\n        s = p[i].min()\n        e = p[i].max() + 1\n\n        ss = s - padding[i]\n        ee = e + padding[i]\n        if ss < 0:\n            ss = 0\n        if ee > mask.shape[i]:\n            ee = mask.shape[i]\n\n        a[i, 0] = ss\n        a[i, 1] = ee\n    return a", "\n\nclass Img_DataSet(Dataset):\n    def __init__(self, pre, pos, sub, adc, t2w, gt, cut_param):\n        self.pre = pre\n        self.pos = pos\n        self.sub = sub\n        self.adc = adc\n        self.t2w = t2w\n        self.gt = gt\n\n        self.ori_shape = self.pre.shape\n        self.cut_param = cut_param\n\n        self.pre = self.padding_img(self.pre, self.cut_param)\n        self.pre = self.extract_ordered_overlap(self.pre, self.cut_param)\n        self.pos = self.padding_img(self.pos, self.cut_param)\n        self.pos = self.extract_ordered_overlap(self.pos, self.cut_param)\n        self.sub = self.padding_img(self.sub, self.cut_param)\n        self.sub = self.extract_ordered_overlap(self.sub, self.cut_param)\n        self.adc = self.padding_img(self.adc, self.cut_param)\n        self.adc = self.extract_ordered_overlap(self.adc, self.cut_param)\n        self.t2w = self.padding_img(self.t2w, self.cut_param)\n        self.t2w = self.extract_ordered_overlap(self.t2w, self.cut_param)\n        self.gt = self.padding_img(self.gt, self.cut_param)\n        self.gt = self.extract_ordered_overlap(self.gt, self.cut_param)\n\n        self.new_shape = self.pre.shape\n\n    def __getitem__(self, index):\n        pre = self.pre[index]\n        pos = self.pos[index]\n        sub = self.sub[index]\n        adc = self.adc[index]\n        t2w = self.t2w[index]\n        gt = self.gt[index]\n\n        return torch.from_numpy(pre), torch.from_numpy(pos), torch.from_numpy(sub), torch.from_numpy(\n            adc), torch.from_numpy(t2w), torch.from_numpy(gt)\n\n    def __len__(self):\n        return len(self.pre)\n\n    def padding_img(self, img, C):\n        assert (len(img.shape) == 3)  # 3D array\n        img_s, img_h, img_w = img.shape\n        leftover_s = (img_s - C['patch_s']) % C['stride_s']\n        leftover_h = (img_h - C['patch_h']) % C['stride_h']\n        leftover_w = (img_w - C['patch_w']) % C['stride_w']\n        if (leftover_s != 0):\n            s = img_s + (C['stride_s'] - leftover_s)\n        else:\n            s = img_s\n\n        if (leftover_h != 0):\n            h = img_h + (C['stride_h'] - leftover_h)\n        else:\n            h = img_h\n\n        if (leftover_w != 0):\n            w = img_w + (C['stride_w'] - leftover_w)\n        else:\n            w = img_w\n\n        tmp_full_imgs = np.zeros((s, h, w))\n        tmp_full_imgs[:img_s, :img_h, 0:img_w] = img\n        return tmp_full_imgs\n\n    def extract_ordered_overlap(self, img, C):\n        assert (len(img.shape) == 3)  # 3D arrays\n        img_s, img_h, img_w = img.shape\n        assert ((img_h - C['patch_h']) % C['stride_h'] == 0\n                and (img_w - C['patch_w']) % C['stride_w'] == 0\n                and (img_s - C['patch_s']) % C['stride_s'] == 0)\n        N_patches_s = (img_s - C['patch_s']) // C['stride_s'] + 1\n        N_patches_h = (img_h - C['patch_h']) // C['stride_h'] + 1\n        N_patches_w = (img_w - C['patch_w']) // C['stride_w'] + 1\n        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n        patches = np.empty((N_patches_img, C['patch_s'], C['patch_h'], C['patch_w']))\n        iter_tot = 0\n        for s in range(N_patches_s):  # loop over the full images\n            for h in range(N_patches_h):\n                for w in range(N_patches_w):\n                    patch = img[s * C['stride_s']: s * C['stride_s'] + C['patch_s'],\n                            h * C['stride_h']: h * C['stride_h'] + C['patch_h'],\n                            w * C['stride_w']: w * C['stride_w'] + C['patch_w']]\n\n                    patches[iter_tot] = patch\n                    iter_tot += 1  # total\n        assert (iter_tot == N_patches_img)\n        return patches  # array with all the full_imgs divided in patches", "\n\nclass Recompone_tool():\n    def __init__(self, img_ori_shape, img_new_shape, Cut_para):\n        self.result = None\n        self.ori_shape = img_ori_shape\n        self.new_shape = img_new_shape\n        self.C = Cut_para\n\n    def add_result(self, tensor):\n        if self.result is not None:\n            self.result = torch.cat((self.result, tensor), dim=0)\n        else:\n            self.result = tensor\n\n    def recompone_overlap(self):\n        \"\"\"\n        :param preds: output of model  shape\uff1a[N_patchs_img,3,patch_s,patch_h,patch_w]\n        :return: result of recompone output shape: [3,img_s,img_h,img_w]\n        \"\"\"\n        patch_s = self.result.shape[2]\n        patch_h = self.result.shape[3]\n        patch_w = self.result.shape[4]\n        N_patches_s = (self.new_shape[0] - patch_s) // self.C['stride_s'] + 1\n        N_patches_h = (self.new_shape[1] - patch_h) // self.C['stride_h'] + 1\n        N_patches_w = (self.new_shape[2] - patch_w) // self.C['stride_w'] + 1\n\n        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n        assert (self.result.shape[0] == N_patches_img)\n\n        full_prob = torch.zeros((self.new_shape[0], self.new_shape[1],\n                                 self.new_shape[2]))\n        full_sum = torch.zeros((self.new_shape[0], self.new_shape[1], self.new_shape[2]))\n        k = 0\n        for s in range(N_patches_s):\n            for h in range(N_patches_h):\n                for w in range(N_patches_w):\n                    full_prob[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += self.result[k].squeeze()\n                    full_sum[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += 1\n                    k += 1\n        assert (k == self.result.size(0))\n        assert (torch.min(full_sum) >= 1.0)  # at least one\n        final_avg = full_prob / full_sum\n        img = final_avg[:self.ori_shape[0], :self.ori_shape[1], :self.ori_shape[2]]\n        return img", "\n\ndef cal_newshape(img, C):\n    assert (len(img.shape) == 3)  # 3D array\n    img_s, img_h, img_w = img.shape\n    leftover_s = (img_s - C['patch_s']) % C['stride_s']\n    leftover_h = (img_h - C['patch_h']) % C['stride_h']\n    leftover_w = (img_w - C['patch_w']) % C['stride_w']\n    if (leftover_s != 0):\n        s = img_s + (C['stride_s'] - leftover_s)\n    else:\n        s = img_s\n\n    if (leftover_h != 0):\n        h = img_h + (C['stride_h'] - leftover_h)\n    else:\n        h = img_h\n\n    if (leftover_w != 0):\n        w = img_w + (C['stride_w'] - leftover_w)\n    else:\n        w = img_w\n\n    return np.zeros((s, h, w)).shape", "\n\ndef Test_all_Datasets(dataset_path, size, flag):\n    f = open(os.path.join(dataset_path, 'train.txt'))\n    data_list = f.read().splitlines()\n    print(\"The number of test samples is: \", len(data_list))\n    for file in data_list:\n        print(\"\\nStart Evaluate: \", file)\n        pre = normalization(load(os.path.join(dataset_path, file, 'DCE0.nii.gz'))).astype(np.float32)\n        pos = normalization(load(os.path.join(dataset_path, file, 'DCE.nii.gz'))).astype(np.float32)\n        sub = pos - pre\n        if flag == 'all_true':\n            adc = normalization(load(os.path.join(dataset_path, file, 'ADC.nii.gz'))).astype(np.float32)\n            t2w = normalization(load(os.path.join(dataset_path, file, 'T2.nii.gz'))).astype(np.float32)\n        elif flag == 'fake_adc':\n            adc = load(os.path.join(dataset_path, file, 'ADC_syn.nii.gz')).astype(np.float32)\n            t2w = normalization(load(os.path.join(dataset_path, file, 'T2.nii.gz'))).astype(np.float32)\n        elif flag == 'fake_t2':\n            adc = normalization(load(os.path.join(dataset_path, file, 'ADC.nii.gz'))).astype(np.float32)\n            t2w = load(os.path.join(dataset_path, file, 'T2_syn.nii.gz')).astype(np.float32)\n        elif flag == 'all_fake':\n            adc = load(os.path.join(dataset_path, file, 'ADC_syn.nii.gz')).astype(np.float32)\n            t2w = load(os.path.join(dataset_path, file, 'T2_syn.nii.gz')).astype(np.float32)\n\n        gt = load(os.path.join(dataset_path, file, 'GT.nii.gz')).astype(np.int16)\n        breast_mask = load(os.path.join(dataset_path, file, 'Breast_mask.nii.gz')).astype(np.int16)\n        original_shape = gt.shape\n        new_shape = cal_newshape(gt, size)\n\n        yield Img_DataSet(pre, pos, sub, adc, t2w, gt, size), original_shape, new_shape, breast_mask, file", ""]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/dataset/dataset_lits_val.py", "chunked_list": ["import random\nimport numpy as np\nimport SimpleITK as sitk\nimport os\nfrom torch.utils.data import Dataset\n\n\nclass Val_DataSet(Dataset):\n    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n        self.root = root\n        self.size = size\n        self.sample_index = sample_index\n        f = open(os.path.join(self.root, 'val.txt'))\n        self.filename = f.read().splitlines()\n\n    def __getitem__(self, index):\n\n        file = self.filename[index]\n        DCE0 = self.normalization(self.load(os.path.join(self.root, file, 'DCE0.nii.gz'))).astype(np.float32)\n        DCE = self.normalization(self.load(os.path.join(self.root, file, 'DCE.nii.gz'))).astype(np.float32)\n        sub = DCE - DCE0\n        ADC = self.normalization(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n        T2W = self.normalization(self.load(os.path.join(self.root, file, 'T2.nii.gz'))).astype(np.float32)\n        ADC_syn = self.load(os.path.join(self.root, file, 'ADC_syn.nii.gz')).astype(np.float32)\n        T2W_syn = self.load(os.path.join(self.root, file, 'T2_syn.nii.gz')).astype(np.float32)\n        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\n        DCE0_patch, DCE_patch, sub_patch, ADC_patch, T2W_patch, ADC_syn_patch, T2W_syn_patch, gt_patch = [], [], [], [], [], [], [], []\n        for i in range(3):\n            if i == 1:\n                DCE0_patch1, DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, ADC_syn_patch1, T2W_syn_patch1, gt_patch1 = self.random_crop_3d_contain(\n                    DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt, self.size)\n            else:\n                DCE0_patch1, DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, ADC_syn_patch1, T2W_syn_patch1, gt_patch1 = self.random_crop_3d_partial(\n                    DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt, self.size)\n\n            DCE0_patch.append(DCE0_patch1), DCE_patch.append(DCE_patch1), sub_patch.append(\n                sub_patch1), ADC_patch.append(ADC_patch1), T2W_patch.append(T2W_patch1), ADC_syn_patch.append(\n                ADC_syn_patch1), T2W_syn_patch.append(T2W_syn_patch1), gt_patch.append(gt_patch1)\n\n        return np.array(DCE0_patch), np.array(DCE_patch), np.array(sub_patch), np.array(ADC_patch), np.array(\n            T2W_patch), np.array(ADC_syn_patch), np.array(T2W_syn_patch), np.array(gt_patch)\n\n    def __len__(self):\n        return len(self.filename)\n\n    def random_crop_3d_contain(self, a, b, c, d, e, f, g, gt, crop_size):\n\n        cor_box = self.maskcor_extract_3d(gt)\n        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n        if random_x_min > random_x_max:\n            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n        if random_y_min > random_y_max:\n            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n        if random_z_min > random_z_max:\n            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\n    def random_crop_3d_partial(self, a, b, c, d, e, f, g, gt, crop_size):\n\n        cor_box = self.maskcor_extract_3d(gt)\n        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\n    def min_max_normalization(self, img):\n        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n        return out\n\n    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if quantile is not None:\n            maxval = round(np.percentile(newimg, 100 - quantile))\n            minval = round(np.percentile(newimg, quantile))\n            newimg[newimg >= maxval] = maxval\n            newimg[newimg <= minval] = minval\n\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n        if rmax is not None:\n            newimg[newimg > rmax] = rmax\n\n        minval = np.min(newimg)\n        if dividend is None:\n            maxval = np.max(newimg)\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        else:\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n        return newimg\n\n    def load(self, file):\n        itkimage = sitk.ReadImage(file)\n        image = sitk.GetArrayFromImage(itkimage)\n        return image\n\n    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n        # mask_s = mask.shape\n        if np.sum(mask) == 0:\n            mask[10:12, 100:102, 100:102] = 1\n\n        p = np.where(mask > 0)\n        a = np.zeros([3, 2], dtype=np.int)\n        for i in range(3):\n            s = p[i].min()\n            e = p[i].max() + 1\n\n            ss = s - padding[i]\n            ee = e + padding[i]\n            if ss < 0:\n                ss = 0\n            if ee > mask.shape[i]:\n                ee = mask.shape[i]\n\n            a[i, 0] = ss\n            a[i, 1] = ee\n        return a", ""]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/dataset/dataset_lits_train.py", "chunked_list": ["import random\nimport numpy as np\nimport SimpleITK as sitk\nimport os\nfrom torch.utils.data import Dataset\n\n\nclass Lits_DataSet(Dataset):\n    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n        self.root = root\n        self.size = size\n        self.sample_index = sample_index\n        f = open(os.path.join(self.root, 'train.txt'))\n        self.filename = f.read().splitlines()\n\n    def __getitem__(self, index):\n\n        file = self.filename[index]\n        DCE0 = self.normalization(self.load(os.path.join(self.root, file, 'DCE0.nii.gz'))).astype(np.float32)\n        DCE = self.normalization(self.load(os.path.join(self.root, file, 'DCE.nii.gz'))).astype(np.float32)\n        sub = DCE - DCE0\n        ADC = self.normalization(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n        T2W = self.normalization(self.load(os.path.join(self.root, file, 'T2.nii.gz'))).astype(np.float32)\n        ADC_syn = self.load(os.path.join(self.root, file, 'ADC_syn.nii.gz')).astype(np.float32)\n        T2W_syn = self.load(os.path.join(self.root, file, 'T2_syn.nii.gz')).astype(np.float32)\n        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\n        DCE0_patch, DCE_patch, sub_patch, ADC_patch, T2W_patch, ADC_syn_patch, T2W_syn_patch, gt_patch = [], [], [], [], [], [], [], []\n        for i in range(3):\n            if i == 1:\n                DCE0_patch1, DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, ADC_syn_patch1, T2W_syn_patch1, gt_patch1 = self.random_crop_3d_contain(\n                    DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt, self.size)\n            else:\n                DCE0_patch1, DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, ADC_syn_patch1, T2W_syn_patch1, gt_patch1 = self.random_crop_3d_partial(\n                    DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt, self.size)\n\n            DCE0_patch.append(DCE0_patch1), DCE_patch.append(DCE_patch1), sub_patch.append(\n                sub_patch1), ADC_patch.append(ADC_patch1), T2W_patch.append(T2W_patch1), ADC_syn_patch.append(\n                ADC_syn_patch1), T2W_syn_patch.append(T2W_syn_patch1), gt_patch.append(gt_patch1)\n\n        return np.array(DCE0_patch), np.array(DCE_patch), np.array(sub_patch), np.array(ADC_patch), np.array(\n            T2W_patch), np.array(ADC_syn_patch), np.array(T2W_syn_patch), np.array(gt_patch)\n\n    def __len__(self):\n        return len(self.filename)\n\n    def random_crop_3d_contain(self, a, b, c, d, e, f, g, gt, crop_size):\n\n        cor_box = self.maskcor_extract_3d(gt)\n        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n        if random_x_min > random_x_max:\n            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n        if random_y_min > random_y_max:\n            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n        if random_z_min > random_z_max:\n            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\n    def random_crop_3d_partial(self, a, b, c, d, e, f, g, gt, crop_size):\n\n        cor_box = self.maskcor_extract_3d(gt)\n        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\n    def min_max_normalization(self, img):\n        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n        return out\n\n    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if quantile is not None:\n            maxval = round(np.percentile(newimg, 100 - quantile))\n            minval = round(np.percentile(newimg, quantile))\n            newimg[newimg >= maxval] = maxval\n            newimg[newimg <= minval] = minval\n\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n        if rmax is not None:\n            newimg[newimg > rmax] = rmax\n\n        minval = np.min(newimg)\n        if dividend is None:\n            maxval = np.max(newimg)\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        else:\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n        return newimg\n\n    def load(self, file):\n        itkimage = sitk.ReadImage(file)\n        image = sitk.GetArrayFromImage(itkimage)\n        return image\n\n    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n        # mask_s = mask.shape\n        if np.sum(mask) == 0:\n            mask[10:12, 100:102, 100:102] = 1\n\n        p = np.where(mask > 0)\n        a = np.zeros([3, 2], dtype=np.int)\n        for i in range(3):\n            s = p[i].min()\n            e = p[i].max() + 1\n\n            ss = s - padding[i]\n            ee = e + padding[i]\n            if ss < 0:\n                ss = 0\n            if ee > mask.shape[i]:\n                ee = mask.shape[i]\n\n            a[i, 0] = ss\n            a[i, 1] = ee\n        return a", ""]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/Model/networks.py", "chunked_list": ["# x: 128x128 resolution for 32 frames.\nimport torch\nimport torch.nn as nn\n\nbasic_dims = 8\ntransformer_basic_dims = 512\nmlp_dim = 4096\nnum_heads = 8\ndepth = 1\nnum_modals = 3", "depth = 1\nnum_modals = 3\npatch_size = [2, 8, 8]\n\ndef normalization(planes, norm='bn'):\n    if norm == 'bn':\n        m = nn.BatchNorm3d(planes)\n    elif norm == 'gn':\n        m = nn.GroupNorm(4, planes)\n    elif norm == 'in':\n        m = nn.InstanceNorm3d(planes)\n    else:\n        raise ValueError('normalization type {} is not supported'.format(norm))\n    return m", "\nclass general_conv3d_prenorm(nn.Module):\n    def __init__(self, in_ch, out_ch, k_size=3, stride=1, padding=1, pad_type='zeros', norm='in', is_training=True,\n                 act_type='lrelu', relufactor=0.2):\n        super(general_conv3d_prenorm, self).__init__()\n        self.conv = nn.Conv3d(in_channels=in_ch, out_channels=out_ch, kernel_size=k_size, stride=stride,\n                              padding=padding, padding_mode=pad_type, bias=True)\n\n        self.norm = normalization(out_ch, norm=norm)\n        if act_type == 'relu':\n            self.activation = nn.ReLU(inplace=True)\n        elif act_type == 'lrelu':\n            self.activation = nn.LeakyReLU(negative_slope=relufactor, inplace=True)\n\n    def forward(self, x):\n        x = self.norm(x)\n        x = self.activation(x)\n        x = self.conv(x)\n        return x", "\n\nclass fusion_prenorm(nn.Module):\n    def __init__(self, in_channel=64, num_cls=1):\n        super(fusion_prenorm, self).__init__()\n        self.fusion_layer = nn.Sequential(\n            general_conv3d_prenorm(in_channel * num_modals, in_channel, k_size=1, padding=0, stride=1),\n            general_conv3d_prenorm(in_channel, in_channel, k_size=3, padding=1, stride=1),\n            general_conv3d_prenorm(in_channel, in_channel, k_size=1, padding=0, stride=1))\n\n    def forward(self, x):\n        return self.fusion_layer(x)", "\n\nclass Encoder(nn.Module):\n    def __init__(self, flag=True):\n        super(Encoder, self).__init__()\n        if flag:\n            self.e1_c1 = nn.Conv3d(in_channels=1, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n                                   padding_mode='zeros', bias=True)\n        else:\n            self.e1_c1 = nn.Conv3d(in_channels=2, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n                                   padding_mode='zeros', bias=True)\n        self.e1_c2 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n        self.e1_c3 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n\n        self.e2_c1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n        self.e2_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n        self.e2_c3 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\n        self.e3_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n        self.e3_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n        self.e3_c3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n\n        self.e4_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n        self.e4_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n        self.e4_c3 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n\n        self.e5_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n        self.e5_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n        self.e5_c3 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\n    def forward(self, x):\n        x1 = self.e1_c1(x)\n        x1 = x1 + self.e1_c3(self.e1_c2(x1))\n\n        x2 = self.e2_c1(x1)\n        x2 = x2 + self.e2_c3(self.e2_c2(x2))\n\n        x3 = self.e3_c1(x2)\n        x3 = x3 + self.e3_c3(self.e3_c2(x3))\n\n        x4 = self.e4_c1(x3)\n        x4 = x4 + self.e4_c3(self.e4_c2(x4))\n\n        x5 = self.e5_c1(x4)\n        x5 = x5 + self.e5_c3(self.e5_c2(x5))\n\n        return x1, x2, x3, x4, x5", "\nclass Decoder_fuse(nn.Module):\n    def __init__(self, num_cls=4):\n        super(Decoder_fuse, self).__init__()\n\n        self.d4_c1 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n        self.d4_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n        self.d4_out = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, k_size=1, padding=0, pad_type='zeros')\n\n        self.d3_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n        self.d3_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n        self.d3_out = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, k_size=1, padding=0, pad_type='zeros')\n\n        self.d2_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n        self.d2_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n        self.d2_out = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, k_size=1, padding=0, pad_type='zeros')\n\n        self.d1_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n        self.d1_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n        self.d1_out = general_conv3d_prenorm(basic_dims, basic_dims, k_size=1, padding=0, pad_type='zeros')\n\n        self.seg_d4 = nn.Conv3d(in_channels=basic_dims * 16, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                bias=True)\n        self.seg_d3 = nn.Conv3d(in_channels=basic_dims * 8, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                bias=True)\n        self.seg_d2 = nn.Conv3d(in_channels=basic_dims * 4, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                bias=True)\n        self.seg_d1 = nn.Conv3d(in_channels=basic_dims * 2, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                bias=True)\n        self.seg_layer = nn.Conv3d(in_channels=basic_dims, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                   bias=True)\n        self.softmax = nn.Softmax(dim=1)\n\n        self.up2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n        self.RFM5 = fusion_prenorm(in_channel=basic_dims * 16, num_cls=num_cls)\n        self.RFM4 = fusion_prenorm(in_channel=basic_dims * 8, num_cls=num_cls)\n        self.RFM3 = fusion_prenorm(in_channel=basic_dims * 4, num_cls=num_cls)\n        self.RFM2 = fusion_prenorm(in_channel=basic_dims * 2, num_cls=num_cls)\n        self.RFM1 = fusion_prenorm(in_channel=basic_dims * 1, num_cls=num_cls)\n\n    def forward(self, x1, x2, x3, x4, x5):\n\n        de_x5 = self.RFM5(x5)\n        de_x5 = self.d4_c1(self.up2(de_x5))\n\n        de_x4 = self.RFM4(x4)\n        de_x4 = torch.cat((de_x4, de_x5), dim=1)\n        de_x4 = self.d4_out(self.d4_c2(de_x4))\n        de_x4 = self.d3_c1(self.up2(de_x4))\n\n        de_x3 = self.RFM3(x3)\n        de_x3 = torch.cat((de_x3, de_x4), dim=1)\n        de_x3 = self.d3_out(self.d3_c2(de_x3))\n        de_x3 = self.d2_c1(self.up2(de_x3))\n\n        de_x2 = self.RFM2(x2)\n        de_x2 = torch.cat((de_x2, de_x3), dim=1)\n        de_x2 = self.d2_out(self.d2_c2(de_x2))\n        de_x2 = self.d1_c1(self.up2(de_x2))\n\n        de_x1 = self.RFM1(x1)\n        de_x1 = torch.cat((de_x1, de_x2), dim=1)\n        de_x1 = self.d1_out(self.d1_c2(de_x1))\n\n        logits = self.seg_layer(de_x1)\n        pred = torch.sigmoid(logits)\n\n        return pred", "\n\nclass RUnet(nn.Module):\n    def __init__(self, num_cls=1):\n        super(RUnet, self).__init__()\n        self.DCE_encoder = Encoder(flag=False)\n        self.ADC_encoder = Encoder(flag=True)\n        self.T2_encoder = Encoder(flag=True)\n\n        self.decoder_fuse = Decoder_fuse(num_cls=num_cls)\n\n        self.is_training = True\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                torch.nn.init.kaiming_normal_(m.weight)\n\n    def forward(self, x):\n        DCE_x1, DCE_x2, DCE_x3, DCE_x4, DCE_x5 = self.DCE_encoder(x[:, 0:2, :, :, :])\n        ADC_x1, ADC_x2, ADC_x3, ADC_x4, ADC_x5 = self.ADC_encoder(x[:, 2:3, :, :, :])\n        T2_x1, T2_x2, T2_x3, T2_x4, T2_x5 = self.T2_encoder(x[:, 3:4, :, :, :])\n\n        x1 = torch.cat((DCE_x1, ADC_x1, T2_x1), dim=1)\n        x2 = torch.cat((DCE_x2, ADC_x2, T2_x2), dim=1)\n        x3 = torch.cat((DCE_x3, ADC_x3, T2_x3), dim=1)\n        x4 = torch.cat((DCE_x4, ADC_x4, T2_x4), dim=1)\n        x5 = torch.cat((DCE_x5, ADC_x5, T2_x5), dim=1)\n\n        fuse_pred = self.decoder_fuse(x1, x2, x3, x4, x5)\n\n        return fuse_pred", "\n"]}
{"filename": "Step3-Tumor-Segmentation/train.py", "chunked_list": ["import torch\nimport numpy as np\nimport torch.optim as optim\nfrom options.Options import Options_x\nfrom dataset.dataset_lits_train import Lits_DataSet\nfrom dataset.dataset_lits_val import Val_DataSet\nfrom Model.networks import MoSID\nfrom torch.utils.data import DataLoader\nfrom utils.common import adjust_learning_rate\nfrom utils import logger, util", "from utils.common import adjust_learning_rate\nfrom utils import logger, util\nfrom utils.metrics import LossAverage, DiceLoss\nimport os\nimport time\nfrom test import test_all\nfrom collections import OrderedDict\n\ndef val(val_dataloader, epoch):\n    since = time.time()\n\n    Loss = LossAverage()\n    DICE_Loss = LossAverage()\n    BCE_Loss = LossAverage()\n\n    for i, (DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt) in enumerate(val_dataloader):\n        b, c, l, w, e = DCE.shape[0], DCE.shape[1], DCE.shape[2], DCE.shape[3], DCE.shape[4]\n\n        DCE = DCE.view(-1, 1, l, w, e).to(device)\n        sub = sub.view(-1, 1, l, w, e).to(device)\n        ADC = ADC.view(-1, 1, l, w, e).to(device)\n        T2W = T2W.view(-1, 1, l, w, e).to(device)\n        Infor_DCE = Infor_DCE.view(-1, 1, l, w, e).to(device)\n        Infor_ADC = Infor_ADC.view(-1, 1, l, w, e).to(device)\n        Infor_T2 = Infor_T2.view(-1, 1, l, w, e).to(device)\n        gt = gt.view(-1, 1, l, w, e).to(device)\n\n        pred = model(DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2)\n\n        Dice_loss = dice_loss(pred, gt)\n        Bce_loss = bce_loss(pred, gt)\n\n        loss = Bce_loss + 5 * Dice_loss\n\n        Loss.update(loss.item(), DCE.size(0))\n        DICE_Loss.update(Dice_loss.item(), DCE.size(0))\n        BCE_Loss.update(Bce_loss.item(), DCE.size(0))\n    time_elapsed = time.time() - since\n    print(\"=======Val Epoch:{}======Learning_rate:{}======Validate complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})", "def val(val_dataloader, epoch):\n    since = time.time()\n\n    Loss = LossAverage()\n    DICE_Loss = LossAverage()\n    BCE_Loss = LossAverage()\n\n    for i, (DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt) in enumerate(val_dataloader):\n        b, c, l, w, e = DCE.shape[0], DCE.shape[1], DCE.shape[2], DCE.shape[3], DCE.shape[4]\n\n        DCE = DCE.view(-1, 1, l, w, e).to(device)\n        sub = sub.view(-1, 1, l, w, e).to(device)\n        ADC = ADC.view(-1, 1, l, w, e).to(device)\n        T2W = T2W.view(-1, 1, l, w, e).to(device)\n        Infor_DCE = Infor_DCE.view(-1, 1, l, w, e).to(device)\n        Infor_ADC = Infor_ADC.view(-1, 1, l, w, e).to(device)\n        Infor_T2 = Infor_T2.view(-1, 1, l, w, e).to(device)\n        gt = gt.view(-1, 1, l, w, e).to(device)\n\n        pred = model(DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2)\n\n        Dice_loss = dice_loss(pred, gt)\n        Bce_loss = bce_loss(pred, gt)\n\n        loss = Bce_loss + 5 * Dice_loss\n\n        Loss.update(loss.item(), DCE.size(0))\n        DICE_Loss.update(Dice_loss.item(), DCE.size(0))\n        BCE_Loss.update(Bce_loss.item(), DCE.size(0))\n    time_elapsed = time.time() - since\n    print(\"=======Val Epoch:{}======Learning_rate:{}======Validate complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})", "\n\ndef train(train_dataloader, epoch):\n    since = time.time()\n\n    Loss = LossAverage()\n    DICE_Loss = LossAverage()\n    BCE_Loss = LossAverage()\n\n    model.train()\n\n    for i, (DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt) in enumerate(train_dataloader):  # inner loop within one epoch\n        b, c, l, w, e = DCE.shape[0], DCE.shape[1], DCE.shape[2], DCE.shape[3], DCE.shape[4]\n\n        DCE = DCE.view(-1, 1, l, w, e).to(device)\n        sub = sub.view(-1, 1, l, w, e).to(device)\n        ADC = ADC.view(-1, 1, l, w, e).to(device)\n        T2W = T2W.view(-1, 1, l, w, e).to(device)\n        Infor_DCE = Infor_DCE.view(-1, 1, l, w, e).to(device)\n        Infor_ADC = Infor_ADC.view(-1, 1, l, w, e).to(device)\n        Infor_T2 = Infor_T2.view(-1, 1, l, w, e).to(device)\n        gt = gt.view(-1, 1, l, w, e).to(device)\n\n        pred = model(DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2)\n\n        Dice_loss = dice_loss(pred, gt)\n        Bce_loss = bce_loss(pred, gt)\n\n        loss = Bce_loss + 5 * Dice_loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        adjust_learning_rate(optimizer, epoch, opt)\n\n        Loss.update(loss.item(), DCE.size(0))\n        DICE_Loss.update(Dice_loss.item(), DCE.size(0))\n        BCE_Loss.update(Bce_loss.item(), DCE.size(0))\n    time_elapsed = time.time() - since\n    print(\"=======Train Epoch:{}======Learning_rate:{}======Train complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})", "\n\nif __name__ == '__main__':\n    opt = Options_x().parse()  # get training options\n    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n    print(\"using {} device.\".format(device))\n\n    model = MoSID().to(device)\n\n    save_path = opt.checkpoints_dir\n    dice_loss = DiceLoss()\n    bce_loss = torch.nn.BCEWithLogitsLoss()\n\n    save_result_path = os.path.join(save_path, opt.task_name)\n    util.mkdir(save_result_path)\n\n    optimizer = optim.Adam(model.parameters(), lr=opt.lr, weight_decay=1e-5)\n    model_save_path = os.path.join(save_result_path, 'model')\n    util.mkdir(model_save_path)\n    logger_save_path = os.path.join(save_result_path, 'logger')\n    util.mkdir(logger_save_path)\n\n    log_train = logger.Train_Logger(logger_save_path, \"train_log\")\n    log_val = logger.Val_Logger(logger_save_path, \"val_log\")\n\n    train_dataset = Lits_DataSet(opt.datapath, opt.patch_size)\n    val_dataset = Val_DataSet(opt.datapath, opt.patch_size)\n\n    train_dataloader = DataLoader(dataset=train_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads,\n                                  shuffle=True)\n    val_dataloader = DataLoader(dataset=val_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads,\n                                shuffle=True)\n\n    types = ['train', 'val']\n    val_dice_loss = 99\n    best_epoch = 0\n\n    for epoch in range(opt.epoch):\n        epoch = epoch + 1\n        for type in types:\n            if type == 'train':\n                train_log = train(train_dataloader, epoch)\n                log_train.update(epoch, train_log)\n            elif type == 'val':\n                val_log = val(val_dataloader, epoch)\n                log_val.update(epoch, val_log)\n                if val_log['DICE_Loss'] < val_dice_loss:\n                    best_epoch = epoch\n                    val_dice_loss = val_log['DICE_Loss']\n                    state = {'model': model.state_dict(), 'epoch': best_epoch}\n                    torch.save(state, os.path.join(model_save_path, 'best_model.pth'))\n\n        state = {'model': model.state_dict(), 'epoch': epoch}\n        torch.save(state, os.path.join(model_save_path, 'latest_model.pth'))\n\n        if epoch % opt.model_save_fre == 0:\n            torch.save(state, os.path.join(model_save_path, 'model_' + np.str(epoch) + '.pth'))\n\n        torch.cuda.empty_cache()\n\n    test_all('best_model.pth')", ""]}
{"filename": "Step3-Tumor-Segmentation/test.py", "chunked_list": ["import torch\nimport gc\nimport numpy as np\nimport SimpleITK as sitk\nfrom options.Options import Options_x\nfrom tqdm import tqdm\nfrom Model.networks import MoSID\nfrom torch.utils.data import DataLoader\nfrom utils import logger, util\nfrom utils.metrics import seg_metric", "from utils import logger, util\nfrom utils.metrics import seg_metric\nimport os\nfrom dataset.dataset_lits_test import Test_all_Datasets, Recompone_tool\nfrom collections import OrderedDict\n\n\ndef load(file):\n    itkimage = sitk.ReadImage(file)\n    image = sitk.GetArrayFromImage(itkimage)\n    return image", "\n\ndef test_all(model_name='model_200.pth'):\n    opt = Options_x().parse()  # get training options\n    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n    print(\"using {} device.\".format(device))\n\n    model = MoSID().to(device)\n    ckpt = torch.load(opt.checkpoints_dir + '/' + opt.task_name + '/model/' + model_name, map_location=device)\n    model.load_state_dict(ckpt['model'])\n\n    save_result_path = os.path.join(opt.checkpoints_dir, opt.task_name, 'test_all_result')\n    util.mkdir(save_result_path)\n    model.eval()\n    log_test = logger.Test_Logger(save_result_path, \"results\")\n    cut_param = {'patch_s': opt.patch_size[0], 'patch_h': opt.patch_size[1], 'patch_w': opt.patch_size[2],\n                 'stride_s': opt.patch_stride[0], 'stride_h': opt.patch_stride[1], 'stride_w': opt.patch_stride[2]}\n    datasets = Test_all_Datasets(opt.datapath, cut_param)\n\n    for img_dataset, original_shape, new_shape, mask, file_idx, crop_box in datasets:\n        save_tool = Recompone_tool(original_shape, new_shape, cut_param)\n        dataloader = DataLoader(img_dataset, batch_size=opt.test_batch, num_workers=opt.num_threads, shuffle=False)\n        with torch.no_grad():\n            for pos, sub, adc, t2w, p_all_fake, p_fake_adc, p_fake_t2, gt in tqdm(dataloader):\n                pos, sub, adc, t2w, p_all_fake, p_fake_adc, p_fake_t2, gt = pos.to(device), sub.to(device), adc.to(\n                    device), t2w.to(device), p_all_fake.to(device), p_fake_adc.to(device), p_fake_t2.to(device), gt.to(\n                    device)\n\n                pos = pos.unsqueeze(1).type(torch.float32)\n                sub = sub.unsqueeze(1).type(torch.float32)\n                adc = adc.unsqueeze(1).type(torch.float32)\n                t2w = t2w.unsqueeze(1).type(torch.float32)\n                p_all_fake = p_all_fake.unsqueeze(1).type(torch.float32)\n                p_fake_adc = p_fake_adc.unsqueeze(1).type(torch.float32)\n                p_fake_t2 = p_fake_t2.unsqueeze(1).type(torch.float32)\n\n                output = model(pos, sub, adc, t2w, p_all_fake, p_fake_adc, p_fake_t2)\n                output = (output >= 0.5).type(torch.float32)\n                save_tool.add_result(output.detach().cpu())\n\n        pred = save_tool.recompone_overlap()\n        recon = (pred.numpy() > 0.5).astype(np.uint16)\n\n        pred_coarse = load(os.path.join(opt.datapath, file_idx, 'pred_coarse.nii.gz'))\n        pred_coarse[crop_box[0, 0]:crop_box[0, 1], crop_box[1, 0]:crop_box[1, 1], crop_box[2, 0]:crop_box[2, 1]] = recon\n\n        if np.sum(pred_coarse) < 15:\n            pred_coarse = load(os.path.join(opt.datapath, file_idx, 'pred_coarse.nii.gz'))\n\n        pred_coarse = pred_coarse * mask\n\n        gt = load(os.path.join(opt.datapath, file_idx, 'GT.nii.gz'))\n        DSC, PPV, SEN, ASD = seg_metric(pred_coarse, gt)\n        index_results = OrderedDict({'DSC': DSC, 'PPV': PPV, 'SEN': SEN, 'ASD': ASD})\n        log_test.update(file_idx, index_results)\n        Pred = sitk.GetImageFromArray(np.array(pred_coarse))\n        result_save_path = os.path.join(save_result_path, file_idx)\n        util.mkdir(result_save_path)\n        sitk.WriteImage(Pred, os.path.join(result_save_path, 'pred.nii.gz'))\n        del pred, recon, Pred, save_tool, pred_coarse, gt\n        gc.collect()\n        torch.cuda.empty_cache()", "\n\nif __name__ == '__main__':\n    test_all('best_model.pth')\n\n"]}
{"filename": "Step3-Tumor-Segmentation/options/BasicOptions.py", "chunked_list": ["import argparse\nimport os\nfrom utils import util\nimport torch\n\n\nclass BaseOptions():\n    \"\"\"This class defines options used during both training and test time.\n\n    It also implements several helper functions such as parsing, printing, and saving the options.\n    It also gathers additional options defined in <modify_commandline_options> functions in both dataset class and model class.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"\n        self.initialized = False\n\n    def initialize(self, parser):\n        \"\"\"Define the common options that are used in both training and test.\"\"\"\n        # basic parameters\n        \n        parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n        parser.add_argument('--num_threads', default=1, type=int, help='# threads for loading data')\n        \n        parser.add_argument('--batch_size', type=int, default=1, help='input train batch size')\n        parser.add_argument('--test_batch', type=int, default=1, help='input test batch size')\n        parser.add_argument('--epoch', type=int, default=400, help='number of epochs with the initial learning rate')\n        parser.add_argument('--step', type=int, default=50, help='number of epochs to adjust learning rate')\n        parser.add_argument('--datapath', default=r'/data', help='path of the raw data')\n        parser.add_argument('--lr', type=float, default=0.005, help='initial learning rate of net for adam')\n        parser.add_argument('--model_save_fre', type=int, default=50, help='frequency of saving model') \n        parser.add_argument('--test_fre', type=int, default=600, help='frequency of testing the model')\n        parser.add_argument('--patch_size', type=int, default=(32, 128, 128), help='the size of crop patch')\n        parser.add_argument('--patch_stride', type=int, default=(8, 64, 64), help='the stride of patch')\n        parser.add_argument('--data_folder', type=int, default=4, help='the folder of datasets(1-3) 0 for debug')\n        parser.add_argument('--task_name', type=str, default='MultiModal_Parametric', help='the current task name')\n        self.initialized = True\n        return parser\n\n    def gather_options(self):\n        \"\"\"Initialize our parser with basic options(only once).\n        Add additional model-specific and dataset-specific options.\n        These options are defined in the <modify_commandline_options> function\n        in model and dataset classes.\n        \"\"\"\n        if not self.initialized:  # check if it has been initialized\n            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n            parser = self.initialize(parser)\n\n        # get the basic options\n        opt, _ = parser.parse_known_args()\n        # save and return the parser\n        self.parser = parser\n        return parser.parse_args()\n\n    def print_options(self, opt):\n        \"\"\"Print and save options\n\n        It will print both current options and default values(if different).\n        It will save options into a text file / [checkpoints_dir] / opt.txt\n        \"\"\"\n        message = ''\n        message += '----------------- Options ---------------\\n'\n        for k, v in sorted(vars(opt).items()):\n            comment = ''\n            default = self.parser.get_default(k)\n            if v != default:\n                comment = '\\t[default: %s]' % str(default)\n            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n        message += '----------------- End -------------------'\n        print(message)\n\n        # save to the disk\n        expr_dir = os.path.join(opt.checkpoints_dir, 'model_parameter_list')\n        util.mkdirs(expr_dir)\n        file_name = os.path.join(expr_dir, '{train_opt.txt')\n        with open(file_name, 'wt') as opt_file:\n            opt_file.write(message)\n            opt_file.write('\\n')\n\n    def parse(self):\n        \"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"\n        opt = self.gather_options()\n        opt.isTrain = self.isTrain   # train or test\n\n        self.print_options(opt)\n\n        self.opt = opt\n        return self.opt", "\n"]}
{"filename": "Step3-Tumor-Segmentation/options/Options.py", "chunked_list": ["from options.BasicOptions import BaseOptions\n\n\nclass Options_x(BaseOptions):\n    \"\"\"This class includes training options.\n\n    It also includes shared options defined in BaseOptions.\n    \"\"\"\n\n    def initialize(self, parser):\n        parser = BaseOptions.initialize(self, parser)\n        # visdom and HTML visualization parameters\n        parser.add_argument('--name', type=str, default='Tumor_seg', help='name_of_the_project')\n        self.isTrain = True\n        return parser", ""]}
{"filename": "Step3-Tumor-Segmentation/utils/weights_init.py", "chunked_list": ["from torch.nn import init\n\n\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('Linear') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_xavier(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.xavier_normal(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.xavier_normal(m.weight.data, gain=1)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('Linear') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_orthogonal(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef init_weights(net, init_type='normal'):\n    if init_type == 'normal':\n        net.apply(weights_init_normal)\n    elif init_type == 'xavier':\n        net.apply(weights_init_xavier)\n    elif init_type == 'kaiming':\n        net.apply(weights_init_kaiming)\n    elif init_type == 'orthogonal':\n        net.apply(weights_init_orthogonal)\n    else:\n        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)", ""]}
{"filename": "Step3-Tumor-Segmentation/utils/metrics.py", "chunked_list": ["import torch.nn as nn\nimport torch\nimport numpy as np\nimport sys\nfrom scipy.ndimage import morphology\n\nsys.dont_write_bytecode = True  # don't generate the binray python file .pyc\n\n\nclass LossAverage(object):\n    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = round(self.sum / self.count, 4)", "\nclass LossAverage(object):\n    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = round(self.sum / self.count, 4)", "        # print(self.val)\n\n\nclass DiceLoss(nn.Module):\n    \"\"\"\n    define the dice loss\n    \"\"\"\n\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, input, target):\n        smooth = 1.\n        iflat = input.contiguous().view(-1)\n        tflat = target.contiguous().view(-1)\n        intersection = (iflat * tflat).sum()\n\n        A_sum = torch.sum(iflat * iflat)\n        B_sum = torch.sum(tflat * tflat)\n\n        return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth))", "\n\n\"\"\"dice coefficient\"\"\"\n\n\ndef dice(pre, gt, tid=1):\n    pre = pre == tid  # make it boolean\n    gt = gt == tid  # make it boolean\n    pre = np.asarray(pre).astype(np.bool)\n    gt = np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    dsc = (2. * intersection.sum() + 1e-07) / (pre.sum() + gt.sum() + 1e-07)\n\n    return dsc", "\n\n\"\"\"positive predictive value\"\"\"\n\n\ndef pospreval(pre, gt, tid=1):\n    pre = pre == tid  # make it boolean\n    gt = gt == tid  # make it boolean\n    pre = np.asarray(pre).astype(np.bool)\n    gt = np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    ppv = (1.0 * intersection.sum() + 1e-07) / (pre.sum() + 1e-07)\n\n    return ppv", "\n\n\"\"\"sensitivity\"\"\"\n\n\ndef sensitivity(pre, gt, tid=1):\n    pre = pre == tid  # make it boolean\n    gt = gt == tid  # make it boolean\n    pre = np.asarray(pre).astype(np.bool)\n    gt = np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    sen = (1.0 * intersection.sum() + 1e-07) / (gt.sum() + 1e-07)\n\n    return sen", "\n\n\"\"\"specificity\"\"\"\n\n\ndef specificity(pre, gt):\n    pre = pre == 0  # make it boolean\n    gt = gt == 0  # make it boolean\n    pre = np.asarray(pre).astype(np.bool)\n    gt = np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    spe = (1.0 * intersection.sum() + 1e-07) / (gt.sum() + 1e-07)\n\n    return spe", "\n\n\"\"\"average surface distance\"\"\"\n\n\ndef surfd(pre, gt, tid=1, sampling=1, connectivity=1):\n    pre = pre == tid  # make it boolean\n    gt = gt == tid  # make it boolean\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    input_1 = np.atleast_1d(pre.astype(np.bool))\n    input_2 = np.atleast_1d(gt.astype(np.bool))\n\n    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n\n    S = np.logical_xor(input_1, morphology.binary_erosion(input_1, conn))\n    Sprime = np.logical_xor(input_2, morphology.binary_erosion(input_2, conn))\n\n    dta = morphology.distance_transform_edt(~S, sampling)\n    dtb = morphology.distance_transform_edt(~Sprime, sampling)\n\n    sds = np.concatenate([np.ravel(dta[Sprime != 0]), np.ravel(dtb[S != 0])])\n    return sds", "\n\ndef asd(pre, gt, tid=1, sampling=1, connectivity=1):\n    sds = surfd(pre, gt, tid=tid, sampling=sampling, connectivity=connectivity)\n    dis = sds.mean()\n    return dis\n\n\ndef seg_metric(pre, gt):\n    mask = (pre > 0.5)\n    gt = (gt > 0.5)\n    ASD = asd(mask, gt)\n    DSC = dice(mask, gt)\n    SEN = sensitivity(mask, gt)\n    PPV = pospreval(mask, gt)\n\n    return DSC, PPV, SEN, ASD", "def seg_metric(pre, gt):\n    mask = (pre > 0.5)\n    gt = (gt > 0.5)\n    ASD = asd(mask, gt)\n    DSC = dice(mask, gt)\n    SEN = sensitivity(mask, gt)\n    PPV = pospreval(mask, gt)\n\n    return DSC, PPV, SEN, ASD\n", ""]}
{"filename": "Step3-Tumor-Segmentation/utils/logger.py", "chunked_list": ["import pandas as pd\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch, random\nimport numpy as np\nfrom collections import OrderedDict\n\n\nclass Train_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, epoch, train_log):\n        item = OrderedDict({'epoch': epoch})\n        item.update(train_log)\n        print(\"\\033[0;33mTrain:\\033[0m\", train_log)\n        self.update_csv(item)\n        self.update_tensorboard(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\n    def update_tensorboard(self, item):\n        if self.summary is None:\n            self.summary = SummaryWriter('%s/' % self.save_path)\n        epoch = item['epoch']\n        for key, value in item.items():\n            if key != 'epoch': self.summary.add_scalar(key, value, epoch)", "\n\nclass Val_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, epoch, val_log):\n        item = OrderedDict({'epoch': epoch})\n        item.update(val_log)\n        print(\"\\033[0;33mValidate:\\033[0m\", val_log)\n        self.update_csv(item)\n        self.update_tensorboard(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\n    def update_tensorboard(self, item):\n        if self.summary is None:\n            self.summary = SummaryWriter('%s/' % self.save_path)\n        epoch = item['epoch']\n        for key, value in item.items():\n            if key != 'epoch': self.summary.add_scalar(key, value, epoch)", "\n\nclass Test_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, name, log):\n        item = OrderedDict({'img_name': name})\n        item.update(log)\n        print(\"\\033[0;33mTest:\\033[0m\", log)\n        self.update_csv(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)", "\n\ndef setpu_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    random.seed(seed)\n\n\ndef dict_round(dic, num):\n    for key, value in dic.items():\n        dic[key] = round(value, num)\n    return dic", "\n\ndef dict_round(dic, num):\n    for key, value in dic.items():\n        dic[key] = round(value, num)\n    return dic\n"]}
{"filename": "Step3-Tumor-Segmentation/utils/__init__.py", "chunked_list": [""]}
{"filename": "Step3-Tumor-Segmentation/utils/util.py", "chunked_list": ["\"\"\"This module contains simple helper functions \"\"\"\nfrom __future__ import print_function\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport os\n\n\ndef tensor2im(input_image, imtype=np.uint8):\n    \"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"\n    if not isinstance(input_image, np.ndarray):\n        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n            image_tensor = input_image.data\n        else:\n            return input_image\n        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n        if image_numpy.shape[0] == 1:  # grayscale to RGB\n            image_numpy = np.tile(image_numpy, (3, 1, 1))\n        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n    else:  # if it is a numpy array, do nothing\n        image_numpy = input_image\n    return image_numpy.astype(imtype)", "def tensor2im(input_image, imtype=np.uint8):\n    \"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"\n    if not isinstance(input_image, np.ndarray):\n        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n            image_tensor = input_image.data\n        else:\n            return input_image\n        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n        if image_numpy.shape[0] == 1:  # grayscale to RGB\n            image_numpy = np.tile(image_numpy, (3, 1, 1))\n        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n    else:  # if it is a numpy array, do nothing\n        image_numpy = input_image\n    return image_numpy.astype(imtype)", "\n\ndef diagnose_network(net, name='network'):\n    \"\"\"Calculate and print the mean of average absolute(gradients)\n\n    Parameters:\n        net (torch network) -- Torch network\n        name (str) -- the name of the network\n    \"\"\"\n    mean = 0.0\n    count = 0\n    for param in net.parameters():\n        if param.grad is not None:\n            mean += torch.mean(torch.abs(param.grad.data))\n            count += 1\n    if count > 0:\n        mean = mean / count\n    print(name)\n    print(mean)", "\n\ndef save_image(image_numpy, image_path, aspect_ratio=1.0):\n    \"\"\"Save a numpy image to the disk\n\n    Parameters:\n        image_numpy (numpy array) -- input numpy array\n        image_path (str)          -- the path of the image\n    \"\"\"\n\n    image_pil = Image.fromarray(image_numpy)\n    h, w, _ = image_numpy.shape\n\n    if aspect_ratio > 1.0:\n        image_pil = image_pil.resize((h, int(w * aspect_ratio)), Image.BICUBIC)\n    if aspect_ratio < 1.0:\n        image_pil = image_pil.resize((int(h / aspect_ratio), w), Image.BICUBIC)\n    image_pil.save(image_path)", "\n\ndef print_numpy(x, val=True, shp=False):\n    \"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"\n    x = x.astype(np.float64)\n    if shp:\n        print('shape,', x.shape)\n    if val:\n        x = x.flatten()\n        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))", "\n\ndef mkdirs(paths):\n    \"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)", "\n\ndef mkdir(path):\n    \"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"\n    \n    if not os.path.exists(path):\n        os.makedirs(path)", ""]}
{"filename": "Step3-Tumor-Segmentation/utils/common.py", "chunked_list": ["import SimpleITK as sitk\nimport numpy as np\nimport math\n\n\ndef normalization(img):\n    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n    return out\n\n\ndef normalization_test(img):\n    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n    return out, np.max(img), np.min(img)", "\n\ndef normalization_test(img):\n    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n    return out, np.max(img), np.min(img)\n\n\ndef center_crop_3d(img, label, slice_num=16):\n    if img.shape[0] < slice_num:\n        return None\n    left_x = img.shape[0] // 2 - slice_num // 2\n    right_x = img.shape[0] // 2 + slice_num // 2\n\n    crop_img = img[left_x:right_x]\n    crop_label = label[left_x:right_x]\n    return crop_img, crop_label", "\n\ndef load_file_name_list(file_path):\n    file_name_list = []\n    with open(file_path, 'r') as file_to_read:\n        while True:\n            lines = file_to_read.readline().strip()\n            if not lines:\n                break\n                pass\n            file_name_list.append(lines)\n            pass\n    return file_name_list", "\n\ndef MaskContour(image, position='xy', line=1):\n    itkimage = sitk.GetImageFromArray(image)\n    if position == 'xy':\n        erode_m = [line, line, 0]\n    elif position == 'yz':\n        erode_m = [0, line, line]\n    elif position == 'zx':\n        erode_m = [line, 0, line]\n    else:\n        erode_m = [line, line, 0]\n\n    mask = sitk.GetArrayFromImage(sitk.BinaryErode(itkimage, erode_m))\n    boundary = image - mask\n    out = sitk.GetImageFromArray(boundary)\n    return out", "\n\ndef print_network(net):\n    num_params = 0\n    for param in net.parameters():\n        num_params += param.numel()\n    print(net)\n    print('Total number of parameters: %d' % num_params)\n\n\ndef adjust_learning_rate(optimizer, epoch, opt):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n    lr = opt.lr * (0.5 ** (epoch // opt.step))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr", "\n\ndef adjust_learning_rate(optimizer, epoch, opt):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n    lr = opt.lr * (0.5 ** (epoch // opt.step))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n\ndef adjust_learning_rate_V2(optimizer, lr):\n    \"\"\"Sets the learning rate to a fixed number\"\"\"\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr", "\ndef adjust_learning_rate_V2(optimizer, lr):\n    \"\"\"Sets the learning rate to a fixed number\"\"\"\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n\ndef get_mse(img1, img2):\n    mse = np.mean((img1 - img2) ** 2)\n\n    return mse", "\n\ndef get_psnr(img1, img2):\n    mse = np.mean((img1 - img2) ** 2)\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1.0\n    return 10 * math.log10(PIXEL_MAX / math.sqrt(mse))\n\n", "\n\n'''\ndef get_ssim(img1,img2):\n    n=img1.shape[0]\n    out = 0\n    for i in range(n):\n        out+=structural_similarity(img1[i].squeeze(),img2[i].squeeze())\n        \n    return out/n", "        \n    return out/n\n'''\n\n\ndef save_result(low_dose, high_dose, output, i, epoch):\n    def save_img(img, name):\n        img = sitk.GetImageFromArray(img)\n        sitk.WriteImage(img, 'result/image/' + name + '.nii.gz')\n\n    save_img(low_dose, 'low_dose_epoch_' + str(epoch) + \"_\" + str(i))\n    save_img(high_dose, 'high_dose_epoch_' + str(epoch) + \"_\" + str(i))\n    save_img(output, 'output_epoch_' + str(epoch) + \"_\" + str(i))", "\n\ndef de_normalization(img, max_x, min_x):\n    return img * (max_x - min_x) + min_x\n"]}
{"filename": "Step3-Tumor-Segmentation/dataset/dataset_lits_test.py", "chunked_list": ["import numpy as np\nimport torch, os\nfrom torch.utils.data import Dataset, DataLoader\nfrom glob import glob\nimport random\nimport SimpleITK as sitk\n\n\ndef normalization(img, lmin=1, rmax=None, dividend=None, quantile=1):\n    newimg = img.copy()\n    newimg = newimg.astype(np.float32)\n    if quantile is not None:\n        maxval = round(np.percentile(newimg, 100 - quantile))\n        minval = round(np.percentile(newimg, quantile))\n        newimg[newimg >= maxval] = maxval\n        newimg[newimg <= minval] = minval\n\n    if lmin is not None:\n        newimg[newimg < lmin] = lmin\n    if rmax is not None:\n        newimg[newimg > rmax] = rmax\n\n    minval = np.min(newimg)\n    if dividend is None:\n        maxval = np.max(newimg)\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n    else:\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n    return newimg, minval, maxval", "def normalization(img, lmin=1, rmax=None, dividend=None, quantile=1):\n    newimg = img.copy()\n    newimg = newimg.astype(np.float32)\n    if quantile is not None:\n        maxval = round(np.percentile(newimg, 100 - quantile))\n        minval = round(np.percentile(newimg, quantile))\n        newimg[newimg >= maxval] = maxval\n        newimg[newimg <= minval] = minval\n\n    if lmin is not None:\n        newimg[newimg < lmin] = lmin\n    if rmax is not None:\n        newimg[newimg > rmax] = rmax\n\n    minval = np.min(newimg)\n    if dividend is None:\n        maxval = np.max(newimg)\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n    else:\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n    return newimg, minval, maxval", "\n\ndef normalization_fix(img, minval, maxval, lmin=1):\n    newimg = img.copy()\n    newimg = newimg.astype(np.float32)\n    if lmin is not None:\n        newimg[newimg < lmin] = lmin\n\n    newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n    return newimg", "\n\ndef normalization_org(img, lmin=1, rmax=None, dividend=None, quantile=None):\n    newimg = img.copy()\n    newimg = newimg.astype(np.float32)\n    if quantile is not None:\n        maxval = round(np.percentile(newimg, 100 - quantile))\n        minval = round(np.percentile(newimg, quantile))\n        newimg[newimg >= maxval] = maxval\n        newimg[newimg <= minval] = minval\n\n    if lmin is not None:\n        newimg[newimg < lmin] = lmin\n    if rmax is not None:\n        newimg[newimg > rmax] = rmax\n\n    minval = np.min(newimg)\n    if dividend is None:\n        maxval = np.max(newimg)\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n    else:\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n    return newimg", "\n\ndef load(file):\n    itkimage = sitk.ReadImage(file)\n    image = sitk.GetArrayFromImage(itkimage)\n    return image\n\n\ndef maskcor_extract_3d(mask, padding=(5, 5, 5)):\n    # mask_s = mask.shape\n    p = np.where(mask > 0)\n    a = np.zeros([3, 2], dtype=np.int)\n    if len(p[0]) == 0:\n        a[0, 0] = 0\n        a[0, 1] = 32\n        a[1, 0] = 0\n        a[1, 1] = 128\n        a[2, 0] = 0\n        a[2, 1] = 128\n        return a\n\n    for i in range(3):\n        s = p[i].min()\n        e = p[i].max() + 1\n\n        ss = s - padding[i]\n        ee = e + padding[i]\n        if ss < 0:\n            ss = 0\n        if ee > mask.shape[i]:\n            ee = mask.shape[i]\n\n        a[i, 0] = ss\n        a[i, 1] = ee\n    return a", "def maskcor_extract_3d(mask, padding=(5, 5, 5)):\n    # mask_s = mask.shape\n    p = np.where(mask > 0)\n    a = np.zeros([3, 2], dtype=np.int)\n    if len(p[0]) == 0:\n        a[0, 0] = 0\n        a[0, 1] = 32\n        a[1, 0] = 0\n        a[1, 1] = 128\n        a[2, 0] = 0\n        a[2, 1] = 128\n        return a\n\n    for i in range(3):\n        s = p[i].min()\n        e = p[i].max() + 1\n\n        ss = s - padding[i]\n        ee = e + padding[i]\n        if ss < 0:\n            ss = 0\n        if ee > mask.shape[i]:\n            ee = mask.shape[i]\n\n        a[i, 0] = ss\n        a[i, 1] = ee\n    return a", "\n\nclass Img_DataSet(Dataset):\n    def __init__(self, pos, sub, adc, t2w, Infor_DCE, Infor_ADC, Infor_T2, gt, cut_param):\n        self.pos = pos\n        self.sub = sub\n        self.adc = adc\n        self.t2w = t2w\n        self.Infor_DCE = Infor_DCE\n        self.Infor_ADC = Infor_ADC\n        self.Infor_T2 = Infor_T2\n        self.gt = gt\n\n        self.ori_shape = self.pos.shape\n        self.cut_param = cut_param\n\n        self.pos = self.padding_img(self.pos, self.cut_param)\n        self.pos = self.extract_ordered_overlap(self.pos, self.cut_param)\n        self.sub = self.padding_img(self.sub, self.cut_param)\n        self.sub = self.extract_ordered_overlap(self.sub, self.cut_param)\n        self.adc = self.padding_img(self.adc, self.cut_param)\n        self.adc = self.extract_ordered_overlap(self.adc, self.cut_param)\n        self.t2w = self.padding_img(self.t2w, self.cut_param)\n        self.t2w = self.extract_ordered_overlap(self.t2w, self.cut_param)\n\n        self.Infor_DCE = self.padding_img(self.Infor_DCE, self.cut_param)\n        self.Infor_DCE = self.extract_ordered_overlap(self.Infor_DCE, self.cut_param)\n        self.Infor_ADC = self.padding_img(self.Infor_ADC, self.cut_param)\n        self.Infor_ADC = self.extract_ordered_overlap(self.Infor_ADC, self.cut_param)\n        self.Infor_T2 = self.padding_img(self.Infor_T2, self.cut_param)\n        self.Infor_T2 = self.extract_ordered_overlap(self.Infor_T2, self.cut_param)\n\n        self.gt = self.padding_img(self.gt, self.cut_param)\n        self.gt = self.extract_ordered_overlap(self.gt, self.cut_param)\n\n        self.new_shape = self.pos.shape\n\n    def __getitem__(self, index):\n        pos = self.pos[index]\n        sub = self.sub[index]\n        adc = self.adc[index]\n        t2w = self.t2w[index]\n        Infor_DCE = self.Infor_DCE[index]\n        Infor_ADC = self.Infor_ADC[index]\n        Infor_T2 = self.Infor_T2[index]\n        gt = self.gt[index]\n\n        return torch.from_numpy(pos), torch.from_numpy(sub), torch.from_numpy(\n            adc), torch.from_numpy(t2w), torch.from_numpy(Infor_DCE), torch.from_numpy(Infor_ADC), torch.from_numpy(\n            Infor_T2), torch.from_numpy(gt)\n\n    def __len__(self):\n        return len(self.pos)\n\n    def padding_img(self, img, C):\n        assert (len(img.shape) == 3)  # 3D array\n        img_s, img_h, img_w = img.shape\n        leftover_s = (img_s - C['patch_s']) % C['stride_s']\n        leftover_h = (img_h - C['patch_h']) % C['stride_h']\n        leftover_w = (img_w - C['patch_w']) % C['stride_w']\n        if (leftover_s != 0):\n            s = img_s + (C['stride_s'] - leftover_s)\n        else:\n            s = img_s\n\n        if (leftover_h != 0):\n            h = img_h + (C['stride_h'] - leftover_h)\n        else:\n            h = img_h\n\n        if (leftover_w != 0):\n            w = img_w + (C['stride_w'] - leftover_w)\n        else:\n            w = img_w\n\n        tmp_full_imgs = np.zeros((s, h, w))\n        tmp_full_imgs[:img_s, :img_h, 0:img_w] = img\n        # print(\"Padded images shape: \" + str(tmp_full_imgs.shape))\n        return tmp_full_imgs\n\n    # Divide all the full_imgs in pacthes\n    def extract_ordered_overlap(self, img, C):\n        assert (len(img.shape) == 3)  # 3D arrays\n        img_s, img_h, img_w = img.shape\n        assert ((img_h - C['patch_h']) % C['stride_h'] == 0\n                and (img_w - C['patch_w']) % C['stride_w'] == 0\n                and (img_s - C['patch_s']) % C['stride_s'] == 0)\n        N_patches_s = (img_s - C['patch_s']) // C['stride_s'] + 1\n        N_patches_h = (img_h - C['patch_h']) // C['stride_h'] + 1\n        N_patches_w = (img_w - C['patch_w']) // C['stride_w'] + 1\n        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n        # print(\"Patches number of the image:{} [s={} | h={} | w={}]\"\\\n        #               .format(N_patches_img, N_patches_s, N_patches_h, N_patches_w))\n        patches = np.empty((N_patches_img, C['patch_s'], C['patch_h'], C['patch_w']))\n        iter_tot = 0  # iter over the total number of patches (N_patches)\n        for s in range(N_patches_s):  # loop over the full images\n            for h in range(N_patches_h):\n                for w in range(N_patches_w):\n                    patch = img[s * C['stride_s']: s * C['stride_s'] + C['patch_s'],\n                            h * C['stride_h']: h * C['stride_h'] + C['patch_h'],\n                            w * C['stride_w']: w * C['stride_w'] + C['patch_w']]\n\n                    patches[iter_tot] = patch\n                    iter_tot += 1  # total\n        assert (iter_tot == N_patches_img)\n        return patches  # array with all the full_imgs divided in patches", "\n\nclass Recompone_tool():\n    def __init__(self, img_ori_shape, img_new_shape, Cut_para):\n        self.result = None\n        self.ori_shape = img_ori_shape\n        self.new_shape = img_new_shape\n        self.C = Cut_para\n\n    def add_result(self, tensor):\n        # tensor = tensor.detach().cpu() # shape: [N,class,s,h,w]\n        # tensor_np = np.squeeze(tensor_np,axis=0)\n        if self.result is not None:\n            self.result = torch.cat((self.result, tensor), dim=0)\n        else:\n            self.result = tensor\n\n    def recompone_overlap(self):\n        \"\"\"\n        :param preds: output of model  shape\uff1a[N_patchs_img,3,patch_s,patch_h,patch_w]\n        :return: result of recompone output shape: [3,img_s,img_h,img_w]\n        \"\"\"\n        patch_s = self.result.shape[2]\n        patch_h = self.result.shape[3]\n        patch_w = self.result.shape[4]\n        N_patches_s = (self.new_shape[0] - patch_s) // self.C['stride_s'] + 1\n        N_patches_h = (self.new_shape[1] - patch_h) // self.C['stride_h'] + 1\n        N_patches_w = (self.new_shape[2] - patch_w) // self.C['stride_w'] + 1\n        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n        assert (self.result.shape[0] == N_patches_img)\n\n        full_prob = torch.zeros((self.new_shape[0], self.new_shape[1],\n                                 self.new_shape[2]))  # itialize to zero mega array with sum of Probabilities\n        full_sum = torch.zeros((self.new_shape[0], self.new_shape[1], self.new_shape[2]))\n        k = 0  # iterator over all the patches\n        for s in range(N_patches_s):\n            for h in range(N_patches_h):\n                for w in range(N_patches_w):\n                    # print(k,self.result[k].squeeze().sum())\n                    full_prob[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += self.result[k].squeeze()\n                    full_sum[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += 1\n                    k += 1\n        assert (k == self.result.size(0))\n        assert (torch.min(full_sum) >= 1.0)  # at least one\n        final_avg = full_prob / full_sum\n        # print(final_avg.size())\n        img = final_avg[:self.ori_shape[0], :self.ori_shape[1], :self.ori_shape[2]]\n        return img", "\n\ndef cal_newshape(img, C):\n    assert (len(img.shape) == 3)  # 3D array\n    img_s, img_h, img_w = img.shape\n    leftover_s = (img_s - C['patch_s']) % C['stride_s']\n    leftover_h = (img_h - C['patch_h']) % C['stride_h']\n    leftover_w = (img_w - C['patch_w']) % C['stride_w']\n    if (leftover_s != 0):\n        s = img_s + (C['stride_s'] - leftover_s)\n    else:\n        s = img_s\n\n    if (leftover_h != 0):\n        h = img_h + (C['stride_h'] - leftover_h)\n    else:\n        h = img_h\n\n    if (leftover_w != 0):\n        w = img_w + (C['stride_w'] - leftover_w)\n    else:\n        w = img_w\n\n    return np.zeros((s, h, w)).shape", "\n\ndef package_torch(pre_patch, pos_patch, sub_patch, gt_patch):\n    pre_patch = torch.from_numpy(pre_patch[np.newaxis, np.newaxis, :])\n    pos_patch = torch.from_numpy(pos_patch[np.newaxis, np.newaxis, :])\n    sub_patch = torch.from_numpy(sub_patch[np.newaxis, np.newaxis, :])\n    gt_patch = torch.from_numpy(gt_patch[np.newaxis, np.newaxis, :])\n    return pre_patch, pos_patch, sub_patch, gt_patch\n\n\ndef crop_patch(img, crop_box):\n    img_patch = img[crop_box[0, 0]:crop_box[0, 1], crop_box[1, 0]:crop_box[1, 1], crop_box[2, 0]:crop_box[2, 1]]\n    return img_patch", "\n\ndef crop_patch(img, crop_box):\n    img_patch = img[crop_box[0, 0]:crop_box[0, 1], crop_box[1, 0]:crop_box[1, 1], crop_box[2, 0]:crop_box[2, 1]]\n    return img_patch\n\n\ndef fine_crop(pred, crop_size):\n    cor_box = maskcor_extract_3d(pred, (10, 10, 10))\n    box_shape = pred.shape\n    for i in range(3):\n        len_cor = cor_box[i, 1] - cor_box[i, 0]\n\n        if (len_cor <= crop_size[i]):\n            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] // 2)\n            cor_box[i, 1] = cor_box[i, 0] + crop_size[i]\n            if cor_box[i, 0] < 0:\n                cor_box[i, 0] = 0\n                cor_box[i, 1] = cor_box[i, 0] + crop_size[i]\n            if cor_box[i, 1] > box_shape[i]:\n                cor_box[i, 1] = box_shape[i]\n                cor_box[i, 0] = cor_box[i, 1] - crop_size[i]\n        elif len_cor <= crop_size[i] * 2:\n            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i])\n            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 2\n            if cor_box[i, 0] < 0:\n                cor_box[i, 0] = 0\n                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 2\n            if cor_box[i, 1] > box_shape[i]:\n                cor_box[i, 1] = box_shape[i]\n                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 2\n        elif len_cor <= crop_size[i] * 3:\n            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 1.5)\n            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 3\n            if cor_box[i, 0] < 0:\n                cor_box[i, 0] = 0\n                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 3\n            if cor_box[i, 1] > box_shape[i]:\n                cor_box[i, 1] = box_shape[i]\n                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 3\n        elif len_cor <= crop_size[i] * 4:\n            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 2)\n            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 4\n            if cor_box[i, 0] < 0:\n                cor_box[i, 0] = 0\n                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 4\n            if cor_box[i, 1] > box_shape[i]:\n                cor_box[i, 1] = box_shape[i]\n                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 4\n        elif len_cor <= crop_size[i] * 5:\n            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 2.5)\n            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 5\n            if cor_box[i, 0] < 0:\n                cor_box[i, 0] = 0\n                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 5\n            if cor_box[i, 1] > box_shape[i]:\n                cor_box[i, 1] = box_shape[i]\n                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 5\n        elif len_cor <= crop_size[i] * 6:\n            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 3)\n            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 6\n            if cor_box[i, 0] < 0:\n                cor_box[i, 0] = 0\n                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 6\n            if cor_box[i, 1] > box_shape[i]:\n                cor_box[i, 1] = box_shape[i]\n                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 6\n        elif len_cor <= crop_size[i] * 7:\n            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 3.5)\n            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 7\n            if cor_box[i, 0] < 0:\n                cor_box[i, 0] = 0\n                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 7\n            if cor_box[i, 1] > box_shape[i]:\n                cor_box[i, 1] = box_shape[i]\n                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 7\n        elif len_cor <= crop_size[i] * 8:\n\n            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 4)\n            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 8\n            if cor_box[i, 0] < 0:\n                cor_box[i, 0] = 0\n                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 8\n            if cor_box[i, 1] > box_shape[i]:\n                cor_box[i, 1] = box_shape[i]\n                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 8\n        else:\n            print('too large tumor')\n            cor_box[i, 0] = 0\n            cor_box[i, 1] = box_shape[i]\n\n        if (cor_box[i, 1] - cor_box[i, 0]) >= box_shape[i]:\n            cor_box[i, 1] = box_shape[i]\n            cor_box[i, 0] = 0\n\n        if (cor_box[i, 1] - cor_box[i, 0]) != box_shape[i]:\n            if (cor_box[i, 1] - cor_box[i, 0]) % crop_size[i] != 0:\n                print('Something goes wrong!')\n        if (cor_box[i, 1] - cor_box[i, 0]) == box_shape[i]:\n            cor_box[i, 1] = (len_cor // crop_size[i]) * crop_size[i] + cor_box[i, 0]\n    return cor_box", "\n\ndef Test_all_Datasets(dataset_path, size):\n    f = open(os.path.join(dataset_path, 'test.txt'))\n    data_list = f.read().splitlines()\n    print(\"The number of test samples is: \", len(data_list))\n    for file in data_list:\n        print(\"\\nStart Evaluate: \", file)\n        pre, pre_min, pre_max = normalization(load(os.path.join(dataset_path, file, 'DCE0.nii.gz')))\n        pos = normalization_fix(load(os.path.join(dataset_path, file, 'DCE.nii.gz')), pre_min, pre_max).astype(\n            np.float32)\n        sub = pos - pre\n        adc = normalization_org(load(os.path.join(dataset_path, file, 'ADC.nii.gz'))).astype(np.float32)\n        t2w = normalization_org(load(os.path.join(dataset_path, file, 'T2.nii.gz'))).astype(np.float32)\n\n        Infor_DCE = load(os.path.join(dataset_path, file, 'Infor_DCE.nii.gz')).astype(np.float32)\n        Infor_ADC = load(os.path.join(dataset_path, file, 'Infor_ADC.nii.gz')).astype(np.float32)\n        Infor_T2 = load(os.path.join(dataset_path, file, 'Infor_T2.nii.gz')).astype(np.float32)\n        gt = load(os.path.join(dataset_path, file, 'GT.nii.gz')).astype(np.int16)\n\n        breast_mask = load(os.path.join(dataset_path, file, 'Breast_mask.nii.gz')).astype(np.int16)\n        pred = load(os.path.join(dataset_path, file, 'pred_coarse.nii.gz')).astype(np.float32)\n\n        cor_box = fine_crop(pred, (32, 128, 128))\n        pos = crop_patch(pos, cor_box)\n        sub = crop_patch(sub, cor_box)\n        t2w = crop_patch(t2w, cor_box)\n        adc = crop_patch(adc, cor_box)\n        Infor_DCE = crop_patch(Infor_DCE, cor_box)\n        Infor_ADC = crop_patch(Infor_ADC, cor_box)\n        Infor_T2 = crop_patch(Infor_T2, cor_box)\n        gt = crop_patch(gt, cor_box)\n\n        original_shape = gt.shape\n        new_shape = cal_newshape(gt, size)\n\n        yield Img_DataSet(pos, sub, adc, t2w, Infor_DCE, Infor_ADC, Infor_T2, gt,\n                          size), original_shape, new_shape, breast_mask, file, cor_box", ""]}
{"filename": "Step3-Tumor-Segmentation/dataset/dataset_lits_val.py", "chunked_list": ["import random\nimport numpy as np\nimport SimpleITK as sitk\nimport os\nfrom torch.utils.data import Dataset\n\n\nclass Val_DataSet(Dataset):\n    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n        self.root = root\n        self.size = size\n        self.sample_index = sample_index\n        f = open(os.path.join(self.root, 'val.txt'))\n        self.filename = f.read().splitlines()\n\n    def __getitem__(self, index):\n\n        file = self.filename[index]\n        DCE0, DCE0_Min, DCE0_Max = self.normalization(self.load(os.path.join(self.root, file, 'DCE0.nii.gz')))\n        DCE = self.normalization_fix(self.load(os.path.join(self.root, file, 'DCE.nii.gz')), DCE0_Min, DCE0_Max).astype(\n            np.float32)\n        sub = DCE - DCE0\n        Coarse = self.load(os.path.join(self.root, file, 'pred_coarse.nii.gz')).astype(np.float32)\n        ADC = self.normalization_org(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n        T2W = self.normalization_org(self.load(os.path.join(self.root, file, 'T2.nii.gz'))).astype(np.float32)\n        Infor_DCE = self.load(os.path.join(self.root, file, 'Infor_DCE.nii.gz')).astype(np.float32)\n        Infor_ADC = self.load(os.path.join(self.root, file, 'Infor_ADC.nii.gz')).astype(np.float32)\n        Infor_T2 = self.load(os.path.join(self.root, file, 'Infor_T2.nii.gz')).astype(np.float32)\n        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\n        DCE_patch, sub_patch, ADC_patch, T2W_patch, Infor_DCE_patch, Infor_ADC_patch, Infor_T2_patch, gt_patch = [], [], [], [], [], [], [], []\n        for i in range(3):\n            if i == 1:\n                DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, Infor_DCE_patch1, Infor_ADC_patch1, Infor_T2_patch1, gt_patch1 = self.random_crop_3d_partial(\n                    DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt, Coarse, self.size, 'add')\n            else:\n                DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, Infor_DCE_patch1, Infor_ADC_patch1, Infor_T2_patch1, gt_patch1 = self.random_crop_3d_contain(\n                    DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt, Coarse, self.size, 'sub')\n\n            DCE_patch.append(DCE_patch1), sub_patch.append(sub_patch1), ADC_patch.append(ADC_patch1), T2W_patch.append(\n                T2W_patch1), Infor_DCE_patch.append(\n                Infor_DCE_patch1), Infor_ADC_patch.append(Infor_ADC_patch1), Infor_T2_patch.append(\n                Infor_T2_patch1), gt_patch.append(gt_patch1)\n\n        return np.array(DCE_patch), np.array(sub_patch), np.array(ADC_patch), np.array(T2W_patch), np.array(\n            Infor_DCE_patch), np.array(Infor_ADC_patch), np.array(Infor_T2_patch), np.array(gt_patch)\n\n    def __len__(self):\n        return len(self.filename)\n\n    def random_crop_3d_contain(self, a, b, c, d, e, f, g, gt, coarse, crop_size, pattern='sub'):\n        if pattern == 'sub':\n            cor_box = self.maskcor_extract_3d(np.abs(gt - coarse))\n        else:\n            cor_box = self.maskcor_extract_3d(np.abs(gt + coarse))\n\n        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n        if random_x_min > random_x_max:\n            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n        if random_y_min > random_y_max:\n            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n        if random_z_min > random_z_max:\n            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\n    def random_crop_3d_partial(self, a, b, c, d, e, f, g, gt, coarse, crop_size, pattern='sub'):\n        if pattern == 'sub':\n            cor_box = self.maskcor_extract_3d(np.abs(gt - coarse))\n        else:\n            cor_box = self.maskcor_extract_3d(np.abs(gt + coarse))\n        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\n    def min_max_normalization(self, img):\n        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n        return out\n\n    def normalization_org(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if quantile is not None:\n            maxval = round(np.percentile(newimg, 100 - quantile))\n            minval = round(np.percentile(newimg, quantile))\n            newimg[newimg >= maxval] = maxval\n            newimg[newimg <= minval] = minval\n\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n        if rmax is not None:\n            newimg[newimg > rmax] = rmax\n\n        minval = np.min(newimg)\n        if dividend is None:\n            maxval = np.max(newimg)\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        else:\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n        return newimg\n\n    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=1):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if quantile is not None:\n            maxval = round(np.percentile(newimg, 100 - quantile))\n            minval = round(np.percentile(newimg, quantile))\n            newimg[newimg >= maxval] = maxval\n            newimg[newimg <= minval] = minval\n\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n        if rmax is not None:\n            newimg[newimg > rmax] = rmax\n\n        minval = np.min(newimg)\n        if dividend is None:\n            maxval = np.max(newimg)\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        else:\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n        return newimg, minval, maxval\n\n    def normalization_fix(self, img, minval, maxval, lmin=1):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        return newimg\n\n    def load(self, file):\n        itkimage = sitk.ReadImage(file)\n        image = sitk.GetArrayFromImage(itkimage)\n        return image\n\n    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n        # mask_s = mask.shape\n        if np.sum(mask) == 0:\n            mask[10:12, 100:102, 100:102] = 1\n\n        p = np.where(mask > 0)\n        a = np.zeros([3, 2], dtype=np.int)\n        for i in range(3):\n            s = p[i].min()\n            e = p[i].max() + 1\n\n            ss = s - padding[i]\n            ee = e + padding[i]\n            if ss < 0:\n                ss = 0\n            if ee > mask.shape[i]:\n                ee = mask.shape[i]\n\n            a[i, 0] = ss\n            a[i, 1] = ee\n        return a", ""]}
{"filename": "Step3-Tumor-Segmentation/dataset/dataset_lits_train.py", "chunked_list": ["import random\nimport numpy as np\nimport SimpleITK as sitk\nimport os\nfrom torch.utils.data import Dataset\n\n\nclass Lits_DataSet(Dataset):\n    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n        self.root = root\n        self.size = size\n        self.sample_index = sample_index\n        f = open(os.path.join(self.root, 'train.txt'))\n        self.filename = f.read().splitlines()\n\n    def __getitem__(self, index):\n\n        file = self.filename[index]\n        DCE0, DCE0_Min, DCE0_Max = self.normalization(self.load(os.path.join(self.root, file, 'DCE0.nii.gz')))\n        DCE = self.normalization_fix(self.load(os.path.join(self.root, file, 'DCE.nii.gz')), DCE0_Min, DCE0_Max).astype(\n            np.float32)\n        sub = DCE - DCE0\n        Coarse = self.load(os.path.join(self.root, file, 'pred_coarse.nii.gz')).astype(np.float32)\n        ADC = self.normalization_org(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n        T2W = self.normalization_org(self.load(os.path.join(self.root, file, 'T2.nii.gz'))).astype(np.float32)\n        Infor_DCE = self.load(os.path.join(self.root, file, 'Infor_DCE.nii.gz')).astype(np.float32)\n        Infor_ADC = self.load(os.path.join(self.root, file, 'Infor_ADC.nii.gz')).astype(np.float32)\n        Infor_T2 = self.load(os.path.join(self.root, file, 'Infor_T2.nii.gz')).astype(np.float32)\n        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\n        DCE_patch, sub_patch, ADC_patch, T2W_patch, Infor_DCE_patch, Infor_ADC_patch, Infor_T2_patch, gt_patch = [], [], [], [], [], [], [], []\n        for i in range(3):\n            if i == 1:\n                DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, Infor_DCE_patch1, Infor_ADC_patch1, Infor_T2_patch1, gt_patch1 = self.random_crop_3d_partial(\n                    DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt, Coarse, self.size, 'add')\n            else:\n                DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, Infor_DCE_patch1, Infor_ADC_patch1, Infor_T2_patch1, gt_patch1 = self.random_crop_3d_contain(\n                    DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt, Coarse, self.size, 'sub')\n\n            DCE_patch.append(DCE_patch1), sub_patch.append(sub_patch1), ADC_patch.append(ADC_patch1), T2W_patch.append(\n                T2W_patch1), Infor_DCE_patch.append(\n                Infor_DCE_patch1), Infor_ADC_patch.append(Infor_ADC_patch1), Infor_T2_patch.append(\n                Infor_T2_patch1), gt_patch.append(gt_patch1)\n\n        return np.array(DCE_patch), np.array(sub_patch), np.array(ADC_patch), np.array(T2W_patch), np.array(\n            Infor_DCE_patch), np.array(Infor_ADC_patch), np.array(Infor_T2_patch), np.array(gt_patch)\n\n    def __len__(self):\n        return len(self.filename)\n\n    def random_crop_3d_contain(self, a, b, c, d, e, f, g, gt, coarse, crop_size, pattern='sub'):\n        if pattern == 'sub':\n            cor_box = self.maskcor_extract_3d(np.abs(gt - coarse))\n        else:\n            cor_box = self.maskcor_extract_3d(np.abs(gt + coarse))\n\n        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n        if random_x_min > random_x_max:\n            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n        if random_y_min > random_y_max:\n            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n        if random_z_min > random_z_max:\n            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\n    def random_crop_3d_partial(self, a, b, c, d, e, f, g, gt, coarse, crop_size, pattern='sub'):\n        if pattern == 'sub':\n            cor_box = self.maskcor_extract_3d(np.abs(gt - coarse))\n        else:\n            cor_box = self.maskcor_extract_3d(np.abs(gt + coarse))\n        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\n    def min_max_normalization(self, img):\n        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n        return out\n\n    def normalization_org(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if quantile is not None:\n            maxval = round(np.percentile(newimg, 100 - quantile))\n            minval = round(np.percentile(newimg, quantile))\n            newimg[newimg >= maxval] = maxval\n            newimg[newimg <= minval] = minval\n\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n        if rmax is not None:\n            newimg[newimg > rmax] = rmax\n\n        minval = np.min(newimg)\n        if dividend is None:\n            maxval = np.max(newimg)\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        else:\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n        return newimg\n\n    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=1):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if quantile is not None:\n            maxval = round(np.percentile(newimg, 100 - quantile))\n            minval = round(np.percentile(newimg, quantile))\n            newimg[newimg >= maxval] = maxval\n            newimg[newimg <= minval] = minval\n\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n        if rmax is not None:\n            newimg[newimg > rmax] = rmax\n\n        minval = np.min(newimg)\n        if dividend is None:\n            maxval = np.max(newimg)\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        else:\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n        return newimg, minval, maxval\n\n    def normalization_fix(self, img, minval, maxval, lmin=1):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        return newimg\n\n    def load(self, file):\n        itkimage = sitk.ReadImage(file)\n        image = sitk.GetArrayFromImage(itkimage)\n        return image\n\n    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n        # mask_s = mask.shape\n        if np.sum(mask) == 0:\n            mask[10:12, 100:102, 100:102] = 1\n\n        p = np.where(mask > 0)\n        a = np.zeros([3, 2], dtype=np.int)\n        for i in range(3):\n            s = p[i].min()\n            e = p[i].max() + 1\n\n            ss = s - padding[i]\n            ee = e + padding[i]\n            if ss < 0:\n                ss = 0\n            if ee > mask.shape[i]:\n                ee = mask.shape[i]\n\n            a[i, 0] = ss\n            a[i, 1] = ee\n        return a", ""]}
{"filename": "Step3-Tumor-Segmentation/Model/networks.py", "chunked_list": ["import torch\nimport torch.nn as nn\n\nbasic_dims = 8\nnum_modals = 3\npatch_size = [2, 8, 8]\n\n\ndef normalization(planes, norm='bn'):\n    if norm == 'bn':\n        m = nn.BatchNorm3d(planes)\n    elif norm == 'gn':\n        m = nn.GroupNorm(4, planes)\n    elif norm == 'in':\n        m = nn.InstanceNorm3d(planes)\n    else:\n        raise ValueError('normalization type {} is not supported'.format(norm))\n    return m", "def normalization(planes, norm='bn'):\n    if norm == 'bn':\n        m = nn.BatchNorm3d(planes)\n    elif norm == 'gn':\n        m = nn.GroupNorm(4, planes)\n    elif norm == 'in':\n        m = nn.InstanceNorm3d(planes)\n    else:\n        raise ValueError('normalization type {} is not supported'.format(norm))\n    return m", "\n\nclass general_conv3d_prenorm(nn.Module):\n    def __init__(self, in_ch, out_ch, k_size=3, stride=1, padding=1, pad_type='zeros', norm='in', is_training=True,\n                 act_type='lrelu', relufactor=0.2):\n        super(general_conv3d_prenorm, self).__init__()\n        self.conv = nn.Conv3d(in_channels=in_ch, out_channels=out_ch, kernel_size=k_size, stride=stride,\n                              padding=padding, padding_mode=pad_type, bias=True)\n\n        self.norm = normalization(out_ch, norm=norm)\n        if act_type == 'relu':\n            self.activation = nn.ReLU(inplace=True)\n        elif act_type == 'lrelu':\n            self.activation = nn.LeakyReLU(negative_slope=relufactor, inplace=True)\n\n    def forward(self, x):\n        x = self.norm(x)\n        x = self.activation(x)\n        x = self.conv(x)\n        return x", "\n\nclass fusion_prenorm(nn.Module):\n    def __init__(self, in_channel=64, num_cls=1):\n        super(fusion_prenorm, self).__init__()\n        self.fusion_layer = nn.Sequential(\n            general_conv3d_prenorm(in_channel * num_modals, in_channel, k_size=1, padding=0, stride=1),\n            general_conv3d_prenorm(in_channel, in_channel, k_size=3, padding=1, stride=1),\n            general_conv3d_prenorm(in_channel, in_channel, k_size=1, padding=0, stride=1))\n\n    def forward(self, x):\n        return self.fusion_layer(x)", "\n\nclass fusion_layer(nn.Module):\n    def __init__(self, in_channel=64, num_cls=1):\n        super(fusion_layer, self).__init__()\n        self.fusion_layer = nn.Sequential(\n            general_conv3d_prenorm(in_channel * 2, in_channel, k_size=1, padding=0, stride=1),\n            general_conv3d_prenorm(in_channel, in_channel, k_size=3, padding=1, stride=1),\n            general_conv3d_prenorm(in_channel, in_channel, k_size=1, padding=0, stride=1))\n\n    def forward(self, x):\n        return self.fusion_layer(x)", "\nclass MSA(nn.Module):\n    def __init__(self, F_g, F_l, n_coefficients):\n        super(MSA, self).__init__()\n\n        self.W_gate = nn.Sequential(\n            nn.Conv3d(F_g, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm3d(n_coefficients)\n        )\n\n        self.W_x = nn.Sequential(\n            nn.Conv3d(F_l, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm3d(n_coefficients)\n        )\n\n        self.psi = nn.Sequential(\n            nn.Conv3d(n_coefficients, 1, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm3d(1),\n            nn.Sigmoid()\n        )\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, gate, skip_connection):\n        g1 = self.W_gate(gate)\n        x1 = self.W_x(skip_connection)\n        psi = self.relu(g1 + x1)\n        psi = self.psi(psi)\n        out = skip_connection * psi\n        return out", "\nclass Encoder(nn.Module):\n    def __init__(self, flag=True):\n        super(Encoder, self).__init__()\n        if flag:\n            self.e1_c1 = nn.Conv3d(in_channels=1, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n                                   padding_mode='zeros', bias=True)\n        else:\n            self.e1_c1 = nn.Conv3d(in_channels=2, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n                                   padding_mode='zeros', bias=True)\n        self.e1_c2 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n        self.e1_c3 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n\n        self.e2_c1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n        self.e2_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n        self.e2_c3 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\n        self.e3_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n        self.e3_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n        self.e3_c3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n\n        self.e4_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n        self.e4_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n        self.e4_c3 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n\n        self.e5_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n        self.e5_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n        self.e5_c3 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\n        self.attehtion_block1 = MSA(basic_dims * 1, basic_dims * 1, basic_dims * 1)\n        self.attehtion_block2 = MSA(basic_dims * 2, basic_dims * 2, basic_dims * 2)\n        self.attehtion_block3 = MSA(basic_dims * 4, basic_dims * 4, basic_dims * 4)\n        self.attehtion_block4 = MSA(basic_dims * 8, basic_dims * 8, basic_dims * 8)\n        self.attehtion_block5 = MSA(basic_dims * 16, basic_dims * 16, basic_dims * 16)\n\n        self.Downsample1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n        self.Downsample2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n        self.Downsample3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n        self.Downsample4 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n\n        self.inforconv = general_conv3d_prenorm(1, basic_dims, pad_type='zeros')\n\n    def forward(self, x, infor):\n        x1 = self.e1_c1(x)\n        x1 = x1 + self.e1_c3(self.e1_c2(x1))\n        infor1 = self.inforconv(infor)\n        x1 = self.attehtion_block1(infor1, x1)\n\n        x2 = self.e2_c1(x1)\n        x2 = x2 + self.e2_c3(self.e2_c2(x2))\n        infor2 = self.Downsample1(infor1)\n        x2 = self.attehtion_block2(infor2, x2)\n\n        x3 = self.e3_c1(x2)\n        x3 = x3 + self.e3_c3(self.e3_c2(x3))\n        infor3 = self.Downsample2(infor2)\n        x3 = self.attehtion_block3(infor3, x3)\n\n        x4 = self.e4_c1(x3)\n        x4 = x4 + self.e4_c3(self.e4_c2(x4))\n        infor4 = self.Downsample3(infor3)\n        x4 = self.attehtion_block4(infor4, x4)\n\n        x5 = self.e5_c1(x4)\n        x5 = x5 + self.e5_c3(self.e5_c2(x5))\n        infor5 = self.Downsample4(infor4)\n        x5 = self.attehtion_block5(infor5, x5)\n\n        return x1, x2, x3, x4, x5", "\nclass Decoder_sep(nn.Module):\n    def __init__(self, num_cls=1):\n        super(Decoder_sep, self).__init__()\n\n        self.d4 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n        self.d4_c1 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n        self.d4_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n        self.d4_out = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, k_size=1, padding=0, pad_type='zeros')\n\n        self.d3 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n        self.d3_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n        self.d3_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n        self.d3_out = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, k_size=1, padding=0, pad_type='zeros')\n\n        self.d2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n        self.d2_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n        self.d2_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n        self.d2_out = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, k_size=1, padding=0, pad_type='zeros')\n\n        self.d1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n        self.d1_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n        self.d1_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n        self.d1_out = general_conv3d_prenorm(basic_dims, basic_dims, k_size=1, padding=0, pad_type='zeros')\n\n        self.seg_layer = nn.Conv3d(in_channels=basic_dims, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                   bias=True)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x1, x2, x3, x4, x5):\n        de_x5 = self.d4_c1(self.d4(x5))\n\n        cat_x4 = torch.cat((de_x5, x4), dim=1)\n        de_x4 = self.d4_out(self.d4_c2(cat_x4))\n        de_x4 = self.d3_c1(self.d3(de_x4))\n\n        cat_x3 = torch.cat((de_x4, x3), dim=1)\n        de_x3 = self.d3_out(self.d3_c2(cat_x3))\n        de_x3 = self.d2_c1(self.d2(de_x3))\n\n        cat_x2 = torch.cat((de_x3, x2), dim=1)\n        de_x2 = self.d2_out(self.d2_c2(cat_x2))\n        de_x2 = self.d1_c1(self.d1(de_x2))\n\n        cat_x1 = torch.cat((de_x2, x1), dim=1)\n        de_x1 = self.d1_out(self.d1_c2(cat_x1))\n\n        logits = self.seg_layer(de_x1)\n        # pred = self.softmax(logits)\n        return torch.sigmoid(logits)", "\n\nclass Downsample(nn.Module):\n    def __init__(self):\n        super(Downsample, self).__init__()\n\n        self.inforconv = general_conv3d_prenorm(1, basic_dims, pad_type='zeros')\n        self.Downsample1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n        self.Downsample2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n        self.Downsample3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n        self.Downsample4 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n\n    def forward(self, x):\n        x1 = self.inforconv(x)\n        x2 = self.Downsample1(x1)\n        x3 = self.Downsample2(x2)\n        x4 = self.Downsample3(x3)\n        x5 = self.Downsample4(x4)\n        return x1, x2, x3, x4, x5", "\nclass att(nn.Module):\n    def __init__(self, in_channel=8):\n        super(att, self).__init__()\n        self.weight_layer = nn.Sequential(\n                            nn.Conv3d(4*in_channel, 128, 1, padding=0, bias=True),\n                            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n                            nn.Conv3d(128, 1, 1, padding=0, bias=True))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, infor, all):\n        B, C, H, W, Z = infor.size()\n\n        infor_avg = torch.mean(infor, dim=(2, 3, 4), keepdim=False)\n        all_avg = torch.mean(all, dim=(2, 3, 4), keepdim=False)\n\n        infor_avg = infor_avg.view(B, C, 1, 1, 1)\n        all_avg = all_avg.view(B, 3 * C, 1, 1, 1)\n        infor_avg = torch.cat((infor_avg, all_avg), dim=1)\n        weight = torch.reshape(self.weight_layer(infor_avg), (B, 1))\n        weight = self.sigmoid(weight).view(B, 1, 1, 1, 1)\n\n        region_feat = infor * weight\n        return region_feat", "\nclass MTG(nn.Module):\n    def __init__(self, in_channel=8):\n        super(MTG, self).__init__()\n\n        self.att_adc = att(in_channel)\n        self.att_t2 = att(in_channel)\n        self.conv_layer = general_conv3d_prenorm(in_channel, in_channel, pad_type='zeros')\n        self.fusion_prenorm = fusion_prenorm(in_channel)\n\n    def forward(self, DCE, ADC, T2, InforDCE, InforADC, InforT2):\n\n        newDCE = DCE * InforDCE\n        newADC = ADC * InforADC\n        newT2 = T2 * InforT2\n        all = torch.cat((newDCE, newADC, newT2), dim=1)\n\n        trust_ADC = self.att_adc(newADC, all)\n        trust_T2 = self.att_t2(newT2, all)\n\n        weight = self.fusion_prenorm(all) + trust_ADC + trust_T2\n\n        x = self.conv_layer(weight)\n        return x", "\nclass MoSID(nn.Module):\n    def __init__(self, num_cls=1):\n        super(MoSID, self).__init__()\n        self.DCE_encoder = Encoder(flag=False)\n        self.ADC_encoder = Encoder(flag=True)\n        self.T2_encoder = Encoder(flag=True)\n\n        self.decoder_sep = Decoder_sep(num_cls=num_cls)\n\n        self.downsample1 = Downsample()\n        self.downsample2 = Downsample()\n        self.downsample3 = Downsample()\n        self.MTG1 = MTG(in_channel=basic_dims * 1)\n        self.MTG2 = MTG(in_channel=basic_dims * 2)\n        self.MTG3 = MTG(in_channel=basic_dims * 4)\n        self.MTG4 = MTG(in_channel=basic_dims * 8)\n        self.MTG5 = MTG(in_channel=basic_dims * 16)\n\n        self.is_training = True\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                torch.nn.init.kaiming_normal_(m.weight)\n\n    def forward(self, DCE, Sub, ADC, T2, InforDCE, InforADC, InforT2):\n\n        input1 = torch.cat((DCE, Sub), dim=1)\n\n        DCE_x1, DCE_x2, DCE_x3, DCE_x4, DCE_x5 = self.DCE_encoder(input1, InforDCE)\n        ADC_x1, ADC_x2, ADC_x3, ADC_x4, ADC_x5 = self.ADC_encoder(ADC, InforADC)\n        T2_x1, T2_x2, T2_x3, T2_x4, T2_x5 = self.T2_encoder(T2, InforT2)\n\n\n        InforDCE_x1, InforDCE_x2, InforDCE_x3, InforDCE_x4, InforDCE_x5 = self.downsample1(InforDCE)\n        InforADC_x1, InforADC_x2, InforADC_x3, InforADC_x4, InforADC_x5 = self.downsample2(InforADC)\n        InforT2_x1, InforT2_x2, InforT2_x3, InforT2_x4, InforT2_x5 = self.downsample3(InforT2)\n\n        x1 = self.MTG1(DCE_x1, ADC_x1, T2_x1, InforDCE_x1, InforADC_x1, InforT2_x1)\n        x2 = self.MTG2(DCE_x2, ADC_x2, T2_x2, InforDCE_x2, InforADC_x2, InforT2_x2)\n        x3 = self.MTG3(DCE_x3, ADC_x3, T2_x3, InforDCE_x3, InforADC_x3, InforT2_x3)\n        x4 = self.MTG4(DCE_x4, ADC_x4, T2_x4, InforDCE_x4, InforADC_x4, InforT2_x4)\n        x5 = self.MTG5(DCE_x5, ADC_x5, T2_x5, InforDCE_x5, InforADC_x5, InforT2_x5)\n\n        fuse_pred = self.decoder_sep(x1, x2, x3, x4, x5)\n\n        return fuse_pred", "\n\n\nif __name__ == '__main__':\n    a = torch.zeros([1, 1, 32, 128, 128])\n    b = torch.zeros([1, 1, 32, 128, 128])\n    c = torch.zeros([1, 1, 32, 128, 128])\n    d = torch.zeros([1, 1, 32, 128, 128])\n    e = torch.zeros([1, 1, 32, 128, 128])\n    f = torch.zeros([1, 1, 32, 128, 128])\n    g = torch.zeros([1, 1, 32, 128, 128])\n\n    x = torch.cat((a, b, c, d, e, f, g), dim=1)\n    model = MoSID(num_cls=1)\n    out = model(a, b, c, d, e, f, g)\n    print(out[1].shape)", "\n\n"]}
{"filename": "Step3-Tumor-Segmentation/Model/__init__.py", "chunked_list": [""]}
{"filename": "Step1-Image-Synthesis/train.py", "chunked_list": ["import torch\nimport numpy as np\nimport torch.optim as optim\nfrom options.Options import Options_x\nfrom dataset.dataset_lits_train import Lits_DataSet\nfrom dataset.dataset_lits_val import Val_DataSet\n\nfrom Model.runet import RUnet\nfrom torch.utils.data import DataLoader\nfrom setting.common import adjust_learning_rate", "from torch.utils.data import DataLoader\nfrom setting.common import adjust_learning_rate\nfrom setting import logger,util\nimport torch.nn as nn\nfrom setting.metrics import LossAverage\nimport os\nimport time\nfrom test import test_all\nfrom collections import OrderedDict\n", "from collections import OrderedDict\n\n\n\ndef train(train_dataloader, epoch):\n    since = time.time()\n    Loss = LossAverage()\n    model.train()\n\n    for i, (DCE,ADC, gt) in enumerate(train_dataloader):  # inner loop within one epoch\n\n        b, c, l, w, e = ADC.shape[0], ADC.shape[1], ADC.shape[2], ADC.shape[3], ADC.shape[4]\n\n        ADC = ADC.view(-1, 1, l, w, e).to(device)\n        DCE = DCE.view(-1, 1, l, w, e).to(device)\n\n        pred = model(DCE)\n        loss = nn.L1Loss()(pred, ADC)\n\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        adjust_learning_rate(optimizer, epoch, opt)\n\n        Loss.update(loss.item(), ADC.size(0))\n\n\n    time_elapsed = time.time() - since\n    print(\"=======Train Epoch:{}======Learning_rate:{}======Train complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n\n    return OrderedDict({'Loss': Loss.avg})", "\n\ndef val(val_dataloader, epoch):\n    since = time.time()\n\n    Loss = LossAverage()\n    model.eval()\n\n    for i, (DCE,ADC, gt) in enumerate(val_dataloader):  # inner loop within one epoch\n\n        b, c, l, w, e = ADC.shape[0], ADC.shape[1], ADC.shape[2], ADC.shape[3], ADC.shape[4]\n\n        ADC = ADC.view(-1, 1, l, w, e).to(device)\n        DCE = DCE.view(-1, 1, l, w, e).to(device)\n\n        pred = model(DCE)\n        loss = nn.L1Loss()(pred, ADC)\n\n        Loss.update(loss.item(), ADC.size(0))\n\n    time_elapsed = time.time() - since\n\n    return OrderedDict({'Loss': Loss.avg})", "\n\nif __name__ == '__main__':\n    opt = Options_x().parse()   # get training options\n    device = torch.device('cuda:'+opt.gpu_ids if torch.cuda.is_available() else \"cpu\")\n    print(\"using {} device.\".format(device))\n\n    model = RUnet(num_cls=1).to(device)\n\n    save_path = opt.checkpoints_dir\n\n    save_result_path = os.path.join(save_path, opt.task_name)\n    util.mkdir(save_result_path)\n\n    optimizer = optim.Adam(model.parameters(), lr=opt.lr, weight_decay=1e-5)\n    model_save_path = os.path.join(save_result_path, 'model')\n    util.mkdir(model_save_path)\n    logger_save_path = os.path.join(save_result_path, 'logger')\n    util.mkdir(logger_save_path)\n\n    log_train = logger.Train_Logger(logger_save_path, \"train_log\")\n    log_val = logger.Val_Logger(logger_save_path, \"val_log\")\n\n    train_dataset = Lits_DataSet(opt.datapath, opt.patch_size)\n    val_dataset = Val_DataSet(opt.datapath, opt.patch_size)\n\n    train_dataloader = DataLoader(dataset=train_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n    val_dataloader = DataLoader(dataset=val_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n\n    types = ['train','val']\n    val_loss = 99\n    best_epoch = 0\n\n    for epoch in range(opt.epoch):\n        epoch = epoch + 1\n        for type in types:\n            if type == 'train':\n                train_log = train(train_dataloader, epoch)\n                log_train.update(epoch, train_log)\n            elif type == 'val':\n                val_log = val(val_dataloader, epoch)\n                log_val.update(epoch, val_log)\n                if val_log['DICE_Loss'] < val_loss:\n                    best_epoch = epoch\n                    val_loss = val_log['DICE_Loss']\n                    state = {'model': model.state_dict(), 'epoch': best_epoch}\n                    torch.save(state, os.path.join(model_save_path, 'best_model.pth'))\n\n        state = {'model': model.state_dict(), 'epoch': epoch}\n        torch.save(state, os.path.join(model_save_path, 'latest_model.pth'))\n\n        if epoch % opt.model_save_fre == 0:\n            torch.save(state, os.path.join(model_save_path, 'model_'+np.str(epoch)+'.pth'))\n\n        torch.cuda.empty_cache()\n\n    test_all('best_model.pth')", "\n\n\n\n\n\n\n\n\n", "\n\n\n\n\n"]}
{"filename": "Step1-Image-Synthesis/test.py", "chunked_list": ["import torch\nimport gc\nimport numpy as np\nimport SimpleITK as sitk\nfrom options.Options import Options_x\nfrom tqdm import tqdm\nfrom Model.runet import RUnet\nfrom torch.utils.data import DataLoader\nfrom setting import logger,util\nimport os", "from setting import logger,util\nimport os\nfrom dataset.dataset_lits_test import Test_all_Datasets, Recompone_tool\n\n\n\ndef load(file):\n    itkimage = sitk.ReadImage(file)\n    image = sitk.GetArrayFromImage(itkimage)\n    return image", "\n\ndef test_all(model_name='model_200.pth'):\n    opt = Options_x().parse()  # get training options\n    device = torch.device('cuda:'+opt.gpu_ids if torch.cuda.is_available() else \"cpu\")\n    print(\"using {} device.\".format(device))\n\n    model = RUnet(num_cls=1).to(device)\n    ckpt = torch.load(opt.checkpoints_dir + '/' + opt.task_name + '/model/' + model_name, map_location=device)\n    model.load_state_dict(ckpt['model'])\n\n    save_result_path = os.path.join(opt.checkpoints_dir, opt.task_name, 'test_all_result')\n    util.mkdir(save_result_path)\n    model.eval()\n    log_test = logger.Test_Logger(save_result_path, \"results\")\n    cut_param = {'patch_s': 192, 'patch_h': 192, 'patch_w': 320,\n                 'stride_s': 192, 'stride_h': 192, 'stride_w': 192}\n    datasets = Test_all_Datasets(opt.datapath, cut_param)\n\n    for img_dataset, original_shape, new_shape,  file_idx in datasets:\n        save_tool = Recompone_tool(original_shape, new_shape, cut_param)\n        dataloader = DataLoader(img_dataset, batch_size=opt.test_batch, num_workers=opt.num_threads, shuffle=False)\n        with torch.no_grad():\n            for DCE in tqdm(dataloader):\n                DCE= DCE.to(device)\n                DCE = DCE.unsqueeze(1).type(torch.float32)\n                pred = model(DCE)\n\n                output = pred.type(torch.float32)\n                save_tool.add_result(output.detach().cpu())\n\n        recon = save_tool.recompone_overlap()\n        Pred = sitk.GetImageFromArray(np.array(recon))\n        aaaaaa = sitk.ReadImage(os.path.join(opt.datapath,file_idx,'ADC.nii.gz'))\n        Pred.SetSpacing(aaaaaa.GetSpacing())\n        Pred.SetDirection(aaaaaa.GetDirection())\n        Pred.SetOrigin(aaaaaa.GetOrigin())\n        sitk.WriteImage(Pred, os.path.join(save_result_path, file_idx+'.nii.gz'))\n        del pred, recon, Pred, save_tool\n        gc.collect()\n        torch.cuda.empty_cache()", "\n\nif __name__ == '__main__':\n    test_all('best_model.pth')\n"]}
{"filename": "Step1-Image-Synthesis/setting/weights_init.py", "chunked_list": ["from torch.nn import init\n\n\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    #print(classname)\n    if classname.find('Conv') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('Linear') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_xavier(m):\n    classname = m.__class__.__name__\n    #print(classname)\n    if classname.find('Conv') != -1:\n        init.xavier_normal(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.xavier_normal(m.weight.data, gain=1)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    #print(classname)\n    if classname.find('Conv') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('Linear') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef weights_init_orthogonal(m):\n    classname = m.__class__.__name__\n    #print(classname)\n    if classname.find('Conv') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('BatchNorm') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)", "\n\ndef init_weights(net, init_type='normal'):\n    #print('initialization method [%s]' % init_type)\n    if init_type == 'normal':\n        net.apply(weights_init_normal)\n    elif init_type == 'xavier':\n        net.apply(weights_init_xavier)\n    elif init_type == 'kaiming':\n        net.apply(weights_init_kaiming)\n    elif init_type == 'orthogonal':\n        net.apply(weights_init_orthogonal)\n    else:\n        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)"]}
{"filename": "Step1-Image-Synthesis/setting/metrics.py", "chunked_list": ["\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\n#from medpy.metric.binary import dc,asd,hd,sensitivity, precision, ravd\nimport numpy as np\nimport sys\nfrom scipy.ndimage import morphology\nsys.dont_write_bytecode = True  # don't generate the binray python file .pyc\n\nclass LossAverage(object):\n    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = round(self.sum / self.count, 4)", "sys.dont_write_bytecode = True  # don't generate the binray python file .pyc\n\nclass LossAverage(object):\n    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = round(self.sum / self.count, 4)", "        # print(self.val)\n\n\n\nclass DiceLoss(nn.Module):\n    \"\"\"\n    define the dice loss\n    \"\"\"\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, input, target):\n        smooth = 1.\n        iflat = input.contiguous().view(-1)\n        tflat = target.contiguous().view(-1)\n        intersection = (iflat * tflat).sum()\n\n        A_sum = torch.sum(iflat * iflat)\n        B_sum = torch.sum(tflat * tflat)\n\n        return 1-((2. * intersection + smooth) / (A_sum + B_sum + smooth))", "\n\n\"\"\"dice coefficient\"\"\"\ndef dice(pre, gt, tid=1):\n    pre=pre==tid   #make it boolean\n    gt=gt==tid     #make it boolean\n    pre=np.asarray(pre).astype(np.bool)\n    gt=np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    dsc=(2. * intersection.sum() + 1e-07) / (pre.sum() + gt.sum() + 1e-07)\n\n    return dsc", "\n\"\"\"positive predictive value\"\"\"\ndef pospreval(pre,gt,tid=1):\n    pre=pre==tid #make it boolean\n    gt=gt==tid   #make it boolean\n    pre=np.asarray(pre).astype(np.bool)\n    gt=np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    ppv=(1.0*intersection.sum() + 1e-07) / (pre.sum()+1e-07)\n\n    return ppv", "\n\"\"\"sensitivity\"\"\"\ndef sensitivity(pre,gt,tid=1):\n    pre=pre==tid #make it boolean\n    gt=gt==tid   #make it boolean\n    pre=np.asarray(pre).astype(np.bool)\n    gt=np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    sen=(1.0*intersection.sum()+1e-07) / (gt.sum()+1e-07)\n\n    return sen", "\n\"\"\"specificity\"\"\"\ndef specificity(pre,gt):\n    pre=pre==0 #make it boolean\n    gt=gt==0   #make it boolean\n    pre=np.asarray(pre).astype(np.bool)\n    gt=np.asarray(gt).astype(np.bool)\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    intersection = np.logical_and(pre, gt)\n    spe=(1.0*intersection.sum()+1e-07) / (gt.sum()+1e-07)\n\n    return spe", "\n\"\"\"average surface distance\"\"\"#\u5982\u4f55\u8ba1\u7b97ASD\u76f8\u5173\u7684\u6307\u6807\u3002\ndef surfd(pre, gt, tid=1, sampling=1, connectivity=1):\n    pre=pre==tid   #make it boolean\n    gt=gt==tid     #make it boolean\n\n    if pre.shape != gt.shape:\n        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\n    input_1 = np.atleast_1d(pre.astype(np.bool))\n    input_2 = np.atleast_1d(gt.astype(np.bool))\n\n    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n\n    S = np.logical_xor(input_1,morphology.binary_erosion(input_1, conn))\n    Sprime = np.logical_xor(input_2,morphology.binary_erosion(input_2, conn))\n\n    dta = morphology.distance_transform_edt(~S,sampling)\n    dtb = morphology.distance_transform_edt(~Sprime,sampling)\n\n    sds = np.concatenate([np.ravel(dta[Sprime!=0]), np.ravel(dtb[S!=0])])\n    return sds", "\ndef asd(pre, gt, tid=1, sampling=1, connectivity=1):\n    sds = surfd(pre, gt, tid=tid, sampling=sampling, connectivity=connectivity)\n    dis = sds.mean()\n    return dis\n\n\n\ndef seg_metric(pre,gt):\n\n    mask = (pre>0.5)\n    gt = (gt>0.5)\n    ASD = asd(mask, gt)\n    DSC = dice(mask, gt)\n    SEN = sensitivity(mask,gt)\n    PPV = pospreval(mask,gt)\n\n\n    return DSC,PPV,SEN,ASD", "def seg_metric(pre,gt):\n\n    mask = (pre>0.5)\n    gt = (gt>0.5)\n    ASD = asd(mask, gt)\n    DSC = dice(mask, gt)\n    SEN = sensitivity(mask,gt)\n    PPV = pospreval(mask,gt)\n\n\n    return DSC,PPV,SEN,ASD", "\n\n\n\n"]}
{"filename": "Step1-Image-Synthesis/setting/logger.py", "chunked_list": ["import pandas as pd\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\nimport torch, random\nimport numpy as np\nfrom collections import OrderedDict\n\n\nclass Train_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, epoch, train_log):\n        item = OrderedDict({'epoch': epoch})\n        item.update(train_log)\n        print(\"\\033[0;33mTrain:\\033[0m\", train_log)\n        self.update_csv(item)\n        self.update_tensorboard(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\n    def update_tensorboard(self, item):\n        if self.summary is None:\n            self.summary = SummaryWriter('%s/' % self.save_path)\n        epoch = item['epoch']\n        for key, value in item.items():\n            if key != 'epoch': self.summary.add_scalar(key, value, epoch)", "class Train_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, epoch, train_log):\n        item = OrderedDict({'epoch': epoch})\n        item.update(train_log)\n        print(\"\\033[0;33mTrain:\\033[0m\", train_log)\n        self.update_csv(item)\n        self.update_tensorboard(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\n    def update_tensorboard(self, item):\n        if self.summary is None:\n            self.summary = SummaryWriter('%s/' % self.save_path)\n        epoch = item['epoch']\n        for key, value in item.items():\n            if key != 'epoch': self.summary.add_scalar(key, value, epoch)", "\n\nclass Val_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, epoch, val_log):\n        item = OrderedDict({'epoch': epoch})\n        item.update(val_log)\n        # item = dict_round(item,4) # \u4fdd\u7559\u5c0f\u6570\u70b9\u540e\u56db\u4f4d\u6709\u6548\u6570\u5b57\n        print(\"\\033[0;33mValidate:\\033[0m\", val_log)\n        self.update_csv(item)\n        self.update_tensorboard(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\n    def update_tensorboard(self, item):\n        if self.summary is None:\n            self.summary = SummaryWriter('%s/' % self.save_path)\n        epoch = item['epoch']\n        for key, value in item.items():\n            if key != 'epoch': self.summary.add_scalar(key, value, epoch)", "\n\nclass Test_Logger():\n    def __init__(self, save_path, save_name):\n        self.log = None\n        self.summary = None\n        self.save_path = save_path\n        self.save_name = save_name\n\n    def update(self, name, log):\n        item = OrderedDict({'img_name': name})\n        item.update(log)\n        print(\"\\033[0;33mTest:\\033[0m\", log)\n        self.update_csv(item)\n\n    def update_csv(self, item):\n        tmp = pd.DataFrame(item, index=[0])\n        if self.log is not None:\n            self.log = self.log.append(tmp, ignore_index=True)\n        else:\n            self.log = tmp\n        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)", "\n\ndef setpu_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    random.seed(seed)\n\n\ndef dict_round(dic, num):\n    for key, value in dic.items():\n        dic[key] = round(value, num)\n    return dic", "\n\ndef dict_round(dic, num):\n    for key, value in dic.items():\n        dic[key] = round(value, num)\n    return dic\n"]}
{"filename": "Step1-Image-Synthesis/setting/util.py", "chunked_list": ["\"\"\"This module contains simple helper functions \"\"\"\nfrom __future__ import print_function\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport os\n\n\ndef tensor2im(input_image, imtype=np.uint8):\n    \"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"\n    if not isinstance(input_image, np.ndarray):\n        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n            image_tensor = input_image.data\n        else:\n            return input_image\n        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n        if image_numpy.shape[0] == 1:  # grayscale to RGB\n            image_numpy = np.tile(image_numpy, (3, 1, 1))\n        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n    else:  # if it is a numpy array, do nothing\n        image_numpy = input_image\n    return image_numpy.astype(imtype)", "def tensor2im(input_image, imtype=np.uint8):\n    \"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"\n    if not isinstance(input_image, np.ndarray):\n        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n            image_tensor = input_image.data\n        else:\n            return input_image\n        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n        if image_numpy.shape[0] == 1:  # grayscale to RGB\n            image_numpy = np.tile(image_numpy, (3, 1, 1))\n        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n    else:  # if it is a numpy array, do nothing\n        image_numpy = input_image\n    return image_numpy.astype(imtype)", "\n\ndef diagnose_network(net, name='network'):\n    \"\"\"Calculate and print the mean of average absolute(gradients)\n\n    Parameters:\n        net (torch network) -- Torch network\n        name (str) -- the name of the network\n    \"\"\"\n    mean = 0.0\n    count = 0\n    for param in net.parameters():\n        if param.grad is not None:\n            mean += torch.mean(torch.abs(param.grad.data))\n            count += 1\n    if count > 0:\n        mean = mean / count\n    print(name)\n    print(mean)", "\n\ndef save_image(image_numpy, image_path, aspect_ratio=1.0):\n    \"\"\"Save a numpy image to the disk\n\n    Parameters:\n        image_numpy (numpy array) -- input numpy array\n        image_path (str)          -- the path of the image\n    \"\"\"\n\n    image_pil = Image.fromarray(image_numpy)\n    h, w, _ = image_numpy.shape\n\n    if aspect_ratio > 1.0:\n        image_pil = image_pil.resize((h, int(w * aspect_ratio)), Image.BICUBIC)\n    if aspect_ratio < 1.0:\n        image_pil = image_pil.resize((int(h / aspect_ratio), w), Image.BICUBIC)\n    image_pil.save(image_path)", "\n\ndef print_numpy(x, val=True, shp=False):\n    \"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"\n    x = x.astype(np.float64)\n    if shp:\n        print('shape,', x.shape)\n    if val:\n        x = x.flatten()\n        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))", "\n\ndef mkdirs(paths):\n    \"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)", "\n\ndef mkdir(path):\n    \"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"\n    \n    if not os.path.exists(path):\n        os.makedirs(path)", ""]}
{"filename": "Step1-Image-Synthesis/setting/common.py", "chunked_list": ["import SimpleITK as sitk\nimport numpy as np\n#import pytorch_ssim\n#from skimage.metrics import structural_similarity\nimport math\nfrom torch.autograd import Variable\nfrom scipy import ndimage\nimport torch, random\n\n", "\n\n\ndef normalization(img):\n    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n    return out\n\n\ndef normalization_test (img):\n    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n    return out, np.max(img), np.min(img)", "def normalization_test (img):\n    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n    return out, np.max(img), np.min(img)\n\ndef center_crop_3d(img, label, slice_num=16):\n    if img.shape[0] < slice_num:\n        return None\n    left_x = img.shape[0]//2 - slice_num//2\n    right_x = img.shape[0]//2 + slice_num//2\n\n    crop_img = img[left_x:right_x]\n    crop_label = label[left_x:right_x]\n    return crop_img, crop_label", "\ndef load_file_name_list(file_path):\n    file_name_list = []\n    with open(file_path, 'r') as file_to_read:\n        while True:\n            lines = file_to_read.readline().strip()\n            if not lines:\n                break\n                pass\n            file_name_list.append(lines)\n            pass\n    return file_name_list", "\n\ndef MaskContour(image, position='xy', line=1):\n    itkimage = sitk.GetImageFromArray(image)\n    if position == 'xy':\n        erode_m = [line, line, 0]\n    elif position == 'yz':\n        erode_m = [0, line, line]\n    elif position == 'zx':\n        erode_m = [line, 0, line]\n    else:\n        erode_m = [line, line, 0]\n\n    mask = sitk.GetArrayFromImage(sitk.BinaryErode(itkimage, erode_m))\n    boundary = image - mask\n    out = sitk.GetImageFromArray(boundary)\n    return out", "\n\ndef print_network(net):\n    num_params = 0\n    for param in net.parameters():\n        num_params += param.numel()\n    print(net)\n    print('Total number of parameters: %d' % num_params)\n\ndef adjust_learning_rate(optimizer, epoch, opt):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n    lr = opt.lr * (0.5 ** (epoch // opt.step))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr", "\ndef adjust_learning_rate(optimizer, epoch, opt):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n    lr = opt.lr * (0.5 ** (epoch // opt.step))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\ndef adjust_learning_rate_V2(optimizer, lr):\n    \"\"\"Sets the learning rate to a fixed number\"\"\"\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr", "        \n        \n        \ndef get_mse(img1, img2):\n    mse = np.mean( (img1 - img2) ** 2 )\n\n    return mse\n\n\ndef get_psnr(img1, img2):\n    mse = np.mean( (img1 - img2) ** 2 )\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1.0\n    return 10 * math.log10(PIXEL_MAX / math.sqrt(mse))", "\ndef get_psnr(img1, img2):\n    mse = np.mean( (img1 - img2) ** 2 )\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1.0\n    return 10 * math.log10(PIXEL_MAX / math.sqrt(mse))\n\n'''\ndef get_ssim(img1,img2):", "'''\ndef get_ssim(img1,img2):\n    n=img1.shape[0]\n    out = 0\n    for i in range(n):\n        out+=structural_similarity(img1[i].squeeze(),img2[i].squeeze())\n        \n    return out/n\n'''    \n    ", "'''    \n    \n\ndef save_result(low_dose, high_dose, output, i, epoch):\n    def save_img(img, name):\n        # img = SimpleITK.GetImageFromArray(img[0,0].cpu().detach().numpy())\n        img = sitk.GetImageFromArray(img)\n        sitk.WriteImage(img, 'result/image/'+name+'.nii.gz')\n        \n    save_img(low_dose, 'low_dose_epoch_'+str(epoch) + \"_\" + str(i))\n    save_img(high_dose, 'high_dose_epoch_'+str(epoch) + \"_\" + str(i))\n    save_img(output, 'output_epoch_'+str(epoch) + \"_\" + str(i))", "\n\ndef de_normalization(img,max_x,min_x):\n    return img*(max_x - min_x) + min_x"]}
{"filename": "Step1-Image-Synthesis/options/BasicOptions.py", "chunked_list": ["import argparse\nimport os\nfrom setting import util\nimport torch\n\n\nclass BaseOptions():\n    \"\"\"This class defines options used during both training and test time.\n\n    It also implements several helper functions such as parsing, printing, and saving the options.\n    It also gathers additional options defined in <modify_commandline_options> functions in both dataset class and model class.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"\n        self.initialized = False\n\n    def initialize(self, parser):\n        \"\"\"Define the common options that are used in both training and test.\"\"\"\n        # basic parameters\n        \n        parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n        parser.add_argument('--num_threads', default=2, type=int, help='# threads for loading data')\n        \n        parser.add_argument('--batch_size', type=int, default=6, help='input train batch size')\n        parser.add_argument('--test_batch', type=int, default=16, help='input test batch size')\n        parser.add_argument('--epoch', type=int, default=500, help='number of epochs with the initial learning rate')\n        parser.add_argument('--step', type=int, default=50, help='number of epochs to adjust learning rate')\n        parser.add_argument('--datapath', default = r'/data', help='path of the raw data')\n        parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate of net for adam')\n        parser.add_argument('--model_save_fre', type=int, default=50, help='frequency of saving model')\n        parser.add_argument('--patch_size', type=int, default=(128, 160, 320), help='the size of crop patch')\n        parser.add_argument('--patch_stride', type=int, default=(8, 64, 64), help='the stride of patch')\n        parser.add_argument('--gpu_ids', type=str, default='1', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n        parser.add_argument('--task_name', type=str, default='Multi-parametric_adc', help='the current task name')\n        self.initialized = True\n        return parser\n\n    def gather_options(self):\n        \"\"\"Initialize our parser with basic options(only once).\n        Add additional model-specific and dataset-specific options.\n        These options are defined in the <modify_commandline_options> function\n        in model and dataset classes.\n        \"\"\"\n        if not self.initialized:  # check if it has been initialized\n            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n            parser = self.initialize(parser)\n\n        # get the basic options\n        opt, _ = parser.parse_known_args()\n        # save and return the parser\n        self.parser = parser\n        return parser.parse_args()\n\n    def print_options(self, opt):\n        \"\"\"Print and save options\n\n        It will print both current options and default values(if different).\n        It will save options into a text file / [checkpoints_dir] / opt.txt\n        \"\"\"\n        message = ''\n        message += '----------------- Options ---------------\\n'\n        for k, v in sorted(vars(opt).items()):\n            comment = ''\n            default = self.parser.get_default(k)\n            if v != default:\n                comment = '\\t[default: %s]' % str(default)\n            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n        message += '----------------- End -------------------'\n        print(message)\n\n        # save to the disk\n        expr_dir = os.path.join(opt.checkpoints_dir, 'model_parameter_list')\n        util.mkdirs(expr_dir)\n        file_name = os.path.join(expr_dir, '{train_opt.txt')\n        with open(file_name, 'wt') as opt_file:\n            opt_file.write(message)\n            opt_file.write('\\n')\n\n    def parse(self):\n        \"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"\n        opt = self.gather_options()\n        opt.isTrain = self.isTrain   # train or test\n\n        self.print_options(opt)\n\n        self.opt = opt\n        return self.opt", "\n"]}
{"filename": "Step1-Image-Synthesis/options/Options.py", "chunked_list": ["from options.BasicOptions import BaseOptions\n\n\nclass Options_x(BaseOptions):\n    \"\"\"This class includes training options.\n\n    It also includes shared options defined in BaseOptions.\n    \"\"\"\n\n    def initialize(self, parser):\n        parser = BaseOptions.initialize(self, parser)\n        # visdom and HTML visualization parameters\n        parser.add_argument('--name', type=str, default='Tumor_seg', help='name_of_the_project')\n        self.isTrain = True\n        return parser", ""]}
{"filename": "Step1-Image-Synthesis/dataset/dataset_lits_test.py", "chunked_list": ["import numpy as np\nimport torch, os\nfrom torch.utils.data import Dataset, DataLoader\nfrom glob import glob\nimport random\nimport SimpleITK as sitk\n\n\ndef min_max_normalization(img):\n    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n    return out", "def min_max_normalization(img):\n    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n    return out\n\n\ndef normalization(img, lmin=1, rmax=None, dividend=None, quantile=None):\n    newimg = img.copy()\n    newimg = newimg.astype(np.float32)\n    if quantile is not None:\n        maxval = round(np.percentile(newimg, 100 - quantile))\n        minval = round(np.percentile(newimg, quantile))\n        newimg[newimg >= maxval] = maxval\n        newimg[newimg <= minval] = minval\n\n    if lmin is not None:\n        newimg[newimg < lmin] = lmin\n    if rmax is not None:\n        newimg[newimg > rmax] = rmax\n\n    minval = np.min(newimg)\n    if dividend is None:\n        maxval = np.max(newimg)\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n    else:\n        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n    return newimg", "\n\ndef load(file):\n    itkimage = sitk.ReadImage(file)\n    image = sitk.GetArrayFromImage(itkimage)\n    return image\n\n\ndef random_crop_3d(adc, pos, sub, gt, crop_size):\n    cor_box = maskcor_extract_3d(gt)\n    random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], adc.shape[0] - crop_size[0])\n    random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], adc.shape[1] - crop_size[1])\n    random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], adc.shape[2] - crop_size[2])\n    if random_x_min > random_x_max:\n        random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n    if random_y_min > random_y_max:\n        random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n    if random_z_min > random_z_max:\n        random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\n    # print(cor_box[0, 0], cor_box[0, 1],cor_box[1, 0], cor_box[1, 1],cor_box[2, 0], cor_box[2, 1])\n    # print(random_x_min, random_x_max,random_y_min, random_y_max,random_z_min, random_z_max)\n    x_random = random.randint(random_x_min, random_x_max)\n    y_random = random.randint(random_y_min, random_y_max)\n    z_random = random.randint(random_z_min, random_z_max)\n\n    adc_patch = adc[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                z_random:z_random + crop_size[2]]\n    pos_patch = pos[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                z_random:z_random + crop_size[2]]\n    sub_patch = sub[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                z_random:z_random + crop_size[2]]\n    gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n               z_random:z_random + crop_size[2]]\n\n    return adc_patch, pos_patch, sub_patch, gt_patch", "def random_crop_3d(adc, pos, sub, gt, crop_size):\n    cor_box = maskcor_extract_3d(gt)\n    random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], adc.shape[0] - crop_size[0])\n    random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], adc.shape[1] - crop_size[1])\n    random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], adc.shape[2] - crop_size[2])\n    if random_x_min > random_x_max:\n        random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n    if random_y_min > random_y_max:\n        random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n    if random_z_min > random_z_max:\n        random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\n    # print(cor_box[0, 0], cor_box[0, 1],cor_box[1, 0], cor_box[1, 1],cor_box[2, 0], cor_box[2, 1])\n    # print(random_x_min, random_x_max,random_y_min, random_y_max,random_z_min, random_z_max)\n    x_random = random.randint(random_x_min, random_x_max)\n    y_random = random.randint(random_y_min, random_y_max)\n    z_random = random.randint(random_z_min, random_z_max)\n\n    adc_patch = adc[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                z_random:z_random + crop_size[2]]\n    pos_patch = pos[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                z_random:z_random + crop_size[2]]\n    sub_patch = sub[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                z_random:z_random + crop_size[2]]\n    gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n               z_random:z_random + crop_size[2]]\n\n    return adc_patch, pos_patch, sub_patch, gt_patch", "\n\ndef maskcor_extract_3d(mask, padding=(5, 5, 5)):\n    # mask_s = mask.shape\n    p = np.where(mask > 0)\n    a = np.zeros([3, 2], dtype=np.int)\n    for i in range(3):\n        s = p[i].min()\n        e = p[i].max() + 1\n\n        ss = s - padding[i]\n        ee = e + padding[i]\n        if ss < 0:\n            ss = 0\n        if ee > mask.shape[i]:\n            ee = mask.shape[i]\n\n        a[i, 0] = ss\n        a[i, 1] = ee\n    return a", "\n\nclass Img_DataSet(Dataset):\n    def __init__(self, adc, cut_param):\n        self.adc = adc\n\n        self.ori_shape = self.adc.shape\n        self.cut_param = cut_param\n\n        self.adc = self.padding_img(self.adc, self.cut_param)\n        self.adc = self.extract_ordered_overlap(self.adc, self.cut_param)\n\n        self.new_shape = self.adc.shape\n\n    def __getitem__(self, index):\n        adc = self.adc[index]\n\n        return torch.from_numpy(adc)\n\n    def __len__(self):\n        return len(self.adc)\n\n    def padding_img(self, img, C):\n        assert (len(img.shape) == 3)  # 3D array\n        img_s, img_h, img_w = img.shape\n        leftover_s = (img_s - C['patch_s']) % C['stride_s']\n        leftover_h = (img_h - C['patch_h']) % C['stride_h']\n        leftover_w = (img_w - C['patch_w']) % C['stride_w']\n        if (leftover_s != 0):\n            s = img_s + (C['stride_s'] - leftover_s)\n        else:\n            s = img_s\n\n        if (leftover_h != 0):\n            h = img_h + (C['stride_h'] - leftover_h)\n        else:\n            h = img_h\n\n        if (leftover_w != 0):\n            w = img_w + (C['stride_w'] - leftover_w)\n        else:\n            w = img_w\n\n        tmp_full_imgs = np.zeros((s, h, w))\n        tmp_full_imgs[:img_s, :img_h, 0:img_w] = img\n        # print(\"Padded images shape: \" + str(tmp_full_imgs.shape))\n        return tmp_full_imgs\n\n    # Divide all the full_imgs in pacthes\n    def extract_ordered_overlap(self, img, C):\n        assert (len(img.shape) == 3)  # 3D arrays\n        img_s, img_h, img_w = img.shape\n        assert ((img_h - C['patch_h']) % C['stride_h'] == 0\n                and (img_w - C['patch_w']) % C['stride_w'] == 0\n                and (img_s - C['patch_s']) % C['stride_s'] == 0)\n        N_patches_s = (img_s - C['patch_s']) // C['stride_s'] + 1\n        N_patches_h = (img_h - C['patch_h']) // C['stride_h'] + 1\n        N_patches_w = (img_w - C['patch_w']) // C['stride_w'] + 1\n        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n        #        print(\"Patches number of the image:{} [s={} | h={} | w={}]\"\\\n        #               .format(N_patches_img, N_patches_s, N_patches_h, N_patches_w))\n        patches = np.empty((N_patches_img, C['patch_s'], C['patch_h'], C['patch_w']))\n        iter_tot = 0  # iter over the total number of patches (N_patches)\n        for s in range(N_patches_s):  # loop over the full images\n            for h in range(N_patches_h):\n                for w in range(N_patches_w):\n                    patch = img[s * C['stride_s']: s * C['stride_s'] + C['patch_s'],\n                            h * C['stride_h']: h * C['stride_h'] + C['patch_h'],\n                            w * C['stride_w']: w * C['stride_w'] + C['patch_w']]\n\n                    patches[iter_tot] = patch\n                    iter_tot += 1  # total\n        assert (iter_tot == N_patches_img)\n        return patches  # array with all the full_imgs divided in patches", "\n\nclass Recompone_tool():\n    def __init__(self, img_ori_shape, img_new_shape, Cut_para):\n        self.result = None\n        self.ori_shape = img_ori_shape\n        self.new_shape = img_new_shape\n        self.C = Cut_para\n\n    def add_result(self, tensor):\n        # tensor = tensor.detach().cpu() # shape: [N,class,s,h,w]\n        # tensor_np = np.squeeze(tensor_np,axis=0)\n        if self.result is not None:\n            self.result = torch.cat((self.result, tensor), dim=0)\n        else:\n            self.result = tensor\n\n    def recompone_overlap(self):\n        \"\"\"\n        :param adcds: output of model  shape\uff1a[N_patchs_img,3,patch_s,patch_h,patch_w]\n        :return: result of recompone output shape: [3,img_s,img_h,img_w]\n        \"\"\"\n        patch_s = self.result.shape[2]\n        patch_h = self.result.shape[3]\n        patch_w = self.result.shape[4]\n        N_patches_s = (self.new_shape[0] - patch_s) // self.C['stride_s'] + 1\n        N_patches_h = (self.new_shape[1] - patch_h) // self.C['stride_h'] + 1\n        N_patches_w = (self.new_shape[2] - patch_w) // self.C['stride_w'] + 1\n\n        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n        # print(\"N_patches_s/h/w:\", N_patches_s, N_patches_h, N_patches_w)\n        # print(\"N_patches_img: \" + str(N_patches_img))\n        assert (self.result.shape[0] == N_patches_img)\n\n        full_prob = torch.zeros((self.new_shape[0], self.new_shape[1],\n                                 self.new_shape[2]))  # itialize to zero mega array with sum of Probabilities\n        full_sum = torch.zeros((self.new_shape[0], self.new_shape[1], self.new_shape[2]))\n        k = 0  # iterator over all the patches\n        for s in range(N_patches_s):\n            for h in range(N_patches_h):\n                for w in range(N_patches_w):\n                    # print(k,self.result[k].squeeze().sum())\n                    full_prob[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += self.result[k].squeeze()\n                    full_sum[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += 1\n                    k += 1\n        assert (k == self.result.size(0))\n        assert (torch.min(full_sum) >= 1.0)  # at least one\n        final_avg = full_prob / full_sum\n        # print(final_avg.size())\n        img = final_avg[:self.ori_shape[0], :self.ori_shape[1], :self.ori_shape[2]]\n        return img", "\n\ndef cal_newshape(img, C):\n    assert (len(img.shape) == 3)  # 3D array\n    img_s, img_h, img_w = img.shape\n    leftover_s = (img_s - C['patch_s']) % C['stride_s']\n    leftover_h = (img_h - C['patch_h']) % C['stride_h']\n    leftover_w = (img_w - C['patch_w']) % C['stride_w']\n    if (leftover_s != 0):\n        s = img_s + (C['stride_s'] - leftover_s)\n    else:\n        s = img_s\n\n    if (leftover_h != 0):\n        h = img_h + (C['stride_h'] - leftover_h)\n    else:\n        h = img_h\n\n    if (leftover_w != 0):\n        w = img_w + (C['stride_w'] - leftover_w)\n    else:\n        w = img_w\n\n    return np.zeros((s, h, w)).shape", "\n\ndef package_torch(adc_patch, pos_patch, sub_patch, gt_patch):\n    adc_patch = torch.from_numpy(adc_patch[np.newaxis, np.newaxis, :])\n    pos_patch = torch.from_numpy(pos_patch[np.newaxis, np.newaxis, :])\n    sub_patch = torch.from_numpy(sub_patch[np.newaxis, np.newaxis, :])\n    gt_patch = torch.from_numpy(gt_patch[np.newaxis, np.newaxis, :])\n    return adc_patch, pos_patch, sub_patch, gt_patch\n\n\ndef Test_Datasets(dataset_path, size, test_folder=1):\n    f = open(os.path.join(dataset_path, 'data_folder', 'test' + str(test_folder) + '.txt'))\n    data_list = f.read().splitlines()\n    print(\"The number of test samples is: \", len(data_list))\n    for file in data_list:\n        # file = str(int(file))\n        # print(\"\\nStart Evaluate: \", file)\n        adc = load(os.path.join(dataset_path, file, 'adc_contrast.nii.gz')).astype(np.float32)\n        pos = load(os.path.join(dataset_path, file, 'Pos_contrast.nii.gz')).astype(np.float32)\n        sub = normalization(pos - adc)\n        print(sub.shape)\n        gt = load(os.path.join(dataset_path, file, 'GT.nii.gz')).astype(np.int16)\n        adc_patch, pos_patch, sub_patch, gt_patch = random_crop_3d(adc, pos, sub, gt, size)\n\n        yield package_torch(adc_patch, pos_patch, sub_patch, gt_patch), file", "\n\ndef Test_Datasets(dataset_path, size, test_folder=1):\n    f = open(os.path.join(dataset_path, 'data_folder', 'test' + str(test_folder) + '.txt'))\n    data_list = f.read().splitlines()\n    print(\"The number of test samples is: \", len(data_list))\n    for file in data_list:\n        # file = str(int(file))\n        # print(\"\\nStart Evaluate: \", file)\n        adc = load(os.path.join(dataset_path, file, 'adc_contrast.nii.gz')).astype(np.float32)\n        pos = load(os.path.join(dataset_path, file, 'Pos_contrast.nii.gz')).astype(np.float32)\n        sub = normalization(pos - adc)\n        print(sub.shape)\n        gt = load(os.path.join(dataset_path, file, 'GT.nii.gz')).astype(np.int16)\n        adc_patch, pos_patch, sub_patch, gt_patch = random_crop_3d(adc, pos, sub, gt, size)\n\n        yield package_torch(adc_patch, pos_patch, sub_patch, gt_patch), file", "\n\ndef Test_all_Datasets(dataset_path, size):\n    f = open(os.path.join(dataset_path, 'data.txt'))\n    data_list = f.read().splitlines()\n    print(\"The number of test samples is: \", len(data_list))\n    for file in data_list:\n        print(\"\\nStart Evaluate: \", file)\n        DCE = normalization(load(os.path.join(dataset_path, file, 'DCE.nii.gz'))).astype(np.float32)\n        original_shape = DCE.shape\n        new_shape = cal_newshape(DCE, size)\n        # adc_patch, pos_patch, sub_patch, gt_patch = random_crop_3d(adc,pos,sub,gt,size)\n\n        yield Img_DataSet(DCE, size), original_shape, new_shape, file", ""]}
{"filename": "Step1-Image-Synthesis/dataset/dataset_lits_val.py", "chunked_list": ["import random\nimport numpy as np\nimport SimpleITK as sitk\nimport os\nfrom torch.utils.data import Dataset\n\n\nclass Val_DataSet(Dataset):\n    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n        self.root = root\n        self.size = size\n        self.sample_index = sample_index\n        f = open(os.path.join(self.root, 'val.txt'))\n        self.filename = f.read().splitlines()\n\n    def __getitem__(self, index):\n\n        file = self.filename[index]\n        DCE = self.normalization(self.load(os.path.join(self.root, file, 'DCE.nii.gz'))).astype(np.float32)\n        ADC = self.normalization(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\n        ADC_patch, DCE_patch, gt_patch = [], []\n        for i in range(5):\n            if i == 1:\n                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d_contain(DCE, ADC, gt, self.size)\n            elif i == 2:\n                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d_partial(DEC, ADC, gt, self.size)\n            else:\n                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d(DEC, ADC, gt, self.size)\n\n            DCE_patch.append(DCE_patch1), ADC_patch.append(ADC_patch1), gt_patch.append(gt_patch1)\n\n        return np.array(DCE_patch), np.array(ADC_patch), np.array(gt_patch)\n\n    def __len__(self):\n        return len(self.filename)\n\n    def random_crop_3d_contain(self, a, b, gt, crop_size):\n\n        cor_box = self.maskcor_extract_3d(gt)\n        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n        if random_x_min > random_x_max:\n            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n        if random_y_min > random_y_max:\n            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n        if random_z_min > random_z_max:\n            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, gt_patch\n\n    def random_crop_3d_partial(self, a, b, gt, crop_size):\n\n        cor_box = self.maskcor_extract_3d(gt)\n        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, gt_patch\n\n    def random_crop_3d(self, a, b, gt, crop_size):\n\n        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(0, a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(0, a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(0, a.shape[2] - crop_size[2])\n        x_random = random.randint(0, a.shape[0] - crop_size[0])\n        y_random = random.randint(0, a.shape[1] - crop_size[1])\n        z_random = random.randint(0, a.shape[2] - crop_size[2])\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                   z_random:z_random + crop_size[2]]\n\n        return a_patch, b_patch, gt_patch\n\n    def min_max_normalization(self, img):\n        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n        return out\n\n    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if quantile is not None:\n            maxval = round(np.percentile(newimg, 100 - quantile))\n            minval = round(np.percentile(newimg, quantile))\n            newimg[newimg >= maxval] = maxval\n            newimg[newimg <= minval] = minval\n\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n        if rmax is not None:\n            newimg[newimg > rmax] = rmax\n\n        minval = np.min(newimg)\n        if dividend is None:\n            maxval = np.max(newimg)\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        else:\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n        return newimg\n\n    def load(self, file):\n        itkimage = sitk.ReadImage(file)\n        image = sitk.GetArrayFromImage(itkimage)\n        return image\n\n    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n        # mask_s = mask.shape\n        if np.sum(mask) == 0:\n            mask[10:12, 100:102, 100:102] = 1\n\n        p = np.where(mask > 0)\n        a = np.zeros([3, 2], dtype=np.int)\n        for i in range(3):\n            s = p[i].min()\n            e = p[i].max() + 1\n\n            ss = s - padding[i]\n            ee = e + padding[i]\n            if ss < 0:\n                ss = 0\n            if ee > mask.shape[i]:\n                ee = mask.shape[i]\n\n            a[i, 0] = ss\n            a[i, 1] = ee\n        return a", ""]}
{"filename": "Step1-Image-Synthesis/dataset/dataset_lits_train.py", "chunked_list": ["import random\nimport numpy as np\nimport SimpleITK as sitk\nimport os\nfrom torch.utils.data import Dataset\n  \nclass Lits_DataSet(Dataset):\n    def __init__(self,root, sample_index='partial', size=(32, 128, 128)):\n        self.root = root\n        self.size = size\n        self.sample_index = sample_index\n        f = open(os.path.join(self.root, 'data.txt'))\n        self.filename = f.read().splitlines()\n\n    def __getitem__(self, index):\n\n        file = self.filename[index]\n        DCE = self.normalization(self.load(os.path.join(self.root, file, 'DCE.nii.gz'))).astype(np.float32)\n        ADC = self.normalization(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\n        ADC_patch,DCE_patch, gt_patch = [], [], []\n        for i in range(5):\n            if i == 1:\n                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d_contain(DCE,ADC, gt, self.size)\n            elif i==2:\n                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d_partial(DCE, ADC, gt, self.size)\n            else:\n                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d(DCE, ADC, gt, self.size)\n\n            DCE_patch.append(DCE_patch1),ADC_patch.append(ADC_patch1), gt_patch.append(gt_patch1)\n\n        return np.array(DCE_patch),np.array(ADC_patch), np.array(gt_patch)\n\n    def __len__(self):\n        return len(self.filename)\n\n    def random_crop_3d_contain(self, a,b, gt, crop_size):\n\n        cor_box = self.maskcor_extract_3d(gt)\n        random_x_min, random_x_max = max(cor_box[0,1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0]-crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1,1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1]-crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2,1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2]-crop_size[2])\n        if random_x_min >random_x_max:\n            random_x_min, random_x_max = cor_box[0,0], cor_box[0,1] - crop_size[0]\n        if random_y_min >random_y_max:\n            random_y_min, random_y_max = cor_box[1,0], cor_box[1,1] - crop_size[1]\n        if random_z_min > random_z_max:\n            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n    \n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n\n        return a_patch,b_patch, gt_patch\n\n    def random_crop_3d_partial(self, a,b, gt, crop_size):\n\n        cor_box = self.maskcor_extract_3d(gt)\n        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n        x_random = random.randint(random_x_min, random_x_max)\n        y_random = random.randint(random_y_min, random_y_max)\n        z_random = random.randint(random_z_min, random_z_max)\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n\n        return a_patch,b_patch, gt_patch\n\n\n    def random_crop_3d(self, a,b, gt, crop_size):\n\n        x_random = random.randint(0, a.shape[0] - crop_size[0])\n        y_random = random.randint(0, a.shape[1] - crop_size[1])\n        z_random = random.randint(0, a.shape[2] - crop_size[2])\n\n        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n                  z_random:z_random + crop_size[2]]\n\n        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n\n        return a_patch,b_patch, gt_patch\n\n\n    def min_max_normalization(self, img):\n        out = (img - np.min(img))/(np.max(img) - np.min(img) + 0.000001)\n        return out\n\n    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n        newimg = img.copy()\n        newimg = newimg.astype(np.float32)\n        if quantile is not None:\n            maxval = round(np.percentile(newimg, 100 - quantile))\n            minval = round(np.percentile(newimg, quantile))\n            newimg[newimg >= maxval] = maxval\n            newimg[newimg <= minval] = minval\n\n        if lmin is not None:\n            newimg[newimg < lmin] = lmin\n        if rmax is not None:\n            newimg[newimg > rmax] = rmax\n\n        minval = np.min(newimg)\n        if dividend is None:\n            maxval = np.max(newimg)\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n        else:\n            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n        return newimg\n\n    def load(self,file):\n        itkimage = sitk.ReadImage(file)\n        image = sitk.GetArrayFromImage(itkimage)\n        return image\n\n    def maskcor_extract_3d(self,mask, padding=(0, 0, 0)):\n        # mask_s = mask.shape\n        if np.sum(mask)==0:\n            mask[10:12,100:102,100:102]=1\n\n        p = np.where(mask > 0)\n        a = np.zeros([3, 2], dtype=np.int)\n        for i in range(3):\n            s = p[i].min()\n            e = p[i].max() + 1\n\n            ss = s - padding[i]\n            ee = e + padding[i]\n            if ss < 0:\n                ss = 0\n            if ee > mask.shape[i]:\n                ee = mask.shape[i]\n\n            a[i, 0] = ss\n            a[i, 1] = ee\n        return a", "\n\n\n\n\n\n"]}
{"filename": "Step1-Image-Synthesis/Model/runet.py", "chunked_list": ["import torch\nimport torch.nn as nn\n\n\nbasic_dims = 8\nnum_modals = 1\npatch_size = [2, 8, 8]\n\n\ndef normalization(planes, norm='bn'):\n    if norm == 'bn':\n        m = nn.BatchNorm3d(planes)\n    elif norm == 'gn':\n        m = nn.GroupNorm(4, planes)\n    elif norm == 'in':\n        m = nn.InstanceNorm3d(planes)\n    else:\n        raise ValueError('normalization type {} is not supported'.format(norm))\n    return m", "\ndef normalization(planes, norm='bn'):\n    if norm == 'bn':\n        m = nn.BatchNorm3d(planes)\n    elif norm == 'gn':\n        m = nn.GroupNorm(4, planes)\n    elif norm == 'in':\n        m = nn.InstanceNorm3d(planes)\n    else:\n        raise ValueError('normalization type {} is not supported'.format(norm))\n    return m", "\n\nclass general_conv3d_prenorm(nn.Module):\n    def __init__(self, in_ch, out_ch, k_size=3, stride=1, padding=1, pad_type='zeros', norm='in', is_training=True,\n                 act_type='lrelu', relufactor=0.2):\n        super(general_conv3d_prenorm, self).__init__()\n        self.conv = nn.Conv3d(in_channels=in_ch, out_channels=out_ch, kernel_size=k_size, stride=stride,\n                              padding=padding, padding_mode=pad_type, bias=True)\n\n        self.norm = normalization(out_ch, norm=norm)\n        if act_type == 'relu':\n            self.activation = nn.ReLU(inplace=True)\n        elif act_type == 'lrelu':\n            self.activation = nn.LeakyReLU(negative_slope=relufactor, inplace=True)\n\n    def forward(self, x):\n        x = self.norm(x)\n        x = self.activation(x)\n        x = self.conv(x)\n        return x", "\n\nclass fusion_prenorm(nn.Module):\n    def __init__(self, in_channel=64, num_cls=4):\n        super(fusion_prenorm, self).__init__()\n        self.fusion_layer = nn.Sequential(\n            general_conv3d_prenorm(in_channel * num_modals, in_channel, k_size=1, padding=0, stride=1),\n            general_conv3d_prenorm(in_channel, in_channel, k_size=3, padding=1, stride=1),\n            general_conv3d_prenorm(in_channel, in_channel, k_size=1, padding=0, stride=1))\n\n    def forward(self, x):\n        return self.fusion_layer(x)", "\n\nclass Encoder(nn.Module):\n    def __init__(self, flag=True):\n        super(Encoder, self).__init__()\n        if flag:\n            self.e1_c1 = nn.Conv3d(in_channels=1, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n                                   padding_mode='zeros', bias=True)\n        else:\n            self.e1_c1 = nn.Conv3d(in_channels=2, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n                                   padding_mode='zeros', bias=True)\n        self.e1_c2 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n        self.e1_c3 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n\n        self.e2_c1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n        self.e2_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n        self.e2_c3 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\n        self.e3_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n        self.e3_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n        self.e3_c3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n\n        self.e4_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n        self.e4_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n        self.e4_c3 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n\n        self.e5_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n        self.e5_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n        self.e5_c3 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\n    def forward(self, x):\n        x1 = self.e1_c1(x)\n        x1 = x1 + self.e1_c3(self.e1_c2(x1))\n\n        x2 = self.e2_c1(x1)\n        x2 = x2 + self.e2_c3(self.e2_c2(x2))\n\n        x3 = self.e3_c1(x2)\n        x3 = x3 + self.e3_c3(self.e3_c2(x3))\n\n        x4 = self.e4_c1(x3)\n        x4 = x4 + self.e4_c3(self.e4_c2(x4))\n\n        x5 = self.e5_c1(x4)\n        x5 = x5 + self.e5_c3(self.e5_c2(x5))\n\n        return x1, x2, x3, x4, x5", "\n\nclass Decoder_fuse(nn.Module):\n    def __init__(self, num_cls=1):\n        super(Decoder_fuse, self).__init__()\n\n        self.d4_c1 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n        self.d4_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n        self.d4_out = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, k_size=1, padding=0, pad_type='zeros')\n\n        self.d3_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n        self.d3_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n        self.d3_out = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, k_size=1, padding=0, pad_type='zeros')\n\n        self.d2_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n        self.d2_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n        self.d2_out = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, k_size=1, padding=0, pad_type='zeros')\n\n        self.d1_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n        self.d1_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n        self.d1_out = general_conv3d_prenorm(basic_dims, basic_dims, k_size=1, padding=0, pad_type='zeros')\n\n        self.seg_d4 = nn.Conv3d(in_channels=basic_dims * 16, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                bias=True)\n        self.seg_d3 = nn.Conv3d(in_channels=basic_dims * 8, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                bias=True)\n        self.seg_d2 = nn.Conv3d(in_channels=basic_dims * 4, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                bias=True)\n        self.seg_d1 = nn.Conv3d(in_channels=basic_dims * 2, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                bias=True)\n        self.seg_layer = nn.Conv3d(in_channels=basic_dims, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n                                   bias=True)\n        self.softmax = nn.Softmax(dim=1)\n\n        self.up2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n\n        self.RFM5 = fusion_prenorm(in_channel=basic_dims * 16, num_cls=num_cls)\n        self.RFM4 = fusion_prenorm(in_channel=basic_dims * 8, num_cls=num_cls)\n        self.RFM3 = fusion_prenorm(in_channel=basic_dims * 4, num_cls=num_cls)\n        self.RFM2 = fusion_prenorm(in_channel=basic_dims * 2, num_cls=num_cls)\n        self.RFM1 = fusion_prenorm(in_channel=basic_dims * 1, num_cls=num_cls)\n\n    def forward(self, x1, x2, x3, x4, x5):\n        de_x5 = self.RFM5(x5)\n        de_x5 = self.d4_c1(self.up2(de_x5))\n        de_x4 = self.RFM4(x4)\n        de_x4 = torch.cat((de_x4, de_x5), dim=1)\n        de_x4 = self.d4_out(self.d4_c2(de_x4))\n        de_x4 = self.d3_c1(self.up2(de_x4))\n\n        de_x3 = self.RFM3(x3)\n        de_x3 = torch.cat((de_x3, de_x4), dim=1)\n        de_x3 = self.d3_out(self.d3_c2(de_x3))\n        de_x3 = self.d2_c1(self.up2(de_x3))\n\n        de_x2 = self.RFM2(x2)\n        de_x2 = torch.cat((de_x2, de_x3), dim=1)\n        de_x2 = self.d2_out(self.d2_c2(de_x2))\n        de_x2 = self.d1_c1(self.up2(de_x2))\n\n        de_x1 = self.RFM1(x1)\n        de_x1 = torch.cat((de_x1, de_x2), dim=1)\n        de_x1 = self.d1_out(self.d1_c2(de_x1))\n\n        logits = self.seg_layer(de_x1)\n        pred = torch.sigmoid(logits)\n\n        return pred", "\n\nclass RUnet(nn.Module):\n    def __init__(self, num_cls=3):\n        super(RUnet, self).__init__()\n        self.ADC_encoder = Encoder(flag=True)\n        self.decoder_fuse = Decoder_fuse(num_cls=num_cls)\n\n        self.is_training = True\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                torch.nn.init.kaiming_normal_(m.weight)\n\n    def forward(self, x):\n\n        ADC_x1, ADC_x2, ADC_x3, ADC_x4, ADC_x5 = self.ADC_encoder(x[:, 0:1, :, :, :])\n\n        x1 = ADC_x1\n        x2 = ADC_x2\n        x3 = ADC_x3\n        x4 = ADC_x4\n        x5 = ADC_x5\n\n        fuse_pred = self.decoder_fuse(x1, x2, x3, x4, x5)\n\n        return fuse_pred", "\n\nif __name__ == '__main__':\n    a = torch.zeros([10, 1, 32, 128, 128])\n\n    model = RUnet(num_cls=1)\n    out = model(a)\n    print(out.shape)\n\n", "\n\n"]}
