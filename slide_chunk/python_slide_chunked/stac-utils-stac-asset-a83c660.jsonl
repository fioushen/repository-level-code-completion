{"filename": "tests/test_functions.py", "chunked_list": ["import os.path\nfrom asyncio import Queue\nfrom pathlib import Path\nfrom typing import Any\n\nimport pytest\nimport stac_asset\nfrom pystac import Asset, Collection, Item, ItemCollection\nfrom pytest import LogCaptureFixture\nfrom stac_asset import (", "from pytest import LogCaptureFixture\nfrom stac_asset import (\n    AssetOverwriteError,\n    Config,\n    ConfigError,\n    DownloadError,\n    DownloadWarning,\n    ErrorStrategy,\n    FileNameStrategy,\n)", "    FileNameStrategy,\n)\n\npytestmark = [\n    pytest.mark.asyncio,\n]\n\n\nasync def test_download_item(tmp_path: Path, item: Item) -> None:\n    item = await stac_asset.download_item(item, tmp_path)", "async def test_download_item(tmp_path: Path, item: Item) -> None:\n    item = await stac_asset.download_item(item, tmp_path)\n    assert os.path.exists(tmp_path / \"20201211_223832_CS2.jpg\")\n    asset = item.assets[\"data\"]\n    assert asset.href == str(tmp_path / \"20201211_223832_CS2.jpg\")\n\n\nasync def test_download_item_with_file_name(tmp_path: Path, item: Item) -> None:\n    await stac_asset.download_item(item, tmp_path, file_name=\"item.json\")\n    item = Item.from_file(str(tmp_path / \"item.json\"))", "    await stac_asset.download_item(item, tmp_path, file_name=\"item.json\")\n    item = Item.from_file(str(tmp_path / \"item.json\"))\n    assert item.assets[\"data\"].href == \"./20201211_223832_CS2.jpg\"\n\n\nasync def test_download_missing_asset_error(tmp_path: Path, item: Item) -> None:\n    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n    with pytest.raises(DownloadError):\n        await stac_asset.download_item(item, tmp_path, config=Config(warn=False))\n", "\n\nasync def test_download_missing_asset_warn(tmp_path: Path, item: Item) -> None:\n    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n    with pytest.warns(DownloadWarning):\n        await stac_asset.download_item(item, tmp_path, config=Config(warn=True))\n\n\nasync def test_download_missing_asset_keep(\n    tmp_path: Path, item: Item, data_path: Path", "async def test_download_missing_asset_keep(\n    tmp_path: Path, item: Item, data_path: Path\n) -> None:\n    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n    with pytest.warns(DownloadWarning):\n        item = await stac_asset.download_item(\n            item,\n            tmp_path,\n            config=Config(error_strategy=ErrorStrategy.KEEP, warn=True),\n        )", "    assert item.assets[\"does-not-exist\"].href == str(data_path / \"not-a-file.md5\")\n\n\nasync def test_download_missing_asset_delete(tmp_path: Path, item: Item) -> None:\n    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n    with pytest.warns(DownloadWarning):\n        item = await stac_asset.download_item(\n            item,\n            tmp_path,\n            config=Config(error_strategy=ErrorStrategy.DELETE, warn=True),\n        )", "    assert \"does-not-exist\" not in item.assets\n\n\nasync def test_download_missing_asset_fail_fast(\n    tmp_path: Path, item: Item, caplog: LogCaptureFixture\n) -> None:\n    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n    with pytest.raises(FileNotFoundError):\n        await stac_asset.download_item(\n            item,\n            tmp_path,\n            config=Config(fail_fast=True),\n        )", "\n\nasync def test_download_item_collection(\n    tmp_path: Path, item_collection: ItemCollection\n) -> None:\n    item_collection = await stac_asset.download_item_collection(\n        item_collection, tmp_path\n    )\n    assert os.path.exists(tmp_path / \"test-item\" / \"20201211_223832_CS2.jpg\")\n    asset = item_collection.items[0].assets[\"data\"]", "    assert os.path.exists(tmp_path / \"test-item\" / \"20201211_223832_CS2.jpg\")\n    asset = item_collection.items[0].assets[\"data\"]\n    assert asset.href == str(tmp_path / \"test-item/20201211_223832_CS2.jpg\")\n\n\nasync def test_download_item_collection_with_file_name(\n    tmp_path: Path, item_collection: ItemCollection\n) -> None:\n    await stac_asset.download_item_collection(\n        item_collection, tmp_path, file_name=\"item-collection.json\"", "    await stac_asset.download_item_collection(\n        item_collection, tmp_path, file_name=\"item-collection.json\"\n    )\n    item_collection = ItemCollection.from_file(str(tmp_path / \"item-collection.json\"))\n    assert (\n        item_collection.items[0].assets[\"data\"].href\n        == \"./test-item/20201211_223832_CS2.jpg\"\n    )\n\n", "\n\nasync def test_download_collection(tmp_path: Path, collection: Collection) -> None:\n    collection = await stac_asset.download_collection(\n        collection, tmp_path, file_name=\"collection.json\"\n    )\n    assert os.path.exists(tmp_path / \"collection.json\")\n    assert os.path.exists(tmp_path / \"20201211_223832_CS2.jpg\")\n    asset = collection.assets[\"data\"]\n    assert asset.href == \"./20201211_223832_CS2.jpg\"", "    asset = collection.assets[\"data\"]\n    assert asset.href == \"./20201211_223832_CS2.jpg\"\n\n\nasync def test_item_download_no_directory(tmp_path: Path, item: Item) -> None:\n    with pytest.raises(DownloadError):\n        await stac_asset.download_item(\n            item, tmp_path / \"doesnt-exist\", config=Config(make_directory=False)\n        )\n", "\n\nasync def test_item_download_key(tmp_path: Path, item: Item) -> None:\n    await stac_asset.download_item(\n        item, tmp_path, config=Config(file_name_strategy=FileNameStrategy.KEY)\n    )\n    assert Path(tmp_path / \"data.jpg\").exists()\n\n\nasync def test_item_download_same_file_name(tmp_path: Path, item: Item) -> None:", "\nasync def test_item_download_same_file_name(tmp_path: Path, item: Item) -> None:\n    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n    with pytest.raises(AssetOverwriteError):\n        await stac_asset.download_item(item, tmp_path)\n\n\nasync def test_include(tmp_path: Path, item: Item) -> None:\n    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n    item = await stac_asset.download_item(", "    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n    item = await stac_asset.download_item(\n        item, tmp_path, config=Config(include=[\"data\"])\n    )\n    assert len(item.assets) == 1\n\n\nasync def test_exclude(tmp_path: Path, item: Item) -> None:\n    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n    await stac_asset.download_item(", "    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n    await stac_asset.download_item(\n        item, tmp_path, config=Config(exclude=[\"other-data\"])\n    )\n\n\nasync def test_cant_include_and_exclude(tmp_path: Path, item: Item) -> None:\n    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n    with pytest.raises(ConfigError):\n        await stac_asset.download_item(\n            item, tmp_path, config=Config(include=[\"data\"], exclude=[\"other-data\"])\n        )", "    with pytest.raises(ConfigError):\n        await stac_asset.download_item(\n            item, tmp_path, config=Config(include=[\"data\"], exclude=[\"other-data\"])\n        )\n\n\n@pytest.mark.network_access\nasync def test_multiple_clients(tmp_path: Path, item: Item) -> None:\n    item.assets[\"remote\"] = Asset(\n        href=\"https://storage.googleapis.com/open-cogs/stac-examples/20201211_223832_CS2.jpg\",", "    item.assets[\"remote\"] = Asset(\n        href=\"https://storage.googleapis.com/open-cogs/stac-examples/20201211_223832_CS2.jpg\",\n    )\n    item = await stac_asset.download_item(\n        item, tmp_path, config=Config(file_name_strategy=FileNameStrategy.KEY)\n    )\n\n\nasync def test_queue(tmp_path: Path, item: Item) -> None:\n    queue: Queue[Any] = Queue()", "async def test_queue(tmp_path: Path, item: Item) -> None:\n    queue: Queue[Any] = Queue()\n    item = await stac_asset.download_item(item, tmp_path, queue=queue)\n    assert not queue.empty()\n"]}
{"filename": "tests/test_config.py", "chunked_list": ["import pytest\nfrom stac_asset import Config, ConfigError\n\n\ndef test_validate_default() -> None:\n    config = Config()\n    config.validate()\n\n\ndef test_validate_include_and_exclude() -> None:\n    config = Config(include=[\"foo\"], exclude=[\"bar\"])\n    with pytest.raises(ConfigError):\n        config.validate()", "\ndef test_validate_include_and_exclude() -> None:\n    config = Config(include=[\"foo\"], exclude=[\"bar\"])\n    with pytest.raises(ConfigError):\n        config.validate()\n\n\ndef test_warn_and_fail_fast() -> None:\n    config = Config(warn=True, fail_fast=True)\n    with pytest.raises(ConfigError):\n        config.validate()", ""]}
{"filename": "tests/test_cli.py", "chunked_list": ["import json\nimport os\nfrom pathlib import Path\n\nimport pytest\nimport stac_asset._cli\nfrom click.testing import CliRunner\nfrom pystac import Item, ItemCollection\n\n\ndef test_download_item(tmp_path: Path, item_path: Path) -> None:\n    runner = CliRunner()\n    result = runner.invoke(\n        stac_asset._cli.cli,\n        [\"download\", str(item_path), str(tmp_path)],\n    )\n    assert result.exit_code == 0", "\n\ndef test_download_item(tmp_path: Path, item_path: Path) -> None:\n    runner = CliRunner()\n    result = runner.invoke(\n        stac_asset._cli.cli,\n        [\"download\", str(item_path), str(tmp_path)],\n    )\n    assert result.exit_code == 0\n", "\n\ndef test_download_item_stdin_stdout(tmp_path: Path, item: Item) -> None:\n    previous_working_directory = os.getcwd()\n    os.chdir(tmp_path)\n    try:\n        item_as_str = json.dumps(\n            item.to_dict(include_self_link=True, transform_hrefs=False)\n        )\n        runner = CliRunner(mix_stderr=False)\n        result = runner.invoke(stac_asset._cli.cli, [\"download\"], input=item_as_str)\n        assert result.exit_code == 0, result.stdout\n        Item.from_dict(json.loads(result.stdout))\n    finally:\n        os.chdir(previous_working_directory)", "\n\ndef test_download_item_collection_stdin_stdout(\n    tmp_path: Path, item_collection: ItemCollection\n) -> None:\n    previous_working_directory = os.getcwd()\n    os.chdir(tmp_path)\n    try:\n        item_collection_as_str = json.dumps(\n            item_collection.to_dict(transform_hrefs=False)\n        )\n        runner = CliRunner(mix_stderr=False)\n        result = runner.invoke(\n            stac_asset._cli.cli, [\"download\"], input=item_collection_as_str\n        )\n        assert result.exit_code == 0, result.stdout\n        ItemCollection.from_dict(json.loads(result.stdout))\n    finally:\n        os.chdir(previous_working_directory)", "\n\n@pytest.mark.network_access\ndef test_download_item_s3_requester_pays(tmp_path: Path) -> None:\n    runner = CliRunner()\n    result = runner.invoke(\n        stac_asset._cli.cli,\n        [\n            \"download\",\n            \"https://landsatlook.usgs.gov/stac-server/collections/landsat-c2l2-sr/items/LC09_L2SP_092068_20230607_20230609_02_T1_SR\",\n            str(tmp_path),\n            \"--s3-requester-pays\",\n            \"-i\",\n            \"thumbnail\",\n            \"--alternate-assets\",\n            \"s3\",\n        ],\n    )\n    assert result.exit_code == 0", ""]}
{"filename": "tests/test_s3_client.py", "chunked_list": ["import os.path\nfrom pathlib import Path\nfrom typing import cast\n\nimport pystac\nimport pytest\nimport stac_asset\nfrom pystac import Item\nfrom stac_asset import Config, S3Client\n", "from stac_asset import Config, S3Client\n\npytestmark = [\n    pytest.mark.asyncio,\n    pytest.mark.network_access,\n]\n\n\n@pytest.fixture\ndef asset_href() -> str:\n    return \"s3://sentinel-cogs/sentinel-s2-l2a-cogs/42/L/TQ/2023/5/S2B_42LTQ_20230524_0_L2A/thumbnail.jpg\"", "@pytest.fixture\ndef asset_href() -> str:\n    return \"s3://sentinel-cogs/sentinel-s2-l2a-cogs/42/L/TQ/2023/5/S2B_42LTQ_20230524_0_L2A/thumbnail.jpg\"\n\n\n@pytest.fixture\ndef requester_pays_asset_href() -> str:\n    return \"s3://usgs-landsat/collection02/level-2/standard/oli-tirs/2023/092/068/LC09_L2SP_092068_20230522_20230524_02_T2/LC09_L2SP_092068_20230522_20230524_02_T2_thumb_small.jpeg\"\n\n", "\n\n@pytest.fixture\ndef requester_pays_item(data_path: Path) -> Item:\n    return cast(\n        Item,\n        pystac.read_file(\n            str(data_path / \"LC09_L2SP_092068_20230607_20230609_02_T1_SR.json\")\n        ),\n    )", "\n\nasync def test_download(tmp_path: Path, asset_href: str) -> None:\n    async with S3Client() as client:\n        await client.download_href(asset_href, tmp_path / \"out.jpg\")\n\n    assert os.path.getsize(tmp_path / \"out.jpg\") == 6060\n\n\nasync def test_download_requester_pays_asset(", "\nasync def test_download_requester_pays_asset(\n    tmp_path: Path, requester_pays_asset_href: str\n) -> None:\n    async with S3Client(requester_pays=True) as client:\n        if not await client.has_credentials():\n            pytest.skip(\"aws credentials are invalid or not present\")\n        await client.download_href(requester_pays_asset_href, tmp_path / \"out.jpg\")\n        assert os.path.getsize(tmp_path / \"out.jpg\") == 6114\n", "        assert os.path.getsize(tmp_path / \"out.jpg\") == 6114\n\n\nasync def test_download_requester_pays_item(\n    tmp_path: Path, requester_pays_item: Item\n) -> None:\n    await stac_asset.download_item(\n        requester_pays_item,\n        tmp_path,\n        config=Config(", "        tmp_path,\n        config=Config(\n            include=[\"thumbnail\"], s3_requester_pays=True, alternate_assets=[\"s3\"]\n        ),\n    )\n    assert (\n        os.path.getsize(\n            tmp_path / \"LC09_L2SP_092068_20230607_20230609_02_T1_thumb_small.jpeg\"\n        )\n        == 19554", "        )\n        == 19554\n    )\n"]}
{"filename": "tests/test_planetary_computer_client.py", "chunked_list": ["import os.path\nfrom pathlib import Path\n\nimport pytest\nfrom stac_asset import Config, PlanetaryComputerClient\n\npytestmark = [\n    pytest.mark.network_access,\n    pytest.mark.asyncio,\n]", "    pytest.mark.asyncio,\n]\n\n\n@pytest.fixture\ndef asset_href() -> str:\n    return \"https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/48/X/VR/2023/05/24/S2B_MSIL2A_20230524T084609_N0509_R107_T48XVR_20230524T120352.SAFE/GRANULE/L2A_T48XVR_A032451_20230524T084603/QI_DATA/T48XVR_20230524T084609_PVI.tif\"\n\n\nasync def test_download(tmp_path: Path, asset_href: str) -> None:", "\nasync def test_download(tmp_path: Path, asset_href: str) -> None:\n    async with await PlanetaryComputerClient.from_config(Config()) as client:\n        await client.download_href(asset_href, tmp_path / \"out.tif\")\n\n    assert os.path.getsize(tmp_path / \"out.tif\") == 4096\n"]}
{"filename": "tests/test_filesystem_client.py", "chunked_list": ["import os.path\nfrom pathlib import Path\n\nimport pytest\nfrom stac_asset import FilesystemClient\n\npytestmark = pytest.mark.asyncio\n\n\n@pytest.fixture\ndef asset_href() -> str:\n    return str(Path(__file__).parent / \"data\" / \"20201211_223832_CS2.jpg\")", "\n@pytest.fixture\ndef asset_href() -> str:\n    return str(Path(__file__).parent / \"data\" / \"20201211_223832_CS2.jpg\")\n\n\nasync def test_download(tmp_path: Path, asset_href: str) -> None:\n    async with FilesystemClient() as client:\n        await client.download_href(asset_href, tmp_path / \"out.jpg\")\n", "        await client.download_href(asset_href, tmp_path / \"out.jpg\")\n\n    assert os.path.getsize(tmp_path / \"out.jpg\") == 31367\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["from pathlib import Path\nfrom typing import Any\n\nimport pytest\nfrom pystac import Collection, Item, ItemCollection\nfrom pytest import Config, Parser\n\n\n@pytest.fixture\ndef asset_path() -> str:\n    return str(Path(__file__).parent / \"data\" / \"20201211_223832_CS2.jpg\")", "@pytest.fixture\ndef asset_path() -> str:\n    return str(Path(__file__).parent / \"data\" / \"20201211_223832_CS2.jpg\")\n\n\n@pytest.fixture\ndef item_path() -> Path:\n    return Path(__file__).parent / \"data\" / \"item.json\"\n\n", "\n\n@pytest.fixture\ndef data_path() -> Path:\n    return Path(__file__).parent / \"data\"\n\n\n@pytest.fixture\ndef item(item_path: Path) -> Item:\n    return Item.from_file(str(item_path))", "def item(item_path: Path) -> Item:\n    return Item.from_file(str(item_path))\n\n\n@pytest.fixture\ndef collection() -> Collection:\n    return Collection.from_file(str(Path(__file__).parent / \"data\" / \"collection.json\"))\n\n\n@pytest.fixture\ndef item_collection(item: Item) -> ItemCollection:\n    item.make_asset_hrefs_absolute()\n    return ItemCollection([item])", "\n@pytest.fixture\ndef item_collection(item: Item) -> ItemCollection:\n    item.make_asset_hrefs_absolute()\n    return ItemCollection([item])\n\n\ndef pytest_addoption(parser: Parser) -> None:\n    parser.addoption(\n        \"--network-access\",\n        action=\"store_true\",\n        default=False,\n        help=\"run tests that access the network\",\n    )", "\n\ndef pytest_configure(config: Config) -> None:\n    config.addinivalue_line(\n        \"markers\",\n        \"network_access: marks tests as accessing the network, \"\n        \"and disables them by default (enable with --network-access)\",\n    )\n\n\ndef pytest_collection_modifyitems(config: Config, items: Any) -> None:\n    if config.getoption(\"--network-access\"):\n        return\n    skip_network_access = pytest.mark.skip(reason=\"need --network-access option to run\")\n    for item in items:\n        if \"network_access\" in item.keywords:\n            item.add_marker(skip_network_access)", "\n\ndef pytest_collection_modifyitems(config: Config, items: Any) -> None:\n    if config.getoption(\"--network-access\"):\n        return\n    skip_network_access = pytest.mark.skip(reason=\"need --network-access option to run\")\n    for item in items:\n        if \"network_access\" in item.keywords:\n            item.add_marker(skip_network_access)\n", ""]}
{"filename": "tests/test_validate.py", "chunked_list": ["import pytest\nfrom stac_asset import ContentTypeError, validate\n\n\ndef test_content_type() -> None:\n    validate.content_type(\"foo\", \"foo\")\n    with pytest.raises(ContentTypeError):\n        validate.content_type(\"foo\", \"bar\")\n    validate.content_type(\n        \"image/tiff\", \"image/tiff; application=geotiff; profile=cloud-optimized\"\n    )\n    validate.content_type(\n        \"image/tiff; application=geotiff; profile=cloud-optimized\", \"image/tiff\"\n    )\n    validate.content_type(\"binary/octet-stream\", \"doesn't matter\")\n    validate.content_type(\"application/octet-stream\", \"doesn't matter\")", ""]}
{"filename": "tests/test_earthdata_client.py", "chunked_list": ["import os.path\nfrom pathlib import Path\n\nimport pytest\nfrom stac_asset import EarthdataClient\n\npytestmark = [\n    pytest.mark.skipif(\n        os.environ.get(\"EARTHDATA_PAT\") is None,\n        reason=\"EARTHDATA_PAT is not set\",", "        os.environ.get(\"EARTHDATA_PAT\") is None,\n        reason=\"EARTHDATA_PAT is not set\",\n    ),\n    pytest.mark.asyncio,\n    pytest.mark.network_access,\n]\n\n\nasync def test_download_href(tmp_path: Path) -> None:\n    href = \"https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/MYD11A1.061/MYD11A1.A2023145.h14v17.061.2023146183035/MYD11A1.A2023145.h14v17.061.2023146183035.hdf\"", "async def test_download_href(tmp_path: Path) -> None:\n    href = \"https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/MYD11A1.061/MYD11A1.A2023145.h14v17.061.2023146183035/MYD11A1.A2023145.h14v17.061.2023146183035.hdf\"\n    async with await EarthdataClient.login() as client:\n        await client.download_href(href, tmp_path / \"out.hdf\")\n        assert os.path.getsize(tmp_path / \"out.hdf\") == 197419\n"]}
{"filename": "docs/conf.py", "chunked_list": ["import importlib.metadata\n\nproject = \"stac-asset\"\ncopyright = \"2023, Pete Gadomski\"\nauthor = \"Pete Gadomski\"\nversion = importlib.metadata.version(\"stac_asset\")\nrelease = importlib.metadata.version(\"stac_asset\")\n\nextensions = [\n    \"sphinx.ext.autodoc\",", "extensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.napoleon\",\n]\n\ntemplates_path = [\"_templates\"]\nexclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\nhtml_theme = \"pydata_sphinx_theme\"\nhtml_static_path = [\"_static\"]", "html_theme = \"pydata_sphinx_theme\"\nhtml_static_path = [\"_static\"]\n"]}
{"filename": "src/stac_asset/filesystem_client.py", "chunked_list": ["from __future__ import annotations\n\nimport os.path\nfrom asyncio import Queue\nfrom types import TracebackType\nfrom typing import AsyncIterator, Optional, Type\n\nimport aiofiles\nfrom yarl import URL\n", "from yarl import URL\n\nfrom .client import Client\nfrom .messages import Message, OpenUrl\n\n\nclass FilesystemClient(Client):\n    \"\"\"A simple client for moving files around on the filesystem.\n\n    Mostly used for testing, but could be useful in some real-world cases.\n    \"\"\"\n\n    async def open_url(\n        self,\n        url: URL,\n        content_type: Optional[str] = None,\n        messages: Optional[Queue[Message]] = None,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"Iterates over data from a local url.\n\n        Args:\n            url: The url to read bytes from\n            content_type: The expected content type. Ignored by this client,\n                because filesystems don't have content types.\n            messages: An optional queue to use for progress reporting\n\n        Yields:\n            AsyncIterator[bytes]: An iterator over the file's bytes.\n\n        Raises:\n            ValueError: Raised if the url has a scheme. This behavior will\n                change if/when we support Windows paths.\n        \"\"\"\n        if url.scheme:\n            raise ValueError(\n                \"cannot read a file with the filesystem client if it has a url scheme: \"\n                + str(url)\n            )\n        if messages:\n            await messages.put(OpenUrl(size=os.path.getsize(url.path), url=url))\n        async with aiofiles.open(url.path, \"rb\") as f:\n            async for chunk in f:\n                yield chunk\n\n    async def __aenter__(self) -> FilesystemClient:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> Optional[bool]:\n        return None", ""]}
{"filename": "src/stac_asset/earthdata_client.py", "chunked_list": ["from __future__ import annotations\n\nimport os\nfrom types import TracebackType\nfrom typing import Optional, Type\n\nfrom aiohttp import ClientSession\n\nfrom .config import Config\nfrom .http_client import HttpClient", "from .config import Config\nfrom .http_client import HttpClient\n\n\nclass EarthdataClient(HttpClient):\n    \"\"\"Access data from https://www.earthdata.nasa.gov/.\"\"\"\n\n    @classmethod\n    async def from_config(cls, config: Config) -> EarthdataClient:\n        \"\"\"Logs in to Earthdata and returns the default earthdata client.\n\n        Uses a token stored in the ``EARTHDATA_PAT`` environment variable, if\n        the token is not provided in the config.\n\n        Args:\n            config: A configuration object.\n\n        Returns:\n            EarthdataClient: A logged-in EarthData client.\n        \"\"\"\n        return await cls.login(config.earthdata_token)\n\n    @classmethod\n    async def login(cls, token: Optional[str] = None) -> EarthdataClient:\n        \"\"\"Logs in to Earthdata and returns a client.\n\n        If token is not provided, it is read from the ``EARTHDATA_PAT``\n        environment variable.\n\n        Args:\n            token: The Earthdata bearer token\n\n        Returns:\n            EarthdataClient: A client configured to use the bearer token\n        \"\"\"\n        if token is None:\n            try:\n                token = os.environ[\"EARTHDATA_PAT\"]\n            except KeyError:\n                raise ValueError(\n                    \"token was not provided, and EARTHDATA_PAT environment variable \"\n                    \"not set\"\n                )\n        session = ClientSession(headers={\"Authorization\": f\"Bearer {token}\"})\n        return cls(session)\n\n    async def __aenter__(self) -> EarthdataClient:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> Optional[bool]:\n        await self.close()\n        return await super().__aexit__(exc_type, exc_val, exc_tb)", ""]}
{"filename": "src/stac_asset/types.py", "chunked_list": ["from os import PathLike\nfrom typing import TYPE_CHECKING, Union\n\nif TYPE_CHECKING:\n    from typing import Any\n\n    _PathLike = PathLike[Any]\nelse:\n    _PathLike = PathLike\n", "\nPathLikeObject = Union[_PathLike, str]\n\"\"\"An object representing a file system path, except we exclude `bytes` because\n`Path()` doesn't accept `bytes`.\n\nA path-like object is either a str or bytes object representing a path, or an\nobject implementing the os.PathLike protocol. An object that supports the\nos.PathLike protocol can be converted to a str or bytes file system path by\ncalling the os.fspath() function; os.fsdecode() and os.fsencode() can be used to\nguarantee a str or bytes result instead, respectively. Introduced by PEP 519.", "calling the os.fspath() function; os.fsdecode() and os.fsencode() can be used to\nguarantee a str or bytes result instead, respectively. Introduced by PEP 519.\n\nhttps://docs.python.org/3/glossary.html#term-path-like-object\n\"\"\"\n"]}
{"filename": "src/stac_asset/http_client.py", "chunked_list": ["from __future__ import annotations\n\nfrom asyncio import Queue\nfrom types import TracebackType\nfrom typing import AsyncIterator, Optional, Type, TypeVar\n\nfrom aiohttp import ClientSession\nfrom yarl import URL\n\nfrom . import validate", "\nfrom . import validate\nfrom .client import Client\nfrom .config import Config\nfrom .messages import Message, OpenUrl\n\nT = TypeVar(\"T\", bound=\"HttpClient\")\n\n\nclass HttpClient(Client):\n    \"\"\"A simple client for making HTTP requests.\n\n    By default, doesn't do any authentication.\n    Configure the session to customize its behavior.\n    \"\"\"\n\n    session: ClientSession\n    \"\"\"A atiohttp session that will be used for all requests.\"\"\"\n\n    @classmethod\n    async def from_config(cls: Type[T], config: Config) -> T:\n        \"\"\"Creates the default http client with a vanilla session object.\"\"\"\n        # TODO add basic auth\n        session = ClientSession()\n        return cls(session)\n\n    def __init__(self, session: ClientSession, check_content_type: bool = True) -> None:\n        super().__init__()\n        self.session = session\n        self.check_content_type = check_content_type\n\n    async def open_url(\n        self,\n        url: URL,\n        content_type: Optional[str] = None,\n        messages: Optional[Queue[Message]] = None,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"Opens a url with this client's session and iterates over its bytes.\n\n        Args:\n            url: The url to open\n            content_type: The expected content type\n            messages: An optional queue to use for progress reporting\n\n        Yields:\n            AsyncIterator[bytes]: An iterator over the file's bytes\n\n        Raises:\n            :py:class:`aiohttp.ClientResponseError`: Raised if the response is not OK\n        \"\"\"\n        async with self.session.get(url, allow_redirects=True) as response:\n            response.raise_for_status()\n            if self.check_content_type and content_type:\n                validate.content_type(\n                    actual=response.content_type, expected=content_type\n                )\n            if messages:\n                await messages.put(OpenUrl(url=url, size=response.content_length))\n            async for chunk, _ in response.content.iter_chunks():\n                yield chunk\n\n    async def close(self) -> None:\n        \"\"\"Close this http client.\n\n        Closes the underlying session.\n        \"\"\"\n        await self.session.close()\n\n    async def __aenter__(self) -> HttpClient:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> Optional[bool]:\n        await self.close()\n        return await super().__aexit__(exc_type, exc_val, exc_tb)", "\nclass HttpClient(Client):\n    \"\"\"A simple client for making HTTP requests.\n\n    By default, doesn't do any authentication.\n    Configure the session to customize its behavior.\n    \"\"\"\n\n    session: ClientSession\n    \"\"\"A atiohttp session that will be used for all requests.\"\"\"\n\n    @classmethod\n    async def from_config(cls: Type[T], config: Config) -> T:\n        \"\"\"Creates the default http client with a vanilla session object.\"\"\"\n        # TODO add basic auth\n        session = ClientSession()\n        return cls(session)\n\n    def __init__(self, session: ClientSession, check_content_type: bool = True) -> None:\n        super().__init__()\n        self.session = session\n        self.check_content_type = check_content_type\n\n    async def open_url(\n        self,\n        url: URL,\n        content_type: Optional[str] = None,\n        messages: Optional[Queue[Message]] = None,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"Opens a url with this client's session and iterates over its bytes.\n\n        Args:\n            url: The url to open\n            content_type: The expected content type\n            messages: An optional queue to use for progress reporting\n\n        Yields:\n            AsyncIterator[bytes]: An iterator over the file's bytes\n\n        Raises:\n            :py:class:`aiohttp.ClientResponseError`: Raised if the response is not OK\n        \"\"\"\n        async with self.session.get(url, allow_redirects=True) as response:\n            response.raise_for_status()\n            if self.check_content_type and content_type:\n                validate.content_type(\n                    actual=response.content_type, expected=content_type\n                )\n            if messages:\n                await messages.put(OpenUrl(url=url, size=response.content_length))\n            async for chunk, _ in response.content.iter_chunks():\n                yield chunk\n\n    async def close(self) -> None:\n        \"\"\"Close this http client.\n\n        Closes the underlying session.\n        \"\"\"\n        await self.session.close()\n\n    async def __aenter__(self) -> HttpClient:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> Optional[bool]:\n        await self.close()\n        return await super().__aexit__(exc_type, exc_val, exc_tb)", ""]}
{"filename": "src/stac_asset/config.py", "chunked_list": ["from __future__ import annotations\n\nimport copy\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional\n\nfrom .errors import ConfigError\nfrom .strategy import ErrorStrategy, FileNameStrategy\n\nDEFAULT_S3_REGION_NAME = \"us-west-2\"", "\nDEFAULT_S3_REGION_NAME = \"us-west-2\"\nDEFAULT_S3_RETRY_MODE = \"adaptive\"\nDEFAULT_S3_MAX_ATTEMPTS = 10\n\n\n@dataclass\nclass Config:\n    \"\"\"Configuration for downloading items and their assets.\"\"\"\n\n    alternate_assets: List[str] = field(default_factory=list)\n    \"\"\"Alternate asset keys to prefer, if available.\"\"\"\n\n    file_name_strategy: FileNameStrategy = FileNameStrategy.FILE_NAME\n    \"\"\"The file name strategy to use when downloading assets.\"\"\"\n\n    warn: bool = False\n    \"\"\"If an error occurs during download, warn instead of raising the error.\"\"\"\n\n    fail_fast: bool = False\n    \"\"\"If an error occurs during download, fail immediately.\n\n    By default, all downloads are completed before raising/warning any errors.\n    Mutually exclusive with ``warn``.\n    \"\"\"\n\n    error_strategy: ErrorStrategy = ErrorStrategy.DELETE\n    \"\"\"The strategy to use when errors occur during download.\"\"\"\n\n    exclude: List[str] = field(default_factory=list)\n    \"\"\"Assets to exclude from the download.\n\n    Mutually exclusive with ``include``.\n    \"\"\"\n\n    include: List[str] = field(default_factory=list)\n    \"\"\"Assets to include in the download.\n\n    Mutually exclusive with ``exclude``.\n    \"\"\"\n\n    make_directory: bool = True\n    \"\"\"Whether to create the output directory.\n\n    If False, and the output directory does not exist, an error will be raised.\n    \"\"\"\n\n    clean: bool = True\n    \"\"\"If true, clean up the downloaded file if it errors.\"\"\"\n\n    overwrite: bool = False\n    \"\"\"Download files even if they already exist locally.\"\"\"\n\n    earthdata_token: Optional[str] = None\n    \"\"\"A token for logging in to Earthdata.\"\"\"\n\n    s3_region_name: str = DEFAULT_S3_REGION_NAME\n    \"\"\"Default s3 region.\"\"\"\n\n    s3_requester_pays: bool = False\n    \"\"\"If using the s3 client, enable requester pays.\"\"\"\n\n    s3_retry_mode: str = DEFAULT_S3_RETRY_MODE\n    \"\"\"The retry mode to use for s3 requests.\"\"\"\n\n    s3_max_attempts: int = DEFAULT_S3_MAX_ATTEMPTS\n    \"\"\"The maximum number of attempts when downloading assets from s3.\"\"\"\n\n    def validate(self) -> None:\n        \"\"\"Validates this configuration.\n\n        Raises:\n            CannotIncludeAndExclude: ``include`` and ``exclude`` are mutually exclusive\n        \"\"\"\n        if self.include and self.exclude:\n            raise ConfigError(\n                f\"cannot provide both include and exclude: include={self.include}, \"\n                \"exclude={self.exclude}\"\n            )\n        if self.warn and self.fail_fast:\n            raise ConfigError(\"cannot warn and fail fast as the same time\")\n\n    def copy(self) -> Config:\n        \"\"\"Returns a deep copy of this config.\n\n        Returns:\n            Config: A deep copy of this config.\n        \"\"\"\n        return copy.deepcopy(self)", ""]}
{"filename": "src/stac_asset/errors.py", "chunked_list": ["from typing import Any, List\n\n\nclass AssetOverwriteError(Exception):\n    \"\"\"Raised when an asset would be overwritten during download.\"\"\"\n\n    def __init__(self, hrefs: List[str]) -> None:\n        super().__init__(\n            f\"assets have the same file names and would overwrite each other: {hrefs}\"\n        )", "\n\nclass DownloadWarning(Warning):\n    \"\"\"A warning for when something couldn't be downloaded.\n\n    Used when we don't want to cancel all downloads, but still inform the user\n    about the problem.\n    \"\"\"\n\n\nclass ConfigError(Exception):\n    \"\"\"Raised if the configuration is not valid.\"\"\"", "\n\nclass ConfigError(Exception):\n    \"\"\"Raised if the configuration is not valid.\"\"\"\n\n\nclass ContentTypeError(Exception):\n    \"\"\"The expected content type does not match the actual content type.\"\"\"\n\n    def __init__(self, actual: str, expected: str, *args: Any, **kwargs: Any) -> None:\n        super().__init__(\n            f\"the actual content type does not match the expected: actual={actual}, \"\n            f\"expected={expected}\",\n            *args,\n            **kwargs,\n        )", "\n\nclass DownloadError(Exception):\n    \"\"\"A collection of exceptions encountered while downloading.\"\"\"\n\n    exceptions: List[Exception]\n\n    def __init__(self, exceptions: List[Exception], *args: Any, **kwargs: Any) -> None:\n        self.exceptions = exceptions\n        messages = list()\n        for exception in exceptions:\n            messages.append(str(exception))\n        super().__init__(\"\\n\".join(messages), *args, **kwargs)", ""]}
{"filename": "src/stac_asset/client.py", "chunked_list": ["from __future__ import annotations\n\nfrom abc import ABC, abstractmethod\nfrom asyncio import Lock, Queue, QueueFull\nfrom pathlib import Path\nfrom types import TracebackType\nfrom typing import AsyncIterator, Dict, Optional, Type, TypeVar\n\nimport aiofiles\nfrom yarl import URL", "import aiofiles\nfrom yarl import URL\n\nfrom .config import Config\nfrom .messages import (\n    Message,\n    WriteChunk,\n)\nfrom .types import PathLikeObject\n", "from .types import PathLikeObject\n\nT = TypeVar(\"T\", bound=\"Client\")\n\n\nclass Client(ABC):\n    \"\"\"An abstract base class for all clients.\"\"\"\n\n    @classmethod\n    async def from_config(cls: Type[T], config: Config) -> T:\n        \"\"\"Creates a client using the provided configuration.\n\n        Needed because some client setups require async operations.\n\n        Returns:\n            T: A new client Client\n        \"\"\"\n        return cls()\n\n    def __init__(self) -> None:\n        pass\n\n    @abstractmethod\n    async def open_url(\n        self,\n        url: URL,\n        content_type: Optional[str] = None,\n        messages: Optional[Queue[Message]] = None,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"Opens a url and yields an iterator over its bytes.\n\n        This is the core method that all clients must implement.\n\n        Args:\n            url: The input url\n            content_type: The expected content type, to be checked by the client\n                implementations\n            messages: An optional queue to use for progress reporting\n\n        Yields:\n            AsyncIterator[bytes]: An iterator over chunks of the read file\n        \"\"\"\n        # https://github.com/python/mypy/issues/5070\n        if False:  # pragma: no cover\n            yield\n\n    async def open_href(\n        self,\n        href: str,\n        content_type: Optional[str] = None,\n        messages: Optional[Queue[Message]] = None,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"Opens a href and yields an iterator over its bytes.\n\n        Args:\n            href: The input href\n            content_type: The expected content type\n            messages: An optional queue to use for progress reporting\n\n        Yields:\n            AsyncIterator[bytes]: An iterator over chunks of the read file\n        \"\"\"\n        async for chunk in self.open_url(\n            URL(href), content_type=content_type, messages=messages\n        ):\n            yield chunk\n\n    async def download_href(\n        self,\n        href: str,\n        path: PathLikeObject,\n        clean: bool = True,\n        content_type: Optional[str] = None,\n        messages: Optional[Queue[Message]] = None,\n    ) -> None:\n        \"\"\"Downloads a file to the local filesystem.\n\n        Args:\n            href: The input href\n            path: The output file path\n            clean: If an error occurs, delete the output file if it exists\n            content_type: The expected content type\n            messages: An optional queue to use for progress reporting\n        \"\"\"\n        try:\n            async with aiofiles.open(path, mode=\"wb\") as f:\n                async for chunk in self.open_href(\n                    href, content_type=content_type, messages=messages\n                ):\n                    await f.write(chunk)\n                    if messages:\n                        try:\n                            messages.put_nowait(\n                                WriteChunk(href=href, path=Path(path), size=len(chunk))\n                            )\n                        except QueueFull:\n                            pass\n        except Exception as err:\n            path_as_path = Path(path)\n            if clean and path_as_path.exists():\n                try:\n                    path_as_path.unlink()\n                except Exception:\n                    pass\n            raise err\n\n    async def close(self) -> None:\n        \"\"\"Close this client.\"\"\"\n        pass\n\n    async def __aenter__(self) -> Client:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> Optional[bool]:\n        return None", "\n\nclass Clients:\n    \"\"\"An async-safe cache of clients.\"\"\"\n\n    lock: Lock\n    clients: Dict[Type[Client], Client]\n    config: Config\n\n    def __init__(self, config: Config) -> None:\n        self.lock = Lock()\n        self.clients = dict()\n        self.config = config\n\n    async def get_client(self, href: str) -> Client:\n        \"\"\"Gets a client for the provided href.\n\n        Args:\n            href: The file href to download\n\n        Returns:\n            Client: An instance of that client.\n        \"\"\"\n        from .filesystem_client import FilesystemClient\n        from .http_client import HttpClient\n        from .planetary_computer_client import PlanetaryComputerClient\n        from .s3_client import S3Client\n\n        url = URL(href)\n        if not url.host:\n            client_class: Type[Client] = FilesystemClient\n        elif url.scheme == \"s3\":\n            client_class = S3Client\n        elif url.host.endswith(\"blob.core.windows.net\"):\n            client_class = PlanetaryComputerClient\n        elif url.scheme == \"http\" or url.scheme == \"https\":\n            client_class = HttpClient\n        else:\n            raise ValueError(f\"could not guess client class for href: {href}\")\n\n        async with self.lock:\n            if client_class in self.clients:\n                return self.clients[client_class]\n            else:\n                client = await client_class.from_config(self.config)\n                self.clients[client_class] = client\n                return client\n\n    async def close_all(self) -> None:\n        \"\"\"Close all clients.\"\"\"\n        async with self.lock:\n            for client in self.clients.values():\n                await client.close()", ""]}
{"filename": "src/stac_asset/_cli.py", "chunked_list": ["import asyncio\nimport json\nimport logging\nimport os\nimport sys\nfrom asyncio import Queue\nfrom dataclasses import dataclass\nfrom typing import TYPE_CHECKING, Any, List, Optional, Union\n\nimport click", "\nimport click\nimport click_logging\nimport tqdm\nfrom pystac import Item, ItemCollection\n\nfrom . import Config, ErrorStrategy, _functions\nfrom .client import Clients\nfrom .config import DEFAULT_S3_MAX_ATTEMPTS, DEFAULT_S3_RETRY_MODE\nfrom .messages import (", "from .config import DEFAULT_S3_MAX_ATTEMPTS, DEFAULT_S3_RETRY_MODE\nfrom .messages import (\n    ErrorAssetDownload,\n    FinishAssetDownload,\n    OpenUrl,\n    StartAssetDownload,\n    WriteChunk,\n)\n\nlogger = logging.getLogger(__name__)", "\nlogger = logging.getLogger(__name__)\nclick_logging.basic_config(logger)\n\n# Needed until we drop Python 3.8\nif TYPE_CHECKING:\n    AnyQueue = Queue[Any]\n    Tqdm = tqdm.tqdm[Any]\nelse:\n    AnyQueue = Queue\n    Tqdm = tqdm.tqdm", "\n\n@click.group()\ndef cli() -> None:\n    \"\"\"Work with STAC assets.\n\n    See each subcommand's help text for more information:\n\n        $ stac-asset download --help\n    \"\"\"", "\n\n@cli.command()\n@click_logging.simple_verbosity_option(logger)  # type: ignore\n@click.argument(\"href\", required=False)\n@click.argument(\"directory\", required=False)\n@click.option(\n    \"-a\",\n    \"--alternate-assets\",\n    help=\"Alternate asset hrefs to prefer, if available\",", "    \"--alternate-assets\",\n    help=\"Alternate asset hrefs to prefer, if available\",\n    multiple=True,\n)\n@click.option(\"-i\", \"--include\", help=\"Asset keys to include\", multiple=True)\n@click.option(\n    \"-x\",\n    \"--exclude\",\n    help=\"Asset keys to exclude (can't be used with include)\",\n    multiple=True,", "    help=\"Asset keys to exclude (can't be used with include)\",\n    multiple=True,\n)\n@click.option(\"-f\", \"--file-name\", help=\"The output file name\")\n@click.option(\n    \"-q\",\n    \"--quiet\",\n    help=\"Do not print anything to standard output.\",\n    default=False,\n    is_flag=True,", "    default=False,\n    is_flag=True,\n    show_default=True,\n)\n@click.option(\n    \"--s3-requester-pays\",\n    help=\"If downloading via the s3 client, enable requester pays\",\n    default=False,\n    is_flag=True,\n    show_default=True,", "    is_flag=True,\n    show_default=True,\n)\n@click.option(\n    \"--s3-retry-mode\",\n    help=\"If downloading via the s3 client, the retry mode (standard, legacy, and \"\n    \"adaptive)\",\n    default=DEFAULT_S3_RETRY_MODE,\n)\n@click.option(", ")\n@click.option(\n    \"--s3-max-attempts\",\n    help=\"If downloading via the s3 client, the max number of retries\",\n    default=DEFAULT_S3_MAX_ATTEMPTS,\n)\n@click.option(\n    \"-w\",\n    \"--warn\",\n    help=\"Warn on download errors, instead of erroring\",", "    \"--warn\",\n    help=\"Warn on download errors, instead of erroring\",\n    default=False,\n    is_flag=True,\n    show_default=True,\n)\n@click.option(\n    \"-k\",\n    \"--keep\",\n    help=(", "    \"--keep\",\n    help=(\n        \"If warning on error, keep assets that couldn't be downloaded with their \"\n        \"original hrefs. If false, delete those assets from the item.\"\n    ),\n    default=False,\n    is_flag=True,\n    show_default=True,\n)\n@click.option(", ")\n@click.option(\n    \"--fail-fast\",\n    help=\"Fail immediately on download error, instead of waiting until all are \"\n    \"complete. Mutually exclusive with --warn\",\n    default=False,\n    is_flag=True,\n    show_default=True,\n)\n@click.option(", ")\n@click.option(\n    \"--overwrite\",\n    help=\"Overwrite existing files if they exist on the filesystem\",\n    default=False,\n    is_flag=True,\n    show_default=True,\n)\n# TODO add option to disable content type checking\ndef download(\n    href: Optional[str],\n    directory: Optional[str],\n    alternate_assets: List[str],\n    include: List[str],\n    exclude: List[str],\n    file_name: Optional[str],\n    quiet: bool,\n    s3_requester_pays: bool,\n    s3_retry_mode: str,\n    s3_max_attempts: int,\n    warn: bool,\n    keep: bool,\n    fail_fast: bool,\n    overwrite: bool,\n) -> None:\n    \"\"\"Download STAC assets from an item or item collection.\n\n    If href is not provided, or is ``-``, the item or item collection is parsed\n    as JSON from standard input. If the directory is not provided, the current\n    working directory is used.\n\n    These three examples are equivalent, and download the assets to the current\n    working directory:\n\n        $ stac-asset download item.json\n\n        $ stac-asset download item.json .\n\n        $ cat item.json | stac-asset download\n\n    To only include certain asset keys:\n\n        $ stac-asset download -i asset-key-to-include item.json\n    \"\"\"\n    asyncio.run(\n        download_async(\n            href,\n            directory,\n            alternate_assets,\n            include,\n            exclude,\n            file_name,\n            quiet,\n            s3_requester_pays,\n            s3_retry_mode,\n            s3_max_attempts,\n            warn=warn,\n            keep=keep,\n            fail_fast=fail_fast,\n            overwrite=overwrite,\n        )\n    )", "# TODO add option to disable content type checking\ndef download(\n    href: Optional[str],\n    directory: Optional[str],\n    alternate_assets: List[str],\n    include: List[str],\n    exclude: List[str],\n    file_name: Optional[str],\n    quiet: bool,\n    s3_requester_pays: bool,\n    s3_retry_mode: str,\n    s3_max_attempts: int,\n    warn: bool,\n    keep: bool,\n    fail_fast: bool,\n    overwrite: bool,\n) -> None:\n    \"\"\"Download STAC assets from an item or item collection.\n\n    If href is not provided, or is ``-``, the item or item collection is parsed\n    as JSON from standard input. If the directory is not provided, the current\n    working directory is used.\n\n    These three examples are equivalent, and download the assets to the current\n    working directory:\n\n        $ stac-asset download item.json\n\n        $ stac-asset download item.json .\n\n        $ cat item.json | stac-asset download\n\n    To only include certain asset keys:\n\n        $ stac-asset download -i asset-key-to-include item.json\n    \"\"\"\n    asyncio.run(\n        download_async(\n            href,\n            directory,\n            alternate_assets,\n            include,\n            exclude,\n            file_name,\n            quiet,\n            s3_requester_pays,\n            s3_retry_mode,\n            s3_max_attempts,\n            warn=warn,\n            keep=keep,\n            fail_fast=fail_fast,\n            overwrite=overwrite,\n        )\n    )", "\n\nasync def download_async(\n    href: Optional[str],\n    directory: Optional[str],\n    alternate_assets: List[str],\n    include: List[str],\n    exclude: List[str],\n    file_name: Optional[str],\n    quiet: bool,", "    file_name: Optional[str],\n    quiet: bool,\n    s3_requester_pays: bool,\n    s3_retry_mode: str,\n    s3_max_attempts: int,\n    warn: bool,\n    keep: bool,\n    fail_fast: bool,\n    overwrite: bool,\n) -> None:", "    overwrite: bool,\n) -> None:\n    config = Config(\n        alternate_assets=alternate_assets,\n        include=include,\n        exclude=exclude,\n        s3_requester_pays=s3_requester_pays,\n        s3_retry_mode=s3_retry_mode,\n        s3_max_attempts=s3_max_attempts,\n        error_strategy=ErrorStrategy.KEEP if keep else ErrorStrategy.DELETE,", "        s3_max_attempts=s3_max_attempts,\n        error_strategy=ErrorStrategy.KEEP if keep else ErrorStrategy.DELETE,\n        warn=warn,\n        fail_fast=fail_fast,\n        overwrite=overwrite,\n    )\n\n    if href is None or href == \"-\":\n        input_dict = json.load(sys.stdin)\n    else:\n        input_dict = json.loads(await read_file(href, config))", "    if directory is None:\n        directory_str = os.getcwd()\n    else:\n        directory_str = str(directory)\n\n    if quiet:\n        queue = None\n    else:\n        queue = Queue()\n", "\n    type_ = input_dict.get(\"type\")\n    if type_ is None:\n        if not quiet:\n            print(\"ERROR: missing 'type' field on input dictionary\", file=sys.stderr)\n        sys.exit(1)\n    elif type_ == \"Feature\":\n        item = Item.from_dict(input_dict)\n        if href:\n            item.set_self_href(href)\n            item.make_asset_hrefs_absolute()\n\n        async def download() -> Union[Item, ItemCollection]:\n            return await _functions.download_item(\n                item,\n                directory_str,\n                file_name=file_name,\n                config=config,\n                queue=queue,\n            )\n\n    elif type_ == \"FeatureCollection\":\n        item_collection = ItemCollection.from_dict(input_dict)\n\n        async def download() -> Union[Item, ItemCollection]:\n            return await _functions.download_item_collection(\n                item_collection,\n                directory_str,\n                file_name=file_name,\n                config=config,\n                queue=queue,\n            )\n\n    else:\n        if not quiet:\n            print(f\"ERROR: unsupported 'type' field: {type_}\", file=sys.stderr)\n        sys.exit(2)", "\n    task = asyncio.create_task(report_progress(queue))\n    output = await download()\n    if queue:\n        await queue.put(None)\n    await task\n\n    if not quiet:\n        json.dump(output.to_dict(transform_hrefs=False), sys.stdout)\n", "\n\nasync def read_file(href: str, config: Config) -> bytes:\n    clients = Clients(config)\n    async with await clients.get_client(href) as client:\n        data = b\"\"\n        async for chunk in client.open_href(href):\n            data += chunk\n        return data\n", "        return data\n\n\nasync def report_progress(queue: Optional[AnyQueue]) -> None:\n    if queue is None:\n        return\n    progress_bar = tqdm.tqdm(\n        unit=\"B\",\n        unit_scale=True,\n        unit_divisor=1024,", "        unit_scale=True,\n        unit_divisor=1024,\n    )\n    sizes = dict()\n    assets = 0\n    done = 0\n    errors = 0\n    total = 0\n    n = 0\n    progress_bar.set_postfix_str(f\"{errors} errors\")", "    n = 0\n    progress_bar.set_postfix_str(f\"{errors} errors\")\n    while True:\n        message = await queue.get()\n        if isinstance(message, StartAssetDownload):\n            assets += 1\n            progress_bar.set_description(f\"{done}/{assets}\")\n        elif isinstance(message, OpenUrl):\n            if message.size:\n                total += message.size\n                sizes[str(message.url)] = message.size\n                progress_bar.reset(total=total)\n                progress_bar.update(n)\n        elif isinstance(message, FinishAssetDownload):\n            done += 1\n            progress_bar.set_description_str(f\"{done}/{assets}\")\n        elif isinstance(message, ErrorAssetDownload):\n            done += 1\n            errors += 1\n            if message.href in sizes:\n                total -= sizes[message.href]\n                progress_bar.reset(total=total)\n                progress_bar.update(n)\n            progress_bar.set_postfix_str(f\"{errors} errors\")\n            progress_bar.set_description_str(f\"{done}/{assets}\")\n        elif isinstance(message, WriteChunk):\n            n += message.size\n            progress_bar.update(message.size)\n        elif message is None:\n            progress_bar.close()\n            return", "\n\n@dataclass\nclass Download:\n    key: str\n    item_id: Optional[str]\n    href: str\n    path: str\n    progress_bar: Tqdm\n", "\n\nif __name__ == \"__main__\":\n    cli()\n"]}
{"filename": "src/stac_asset/planetary_computer_client.py", "chunked_list": ["from __future__ import annotations\n\nimport datetime\nfrom asyncio import Lock, Queue\nfrom datetime import timezone\nfrom types import TracebackType\nfrom typing import Any, AsyncIterator, Dict, Optional, Type\n\nimport dateutil.parser\nfrom aiohttp import ClientSession", "import dateutil.parser\nfrom aiohttp import ClientSession\nfrom yarl import URL\n\nfrom .http_client import HttpClient\n\nDEFAULT_SAS_TOKEN_ENDPOINT = \"https://planetarycomputer.microsoft.com/api/sas/v1/token\"\n\n\nclass _Token:\n    expiry: datetime.datetime\n    token: str\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> _Token:\n        try:\n            expiry = dateutil.parser.isoparse(data[\"msft:expiry\"])\n        except KeyError:\n            raise ValueError(f\"missing 'msft:expiry' key in dict: {data}\")\n\n        try:\n            token = data[\"token\"]\n        except KeyError:\n            raise ValueError(f\"missing 'token' key in dict: {data}\")\n\n        return cls(expiry=expiry, token=token)\n\n    def __init__(self, expiry: datetime.datetime, token: str) -> None:\n        self.expiry = expiry\n        self.token = token\n\n    def ttl(self) -> float:\n        return (self.expiry - datetime.datetime.now(timezone.utc)).total_seconds()\n\n    def __str__(self) -> str:\n        return self.token", "\nclass _Token:\n    expiry: datetime.datetime\n    token: str\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> _Token:\n        try:\n            expiry = dateutil.parser.isoparse(data[\"msft:expiry\"])\n        except KeyError:\n            raise ValueError(f\"missing 'msft:expiry' key in dict: {data}\")\n\n        try:\n            token = data[\"token\"]\n        except KeyError:\n            raise ValueError(f\"missing 'token' key in dict: {data}\")\n\n        return cls(expiry=expiry, token=token)\n\n    def __init__(self, expiry: datetime.datetime, token: str) -> None:\n        self.expiry = expiry\n        self.token = token\n\n    def ttl(self) -> float:\n        return (self.expiry - datetime.datetime.now(timezone.utc)).total_seconds()\n\n    def __str__(self) -> str:\n        return self.token", "\n\nclass PlanetaryComputerClient(HttpClient):\n    \"\"\"Open and download assets from Microsoft's Planetary Computer.\n\n    Heavily cribbed from\n    https://github.com/microsoft/planetary-computer-sdk-for-python/blob/main/planetary_computer/sas.py,\n    thanks Tom Augspurger!\n    \"\"\"\n\n    _cache: Dict[URL, _Token]\n    _cache_lock: Lock\n    token_request_url: URL\n\n    def __init__(\n        self,\n        session: ClientSession,\n        sas_token_endpoint: str = DEFAULT_SAS_TOKEN_ENDPOINT,\n    ) -> None:\n        super().__init__(session)\n        self._cache = dict()\n        self._cache_lock = Lock()\n        self.sas_token_endpoint = URL(sas_token_endpoint)\n\n    async def open_url(\n        self,\n        url: URL,\n        content_type: Optional[str] = None,\n        messages: Optional[Queue[Any]] = None,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"Opens a url and iterates over its bytes.\n\n        Includes functionality to sign the url with a SAS token fetched from\n        this client's ``sas_token_endpoint``. Tokens are cached on a per-client\n        basis to prevent a large number of requests when fetching many assets.\n\n        Not every URL is modified with a SAS token. We only modify the url if:\n\n        - The url is in Azure blob storage\n        - The url is not in the public thumbnail storage account\n        - The url hasn't already signed (we check this by seeing if the url has\n            SAS-like query parameters)\n\n        Args:\n            url: The url to open\n            content_type: The expected content type\n            messages: An optional queue to use for progress reporting\n\n        Yields:\n            AsyncIterator[bytes]: An iterator over the file's bytes\n        \"\"\"\n        if (\n            url.host is not None\n            and url.host.endswith(\".blob.core.windows.net\")\n            and not url.host == \"ai4edatasetspublicassets.blob.core.windows.net\"\n            and not set(url.query) & {\"st\", \"se\", \"sp\"}\n        ):\n            url = await self._sign(url)\n        async for chunk in super().open_url(\n            url, content_type=content_type, messages=messages\n        ):\n            yield chunk\n\n    async def _sign(self, url: URL) -> URL:\n        assert url.host\n        account_name = url.host.split(\".\")[0]\n        container_name = url.path.split(\"/\", 2)[1]\n        token = await self._get_token(account_name, container_name)\n        return URL(str(url.with_query(None)) + \"?\" + token, encoded=False)\n\n    async def _get_token(self, account_name: str, container_name: str) -> str:\n        url = self.sas_token_endpoint.joinpath(account_name, container_name)\n        async with self._cache_lock:\n            token = self._cache.get(url)\n            if token is None or token.ttl() < 60:\n                response = await self.session.get(url)\n                response.raise_for_status()\n                token = _Token.from_dict(await response.json())\n                self._cache[url] = token\n        return str(token)\n\n    async def __aenter__(self) -> PlanetaryComputerClient:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> Optional[bool]:\n        await self.close()\n        return await super().__aexit__(exc_type, exc_val, exc_tb)", ""]}
{"filename": "src/stac_asset/__init__.py", "chunked_list": ["\"\"\"Read and download STAC items, item collections, collections, and assets.\n\nThe core class is :py:class:`Client`, which defines a common interface for\naccessing assets. There are also some free functions, :py:func:`download_item`\nand :py:func:`download_item_collection`, which provide simple one-shot\ninterfaces for downloading assets.\n\nWriting items, item collections, collections, and assets is currently\nunsupported, but is on the roadmap.\n\"\"\"", "unsupported, but is on the roadmap.\n\"\"\"\n\n\nfrom ._functions import (\n    download_collection,\n    download_item,\n    download_item_collection,\n)\nfrom .client import Client", ")\nfrom .client import Client\nfrom .config import Config\nfrom .earthdata_client import EarthdataClient\nfrom .errors import (\n    AssetOverwriteError,\n    ConfigError,\n    ContentTypeError,\n    DownloadError,\n    DownloadWarning,", "    DownloadError,\n    DownloadWarning,\n)\nfrom .filesystem_client import FilesystemClient\nfrom .http_client import HttpClient\nfrom .planetary_computer_client import PlanetaryComputerClient\nfrom .s3_client import S3Client\nfrom .strategy import ErrorStrategy, FileNameStrategy\n\n# Keep this list sorted", "\n# Keep this list sorted\n__all__ = [\n    \"AssetOverwriteError\",\n    \"Client\",\n    \"Config\",\n    \"ConfigError\",\n    \"ContentTypeError\",\n    \"DownloadError\",\n    \"DownloadWarning\",", "    \"DownloadError\",\n    \"DownloadWarning\",\n    \"EarthdataClient\",\n    \"ErrorStrategy\",\n    \"FileNameStrategy\",\n    \"FilesystemClient\",\n    \"HttpClient\",\n    \"PlanetaryComputerClient\",\n    \"S3Client\",\n    \"download_collection\",", "    \"S3Client\",\n    \"download_collection\",\n    \"download_item\",\n    \"download_item_collection\",\n]\n"]}
{"filename": "src/stac_asset/s3_client.py", "chunked_list": ["from __future__ import annotations\n\nfrom asyncio import Queue\nfrom types import TracebackType\nfrom typing import AsyncIterator, Optional, Type\n\nimport aiobotocore.session\nimport botocore.config\nfrom aiobotocore.session import AioSession\nfrom botocore import UNSIGNED", "from aiobotocore.session import AioSession\nfrom botocore import UNSIGNED\nfrom yarl import URL\n\nfrom . import validate\nfrom .client import Client\nfrom .config import (\n    DEFAULT_S3_MAX_ATTEMPTS,\n    DEFAULT_S3_REGION_NAME,\n    DEFAULT_S3_RETRY_MODE,", "    DEFAULT_S3_REGION_NAME,\n    DEFAULT_S3_RETRY_MODE,\n    Config,\n)\nfrom .messages import Message, OpenUrl\n\n\nclass S3Client(Client):\n    \"\"\"A client for interacting with s3 urls.\"\"\"\n\n    session: AioSession\n    \"\"\"The session that will be used for all s3 requests.\"\"\"\n\n    region_name: str\n    \"\"\"The region that all clients will be rooted in.\"\"\"\n\n    requester_pays: bool\n    \"\"\"If True, add `--request-payer requester` to all requests.\"\"\"\n\n    retry_mode: str\n    \"\"\"The retry mode.\"\"\"\n\n    max_attempts: int\n    \"\"\"The maximum number of attempts.\"\"\"\n\n    @classmethod\n    async def from_config(cls, config: Config) -> S3Client:\n        \"\"\"Creates an s3 client from a config.\n\n        Args:\n            config: The config object\n\n        Returns:\n            S3Client: A new s3 client\n        \"\"\"\n        return cls(\n            requester_pays=config.s3_requester_pays,\n            region_name=config.s3_region_name,\n            retry_mode=config.s3_retry_mode,\n            max_attempts=config.s3_max_attempts,\n        )\n\n    def __init__(\n        self,\n        requester_pays: bool = False,\n        region_name: str = DEFAULT_S3_REGION_NAME,\n        retry_mode: str = DEFAULT_S3_RETRY_MODE,\n        max_attempts: int = DEFAULT_S3_MAX_ATTEMPTS,\n    ) -> None:\n        super().__init__()\n        self.session = aiobotocore.session.get_session()\n        self.region_name = region_name\n        self.requester_pays = requester_pays\n        self.retry_mode = retry_mode\n        self.max_attempts = max_attempts\n\n    async def open_url(\n        self,\n        url: URL,\n        content_type: Optional[str] = None,\n        messages: Optional[Queue[Message]] = None,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"Opens an s3 url and iterates over its bytes.\n\n        Args:\n            url: The url to open\n            content_type: The expected content type\n            messages: An optional queue to use for progress reporting\n\n        Yields:\n            AsyncIterator[bytes]: An iterator over the file's bytes\n\n        Raises:\n            SchemeError: Raised if the url's scheme is not ``s3``\n        \"\"\"\n        retries = {\n            \"max_attempts\": self.max_attempts,\n            \"mode\": self.retry_mode,\n        }\n        if self.requester_pays:\n            config = botocore.config.Config(retries=retries)\n        else:\n            config = botocore.config.Config(signature_version=UNSIGNED, retries=retries)\n        async with self.session.create_client(\n            \"s3\",\n            region_name=self.region_name,\n            config=config,\n        ) as client:\n            bucket = url.host\n            key = url.path[1:]\n            params = {\n                \"Bucket\": bucket,\n                \"Key\": key,\n            }\n            if self.requester_pays:\n                params[\"RequestPayer\"] = \"requester\"\n            response = await client.get_object(**params)\n            if content_type:\n                validate.content_type(response[\"ContentType\"], content_type)\n            if messages:\n                await messages.put(OpenUrl(url=url, size=response[\"ContentLength\"]))\n            async for chunk in response[\"Body\"]:\n                yield chunk\n\n    async def has_credentials(self) -> bool:\n        \"\"\"Returns true if the sessions has credentials.\"\"\"\n        return await self.session.get_credentials() is not None\n\n    async def __aenter__(self) -> S3Client:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> Optional[bool]:\n        return None", ""]}
{"filename": "src/stac_asset/_functions.py", "chunked_list": ["from __future__ import annotations\n\nimport asyncio\nimport json\nimport os.path\nimport warnings\nfrom asyncio import Queue, Task\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom types import TracebackType", "from pathlib import Path\nfrom types import TracebackType\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    List,\n    Optional,\n    Set,\n    Type,\n    Union,", "    Type,\n    Union,\n)\n\nimport pystac.utils\nfrom pystac import Asset, Collection, Item, ItemCollection, STACError\nfrom yarl import URL\n\nfrom .client import Clients\nfrom .config import Config", "from .client import Clients\nfrom .config import Config\nfrom .errors import AssetOverwriteError, DownloadError, DownloadWarning\nfrom .messages import (\n    ErrorAssetDownload,\n    FinishAssetDownload,\n    Message,\n    StartAssetDownload,\n)\nfrom .strategy import ErrorStrategy, FileNameStrategy", ")\nfrom .strategy import ErrorStrategy, FileNameStrategy\nfrom .types import PathLikeObject\n\n# Needed until we drop Python 3.8\nif TYPE_CHECKING:\n    AnyQueue = Queue[Any]\nelse:\n    AnyQueue = Queue\n", "\n\n@dataclass\nclass Download:\n    owner: Union[Item, Collection]\n    key: str\n    asset: Asset\n    path: Path\n    clients: Clients\n    config: Config\n\n    async def download(\n        self,\n        messages: Optional[AnyQueue],\n    ) -> Union[Download, WrappedError]:\n        if not os.path.exists(self.path) or self.config.overwrite:\n            try:\n                await download_asset(\n                    self.key,\n                    self.asset,\n                    self.path,\n                    config=self.config,\n                    messages=messages,\n                    clients=self.clients,\n                )\n            except Exception as error:\n                if self.config.fail_fast:\n                    raise error\n                else:\n                    return WrappedError(self, error)\n\n        self.asset.href = str(self.path)\n        return self", "\n\nclass Downloads:\n    clients: Clients\n    config: Config\n    downloads: List[Download]\n\n    def __init__(self, config: Config) -> None:\n        config.validate()\n        self.config = config\n        self.downloads = list()\n        self.clients = Clients(config)\n\n    async def add(\n        self, stac_object: Union[Item, Collection], root: Path, file_name: Optional[str]\n    ) -> None:\n        stac_object = make_link_hrefs_absolute(stac_object)\n        # Will fail if the stac object doesn't have a self href and there's\n        # relative asset hrefs\n        stac_object = make_asset_hrefs_absolute(stac_object)\n        if file_name:\n            stac_object.set_self_href(str(Path(root) / file_name))\n        else:\n            stac_object.set_self_href(None)\n\n        asset_file_names: Set[str] = set()\n        assets = dict()\n        for key, asset in (\n            (k, a)\n            for k, a in stac_object.assets.items()\n            if (not self.config.include or k in self.config.include)\n            and (not self.config.exclude or k not in self.config.exclude)\n        ):\n            if self.config.file_name_strategy == FileNameStrategy.FILE_NAME:\n                asset_file_name = os.path.basename(URL(asset.href).path)\n            elif self.config.file_name_strategy == FileNameStrategy.KEY:\n                asset_file_name = key + Path(asset.href).suffix\n            else:\n                raise ValueError(\n                    f\"unexpected file name strategy: {self.config.file_name_strategy}\"\n                )\n            if asset_file_name in asset_file_names:\n                raise AssetOverwriteError(list(asset_file_names))\n\n            asset_file_names.add(asset_file_name)\n            assets[key] = asset\n            self.downloads.append(\n                Download(\n                    owner=stac_object,\n                    key=key,\n                    asset=asset,\n                    path=root / asset_file_name,\n                    clients=self.clients,\n                    config=self.config,\n                )\n            )\n        stac_object.assets = assets\n\n    async def download(self, messages: Optional[AnyQueue]) -> None:\n        tasks: Set[Task[Union[Download, WrappedError]]] = set()\n        for download in self.downloads:\n            task = asyncio.create_task(\n                download.download(\n                    messages=messages,\n                )\n            )\n            tasks.add(task)\n            task.add_done_callback(tasks.discard)\n\n        try:\n            results = await asyncio.gather(*tasks)\n        except Exception as error:\n            # We failed fast\n            for task in tasks:\n                if not task.done():\n                    task.cancel()\n            await asyncio.gather(*tasks, return_exceptions=True)\n            raise error\n\n        exceptions = list()\n        for result in results:\n            if isinstance(result, WrappedError):\n                if self.config.error_strategy == ErrorStrategy.DELETE:\n                    del result.download.owner.assets[result.download.key]\n                else:\n                    # Simple check to make sure we haven't added other\n                    # strategies that we're not handling\n                    assert self.config.error_strategy == ErrorStrategy.KEEP\n\n                if self.config.warn:\n                    warnings.warn(str(result.error), DownloadWarning)\n                else:\n                    exceptions.append(result.error)\n        if exceptions:\n            raise DownloadError(exceptions)\n\n    async def __aenter__(self) -> Downloads:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        await self.clients.close_all()", "\n\nclass WrappedError:\n    download: Download\n    error: Exception\n\n    def __init__(self, download: Download, error: Exception) -> None:\n        self.download = download\n        self.error = error\n", "\n\nasync def download_item(\n    item: Item,\n    directory: PathLikeObject,\n    file_name: Optional[str] = None,\n    config: Optional[Config] = None,\n    queue: Optional[AnyQueue] = None,\n) -> Item:\n    \"\"\"Downloads an item to the local filesystem.", ") -> Item:\n    \"\"\"Downloads an item to the local filesystem.\n\n    Args:\n        item: The :py:class:`pystac.Item`.\n        directory: The output directory that will hold the items and assets.\n        file_name: The name of the item file to save. If not provided, will not\n            be saved.\n        config: The download configuration\n        queue: An optional queue to use for progress reporting", "        config: The download configuration\n        queue: An optional queue to use for progress reporting\n\n    Returns:\n        Item: The `~pystac.Item`, with the updated asset hrefs and self href.\n\n    Raises:\n        ValueError: Raised if the item doesn't have any assets.\n    \"\"\"\n    async with Downloads(config or Config()) as downloads:", "    \"\"\"\n    async with Downloads(config or Config()) as downloads:\n        await downloads.add(item, Path(directory), file_name)\n        await downloads.download(queue)\n\n    self_href = item.get_self_href()\n    if self_href:\n        make_asset_hrefs_relative(item)\n        d = item.to_dict(include_self_link=True, transform_hrefs=False)\n        with open(self_href, \"w\") as f:\n            json.dump(d, f)", "\n    return item\n\n\nasync def download_collection(\n    collection: Collection,\n    directory: PathLikeObject,\n    file_name: Optional[str] = None,\n    config: Optional[Config] = None,\n    queue: Optional[AnyQueue] = None,", "    config: Optional[Config] = None,\n    queue: Optional[AnyQueue] = None,\n) -> Collection:\n    \"\"\"Downloads a collection to the local filesystem.\n\n    Does not download the collection's items' assets -- use\n    :py:func:`download_item_collection` to download multiple items.\n\n    Args:\n        collection: A pystac collection", "    Args:\n        collection: A pystac collection\n        directory: The destination directory\n        file_name: The name of the collection file to save. If not provided,\n            will not be saved.\n        config: The download configuration\n        queue: An optional queue to use for progress reporting\n\n    Returns:\n        Collection: The collection, with updated asset hrefs", "    Returns:\n        Collection: The collection, with updated asset hrefs\n\n    Raises:\n        CantIncludeAndExclude: Raised if both include and exclude are not None.\n    \"\"\"\n    async with Downloads(config or Config()) as downloads:\n        await downloads.add(collection, Path(directory), file_name)\n        await downloads.download(queue)\n", "        await downloads.download(queue)\n\n    self_href = collection.get_self_href()\n    if self_href:\n        make_asset_hrefs_relative(collection)\n        d = collection.to_dict(include_self_link=True, transform_hrefs=False)\n        with open(self_href, \"w\") as f:\n            json.dump(d, f)\n\n    return collection", "\n    return collection\n\n\nasync def download_item_collection(\n    item_collection: ItemCollection,\n    directory: PathLikeObject,\n    file_name: Optional[str] = None,\n    config: Optional[Config] = None,\n    queue: Optional[AnyQueue] = None,", "    config: Optional[Config] = None,\n    queue: Optional[AnyQueue] = None,\n) -> ItemCollection:\n    \"\"\"Downloads an item collection to the local filesystem.\n\n    Args:\n        item_collection: The item collection to download\n        directory: The destination directory\n        file_name: The name of the item collection file to save. If not\n            provided, will not be saved.", "        file_name: The name of the item collection file to save. If not\n            provided, will not be saved.\n        config: The download configuration\n        queue: An optional queue to use for progress reporting\n\n    Returns:\n        ItemCollection: The item collection, with updated asset hrefs\n\n    Raises:\n        CantIncludeAndExclude: Raised if both include and exclude are not None.", "    Raises:\n        CantIncludeAndExclude: Raised if both include and exclude are not None.\n    \"\"\"\n    async with Downloads(config or Config()) as downloads:\n        for item in item_collection.items:\n            item.set_self_href(None)\n            root = Path(directory) / item.id\n            await downloads.add(item, root, None)\n        await downloads.download(queue)\n    if file_name:\n        dest_href = Path(directory) / file_name\n        for item in item_collection.items:\n            for asset in item.assets.values():\n                asset.href = pystac.utils.make_relative_href(\n                    asset.href, str(dest_href), start_is_dir=False\n                )\n        item_collection.save_object(dest_href=str(dest_href))", "        await downloads.download(queue)\n    if file_name:\n        dest_href = Path(directory) / file_name\n        for item in item_collection.items:\n            for asset in item.assets.values():\n                asset.href = pystac.utils.make_relative_href(\n                    asset.href, str(dest_href), start_is_dir=False\n                )\n        item_collection.save_object(dest_href=str(dest_href))\n", "\n    return item_collection\n\n\nasync def download_asset(\n    key: str,\n    asset: Asset,\n    path: Path,\n    config: Config,\n    messages: Optional[Queue[Message]] = None,", "    config: Config,\n    messages: Optional[Queue[Message]] = None,\n    clients: Optional[Clients] = None,\n) -> Asset:\n    \"\"\"Downloads an asset.\n\n    Args:\n        key: The asset key\n        asset: The asset\n        path: The path to which the asset will be downloaded", "        asset: The asset\n        path: The path to which the asset will be downloaded\n        config: The download configuration\n        messages: An optional queue to use for progress reporting\n        clients: A async-safe cache of clients. If not provided, a new one\n            will be created.\n\n    Returns:\n        Asset: The asset with an updated href\n", "        Asset: The asset with an updated href\n\n    Raises:\n        ValueError: Raised if the asset does not have an absolute href\n    \"\"\"\n    if clients is None:\n        clients = Clients(config)\n\n    if not path.parent.exists():\n        if config.make_directory:\n            path.parent.mkdir(parents=True, exist_ok=True)\n        else:\n            raise FileNotFoundError(f\"output directory does not exist: {path.parent}\")", "    if not path.parent.exists():\n        if config.make_directory:\n            path.parent.mkdir(parents=True, exist_ok=True)\n        else:\n            raise FileNotFoundError(f\"output directory does not exist: {path.parent}\")\n\n    href = get_absolute_asset_href(\n        asset=asset, alternate_assets=config.alternate_assets\n    )\n    if href is None:\n        raise ValueError(f\"asset '{key}' does not have an absolute href: {asset.href}\")", "    )\n    if href is None:\n        raise ValueError(f\"asset '{key}' does not have an absolute href: {asset.href}\")\n    client = await clients.get_client(href)\n\n    if messages:\n        if asset.owner:\n            item_id = asset.owner.id\n        else:\n            item_id = None\n        await messages.put(\n            StartAssetDownload(key=key, href=href, path=path, item_id=item_id)\n        )", "    try:\n        await client.download_href(\n            href,\n            path,\n            clean=config.clean,\n            content_type=asset.media_type,\n            messages=messages,\n        )\n    except Exception as err:\n        if messages:\n            await messages.put(ErrorAssetDownload(key=key, href=href, path=path))\n        raise err", "\n    if messages:\n        await messages.put(FinishAssetDownload(key=key, href=href, path=path))\n    return asset\n\n\ndef make_asset_hrefs_relative(\n    stac_object: Union[Item, Collection]\n) -> Union[Item, Collection]:\n    # Copied from\n    # https://github.com/stac-utils/pystac/blob/381cf89fc25c15142fb5a187d905e22681de42a2/pystac/item.py#L284C5-L298C20\n    # until a fix for https://github.com/stac-utils/pystac/issues/1199 is\n    # released.\n    self_href = stac_object.get_self_href()\n    for asset in stac_object.assets.values():\n        if pystac.utils.is_absolute_href(asset.href):\n            if self_href is None:\n                raise STACError(\n                    \"Cannot make asset HREFs relative \" \"if no self_href is set.\"\n                )\n            asset.href = pystac.utils.make_relative_href(asset.href, self_href)\n    return stac_object", "\n\ndef make_asset_hrefs_absolute(\n    stac_object: Union[Item, Collection]\n) -> Union[Item, Collection]:\n    # Copied from\n    # https://github.com/stac-utils/pystac/blob/381cf89fc25c15142fb5a187d905e22681de42a2/pystac/item.py#L309C3-L319C1\n    # until a fix for https://github.com/stac-utils/pystac/issues/1199 is\n    # released.\n    self_href = stac_object.get_self_href()\n    for asset in stac_object.assets.values():\n        if not pystac.utils.is_absolute_href(asset.href):\n            if self_href is None:\n                raise STACError(\n                    \"Cannot make asset HREFs absolute if no self_href is set.\"\n                )\n            asset.href = pystac.utils.make_absolute_href(asset.href, self_href)\n    return stac_object", "\n\ndef make_link_hrefs_absolute(\n    stac_object: Union[Item, Collection], drop: bool = True\n) -> Union[Item, Collection]:\n    # This could be in pystac w/ STACObject as the input+output type\n    links = list()\n    for link in stac_object.links:\n        absolute_href = link.get_absolute_href()\n        if absolute_href:\n            link.target = absolute_href\n            links.append(link)\n        elif not drop:\n            raise ValueError(f\"cannot make link's href absolute: {link}\")\n    stac_object.links = links\n    return stac_object", "\n\ndef get_absolute_asset_href(asset: Asset, alternate_assets: List[str]) -> Optional[str]:\n    alternate = asset.extra_fields.get(\"alternate\")\n    if not isinstance(alternate, dict):\n        alternate = None\n    if alternate and alternate_assets:\n        for alternate_asset in alternate_assets:\n            if alternate_asset in alternate:\n                try:\n                    href = alternate[alternate_asset][\"href\"]\n                    if asset.owner:\n                        start_href = asset.owner.get_self_href()\n                    else:\n                        start_href = None\n                    return pystac.utils.make_absolute_href(\n                        href, start_href, start_is_dir=False\n                    )\n                except KeyError:\n                    raise ValueError(\n                        \"invalid alternate asset definition (missing href): \"\n                        f\"{alternate}\"\n                    )\n    return asset.get_absolute_href()", ""]}
{"filename": "src/stac_asset/validate.py", "chunked_list": ["from .errors import ContentTypeError\n\nALLOWABLE_PAIRS = [\n    (\"image/tiff\", \"image/tiff; application=geotiff; profile=cloud-optimized\")\n]\nIGNORED_CONTENT_TYPES = [\"binary/octet-stream\", \"application/octet-stream\"]\n\n\ndef content_type(actual: str, expected: str) -> None:\n    \"\"\"Validates that the actual content type matches the expected.\n\n    This is more complicated than a simple string comparison, because we want to\n    allow TIFF when COG is expected, etc.\n\n    Args:\n        actual: The actual content type\n        expected: The expected content type\n\n    Raises:\n        ContentTypeError: Raised if the actual doesn't match the expected.\n    \"\"\"\n    if (\n        actual != expected\n        and actual not in IGNORED_CONTENT_TYPES\n        and (actual, expected) not in ALLOWABLE_PAIRS\n        and (expected, actual) not in ALLOWABLE_PAIRS\n    ):\n        raise ContentTypeError(actual=actual, expected=expected)", "def content_type(actual: str, expected: str) -> None:\n    \"\"\"Validates that the actual content type matches the expected.\n\n    This is more complicated than a simple string comparison, because we want to\n    allow TIFF when COG is expected, etc.\n\n    Args:\n        actual: The actual content type\n        expected: The expected content type\n\n    Raises:\n        ContentTypeError: Raised if the actual doesn't match the expected.\n    \"\"\"\n    if (\n        actual != expected\n        and actual not in IGNORED_CONTENT_TYPES\n        and (actual, expected) not in ALLOWABLE_PAIRS\n        and (expected, actual) not in ALLOWABLE_PAIRS\n    ):\n        raise ContentTypeError(actual=actual, expected=expected)", ""]}
{"filename": "src/stac_asset/strategy.py", "chunked_list": ["from enum import Enum, auto\n\n\nclass FileNameStrategy(Enum):\n    \"\"\"Strategy to use for naming files.\"\"\"\n\n    FILE_NAME = auto()\n    \"\"\"Save the asset with the file name in its href.\n\n    Could potentially conflict with another asset with the same file name but\n    different path.\n    \"\"\"\n\n    KEY = auto()\n    \"\"\"Save the asset with its key as its file name.\"\"\"", "\n\nclass ErrorStrategy(Enum):\n    \"\"\"Strategy to use when encountering errors during download.\"\"\"\n\n    KEEP = auto()\n    \"\"\"Keep the asset on the item with its original href.\"\"\"\n\n    DELETE = auto()\n    \"\"\"Delete the asset from the item.\"\"\"", ""]}
{"filename": "src/stac_asset/messages.py", "chunked_list": ["from dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom yarl import URL\n\n\n@dataclass\nclass Message:\n    \"\"\"A message about downloading.\"\"\"", "class Message:\n    \"\"\"A message about downloading.\"\"\"\n\n\n@dataclass\nclass StartAssetDownload(Message):\n    \"\"\"Sent when an asset starts downloading.\"\"\"\n\n    key: str\n    \"\"\"The asset key.\"\"\"\n\n    item_id: Optional[str]\n    \"\"\"The item id.\"\"\"\n\n    href: str\n    \"\"\"The asset href.\"\"\"\n\n    path: Path\n    \"\"\"The local path that the asset is being downloaded to.\"\"\"", "\n\n@dataclass\nclass ErrorAssetDownload(Message):\n    \"\"\"Sent when an asset starts downloading.\"\"\"\n\n    key: str\n    \"\"\"The asset key.\"\"\"\n\n    href: str\n    \"\"\"The asset href.\"\"\"\n\n    path: Path\n    \"\"\"The local path that the asset is being downloaded to.\"\"\"", "\n\n@dataclass\nclass FinishAssetDownload(Message):\n    \"\"\"Sent when an asset finishes downloading.\"\"\"\n\n    key: str\n    \"\"\"The asset key.\"\"\"\n\n    href: str\n    \"\"\"The asset href.\"\"\"\n\n    path: Path\n    \"\"\"The local path that the asset is being downloaded to.\"\"\"", "\n\n@dataclass\nclass WriteChunk(Message):\n    \"\"\"Sent when a chunk is written to disk.\"\"\"\n\n    href: str\n    \"\"\"The asset href.\"\"\"\n\n    path: Path\n    \"\"\"The local path that the asset is being downloaded to.\"\"\"\n\n    size: int\n    \"\"\"The number of bytes written.\"\"\"", "\n\n@dataclass\nclass OpenUrl(Message):\n    \"\"\"Sent when a url is first opened.\"\"\"\n\n    url: URL\n    \"\"\"The URL\"\"\"\n\n    size: Optional[int]\n    \"\"\"The file size.\"\"\"", ""]}
