{"filename": "us_lat/cluster_latency.py", "chunked_list": ["\nfrom pathlib import Path\nimport paramiko\nimport sys\n\nclass bcolors:\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'", "\nif (len(sys.argv) != 4) :\n    print(bcolors.WARNING + 'Usage:')\n    print('python3 cluster_latency.py compute_node_num epoch_start epoch_num' + bcolors.ENDC)\n    exit(0)\n\nnode_num = int(sys.argv[1])\nepoch_start = int(sys.argv[2])\nepoch_num = int(sys.argv[3])\n", "epoch_num = int(sys.argv[3])\n\n\n# epoch_start = 1\n# epoch_num = 10\ncluster_ips = [\n  '10.10.1.1',\n  '10.10.1.2',\n  '10.10.1.3',\n  '10.10.1.4',", "  '10.10.1.3',\n  '10.10.1.4',\n  '10.10.1.5',\n  '10.10.1.6',\n  '10.10.1.7',\n  '10.10.1.8',\n  '10.10.1.9',\n  '10.10.1.10',\n  '10.10.1.11',\n  '10.10.1.12',", "  '10.10.1.11',\n  '10.10.1.12',\n  '10.10.1.13',\n  '10.10.1.14',\n  '10.10.1.15',\n  '10.10.1.16',\n][:node_num]\n\nlat_cnt = dict()\nlat_dir = Path(__file__).resolve().parent", "lat_cnt = dict()\nlat_dir = Path(__file__).resolve().parent\nprint(f'latency_dir: {lat_dir}')\n\n\ndef get_sftp_client(hostname):\n  port = 22\n  client = paramiko.SSHClient()\n  client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n  client.connect(hostname, port, compress=True)\n  return client.open_sftp()", "\n\ndef load_remote_lat(sftp_client : paramiko.SFTPClient, file_path):\n  remote_file = sftp_client.open(file_path)\n  try:\n    for line in remote_file:\n      lat, cnt = line.strip().split('\\t', 1)\n      if int(cnt):\n        if lat not in lat_cnt:\n          lat_cnt[lat] = 0\n        lat_cnt[lat] += int(cnt)\n  finally:\n    remote_file.close()", "\n\ndef cal_lat(e_id):\n  print(f'### epoch-{e_id} ###')\n  all_lat = sum(lat_cnt.values())\n  th50 = all_lat / 2\n  th90 = all_lat * 9 / 10\n  th95 = all_lat * 95 / 100\n  th99 = all_lat * 99 / 100\n  th999 = all_lat * 999 / 1000\n  cum = 0\n  for lat, cnt in sorted(lat_cnt.items(), key=lambda s:float(s[0])):\n    cum += cnt\n    if cum >= th50:\n      print(f'p50 {lat}', end='\\t')\n      th50 = all_lat + 1\n    if cum >= th90:\n      print(f'p90 {lat}', end='\\t')\n      th90 = all_lat + 1\n    if cum >= th95:\n      print(f'p95 {lat}', end='\\t')\n      th95 = all_lat + 1\n    if cum >= th99:\n      print(f'p99 {lat}', end='\\t')\n      th99 = all_lat + 1\n    if cum >= th999:\n      print(f'p999 {lat}')\n      th999 = all_lat + 1", "\n\nif __name__ == '__main__':\n  sftp_clients = [get_sftp_client(hostname) for hostname in cluster_ips]\n  for e_id in range(epoch_start, epoch_start + epoch_num):\n    lat_cnt.clear()\n    for client in sftp_clients:\n      load_remote_lat(client, str(lat_dir / f'epoch_{e_id}.lat'))\n    cal_lat(e_id)\n", ""]}
{"filename": "exp/fig_12.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '12'\nsmall_fig_num = {'YCSB LOAD': 'a', 'YCSB A': 'b', 'YCSB B': 'c', 'YCSB C': 'd', 'YCSB D': 'e'}\n", "small_fig_num = {'YCSB LOAD': 'a', 'YCSB A': 'b', 'YCSB B': 'c', 'YCSB C': 'd', 'YCSB D': 'e'}\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']", "master_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods            = fig_params['methods']\nworkload_names     = fig_params['workload_names']\ntarget_epochs      = fig_params['target_epoch']\nCN_and_client_nums = fig_params['client_num']  # as Sherman/ART saturates the network more easily than SMART, we test them with fewer clients", "target_epochs      = fig_params['target_epoch']\nCN_and_client_nums = fig_params['client_num']  # as Sherman/ART saturates the network more easily than SMART, we test them with fewer clients\nMN_num             = fig_params['MN_num']\nkey_type           = fig_params['key_size']\nvalue_size         = fig_params['value_size']\ncache_size         = fig_params['cache_size']\nspan_size          = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    for workload, workload_name in workload_names.items():\n        plot_data = {\n            'methods': methods,\n            'X_data': {method: [] for method in methods},\n            'Y_data': {method: [] for method in methods}\n        }\n        for method in methods:\n            project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n            work_dir = f\"{project_dir}/build\"\n            env_cmd = f\"cd {work_dir}\"\n\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            cmake_option = cmake_options[method]\n            if workload != 'YCSB LOAD':\n                cmake_option = cmake_option.replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            cmd.all_execute(BUILD_PROJECT)\n\n            for CN_num, client_num_per_CN in CN_and_client_nums[method][workload]:\n                CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n                SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n                YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n                KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n                cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n                while True:\n                    try:\n                        cmd.one_execute(CLEAR_MEMC)\n                        cmd.all_execute(KILL_PROCESS, CN_num)\n                        logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                        _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epochs[workload])\n                        tpt, _, _, _ = tp.get_statistics(logs, target_epochs[workload])\n                        break\n                    except (FunctionTimedOut, Exception) as e:\n                        print_WARNING(f\"Error! Retry... {e}\")\n\n                print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n                plot_data['X_data'][method].append(tpt)\n                plot_data['Y_data'][method].append(p99_lat)\n        # save data\n        Path(output_path).mkdir(exist_ok=True)\n        with (Path(output_path) / f'fig_{fig_num}{small_fig_num[workload]}.json').open(mode='w') as f:\n            json.dump(plot_data, f, indent=2)", "\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    for workload, workload_name in workload_names.items():\n        plot_data = {\n            'methods': methods,\n            'X_data': {method: [] for method in methods},\n            'Y_data': {method: [] for method in methods}\n        }\n        for method in methods:\n            project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n            work_dir = f\"{project_dir}/build\"\n            env_cmd = f\"cd {work_dir}\"\n\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            cmake_option = cmake_options[method]\n            if workload != 'YCSB LOAD':\n                cmake_option = cmake_option.replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            cmd.all_execute(BUILD_PROJECT)\n\n            for CN_num, client_num_per_CN in CN_and_client_nums[method][workload]:\n                CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n                SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n                YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n                KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n                cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n                while True:\n                    try:\n                        cmd.one_execute(CLEAR_MEMC)\n                        cmd.all_execute(KILL_PROCESS, CN_num)\n                        logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                        _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epochs[workload])\n                        tpt, _, _, _ = tp.get_statistics(logs, target_epochs[workload])\n                        break\n                    except (FunctionTimedOut, Exception) as e:\n                        print_WARNING(f\"Error! Retry... {e}\")\n\n                print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n                plot_data['X_data'][method].append(tpt)\n                plot_data['Y_data'][method].append(p99_lat)\n        # save data\n        Path(output_path).mkdir(exist_ok=True)\n        with (Path(output_path) / f'fig_{fig_num}{small_fig_num[workload]}.json').open(mode='w') as f:\n            json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    for small_num in small_fig_num.values():\n        pg.generate(fig_num + small_num)", ""]}
{"filename": "exp/fig_18a.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '18a'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nzipfians, read_ratio      = fig_params['zipfian'], fig_params['read_ratio']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_size                = fig_params['cache_size']\nspan_size                 = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': methods,\n        'X_data': zipfians,\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n        cmd.all_execute(BUILD_PROJECT, CN_num)\n\n        for zipfian in zipfians:\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            ZIPFIAN_TEST = f\"{env_cmd} && ./zipfian_test {CN_num} {read_ratio} {client_num_per_CN} {zipfian} 2\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 zipfian_test\"\n\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(ZIPFIAN_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} zipfian={zipfian} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': methods,\n        'X_data': zipfians,\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n        cmd.all_execute(BUILD_PROJECT, CN_num)\n\n        for zipfian in zipfians:\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            ZIPFIAN_TEST = f\"{env_cmd} && ./zipfian_test {CN_num} {read_ratio} {client_num_per_CN} {zipfian} 2\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 zipfian_test\"\n\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(ZIPFIAN_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} zipfian={zipfian} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_18c.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '18c'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nworkload, workload_name   = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_sizes               = fig_params['value_size']\ncache_size                = fig_params['cache_size']\nspan_size                 = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    with (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n        fig_params = json.load(f)\n    CN_num, client_num_per_CN = fig_params['client_num']\n    key_type = fig_params['key_size']\n    value_sizes = fig_params['value_size']\n    cache_size = fig_params['cache_size']\n\n    plot_data = {\n        'methods': methods,\n        'X_data': value_sizes,\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for value_size in value_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} value_size={value_size} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    with (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n        fig_params = json.load(f)\n    CN_num, client_num_per_CN = fig_params['client_num']\n    key_type = fig_params['key_size']\n    value_sizes = fig_params['value_size']\n    cache_size = fig_params['cache_size']\n\n    plot_data = {\n        'methods': methods,\n        'X_data': value_sizes,\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for value_size in value_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} value_size={value_size} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_4a.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '4a'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethod                    = fig_params['methods']\nwrite_ratios              = fig_params['write_ratio']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_size                = fig_params['cache_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': ['Throughput', 'P99 Latency'],\n        'X_data': write_ratios,\n        'Y_data': {'Throughput': [], 'P99 Latency': []}\n    }\n    project_dir = f\"{home_dir}/SMART\"\n    work_dir = f\"{project_dir}/build\"\n    env_cmd = f\"cd {work_dir}\"\n\n    # change config\n    sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n    cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n    cmd.all_execute(BUILD_PROJECT, CN_num)\n\n    for write_ratio in write_ratios:\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {write_ratio}- {key_type} {CN_num} {client_num_per_CN}\"\n        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {write_ratio}-\"\n        KILL_PROCESS = f\"{env_cmd} && killall -9 zipfian_test\"\n\n        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n                tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] method={method} write_ratio={write_ratio} tpt={tpt} p99_lat={p99_lat}\")\n        plot_data['Y_data']['Throughput'].append(tpt)\n        plot_data['Y_data']['P99 Latency'].append(p99_lat)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "def main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': ['Throughput', 'P99 Latency'],\n        'X_data': write_ratios,\n        'Y_data': {'Throughput': [], 'P99 Latency': []}\n    }\n    project_dir = f\"{home_dir}/SMART\"\n    work_dir = f\"{project_dir}/build\"\n    env_cmd = f\"cd {work_dir}\"\n\n    # change config\n    sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n    cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n    cmd.all_execute(BUILD_PROJECT, CN_num)\n\n    for write_ratio in write_ratios:\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {write_ratio}- {key_type} {CN_num} {client_num_per_CN}\"\n        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {write_ratio}-\"\n        KILL_PROCESS = f\"{env_cmd} && killall -9 zipfian_test\"\n\n        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n                tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] method={method} write_ratio={write_ratio} tpt={tpt} p99_lat={p99_lat}\")\n        plot_data['Y_data']['Throughput'].append(tpt)\n        plot_data['Y_data']['P99 Latency'].append(p99_lat)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_3b.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '3b'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nworkload, workload_name   = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_types                 = fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_size                = fig_params['cache_size']\nspan_sizes                = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    def get_legend(method, span_size):\n        return method if span_size is None else f'{method} ({span_size}-span)'\n    def get_xlabel(key_type):\n        return 'int (8 byte)' if key_type == 'randint' else 'string (32 byte)'\n\n    plot_methods = [(method, None) for method in methods if method != 'Sherman'] + [(method, span_size) for method in methods if method == 'Sherman' for span_size in span_sizes]\n    plot_data = {\n        'methods': [get_legend(method, span_size) for method, span_size in plot_methods],\n        'bar_groups' : [get_xlabel(key_type) for key_type in ['randint', 'email']],\n        'Y_data' : {\n            get_legend(method, span_size): {}  # store tpt with int, string key, respectively\n            for method, span_size in plot_methods\n        }\n    }\n    for method, span_size in plot_methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for key_type in key_types:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n            if method == 'ART':\n                cmake_option = cmake_option.replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} span_size={span_size} tpt={tpt}\")\n            plot_data['Y_data'][get_legend(method, span_size)][get_xlabel(key_type)] = tpt\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    def get_legend(method, span_size):\n        return method if span_size is None else f'{method} ({span_size}-span)'\n    def get_xlabel(key_type):\n        return 'int (8 byte)' if key_type == 'randint' else 'string (32 byte)'\n\n    plot_methods = [(method, None) for method in methods if method != 'Sherman'] + [(method, span_size) for method in methods if method == 'Sherman' for span_size in span_sizes]\n    plot_data = {\n        'methods': [get_legend(method, span_size) for method, span_size in plot_methods],\n        'bar_groups' : [get_xlabel(key_type) for key_type in ['randint', 'email']],\n        'Y_data' : {\n            get_legend(method, span_size): {}  # store tpt with int, string key, respectively\n            for method, span_size in plot_methods\n        }\n    }\n    for method, span_size in plot_methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for key_type in key_types:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n            if method == 'ART':\n                cmake_option = cmake_option.replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} span_size={span_size} tpt={tpt}\")\n            plot_data['Y_data'][get_legend(method, span_size)][get_xlabel(key_type)] = tpt\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_3c.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '3c'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nworkload, workload_name   = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_sizes               = fig_params['cache_size']\nspan_size                 = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': methods,\n        'X_data': cache_sizes,\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for cache_size in cache_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n            if method == 'Sherman':\n                cmake_option = cmake_option.replace('-DENABLE_CACHE_EVICTION=off', '-DENABLE_CACHE_EVICTION=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} cache_size={cache_size} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': methods,\n        'X_data': cache_sizes,\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for cache_size in cache_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n            if method == 'Sherman':\n                cmake_option = cmake_option.replace('-DENABLE_CACHE_EVICTION=off', '-DENABLE_CACHE_EVICTION=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} cache_size={cache_size} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_14.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '14'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nworkload, workload_name   = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_sizes               = fig_params['value_size']\ncache_size                = fig_params['cache_size']\nspan_size                 = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    metrics = ['Throughput', 'P50 Latency', 'P99 Latency']\n    plot_data = {\n        'methods': methods,\n        'bar_groups': list(map(str, value_sizes)),\n        'metrics': metrics,\n        'Y_data': {\n            method: {\n                str(value_size): {}  # store tpt, p50, p99, respectively\n                for value_size in value_sizes\n            }\n            for method in methods\n        }\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for value_size in value_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    p50_lat, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] value_size={value_size} method={method} tpt={tpt} p50_lat={p50_lat} p99_lat={p99_lat}\")\n            plot_data['Y_data'][method][str(value_size)] = {metrics[0]: tpt, metrics[1]: p50_lat, metrics[2]: p99_lat}\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    metrics = ['Throughput', 'P50 Latency', 'P99 Latency']\n    plot_data = {\n        'methods': methods,\n        'bar_groups': list(map(str, value_sizes)),\n        'metrics': metrics,\n        'Y_data': {\n            method: {\n                str(value_size): {}  # store tpt, p50, p99, respectively\n                for value_size in value_sizes\n            }\n            for method in methods\n        }\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for value_size in value_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    p50_lat, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] value_size={value_size} method={method} tpt={tpt} p50_lat={p50_lat} p99_lat={p99_lat}\")\n            plot_data['Y_data'][method][str(value_size)] = {metrics[0]: tpt, metrics[1]: p50_lat, metrics[2]: p99_lat}\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_3a.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '3a'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                 = fig_params['methods']\nworkload, workload_name = fig_params['workload_names']\ntarget_epoch            = fig_params['target_epoch']\nclient_nums             = fig_params['client_num']\nMN_nums                 = fig_params['MN_num']", "client_nums             = fig_params['client_num']\nMN_nums                 = fig_params['MN_num']\nkey_type                = fig_params['key_size']\nvalue_size              = fig_params['value_size']\ncache_size              = fig_params['cache_size']\nspan_size               = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    def get_legend(method, MN_num):\n        return f'{method} ({MN_num}MN)'\n\n    plot_lines = [(method, MN_num) for method in methods for MN_num in MN_nums]\n    legends = [get_legend(method, MN_num) for method, MN_num in plot_lines]\n    plot_data = {\n        'methods': legends,\n        'X_data': [0] + [t[0] * t[1] for t in client_nums],\n        'Y_data': {legend: [0] for legend in legends}\n    }\n    for method, MN_num in plot_lines:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n        cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n        cmd.all_execute(BUILD_PROJECT)\n\n        for CN_num, client_num_per_CN in client_nums:\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} MN_num={MN_num} client_num={CN_num*client_num_per_CN} tpt={tpt}\")\n            plot_data['Y_data'][get_legend(method, MN_num)].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    def get_legend(method, MN_num):\n        return f'{method} ({MN_num}MN)'\n\n    plot_lines = [(method, MN_num) for method in methods for MN_num in MN_nums]\n    legends = [get_legend(method, MN_num) for method, MN_num in plot_lines]\n    plot_data = {\n        'methods': legends,\n        'X_data': [0] + [t[0] * t[1] for t in client_nums],\n        'Y_data': {legend: [0] for legend in legends}\n    }\n    for method, MN_num in plot_lines:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n        cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n        cmd.all_execute(BUILD_PROJECT)\n\n        for CN_num, client_num_per_CN in client_nums:\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} MN_num={MN_num} client_num={CN_num*client_num_per_CN} tpt={tpt}\")\n            plot_data['Y_data'][get_legend(method, MN_num)].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_18b.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '18b'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nworkload, workload_name   = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type, key_sizes       = 'randint', fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_size                = fig_params['cache_size']\nspan_size                 = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    with (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n        fig_params = json.load(f)\n    CN_num, client_num_per_CN = fig_params['client_num']\n    key_type, key_sizes = 'randint', fig_params['key_size']\n    value_size = fig_params['value_size']\n    cache_size = fig_params['cache_size']\n\n    plot_data = {\n        'methods': methods,\n        'X_data': key_sizes,\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for key_size in key_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', key_size, value_size, cache_size, MN_num, span_size)\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} key_size={key_size} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    with (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n        fig_params = json.load(f)\n    CN_num, client_num_per_CN = fig_params['client_num']\n    key_type, key_sizes = 'randint', fig_params['key_size']\n    value_size = fig_params['value_size']\n    cache_size = fig_params['cache_size']\n\n    plot_data = {\n        'methods': methods,\n        'X_data': key_sizes,\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for key_size in key_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', key_size, value_size, cache_size, MN_num, span_size)\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} key_size={key_size} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_17.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '17'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nworkload, workload_name   = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_sizes               = fig_params['cache_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    metrics = ['Throughput', 'Cache Hit Ratio']\n    plot_data = {\n        'methods': methods,\n        'bar_groups': list(map(str, cache_sizes)),\n        'metrics': metrics,\n        'Y_data': {\n            method: {\n                str(cache_size): {}  # store tpt, cache-hit rate, respectively\n                for cache_size in cache_sizes\n            }\n            for method in methods\n        }\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/SMART\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for cache_size in cache_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n            cmake_option = cmake_options[method].replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, cache_hit_rate, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} cache_size={cache_size} tpt={tpt} cache_hit_rate={cache_hit_rate}\")\n            plot_data['Y_data'][method][str(cache_size)] = {metrics[0]: tpt, metrics[1]: cache_hit_rate}\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "def main(cmd: CMDManager, tp: LogParser):\n    metrics = ['Throughput', 'Cache Hit Ratio']\n    plot_data = {\n        'methods': methods,\n        'bar_groups': list(map(str, cache_sizes)),\n        'metrics': metrics,\n        'Y_data': {\n            method: {\n                str(cache_size): {}  # store tpt, cache-hit rate, respectively\n                for cache_size in cache_sizes\n            }\n            for method in methods\n        }\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/SMART\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        for cache_size in cache_sizes:\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n            cmake_option = cmake_options[method].replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, cache_hit_rate, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} cache_size={cache_size} tpt={tpt} cache_hit_rate={cache_hit_rate}\")\n            plot_data['Y_data'][method][str(cache_size)] = {metrics[0]: tpt, metrics[1]: cache_hit_rate}\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_13.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '13'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                 = fig_params['methods']\nworkload, workload_name = fig_params['workload_names']\ntarget_epoch            = fig_params['target_epoch']\nclient_nums             = fig_params['client_num']\nMN_num                  = fig_params['MN_num']", "client_nums             = fig_params['client_num']\nMN_num                  = fig_params['MN_num']\nkey_type                = fig_params['key_size']\nvalue_size              = fig_params['value_size']\ncache_size              = fig_params['cache_size']\nspan_size               = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': methods,\n        'X_data': [0] + [t[0] * t[1] for t in client_nums],\n        'Y_data': {method: [0] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n        cmd.all_execute(BUILD_PROJECT)\n\n        for CN_num, client_num_per_CN in client_nums:\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': methods,\n        'X_data': [0] + [t[0] * t[1] for t in client_nums],\n        'Y_data': {method: [0] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\n        cmd.all_execute(BUILD_PROJECT)\n\n        for CN_num, client_num_per_CN in client_nums:\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt}\")\n            plot_data['Y_data'][method].append(tpt)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_4b.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '4b'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethod                    = fig_params['methods']\nworkload, workload_name   = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_size                = fig_params['cache_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    legends = ['Throughput', 'Invalid Ratio']\n    udpate_schemes = ['out-of-place', 'in-place']\n\n    plot_data = {\n        'methods': legends,\n        'bar_groups': udpate_schemes,\n        'Y_data': {\n            legend: {}  # store out-of-place, in-place, respectively\n            for legend in legends\n        }\n    }\n    project_dir = f\"{home_dir}/SMART\"\n    work_dir = f\"{project_dir}/build\"\n    env_cmd = f\"cd {work_dir}\"\n\n    for udpate_scheme in udpate_schemes:\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n        cmake_option = cmake_options[method]\n        if udpate_scheme == 'in-place':\n            cmake_option = cmake_option.replace('-DUPDATE_IN_PLACE_LEAF_NODE=off', '-DUPDATE_IN_PLACE_LEAF_NODE=on')\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name} 1\"  # 1 --> rm_write_conflict\n        KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n        cmd.all_execute(BUILD_PROJECT, CN_num)\n        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                tpt, _, _, leaf_invalid_rate = tp.get_statistics(logs, target_epoch)\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] method={method} udpate_scheme={udpate_scheme} tpt={tpt} cache_invalid_rate={leaf_invalid_rate}\")\n        plot_data['Y_data'][legends[0]][udpate_scheme] = tpt\n        plot_data['Y_data'][legends[1]][udpate_scheme] = leaf_invalid_rate\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "def main(cmd: CMDManager, tp: LogParser):\n    legends = ['Throughput', 'Invalid Ratio']\n    udpate_schemes = ['out-of-place', 'in-place']\n\n    plot_data = {\n        'methods': legends,\n        'bar_groups': udpate_schemes,\n        'Y_data': {\n            legend: {}  # store out-of-place, in-place, respectively\n            for legend in legends\n        }\n    }\n    project_dir = f\"{home_dir}/SMART\"\n    work_dir = f\"{project_dir}/build\"\n    env_cmd = f\"cd {work_dir}\"\n\n    for udpate_scheme in udpate_schemes:\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n        cmake_option = cmake_options[method]\n        if udpate_scheme == 'in-place':\n            cmake_option = cmake_option.replace('-DUPDATE_IN_PLACE_LEAF_NODE=off', '-DUPDATE_IN_PLACE_LEAF_NODE=on')\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name} 1\"  # 1 --> rm_write_conflict\n        KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n        cmd.all_execute(BUILD_PROJECT, CN_num)\n        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                tpt, _, _, leaf_invalid_rate = tp.get_statistics(logs, target_epoch)\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] method={method} udpate_scheme={udpate_scheme} tpt={tpt} cache_invalid_rate={leaf_invalid_rate}\")\n        plot_data['Y_data'][legends[0]][udpate_scheme] = tpt\n        plot_data['Y_data'][legends[1]][udpate_scheme] = leaf_invalid_rate\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_3d.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '3d'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                 = fig_params['methods']\nworkload, workload_name = fig_params['workload_names']\ntarget_epoch            = fig_params['target_epoch']\nCN_and_client_nums      = fig_params['client_num']\nMN_num                  = fig_params['MN_num']", "CN_and_client_nums      = fig_params['client_num']\nMN_num                  = fig_params['MN_num']\nkey_type                = fig_params['key_size']\nvalue_size              = fig_params['value_size']\ncache_size              = fig_params['cache_size']\nspan_size               = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': methods,\n        'X_data': {method: [] for method in methods},\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n        cmake_option = cmake_options[method].replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n        cmd.all_execute(BUILD_PROJECT)\n\n        for CN_num, client_num_per_CN in CN_and_client_nums[method]:\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n            plot_data['X_data'][method].append(tpt)\n            plot_data['Y_data'][method].append(p99_lat)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    plot_data = {\n        'methods': methods,\n        'X_data': {method: [] for method in methods},\n        'Y_data': {method: [] for method in methods}\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n        cmake_option = cmake_options[method].replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n        cmd.all_execute(BUILD_PROJECT)\n\n        for CN_num, client_num_per_CN in CN_and_client_nums[method]:\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n            plot_data['X_data'][method].append(tpt)\n            plot_data['Y_data'][method].append(p99_lat)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_4d.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import sed_MN_num\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '4d'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)", "# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nzipfian, read_ratio       = fig_params['zipfian'], fig_params['read_ratio']\nclient_num_per_CNs        = fig_params['client_num_per_CN']\nMN_num                    = fig_params['MN_num']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    CN_num = 1\n    plot_data = {\n        'methods': ['RDMA_WRITE', 'RDMA_CAS'],\n        'X_data': [1] + client_num_per_CNs,\n        'Y_data': {'RDMA_WRITE': [0], 'RDMA_CAS': [0]}\n    }\n    project_dir = f\"{home_dir}/SMART\"\n    work_dir = f\"{project_dir}/build\"\n    env_cmd = f\"cd {work_dir}\"\n\n    # change config\n    sed_cmd = sed_MN_num('./include/Common.h', MN_num)\n    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake .. && make clean && make -j\"\n\n    cmd.all_execute(BUILD_PROJECT, CN_num)\n\n    for client_num_per_CN in client_num_per_CNs:\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        REDUNDANT_TEST = f\"{env_cmd} && ./redundant_test {read_ratio} {client_num_per_CN} {zipfian}\"\n        KILL_PROCESS = f\"{env_cmd} && killall -9 redundant_test\"\n\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(REDUNDANT_TEST, CN_num)\n                _, redundant_write, redundant_cas = tp.get_redundant_statistics(list(logs.values())[0])  # CN_num = 1\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] RDMA_READ zipfian={zipfian} avg.redundant_write={redundant_write} avg.redundant_cas={redundant_cas}\")\n        plot_data['Y_data']['RDMA_WRITE'].append(redundant_write)\n        plot_data['Y_data']['RDMA_CAS'].append(redundant_cas)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    CN_num = 1\n    plot_data = {\n        'methods': ['RDMA_WRITE', 'RDMA_CAS'],\n        'X_data': [1] + client_num_per_CNs,\n        'Y_data': {'RDMA_WRITE': [0], 'RDMA_CAS': [0]}\n    }\n    project_dir = f\"{home_dir}/SMART\"\n    work_dir = f\"{project_dir}/build\"\n    env_cmd = f\"cd {work_dir}\"\n\n    # change config\n    sed_cmd = sed_MN_num('./include/Common.h', MN_num)\n    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake .. && make clean && make -j\"\n\n    cmd.all_execute(BUILD_PROJECT, CN_num)\n\n    for client_num_per_CN in client_num_per_CNs:\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        REDUNDANT_TEST = f\"{env_cmd} && ./redundant_test {read_ratio} {client_num_per_CN} {zipfian}\"\n        KILL_PROCESS = f\"{env_cmd} && killall -9 redundant_test\"\n\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(REDUNDANT_TEST, CN_num)\n                _, redundant_write, redundant_cas = tp.get_redundant_statistics(list(logs.values())[0])  # CN_num = 1\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] RDMA_READ zipfian={zipfian} avg.redundant_write={redundant_write} avg.redundant_cas={redundant_cas}\")\n        plot_data['Y_data']['RDMA_WRITE'].append(redundant_write)\n        plot_data['Y_data']['RDMA_CAS'].append(redundant_cas)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_15.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '15'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nworkload_names            = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_size                = fig_params['cache_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    metrics = ['Throughput', 'P50 Latency', 'P99 Latency']\n    plot_data = {\n        'methods': methods,\n        'bar_groups': list(workload_names.keys()),\n        'metrics': metrics,\n        'Y_data': {\n            method: {\n                workload: {}  # store tpt, p50, p99, respectively\n                for workload in workload_names.keys()\n            }\n            for method in methods\n        }\n    }\n    for workload, workload_name in workload_names.items():\n        project_dir = f\"{home_dir}/SMART\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\n        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\n        for method in methods:\n            cmake_option = cmake_options[method]\n            if workload != 'YCSB LOAD' and method in ['+Read Delegation', '+Write Combining']:\n                cmake_option = cmake_option.replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    p50_lat, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch, get_avg=True)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} workload={workload} tpt={tpt} p50_lat={p50_lat} p99_lat={p99_lat}\")\n            plot_data['Y_data'][method][workload] = {metrics[0]: tpt, metrics[1]: p50_lat, metrics[2]: p99_lat}\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "def main(cmd: CMDManager, tp: LogParser):\n    metrics = ['Throughput', 'P50 Latency', 'P99 Latency']\n    plot_data = {\n        'methods': methods,\n        'bar_groups': list(workload_names.keys()),\n        'metrics': metrics,\n        'Y_data': {\n            method: {\n                workload: {}  # store tpt, p50, p99, respectively\n                for workload in workload_names.keys()\n            }\n            for method in methods\n        }\n    }\n    for workload, workload_name in workload_names.items():\n        project_dir = f\"{home_dir}/SMART\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\n        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\n        for method in methods:\n            cmake_option = cmake_options[method]\n            if workload != 'YCSB LOAD' and method in ['+Read Delegation', '+Write Combining']:\n                cmake_option = cmake_option.replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n            cmd.all_execute(BUILD_PROJECT, CN_num)\n            while True:\n                try:\n                    cmd.one_execute(CLEAR_MEMC)\n                    cmd.all_execute(KILL_PROCESS, CN_num)\n                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                    p50_lat, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch, get_avg=True)\n                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n                    break\n                except (FunctionTimedOut, Exception) as e:\n                    print_WARNING(f\"Error! Retry... {e}\")\n\n            print_GOOD(f\"[FINISHED POINT] method={method} workload={workload} tpt={tpt} p50_lat={p50_lat} p99_lat={p99_lat}\")\n            plot_data['Y_data'][method][workload] = {metrics[0]: tpt, metrics[1]: p50_lat, metrics[2]: p99_lat}\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_16.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '16'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n", "cmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods                   = fig_params['methods']\nworkload, workload_name   = fig_params['workload_names']\ntarget_epoch              = fig_params['target_epoch']\nCN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']", "CN_num, client_num_per_CN = fig_params['client_num']\nMN_num                    = fig_params['MN_num']\nkey_type                  = fig_params['key_size']\nvalue_size                = fig_params['value_size']\ncache_size                = fig_params['cache_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    legends = ['Throughput', 'Lock-fail']\n    plot_data = {\n        'methods': legends,\n        'bar_groups': methods,\n        'Y_data': {\n            legend: {}  # store HOCL. E-HOCL, RDWC, respectively\n            for legend in legends\n        }\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/SMART\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n        cmake_option = cmake_options[method].replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n        KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n        cmd.all_execute(BUILD_PROJECT, CN_num)\n        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                tpt, _, avg_lock_fail_cnt, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] method={method} workload={workload} tpt={tpt} avg_lock_fail_cnt={avg_lock_fail_cnt}\")\n        plot_data['Y_data'][legends[0]][method] = tpt\n        plot_data['Y_data'][legends[1]][method] = avg_lock_fail_cnt\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "def main(cmd: CMDManager, tp: LogParser):\n    legends = ['Throughput', 'Lock-fail']\n    plot_data = {\n        'methods': legends,\n        'bar_groups': methods,\n        'Y_data': {\n            legend: {}  # store HOCL. E-HOCL, RDWC, respectively\n            for legend in legends\n        }\n    }\n    for method in methods:\n        project_dir = f\"{home_dir}/SMART\"\n        work_dir = f\"{project_dir}/build\"\n        env_cmd = f\"cd {work_dir}\"\n\n        # change config\n        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n        cmake_option = cmake_options[method].replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n        KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n        cmd.all_execute(BUILD_PROJECT, CN_num)\n        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                tpt, _, avg_lock_fail_cnt, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] method={method} workload={workload} tpt={tpt} avg_lock_fail_cnt={avg_lock_fail_cnt}\")\n        plot_data['Y_data'][legends[0]][method] = tpt\n        plot_data['Y_data'][legends[1]][method] = avg_lock_fail_cnt\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/fig_11.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import generate_sed_cmd\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '11'\nsmall_fig_num = {'YCSB LOAD': 'a', 'YCSB A': 'b', 'YCSB B': 'c', 'YCSB C': 'd', 'YCSB D': 'e'}\n", "small_fig_num = {'YCSB LOAD': 'a', 'YCSB A': 'b', 'YCSB B': 'c', 'YCSB C': 'd', 'YCSB D': 'e'}\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\nycsb_dir      = f'{home_dir}/SMART/ycsb'\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\ncmake_options = params['cmake_options']", "master_ip     = params['master_ip']\ncmake_options = params['cmake_options']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nmethods            = fig_params['methods']\nworkload_names     = fig_params['workload_names']\ntarget_epochs      = fig_params['target_epoch']\nCN_and_client_nums = fig_params['client_num']  # as Sherman/ART saturates the network more easily than SMART, we test them with fewer clients", "target_epochs      = fig_params['target_epoch']\nCN_and_client_nums = fig_params['client_num']  # as Sherman/ART saturates the network more easily than SMART, we test them with fewer clients\nMN_num             = fig_params['MN_num']\nkey_type           = fig_params['key_size']\nvalue_size         = fig_params['value_size']\ncache_size         = fig_params['cache_size']\nspan_size          = fig_params['span_size']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    for workload, workload_name in workload_names.items():\n        plot_data = {\n            'methods': methods,\n            'X_data': {method: [] for method in methods},\n            'Y_data': {method: [] for method in methods}\n        }\n        for method in methods:\n            project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n            work_dir = f\"{project_dir}/build\"\n            env_cmd = f\"cd {work_dir}\"\n\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            cmake_option = cmake_options[method]\n            if workload != 'YCSB LOAD':\n                cmake_option = cmake_option.replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            cmd.all_execute(BUILD_PROJECT)\n\n            for CN_num, client_num_per_CN in CN_and_client_nums[method][workload]:\n                CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n                SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n                YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n                KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n                cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n                while True:\n                    try:\n                        cmd.one_execute(CLEAR_MEMC)\n                        cmd.all_execute(KILL_PROCESS, CN_num)\n                        logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                        _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epochs[workload])\n                        tpt, _, _, _ = tp.get_statistics(logs, target_epochs[workload])\n                        break\n                    except (FunctionTimedOut, Exception) as e:\n                        print_WARNING(f\"Error! Retry... {e}\")\n\n                print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n                plot_data['X_data'][method].append(tpt)\n                plot_data['Y_data'][method].append(p99_lat)\n        # save data\n        Path(output_path).mkdir(exist_ok=True)\n        with (Path(output_path) / f'fig_{fig_num}{small_fig_num[workload]}.json').open(mode='w') as f:\n            json.dump(plot_data, f, indent=2)", "\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    for workload, workload_name in workload_names.items():\n        plot_data = {\n            'methods': methods,\n            'X_data': {method: [] for method in methods},\n            'Y_data': {method: [] for method in methods}\n        }\n        for method in methods:\n            project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n            work_dir = f\"{project_dir}/build\"\n            env_cmd = f\"cd {work_dir}\"\n\n            # change config\n            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n            cmake_option = cmake_options[method]\n            if workload != 'YCSB LOAD':\n                cmake_option = cmake_option.replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\n            cmd.all_execute(BUILD_PROJECT)\n\n            for CN_num, client_num_per_CN in CN_and_client_nums[method][workload]:\n                CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n                SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n                YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n                KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\n                cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n                while True:\n                    try:\n                        cmd.one_execute(CLEAR_MEMC)\n                        cmd.all_execute(KILL_PROCESS, CN_num)\n                        logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n                        _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epochs[workload])\n                        tpt, _, _, _ = tp.get_statistics(logs, target_epochs[workload])\n                        break\n                    except (FunctionTimedOut, Exception) as e:\n                        print_WARNING(f\"Error! Retry... {e}\")\n\n                print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n                plot_data['X_data'][method].append(tpt)\n                plot_data['Y_data'][method].append(p99_lat)\n        # save data\n        Path(output_path).mkdir(exist_ok=True)\n        with (Path(output_path) / f'fig_{fig_num}{small_fig_num[workload]}.json').open(mode='w') as f:\n            json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    for small_num in small_fig_num.values():\n        pg.generate(fig_num + small_num)", ""]}
{"filename": "exp/fig_4c.py", "chunked_list": ["from func_timeout import FunctionTimedOut\nfrom pathlib import Path\nimport json\n\nfrom utils.cmd_manager import CMDManager\nfrom utils.log_parser import LogParser\nfrom utils.sed_generator import sed_MN_num\nfrom utils.color_printer import print_GOOD, print_WARNING\nfrom utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator", "from utils.func_timer import print_func_time\nfrom utils.pic_generator import PicGenerator\n\n\ninput_path = './params'\nstyle_path = \"./styles\"\noutput_path = './results'\nfig_num = '4c'\n\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)", "\n# common params\nwith (Path(input_path) / f'common.json').open(mode='r') as f:\n    params = json.load(f)\nhome_dir      = params['home_dir']\ncluster_ips   = params['cluster_ips']\nmaster_ip     = params['master_ip']\n\n# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)", "# fig params\nwith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n    fig_params = json.load(f)\nzipfian, read_ratio       = fig_params['zipfian'], fig_params['read_ratio']\nclient_num_per_CNs        = fig_params['client_num_per_CN']\nMN_num                    = fig_params['MN_num']\n\n\n@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    CN_num = 1\n    plot_data = {\n        'methods': ['RDMA_READ'],\n        'X_data': [1] + client_num_per_CNs,\n        'Y_data': {'RDMA_READ': [0]}  # avg.redundant READ\n    }\n    project_dir = f\"{home_dir}/SMART\"\n    work_dir = f\"{project_dir}/build\"\n    env_cmd = f\"cd {work_dir}\"\n\n    # change config\n    sed_cmd = sed_MN_num('./include/Common.h', MN_num)\n    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake .. && make clean && make -j\"\n\n    cmd.all_execute(BUILD_PROJECT, CN_num)\n\n    for client_num_per_CN in client_num_per_CNs:\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        REDUNDANT_TEST = f\"{env_cmd} && ./redundant_test {read_ratio} {client_num_per_CN} {zipfian}\"\n        KILL_PROCESS = f\"{env_cmd} && killall -9 redundant_test\"\n\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(REDUNDANT_TEST, CN_num)\n                redundant_read, _, _ = tp.get_redundant_statistics(list(logs.values())[0])  # CN_num = 1\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] RDMA_READ zipfian={zipfian} avg.redundant_read={redundant_read}\")\n        plot_data['Y_data']['RDMA_READ'].append(redundant_read)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "@print_func_time\ndef main(cmd: CMDManager, tp: LogParser):\n    CN_num = 1\n    plot_data = {\n        'methods': ['RDMA_READ'],\n        'X_data': [1] + client_num_per_CNs,\n        'Y_data': {'RDMA_READ': [0]}  # avg.redundant READ\n    }\n    project_dir = f\"{home_dir}/SMART\"\n    work_dir = f\"{project_dir}/build\"\n    env_cmd = f\"cd {work_dir}\"\n\n    # change config\n    sed_cmd = sed_MN_num('./include/Common.h', MN_num)\n    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake .. && make clean && make -j\"\n\n    cmd.all_execute(BUILD_PROJECT, CN_num)\n\n    for client_num_per_CN in client_num_per_CNs:\n        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n        REDUNDANT_TEST = f\"{env_cmd} && ./redundant_test {read_ratio} {client_num_per_CN} {zipfian}\"\n        KILL_PROCESS = f\"{env_cmd} && killall -9 redundant_test\"\n\n        while True:\n            try:\n                cmd.one_execute(CLEAR_MEMC)\n                cmd.all_execute(KILL_PROCESS, CN_num)\n                logs = cmd.all_long_execute(REDUNDANT_TEST, CN_num)\n                redundant_read, _, _ = tp.get_redundant_statistics(list(logs.values())[0])  # CN_num = 1\n                break\n            except (FunctionTimedOut, Exception) as e:\n                print_WARNING(f\"Error! Retry... {e}\")\n\n        print_GOOD(f\"[FINISHED POINT] RDMA_READ zipfian={zipfian} avg.redundant_read={redundant_read}\")\n        plot_data['Y_data']['RDMA_READ'].append(redundant_read)\n    # save data\n    Path(output_path).mkdir(exist_ok=True)\n    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n        json.dump(plot_data, f, indent=2)", "\n\nif __name__ == '__main__':\n    cmd = CMDManager(cluster_ips, master_ip)\n    tp = LogParser()\n    t = main(cmd, tp)\n    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\n    pg = PicGenerator(output_path, style_path)\n    pg.generate(fig_num)", ""]}
{"filename": "exp/utils/color_printer.py", "chunked_list": ["\n\nclass bcolors:\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'", "\ndef print_GOOD(msg):\n    print(bcolors.OKGREEN + msg + bcolors.ENDC)\n\ndef print_OK(msg):\n    print(bcolors.OKBLUE + msg + bcolors.ENDC)\n\ndef print_WARNING(msg):\n    print(bcolors.WARNING + msg + bcolors.ENDC)\n\ndef print_FAIL(msg):\n    print(bcolors.FAIL + msg + bcolors.ENDC)", "\ndef print_FAIL(msg):\n    print(bcolors.FAIL + msg + bcolors.ENDC)\n"]}
{"filename": "exp/utils/log_parser.py", "chunked_list": ["from typing import Optional\n\nfrom utils.color_printer import print_FAIL\n\n\nclass LogParser(object):\n\n    def __init__(self):\n        pass\n\n    def get_statistics(self, logs: dict, target_epoch: int, get_avg: bool=False):\n        for log in logs.values():\n            if get_avg:\n                tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate = self.__parse_log_avg(log, target_epoch)\n            else:\n                tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate = self.__parse_log(log, target_epoch)\n            if tpt is not None:\n                break\n        assert(tpt is not None)\n        return tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate\n\n    def __parse_log(self, log, target_epoch):\n        tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate = None, 0, 0, 0\n        flag = False\n        for line in log:\n            if f\"epoch {target_epoch} passed!\" in line:\n                flag = True\n\n            elif flag and \"cluster throughput\" in line:\n                tpt = float(line.strip().split(' ')[2])\n\n            elif flag and \"cache hit rate\" in line:\n                data = line.strip().split(' ')[3]\n                if data.replace('.', '').isdigit():\n                    cache_hit_rate = float(data)\n\n            elif flag and \"avg. lock/cas fail cnt\" in line:\n                data = line.strip().split(' ')[4]\n                if data.replace('.', '').isdigit():\n                    lock_fail_cnt = float(data)\n\n            elif flag and \"read invalid leaf rate\" in line:\n                data = line.strip().split(' ')[4]\n                if data.replace('.', '').isdigit():\n                    leaf_invalid_rate = float(data) * 100\n                break\n\n        return tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate\n\n    def __parse_log_avg(self, log, target_epoch):\n        tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate = [], [], [], []\n        flag = False\n        start_epoch = max(target_epoch // 2, target_epoch - 4)\n        cnt = start_epoch\n        for line in log:\n            if f\"epoch {start_epoch} passed!\" in line:\n                flag = True\n\n            elif flag and \"cluster throughput\" in line:\n                tpt.append(float(line.strip().split(' ')[2]))\n\n            elif flag and \"cache hit rate\" in line:\n                data = line.strip().split(' ')[3]\n                if data.replace('.', '').isdigit():\n                    cache_hit_rate.append(float(data))\n\n            elif flag and \"avg. lock/cas fail cnt\" in line:\n                data = line.strip().split(' ')[4]\n                if data.replace('.', '').isdigit():\n                    lock_fail_cnt.append(float(data))\n\n            elif flag and \"read invalid leaf rate\" in line:\n                data = line.strip().split(' ')[4]\n                if data.replace('.', '').isdigit():\n                    leaf_invalid_rate.append(float(data) * 100)\n                cnt += 1\n                if cnt == target_epoch:\n                    break\n\n        def get_avg(l):\n            return sum(l) / len(l) if l else 0\n\n        return get_avg(tpt) if tpt else None, get_avg(cache_hit_rate), get_avg(lock_fail_cnt), get_avg(leaf_invalid_rate)\n\n    def get_redundant_statistics(self, log):\n        redundant_read, redundant_write, redundant_cas = None, None, None\n        flag = False\n        for line in log:\n            if \"Calculation done!\" in line:\n                flag = True\n\n            elif flag and \"Avg. redundant rdma_read\" in line:\n                data = line.strip().split(' ')[3]\n                if data.replace('.', '').isdigit():\n                    redundant_read = float(data)\n\n            elif flag and \"Avg. redundant rdma_write\" in line:\n                data = line.strip().split(' ')[3]\n                if data.replace('.', '').isdigit():\n                    redundant_write = float(data)\n\n            elif flag and \"Avg. redundant rdma_cas\" in line:\n                data = line.strip().split(' ')[3]\n                if data.replace('.', '').isdigit():\n                    redundant_cas = float(data)\n                break\n\n        return redundant_read, redundant_write, redundant_cas", ""]}
{"filename": "exp/utils/sed_generator.py", "chunked_list": ["from typing import Optional\n\n\ndef sed_key_len(config_path: str, key_size: int):\n    old_key_code   = \"^constexpr uint32_t keyLen = .*\"\n    new_key_code   = f\"constexpr uint32_t keyLen = {key_size};\"\n    return f\"sed -i 's/{old_key_code}/{new_key_code}/g' {config_path}\"\n\n\ndef sed_val_len(config_path: str, value_size: int):\n    old_val_code   = \"^constexpr uint32_t simulatedValLen =.*\"\n    new_val_code   = f\"constexpr uint32_t simulatedValLen = {value_size};\"\n    return f\"sed -i 's/{old_val_code}/{new_val_code}/g' {config_path}\"", "\ndef sed_val_len(config_path: str, value_size: int):\n    old_val_code   = \"^constexpr uint32_t simulatedValLen =.*\"\n    new_val_code   = f\"constexpr uint32_t simulatedValLen = {value_size};\"\n    return f\"sed -i 's/{old_val_code}/{new_val_code}/g' {config_path}\"\n\n\ndef sed_cache_size(config_path: str, cache_size: int):\n    old_cache_code = \"^constexpr int kIndexCacheSize = .*\"\n    new_cache_node = f\"constexpr int kIndexCacheSize = {cache_size};\"\n    return f\"sed -i 's/{old_cache_code}/{new_cache_node}/g' {config_path}\"", "\n\ndef sed_MN_num(config_path: str, MN_num: int):\n    old_MN_code = \"^#define MEMORY_NODE_NUM .*\"\n    new_MN_node = f\"#define MEMORY_NODE_NUM {MN_num}\"\n    return f\"sed -i 's/{old_MN_code}/{new_MN_node}/g' {config_path}\"\n\n\ndef sed_span_size(config_path: str, span_size: int):  # only for Sherman\n    old_span_code = \"^constexpr int spanSize = .*\"\n    new_span_node = f\"constexpr int spanSize = {span_size};\"\n    return f\"sed -i 's/{old_span_code}/{new_span_node}/g' {config_path}\"", "def sed_span_size(config_path: str, span_size: int):  # only for Sherman\n    old_span_code = \"^constexpr int spanSize = .*\"\n    new_span_node = f\"constexpr int spanSize = {span_size};\"\n    return f\"sed -i 's/{old_span_code}/{new_span_node}/g' {config_path}\"\n\n\ndef generate_sed_cmd(config_path: str, is_Btree: bool, key_size: int, value_size: int, cache_size: int, MN_num: int, span_size: Optional[int] = None):\n    cmd = f\"{sed_key_len(config_path, key_size)} && {sed_val_len(config_path, value_size)} && {sed_cache_size(config_path, cache_size)} && {sed_MN_num(config_path, MN_num)}\"\n    if is_Btree:  # change span size for Sherman\n        assert(span_size is not None)\n        cmd += f\"&& {sed_span_size(config_path, span_size)}\"\n    return cmd", ""]}
{"filename": "exp/utils/func_timer.py", "chunked_list": ["import time\n\nfrom utils.color_printer import print_OK\n\n\ndef print_func_time(func):\n    def fun(*args, **kwargs):\n        t = time.perf_counter()\n        func(*args, **kwargs)\n        execute_time = time.perf_counter() - t\n        print_OK(f'Execution Time: {execute_time:.2f} s')\n        return execute_time\n    return fun", ""]}
{"filename": "exp/utils/pic_line_drawer.py", "chunked_list": ["import matplotlib.pyplot as plt\nfrom matplotlib.ticker import FormatStrFormatter\nfrom pathlib import Path\nimport numpy as np\n\n\nclass LineDrawer(object):\n\n    def __init__(self, pic_dir: str):\n        Path(pic_dir).mkdir(exist_ok=True)\n        self.pic_dir = pic_dir\n\n\n    def __load_default_style(self):\n        # line\n        self.lineStyleDict = {\n            'Sherman (2MN)'    : (0, (5, 3)),\n            'Sherman (1MN)'    : (0, ()),\n            'ART (2MN)'        : (0, (5, 3)),\n            'ART (1MN)'        : (0, ()),\n            'ART'            : (0, ()),\n            'Sherman'        : (0, ()),\n            'SMART'          : (0, ()),\n\n            'Throughput': (0, ()),\n            'P99 Latency': (0, ()),\n\n            'RDMA_READ' : (0, ()),\n            'RDMA_WRITE': (0, ()),\n            'RDMA_CAS'  : (0, ()),\n        }\n        self.lineColorDict = {\n            'Sherman (2MN)'    : '#4575B5',\n            'Sherman (1MN)'    : '#4575B5',\n            'ART (2MN)'        : '#D63026',\n            'ART (1MN)'        : '#D63026',\n            'ART'            : '#D63026',\n            'Sherman'        : '#4575B5',\n            'SMART'          : '#82B366',\n\n            'Throughput': '#4575B5',\n            'P99 Latency': '#D63026',\n\n            'RDMA_READ' : '#D63026',\n            'RDMA_WRITE': '#D63026',\n            'RDMA_CAS'  : '#82B366',\n        }\n        self.lineMarkerDict = {\n            'Sherman (2MN)'    : 'x',\n            'Sherman (1MN)'    : 'x',\n            'ART (2MN)'        : 'o',\n            'ART (1MN)'        : 'o',\n            'ART'            : 'o',\n            'Sherman'        : 'x',\n            'SMART'          : 's',\n\n            'Throughput': 'x',\n            'P99 Latency': '^',\n\n            'RDMA_READ' : 'x',\n            'RDMA_WRITE': 'x',\n            'RDMA_CAS'  : '^',\n        }\n        self.zorderDict = {\n            'Sherman (2MN)'    : 1100,\n            'Sherman (1MN)'    : 1100,\n            'ART (2MN)'        : 1200,\n            'ART (1MN)'        : 1200,\n            'ART'            : 1200,\n            'Sherman'        : 1150,\n            'SMART'          : 1250,\n\n            'Throughput': 1000,\n            'P99 Latency': 1000,\n\n            'RDMA_READ' : 1000,\n            'RDMA_WRITE': 1000,\n            'RDMA_CAS'  : 1100,\n        }\n        # size\n        self.figsize=(4, 2.5)\n        self.font_size = 15\n        self.legend_size = 15\n        self.tick_size = 14\n        self.linewidth = 0.8\n        self.markersize = 6\n        # grid\n        self.grid_type = {'axis': 'y', 'lw': 0.3}\n        self.y_major_num = self.x_major_num = 0\n        self.grid_minor = False\n        # edge\n        self.hide_half_edge = False\n        self.hide_ylabel = False\n        self.clip_on = True\n        # legend\n        self.legend_location = ''\n        self.legend_anchor = ()\n        self.legendL_anchor = self.legendR_anchor = ()\n        self.legend_ncol = 1\n        # tick\n        self.x_ticklabel = False\n        self.y_lim = self.x_lim = ()\n        self.ylim = self.xlim = ()\n        self.yL_lim = self.yR_lim = ()\n        self.x_tick = self.y_tick = []\n        self.yL_tick = self.yR_tick = []\n        self.yscale = ''\n        self.yfloat = False\n        # label\n        self.x_label = ''\n        self.y_label = ''\n        self.yL_label = ''\n        self.yR_label = ''\n        # func\n        self.aux_plt_func = None\n        self.annotation_func = None\n\n\n    def plot_with_one_ax(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}):\n        self.__load_default_style()\n        # load custom style\n        for k, v in custom_style.items():\n            setattr(self, k, v)\n\n        fig, ax = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n        if self.hide_half_edge:\n            ax.spines['right'].set_visible(False)\n            ax.spines['top'].set_visible(False)\n        legend_handles = []\n        legend_labels  = []\n        if not method_legend:\n            method_legend = {method: method for method in data['methods']}\n\n        X_data = data['X_data']\n        Y_data = data['Y_data']\n        for method in data['methods']:\n            l, = ax.plot(X_data[method] if isinstance(X_data, dict) else X_data,\n                         Y_data[method],\n                         linestyle=self.lineStyleDict[method],\n                         color=self.lineColorDict[method],\n                         marker=self.lineMarkerDict[method],\n                         markerfacecolor='none',\n                         mew=self.linewidth,\n                         clip_on=self.clip_on,\n                         linewidth=self.linewidth,\n                         markersize=self.markersize + 1.5 if self.lineMarkerDict[method] == '+' else\n                                    self.markersize + 0.5 if self.lineMarkerDict[method] == 'x' else self.markersize,\n                         zorder=self.zorderDict[method])\n            if method in method_legend:\n                legend_handles.append(l)\n                legend_labels.append(method_legend[method])\n        ax.set_xlabel(self.x_label, fontsize=self.font_size)\n        if not self.hide_ylabel:\n            ax.set_ylabel(self.y_label, fontsize=self.font_size)\n        if self.yscale:\n            ax.set_yscale(self.yscale)\n        if self.yfloat:\n            ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n        if self.ylim:\n            ytick       = list(np.linspace(self.ylim[0], self.ylim[1], self.y_major_num))\n            ytick_minor = list(np.linspace(self.ylim[0], self.ylim[1], 0 if self.grid_minor is False else self.y_major_num * 2 - 1))\n            ax.set_yticks(ytick)\n            ax.set_yticks(ytick_minor, minor=True)\n        if self.xlim:\n            xtick       = list(np.linspace(self.xlim[0], self.xlim[1], self.x_major_num))\n            xtick_minor = list(np.linspace(self.xlim[0], self.xlim[1], 0 if self.grid_minor is False else self.x_major_num * 2 - 1))\n            ax.set_xticks(xtick)\n            ax.set_xticks(xtick_minor, minor=True)\n        if self.y_tick:\n            ax.set_yticks(self.y_tick)\n        if self.x_tick:\n            ax.set_xticks(self.x_tick)\n            if self.x_ticklabel:\n                ax.set_xticklabels(self.x_ticklabel, fontsize=self.tick_size)\n        if self.y_lim:  # x, y limitation, use when xlim/ylim is not enough\n            ax.set_ylim(*self.y_lim)\n        if self.x_lim:\n            ax.set_xlim(*self.x_lim)\n        ax.tick_params(labelsize=self.tick_size)\n        # ax.set_xscale('log')\n        if self.annotation_func:\n            self.annotation_func(ax)\n        ax.grid(color='#dbdbdb', **self.grid_type, which='both' if self.grid_minor else 'major', zorder=0)\n        if self.legend_location or self.legend_anchor:\n            if self.legend_anchor:\n                ax.legend(legend_handles, legend_labels, fontsize=self.legend_size, bbox_to_anchor=self.legend_anchor, frameon=False, ncol=self.legend_ncol)\n            else:\n                ax.legend(legend_handles, legend_labels, fontsize=self.legend_size, loc=self.legend_location, frameon=False, ncol=self.legend_ncol) # labelspacing=0.1\n        if self.aux_plt_func:\n            self.aux_plt_func(ax)\n        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n        plt.close()\n\n\n    def plot_with_two_ax(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}, method_ax: dict = {}):\n        self.__load_default_style()\n        # load custom style\n        for k, v in custom_style.items():\n            setattr(self, k, v)\n\n        fig, ax_L = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n        ax_R = ax_L.twinx()\n        # legend_list = []\n        if not method_legend:\n            method_legend = {method: method for method in data['methods']}\n        if not method_ax:\n            method_ax = dict(zip(data['methods'], ['left', 'right']))\n\n        X_data = data['X_data']\n        Y_data = data['Y_data']\n        for method in data['methods']:\n            ax = ax_L if method_ax[method] == 'left' else ax_R\n            ax.plot(X_data[method] if isinstance(X_data, dict) else X_data,\n                    Y_data[method],\n                    label=method_legend[method],\n                    linestyle=self.lineStyleDict[method],\n                    color=self.lineColorDict[method],\n                    marker=self.lineMarkerDict[method],\n                    markerfacecolor='none',\n                    clip_on=False,\n                    linewidth=self.linewidth,\n                    markersize=self.markersize + 1.5 if self.lineMarkerDict[method] == '+' else\n                               self.markersize + 0.5 if self.lineMarkerDict[method] == 'x' else self.markersize)\n            # if method in method_legend:\n            #     legend_list.append(method_legend[method])\n        ax_L.set_xlabel(self.x_label, fontsize=self.font_size)\n        ax_L.set_ylabel(self.yL_label, fontsize=self.font_size)\n        ax_R.set_ylabel(self.yR_label, fontsize=self.font_size)\n        if self.yL_tick:\n            ax_L.set_yticks(self.yL_tick)\n            ax_L.set_yticklabels(self.yL_tick, fontsize=self.tick_size)\n        if self.yR_tick:\n            ax_R.set_yticks(self.yR_tick)\n            ax_R.set_yticklabels(self.yR_tick, fontsize=self.tick_size)\n        if self.yfloat:\n            ax_L.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n        if self.x_tick:\n            ax_L.set_xticks(self.x_tick)\n            ax_L.set_xticklabels(self.x_tick, fontsize=self.tick_size)\n        if self.yL_lim:\n            ax_L.set_ylim(*self.yL_lim)\n        if self.yR_lim:\n            ax_R.set_ylim(*self.yR_lim)\n        if self.x_lim:\n            ax.set_xlim(*self.x_lim)\n        ax_L.grid(color='#dbdbdb', **self.grid_type, which='both', zorder=0)\n        ax_L.legend(fontsize=self.legend_size, bbox_to_anchor=self.legendL_anchor, frameon=False, ncol=self.legend_ncol)\n        ax_R.legend(fontsize=self.legend_size, bbox_to_anchor=self.legendR_anchor, frameon=False, ncol=self.legend_ncol)\n        if self.aux_plt_func:\n            self.aux_plt_func(ax)\n        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n        plt.close()"]}
{"filename": "exp/utils/lat_parser.py", "chunked_list": ["from typing import List\nfrom pathlib import Path\nimport paramiko\n\n\nclass LatParser(object):\n\n    def __init__(self, clients: List[paramiko.SSHClient]):\n        self.__sftps = [cli.open_sftp() for cli in clients]\n        self.__lat_cnt = dict()\n\n\n    def load_remote_lats(self, lat_dir_path: str, CN_num: int, epoch_start: int = 1, epoch_num: int = 10):\n        p50_p99_lats = {}\n        for e_id in range(epoch_start, epoch_start + epoch_num):\n            self.__lat_cnt.clear()\n            for sftp in self.__sftps[:CN_num]:\n                remote_file = sftp.open(str(Path(lat_dir_path) / f'epoch_{e_id}.lat'))\n                try:\n                    for line in remote_file:\n                        lat, cnt = line.strip().split('\\t', 1)\n                        if int(cnt):\n                            if lat not in self.__lat_cnt:\n                                self.__lat_cnt[lat] = 0\n                            self.__lat_cnt[lat] += int(cnt)\n                finally:\n                    remote_file.close()\n            if self.__lat_cnt:\n                p50_p99_lats[e_id] = self.__cal_lat()\n                print(f'epoch_id={e_id} p50_lat={p50_p99_lats[e_id][0]} p99_lat={p50_p99_lats[e_id][1]}')\n        return p50_p99_lats\n\n\n    def __cal_lat(self):\n        all_lat = sum(self.__lat_cnt.values())\n        th50 = all_lat / 2\n        th99 = all_lat * 99 / 100\n        cum = 0\n        p50, p99 = None, None\n        for lat, cnt in sorted(self.__lat_cnt.items(), key=lambda s:float(s[0])):\n            cum += cnt\n            if cum >= th50:\n                p50 = float(lat)\n                th50 = all_lat + 1\n            if cum >= th99:\n                p99 = float(lat)\n                break\n        assert(p50 is not None and p99 is not None)\n        return p50, p99", "\n"]}
{"filename": "exp/utils/cmd_manager.py", "chunked_list": ["import paramiko\nimport time\nimport socket\nfrom func_timeout import func_set_timeout\n\nfrom utils.lat_parser import LatParser\nfrom utils.color_printer import print_OK, print_FAIL\n\n\nBUFFER_SIZE = 16 * 1024 * 1024", "\nBUFFER_SIZE = 16 * 1024 * 1024\nEND_PROMPT = '[END]'\nOOM_PROMPT = 'shared memory space run out'\nDEADLOCK_PROMPT = 'Deadlock'\n\n\nclass CMDManager(object):\n\n    def __init__(self, cluster_ips: list, master_ip: str):\n        super().__init__()\n        self.__cluster_ips = cluster_ips\n        self.__master_idx = cluster_ips.index(master_ip)\n        self.__CNs = [self.__get_ssh_CNs(hostname) for hostname in cluster_ips]\n        self.__shells = [cli.invoke_shell() for cli in self.__CNs]\n        for shell in self.__shells:\n            shell.setblocking(False)\n            self.__clear_shell(shell)\n        self.__lat_parser = LatParser(self.__CNs)\n\n    def __del__(self):\n        for cli in self.__CNs:\n            cli.close()\n\n    def __clear_shell(self, shell):\n        shell.send('\\n')\n        while True:\n            try:\n                shell.recv(BUFFER_SIZE)\n                break\n            except socket.timeout:\n                continue\n\n    def __match_prompt(self, content: str, end: str):\n        if end in content:\n            return True\n        return False\n\n    def __get_ssh_CNs(self, hostname: str):\n        port = 22\n        cli = paramiko.SSHClient()\n        cli.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        cli.connect(hostname, port, compress=True)\n        return cli\n\n    @func_set_timeout(60)\n    def all_execute(self, command: str, CN_num: int = -1):\n        if CN_num < 0:  # -1 means use all CNs\n            CN_num = len(self.__CNs)\n        outs = {}\n        errs = {}\n        stdouts = {}\n        stderrs = {}\n        print_OK(f'COMMAND=\"{command}\"')\n        print_OK(f'EXECUTE_IPs={self.__cluster_ips[:CN_num]}')\n        for i in range(CN_num):\n            cli_ip = self.__cluster_ips[i]\n            _, stdouts[cli_ip], stderrs[cli_ip] = self.__CNs[i].exec_command(command, get_pty=True)\n        for i in range(CN_num):\n            cli_ip = self.__cluster_ips[i]\n            outs[cli_ip] = stdouts[cli_ip].readlines()  # block here\n            errs[cli_ip] = stderrs[cli_ip].readlines()  # TODO: Retry\n            for line in outs[cli_ip]:\n                print(f'[CN {cli_ip} OUTPUT] {line.strip()}')\n            for line in errs[cli_ip]:\n                print_FAIL(f'[CN {cli_ip} ERROR] {line.strip()}')\n        return outs\n\n\n    def one_execute(self, command: str):\n        # one of the nodes (i.e., master node) will do some special task\n        cli = self.__CNs[self.__master_idx]\n        cli_ip = self.__cluster_ips[self.__master_idx]\n        print_OK(f'COMMAND=\"{command}\"')\n        print_OK(f'EXECUTE_IP={cli_ip}')\n        try:\n            _, stdout, stderr = cli.exec_command(command, get_pty=True)\n            out = stdout.readlines()  # block here\n            err = stderr.readlines()\n            for line in out:\n                print(f'[CN {cli_ip} OUTPUT] {line.strip()}')\n            for line in err:\n                print_FAIL(f'[CN {cli_ip} OUTPUT] {line.strip()}')\n        except:\n            print_FAIL(f'[CN {cli_ip}] FAILURE: {command}')\n        return out\n\n\n    @func_set_timeout(600)\n    def all_long_execute(self, command: str, CN_num: int = -1):\n        if CN_num < 0:  # -1 means use all CNs\n            CN_num = len(self.__CNs)\n        print_OK(f'COMMAND=\"{command}\"')\n        print_OK(f'EXECUTE_IPs={self.__cluster_ips[:CN_num]}')\n        if not command.endswith('\\n'):\n            command += '\\n'\n        for i in range(CN_num):\n            self.__shells[i].send(command)\n        for i in range(CN_num):\n            while not self.__shells[i].recv_ready():\n                time.sleep(0.2)\n\n        outs = {self.__cluster_ips[i]: '' for i in range(CN_num)}\n        for i in range(CN_num):\n            cli_ip = self.__cluster_ips[i]\n            while not self.__match_prompt(outs[cli_ip], END_PROMPT):\n                try:\n                    msg = self.__shells[i].recv(BUFFER_SIZE).decode()\n                    if msg:\n                        print(f'[CN {cli_ip} OUTPUT] {msg.strip()}')\n                        outs[cli_ip] += msg\n                    if self.__match_prompt(outs[cli_ip], OOM_PROMPT):\n                        raise Exception(OOM_PROMPT)\n                    if self.__match_prompt(outs[cli_ip], DEADLOCK_PROMPT):\n                        raise Exception(DEADLOCK_PROMPT)\n                except socket.timeout:\n                    continue\n\n        for ip in outs.keys():\n            outs[ip] = outs[ip].strip().split('\\n')\n        return outs\n\n    def get_cluster_lats(self, lat_dir_path: str, CN_num: int, target_epoch: int, get_avg: bool=False):\n        if get_avg:\n            start_epoch = max(target_epoch // 2, target_epoch - 4)\n            p50_p99_lats = self.__lat_parser.load_remote_lats(lat_dir_path, CN_num, start_epoch, target_epoch - start_epoch + 1)\n            assert(p50_p99_lats)\n            p50s, p99s = zip(*list(p50_p99_lats.values()))\n            p50 = sum(p50s) / len(p50s)\n            p99 = sum(p99s) / len(p99s)\n        else:\n            p50, p99 = self.__lat_parser.load_remote_lats(lat_dir_path, CN_num, target_epoch, 1)[target_epoch]  # to save time, we simply use the latency result in one epoch\n        assert(p50 is not None and p99 is not None)\n        return p50, p99", ""]}
{"filename": "exp/utils/pic_bar_drawer.py", "chunked_list": ["import matplotlib.pyplot as plt\nfrom matplotlib.ticker import FormatStrFormatter\nfrom pathlib import Path\nimport numpy as np\n\n\nclass BarDrawer(object):\n\n    def __init__(self, pic_dir: str):\n        Path(pic_dir).mkdir(exist_ok=True)\n        self.pic_dir = pic_dir\n\n    def __load_default_style(self):\n        # bar\n        self.barHatchDict = {\n            'Throughput'        : '/',\n            'Invalid Ratio'     : '\\\\',\n            'Delegated Ratio'   : '\\\\',\n            'Combined Ratio'    : '\\\\',\n            'P99 Latency'       : '\\\\',\n            'Lock-fail'         : 'x',\n\n            'SMART'            : '',\n            'ART'              : '//',\n            'Sherman'          : '\\\\\\\\',\n            'Sherman (8-span)' : 'x',\n            'Sherman (16-span)': '+',\n            'Sherman (32-span)': '\\\\\\\\',\n            'Sherman (64-span)': '',\n\n            \"+Lock-free Internal Node\"  : \"\\\\\\\\\",\n            '+Update-in-place Leaf Node': '||',\n            '+Rear Embedded Lock'       : '-',\n            '+Read Delegation'          : '++',\n            '+Write Combining'          : 'xx',\n\n            \"Baseline\"                           : \"//\",\n            \"+Homogeneous Adaptive Internal Node\": \"\\\\\\\\\",\n            '+ART-indexed Cache'                 : 'xx',\n        }\n        self.barColorDict = {\n            'Throughput'        : '#F8CECC',\n            'Invalid Ratio'     : '#DAE8FC',\n            'Delegated Ratio'   : '#DAE8FC',\n            'Combined Ratio'    : '#DAE8FC',\n            'P99 Latency'       : '#DAE8FC',\n            'Lock-fail'         : '#D5E8D4',\n\n            'SMART'            : '#D5E8D4',\n            'ART'              : '#F8CECC',\n            'Sherman'          : '#DAE8FC',\n            'Sherman (8-span)' : '#F5F5F5',\n            'Sherman (16-span)': '#F5F5F5',\n            'Sherman (32-span)': '#DAE8FC',\n            'Sherman (64-span)': '#F5F5F5',\n\n            \"+Lock-free Internal Node\"  : \"#DAE8FC\",\n            '+Update-in-place Leaf Node': '#DAE8FC',\n            '+Rear Embedded Lock'       : '#DAE8FC',\n            '+Read Delegation'          : '#D5E8D4',\n            '+Write Combining'          : '#D5E8D4',\n\n            \"Baseline\"                           : \"#F8CECC\",\n            \"+Homogeneous Adaptive Internal Node\": \"#DAE8FC\",\n            '+ART-indexed Cache'                 : '#D5E8D4',\n        }\n        # line\n        self.lineStyleDict = {\n            'P50 Latency'    : (0, ()),\n            'P99 Latency'    : (0, (3, 1)),\n            'Cache Hit Ratio': (0, ())\n        }\n        self.lineColorDict = {\n            'P50 Latency'    : '#333333',\n            'P99 Latency'    : '#333333',\n            'Cache Hit Ratio': '#333333',\n        }\n        self.lineMarkerDict = {\n            'P50 Latency'    : 'o',\n            'P99 Latency'    : '^',\n            'Cache Hit Ratio': 'o',\n        }\n        self.zorderDict = {\n            'P50 Latency'    : 1200,\n            'P99 Latency'    : 1250,\n            'Cache Hit Ratio': 1250,\n        }\n        # size\n        self.figsize=(4, 2.5)\n        self.font_size = 15\n        self.legend_size = 15\n        self.tick_size = 14\n        self.linewidth = 0.8\n        plt.rcParams['hatch.linewidth'] = 0.4\n        self.markersize = 6\n        # edge\n        self.line_clip_on=False\n        # tick\n        self.yRfloat = False\n        # bar size\n        self.group_width = 0.8\n        self.bar_offset = 0.5\n        self.bar_padding = 0\n        # legend\n        self.legend_location = ''\n        self.legend_anchor = ()\n        self.legendL_location = self.legendR_location = ''\n        self.legendL_anchor = self.legendR_anchor = ()\n        self.legend_ncol = 1\n        self.legendL_ncol = self.legendR_ncol = 2\n        self.legend_param = {}\n        self.legendL_param = self.legendR_param = {}\n        # tick\n        self.x_ticklabel = False\n        self.y_lim = self.x_lim = ()\n        self.yL_lim = self.yR_lim = ()\n        self.x_tick = self.y_tick = []\n        self.yL_tick = self.yR_tick = []\n        self.yscale = ''\n        self.yfloat = False\n        self.yR_scale = ''\n        # label\n        self.x_label = ''\n        self.y_label = ''\n        self.yL_label = ''\n        self.yR_label = ''\n        # func\n        self.aux_plt_func = None\n        self.annotation_func = None\n\n\n    def plot_with_one_ax(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}):\n        self.__load_default_style()\n        # load custom style\n        for k, v in custom_style.items():\n            setattr(self, k, v)\n\n        fig, ax = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n        methods = data['methods']\n        bar_groups = data['bar_groups']\n        if not method_legend:\n            method_legend = {method: method for method in data['methods']}\n\n        bar_width = self.group_width / len(methods)\n        for i, method in enumerate(methods):\n            ax.bar(np.arange(len(bar_groups)) + (i - self.bar_offset) * bar_width,\n                   [data['Y_data'][method][g] for g in bar_groups],\n                   width=bar_width,\n                   label=method_legend[method],\n                   color=self.barColorDict[method],\n                   edgecolor='black',\n                   linewidth=self.linewidth,\n                   fill=True,\n                   hatch=self.barHatchDict[method],\n                   zorder=100)\n        if self.x_label:\n            ax.set_xlabel(self.x_label, fontsize=self.font_size)\n        ax.set_xticks([i for i in range(len(bar_groups))])\n        ax.set_xticklabels(bar_groups, fontsize=self.tick_size)\n        ax.grid(axis='y', color='#dbdbdb', lw=0.3, zorder=0)\n\n        ax.set_ylabel(self.y_label, fontsize=self.font_size)\n        if self.y_tick:\n            ax.set_yticks(self.y_tick)\n            ax.set_yticklabels(self.y_tick, fontsize=self.tick_size)\n        if self.y_lim:\n            ax.set_ylim(*self.y_lim)\n        if self.legend_anchor:\n            ax.legend(fontsize=self.legend_size, bbox_to_anchor=self.legend_anchor, frameon=False)\n        else:\n            ax.legend(fontsize=self.legend_size, loc=self.legend_location, frameon=False)\n\n        if self.aux_plt_func:\n            self.aux_plt_func(ax)\n        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n        plt.close()\n\n\n    def plot_with_two_ax(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}, method_ax: dict = {}):\n        self.__load_default_style()\n        # load custom style\n        for k, v in custom_style.items():\n            setattr(self, k, v)\n\n        fig, ax_L = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n        methods = data['methods']\n        bar_groups = data['bar_groups']\n        if not method_legend:\n            method_legend = {method: method for method in data['methods']}\n        if not method_ax:\n            method_ax = dict(zip(data['methods'], ['left', 'right']))\n\n        ax_R = ax_L.twinx()\n        bar_width = self.group_width / len(methods)\n        for i, method in enumerate(methods):\n            ax = ax_L if method_ax[method] == 'left' else ax_R\n            ax.bar(np.arange(len(bar_groups)) + (i - self.bar_offset) * bar_width,\n                   [data['Y_data'][method][g] for g in bar_groups],\n                   width=bar_width,\n                   label=method_legend[method],\n                   color=self.barColorDict[method],\n                   edgecolor='black',\n                   linewidth=self.linewidth,\n                   fill=True,\n                   hatch=self.barHatchDict[method],\n                   zorder=100)\n        if self.x_label:\n            ax_L.set_xlabel(self.x_label, fontsize=self.font_size)\n        ax_L.set_xticks([i for i in range(len(bar_groups))])\n        ax_L.set_xticklabels(bar_groups, fontsize=self.tick_size)\n        ax_L.grid(axis='y', color='#dbdbdb', lw=0.3, zorder=0)\n\n        ax_L.set_ylabel(self.yL_label, fontsize=self.font_size)\n        ax_L.set_yticks(self.yL_tick)\n        ax_L.set_yticklabels(self.yL_tick, fontsize=self.font_size)\n        if self.legendL_anchor:\n            if self.legendL_param:\n                ax_L.legend(bbox_to_anchor=self.legendL_anchor, frameon=False, **self.legendL_param)\n            else:\n                ax_L.legend(fontsize=self.legend_size, bbox_to_anchor=self.legendL_anchor, frameon=False)\n        else:\n            ax_L.legend(fontsize=self.legend_size, loc=self.legendL_location, frameon=False)\n        ax_R.set_ylabel(self.yR_label, fontsize=self.font_size)\n        ax_R.set_yticks(self.yR_tick)\n        ax_R.set_yticklabels(self.yR_tick, fontsize=self.tick_size)\n        if self.legendR_anchor:\n            if self.legendR_param:\n                ax_R.legend(bbox_to_anchor=self.legendR_anchor, frameon=False, **self.legendR_param)\n            else:\n                ax_R.legend(fontsize=self.legend_size, bbox_to_anchor=self.legendR_anchor, frameon=False)\n        else:\n            ax_R.legend(fontsize=self.legend_size, loc=self.legendR_location, frameon=False)\n        if self.yRfloat:\n            ax_R.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n\n        if self.aux_plt_func:\n            self.aux_plt_func(ax)\n        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n        plt.close()\n\n\n    def plot_with_line(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}, method_ax: dict = {}):\n        self.__load_default_style()\n        # load custom style\n        for k, v in custom_style.items():\n            setattr(self, k, v)\n\n        fig, ax_L = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n        methods = data['methods']\n        bar_groups = data['bar_groups']\n        if not method_legend:\n            method_legend = {method: method for method in data['methods']}\n        if not method_ax:\n            method_ax = dict(zip(data['methods'], ['left', 'right']))\n\n        line_x_data = {g : [] for g in bar_groups}\n\n        # plot bar\n        bar_metric = data['metrics'][0]\n        totalWidth = self.group_width\n        barWidth = totalWidth / len(methods)\n        for i, method in enumerate(methods):\n            bar_x_data = np.arange(len(bar_groups)) + (i - self.bar_offset) * barWidth\n            for x, g in zip(bar_x_data, bar_groups):\n                line_x_data[g].append(x)\n            ax_L.bar(bar_x_data,\n                     [data['Y_data'][method][g][bar_metric] for g in bar_groups],\n                     width=barWidth*(1-self.bar_padding),\n                     label=method_legend[method],\n                     color=self.barColorDict[method],\n                     edgecolor='black',\n                     linewidth=self.linewidth,\n                     fill=True,\n                     hatch=self.barHatchDict[method],\n                     zorder=100)\n        if self.x_label:\n            ax_L.set_xlabel(self.x_label, fontsize=self.font_size)\n        ax_L.set_xticks([i for i in range(len(bar_groups))])\n        ax_L.set_xticklabels(bar_groups, fontsize=self.font_size)\n        ax_L.grid(axis='y', color='#dbdbdb', lw=0.3, zorder=0)\n\n        ax_L.set_ylabel(self.y_label, fontsize=self.font_size)\n        if self.y_tick:\n            ax_L.set_yticks(self.y_tick)\n        if self.y_lim:\n            ax_L.set_ylim(*self.y_lim)\n        if self.legend_anchor:\n            if self.legend_param:\n                ax_L.legend(bbox_to_anchor=self.legend_anchor, frameon=False, **self.legend_param)\n            else:\n                ax_L.legend(fontsize=self.legend_size, bbox_to_anchor=self.legend_anchor, frameon=False, ncol=self.legend_ncol)\n        else:\n            ax_L.legend(fontsize=self.legend_size, loc=self.legend_location, frameon=False, ncol=self.legend_ncol, columnspacing=0.8)\n        ax_L.tick_params(labelsize=self.tick_size)\n\n        # plot line\n        line_metrics = data['metrics'][1:]\n        lines_data = []\n        for g in bar_groups:\n            for m in line_metrics:\n                lines_data.append((g, m, [data['Y_data'][method][g][m] for method in methods]))\n\n        ax_R = ax_L.twinx()\n        legend_handles = {}\n        if len(methods) > 1:\n            for g, metric, line_data in lines_data:\n                l, = ax_R.plot(line_x_data[g],\n                               line_data,\n                               linestyle=self.lineStyleDict[metric],\n                               color=self.lineColorDict[metric],\n                               marker=self.lineMarkerDict[metric],\n                               markerfacecolor='white',\n                               mew=self.linewidth,\n                               clip_on=self.line_clip_on,\n                               linewidth=self.linewidth,\n                               markersize=self.markersize + 1.5 if self.lineMarkerDict[metric] == '+' else\n                                          self.markersize + 0.5 if self.lineMarkerDict[metric] in ['x', '^'] else self.markersize,\n                               zorder=self.zorderDict[metric])\n                legend_handles[metric] = l\n        else:\n            for metric, line_data in lines_data:\n                l, = ax_R.plot([a[0] for a in line_x_data.values()],\n                               line_data,\n                               linestyle=self.lineStyleDict[metric],\n                               color=self.lineColorDict[metric],\n                               marker=self.lineMarkerDict[metric],\n                               markerfacecolor='white',\n                               mew=self.linewidth,\n                               clip_on=self.line_clip_on,\n                               linewidth=self.linewidth,\n                               markersize=self.markersize + 1.5 if self.lineMarkerDict[metric] == '+' else\n                                          self.markersize + 0.5 if self.lineMarkerDict[metric] in ['x', '^'] else self.markersize,\n                               zorder=self.zorderDict[metric])\n                legend_handles[metric] = l\n        ax_R.set_ylabel(self.yR_label, fontsize=self.font_size)\n        if self.yR_tick:\n            ax_R.set_yticks(self.yR_tick)\n        if self.yR_lim:\n            ax_R.set_ylim(*self.yR_lim)\n        if self.yR_scale:\n            ax_R.set_yscale(self.yR_scale)\n        ax_R.tick_params(labelsize=self.tick_size)\n        if self.legendR_location:\n            if self.legendR_param:\n                ax_R.legend(legend_handles.values(), legend_handles.keys(), loc=self.legendR_location, frameon=False, **self.legendR_param)\n            else:\n                ax_R.legend(legend_handles.values(), legend_handles.keys(), fontsize=self.legend_size, loc=self.legendR_location, frameon=False, ncol=self.legendR_ncol)\n        else:\n            if self.legendR_param:\n                ax_R.legend(legend_handles.values(), legend_handles.keys(), bbox_to_anchor=self.legendR_anchor, frameon=False, **self.legendR_param)\n            else:\n                ax_R.legend(legend_handles.values(), legend_handles.keys(), fontsize=self.legend_size, bbox_to_anchor=self.legendR_anchor, frameon=False, ncol=self.legendR_ncol)\n\n        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n        plt.close()"]}
{"filename": "exp/utils/pic_generator.py", "chunked_list": ["from pathlib import Path\nimport json\n\nfrom utils.pic_line_drawer import LineDrawer\nfrom utils.pic_bar_drawer import BarDrawer\nfrom utils.color_printer import print_OK\n\n\nclass PicGenerator(object):\n\n    def __init__(self, data_path: str, style_path: str):\n        self.__data_path = data_path\n        self.__style_path = style_path\n        self.__ld = LineDrawer(data_path)\n        self.__bd = BarDrawer(data_path)\n        self.__figs_type = {\n            '3a' : 'line_one_ax', '3b' : 'bar_one_ax'   , '3c' : 'line_one_ax'  , '3d' : 'line_one_ax',\n            '4a' : 'line_two_ax', '4b' : 'bar_two_ax'   , '4c' : 'line_one_ax'  , '4d' : 'line_two_ax',\n            '11a': 'line_one_ax', '11b': 'line_one_ax'  , '11c': 'line_one_ax'  , '11d': 'line_one_ax', '11e': 'line_one_ax'  ,\n            '12a': 'line_one_ax', '12b': 'line_one_ax'  , '12c': 'line_one_ax'  , '12d': 'line_one_ax', '12e': 'line_one_ax'  ,\n            '13' : 'line_one_ax', '14' : 'bar_with_line', '15' : 'bar_with_line', '16' : 'bar_two_ax' , '17' : 'bar_with_line',\n            '18a': 'line_one_ax', '18b': 'line_one_ax'  , '18c': 'line_one_ax'\n        }\n        self.__axhlineColor = '#00007c'\n        self.__linewidth = 0.8\n        self.__font_size = 15\n\n\n    def __aux_plt(self, ax):\n        ax.axhline(y=45, ls=(0, (5, 3)), c=self.__axhlineColor, lw=self.__linewidth)\n        ax.text(200, 47, 'IOPS Upper Bound', fontsize=self.__font_size-1, color=self.__axhlineColor)\n        ax.axhline(y=7, ls=(0, (5, 3)), c=self.__axhlineColor, lw=self.__linewidth)\n        ax.text(120, 9, 'Bandwidth Bottleneck', fontsize=self.__font_size-1, color=self.__axhlineColor)\n\n\n    def __annotation(self, ax):\n        ax.annotate('', xy=(4, 14), xytext=(40, 14), arrowprops=dict(arrowstyle=\"<->\", color=self.__axhlineColor, ls=(0, (5, 3))), fontsize=self.__font_size-1)\n        ax.text(12.5, 16, '4M vs. 40M', fontsize=self.__font_size-1, color=self.__axhlineColor)\n\n\n    def generate(self, fig_num: str):\n        fig_name = f\"fig_{fig_num}.pdf\"\n        fig_type = self.__figs_type[fig_num]\n\n        # load data\n        with (Path(self.__data_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n            data = json.load(f)\n        # load style\n        with (Path(self.__style_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n            custom_style = json.load(f)\n        # load func\n        if fig_num == '3c':\n            custom_style['aux_plt_func'] = self.__aux_plt\n        if fig_num == '3d':\n            custom_style['aux_plt_func'] = self.__annotation\n\n        # draw\n        if fig_type == 'line_one_ax':\n            self.__ld.plot_with_one_ax(data, fig_name, custom_style=custom_style)\n        elif fig_type == 'line_two_ax':\n            self.__ld.plot_with_two_ax(data, fig_name, custom_style=custom_style)\n        elif fig_type == 'bar_one_ax':\n            self.__bd.plot_with_one_ax(data, fig_name, custom_style=custom_style)\n        elif fig_type == 'bar_two_ax':\n            self.__bd.plot_with_two_ax(data, fig_name, custom_style=custom_style)\n        elif fig_type == 'bar_with_line':\n            self.__bd.plot_with_line(data, fig_name, custom_style=custom_style)\n\n        print_OK(f\"Draw {fig_name} done!\")", "class PicGenerator(object):\n\n    def __init__(self, data_path: str, style_path: str):\n        self.__data_path = data_path\n        self.__style_path = style_path\n        self.__ld = LineDrawer(data_path)\n        self.__bd = BarDrawer(data_path)\n        self.__figs_type = {\n            '3a' : 'line_one_ax', '3b' : 'bar_one_ax'   , '3c' : 'line_one_ax'  , '3d' : 'line_one_ax',\n            '4a' : 'line_two_ax', '4b' : 'bar_two_ax'   , '4c' : 'line_one_ax'  , '4d' : 'line_two_ax',\n            '11a': 'line_one_ax', '11b': 'line_one_ax'  , '11c': 'line_one_ax'  , '11d': 'line_one_ax', '11e': 'line_one_ax'  ,\n            '12a': 'line_one_ax', '12b': 'line_one_ax'  , '12c': 'line_one_ax'  , '12d': 'line_one_ax', '12e': 'line_one_ax'  ,\n            '13' : 'line_one_ax', '14' : 'bar_with_line', '15' : 'bar_with_line', '16' : 'bar_two_ax' , '17' : 'bar_with_line',\n            '18a': 'line_one_ax', '18b': 'line_one_ax'  , '18c': 'line_one_ax'\n        }\n        self.__axhlineColor = '#00007c'\n        self.__linewidth = 0.8\n        self.__font_size = 15\n\n\n    def __aux_plt(self, ax):\n        ax.axhline(y=45, ls=(0, (5, 3)), c=self.__axhlineColor, lw=self.__linewidth)\n        ax.text(200, 47, 'IOPS Upper Bound', fontsize=self.__font_size-1, color=self.__axhlineColor)\n        ax.axhline(y=7, ls=(0, (5, 3)), c=self.__axhlineColor, lw=self.__linewidth)\n        ax.text(120, 9, 'Bandwidth Bottleneck', fontsize=self.__font_size-1, color=self.__axhlineColor)\n\n\n    def __annotation(self, ax):\n        ax.annotate('', xy=(4, 14), xytext=(40, 14), arrowprops=dict(arrowstyle=\"<->\", color=self.__axhlineColor, ls=(0, (5, 3))), fontsize=self.__font_size-1)\n        ax.text(12.5, 16, '4M vs. 40M', fontsize=self.__font_size-1, color=self.__axhlineColor)\n\n\n    def generate(self, fig_num: str):\n        fig_name = f\"fig_{fig_num}.pdf\"\n        fig_type = self.__figs_type[fig_num]\n\n        # load data\n        with (Path(self.__data_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n            data = json.load(f)\n        # load style\n        with (Path(self.__style_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n            custom_style = json.load(f)\n        # load func\n        if fig_num == '3c':\n            custom_style['aux_plt_func'] = self.__aux_plt\n        if fig_num == '3d':\n            custom_style['aux_plt_func'] = self.__annotation\n\n        # draw\n        if fig_type == 'line_one_ax':\n            self.__ld.plot_with_one_ax(data, fig_name, custom_style=custom_style)\n        elif fig_type == 'line_two_ax':\n            self.__ld.plot_with_two_ax(data, fig_name, custom_style=custom_style)\n        elif fig_type == 'bar_one_ax':\n            self.__bd.plot_with_one_ax(data, fig_name, custom_style=custom_style)\n        elif fig_type == 'bar_two_ax':\n            self.__bd.plot_with_two_ax(data, fig_name, custom_style=custom_style)\n        elif fig_type == 'bar_with_line':\n            self.__bd.plot_with_line(data, fig_name, custom_style=custom_style)\n\n        print_OK(f\"Draw {fig_name} done!\")", ""]}
{"filename": "ycsb/gen_workload.py", "chunked_list": ["import sys\nimport os\n\nclass bcolors:\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'", "\n#####################################################################################\n\ndef reverseHostName ( email ) :\n    name, sep, host = email.partition('@')\n    hostparts = host.strip().split('.')\n    r_host = '.'.join(reversed(hostparts))\n    # for part in hostparts :\n    #     r_host = part + '.' + r_host\n    return (r_host + sep + name).replace(\" \", \"\").strip()", "\n#####################################################################################\n\nif (len(sys.argv) != 4) :\n    print(bcolors.WARNING + 'Usage:')\n    print('python3 gen_workload.py workload_name key_type full_or_small' + bcolors.ENDC)\n    exit(0)\n\n# config_file = sys.argv[1]\n", "# config_file = sys.argv[1]\n\n# args = []\n# f_config = open (config_file, 'r')\n# for line in f_config :\n#     args.append(line[:-1])\n\nworkload = sys.argv[1]\nkey_type = sys.argv[2]\n", "key_type = sys.argv[2]\n\nycsb_dir = 'YCSB/'\nworkload_dir = f'{sys.argv[3]}_workload_spec/'\noutput_dir= 'workloads/'\n\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\n\nprint(bcolors.OKGREEN + 'workload = ' + workload)", "\nprint(bcolors.OKGREEN + 'workload = ' + workload)\nprint('key type = ' + key_type + bcolors.ENDC)\n\nemail_list = 'emails.txt'            # NOTE: To generate email-key workloads, an email list is needed\nemail_list_size = 125050709          # NOTE: change to the size of your email list (p.s. should be larger than twice of your YCSB LOAD size)\n\nout_ycsb_load = output_dir + 'ycsb_load_' + key_type + '_' + workload\nout_ycsb_txn = output_dir + 'ycsb_txn_' + key_type + '_' + workload\nout_load_ycsbkey = output_dir + 'load_' + 'ycsbkey' + '_' + workload", "out_ycsb_txn = output_dir + 'ycsb_txn_' + key_type + '_' + workload\nout_load_ycsbkey = output_dir + 'load_' + 'ycsbkey' + '_' + workload\nout_txn_ycsbkey = output_dir + 'txn_' + 'ycsbkey' + '_' + workload\nout_load = output_dir + 'load_' + key_type + '_' + workload\nout_txn = output_dir + 'txn_' + key_type + '_' + workload\n\ncmd_ycsb_load = ycsb_dir + 'bin/ycsb load basic -P ' + workload_dir + workload + ' -s > ' + out_ycsb_load\ncmd_ycsb_txn = ycsb_dir + 'bin/ycsb run basic -P ' + workload_dir + workload + ' -s > ' + out_ycsb_txn\n\nos.system(cmd_ycsb_load)", "\nos.system(cmd_ycsb_load)\nos.system(cmd_ycsb_txn)\n\n#####################################################################################\n\nf_load = open (out_ycsb_load, 'r')\nf_load_out = open (out_load_ycsbkey, 'w')\nfor line in f_load :\n    cols = line.split()\n    if len(cols) > 0 and cols[0] == \"INSERT\":\n        f_load_out.write (cols[0] + \" \" + cols[2][4:] + \"\\n\")", "for line in f_load :\n    cols = line.split()\n    if len(cols) > 0 and cols[0] == \"INSERT\":\n        f_load_out.write (cols[0] + \" \" + cols[2][4:] + \"\\n\")\nf_load.close()\nf_load_out.close()\n\nf_txn = open (out_ycsb_txn, 'r')\nf_txn_out = open (out_txn_ycsbkey, 'w')\nfor line in f_txn :\n    cols = line.split()\n    if (cols[0] == 'SCAN') or (cols[0] == 'INSERT') or (cols[0] == 'READ') or (cols[0] == 'UPDATE'):\n        startkey = cols[2][4:]\n        if cols[0] == 'SCAN' :\n            numkeys = cols[3]\n            f_txn_out.write (cols[0] + ' ' + startkey + ' ' + numkeys + '\\n')\n        else :\n            f_txn_out.write (cols[0] + ' ' + startkey + '\\n')", "f_txn_out = open (out_txn_ycsbkey, 'w')\nfor line in f_txn :\n    cols = line.split()\n    if (cols[0] == 'SCAN') or (cols[0] == 'INSERT') or (cols[0] == 'READ') or (cols[0] == 'UPDATE'):\n        startkey = cols[2][4:]\n        if cols[0] == 'SCAN' :\n            numkeys = cols[3]\n            f_txn_out.write (cols[0] + ' ' + startkey + ' ' + numkeys + '\\n')\n        else :\n            f_txn_out.write (cols[0] + ' ' + startkey + '\\n')", "f_txn.close()\nf_txn_out.close()\n\ncmd = 'rm -f ' + out_ycsb_load\nos.system(cmd)\ncmd = 'rm -f ' + out_ycsb_txn\nos.system(cmd)\n\n#####################################################################################\n\nif key_type == 'randint' :\n    f_load = open (out_load_ycsbkey, 'r')\n    f_load_out = open (out_load, 'w')\n    for line in f_load :\n        f_load_out.write (line)\n\n    f_txn = open (out_txn_ycsbkey, 'r')\n    f_txn_out = open (out_txn, 'w')\n    for line in f_txn :\n        f_txn_out.write (line)\n\nelif key_type == 'monoint' :\n    keymap = {}\n    f_load = open (out_load_ycsbkey, 'r')\n    f_load_out = open (out_load, 'w')\n    count = 0\n    for line in f_load :\n        cols = line.split()\n        keymap[int(cols[1])] = count\n        f_load_out.write (cols[0] + ' ' + str(count) + '\\n')\n        count += 1\n\n    f_txn = open (out_txn_ycsbkey, 'r')\n    f_txn_out = open (out_txn, 'w')\n    for line in f_txn :\n        cols = line.split()\n        if cols[0] == 'SCAN' :\n            f_txn_out.write (cols[0] + ' ' + str(keymap[int(cols[1])]) + ' ' + cols[2] + '\\n')\n        elif cols[0] == 'INSERT' :\n            keymap[int(cols[1])] = count\n            f_txn_out.write (cols[0] + ' ' + str(count) + '\\n')\n            count += 1\n        else :\n            f_txn_out.write (cols[0] + ' ' + str(keymap[int(cols[1])]) + '\\n')\n\nelif key_type == 'email' :\n    keymap = {}\n    f_email = open (email_list, 'r')\n    emails = f_email.readlines()\n\n    f_load = open (out_load_ycsbkey, 'r')\n    f_load_out = open (out_load, 'w')\n\n    sample_size = len(f_load.readlines())\n    gap = email_list_size // sample_size\n\n    if workload in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)]:\n        gap = 1\n    else:\n        assert(gap >= 2)\n\n    f_load.close()\n    f_load = open (out_load_ycsbkey, 'r')\n    count = 0\n    for line in f_load :\n        cols = line.split()\n        email = reverseHostName(emails[count * gap])\n        keymap[int(cols[1])] = email\n        f_load_out.write (cols[0] + ' ' + email + '\\n')\n        count += 1\n\n    if workload not in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)]:\n        count = 0\n    f_txn = open (out_txn_ycsbkey, 'r')\n    f_txn_out = open (out_txn, 'w')\n    for line in f_txn :\n        cols = line.split()\n        if cols[0] == 'SCAN' :\n            f_txn_out.write (cols[0] + ' ' + keymap[int(cols[1])] + ' ' + cols[2] + '\\n')\n        elif cols[0] == 'INSERT' :\n            email = reverseHostName(emails[count if workload in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)] else (count * gap + 1)])\n            keymap[int(cols[1])] = email\n            f_txn_out.write (cols[0] + ' ' + email + '\\n')\n            count += 1\n        else :\n            f_txn_out.write (cols[0] + ' ' + keymap[int(cols[1])] + '\\n')", "#####################################################################################\n\nif key_type == 'randint' :\n    f_load = open (out_load_ycsbkey, 'r')\n    f_load_out = open (out_load, 'w')\n    for line in f_load :\n        f_load_out.write (line)\n\n    f_txn = open (out_txn_ycsbkey, 'r')\n    f_txn_out = open (out_txn, 'w')\n    for line in f_txn :\n        f_txn_out.write (line)\n\nelif key_type == 'monoint' :\n    keymap = {}\n    f_load = open (out_load_ycsbkey, 'r')\n    f_load_out = open (out_load, 'w')\n    count = 0\n    for line in f_load :\n        cols = line.split()\n        keymap[int(cols[1])] = count\n        f_load_out.write (cols[0] + ' ' + str(count) + '\\n')\n        count += 1\n\n    f_txn = open (out_txn_ycsbkey, 'r')\n    f_txn_out = open (out_txn, 'w')\n    for line in f_txn :\n        cols = line.split()\n        if cols[0] == 'SCAN' :\n            f_txn_out.write (cols[0] + ' ' + str(keymap[int(cols[1])]) + ' ' + cols[2] + '\\n')\n        elif cols[0] == 'INSERT' :\n            keymap[int(cols[1])] = count\n            f_txn_out.write (cols[0] + ' ' + str(count) + '\\n')\n            count += 1\n        else :\n            f_txn_out.write (cols[0] + ' ' + str(keymap[int(cols[1])]) + '\\n')\n\nelif key_type == 'email' :\n    keymap = {}\n    f_email = open (email_list, 'r')\n    emails = f_email.readlines()\n\n    f_load = open (out_load_ycsbkey, 'r')\n    f_load_out = open (out_load, 'w')\n\n    sample_size = len(f_load.readlines())\n    gap = email_list_size // sample_size\n\n    if workload in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)]:\n        gap = 1\n    else:\n        assert(gap >= 2)\n\n    f_load.close()\n    f_load = open (out_load_ycsbkey, 'r')\n    count = 0\n    for line in f_load :\n        cols = line.split()\n        email = reverseHostName(emails[count * gap])\n        keymap[int(cols[1])] = email\n        f_load_out.write (cols[0] + ' ' + email + '\\n')\n        count += 1\n\n    if workload not in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)]:\n        count = 0\n    f_txn = open (out_txn_ycsbkey, 'r')\n    f_txn_out = open (out_txn, 'w')\n    for line in f_txn :\n        cols = line.split()\n        if cols[0] == 'SCAN' :\n            f_txn_out.write (cols[0] + ' ' + keymap[int(cols[1])] + ' ' + cols[2] + '\\n')\n        elif cols[0] == 'INSERT' :\n            email = reverseHostName(emails[count if workload in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)] else (count * gap + 1)])\n            keymap[int(cols[1])] = email\n            f_txn_out.write (cols[0] + ' ' + email + '\\n')\n            count += 1\n        else :\n            f_txn_out.write (cols[0] + ' ' + keymap[int(cols[1])] + '\\n')", "\nf_load.close()\nf_load_out.close()\nf_txn.close()\nf_txn_out.close()\n\ncmd = 'rm -f ' + out_load_ycsbkey\nos.system(cmd)\ncmd = 'rm -f ' + out_txn_ycsbkey\nos.system(cmd)", "cmd = 'rm -f ' + out_txn_ycsbkey\nos.system(cmd)\n"]}
{"filename": "ycsb/split_workload.py", "chunked_list": ["import sys\n\nclass bcolors:\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'", "\nif (len(sys.argv) != 5) and (len(sys.argv) != 6):\n    print(bcolors.WARNING + 'Usage:')\n    print('python3 split_workload.py workload_name[a/b/c/d/e] key_type[randint/email] CN_num client_per_CN (loader_num)' + bcolors.ENDC)\n    exit(0)\n\nworkload = sys.argv[1]\nkeyType = sys.argv[2]\nCNum = sys.argv[3]\nclientPerNode = sys.argv[4]", "CNum = sys.argv[3]\nclientPerNode = sys.argv[4]\nloader_num = '8' if len(sys.argv) == 5 else sys.argv[5]\n\nprint(bcolors.OKGREEN + 'workload = ' + workload)\nprint('key type = ' + keyType)\nprint('CN num = ' + CNum)\nprint('client-num/CN = ' + clientPerNode)\nprint('loader_num = ' + loader_num + bcolors.ENDC)\n", "print('loader_num = ' + loader_num + bcolors.ENDC)\n\nCNum = int(CNum)\nclientPerNode = int(clientPerNode)\nloader_num = int(loader_num)\nsplitNums = {\n    \"load\": CNum * min(clientPerNode, loader_num),\n    \"txn\": CNum * clientPerNode\n}\nfor op in [\"load\", \"txn\"]:\n    splitNum = splitNums[op]\n    fname = f\"{sys.path[0]}/workloads/{op}_{keyType}_workload{workload}\"\n    print(\"spliting: \", fname)\n    with open(fname, \"r\") as wlFile:\n        lines = wlFile.readlines()\n        lineNum = len(lines)\n        splitSize = lineNum // splitNum\n        for i in range(splitNum):\n            print(i * splitSize, (i + 1) * splitSize)\n            slines = lines[int(i * splitSize): int((i + 1) * splitSize)]\n            splitFname = fname + str(i)\n            with open(splitFname, \"w\") as outFile:\n                outFile.writelines(slines)", "}\nfor op in [\"load\", \"txn\"]:\n    splitNum = splitNums[op]\n    fname = f\"{sys.path[0]}/workloads/{op}_{keyType}_workload{workload}\"\n    print(\"spliting: \", fname)\n    with open(fname, \"r\") as wlFile:\n        lines = wlFile.readlines()\n        lineNum = len(lines)\n        splitSize = lineNum // splitNum\n        for i in range(splitNum):\n            print(i * splitSize, (i + 1) * splitSize)\n            slines = lines[int(i * splitSize): int((i + 1) * splitSize)]\n            splitFname = fname + str(i)\n            with open(splitFname, \"w\") as outFile:\n                outFile.writelines(slines)", ""]}
