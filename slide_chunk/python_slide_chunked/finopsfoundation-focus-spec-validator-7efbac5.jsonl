{"filename": "focus_validator/validator.py", "chunked_list": ["from pkg_resources import resource_filename\n\nfrom focus_validator.data_loaders import data_loader\nfrom focus_validator.outputter.outputter import Outputter\nfrom focus_validator.rules.spec_rules import SpecRules\n\nDEFAULT_VERSION_SETS_PATH = resource_filename(\"focus_validator.rules\", \"version_sets\")\n\n\nclass Validator:\n    def __init__(\n        self,\n        data_filename,\n        output_destination,\n        output_type,\n        rule_set_path=DEFAULT_VERSION_SETS_PATH,\n        rules_version=\"0.5\",\n        override_filename=None,\n        column_namespace=None,\n    ):\n        self.data_filename = data_filename\n        self.focus_data = None\n        self.override_filename = override_filename\n\n        self.rules_version = rules_version\n        self.spec_rules = SpecRules(\n            override_filename=override_filename,\n            rule_set_path=rule_set_path,\n            rules_version=rules_version,\n            column_namespace=column_namespace,\n        )\n        self.outputter = Outputter(\n            output_type=output_type, output_destination=output_destination\n        )\n\n    def load(self):\n        self.focus_data = data_loader.DataLoader(\n            data_filename=self.data_filename\n        ).load()\n        self.spec_rules.load()\n\n    def validate(self):\n        self.load()\n        results = self.spec_rules.validate(self.focus_data)\n        self.outputter = self.outputter.write(results)\n\n    def get_supported_versions(self):\n        return self.spec_rules.supported_versions()", "\nclass Validator:\n    def __init__(\n        self,\n        data_filename,\n        output_destination,\n        output_type,\n        rule_set_path=DEFAULT_VERSION_SETS_PATH,\n        rules_version=\"0.5\",\n        override_filename=None,\n        column_namespace=None,\n    ):\n        self.data_filename = data_filename\n        self.focus_data = None\n        self.override_filename = override_filename\n\n        self.rules_version = rules_version\n        self.spec_rules = SpecRules(\n            override_filename=override_filename,\n            rule_set_path=rule_set_path,\n            rules_version=rules_version,\n            column_namespace=column_namespace,\n        )\n        self.outputter = Outputter(\n            output_type=output_type, output_destination=output_destination\n        )\n\n    def load(self):\n        self.focus_data = data_loader.DataLoader(\n            data_filename=self.data_filename\n        ).load()\n        self.spec_rules.load()\n\n    def validate(self):\n        self.load()\n        results = self.spec_rules.validate(self.focus_data)\n        self.outputter = self.outputter.write(results)\n\n    def get_supported_versions(self):\n        return self.spec_rules.supported_versions()", ""]}
{"filename": "focus_validator/main.py", "chunked_list": ["import argparse\nimport os\nimport sys\n\nfrom focus_validator.validator import Validator\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"FOCUS specification validator.\")\n    parser.add_argument(\n        \"--data-file\",\n        help=\"Path to the data file (CSV)\",\n        required=\"--supported-versions\" not in sys.argv,\n    )\n    parser.add_argument(\n        \"--column-namespace\",\n        help=\"Column namespace to differentiate focus columns from vendor columns\",\n    )\n    parser.add_argument(\"--override-file\", help=\"Path to the override file (YAML)\")\n    parser.add_argument(\n        \"--output-format\", default=\"text\", help=\"Path to the output report file\"\n    )\n    parser.add_argument(\n        \"--supported-versions\",\n        action=\"store_true\",\n        default=False,\n        help=\"Return the supported FOCUS versions for validation\",\n    )\n    parser.add_argument(\n        \"--transitional\",\n        action=\"store_true\",\n        default=False,\n        help=\"Allow transitional rules in validation\",\n    )\n    parser.add_argument(\n        \"--validate-version\", default=\"0.5\", help=\"Version of FOCUS to validate against\"\n    )\n    parser.add_argument(\n        \"--rule-set-path\",\n        default=os.path.join(\"focus_validator\", \"rules\", \"version_sets\"),\n        help=\"Path to rules definitions\",\n    )\n    parser.add_argument(\n        \"--output-type\",\n        default=\"console\",\n        help=\"What type of output you would like\",\n        choices=[\"console\", \"unittest\"],\n    )\n    parser.add_argument(\n        \"--output-destination\",\n        default=None,\n        help=\"filename of where to output the rules\",\n    )\n\n    args = parser.parse_args()\n\n    if args.output_type != \"console\" and args.output_destination is None:\n        parser.error(\"--output-destination required {}\".format(args.output_type))\n        sys.exit(1)\n\n    validator = Validator(\n        data_filename=args.data_file,\n        override_filename=args.override_file,\n        rule_set_path=args.rule_set_path,\n        rules_version=args.validate_version,\n        output_type=args.output_type,\n        output_destination=args.output_destination,\n        column_namespace=args.column_namespace,\n    )\n    if args.supported_versions:\n        for version in validator.get_supported_versions():\n            print(version)\n    else:\n        validator.validate()", "\n\nif __name__ == \"__main__\":\n    main()\n"]}
{"filename": "focus_validator/__init__.py", "chunked_list": ["# this import is needed to initialize custom pandera extensions implemented in this package\nfrom focus_validator.rules.checks import *  # noqa\n"]}
{"filename": "focus_validator/exceptions.py", "chunked_list": ["class FocusValidationError(Exception):\n    pass\n\n\nclass FocusNotImplementedError(FocusValidationError):\n    def __init__(self, msg=None):\n        super().__init__(msg)\n\n\nclass UnsupportedVersion(FocusValidationError):\n    pass", "\nclass UnsupportedVersion(FocusValidationError):\n    pass\n"]}
{"filename": "focus_validator/data_loaders/csv_data_loader.py", "chunked_list": ["import pandas as pd\n\n\nclass CSVDataLoader:\n    def __init__(self, data_filename):\n        self.data_filename = data_filename\n\n    def load(self):\n        return pd.read_csv(self.data_filename, keep_default_na=False)\n", ""]}
{"filename": "focus_validator/data_loaders/parquet_data_loader.py", "chunked_list": ["import pandas as pd\n\n\nclass ParquetDataLoader:\n    def __init__(self, data_filename):\n        self.data_filename = data_filename\n\n    def load(self):\n        return pd.read_parquet(self.data_filename)\n", ""]}
{"filename": "focus_validator/data_loaders/__init__.py", "chunked_list": [""]}
{"filename": "focus_validator/data_loaders/data_loader.py", "chunked_list": ["import magic\n\nfrom focus_validator.data_loaders.csv_data_loader import CSVDataLoader\nfrom focus_validator.data_loaders.parquet_data_loader import ParquetDataLoader\nfrom focus_validator.exceptions import FocusNotImplementedError\n\n\ndef get_file_mime_type(filename):\n    f = magic.Magic(uncompress=True)\n    return f.from_file(filename=filename)", "\n\nclass DataLoader:\n    def __init__(self, data_filename):\n        self.data_filename = data_filename\n        self.data_loader_class = self.find_data_loader()\n        self.data_loader = self.data_loader_class(self.data_filename)\n\n    def find_data_loader(self):\n        file_mime_type = get_file_mime_type(self.data_filename)\n\n        if file_mime_type in [\"ASCII text\", \"CSV text\"]:\n            return CSVDataLoader\n        elif file_mime_type == \"Apache Parquet\":\n            return ParquetDataLoader\n        else:\n            raise FocusNotImplementedError(\n                msg=f\"Validator for file_type {file_mime_type} not implemented yet.\"\n            )\n\n    def load(self):\n        return self.data_loader.load()", ""]}
{"filename": "focus_validator/rules/checks.py", "chunked_list": ["import re\nfrom datetime import datetime\n\nimport pandas as pd\nfrom pandera import extensions\n\nfrom focus_validator.utils.download_currency_codes import get_currency_codes\n\n\ndef is_camel_case(column_name):\n    return (\n        column_name != column_name.lower()\n        and column_name != column_name.upper()\n        and \"_\" not in column_name\n    )", "\ndef is_camel_case(column_name):\n    return (\n        column_name != column_name.lower()\n        and column_name != column_name.upper()\n        and \"_\" not in column_name\n    )\n\n\n@extensions.register_check_method()\ndef check_not_null(pandas_obj: pd.Series, allow_nulls: bool):\n    # TODO: works for string type, need to verify for other data types\n    check_values = pandas_obj.isnull() | (pandas_obj == \"\")\n    if not allow_nulls:\n        check_values = check_values | (pandas_obj == \"NULL\")\n    return ~check_values", "\n@extensions.register_check_method()\ndef check_not_null(pandas_obj: pd.Series, allow_nulls: bool):\n    # TODO: works for string type, need to verify for other data types\n    check_values = pandas_obj.isnull() | (pandas_obj == \"\")\n    if not allow_nulls:\n        check_values = check_values | (pandas_obj == \"NULL\")\n    return ~check_values\n\n", "\n\n@extensions.register_check_method()\ndef check_unique(pandas_obj: pd.Series):\n    return ~pandas_obj.duplicated()\n\n\n@extensions.register_check_method()\ndef check_value_in(pandas_obj: pd.Series, allowed_values):\n    return pandas_obj.isin(allowed_values)", "def check_value_in(pandas_obj: pd.Series, allowed_values):\n    return pandas_obj.isin(allowed_values)\n\n\n@extensions.register_check_method()\ndef check_datetime_dtype(pandas_obj: pd.Series):\n    pattern = re.compile(r\"\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}Z$\")\n\n    def __validate_date_obj__(value: str):\n        if not (isinstance(value, str) and re.match(pattern, value)):\n            return False\n\n        try:\n            datetime.strptime(value[:-1], \"%Y-%m-%dT%H:%M:%S\")\n            return True\n        except ValueError:\n            return False\n\n    return pd.Series(map(__validate_date_obj__, pandas_obj.values))", "\n\n@extensions.register_check_method()\ndef check_currency_code_dtype(pandas_obj: pd.Series):\n    currency_codes = set(get_currency_codes())\n    return pd.Series(\n        map(lambda v: isinstance(v, str) and v in currency_codes, pandas_obj.values)\n    )\n", ""]}
{"filename": "focus_validator/rules/__init__.py", "chunked_list": [""]}
{"filename": "focus_validator/rules/spec_rules.py", "chunked_list": ["import os\nfrom typing import Dict, Optional\n\nimport pandas as pd\nfrom pandera.errors import SchemaErrors\n\nfrom focus_validator.config_objects import (\n    ChecklistObject,\n    ChecklistObjectStatus,\n    Override,", "    ChecklistObjectStatus,\n    Override,\n    Rule,\n)\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.exceptions import UnsupportedVersion\n\n\ndef convert_missing_column_errors(df, checklist):\n    def process_row(row):\n        if (\n            row[\"schema_context\"] == \"DataFrameSchema\"\n            and row[\"check\"] == \"column_in_dataframe\"\n        ):\n            for check_name, check_obj in checklist.items():\n                if (\n                    row[\"failure_case\"] == check_obj.column_id\n                    and check_obj.rule_ref.check == \"column_required\"\n                ):\n                    row[\"check\"] = f\"{check_name}:::{check_obj.friendly_name}\"\n                    row[\"column\"] = check_obj.column_id\n                    row[\"failure_case\"] = None\n                    return row\n        else:\n            return row\n\n    filtered_df = df.apply(process_row, axis=1)\n    return filtered_df", "\n\ndef convert_missing_column_errors(df, checklist):\n    def process_row(row):\n        if (\n            row[\"schema_context\"] == \"DataFrameSchema\"\n            and row[\"check\"] == \"column_in_dataframe\"\n        ):\n            for check_name, check_obj in checklist.items():\n                if (\n                    row[\"failure_case\"] == check_obj.column_id\n                    and check_obj.rule_ref.check == \"column_required\"\n                ):\n                    row[\"check\"] = f\"{check_name}:::{check_obj.friendly_name}\"\n                    row[\"column\"] = check_obj.column_id\n                    row[\"failure_case\"] = None\n                    return row\n        else:\n            return row\n\n    filtered_df = df.apply(process_row, axis=1)\n    return filtered_df", "\n\ndef convert_dtype_column_errors(df, checklist):\n    def process_row(row):\n        if row[\"schema_context\"] == \"Column\" and row[\"check\"].startswith(\"dtype\"):\n            for check_name, check_obj in checklist.items():\n                if row[\"column\"] == check_obj.column_id:\n                    row[\"check\"] = f\"{check_name}:::{check_obj.friendly_name}\"\n                    row[\"column\"] = check_obj.column_id\n                    row[\"failure_case\"] = None\n                    return row\n        else:\n            return row\n\n    filtered_df = df.apply(process_row, axis=1)\n    return filtered_df", "\n\ndef restructure_failure_cases_df(failure_cases: pd.DataFrame, checklist):\n    failure_cases = convert_missing_column_errors(failure_cases, checklist)\n    failure_cases = convert_dtype_column_errors(failure_cases, checklist)\n    failure_cases = failure_cases.rename(\n        columns={\"column\": \"Column\", \"index\": \"Row #\", \"failure_case\": \"Values\"}\n    )\n\n    failure_cases[[\"Check Name\", \"Description\"]] = failure_cases[\"check\"].str.split(\n        \":::\", expand=True\n    )\n    failure_cases = failure_cases.drop(\"check\", axis=1)\n    failure_cases = failure_cases.drop(\"check_number\", axis=1)\n    failure_cases = failure_cases.drop(\"schema_context\", axis=1)\n\n    failure_cases = failure_cases.rename_axis(\"#\")\n    failure_cases.index = failure_cases.index + 1\n\n    failure_cases[\"Row #\"] = failure_cases[\"Row #\"] + 1\n    failure_cases = failure_cases[\n        [\"Column\", \"Check Name\", \"Description\", \"Values\", \"Row #\"]\n    ]\n\n    return failure_cases", "\n\nclass ValidationResult:\n    checklist: Dict[str, ChecklistObject]\n    failure_cases: Optional[pd.DataFrame]\n\n    def __init__(\n        self,\n        checklist: Dict[str, ChecklistObject],\n        failure_cases: Optional[pd.DataFrame] = None,\n    ):\n        self.__failure_cases__ = failure_cases\n        self.__checklist__ = checklist\n\n    def process_result(self):\n        failure_cases = self.__failure_cases__\n        checklist = self.__checklist__\n        if failure_cases is None:\n            self.failure_cases = None\n        else:\n            self.failure_cases = failure_cases = restructure_failure_cases_df(\n                failure_cases, checklist\n            )\n            failed = set(failure_cases[\"Check Name\"])\n            for check_name in failed:\n                checklist[check_name].status = ChecklistObjectStatus.FAILED\n\n        for check_list_object in checklist.values():\n            if check_list_object.status == ChecklistObjectStatus.PENDING:\n                check_list_object.status = ChecklistObjectStatus.PASSED\n        self.checklist = checklist", "\n\nclass SpecRules:\n    def __init__(\n        self, override_filename, rule_set_path, rules_version, column_namespace\n    ):\n        self.override_filename = override_filename\n        self.override_config = None\n        self.rules_version = rules_version\n        self.rule_set_path = rule_set_path\n        if self.rules_version not in self.supported_versions():\n            raise UnsupportedVersion(\n                f\"FOCUS version {self.rules_version} not supported.\"\n            )\n        self.rules_path = os.path.join(self.rule_set_path, self.rules_version)\n        self.rules = []\n        self.column_namespace = column_namespace\n\n    def supported_versions(self):\n        return sorted([x for x in os.walk(self.rule_set_path)][0][1])\n\n    def load(self):\n        self.load_overrides()\n        self.load_rules()\n\n    def load_overrides(self):\n        if not self.override_filename:\n            return {}\n        self.override_config = Override.load_yaml(self.override_filename)\n\n    def load_rules(self):\n        for rule_path in self.get_rule_paths():\n            self.rules.append(\n                Rule.load_yaml(rule_path, column_namespace=self.column_namespace)\n            )\n\n    def get_rule_paths(self):\n        for root, dirs, files in os.walk(self.rules_path, topdown=False):\n            for name in files:\n                yield os.path.join(root, name)\n\n    def validate(self, focus_data):\n        (\n            pandera_schema,\n            checklist,\n        ) = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=self.rules, override_config=self.override_config\n        )\n        try:\n            pandera_schema.validate(focus_data, lazy=True)\n            failure_cases = None\n        except SchemaErrors as e:\n            failure_cases = e.failure_cases\n\n        validation_result = ValidationResult(\n            checklist=checklist, failure_cases=failure_cases\n        )\n        validation_result.process_result()\n        return validation_result", ""]}
{"filename": "focus_validator/utils/download_currency_codes.py", "chunked_list": ["import xml.etree.ElementTree as ET\n\nimport pandas as pd\nimport requests\n\nDATAHUB_URL = \"https://www.six-group.com/dam/download/financial-information/data-center/iso-currrency/lists/list-one.xml\"\nCURRENCY_CODE_CSV_PATH = \"focus_validator/utils/currency_codes.csv\"\n\n\ndef download_currency_codes():\n    r = requests.get(DATAHUB_URL)\n    root = ET.fromstring(r.content.decode())\n\n    currency_codes = []\n    for child in root.iter():\n        if child.tag == \"Ccy\":\n            currency_codes.append(child.text)\n\n    df = pd.DataFrame(set(currency_codes), columns=[\"currency_codes\"])\n    df.to_csv(CURRENCY_CODE_CSV_PATH)", "\ndef download_currency_codes():\n    r = requests.get(DATAHUB_URL)\n    root = ET.fromstring(r.content.decode())\n\n    currency_codes = []\n    for child in root.iter():\n        if child.tag == \"Ccy\":\n            currency_codes.append(child.text)\n\n    df = pd.DataFrame(set(currency_codes), columns=[\"currency_codes\"])\n    df.to_csv(CURRENCY_CODE_CSV_PATH)", "\n\ndef get_currency_codes():\n    df = pd.read_csv(CURRENCY_CODE_CSV_PATH)\n    return set(df[\"currency_codes\"].values)\n\n\nif __name__ == \"__main__\":\n    download_currency_codes()\n", ""]}
{"filename": "focus_validator/utils/__init__.py", "chunked_list": [""]}
{"filename": "focus_validator/config_objects/focus_to_pandera_schema_converter.py", "chunked_list": ["from itertools import groupby\nfrom typing import Dict, List, Optional, Set, Union\n\nimport pandera as pa\nfrom pandera.api.pandas.types import PandasDtypeInputTypes\n\nfrom focus_validator.config_objects import ChecklistObject, InvalidRule, Rule\nfrom focus_validator.config_objects.common import (\n    AllowNullsCheck,\n    ChecklistObjectStatus,", "    AllowNullsCheck,\n    ChecklistObjectStatus,\n    DataTypeCheck,\n    DataTypes,\n    ValueInCheck,\n)\nfrom focus_validator.config_objects.override import Override\nfrom focus_validator.exceptions import FocusNotImplementedError\n\n\nclass FocusToPanderaSchemaConverter:\n    @staticmethod\n    def __generate_pandera_check__(rule: Rule, check_id):\n        \"\"\"\n        Generates a single pandera check based on the check config which can then be added to the pa.Column.\n        :param rule:\n        :param check_id:\n        :return:\n        \"\"\"\n\n        check = rule.check\n        error_string = \"{}::: {}\".format(check_id, rule.check_friendly_name)\n\n        if isinstance(check, str):\n            if check == \"check_unique\":\n                return pa.Check.check_unique(error=error_string)\n            else:\n                raise FocusNotImplementedError(\n                    msg=\"Check type: {} not implemented.\".format(check)\n                )\n        elif isinstance(check, ValueInCheck):\n            return pa.Check.check_value_in(\n                allowed_values=check.value_in, error=error_string\n            )\n        elif isinstance(check, AllowNullsCheck):\n            return pa.Check.check_not_null(\n                error=error_string, ignore_na=False, allow_nulls=check.allow_nulls\n            )\n        else:\n            raise FocusNotImplementedError(\n                msg=\"Check type: {} not implemented.\".format(type(check))\n            )\n\n    @classmethod\n    def __generate_column_definition__(\n        cls, rule: Rule, overrides, data_type: DataTypes\n    ):\n        \"\"\"\n        Generates column data type validation obj and pa.Column which will contain all other checks\n        \"\"\"\n        column_checks = []\n\n        pandera_type: Optional[PandasDtypeInputTypes]\n        if data_type == DataTypes.DECIMAL:\n            pandera_type = pa.Float\n        elif data_type == DataTypes.DATETIME:\n            pandera_type = None\n            column_checks.append(\n                pa.Check.check_datetime_dtype(\n                    ignore_na=True,\n                    error=f\"{rule.check_id}:::Ensures that column is of {data_type.value} type.\",\n                )\n            )\n        elif data_type == DataTypes.CURRENCY_CODE:\n            pandera_type = None\n            column_checks.append(\n                pa.Check.check_currency_code_dtype(\n                    ignore_na=True,\n                    error=f\"{rule.check_id}:::Ensures that column is of {data_type.value} type.\",\n                )\n            )\n        else:\n            pandera_type = pa.String\n\n        check_list_object = ChecklistObject(\n            check_name=rule.check_id,\n            column_id=rule.column_id,\n            status=ChecklistObjectStatus.SKIPPED\n            if rule.check_id in overrides\n            else ChecklistObjectStatus.PENDING,\n            friendly_name=f\"Ensures that column is of {data_type.value} type.\",\n            rule_ref=rule,\n        )\n        pa_column = pa.Column(\n            pandera_type,  # type: ignore\n            required=False,\n            checks=column_checks,\n            nullable=True,\n        )\n        return check_list_object, pa_column\n\n    @classmethod\n    def __generate_non_dtype_check__(\n        cls,\n        column_id,\n        column_rules: List[\"Rule\"],\n        schema_dict: Dict[str, pa.Column],\n        checklist,\n        overrides,\n    ):\n        try:\n            pa_column = schema_dict[column_id]\n        except KeyError:\n            pa_column = None\n        for rule in column_rules:\n            checklist[rule.check_id] = check_list_object = ChecklistObject(\n                check_name=rule.check_id,\n                column_id=column_id,\n                friendly_name=rule.check_friendly_name,\n                status=ChecklistObjectStatus.PENDING,\n                rule_ref=rule,\n            )\n\n            if pa_column is None:\n                check_list_object.error = (\n                    \"ConfigurationError: No configuration found for column.\"\n                )\n                check_list_object.status = ChecklistObjectStatus.ERRORED\n            elif rule.check_id in overrides:\n                check_list_object.status = ChecklistObjectStatus.SKIPPED\n            else:\n                if rule.check == \"column_required\":\n                    pa_column.required = True\n                else:\n                    check = cls.__generate_pandera_check__(\n                        rule=rule, check_id=rule.check_id\n                    )\n                    pa_column.checks.append(check)\n\n    @classmethod\n    def generate_pandera_schema(\n        cls,\n        rules: List[Union[Rule, InvalidRule]],\n        override_config: Optional[Override] = None,\n    ):\n        schema_dict = {}\n        checklist = {}\n        overrides: Set[str] = set()\n        if override_config:\n            overrides = set(override_config.overrides)\n\n        validation_rules = []\n        for rule in rules:\n            if isinstance(rule, InvalidRule):\n                checklist[rule.rule_path] = ChecklistObject(\n                    check_name=rule.rule_path,\n                    column_id=\"Unknown\",\n                    error=f\"{rule.error_type}: {rule.error}\",\n                    status=ChecklistObjectStatus.ERRORED,\n                    rule_ref=rule,\n                )\n                continue\n\n            if isinstance(rule.check, DataTypeCheck):\n                check_list_object, pa_column = cls.__generate_column_definition__(\n                    rule=rule, overrides=overrides, data_type=rule.check.data_type\n                )\n                checklist[rule.check_id] = check_list_object\n                schema_dict[rule.column_id] = pa_column\n            else:\n                validation_rules.append(rule)\n\n        # groups check types by column id so that they can be associated with matching column\n        for column_id, column_rules in groupby(\n            sorted(validation_rules, key=lambda item: item.column_id),\n            key=lambda item: item.column_id,\n        ):\n            cls.__generate_non_dtype_check__(\n                column_id=column_id,\n                checklist=checklist,\n                column_rules=list(column_rules),\n                overrides=overrides,\n                schema_dict=schema_dict,\n            )\n        return pa.DataFrameSchema(schema_dict, strict=False), checklist", "\n\nclass FocusToPanderaSchemaConverter:\n    @staticmethod\n    def __generate_pandera_check__(rule: Rule, check_id):\n        \"\"\"\n        Generates a single pandera check based on the check config which can then be added to the pa.Column.\n        :param rule:\n        :param check_id:\n        :return:\n        \"\"\"\n\n        check = rule.check\n        error_string = \"{}::: {}\".format(check_id, rule.check_friendly_name)\n\n        if isinstance(check, str):\n            if check == \"check_unique\":\n                return pa.Check.check_unique(error=error_string)\n            else:\n                raise FocusNotImplementedError(\n                    msg=\"Check type: {} not implemented.\".format(check)\n                )\n        elif isinstance(check, ValueInCheck):\n            return pa.Check.check_value_in(\n                allowed_values=check.value_in, error=error_string\n            )\n        elif isinstance(check, AllowNullsCheck):\n            return pa.Check.check_not_null(\n                error=error_string, ignore_na=False, allow_nulls=check.allow_nulls\n            )\n        else:\n            raise FocusNotImplementedError(\n                msg=\"Check type: {} not implemented.\".format(type(check))\n            )\n\n    @classmethod\n    def __generate_column_definition__(\n        cls, rule: Rule, overrides, data_type: DataTypes\n    ):\n        \"\"\"\n        Generates column data type validation obj and pa.Column which will contain all other checks\n        \"\"\"\n        column_checks = []\n\n        pandera_type: Optional[PandasDtypeInputTypes]\n        if data_type == DataTypes.DECIMAL:\n            pandera_type = pa.Float\n        elif data_type == DataTypes.DATETIME:\n            pandera_type = None\n            column_checks.append(\n                pa.Check.check_datetime_dtype(\n                    ignore_na=True,\n                    error=f\"{rule.check_id}:::Ensures that column is of {data_type.value} type.\",\n                )\n            )\n        elif data_type == DataTypes.CURRENCY_CODE:\n            pandera_type = None\n            column_checks.append(\n                pa.Check.check_currency_code_dtype(\n                    ignore_na=True,\n                    error=f\"{rule.check_id}:::Ensures that column is of {data_type.value} type.\",\n                )\n            )\n        else:\n            pandera_type = pa.String\n\n        check_list_object = ChecklistObject(\n            check_name=rule.check_id,\n            column_id=rule.column_id,\n            status=ChecklistObjectStatus.SKIPPED\n            if rule.check_id in overrides\n            else ChecklistObjectStatus.PENDING,\n            friendly_name=f\"Ensures that column is of {data_type.value} type.\",\n            rule_ref=rule,\n        )\n        pa_column = pa.Column(\n            pandera_type,  # type: ignore\n            required=False,\n            checks=column_checks,\n            nullable=True,\n        )\n        return check_list_object, pa_column\n\n    @classmethod\n    def __generate_non_dtype_check__(\n        cls,\n        column_id,\n        column_rules: List[\"Rule\"],\n        schema_dict: Dict[str, pa.Column],\n        checklist,\n        overrides,\n    ):\n        try:\n            pa_column = schema_dict[column_id]\n        except KeyError:\n            pa_column = None\n        for rule in column_rules:\n            checklist[rule.check_id] = check_list_object = ChecklistObject(\n                check_name=rule.check_id,\n                column_id=column_id,\n                friendly_name=rule.check_friendly_name,\n                status=ChecklistObjectStatus.PENDING,\n                rule_ref=rule,\n            )\n\n            if pa_column is None:\n                check_list_object.error = (\n                    \"ConfigurationError: No configuration found for column.\"\n                )\n                check_list_object.status = ChecklistObjectStatus.ERRORED\n            elif rule.check_id in overrides:\n                check_list_object.status = ChecklistObjectStatus.SKIPPED\n            else:\n                if rule.check == \"column_required\":\n                    pa_column.required = True\n                else:\n                    check = cls.__generate_pandera_check__(\n                        rule=rule, check_id=rule.check_id\n                    )\n                    pa_column.checks.append(check)\n\n    @classmethod\n    def generate_pandera_schema(\n        cls,\n        rules: List[Union[Rule, InvalidRule]],\n        override_config: Optional[Override] = None,\n    ):\n        schema_dict = {}\n        checklist = {}\n        overrides: Set[str] = set()\n        if override_config:\n            overrides = set(override_config.overrides)\n\n        validation_rules = []\n        for rule in rules:\n            if isinstance(rule, InvalidRule):\n                checklist[rule.rule_path] = ChecklistObject(\n                    check_name=rule.rule_path,\n                    column_id=\"Unknown\",\n                    error=f\"{rule.error_type}: {rule.error}\",\n                    status=ChecklistObjectStatus.ERRORED,\n                    rule_ref=rule,\n                )\n                continue\n\n            if isinstance(rule.check, DataTypeCheck):\n                check_list_object, pa_column = cls.__generate_column_definition__(\n                    rule=rule, overrides=overrides, data_type=rule.check.data_type\n                )\n                checklist[rule.check_id] = check_list_object\n                schema_dict[rule.column_id] = pa_column\n            else:\n                validation_rules.append(rule)\n\n        # groups check types by column id so that they can be associated with matching column\n        for column_id, column_rules in groupby(\n            sorted(validation_rules, key=lambda item: item.column_id),\n            key=lambda item: item.column_id,\n        ):\n            cls.__generate_non_dtype_check__(\n                column_id=column_id,\n                checklist=checklist,\n                column_rules=list(column_rules),\n                overrides=overrides,\n                schema_dict=schema_dict,\n            )\n        return pa.DataFrameSchema(schema_dict, strict=False), checklist", ""]}
{"filename": "focus_validator/config_objects/rule.py", "chunked_list": ["from typing import Optional, Union\n\nimport yaml\nfrom pydantic import BaseModel, root_validator\n\nfrom focus_validator.config_objects.common import (\n    SIMPLE_CHECKS,\n    AllowNullsCheck,\n    ChecklistObjectStatus,\n    DataTypeCheck,", "    ChecklistObjectStatus,\n    DataTypeCheck,\n    ValueInCheck,\n    generate_check_friendly_name,\n)\n\n\nclass InvalidRule(BaseModel):\n    rule_path: str\n    error: str\n    error_type: str", "\n\nclass Rule(BaseModel):\n    \"\"\"\n    Base rule class that loads spec configs and generate\n    a pandera rule that can be validated.\n    \"\"\"\n\n    check_id: str\n    column_id: str\n    check: Union[SIMPLE_CHECKS, AllowNullsCheck, ValueInCheck, DataTypeCheck]\n\n    check_friendly_name: Optional[\n        str\n    ] = None  # auto generated or else can be overwritten\n    check_type_friendly_name: Optional[str] = None\n\n    class Config:\n        extra = \"forbid\"  # prevents config from containing any undesirable keys\n        frozen = (\n            True  # prevents any modification to any attribute onces loaded from config\n        )\n\n    @root_validator\n    def root_val(cls, values):\n        \"\"\"\n        Root validator that checks for all options passed in the config and generate missing options.\n        \"\"\"\n\n        check = values.get(\"check\")\n        check_friendly_name = values.get(\"check_friendly_name\")\n        column_id = values.get(\"column_id\")\n        if check is not None:\n            if isinstance(check, str):\n                check_type_friendly_name = \"\".join(\n                    [word.title() for word in check.split(\"_\")]\n                )\n            else:\n                check_type_friendly_name = check.__class__.__name__\n            values[\"check_type_friendly_name\"] = check_type_friendly_name\n\n            if check_friendly_name is None and column_id is not None:\n                values[\"check_friendly_name\"] = generate_check_friendly_name(\n                    check=check, column_id=column_id\n                )\n\n        return values\n\n    @staticmethod\n    def load_yaml(\n        rule_path, column_namespace: Optional[str] = None\n    ) -> Union[\"Rule\", InvalidRule]:\n        try:\n            with open(rule_path, \"r\") as f:\n                rule_obj = yaml.safe_load(f)\n\n            if (\n                isinstance(rule_obj, dict)\n                and rule_obj.get(\"column\")\n                and column_namespace\n            ):\n                rule_obj[\"column\"] = f\"{column_namespace}:{rule_obj['column']}\"\n\n            return Rule.parse_obj(rule_obj)\n        except Exception as e:\n            return InvalidRule(\n                rule_path=rule_path, error=str(e), error_type=e.__class__.__name__\n            )", "\n\nclass ChecklistObject(BaseModel):\n    check_name: str\n    column_id: str\n    friendly_name: Optional[str] = None\n    error: Optional[str] = None\n    status: ChecklistObjectStatus\n    rule_ref: Union[InvalidRule, Rule]\n", ""]}
{"filename": "focus_validator/config_objects/__init__.py", "chunked_list": ["from .common import ChecklistObjectStatus\nfrom .override import Override\nfrom .rule import ChecklistObject, InvalidRule, Rule\n\n__all__ = [\n    \"ChecklistObject\",\n    \"ChecklistObjectStatus\",\n    \"Rule\",\n    \"InvalidRule\",\n    \"Override\",", "    \"InvalidRule\",\n    \"Override\",\n]\n"]}
{"filename": "focus_validator/config_objects/common.py", "chunked_list": ["from enum import Enum\nfrom typing import List, Literal\n\nfrom pydantic import BaseModel\n\n\nclass AllowNullsCheck(BaseModel):\n    allow_nulls: bool\n\n\nclass ValueInCheck(BaseModel):\n    value_in: List[str]", "\n\nclass ValueInCheck(BaseModel):\n    value_in: List[str]\n\n\nSIMPLE_CHECKS = Literal[\"check_unique\", \"column_required\"]\n\n\nclass DataTypes(Enum):\n    STRING = \"string\"\n    DECIMAL = \"decimal\"\n    DATETIME = \"datetime\"\n    CURRENCY_CODE = \"currency-code\"", "\nclass DataTypes(Enum):\n    STRING = \"string\"\n    DECIMAL = \"decimal\"\n    DATETIME = \"datetime\"\n    CURRENCY_CODE = \"currency-code\"\n\n\nclass DataTypeCheck(BaseModel):\n    data_type: DataTypes", "class DataTypeCheck(BaseModel):\n    data_type: DataTypes\n\n\nclass ChecklistObjectStatus(Enum):\n    ERRORED = \"errored\"\n    PASSED = \"passed\"\n    FAILED = \"failed\"\n    SKIPPED = \"skipped\"\n    PENDING = \"pending\"", "\n\ndef generate_check_friendly_name(check, column_id):\n    if check == \"check_unique\":\n        return f\"{column_id}, requires unique values.\"\n    elif check == \"column_required\":\n        return f\"{column_id} is a required column.\"\n    elif isinstance(check, ValueInCheck):\n        return (\n            f\"{column_id} must have a value from the list: {','.join(check.value_in)}.\"\n        )\n    elif isinstance(check, AllowNullsCheck):\n        if check.allow_nulls:\n            return f\"{column_id} allows null values.\"\n        else:\n            return f\"{column_id} does not allow null values.\"\n    elif isinstance(check, DataTypeCheck):\n        return f\"{column_id} requires values of type {check.data_type.value}.\"", ""]}
{"filename": "focus_validator/config_objects/override.py", "chunked_list": ["from typing import List\n\nimport yaml\nfrom pydantic import BaseModel\n\n\nclass Override(BaseModel):\n    overrides: List[str]\n\n    @staticmethod\n    def load_yaml(override_filename):\n        with open(override_filename, \"r\") as file:\n            override_obj = yaml.safe_load(file)\n        return Override.parse_obj(override_obj)", ""]}
{"filename": "focus_validator/outputter/outputter.py", "chunked_list": ["from focus_validator.exceptions import FocusNotImplementedError\nfrom focus_validator.outputter.outputter_console import ConsoleOutputter\nfrom focus_validator.outputter.outputter_unittest import UnittestOutputter\nfrom focus_validator.rules.spec_rules import ValidationResult\n\n\nclass Outputter:\n    def __init__(self, output_type, output_destination):\n        if output_type == \"console\":\n            self.outputter = ConsoleOutputter(output_destination=output_destination)\n        elif output_type == \"unittest\":\n            self.outputter = UnittestOutputter(output_destination=output_destination)\n        else:\n            raise FocusNotImplementedError(\"Output type not supported\")\n\n    def write(self, result_set: ValidationResult):\n        self.outputter.write(result_set)", ""]}
{"filename": "focus_validator/outputter/__init__.py", "chunked_list": [""]}
{"filename": "focus_validator/outputter/outputter_console.py", "chunked_list": ["import pandas as pd\nfrom tabulate import tabulate\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.rules.spec_rules import ValidationResult\n\n\nclass ConsoleOutputter:\n    def __init__(self, output_destination):\n        self.output_destination = output_destination\n        self.result_set = None\n\n    @staticmethod\n    def __restructure_check_list__(result_set: ValidationResult):\n        rows = []\n        for value in result_set.checklist.values():\n            if isinstance(value.rule_ref, Rule):\n                check_type = value.rule_ref.check_type_friendly_name\n            else:\n                check_type = \"ERRORED\"\n\n            row_obj = value.dict()\n            row_obj.update(\n                {\n                    \"check_type\": check_type,\n                    \"status\": row_obj[\"status\"].value.title(),\n                }\n            )\n            rows.append(row_obj)\n        df = pd.DataFrame(rows)\n        df.rename(\n            columns={\n                \"check_name\": \"Check Name\",\n                \"check_type\": \"Check Type\",\n                \"column_id\": \"Column\",\n                \"friendly_name\": \"Friendly Name\",\n                \"error\": \"Error\",\n                \"status\": \"Status\",\n            },\n            inplace=True,\n        )\n        df = df.reindex(\n            columns=[\n                \"Check Name\",\n                \"Check Type\",\n                \"Column\",\n                \"Friendly Name\",\n                \"Error\",\n                \"Status\",\n            ]\n        )\n        return df\n\n    def write(self, result_set: ValidationResult):\n        self.result_set = result_set\n\n        checklist = self.__restructure_check_list__(result_set)\n        print(\"Checklist:\")\n        print(tabulate(checklist, headers=\"keys\", tablefmt=\"psql\"))\n\n        if result_set.failure_cases is not None:\n            print(\"Checks summary:\")\n            print(\n                tabulate(\n                    tabular_data=result_set.failure_cases,  # type: ignore\n                    headers=\"keys\",\n                    tablefmt=\"psql\",\n                )\n            )", ""]}
{"filename": "focus_validator/outputter/outputter_unittest.py", "chunked_list": ["import logging\nimport re\nimport sys\nimport xml.etree.cElementTree as ET\nfrom datetime import datetime, timezone\n\n\nclass UnittestFormatter:\n    def __init__(\n        self,\n        name,\n        tests,\n        failures,\n        errors,\n        skipped,\n        assertions=None,\n        time=\"0\",\n        timestamp=None,\n    ):\n        self.name = name\n        self.tests = str(tests)\n        self.failures = str(failures)\n        self.errors = str(errors)\n        self.skipped = str(skipped)\n        self.assertions = str(assertions)\n        if not self.assertions:\n            self.assertions = self.tests\n        self.time = time\n        self.timestamp = timestamp\n        if not self.timestamp:\n            self.timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S\")\n        self.results = {}\n\n    def add_testsuite(self, name, column):\n        if name not in self.results:\n            self.results[name] = {\"tests\": {}, \"time\": \"0\", \"column\": column}\n\n    def add_testcase(self, testsuite, name, result, message, check_type_name):\n        self.results[testsuite][\"tests\"][name] = {\n            \"result\": result.lower(),\n            \"message\": message,\n            \"check_type_name\": check_type_name,\n        }\n\n    def generate_unittest(self):\n        testsuites = ET.Element(\n            \"testsuites\",\n            name=self.name,\n            tests=self.tests,\n            failures=self.failures,\n            errors=self.errors,\n            skipped=self.skipped,\n            assertions=self.assertions,\n            time=self.time,\n            timestamp=self.timestamp,\n        )\n\n        for testsuite in sorted(self.results.keys()):\n            ts = ET.SubElement(\n                testsuites,\n                \"testsuite\",\n                name=f'{testsuite}-{self.results[testsuite][\"column\"]}',\n                time=\"0\",\n            )\n            for testcase in sorted(self.results[testsuite][\"tests\"].keys()):\n                tc = ET.SubElement(\n                    ts,\n                    \"testcase\",\n                    name=f\"{testcase} :: {self.results[testsuite]['tests'][testcase]['check_type_name']}\",\n                    time=\"0\",\n                )\n                if (\n                    self.results[testsuite][\"tests\"][testcase][\"result\"].lower()\n                    == \"failed\"\n                ):\n                    ET.SubElement(\n                        tc,\n                        \"failure\",\n                        name=testcase,\n                        message=self.results[testsuite][\"tests\"][testcase][\"message\"],\n                        type=\"AssertionError\",\n                    ).text = \"Failed\"\n                elif (\n                    self.results[testsuite][\"tests\"][testcase][\"result\"].lower()\n                    == \"skipped\"\n                ):\n                    ET.SubElement(\n                        tc,\n                        \"skipped\",\n                        message=self.results[testsuite][\"tests\"][testcase][\"message\"],\n                    )\n                elif (\n                    self.results[testsuite][\"tests\"][testcase][\"result\"].lower()\n                    == \"errored\"\n                ):\n                    ET.SubElement(\n                        tc,\n                        \"error\",\n                        message=self.results[testsuite][\"tests\"][testcase][\"message\"],\n                    )\n        tree = ET.ElementTree(testsuites)\n        if sys.version_info < (3, 9):\n            logging.warning(\n                \"produced output not indent due to lack of support before 3.9\"\n            )\n        else:\n            ET.indent(tree)\n        return tree", "\n\nclass UnittestOutputter:\n    def __init__(self, output_destination):\n        self.output_destination = output_destination\n\n    def write(self, result_set):\n        # First generate the summary\n        result_statuses = {}\n        for status in [\"passed\", \"failed\", \"skipped\", \"errored\"]:\n            result_statuses[status] = sum(\n                [1 for r in result_set.checklist.values() if r.status.value == status]\n            )\n\n        # format the results for processing\n        rows = [v.dict() for v in result_set.checklist.values()]\n\n        # Setup a Formatter and initiate with result totals\n        formatter = UnittestFormatter(\n            name=\"FOCUS Validations\",\n            tests=len(rows),\n            failures=result_statuses[\"failed\"],\n            errors=result_statuses[\"errored\"],\n            skipped=result_statuses[\"skipped\"],\n        )\n\n        # If there are any errors load them in first\n        if result_statuses[\"errored\"]:\n            formatter.add_testsuite(name=\"Base\", column=\"Unknown\")\n            for testcase in [r for r in rows if r.get(\"error\", False)]:\n                formatter.add_testcase(\n                    testsuite=\"Base\",\n                    name=testcase[\"check_name\"],\n                    result=testcase[\"status\"].value,\n                    message=testcase[\"error\"],\n                    check_type_name=None,\n                )\n\n        # Add the testcases to the testsuites\n        added_testsuites = {}\n        for testcase in [\n            r for r in rows if re.match(r\"^FV-[D,M][0-9]{3}-[0-9]{4}$\", r[\"check_name\"])\n        ]:\n            test_suite_id = testcase[\"check_name\"].rsplit(\"-\", 1)[0]\n            if test_suite_id not in added_testsuites:\n                formatter.add_testsuite(\n                    name=test_suite_id, column=testcase[\"column_id\"]\n                )\n\n            formatter.add_testcase(\n                testsuite=test_suite_id,\n                name=testcase[\"check_name\"],\n                result=testcase[\"status\"].value,\n                message=testcase[\"friendly_name\"],\n                check_type_name=testcase[\"rule_ref\"][\"check_type_friendly_name\"],\n            )\n\n        tree = formatter.generate_unittest()\n        tree.write(self.output_destination, encoding=\"utf-8\", xml_declaration=True)", ""]}
{"filename": "tests/test_validate_default_configs.py", "chunked_list": ["import os\nimport re\nfrom itertools import groupby\nfrom unittest import TestCase\n\nimport pandas as pd\n\nfrom focus_validator.config_objects import ChecklistObjectStatus, Rule\nfrom focus_validator.config_objects.common import DataTypeCheck, DataTypes\nfrom focus_validator.rules.spec_rules import SpecRules", "from focus_validator.config_objects.common import DataTypeCheck, DataTypes\nfrom focus_validator.rules.spec_rules import SpecRules\n\n\nclass TestValidateDefaultConfigs(TestCase):\n    def test_version_sets_have_valid_config(self):\n        for root, dirs, _ in os.walk(\n            \"focus_validator/rules/version_sets\", topdown=False\n        ):\n            for version in dirs:\n                spec_rules = SpecRules(\n                    override_filename=None,\n                    rule_set_path=\"focus_validator/rules/version_sets\",\n                    rules_version=version,\n                    column_namespace=None,\n                )\n                spec_rules.load_rules()\n\n                result = spec_rules.validate(focus_data=pd.DataFrame())\n                for check_id in result.checklist.keys():\n                    self.assertIsNot(\n                        result.checklist[check_id].status, ChecklistObjectStatus.ERRORED\n                    )\n\n    def test_default_rules_with_sample_data(self):\n        check_id_pattern = re.compile(r\"FV-[D,M]\\d{3}-\\d{4}$\")\n\n        for root, dirs, files in os.walk(\n            \"focus_validator/rules/version_sets\", topdown=False\n        ):\n            column_test_suites = []\n            for file_path in files:\n                rule_path = os.path.join(root, file_path)\n                rule = Rule.load_yaml(rule_path=rule_path)\n                self.assertIsInstance(rule, Rule)\n\n                column_id = rule.column_id\n                self.assertIsNotNone(re.match(check_id_pattern, rule.check_id))\n\n                check_column_id = rule.check_id.split(\"-\")[1]\n                local_check_id = rule.check_id.split(\"-\")[2]\n                column_test_suites.append((column_id, check_column_id, local_check_id))\n\n            # sort column test suites to allow grouping by column\n            column_test_suites = sorted(column_test_suites, key=lambda item: item[0])\n            for _, test_suites in groupby(column_test_suites, key=lambda item: item[0]):\n                test_suites = list(test_suites)\n                self.assertEqual(\n                    len(set([test_suite[1] for test_suite in test_suites])), 1\n                )\n                local_check_ids = [int(test_suite[2]) for test_suite in test_suites]\n                # check all ids are in order\n                self.assertEqual(\n                    sorted(local_check_ids), list(range(1, len(local_check_ids) + 1))\n                )\n\n    def test_metric_file_format_metric_vs_dimension(self):\n        metric_check_id_pattern = re.compile(r\"FV-M\\d{3}-\\d{4}$\")\n        dimension_check_id_pattern = re.compile(r\"FV-D\\d{3}-\\d{4}$\")\n\n        for root, dirs, files in os.walk(\n            \"focus_validator/rules/version_sets\", topdown=False\n        ):\n            for file_path in files:\n                rule_path = os.path.join(root, file_path)\n                rule = Rule.load_yaml(rule_path=rule_path)\n                self.assertIsInstance(rule, Rule)\n\n                if isinstance(rule.check, DataTypeCheck):\n                    if rule.check.data_type == DataTypes.DECIMAL:\n                        self.assertIsNotNone(\n                            re.match(metric_check_id_pattern, rule.check_id),\n                            \"For metric column type check_id format should be FV-MYYY-YYYY\",\n                        )\n                    else:\n                        self.assertIsNotNone(\n                            re.match(dimension_check_id_pattern, rule.check_id),\n                            \"For metric column type check_id format should be FV-DYYY-YYYY\",\n                        )", ""]}
{"filename": "tests/__init__.py", "chunked_list": [""]}
{"filename": "tests/test_spec_rules_unsupported_version.py", "chunked_list": ["from unittest import TestCase\n\nfrom focus_validator.exceptions import UnsupportedVersion\nfrom focus_validator.rules.spec_rules import SpecRules\n\n\nclass TestSpecRulesUnsupportedVersion(TestCase):\n    def test_load_unsupported_version(self):\n        with self.assertRaises(UnsupportedVersion) as cm:\n            SpecRules(\n                column_namespace=None,\n                rule_set_path=\"focus_validator/rules/version_sets\",\n                rules_version=\"0.1\",\n                override_filename=None,\n            )\n        self.assertEqual(\"FOCUS version 0.1 not supported.\", str(cm.exception))", ""]}
{"filename": "tests/test_main_function.py", "chunked_list": ["from unittest import TestCase\nfrom unittest.mock import patch\n\nfrom focus_validator.main import main\nfrom focus_validator.validator import Validator\n\n\nclass TestMainFunction(TestCase):\n    @patch.object(Validator, \"validate\")\n    def test_required_data_file(self, *_args):\n        with patch(\"sys.argv\", [\"file.py\", \"-h\"]):\n            with self.assertRaises(SystemExit) as cm:\n                main()\n            self.assertEqual(cm.exception.code, 0)\n\n    def test_supported_versions(self):\n        with patch(\"sys.argv\", [\"prog\", \"--supported-versions\"]):\n            try:\n                main()\n            except SystemExit as e:\n                self.assertNotEqual(e.code, 2)\n\n    @patch.object(Validator, \"validate\")\n    def test_data_file(self, *_args):\n        with patch(\"sys.argv\", [\"prog\", \"--data-file\", \"path/to/data.csv\"]):\n            try:\n                main()\n            except SystemExit as e:\n                self.assertNotEqual(e.code, 2)\n\n    @patch.object(Validator, \"validate\")\n    def test_column_namespace(self, *_args):\n        with patch(\n            \"sys.argv\",\n            [\n                \"prog\",\n                \"--data-file\",\n                \"path/to/data.csv\",\n                \"--column-namespace\",\n                \"namespace\",\n            ],\n        ):\n            try:\n                main()\n            except SystemExit as e:\n                self.assertNotEqual(e.code, 2)\n\n    @patch.object(Validator, \"validate\")\n    def test_override_file(self, *_args):\n        with patch(\n            \"sys.argv\",\n            [\n                \"prog\",\n                \"--data-file\",\n                \"path/to/data.csv\",\n                \"--override-file\",\n                \"path/to/override.yaml\",\n            ],\n        ):\n            try:\n                main()\n            except SystemExit as e:\n                self.assertNotEqual(e.code, 2)\n\n    @patch.object(Validator, \"validate\")\n    def test_output_format(self, *_args):\n        with patch(\n            \"sys.argv\",\n            [\"prog\", \"--data-file\", \"path/to/data.csv\", \"--output-format\", \"json\"],\n        ):\n            try:\n                main()\n            except SystemExit as e:\n                self.assertNotEqual(e.code, 2)", ""]}
{"filename": "tests/test_match_check_id_rule_config_file.py", "chunked_list": ["import os\nfrom pathlib import Path\nfrom unittest import TestCase\n\nfrom focus_validator.config_objects import Rule\n\n\nclass TestMatchCheckIdRuleConfigFile(TestCase):\n    def test_match_check_id_in_base_definitions(self):\n        for root, dirs, files in os.walk(\n            \"focus_validator/rules/base_rule_definitions/\", topdown=False\n        ):\n            for name in files:\n                rule_path = os.path.join(root, name)\n                rule = Rule.load_yaml(rule_path=rule_path)\n                self.assertIsInstance(rule, Rule)\n                self.assertEqual(rule.check_id, Path(name).stem)\n\n    def test_version_sets(self):\n        for root, dirs, files in os.walk(\n            \"focus_validator/rules/version_sets\", topdown=False\n        ):\n            for name in files:\n                rule_path = os.path.join(root, name)\n                self.assertTrue(\n                    os.path.islink(rule_path), f\"path not a sym link, {rule_path}\"\n                )\n                self.assertTrue(\n                    Path(rule_path).exists(), f\"invalid sym link, {rule_path}\"\n                )", ""]}
{"filename": "tests/test_invoice_issuer.py", "chunked_list": [""]}
{"filename": "tests/attributes/test_attribute_currency_code.py", "chunked_list": ["from unittest import TestCase\nfrom uuid import uuid4\n\nimport pandas as pd\nfrom pandera.errors import SchemaErrors\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import (\n    ChecklistObjectStatus,\n    DataTypeCheck,", "    ChecklistObjectStatus,\n    DataTypeCheck,\n    DataTypes,\n)\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.rules.spec_rules import ValidationResult\n\n", "\n\n# noinspection DuplicatedCode\nclass TestAttributeCurrencyType(TestCase):\n    def __eval_function__(self, sample_value, should_fail):\n        random_column_id = str(uuid4())\n        random_check_id = str(uuid4())\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=[\n                Rule(\n                    check_id=random_check_id,\n                    column_id=random_column_id,\n                    check=DataTypeCheck(data_type=DataTypes.CURRENCY_CODE),\n                )\n            ]\n        )\n\n        sample_data = pd.DataFrame([{random_column_id: sample_value}])\n\n        try:\n            schema.validate(sample_data, lazy=True)\n            failure_cases = None\n        except SchemaErrors as e:\n            failure_cases = e.failure_cases\n\n        validation_result = ValidationResult(\n            failure_cases=failure_cases, checklist=checklist\n        )\n        validation_result.process_result()\n\n        if should_fail:\n            self.assertIsNotNone(validation_result.failure_cases)\n            records = validation_result.failure_cases.to_dict(orient=\"records\")\n            self.assertEqual(len(records), 1)\n            collected_values = [record[\"Values\"] for record in records]\n            self.assertEqual(collected_values, [sample_value])\n            self.assertEqual(\n                validation_result.checklist[random_check_id].status,\n                ChecklistObjectStatus.FAILED,\n            )\n        else:\n            self.assertIsNone(validation_result.failure_cases)\n            self.assertEqual(\n                validation_result.checklist[random_check_id].status,\n                ChecklistObjectStatus.PASSED,\n            )\n\n    def test_valid_currency_code(self):\n        self.__eval_function__(\"USD\", False)\n\n    def test_valid_currency_code_bad_data_type(self):\n        self.__eval_function__(0, True)\n\n    def test_valid_currency_code_null_value(self):\n        self.__eval_function__(None, False)\n\n    def test_valid_currency_code_empty_string(self):\n        self.__eval_function__(\"\", True)", ""]}
{"filename": "tests/attributes/test_attribute_datetime.py", "chunked_list": ["from unittest import TestCase\nfrom uuid import uuid4\n\nimport pandas as pd\nfrom pandera.errors import SchemaErrors\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import (\n    ChecklistObjectStatus,\n    DataTypeCheck,", "    ChecklistObjectStatus,\n    DataTypeCheck,\n    DataTypes,\n)\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.rules.spec_rules import ValidationResult\n\n", "\n\n# noinspection DuplicatedCode\nclass TestAttributeDatetime(TestCase):\n    def __eval_function__(self, sample_value, should_fail):\n        random_column_id = str(uuid4())\n        random_check_id = str(uuid4())\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=[\n                Rule(\n                    check_id=random_check_id,\n                    column_id=random_column_id,\n                    check=DataTypeCheck(data_type=DataTypes.DATETIME),\n                )\n            ]\n        )\n\n        sample_data = pd.DataFrame([{random_column_id: sample_value}])\n\n        try:\n            schema.validate(sample_data, lazy=True)\n            failure_cases = None\n        except SchemaErrors as e:\n            failure_cases = e.failure_cases\n\n        validation_result = ValidationResult(\n            failure_cases=failure_cases, checklist=checklist\n        )\n        validation_result.process_result()\n\n        if should_fail:\n            self.assertIsNotNone(validation_result.failure_cases)\n            records = validation_result.failure_cases.to_dict(orient=\"records\")\n            self.assertEqual(len(records), 1)\n            collected_values = [record[\"Values\"] for record in records]\n            self.assertEqual(collected_values, [sample_value])\n            self.assertEqual(\n                validation_result.checklist[random_check_id].status,\n                ChecklistObjectStatus.FAILED,\n            )\n        else:\n            self.assertIsNone(validation_result.failure_cases)\n            self.assertEqual(\n                validation_result.checklist[random_check_id].status,\n                ChecklistObjectStatus.PASSED,\n            )\n\n    def test_null_value(self):\n        self.__eval_function__(None, False)\n\n    def test_month_without_padding(self):\n        self.__eval_function__(\"2023-5-12T21:00:00Z\", True)\n\n    def test_day_without_padding(self):\n        self.__eval_function__(\"2023-05-1T21:00:00Z\", True)\n\n    def test_hour_without_padding(self):\n        self.__eval_function__(\"2023-05-01T1:00:00Z\", True)\n\n    def test_minute_without_padding(self):\n        self.__eval_function__(\"2023-05-01T21:0:00Z\", True)\n\n    def test_second_without_padding(self):\n        self.__eval_function__(\"2023-05-01T21:00:5Z\", True)\n\n    def test_bad_data_type(self):\n        self.__eval_function__(0, True)\n\n    def test_empty_string(self):\n        self.__eval_function__(\"\", True)\n\n    def test_string_without_termination_character(self):\n        self.__eval_function__(\"2023-05-01T21:00:05\", True)\n\n    def test_valid_iso_string(self):\n        self.__eval_function__(\"2023-05-01T21:00:05Z\", False)", ""]}
{"filename": "tests/checks/test_null_value_check.py", "chunked_list": ["from unittest import TestCase\n\nimport pandas as pd\nfrom pandera.errors import SchemaErrors\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import (\n    AllowNullsCheck,\n    ChecklistObjectStatus,\n    DataTypeCheck,", "    ChecklistObjectStatus,\n    DataTypeCheck,\n    DataTypes,\n)\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.rules.spec_rules import ValidationResult\n\n", "\n\n# noinspection DuplicatedCode\nclass TestNullValueCheck(TestCase):\n    @staticmethod\n    def __generate_sample_rule_type_string__(allow_nulls: bool, data_type: DataTypes):\n        return [\n            Rule(\n                check_id=\"allow_null\",\n                column_id=\"test_dimension\",\n                check=AllowNullsCheck(allow_nulls=allow_nulls),\n            ),\n            Rule(\n                check_id=\"test_dimension\",\n                column_id=\"test_dimension\",\n                check=DataTypeCheck(data_type=data_type),\n            ),\n        ]\n\n    @staticmethod\n    def __validate_helper__(schema, checklist, sample_data):\n        try:\n            schema.validate(sample_data, lazy=True)\n            failure_cases = None\n        except SchemaErrors as e:\n            failure_cases = e.failure_cases\n\n        validation_result = ValidationResult(\n            checklist=checklist, failure_cases=failure_cases\n        )\n        validation_result.process_result()\n        return validation_result\n\n    def test_null_value_allowed_valid_case(self):\n        rules = self.__generate_sample_rule_type_string__(\n            allow_nulls=True, data_type=DataTypes.STRING\n        )\n        sample_data = pd.DataFrame(\n            [{\"test_dimension\": \"NULL\"}, {\"test_dimension\": \"some-value\"}]\n        )\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        validation_result = self.__validate_helper__(\n            schema=schema, checklist=checklist, sample_data=sample_data\n        )\n        self.assertIsNone(validation_result.failure_cases)\n\n    def test_null_value_not_allowed_valid_case(self):\n        rules = self.__generate_sample_rule_type_string__(\n            allow_nulls=False, data_type=DataTypes.STRING\n        )\n        sample_data = pd.DataFrame(\n            [{\"test_dimension\": \"val1\"}, {\"test_dimension\": \"val2\"}]\n        )\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        validation_result = self.__validate_helper__(\n            schema=schema, checklist=checklist, sample_data=sample_data\n        )\n        self.assertIsNone(validation_result.failure_cases)\n\n    def test_null_value_not_allowed_invalid_case(self):\n        rules = self.__generate_sample_rule_type_string__(\n            allow_nulls=False, data_type=DataTypes.STRING\n        )\n        sample_data = pd.DataFrame(\n            [{\"test_dimension\": \"NULL\"}, {\"test_dimension\": \"val2\"}]\n        )\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        validation_result = self.__validate_helper__(\n            schema=schema, checklist=checklist, sample_data=sample_data\n        )\n        self.assertEqual(\n            validation_result.checklist[\"allow_null\"].status,\n            ChecklistObjectStatus.FAILED,\n        )\n        self.assertIsNotNone(validation_result.failure_cases)\n        failure_cases_dict = validation_result.failure_cases.to_dict(orient=\"records\")\n        self.assertEqual(len(failure_cases_dict), 1)\n        self.assertEqual(\n            failure_cases_dict[0],\n            {\n                \"Column\": \"test_dimension\",\n                \"Check Name\": \"allow_null\",\n                \"Description\": \" test_dimension does not allow null values.\",\n                \"Values\": \"NULL\",\n                \"Row #\": 1,\n            },\n        )\n\n    def test_null_value_allowed_invalid_case_with_empty_strings(self):\n        rules = self.__generate_sample_rule_type_string__(\n            allow_nulls=True, data_type=DataTypes.STRING\n        )\n        sample_data = pd.DataFrame([{\"test_dimension\": \"NULL\"}, {\"test_dimension\": \"\"}])\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        validation_result = self.__validate_helper__(\n            schema=schema, checklist=checklist, sample_data=sample_data\n        )\n        self.assertEqual(\n            validation_result.checklist[\"allow_null\"].status,\n            ChecklistObjectStatus.FAILED,\n        )\n        self.assertIsNotNone(validation_result.failure_cases)\n        failure_cases_dict = validation_result.failure_cases.to_dict(orient=\"records\")\n        self.assertEqual(len(failure_cases_dict), 1)\n        self.assertEqual(\n            failure_cases_dict[0],\n            {\n                \"Column\": \"test_dimension\",\n                \"Check Name\": \"allow_null\",\n                \"Description\": \" test_dimension allows null values.\",\n                \"Values\": \"\",\n                \"Row #\": 2,\n            },\n        )\n\n    def test_null_value_allowed_invalid_case_with_nan_values(self):\n        rules = self.__generate_sample_rule_type_string__(\n            allow_nulls=True, data_type=DataTypes.STRING\n        )\n        sample_data = pd.DataFrame(\n            [{\"test_dimension\": \"NULL\"}, {\"test_dimension\": None}]\n        )\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        validation_result = self.__validate_helper__(\n            schema=schema, checklist=checklist, sample_data=sample_data\n        )\n        self.assertEqual(\n            validation_result.checklist[\"allow_null\"].status,\n            ChecklistObjectStatus.FAILED,\n        )\n        self.assertIsNotNone(validation_result.failure_cases)\n        failure_cases_dict = validation_result.failure_cases.to_dict(orient=\"records\")\n        self.assertEqual(len(failure_cases_dict), 1)\n        self.assertEqual(\n            failure_cases_dict[0],\n            {\n                \"Column\": \"test_dimension\",\n                \"Check Name\": \"allow_null\",\n                \"Description\": \" test_dimension allows null values.\",\n                \"Values\": None,\n                \"Row #\": 2,\n            },\n        )", ""]}
{"filename": "tests/checks/test_decimal_type_check.py", "chunked_list": ["from unittest import TestCase\nfrom uuid import uuid4\n\nimport numpy\nimport pandas as pd\nfrom pandera.errors import SchemaErrors\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import DataTypeCheck, DataTypes\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (", "from focus_validator.config_objects.common import DataTypeCheck, DataTypes\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.rules.spec_rules import ValidationResult\n\n\nclass TestDecimalTypeCheck(TestCase):\n    def test_decimal_column(self):\n        random_column_id = str(uuid4())\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=[\n                Rule(\n                    check_id=random_column_id,\n                    column_id=random_column_id,\n                    check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n                ),\n            ]\n        )\n\n        sample_df = pd.DataFrame(\n            [\n                {random_column_id: 0.1},\n                {random_column_id: 1},\n                {random_column_id: 1.001},\n            ]\n        )\n        values = schema.validate(sample_df)[random_column_id].values\n        self.assertEqual(list(values), [0.1, 1.0, 1.001])\n\n    def test_decimal_column_bad_data_type(self):\n        random_column_id = str(uuid4())\n        random_check_name = str(uuid4())\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=[\n                Rule(\n                    check_id=\"some-check\",\n                    column_id=random_column_id,\n                    check=\"column_required\",\n                ),\n                Rule(\n                    check_id=random_check_name,\n                    column_id=random_column_id,\n                    check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n                ),\n            ]\n        )\n\n        sample_df = pd.DataFrame(\n            [\n                {random_column_id: \"a\"},\n                {random_column_id: 1},\n                {random_column_id: 1.001},\n            ]\n        )\n        try:\n            schema.validate(sample_df, lazy=True)\n            failure_cases = None\n        except SchemaErrors as e:\n            failure_cases = e.failure_cases\n\n        result = ValidationResult(checklist=checklist, failure_cases=failure_cases)\n        result.process_result()\n        self.assertEqual(\n            result.failure_cases.to_dict(orient=\"records\"),\n            [\n                {\n                    \"Column\": random_column_id,\n                    \"Check Name\": random_check_name,\n                    \"Description\": \"Ensures that column is of decimal type.\",\n                    \"Values\": None,\n                    \"Row #\": numpy.NaN,\n                }\n            ],\n        )", ""]}
{"filename": "tests/data_loaders/__init__.py", "chunked_list": [""]}
{"filename": "tests/data_loaders/test_null_value_loader.py", "chunked_list": ["import io\nfrom unittest import TestCase\n\nimport pandas as pd\n\nfrom focus_validator.data_loaders.csv_data_loader import CSVDataLoader\nfrom focus_validator.data_loaders.parquet_data_loader import ParquetDataLoader\n\n\nclass TestNullValueLoader(TestCase):\n    def test_null_value_from_csv(self):\n        sample_data = pd.DataFrame([{\"value\": \"NULL\"}])\n\n        buffer = io.BytesIO()\n        sample_data.to_csv(buffer, index=False)\n\n        buffer.seek(0)\n        self.assertEqual(buffer.read(), b\"value\\nNULL\\n\")\n\n        buffer.seek(0)\n        loader = CSVDataLoader(buffer)\n        data = loader.load()\n\n        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"NULL\"})\n\n    def test_null_value_from_csv_with_missing_value(self):\n        sample_data = pd.DataFrame([{\"value\": None}])\n\n        buffer = io.BytesIO()\n        sample_data.to_csv(buffer, index=False)\n\n        buffer.seek(0)\n        self.assertEqual(buffer.read(), b'value\\n\"\"\\n')\n\n        buffer.seek(0)\n        loader = CSVDataLoader(buffer)\n        data = loader.load()\n\n        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"\"})\n\n    def test_null_value_from_parquet(self):\n        sample_data = pd.DataFrame([{\"value\": \"NULL\"}])\n\n        buffer = io.BytesIO()\n        sample_data.to_parquet(buffer, index=False)\n\n        buffer.seek(0)\n        loader = ParquetDataLoader(buffer)\n        data = loader.load()\n\n        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"NULL\"})", "\nclass TestNullValueLoader(TestCase):\n    def test_null_value_from_csv(self):\n        sample_data = pd.DataFrame([{\"value\": \"NULL\"}])\n\n        buffer = io.BytesIO()\n        sample_data.to_csv(buffer, index=False)\n\n        buffer.seek(0)\n        self.assertEqual(buffer.read(), b\"value\\nNULL\\n\")\n\n        buffer.seek(0)\n        loader = CSVDataLoader(buffer)\n        data = loader.load()\n\n        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"NULL\"})\n\n    def test_null_value_from_csv_with_missing_value(self):\n        sample_data = pd.DataFrame([{\"value\": None}])\n\n        buffer = io.BytesIO()\n        sample_data.to_csv(buffer, index=False)\n\n        buffer.seek(0)\n        self.assertEqual(buffer.read(), b'value\\n\"\"\\n')\n\n        buffer.seek(0)\n        loader = CSVDataLoader(buffer)\n        data = loader.load()\n\n        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"\"})\n\n    def test_null_value_from_parquet(self):\n        sample_data = pd.DataFrame([{\"value\": \"NULL\"}])\n\n        buffer = io.BytesIO()\n        sample_data.to_parquet(buffer, index=False)\n\n        buffer.seek(0)\n        loader = ParquetDataLoader(buffer)\n        data = loader.load()\n\n        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"NULL\"})", ""]}
{"filename": "tests/data_loaders/test_parquet_loader.py", "chunked_list": ["from unittest import TestCase\n\nimport pandas as pd\n\nfrom focus_validator.data_loaders.data_loader import DataLoader\nfrom focus_validator.data_loaders.parquet_data_loader import ParquetDataLoader\n\n\nclass TestParquetLoader(TestCase):\n    def test_load_parquet_file(self):\n        data_loader = DataLoader(data_filename=\"tests/samples/sample.parquet\")\n        df = data_loader.load()\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(\n            list(df.columns), [\"InvoiceIssuer\", \"ResourceID\", \"ChargeType\"]\n        )\n\n    def test_find_data_loader(self):\n        data_loader = DataLoader(data_filename=\"tests/samples/sample.parquet\")\n        data_loader_class = data_loader.find_data_loader()\n        self.assertEqual(data_loader_class, ParquetDataLoader)", "class TestParquetLoader(TestCase):\n    def test_load_parquet_file(self):\n        data_loader = DataLoader(data_filename=\"tests/samples/sample.parquet\")\n        df = data_loader.load()\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(\n            list(df.columns), [\"InvoiceIssuer\", \"ResourceID\", \"ChargeType\"]\n        )\n\n    def test_find_data_loader(self):\n        data_loader = DataLoader(data_filename=\"tests/samples/sample.parquet\")\n        data_loader_class = data_loader.find_data_loader()\n        self.assertEqual(data_loader_class, ParquetDataLoader)", ""]}
{"filename": "tests/config_objects/test_load_bad_rule_config_file.py", "chunked_list": ["from unittest import TestCase\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import ChecklistObjectStatus\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.config_objects.rule import InvalidRule\n\n\nclass TestLoadBadRuleConfigFile(TestCase):\n    def test_load_empty_config(self):\n        rule = Rule.load_yaml(\n            \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n        )\n        self.assertIsInstance(rule, InvalidRule)\n\n    def test_load_incomplete_config(self):\n        rule = Rule.load_yaml(\n            \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n        )\n        self.assertIsInstance(rule, InvalidRule)\n\n    def test_load_bad_yaml(self):\n        rule = Rule.load_yaml(\n            \"tests/samples/rule_configs/bad_rule_config_invalid_yaml.yaml\"\n        )\n        self.assertIsInstance(rule, InvalidRule)\n\n    def test_load_valid_rule(self):\n        rule = Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\")\n        self.assertIsInstance(rule, Rule)\n\n    def test_load_schema(self):\n        rules = [\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n            ),\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n            ),\n            Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n            ),\n        ]\n\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        self.assertEqual(\n            checklist[\"FV-D001-0001\"].status, ChecklistObjectStatus.PENDING\n        )\n        self.assertIsNone(checklist[\"FV-D001-0001\"].error)\n        self.assertIsNotNone(checklist[\"FV-D001-0001\"].friendly_name)\n\n        self.assertEqual(checklist[\"FV-D001\"].column_id, \"ChargeType\")\n        self.assertEqual(checklist[\"FV-D001\"].status, ChecklistObjectStatus.PENDING)\n        self.assertIsNone(checklist[\"FV-D001\"].error)\n        self.assertIsNotNone(checklist[\"FV-D001\"].friendly_name)\n        self.assertEqual(\n            checklist[\"FV-D001\"].friendly_name, \"Ensures that column is of string type.\"\n        )\n\n        for errored_file_paths in [\n            \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\",\n            \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\",\n        ]:\n            self.assertEqual(\n                checklist[errored_file_paths].status, ChecklistObjectStatus.ERRORED\n            )\n            self.assertIsNotNone(checklist[errored_file_paths].error)\n            self.assertIsNone(checklist[errored_file_paths].friendly_name)\n            self.assertEqual(checklist[errored_file_paths].column_id, \"Unknown\")\n\n    def test_load_schema_without_valid_column_metadata(self):\n        rules = [\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n            ),\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n            ),\n            Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n        ]\n\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        self.assertEqual(\n            checklist[\"FV-D001-0001\"].status, ChecklistObjectStatus.ERRORED\n        )\n        self.assertEqual(\n            checklist[\"FV-D001-0001\"].error,\n            \"ConfigurationError: No configuration found for column.\",\n        )\n        self.assertIsNotNone(checklist[\"FV-D001-0001\"].friendly_name)\n        self.assertEqual(checklist[\"FV-D001-0001\"].column_id, \"ChargeType\")", "\n\nclass TestLoadBadRuleConfigFile(TestCase):\n    def test_load_empty_config(self):\n        rule = Rule.load_yaml(\n            \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n        )\n        self.assertIsInstance(rule, InvalidRule)\n\n    def test_load_incomplete_config(self):\n        rule = Rule.load_yaml(\n            \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n        )\n        self.assertIsInstance(rule, InvalidRule)\n\n    def test_load_bad_yaml(self):\n        rule = Rule.load_yaml(\n            \"tests/samples/rule_configs/bad_rule_config_invalid_yaml.yaml\"\n        )\n        self.assertIsInstance(rule, InvalidRule)\n\n    def test_load_valid_rule(self):\n        rule = Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\")\n        self.assertIsInstance(rule, Rule)\n\n    def test_load_schema(self):\n        rules = [\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n            ),\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n            ),\n            Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n            ),\n        ]\n\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        self.assertEqual(\n            checklist[\"FV-D001-0001\"].status, ChecklistObjectStatus.PENDING\n        )\n        self.assertIsNone(checklist[\"FV-D001-0001\"].error)\n        self.assertIsNotNone(checklist[\"FV-D001-0001\"].friendly_name)\n\n        self.assertEqual(checklist[\"FV-D001\"].column_id, \"ChargeType\")\n        self.assertEqual(checklist[\"FV-D001\"].status, ChecklistObjectStatus.PENDING)\n        self.assertIsNone(checklist[\"FV-D001\"].error)\n        self.assertIsNotNone(checklist[\"FV-D001\"].friendly_name)\n        self.assertEqual(\n            checklist[\"FV-D001\"].friendly_name, \"Ensures that column is of string type.\"\n        )\n\n        for errored_file_paths in [\n            \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\",\n            \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\",\n        ]:\n            self.assertEqual(\n                checklist[errored_file_paths].status, ChecklistObjectStatus.ERRORED\n            )\n            self.assertIsNotNone(checklist[errored_file_paths].error)\n            self.assertIsNone(checklist[errored_file_paths].friendly_name)\n            self.assertEqual(checklist[errored_file_paths].column_id, \"Unknown\")\n\n    def test_load_schema_without_valid_column_metadata(self):\n        rules = [\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n            ),\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n            ),\n            Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n        ]\n\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=None\n        )\n        self.assertEqual(\n            checklist[\"FV-D001-0001\"].status, ChecklistObjectStatus.ERRORED\n        )\n        self.assertEqual(\n            checklist[\"FV-D001-0001\"].error,\n            \"ConfigurationError: No configuration found for column.\",\n        )\n        self.assertIsNotNone(checklist[\"FV-D001-0001\"].friendly_name)\n        self.assertEqual(checklist[\"FV-D001-0001\"].column_id, \"ChargeType\")", ""]}
{"filename": "tests/config_objects/test_check_friendly_name.py", "chunked_list": ["from unittest import TestCase\nfrom uuid import uuid4\n\nfrom polyfactory.factories.pydantic_factory import ModelFactory\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import (\n    AllowNullsCheck,\n    DataTypeCheck,\n    ValueInCheck,", "    DataTypeCheck,\n    ValueInCheck,\n)\n\n\nclass TestCheckFriendlyName(TestCase):\n    def test_default_friendly_name_is_generated(self):\n        random_column_name = str(uuid4())\n\n        model_factory = ModelFactory.create_factory(\n            model=Rule, check_friendly_name=None, column_id=random_column_name\n        )\n\n        for _ in range(1000):  # there is no way to generate all values for a field type\n            random_model = model_factory.build()\n            if random_model.check == \"column_required\":\n                self.assertEqual(\n                    random_model.check_friendly_name,\n                    f\"{random_column_name} is a required column.\",\n                )\n            elif random_model.check == \"check_unique\":\n                self.assertEqual(\n                    random_model.check_friendly_name,\n                    f\"{random_column_name}, requires unique values.\",\n                )\n            elif isinstance(random_model.check, AllowNullsCheck):\n                if random_model.check.allow_nulls:\n                    self.assertEqual(\n                        random_model.check_friendly_name,\n                        f\"{random_column_name} allows null values.\",\n                    )\n                else:\n                    self.assertEqual(\n                        random_model.check_friendly_name,\n                        f\"{random_column_name} does not allow null values.\",\n                    )\n            elif isinstance(random_model.check, DataTypeCheck):\n                self.assertEqual(\n                    random_model.check_friendly_name,\n                    f\"{random_column_name} requires values of type {random_model.check.data_type.value}.\",\n                )\n            elif isinstance(random_model.check, ValueInCheck):\n                options = \",\".join(random_model.check.value_in)\n                self.assertEqual(\n                    random_model.check_friendly_name,\n                    f\"{random_column_name} must have a value from the list: {options}.\",\n                )\n            else:\n                raise NotImplementedError(\n                    f\"check_type: {random_model.check} not implemented\"\n                )\n\n    def test_override_friendly_name(self):\n        random_friendly_name = str(uuid4())\n\n        sample_rule = Rule(\n            check=\"check_unique\",\n            check_id=\"sample-check\",\n            column_id=\"sample-column\",\n            check_friendly_name=random_friendly_name,\n        )\n        self.assertIsNotNone(random_friendly_name, sample_rule.check_friendly_name)", ""]}
{"filename": "tests/config_objects/test_required_column.py", "chunked_list": ["from unittest import TestCase\nfrom uuid import uuid4\n\nimport pandas as pd\nfrom pandera.errors import SchemaErrors\n\nfrom focus_validator.config_objects import Override, Rule\nfrom focus_validator.config_objects.common import DataTypeCheck, DataTypes\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,", "from focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.rules.spec_rules import ValidationResult\n\n\nclass TestRequiredColumn(TestCase):\n    def test_load_column_required_config(self):\n        rules = [\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n            ),\n            Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/valid_rule_config_required.yaml\"\n            ),\n        ]\n        schema, _ = FocusToPanderaSchemaConverter.generate_pandera_schema(rules=rules)\n        self.assertIn(\"ChargeType\", schema.columns)\n        self.assertTrue(schema.columns[\"ChargeType\"].required)\n\n    def test_load_column_required_config_but_ignored(self):\n        rules = [\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n            ),\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/valid_rule_config_required.yaml\"\n            ),\n        ]\n        schema, _ = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules, override_config=Override(overrides=[\"FV-D001-0001\"])\n        )\n        self.assertIn(\"ChargeType\", schema.columns)\n        self.assertFalse(schema.columns[\"ChargeType\"].required)\n\n    def test_check_summary_has_correct_mappings(self):\n        random_column_id = str(uuid4())\n        random_test_name = str(uuid4())\n\n        sample_data = pd.read_csv(\"tests/samples/multiple_failure_examples.csv\")\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=[\n                Rule(\n                    check_id=str(uuid4()),\n                    column_id=random_column_id,\n                    check=DataTypeCheck(data_type=DataTypes.STRING),\n                ),\n                Rule(\n                    check_id=random_test_name,\n                    column_id=random_column_id,\n                    check=\"column_required\",\n                    check_friendly_name=\"Column required.\",\n                ),\n                Rule.load_yaml(\n                    \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n                ),\n                Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n            ]\n        )\n\n        with self.assertRaises(SchemaErrors) as cm:\n            schema.validate(sample_data, lazy=True)\n\n        failure_cases = cm.exception.failure_cases\n        result = ValidationResult(failure_cases=failure_cases, checklist=checklist)\n        result.process_result()\n\n        self.assertEqual(result.failure_cases.shape[0], 4)\n        missing_column_errors = result.failure_cases[\n            result.failure_cases[\"Column\"] == random_column_id\n        ]\n\n        raw_values = missing_column_errors.to_dict()\n        self.assertEqual(raw_values[\"Column\"], {1: random_column_id})\n        self.assertEqual(raw_values[\"Check Name\"], {1: random_test_name})\n        self.assertEqual(\n            raw_values[\"Description\"],\n            {1: \"Column required.\"},\n        )\n        self.assertEqual(raw_values[\"Values\"], {1: None})", ""]}
{"filename": "tests/config_objects/test_friendly_name_in_values_template.py", "chunked_list": ["from unittest import TestCase\nfrom uuid import uuid4\n\nimport pandera as pa\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import ValueInCheck\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)", "    FocusToPanderaSchemaConverter,\n)\n\n\nclass TestFriendlyNameInValuesTemplate(TestCase):\n    def test_check_value_in(self):\n        rule = Rule(\n            check_id=str(uuid4()),\n            column_id=str(uuid4()),\n            check=ValueInCheck(value_in=[\"foo\", \"bar\"]),\n            check_friendly_name=\"Values in {values}\",\n        )\n        pa_check = FocusToPanderaSchemaConverter.__generate_pandera_check__(\n            rule=rule, check_id=str(uuid4())\n        )\n        self.assertIsInstance(pa_check, pa.Check)", ""]}
{"filename": "tests/config_objects/__init__.py", "chunked_list": [""]}
{"filename": "tests/config_objects/test_column_namespace.py", "chunked_list": ["from unittest import TestCase\nfrom uuid import uuid4\n\nimport pandas as pd\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import (\n    AllowNullsCheck,\n    DataTypeCheck,\n    DataTypes,", "    DataTypeCheck,\n    DataTypes,\n)\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.validator import Validator\n\n\nclass TestColumnNamespace(TestCase):\n    def test_load_rule_config_with_namespace(self):\n        validator = Validator(\n            data_filename=\"tests/samples/multiple_failure_example_namespaced.csv\",\n            output_type=\"console\",\n            output_destination=None,\n            column_namespace=\"F\",\n        )\n        validator.load()\n        result = validator.spec_rules.validate(focus_data=validator.focus_data)\n        self.assertIsNotNone(result.failure_cases)\n\n    def test_load_rule_config_without_namespace(self):\n        random_column_id = str(uuid4())\n        random_test_name = str(uuid4())\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=[\n                Rule(\n                    check_id=random_test_name,\n                    column_id=random_column_id,\n                    check=DataTypeCheck(data_type=DataTypes.STRING),\n                ),\n                Rule(\n                    check_id=random_test_name,\n                    column_id=random_column_id,\n                    check=AllowNullsCheck(allow_nulls=False),\n                ),\n            ]\n        )\n\n        sample_data = pd.read_csv(\n            \"tests/samples/multiple_failure_example_namespaced.csv\"\n        )\n        result = schema.validate(\n            sample_data\n        )  # should not fail as columns are namespaced\n        self.assertIsNotNone(result)", "\nclass TestColumnNamespace(TestCase):\n    def test_load_rule_config_with_namespace(self):\n        validator = Validator(\n            data_filename=\"tests/samples/multiple_failure_example_namespaced.csv\",\n            output_type=\"console\",\n            output_destination=None,\n            column_namespace=\"F\",\n        )\n        validator.load()\n        result = validator.spec_rules.validate(focus_data=validator.focus_data)\n        self.assertIsNotNone(result.failure_cases)\n\n    def test_load_rule_config_without_namespace(self):\n        random_column_id = str(uuid4())\n        random_test_name = str(uuid4())\n\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=[\n                Rule(\n                    check_id=random_test_name,\n                    column_id=random_column_id,\n                    check=DataTypeCheck(data_type=DataTypes.STRING),\n                ),\n                Rule(\n                    check_id=random_test_name,\n                    column_id=random_column_id,\n                    check=AllowNullsCheck(allow_nulls=False),\n                ),\n            ]\n        )\n\n        sample_data = pd.read_csv(\n            \"tests/samples/multiple_failure_example_namespaced.csv\"\n        )\n        result = schema.validate(\n            sample_data\n        )  # should not fail as columns are namespaced\n        self.assertIsNotNone(result)", ""]}
{"filename": "tests/config_objects/test_load_base_rules_only.py", "chunked_list": ["from unittest import TestCase\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\n\n\nclass TestLoadBaseRulesOnly(TestCase):\n    \"\"\"\n    Ensures column config with only base config can enforce validations.\n    \"\"\"\n\n    def test_load_without_any_subsequent_rules(self):\n        rules = [\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n            )\n        ]\n        schema, _ = FocusToPanderaSchemaConverter.generate_pandera_schema(rules=rules)\n        self.assertIn(\"ChargeType\", schema.columns)", "class TestLoadBaseRulesOnly(TestCase):\n    \"\"\"\n    Ensures column config with only base config can enforce validations.\n    \"\"\"\n\n    def test_load_without_any_subsequent_rules(self):\n        rules = [\n            Rule.load_yaml(\n                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n            )\n        ]\n        schema, _ = FocusToPanderaSchemaConverter.generate_pandera_schema(rules=rules)\n        self.assertIn(\"ChargeType\", schema.columns)", ""]}
{"filename": "tests/config_objects/test_check_type_friendly_name.py", "chunked_list": ["from unittest import TestCase\nfrom uuid import uuid4\n\nfrom polyfactory.factories.pydantic_factory import ModelFactory\nfrom pydantic import ValidationError\n\nfrom focus_validator.config_objects import Rule\nfrom focus_validator.config_objects.common import DataTypes, DataTypeCheck\n\n\nclass TestCheckTypeFriendlyName(TestCase):\n    def test_generate_name_for_check_types(self):\n        \"\"\"\n        there is no way to generate all values for a field type hence generating random instances\n        in hope of catching any validation error\n        :return:\n        \"\"\"\n        model_factory = ModelFactory.create_factory(model=Rule)\n\n        for _ in range(1000):  # there is no way to generate all values for a field type\n            random_model = model_factory.build()\n            self.assertIn(\n                random_model.check_type_friendly_name,\n                [\n                    \"CheckUnique\",\n                    \"AllowNullsCheck\",\n                    \"ValueInCheck\",\n                    \"ColumnRequired\",\n                    \"DataTypeCheck\",\n                ],  # needs to be updated as more checks are introduced\n            )\n\n    def test_random_value_is_ignored(self):\n        sample = Rule(\n            check_id=str(uuid4()),\n            column_id=str(uuid4()),\n            check=\"check_unique\",\n            check_friendly_name=\"some-check\",\n            check_type_friendly_name=\"some-name\",\n        )\n        self.assertEqual(sample.check_type_friendly_name, \"CheckUnique\")\n\n    def test_data_type_config(self):\n        model_factory = ModelFactory.create_factory(model=Rule)\n\n        sample_data_type = model_factory.build(\n            **{\"check\": DataTypeCheck(data_type=DataTypes.STRING)}\n        )\n        self.assertEqual(sample_data_type.check_type_friendly_name, \"DataTypeCheck\")\n\n    def test_check_type_config_deny_update(self):\n        model_factory = ModelFactory.create_factory(model=Rule)\n\n        sample_data_type = model_factory.build()\n        with self.assertRaises(TypeError) as cm:\n            sample_data_type.check_type_friendly_name = \"new_value\"\n        self.assertIn(\n            '\"Rule\" is immutable and does not support item assignment',\n            str(cm.exception),\n        )\n\n    def test_assign_bad_type(self):\n        with self.assertRaises(ValidationError) as cm:\n            Rule(\n                check_id=str(uuid4()),\n                column_id=str(uuid4()),\n                check=DataTypeCheck(data_type=\"bad-type\"),\n                check_type_friendly_name=\"some-check\",\n            )\n        self.assertEqual(len(cm.exception.errors()), 1)\n        self.assertIn(\n            \"value is not a valid enumeration member; permitted:\", str(cm.exception)\n        )", "\n\nclass TestCheckTypeFriendlyName(TestCase):\n    def test_generate_name_for_check_types(self):\n        \"\"\"\n        there is no way to generate all values for a field type hence generating random instances\n        in hope of catching any validation error\n        :return:\n        \"\"\"\n        model_factory = ModelFactory.create_factory(model=Rule)\n\n        for _ in range(1000):  # there is no way to generate all values for a field type\n            random_model = model_factory.build()\n            self.assertIn(\n                random_model.check_type_friendly_name,\n                [\n                    \"CheckUnique\",\n                    \"AllowNullsCheck\",\n                    \"ValueInCheck\",\n                    \"ColumnRequired\",\n                    \"DataTypeCheck\",\n                ],  # needs to be updated as more checks are introduced\n            )\n\n    def test_random_value_is_ignored(self):\n        sample = Rule(\n            check_id=str(uuid4()),\n            column_id=str(uuid4()),\n            check=\"check_unique\",\n            check_friendly_name=\"some-check\",\n            check_type_friendly_name=\"some-name\",\n        )\n        self.assertEqual(sample.check_type_friendly_name, \"CheckUnique\")\n\n    def test_data_type_config(self):\n        model_factory = ModelFactory.create_factory(model=Rule)\n\n        sample_data_type = model_factory.build(\n            **{\"check\": DataTypeCheck(data_type=DataTypes.STRING)}\n        )\n        self.assertEqual(sample_data_type.check_type_friendly_name, \"DataTypeCheck\")\n\n    def test_check_type_config_deny_update(self):\n        model_factory = ModelFactory.create_factory(model=Rule)\n\n        sample_data_type = model_factory.build()\n        with self.assertRaises(TypeError) as cm:\n            sample_data_type.check_type_friendly_name = \"new_value\"\n        self.assertIn(\n            '\"Rule\" is immutable and does not support item assignment',\n            str(cm.exception),\n        )\n\n    def test_assign_bad_type(self):\n        with self.assertRaises(ValidationError) as cm:\n            Rule(\n                check_id=str(uuid4()),\n                column_id=str(uuid4()),\n                check=DataTypeCheck(data_type=\"bad-type\"),\n                check_type_friendly_name=\"some-check\",\n            )\n        self.assertEqual(len(cm.exception.errors()), 1)\n        self.assertIn(\n            \"value is not a valid enumeration member; permitted:\", str(cm.exception)\n        )", ""]}
{"filename": "tests/outputter/test_outputter_unittest.py", "chunked_list": ["import io\nimport xml.etree.cElementTree as ET\nfrom random import randint\nfrom unittest import TestCase\nfrom uuid import uuid4\n\nfrom focus_validator.config_objects import InvalidRule, Rule\nfrom focus_validator.config_objects.common import DataTypeCheck, DataTypes\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,", "from focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.outputter.outputter_unittest import UnittestOutputter\nfrom focus_validator.rules.spec_rules import ValidationResult\n\n\n# noinspection DuplicatedCode\nclass TestOutputterUnittest(TestCase):\n    def test_unittest_output_all_valid_rules(self):\n        random_check_id = f\"FV-D00{randint(0, 9)}\"\n        random_column_id = str(uuid4())\n\n        rules = [\n            Rule(\n                check_id=f\"{random_check_id}-0001\",\n                column_id=random_column_id,\n                check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n            ),\n            Rule(\n                check_id=f\"{random_check_id}-0002\",\n                column_id=random_column_id,\n                check=\"column_required\",\n            ),\n        ]\n\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules\n        )\n        result = ValidationResult(checklist=checklist)\n        result.process_result()\n\n        buffer = io.BytesIO()\n        outputter = UnittestOutputter(output_destination=buffer)\n        outputter.write(result_set=result)\n\n        buffer.seek(0)\n        output = buffer.read()\n        testsuites = ET.fromstring(output)\n        self.assertEqual(len(testsuites), 1)  # assert one column in sample rules config\n        self.assertEqual(testsuites.get(\"name\"), \"FOCUS Validations\")\n        for testsuite in testsuites:\n            self.assertEqual(\n                testsuite.get(\"name\"), f\"{random_check_id}-{random_column_id}\"\n            )\n            self.assertEqual(\n                len(testsuite), 2\n            )  # assert two tests in sample rules config\n            self.assertEqual(\n                testsuite[0].get(\"name\"), f\"{random_check_id}-0001 :: DataTypeCheck\"\n            )\n            self.assertEqual(\n                testsuite[1].get(\"name\"), f\"{random_check_id}-0002 :: ColumnRequired\"\n            )\n\n    def test_unittest_output_with_bad_rule(self):\n        random_path = str(uuid4())\n        random_error = str(uuid4())\n        random_error_type = str(uuid4())\n\n        rules = [\n            InvalidRule(\n                error=random_error, error_type=random_error_type, rule_path=random_path\n            )\n        ]\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules\n        )\n        result = ValidationResult(checklist=checklist)\n        result.process_result()\n\n        buffer = io.BytesIO()\n        outputter = UnittestOutputter(output_destination=buffer)\n        outputter.write(result_set=result)\n\n        buffer.seek(0)\n        output = buffer.read()\n        testsuites = ET.fromstring(output)\n\n        self.assertEqual(testsuites.get(\"tests\"), \"1\")\n        self.assertEqual(testsuites.get(\"failures\"), \"0\")\n        self.assertEqual(testsuites.get(\"skipped\"), \"0\")\n        self.assertEqual(testsuites.get(\"errors\"), \"1\")\n\n    def test_outputter_with_metric_dimension(self):\n        random_check_id = f\"FV-M00{randint(0, 9)}\"\n        random_column_id = str(uuid4())\n\n        rules = [\n            Rule(\n                check_id=f\"{random_check_id}-0001\",\n                column_id=random_column_id,\n                check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n            ),\n            Rule(\n                check_id=f\"{random_check_id}-0002\",\n                column_id=random_column_id,\n                check=\"column_required\",\n            ),\n        ]\n\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules\n        )\n        result = ValidationResult(checklist=checklist)\n        result.process_result()\n\n        buffer = io.BytesIO()\n        outputter = UnittestOutputter(output_destination=buffer)\n        outputter.write(result_set=result)\n\n        buffer.seek(0)\n        output = buffer.read()\n        testsuites = ET.fromstring(output)\n        self.assertEqual(len(testsuites), 1)  # assert one column in sample rules config\n        self.assertEqual(testsuites.get(\"name\"), \"FOCUS Validations\")\n        for testsuite in testsuites:\n            self.assertEqual(\n                testsuite.get(\"name\"), f\"{random_check_id}-{random_column_id}\"\n            )\n            self.assertEqual(\n                len(testsuite), 2\n            )  # assert two tests in sample rules config\n            self.assertEqual(\n                testsuite[0].get(\"name\"), f\"{random_check_id}-0001 :: DataTypeCheck\"\n            )\n            self.assertEqual(\n                testsuite[1].get(\"name\"), f\"{random_check_id}-0002 :: ColumnRequired\"\n            )", "class TestOutputterUnittest(TestCase):\n    def test_unittest_output_all_valid_rules(self):\n        random_check_id = f\"FV-D00{randint(0, 9)}\"\n        random_column_id = str(uuid4())\n\n        rules = [\n            Rule(\n                check_id=f\"{random_check_id}-0001\",\n                column_id=random_column_id,\n                check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n            ),\n            Rule(\n                check_id=f\"{random_check_id}-0002\",\n                column_id=random_column_id,\n                check=\"column_required\",\n            ),\n        ]\n\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules\n        )\n        result = ValidationResult(checklist=checklist)\n        result.process_result()\n\n        buffer = io.BytesIO()\n        outputter = UnittestOutputter(output_destination=buffer)\n        outputter.write(result_set=result)\n\n        buffer.seek(0)\n        output = buffer.read()\n        testsuites = ET.fromstring(output)\n        self.assertEqual(len(testsuites), 1)  # assert one column in sample rules config\n        self.assertEqual(testsuites.get(\"name\"), \"FOCUS Validations\")\n        for testsuite in testsuites:\n            self.assertEqual(\n                testsuite.get(\"name\"), f\"{random_check_id}-{random_column_id}\"\n            )\n            self.assertEqual(\n                len(testsuite), 2\n            )  # assert two tests in sample rules config\n            self.assertEqual(\n                testsuite[0].get(\"name\"), f\"{random_check_id}-0001 :: DataTypeCheck\"\n            )\n            self.assertEqual(\n                testsuite[1].get(\"name\"), f\"{random_check_id}-0002 :: ColumnRequired\"\n            )\n\n    def test_unittest_output_with_bad_rule(self):\n        random_path = str(uuid4())\n        random_error = str(uuid4())\n        random_error_type = str(uuid4())\n\n        rules = [\n            InvalidRule(\n                error=random_error, error_type=random_error_type, rule_path=random_path\n            )\n        ]\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules\n        )\n        result = ValidationResult(checklist=checklist)\n        result.process_result()\n\n        buffer = io.BytesIO()\n        outputter = UnittestOutputter(output_destination=buffer)\n        outputter.write(result_set=result)\n\n        buffer.seek(0)\n        output = buffer.read()\n        testsuites = ET.fromstring(output)\n\n        self.assertEqual(testsuites.get(\"tests\"), \"1\")\n        self.assertEqual(testsuites.get(\"failures\"), \"0\")\n        self.assertEqual(testsuites.get(\"skipped\"), \"0\")\n        self.assertEqual(testsuites.get(\"errors\"), \"1\")\n\n    def test_outputter_with_metric_dimension(self):\n        random_check_id = f\"FV-M00{randint(0, 9)}\"\n        random_column_id = str(uuid4())\n\n        rules = [\n            Rule(\n                check_id=f\"{random_check_id}-0001\",\n                column_id=random_column_id,\n                check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n            ),\n            Rule(\n                check_id=f\"{random_check_id}-0002\",\n                column_id=random_column_id,\n                check=\"column_required\",\n            ),\n        ]\n\n        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=rules\n        )\n        result = ValidationResult(checklist=checklist)\n        result.process_result()\n\n        buffer = io.BytesIO()\n        outputter = UnittestOutputter(output_destination=buffer)\n        outputter.write(result_set=result)\n\n        buffer.seek(0)\n        output = buffer.read()\n        testsuites = ET.fromstring(output)\n        self.assertEqual(len(testsuites), 1)  # assert one column in sample rules config\n        self.assertEqual(testsuites.get(\"name\"), \"FOCUS Validations\")\n        for testsuite in testsuites:\n            self.assertEqual(\n                testsuite.get(\"name\"), f\"{random_check_id}-{random_column_id}\"\n            )\n            self.assertEqual(\n                len(testsuite), 2\n            )  # assert two tests in sample rules config\n            self.assertEqual(\n                testsuite[0].get(\"name\"), f\"{random_check_id}-0001 :: DataTypeCheck\"\n            )\n            self.assertEqual(\n                testsuite[1].get(\"name\"), f\"{random_check_id}-0002 :: ColumnRequired\"\n            )", ""]}
{"filename": "tests/outputter/__init__.py", "chunked_list": [""]}
{"filename": "tests/outputter/test_outputter_console.py", "chunked_list": ["from unittest import TestCase\n\nfrom focus_validator.config_objects import InvalidRule\nfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n    FocusToPanderaSchemaConverter,\n)\nfrom focus_validator.outputter.outputter_console import ConsoleOutputter\nfrom focus_validator.rules.spec_rules import ValidationResult\nfrom focus_validator.validator import Validator\n", "from focus_validator.validator import Validator\n\n\nclass TestOutputterConsole(TestCase):\n    def test_failure_output(self):\n        validator = Validator(\n            data_filename=\"tests/samples/multiple_failure_example_namespaced.csv\",\n            output_type=\"console\",\n            output_destination=None,\n            column_namespace=\"F\",\n        )\n        validator.load()\n        result = validator.spec_rules.validate(focus_data=validator.focus_data)\n\n        outputter = ConsoleOutputter(output_destination=None)\n        checklist = outputter.__restructure_check_list__(result_set=result)\n        self.assertEqual(\n            list(checklist.columns),\n            [\n                \"Check Name\",\n                \"Check Type\",\n                \"Column\",\n                \"Friendly Name\",\n                \"Error\",\n                \"Status\",\n            ],\n        )\n\n    def test_output_with_bad_configs_loaded(self):\n        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n            rules=[\n                InvalidRule(\n                    rule_path=\"bad_rule_path\",\n                    error=\"random-error\",\n                    error_type=\"ValueError\",\n                )\n            ]\n        )\n\n        validation_result = ValidationResult(failure_cases=None, checklist=checklist)\n        validation_result.process_result()\n\n        outputter = ConsoleOutputter(output_destination=None)\n        checklist = outputter.__restructure_check_list__(result_set=validation_result)\n        self.assertEqual(\n            checklist.to_dict(orient=\"records\"),\n            [\n                {\n                    \"Check Name\": \"bad_rule_path\",\n                    \"Check Type\": \"ERRORED\",\n                    \"Column\": \"Unknown\",\n                    \"Friendly Name\": None,\n                    \"Error\": \"ValueError: random-error\",\n                    \"Status\": \"Errored\",\n                }\n            ],\n        )", ""]}
