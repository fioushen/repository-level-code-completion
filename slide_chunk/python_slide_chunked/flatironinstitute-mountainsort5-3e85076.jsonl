{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\n# read the contents of README.md\nfrom pathlib import Path\nthis_directory = Path(__file__).parent\nlong_description = (this_directory / \"README.md\").read_text()\n\n__version__ = '0.3.0'\n\nsetup(", "\nsetup(\n    name='mountainsort5',\n    version=__version__,\n    author=\"Jeremy Magland\",\n    author_email=\"jmagland@flatironinstitute.org\",\n    url=\"https://github.com/flatironinstitute/mountainsort5\",\n    description=\"MountainSort 5 spike sorting algorithm\",\n    long_description=long_description,\n    long_description_content_type='text/markdown',", "    long_description=long_description,\n    long_description_content_type='text/markdown',\n    packages=find_packages(),\n    install_requires=[\n        'spikeinterface>=0.97.1',\n        'isosplit6>=0.1.0',\n        'scikit-learn'\n    ],\n    tests_require=[\n        \"pytest\",", "    tests_require=[\n        \"pytest\",\n        \"pytest-cov\"\n    ]\n)"]}
{"filename": "tests/test_scheme1.py", "chunked_list": ["import time\nimport spikeinterface as si\nimport spikeinterface.extractors as se\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\n\n\ndef test_scheme1():\n    recording, sorting_true = se.toy_example(\n        duration=20,\n        num_channels=8,\n        num_units=16,\n        sampling_frequency=30000,\n        num_segments=2,\n        seed=0\n    )\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme1(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme1SortingParameters(\n            snippet_mask_radius=50\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')", "def test_scheme1():\n    recording, sorting_true = se.toy_example(\n        duration=20,\n        num_channels=8,\n        num_units=16,\n        sampling_frequency=30000,\n        num_segments=2,\n        seed=0\n    )\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme1(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme1SortingParameters(\n            snippet_mask_radius=50\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')", "\n    # commenting out because this step takes a while\n    # print('Comparing with truth')\n    # comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    # print(comparison.get_performance())"]}
{"filename": "tests/test_scheme3.py", "chunked_list": ["import time\nimport spikeinterface as si\nimport spikeinterface.extractors as se\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\n\n\ndef test_scheme3():\n    recording, sorting_true = se.toy_example(\n        duration=20,\n        num_channels=8,\n        num_units=16,\n        sampling_frequency=30000,\n        num_segments=2,\n        seed=0\n    )\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme3(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme3SortingParameters(\n            block_sorting_parameters=ms5.Scheme2SortingParameters(\n                phase1_detect_channel_radius=150,\n                detect_channel_radius=50\n            ),\n            block_duration_sec=3\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')", "def test_scheme3():\n    recording, sorting_true = se.toy_example(\n        duration=20,\n        num_channels=8,\n        num_units=16,\n        sampling_frequency=30000,\n        num_segments=2,\n        seed=0\n    )\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme3(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme3SortingParameters(\n            block_sorting_parameters=ms5.Scheme2SortingParameters(\n                phase1_detect_channel_radius=150,\n                detect_channel_radius=50\n            ),\n            block_duration_sec=3\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')", "\n    # commenting out because this step takes a while\n    # print('Comparing with truth')\n    # comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    # print(comparison.get_performance())"]}
{"filename": "tests/test_scheme2.py", "chunked_list": ["import time\nimport spikeinterface as si\nimport spikeinterface.extractors as se\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\n\n\ndef test_scheme2():\n    recording, sorting_true = se.toy_example(\n        duration=40,\n        num_channels=8,\n        num_units=16,\n        sampling_frequency=30000,\n        num_segments=2,\n        seed=0\n    )\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5 (sorting1)')\n    timer = time.time()\n    sorting1, classifer1 = ms5.sorting_scheme2(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme2SortingParameters(\n            phase1_detect_channel_radius=150,\n            detect_channel_radius=50,\n            max_num_snippets_per_training_batch=3, # for improving test coverage\n            snippet_mask_radius=150,\n            training_duration_sec=15\n        ),\n        return_snippet_classifiers=True # for coverage\n    )\n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Starting MountainSort5 (sorting2)')\n    timer = time.time()\n    sorting2 = ms5.sorting_scheme2(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme2SortingParameters(\n            phase1_detect_channel_radius=150,\n            detect_channel_radius=50,\n            training_duration_sec=25,\n            training_recording_sampling_mode='uniform'\n        )\n    )\n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')", "def test_scheme2():\n    recording, sorting_true = se.toy_example(\n        duration=40,\n        num_channels=8,\n        num_units=16,\n        sampling_frequency=30000,\n        num_segments=2,\n        seed=0\n    )\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5 (sorting1)')\n    timer = time.time()\n    sorting1, classifer1 = ms5.sorting_scheme2(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme2SortingParameters(\n            phase1_detect_channel_radius=150,\n            detect_channel_radius=50,\n            max_num_snippets_per_training_batch=3, # for improving test coverage\n            snippet_mask_radius=150,\n            training_duration_sec=15\n        ),\n        return_snippet_classifiers=True # for coverage\n    )\n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Starting MountainSort5 (sorting2)')\n    timer = time.time()\n    sorting2 = ms5.sorting_scheme2(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme2SortingParameters(\n            phase1_detect_channel_radius=150,\n            detect_channel_radius=50,\n            training_duration_sec=25,\n            training_recording_sampling_mode='uniform'\n        )\n    )\n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')", "\n    # commenting out because this step takes a while\n    # print('Comparing with truth')\n    # comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    # print(comparison.get_performance())\n\n# for coverage\ndef test_scheme2_single_segment():\n    recording, sorting_true = se.toy_example(\n        duration=4,\n        num_channels=4,\n        num_units=4,\n        sampling_frequency=30000,\n        num_segments=1,\n        seed=0\n    )\n\n    sorting1 = ms5.sorting_scheme2(\n        recording,\n        sorting_parameters=ms5.Scheme2SortingParameters(\n            phase1_detect_channel_radius=150,\n            detect_channel_radius=50,\n            max_num_snippets_per_training_batch=3, # for improving test coverage\n            snippet_mask_radius=150,\n            training_duration_sec=15,\n            classifier_npca=4\n        )\n    )"]}
{"filename": "tests/test_core.py", "chunked_list": ["import numpy as np\nimport spikeinterface as si\nimport spikeinterface.extractors as se\nfrom mountainsort5.core.compute_pca_features import compute_pca_features\nfrom mountainsort5.core.compute_templates import compute_templates\nfrom mountainsort5.core.detect_spikes import detect_spikes\nfrom mountainsort5.core.extract_snippets import extract_snippets, extract_snippets_in_channel_neighborhood\nfrom mountainsort5.core.get_sampled_recording_for_training import get_sampled_recording_for_training\nfrom mountainsort5.core.get_block_recording_for_scheme3 import get_block_recording_for_scheme3\nfrom mountainsort5.core.isosplit6_subdivision_method import isosplit6_subdivision_method", "from mountainsort5.core.get_block_recording_for_scheme3 import get_block_recording_for_scheme3\nfrom mountainsort5.core.isosplit6_subdivision_method import isosplit6_subdivision_method\nfrom mountainsort5.core.get_times_labels_from_sorting import get_times_labels_from_sorting\n\n\ndef test_compute_pca_features():\n    x = np.random.normal(size=(100, 20))\n    features = compute_pca_features(x, npca=10)\n    assert features.shape == (100, 10)\n\ndef test_compute_templates():\n    L = 1000\n    T = 20\n    M = 10\n    snippets = np.random.normal(size=(L, T, M))\n    labels = np.random.randint(1, 11, size=(L,))\n    templates = compute_templates(snippets, labels)\n    assert templates.shape == (10, T, M)", "\ndef test_compute_templates():\n    L = 1000\n    T = 20\n    M = 10\n    snippets = np.random.normal(size=(L, T, M))\n    labels = np.random.randint(1, 11, size=(L,))\n    templates = compute_templates(snippets, labels)\n    assert templates.shape == (10, T, M)\n\ndef test_detect_spikes():\n    N = 100\n    M = 3\n    traces= np.zeros((N, M))\n    channel_locations = np.zeros((M, 2))\n    traces[8, 0] = -10 # in margin\n    traces[9, 1] = -4 # in margin\n    traces[30, 1] = -4\n    traces[31, 1] = -10\n    traces[40, 2] = -10\n    traces[41, 2] = -4\n    traces[98, 0] = -10 # in margin\n    times, channel_indices = detect_spikes(\n        traces,\n        channel_locations=channel_locations,\n        time_radius=10,\n        channel_radius=50,\n        detect_threshold=3,\n        detect_sign=-1,\n        margin_left=10,\n        margin_right=10,\n        verbose=False\n    )\n    assert len(times) == len(channel_indices) == 2\n    assert times[0] == 31\n    assert channel_indices[0] == 1\n    assert times[1] == 40\n    assert channel_indices[1] == 2", "\ndef test_detect_spikes():\n    N = 100\n    M = 3\n    traces= np.zeros((N, M))\n    channel_locations = np.zeros((M, 2))\n    traces[8, 0] = -10 # in margin\n    traces[9, 1] = -4 # in margin\n    traces[30, 1] = -4\n    traces[31, 1] = -10\n    traces[40, 2] = -10\n    traces[41, 2] = -4\n    traces[98, 0] = -10 # in margin\n    times, channel_indices = detect_spikes(\n        traces,\n        channel_locations=channel_locations,\n        time_radius=10,\n        channel_radius=50,\n        detect_threshold=3,\n        detect_sign=-1,\n        margin_left=10,\n        margin_right=10,\n        verbose=False\n    )\n    assert len(times) == len(channel_indices) == 2\n    assert times[0] == 31\n    assert channel_indices[0] == 1\n    assert times[1] == 40\n    assert channel_indices[1] == 2", "\ndef test_extract_snippets():\n    N = 1000\n    M = 4\n    L = 100\n    T1 = 20\n    T2 = 20\n    T = T1 + T2\n    traces = np.random.normal(size=(N, M))\n    times = np.random.randint(T1, N - T2, size=(L,))\n    snippets = extract_snippets(traces, times=times, channel_locations=None, mask_radius=None, channel_indices=None, T1=T1, T2=T2)\n    assert snippets.shape == (L, T, M)", "\ndef test_extract_snippets_in_channel_neighborhood():\n    N = 1000\n    M = 4\n    L = 100\n    T1 = 20\n    T2 = 20\n    T = T1 + T2\n    traces = np.random.normal(size=(N, M))\n    times = np.random.randint(T1, N - T2, size=(L,))\n    neighborhood = [0, 2]\n    snippets = extract_snippets_in_channel_neighborhood(\n        traces=traces,\n        times=times,\n        neighborhood=neighborhood,\n        T1=T1,\n        T2=T2\n    )\n    assert snippets.shape == (L, T, len(neighborhood))", "\ndef test_get_sampled_recording_for_training():\n    recording, _ = se.toy_example(duration=60, num_channels=4, num_units=10, sampling_frequency=30000, seed=0, num_segments=1)\n    recording: si.BaseRecording = recording\n\n    # test case where the training duration is longer than the recording duration\n    recording1 = get_sampled_recording_for_training(\n        recording=recording,\n        training_duration_sec=100,\n        mode='initial'\n    )\n    assert np.array_equal(\n        recording1.get_traces(),\n        recording.get_traces()\n    )\n\n    # test case where the training recording has only one chunk\n    recording1b = get_sampled_recording_for_training(\n        recording=recording,\n        training_duration_sec=7,\n        mode='uniform'\n    )\n    assert np.array_equal(\n        recording1b.get_traces(),\n        recording.get_traces(start_frame=0, end_frame=7 * recording.sampling_frequency)\n    )\n\n    # Test the mode='initial' case which is easier\n    recording2 = get_sampled_recording_for_training(\n        recording=recording,\n        training_duration_sec=25,\n        mode='initial'\n    )\n    assert recording2.get_num_frames() == 25 * recording.sampling_frequency\n    assert np.array_equal(\n        recording2.get_traces(),\n        recording.get_traces(start_frame=0, end_frame=25 * recording.sampling_frequency)\n    )\n\n    # Important to test mode='uniform' which can be tricky\n    recording3 = get_sampled_recording_for_training(\n        recording=recording,\n        training_duration_sec=25,\n        mode='uniform'\n    )\n    assert recording3.get_num_frames() == 25 * recording.sampling_frequency\n    assert np.array_equal(\n        recording3.get_traces(start_frame=0, end_frame=10 * recording.sampling_frequency),\n        recording.get_traces(start_frame=0, end_frame=10 * recording.sampling_frequency)\n    )\n    # 60 - 25 = 35\n    # spacing = 35 / 2 = 17.5\n    assert np.array_equal(\n        recording3.get_traces(start_frame=10 * recording.sampling_frequency, end_frame=20 * recording.sampling_frequency),\n        recording.get_traces(start_frame=int(27.5 * recording.sampling_frequency), end_frame=int(37.5 * recording.sampling_frequency))\n    )\n    # 37.5 + 17.5 = 55\n    assert np.array_equal(\n        recording3.get_traces(start_frame=20 * recording.sampling_frequency, end_frame=25 * recording.sampling_frequency),\n        recording.get_traces(start_frame=int(55 * recording.sampling_frequency), end_frame=int(60 * recording.sampling_frequency))\n    )", "\ndef test_get_block_recording_for_scheme3():\n    recording, _ = se.toy_example(duration=60, num_channels=4, num_units=10, sampling_frequency=30000, seed=0, num_segments=1)\n    recording: si.BaseRecording = recording\n\n    recording2 = get_block_recording_for_scheme3(\n        recording=recording,\n        start_frame=10 * recording.sampling_frequency,\n        end_frame=20 * recording.sampling_frequency\n    )\n    assert np.array_equal(\n        recording.get_traces(start_frame=10 * recording.sampling_frequency, end_frame=20 * recording.sampling_frequency),\n        recording2.get_traces()\n    )", "\ndef test_subdivision_cluster():\n    N = 1000\n    L = 100\n    M = 4\n    T1 = 20\n    T2 = 20\n    traces = np.random.normal(size=(N, M))\n    traces[500:] += 10 # offset this so we get more than one cluster (important for coverage of cluster_snippets)\n    times = np.random.randint(T1, N - T2, size=(L,))\n    snippets = extract_snippets(traces, times=times, channel_locations=None, mask_radius=None, channel_indices=None, T1=T1, T2=T2)\n    labels = isosplit6_subdivision_method(\n        snippets.reshape((L, M * (T1 + T2))),\n        npca_per_subdivision=10\n    )\n    assert np.min(labels) == 1\n    assert len(labels) == L", "\ndef test_get_times_labels_from_sorting():\n    recording, sorting = se.toy_example(duration=6, num_channels=4, num_units=10, sampling_frequency=30000, seed=0, num_segments=1)\n    recording: si.BaseRecording = recording\n    sorting: si.BaseSorting = sorting\n\n    times, labels = get_times_labels_from_sorting(sorting)\n    assert len(times) == len(labels)\n    assert len(np.unique(labels)) == sorting.get_num_units()\n\n    # test the case of an empty sorting\n    sorting2 = se.NumpySorting(sampling_frequency=30000)\n    times2, labels2 = get_times_labels_from_sorting(sorting2)\n    assert len(times2) == 0\n    assert len(labels2) == 0"]}
{"filename": "mountainsort5/__init__.py", "chunked_list": ["import importlib.metadata\n__version__ = importlib.metadata.version(\"mountainsort5\")\n\nfrom .schemes.sorting_scheme1 import sorting_scheme1\nfrom .schemes.Scheme1SortingParameters import Scheme1SortingParameters\nfrom .schemes.sorting_scheme2 import sorting_scheme2\nfrom .schemes.Scheme2SortingParameters import Scheme2SortingParameters\nfrom .schemes.sorting_scheme3 import sorting_scheme3\nfrom .schemes.Scheme3SortingParameters import Scheme3SortingParameters", "from .schemes.Scheme3SortingParameters import Scheme3SortingParameters"]}
{"filename": "mountainsort5/core/get_times_labels_from_sorting.py", "chunked_list": ["from typing import Tuple\nimport numpy as np\nimport numpy.typing as npt\nimport spikeinterface as si\n\n\ndef get_times_labels_from_sorting(sorting: si.BaseSorting) -> Tuple[npt.NDArray[np.int64], npt.NDArray[np.int32]]:\n    \"\"\"Get times and labels from a sorting object\n    Inputs:\n        sorting: a sorting object\n    Returns:\n        times: 1D array of spike times\n        labels: 1D array of spike labels\n    Example:\n        times, labels = get_times_labels_from_sorting(sorting)\n    \"\"\"\n    times_list = []\n    labels_list = []\n    for unit_id in sorting.get_unit_ids():\n        times0 = sorting.get_unit_spike_train(unit_id=unit_id)\n        labels0 = np.ones(times0.shape, dtype=np.int32) * unit_id\n        times_list.append(times0.astype(np.int64))\n        labels_list.append(labels0)\n    if len(times_list) > 0:\n        times = np.concatenate(times_list).astype(np.int64)\n        labels = np.concatenate(labels_list)\n        inds = np.argsort(times)\n        times = times[inds]\n        labels = labels[inds]\n        return times, labels\n    else:\n        return np.array([], dtype=np.int64), np.array([], dtype=np.int32)"]}
{"filename": "mountainsort5/core/get_block_recording_for_scheme3.py", "chunked_list": ["import spikeinterface as si\nfrom typing import Literal\n\n\ndef get_block_recording_for_scheme3(\n    recording: si.BaseRecording, *,\n    start_frame: int,\n    end_frame: int\n) -> si.BaseRecording:\n    return BlockRecording(\n        recording=recording,\n        start_frame=start_frame,\n        end_frame=end_frame\n    )", "\nclass BlockRecording(si.BaseRecording):\n    def __init__(self, recording: si.BaseRecording, start_frame: int, end_frame: int):\n        sampling_frequency = recording.get_sampling_frequency()\n        dtype = recording.get_dtype()\n        channel_ids = recording.get_channel_ids()\n        \n        si.BaseRecording.__init__(self, sampling_frequency, channel_ids, dtype)\n\n        self.start_frame = start_frame\n        self.end_frame = end_frame\n\n        self.set_channel_locations(recording.get_channel_locations())\n        self.is_dumpable = False\n\n        self.add_recording_segment(\n            BlockRecordingSegment(recording=recording, start_frame=start_frame, end_frame=end_frame)\n        )\n\n        self._kwargs = {'recording': recording, 'start_frame': start_frame, 'end_frame': end_frame}", "\nclass BlockRecordingSegment(si.BaseRecordingSegment):\n    def __init__(self, recording: si.BaseRecording, start_frame: int, end_frame: int):\n        si.BaseRecordingSegment.__init__(\n            self,\n            sampling_frequency=recording.get_sampling_frequency(),\n            t_start=0\n        )\n        self._recording = recording\n        self._start_frame = start_frame\n        self._end_frame = end_frame\n\n    def get_num_samples(self):\n        return self._end_frame - self._start_frame\n\n    def get_traces(self, start_frame, end_frame, channel_indices):\n        if start_frame is None:\n            start_frame = 0\n        if end_frame is None:\n            end_frame = self.get_num_samples()\n\n        # Get the traces from the parent recording\n        return self._recording._recording_segments[0].get_traces(\n            start_frame=start_frame + self._start_frame,\n            end_frame=end_frame + self._start_frame,\n            channel_indices=channel_indices\n        )"]}
{"filename": "mountainsort5/core/extract_snippets.py", "chunked_list": ["from typing import Union, List\nimport numpy as np\nimport numpy.typing as npt\n\n\ndef extract_snippets(\n    traces: npt.NDArray[np.float32], *,\n    channel_locations: Union[npt.NDArray[np.float32], None],\n    mask_radius: Union[float, None],\n    times: npt.NDArray[np.int32],\n    channel_indices: Union[npt.NDArray[np.int32], None],\n    T1: int,\n    T2: int\n) -> npt.NDArray[np.float32]:\n    M = traces.shape[1]\n    L = len(times)\n\n    if mask_radius is not None:\n        assert channel_locations is not None\n        assert channel_indices is not None\n        adjacency = []\n        for m in range(M):\n            adjacency.append([])\n            for m2 in range(M):\n                dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n                if dist0 <= mask_radius:\n                    adjacency[m].append(m2)\n    else:\n        adjacency = None\n    \n    snippets = np.zeros((L, T1 + T2, M), dtype=np.float32)\n    for j in range(L):\n        t1 = times[j] - T1\n        t2 = times[j] + T2\n        if adjacency is not None:\n            assert channel_indices is not None\n            channel_inds = adjacency[channel_indices[j]]\n            snippets[j][:, channel_inds] = traces[t1:t2, channel_inds]\n        else:\n            snippets[j] = traces[t1:t2]\n    return snippets", "\ndef extract_snippets_in_channel_neighborhood(\n    traces: npt.NDArray[np.float32], *,\n    times: npt.NDArray[np.int32],\n    neighborhood: Union[List[int], None],\n    T1: int,\n    T2: int\n) -> np.ndarray:\n    L = len(times)\n\n    if neighborhood is None:\n        neighborhood = list(range(traces.shape[1]))\n\n    snippets = np.zeros((L, T1 + T2, len(neighborhood)), dtype=np.float32)\n    for j in range(L):\n        t1 = times[j] - T1\n        t2 = times[j] + T2\n        snippets[j] = traces[t1:t2][:, neighborhood]\n            \n    return snippets"]}
{"filename": "mountainsort5/core/compute_templates.py", "chunked_list": ["import numpy as np\nimport numpy.typing as npt\n\n\ndef compute_templates(snippets: npt.NDArray[np.float32], labels: np.int32):\n    # L = snippets.shape[0]\n    T = snippets.shape[1]\n    M = snippets.shape[2]\n    K = np.max(labels)\n    templates = np.zeros((K, T, M), dtype=np.float32)\n    for k in range(1, K + 1):\n        snippets1 = snippets[labels == k]\n        templates[k - 1] = np.median(snippets1, axis=0)\n    return templates", "        "]}
{"filename": "mountainsort5/core/compute_pca_features.py", "chunked_list": ["import numpy as np\nimport numpy.typing as npt\nfrom sklearn import decomposition\n\n\ndef compute_pca_features(X: npt.NDArray[np.float32], *, npca: int):\n    pca = decomposition.PCA(n_components=np.minimum(npca, X.shape[0]))\n    return pca.fit_transform(X)"]}
{"filename": "mountainsort5/core/remove_duplicate_events.py", "chunked_list": ["import numpy as np\nimport numpy.typing as npt\n\n\ndef remove_duplicate_events(times: npt.NDArray[np.int32], labels: npt.NDArray[np.int32], *, tol: int) -> npt.NDArray[np.int32]:\n    new_labels = np.array(labels)\n    unit_ids = np.unique(new_labels)\n    for unit_id in unit_ids:\n        unit_inds = np.nonzero(new_labels == unit_id)[0]\n        unit_times = times[unit_inds]\n        inds_duplicate = find_duplicate_times(unit_times, tol=tol)\n        new_labels[unit_inds[inds_duplicate]] = 0\n    inds_nonzero = np.nonzero(new_labels)[0]\n    return inds_nonzero", "\ndef find_duplicate_times(times: npt.NDArray[np.int32], *, tol: int) -> npt.NDArray[np.int32]:\n    ret: list[np.int32] = []\n    deleted = np.zeros((len(times),), dtype=np.int16)\n    for i1 in range(len(times)):\n        if not deleted[i1]:\n            i2 = i1 + 1\n            while i2 < len(times) and times[i2] <= times[i1] + tol:\n                ret.append(i2)\n                deleted[i2] = True\n                i2 += 1\n    return np.array(ret, dtype=np.int32)"]}
{"filename": "mountainsort5/core/isosplit6_subdivision_method.py", "chunked_list": ["\nimport numpy as np\nimport numpy.typing as npt\nimport warnings\nfrom scipy.cluster.hierarchy import ClusterWarning\nfrom isosplit6 import isosplit6\nfrom .compute_pca_features import compute_pca_features\n\n\nwarnings.filterwarnings('ignore', category=ClusterWarning)", "\nwarnings.filterwarnings('ignore', category=ClusterWarning)\n\n\nfrom typing import Union\n\ndef isosplit6_subdivision_method(\n    X: npt.NDArray[np.float32], *,\n    npca_per_subdivision: int,\n    inds: Union[npt.NDArray[np.int32], None]=None # pass in inds so that we don't keep making copies of the array\n):\n    if inds is not None:\n        X_sub = X[inds]\n    else:\n        X_sub = X\n    L = X_sub.shape[0]\n    features = compute_pca_features(X_sub, npca=npca_per_subdivision)\n    labels = isosplit6(features)\n    K = np.max(labels)\n    if K <= 1:\n        return labels\n    centroids = np.zeros((K, X.shape[1]), dtype=np.float32)\n    for k in range(1, K + 1):\n        centroids[k - 1] = np.median(X_sub[labels == k], axis=0)\n    X_sub = None # free up memory\n    dists_between_centroids = np.sqrt(np.sum((centroids[:, None, :] - centroids[None, :, :]) ** 2, axis=2))\n    # hierarchical clustering\n    from scipy.cluster.hierarchy import linkage, cut_tree\n    Z = linkage(dists_between_centroids, method='single', metric='euclidean')\n    clusters0 = cut_tree(Z, n_clusters=2)\n    cluster_inds_1 = np.where(clusters0 == 0)[0] + 1\n    cluster_inds_2 = np.where(clusters0 == 1)[0] + 1\n    inds1 = np.where(np.isin(labels, cluster_inds_1))[0]\n    inds2 = np.where(np.isin(labels, cluster_inds_2))[0]\n    if inds is not None:\n        inds1_b = inds[inds1]\n        inds2_b = inds[inds2]\n    else:\n        inds1_b = inds1\n        inds2_b = inds2\n    labels1 = isosplit6_subdivision_method(X, npca_per_subdivision=npca_per_subdivision, inds=inds1_b)\n    labels2 = isosplit6_subdivision_method(X, npca_per_subdivision=npca_per_subdivision, inds=inds2_b)\n    K1 = np.max(labels1)\n    K2 = np.max(labels2)\n    ret_labels = np.zeros(L, dtype=np.int32)\n    ret_labels[inds1] = labels1\n    ret_labels[inds2] = labels2 + K1\n    return ret_labels"]}
{"filename": "mountainsort5/core/__init__.py", "chunked_list": [""]}
{"filename": "mountainsort5/core/SnippetClassifier.py", "chunked_list": ["from typing import List, Tuple, Union, Dict\nimport numpy as np\nimport numpy.typing as npt\nfrom dataclasses import dataclass\nfrom sklearn import decomposition\nfrom sklearn.neighbors import NearestNeighbors\n\n\nclass SnippetClassifier:\n    def __init__(self, npca: Union[int, None]) -> None:\n        self.npca = npca\n        self.training_batches: List[TrainingBatch] = []\n        self.pca_model = None\n    def add_training_snippets(self, snippets: npt.NDArray[np.float32], label: int, offset: int):\n        self.training_batches.append(TrainingBatch(snippets=snippets, label=label, offset=offset))\n    def fit(self):\n        if len(self.training_batches) == 0:\n            raise Exception('No training batches added for classifier.') # pragma: no cover\n        all_training_snippets = np.concatenate([b.snippets for b in self.training_batches], axis=0)\n        L = all_training_snippets.shape[0]\n        self.T = all_training_snippets.shape[1]\n        self.M = all_training_snippets.shape[2]\n        self.all_training_labels = np.concatenate([np.ones((b.num_snippets,), dtype=np.int32) * b.label for b in self.training_batches])\n        self.all_training_offsets = np.concatenate([np.ones((b.num_snippets,), dtype=np.int32) * b.offset for b in self.training_batches])\n        if self.npca is not None:\n            effective_npca = self.npca\n        else:\n            effective_npca = max(12, self.M * 3)\n        self.pca_model = decomposition.PCA(n_components=min(effective_npca, L))\n        self.pca_model.fit(all_training_snippets.reshape(L, self.T * self.M))\n        X = self.pca_model.transform(all_training_snippets.reshape(L, self.T * self.M))\n        self.nearest_neighbor_model = NearestNeighbors(n_neighbors=2)\n        self.nearest_neighbor_model.fit(X)\n    def classify_snippets(self, snippets: npt.NDArray[np.float32]) -> Tuple[Union[npt.NDArray[np.int32], None], Union[npt.NDArray[np.int32], None]]:\n        if self.pca_model is None:\n            raise Exception('self.pca_model is None, which probably means that fit() was not called.') # pragma: no cover\n        Y = self.pca_model.transform(snippets.reshape(snippets.shape[0], self.T * self.M))\n        nearest_inds = self.nearest_neighbor_model.kneighbors(Y, n_neighbors=2, return_distance=False)\n        inds = nearest_inds[:, 1] # don't use the first because that could be an identical match\n        return self.all_training_labels[inds], self.all_training_offsets[inds]\n    def apply_label_mapping(self, mapping: Dict[int, int]):\n        for k1, k2 in mapping.items():\n            self.all_training_labels[self.all_training_labels == k1] = k2", "class SnippetClassifier:\n    def __init__(self, npca: Union[int, None]) -> None:\n        self.npca = npca\n        self.training_batches: List[TrainingBatch] = []\n        self.pca_model = None\n    def add_training_snippets(self, snippets: npt.NDArray[np.float32], label: int, offset: int):\n        self.training_batches.append(TrainingBatch(snippets=snippets, label=label, offset=offset))\n    def fit(self):\n        if len(self.training_batches) == 0:\n            raise Exception('No training batches added for classifier.') # pragma: no cover\n        all_training_snippets = np.concatenate([b.snippets for b in self.training_batches], axis=0)\n        L = all_training_snippets.shape[0]\n        self.T = all_training_snippets.shape[1]\n        self.M = all_training_snippets.shape[2]\n        self.all_training_labels = np.concatenate([np.ones((b.num_snippets,), dtype=np.int32) * b.label for b in self.training_batches])\n        self.all_training_offsets = np.concatenate([np.ones((b.num_snippets,), dtype=np.int32) * b.offset for b in self.training_batches])\n        if self.npca is not None:\n            effective_npca = self.npca\n        else:\n            effective_npca = max(12, self.M * 3)\n        self.pca_model = decomposition.PCA(n_components=min(effective_npca, L))\n        self.pca_model.fit(all_training_snippets.reshape(L, self.T * self.M))\n        X = self.pca_model.transform(all_training_snippets.reshape(L, self.T * self.M))\n        self.nearest_neighbor_model = NearestNeighbors(n_neighbors=2)\n        self.nearest_neighbor_model.fit(X)\n    def classify_snippets(self, snippets: npt.NDArray[np.float32]) -> Tuple[Union[npt.NDArray[np.int32], None], Union[npt.NDArray[np.int32], None]]:\n        if self.pca_model is None:\n            raise Exception('self.pca_model is None, which probably means that fit() was not called.') # pragma: no cover\n        Y = self.pca_model.transform(snippets.reshape(snippets.shape[0], self.T * self.M))\n        nearest_inds = self.nearest_neighbor_model.kneighbors(Y, n_neighbors=2, return_distance=False)\n        inds = nearest_inds[:, 1] # don't use the first because that could be an identical match\n        return self.all_training_labels[inds], self.all_training_offsets[inds]\n    def apply_label_mapping(self, mapping: Dict[int, int]):\n        for k1, k2 in mapping.items():\n            self.all_training_labels[self.all_training_labels == k1] = k2", "\n@dataclass\nclass TrainingBatch:\n    snippets: npt.NDArray[np.float32]\n    label: int\n    offset: int\n    @property\n    def num_snippets(self):\n        return self.snippets.shape[0]"]}
{"filename": "mountainsort5/core/get_sampled_recording_for_training.py", "chunked_list": ["import spikeinterface as si\nimport numpy as np\nfrom typing import Literal\n\n\ndef get_sampled_recording_for_training(\n    recording: si.BaseRecording, *,\n    training_duration_sec: float,\n    mode: Literal['initial', 'uniform'] = 'initial'\n) -> si.BaseRecording:\n    \"\"\"Get a sampled recording for the purpose of training\n\n    Args:\n        recording (si.BaseRecording): SpikeInterface recording object\n        training_duration_sec (float): Duration of the training in seconds\n        mode (str): 'initial' or 'uniform'\n\n    Returns:\n        si.BaseRecording: SpikeInterface recording object\n    \"\"\"\n    if training_duration_sec * recording.sampling_frequency >= recording.get_num_frames():\n        # if the training duration is longer than the recording, then just use the entire recording\n        return recording\n    if mode == 'initial':\n        traces = recording.get_traces(start_frame=0, end_frame=int(training_duration_sec * recording.sampling_frequency))\n    elif mode == 'uniform':\n        # use chunks of 10 seconds\n        chunk_size = int(recording.sampling_frequency * min(10, training_duration_sec))\n        # the number of chunks depends on the training duration\n        num_chunks = int(np.ceil(training_duration_sec * recording.sampling_frequency / chunk_size))\n        chunk_sizes = [chunk_size for i in range(num_chunks)]\n        chunk_sizes[-1] = int(training_duration_sec * recording.sampling_frequency - (num_chunks - 1) * chunk_size)\n        if num_chunks == 1:\n            # if only 1 chunk, then just use the initial chunk\n            traces = recording.get_traces(start_frame=0, end_frame=int(training_duration_sec * recording.sampling_frequency))\n        else:\n            # the spacing between the chunks\n            spacing = int((recording.get_num_frames() - np.sum(chunk_sizes)) / (num_chunks - 1))\n            traces_list: list[np.ndarray] = []\n            tt = 0\n            for i in range(num_chunks):\n                start_frame = tt\n                end_frame = int(start_frame + chunk_sizes[i])\n                traces_list.append(recording.get_traces(start_frame=start_frame, end_frame=end_frame))\n                tt += int(chunk_sizes[i] + spacing)\n            traces = np.concatenate(traces_list, axis=0)\n    else:\n        raise Exception('Invalid mode: ' + mode) # pragma: no cover\n    \n    rec = si.NumpyRecording(\n        traces_list=[traces],\n        sampling_frequency=recording.sampling_frequency,\n        channel_ids=recording.get_channel_ids()\n    )\n    rec.set_channel_locations(recording.get_channel_locations())\n    return rec"]}
{"filename": "mountainsort5/core/detect_spikes.py", "chunked_list": ["from typing import Tuple, Union\nimport numpy as np\nimport numpy.typing as npt\n\n\ndef detect_spikes(\n    traces: npt.NDArray[np.float32], *,\n    channel_locations: npt.NDArray[np.float32],\n    time_radius: int,\n    channel_radius: Union[float, None],\n    detect_threshold: float,\n    detect_sign: int,\n    margin_left: int,\n    margin_right: int,\n    verbose: bool\n) -> Tuple[npt.NDArray[np.int32], npt.NDArray[np.int32]]:\n    N = traces.shape[0]\n    M = traces.shape[1]\n\n    if detect_sign > 0:\n        # todo: figure out how to avoid making a copy\n        traces = -traces # pragma: no cover\n    elif detect_sign == 0:\n        # todo: figure out how to avoid making a copy\n        traces = -np.abs(traces) # pragma: no cover\n    \n    adjacency = []\n    for m in range(M):\n        adjacency.append([])\n        for m2 in range(M):\n            dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n            if (channel_radius is None) or (dist0 <= channel_radius):\n                adjacency[m].append(m2)\n    print('')\n    print(f'Adjacency for detect spikes with channel radius {channel_radius}')\n    print(adjacency)\n    print('')\n    \n    inds1, inds2 = np.nonzero(traces <= -detect_threshold)\n    \n    candidate_times = [[] for m in range(M)]\n    candidate_values = [[] for m in range(M)]\n    for i in range(len(inds1)):\n        if inds1[i] >= margin_left and inds1[i] < N - margin_right:\n            candidate_times[inds2[i]].append(inds1[i])\n            candidate_values[inds2[i]].append(traces[inds1[i], inds2[i]])\n\n    times = []\n    channel_indices = []\n    for m in range(M):\n        nbhd = adjacency[m]\n        if verbose:\n            print(f'm = {m} (nbhd size: {len(nbhd)})')\n        indices = [0 for j in range(len(nbhd))]\n        for i in range(len(candidate_times[m])):\n            t = candidate_times[m][i]\n            v = candidate_values[m][i]\n            okay = True\n            for j in range(len(nbhd)):\n                if not okay:\n                    break\n                tt = candidate_times[nbhd[j]]\n                vv = candidate_values[nbhd[j]]\n                ii = indices[j]\n                while ii < len(tt) and tt[ii] < t - time_radius:\n                    ii += 1\n                indices[j] = ii # advance\n                jj = ii\n                while jj < len(tt) and tt[jj] <= t + time_radius:\n                    if vv[jj] < v:\n                        okay =False\n                        break\n                    jj += 1\n            if okay:\n                times.append(t)\n                channel_indices.append(m)\n    \n    times = np.array(times, dtype=np.int32)\n    channel_indices = np.array(channel_indices, dtype=np.int32)\n    inds = np.argsort(times)\n    times = times[inds]\n    channel_indices = channel_indices[inds]\n    return times, channel_indices", "\n"]}
{"filename": "mountainsort5/schemes/Scheme3SortingParameters.py", "chunked_list": ["import numpy as np\nfrom typing import Union, Literal\nfrom dataclasses import dataclass\nfrom .Scheme2SortingParameters import Scheme2SortingParameters\n\n\n@dataclass\nclass Scheme3SortingParameters:\n    \"\"\"Parameters for MountainSort sorting scheme 3\n\n    - block_sorting_parameters: Scheme2SortingParameters for individual blocks\n    - block_duration_sec: duration of each block\n    \"\"\"\n    block_sorting_parameters: Scheme2SortingParameters\n    block_duration_sec: float\n\n    def check_valid(self, *, M: int, N: int, sampling_frequency: float, channel_locations: Union[np.ndarray, None]=None):\n        \"\"\"Internal function for checking validity of parameters\"\"\"\n        self.block_sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n        assert self.block_duration_sec > 0", ""]}
{"filename": "mountainsort5/schemes/sorting_scheme3.py", "chunked_list": ["from typing import Dict, Union\nimport numpy as np\nimport numpy.typing as npt\nimport spikeinterface as si\nfrom .Scheme3SortingParameters import Scheme3SortingParameters\nfrom .sorting_scheme2 import get_time_chunks\nfrom .sorting_scheme2 import sorting_scheme2, get_times_labels_from_sorting\nfrom ..core.get_block_recording_for_scheme3 import get_block_recording_for_scheme3\nfrom ..core.SnippetClassifier import SnippetClassifier\nfrom ..core.get_times_labels_from_sorting import get_times_labels_from_sorting", "from ..core.SnippetClassifier import SnippetClassifier\nfrom ..core.get_times_labels_from_sorting import get_times_labels_from_sorting\n\n\ndef sorting_scheme3(\n    recording: si.BaseRecording, *,\n    sorting_parameters: Scheme3SortingParameters\n) -> si.BaseSorting:\n    \"\"\"MountainSort 5 sorting scheme 3\n\n    Args:\n        recording (si.BaseRecording): SpikeInterface recording object\n        sorting_parameters (Scheme3SortingParameters): Sorting parameters\n\n    Returns:\n        si.BaseSorting: SpikeInterface sorting object\n    \"\"\"\n\n    ###################################################################\n    # Handle multi-segment recordings\n    if recording.get_num_segments() > 1:\n        print('Recording has multiple segments. Joining segments for sorting...')\n        recording_joined = si.concatenate_recordings(recording_list=[recording])\n        sorting_joined = sorting_scheme3(recording_joined, sorting_parameters=sorting_parameters)\n        print('Splitting sorting into segments to match original multisegment recording...')\n        sorting = si.split_sorting(sorting_joined, recording_joined)\n        return sorting\n    ###################################################################\n\n    M = recording.get_num_channels()\n    N = recording.get_num_frames()\n    sampling_frequency = recording.sampling_frequency\n    channel_locations = recording.get_channel_locations()\n\n    sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n\n    block_size = int(sorting_parameters.block_duration_sec * sampling_frequency) # size of chunks in samples\n    blocks = get_time_chunks(recording.get_num_samples(), chunk_size=block_size, padding=1000)\n\n    times_list: list[npt.NDArray[np.int64]] = []\n    labels_list: list[npt.NDArray[np.int32]] = []\n    last_label_used = 0\n    previous_snippet_classifiers: Union[Dict[int, SnippetClassifier], None] = None\n    for i, chunk in enumerate(blocks):\n        print('')\n        print('=============================================')\n        print(f'Processing block {i + 1} of {len(blocks)}...')\n        subrecording = get_block_recording_for_scheme3(recording=recording, start_frame=chunk.start - chunk.padding_left, end_frame=chunk.end + chunk.padding_right)\n        subsorting, snippet_classifiers = sorting_scheme2(\n            subrecording,\n            sorting_parameters=sorting_parameters.block_sorting_parameters,\n            return_snippet_classifiers=True,\n            reference_snippet_classifiers=previous_snippet_classifiers,\n            label_offset=last_label_used\n        )\n        previous_snippet_classifiers = snippet_classifiers\n        times0, labels0 = get_times_labels_from_sorting(subsorting)\n        valid_inds = np.where((times0 >= chunk.padding_left) & (times0 < chunk.padding_left + (chunk.end - chunk.start)))[0]\n        times0: npt.NDArray[np.int32] = times0[valid_inds]\n        labels0: npt.NDArray[np.int32] = labels0[valid_inds]\n        times0 = times0.astype(np.int64) + chunk.start - np.int64(chunk.padding_left)\n        if len(labels0) > 0:\n            last_label_used = max(last_label_used, np.max(labels0))\n        times_list.append(times0)\n        labels_list.append(labels0)\n    \n    times_concat = np.concatenate(times_list)\n    labels_concat = np.concatenate(labels_list)\n\n    # Now create a new sorting object from the times and labels results\n    sorting2 = si.NumpySorting.from_times_labels([times_concat], [labels_concat], sampling_frequency=recording.sampling_frequency)\n\n    return sorting2"]}
{"filename": "mountainsort5/schemes/__init__.py", "chunked_list": [""]}
{"filename": "mountainsort5/schemes/Scheme2SortingParameters.py", "chunked_list": ["import numpy as np\nimport numpy.typing as npt\nfrom typing import Union, Literal\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Scheme2SortingParameters:\n    \"\"\"Parameters for MountainSort sorting scheme 2\n\n    See Scheme1SortingParameters for more details on the parameters below.\n\n    - phase1_detect_channel_radius: detect_channel_radius in phase 1\n    - detect_channel_radius: detect_channel_radius in phase 2\n    - phase1_detect_threshold: detect_threshold in phase 1\n    - phase1_detect_time_radius_msec: detect_time_radius_msec in phase 1\n    - detect_time_radius_msec: detect_time_radius_msec in phase 2\n    - phase1_npca_per_channel: npca_per_channel in phase 1\n    - phase1_npca_per_subdivision: npca_per_subdivision in phase 1\n    - detect_sign\n    - detect_threshold: detect_threshold in phase 2\n    - snippet_T1\n    - snippet_T2\n    - snippet_mask_radius\n    - max_num_snippets_per_training_batch: the maximum number of snippets to use for training the classifier in each batch\n    - classifier_npca: the number of principal components to use for each neighborhood classifier\n    - training_duration_sec: the duration of the training data (in seconds)\n    - training_recording_sampling_mode: how to sample the training data. If 'initial', then the first training_duration_sec of the recording will be used. If 'uniform', then the training data will be sampled uniformly in 10-second chunks from the recording.\n    \"\"\"\n    phase1_detect_channel_radius: Union[float, None]\n    detect_channel_radius: Union[float, None]\n    phase1_detect_threshold: float=5.5\n    phase1_detect_time_radius_msec: float=1.5\n    detect_time_radius_msec: float=0.5\n    phase1_npca_per_channel: int=3\n    phase1_npca_per_subdivision: int=10\n    subdivision: int=10\n    phase1_pairwise_merge_step: bool=False # deprecated\n    detect_sign: int=-1\n    detect_threshold: float=5.5\n    snippet_T1: int=20\n    snippet_T2: int=20\n    snippet_mask_radius: Union[float, None]=None\n    max_num_snippets_per_training_batch: int=200\n    classifier_npca: Union[int, None]=None\n    training_duration_sec: Union[float, None]=None\n    training_recording_sampling_mode: Literal['initial', 'uniform']='initial'\n\n    def check_valid(self, *, M: int, N: int, sampling_frequency: float, channel_locations: npt.NDArray[np.float32]):\n        \"\"\"Internal function for checking validity of parameters\"\"\"\n        assert channel_locations.shape[0] == M, 'Shape mismatch between traces and channel locations'\n        D = channel_locations.shape[1]\n        assert N >= self.snippet_T1 + self.snippet_T2\n        if self.snippet_mask_radius is not None:\n            assert self.snippet_mask_radius >= 0\n        assert M >= 1 and M < 1e6\n        assert D >= 1 and D <= 3\n        assert sampling_frequency > 0 and sampling_frequency <= 1e7\n        if self.phase1_detect_channel_radius is not None:\n            assert self.phase1_detect_channel_radius > 0\n        assert self.phase1_detect_time_radius_msec > 0 and self.phase1_detect_time_radius_msec <= 1e4\n        assert self.phase1_detect_threshold > 0\n        assert self.detect_sign in [-1, 0, 1]\n        assert self.phase1_npca_per_channel >=1 and self.phase1_npca_per_channel <= 1e3\n        assert self.phase1_npca_per_subdivision >= 1 and self.phase1_npca_per_subdivision <= 1e3", "\n"]}
{"filename": "mountainsort5/schemes/Scheme1SortingParameters.py", "chunked_list": ["import numpy as np\nimport numpy.typing as npt\nfrom typing import Union\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Scheme1SortingParameters:\n    \"\"\"Parameters for MountainSort sorting scheme 1\n    - detect_threshold: the threshold for detection of whitened data\n    - detect_channel_radius: the radius (in units of channel locations) for exluding nearby channels from detection\n    - detect_time_radius_msec: the radius (in msec) for excluding nearby events from detection\n    - detect_sign: the sign of the threshold for detection (1, -1, or 0)\n    - snippet_T1: the number of timepoints before the event to include in the snippet\n    - snippet_T2: the number of timepoints after the event to include in the snippet\n    - snippet_mask_radius: the radius (in units of channel locations) for making a snippet around the central channel\n    - npca_per_channel: the number of PCA components per channel for initial dimension reduction\n    - npca_per_subdivision: the number of PCA components to compute for each subdivision of clustering\n    \"\"\"\n    detect_threshold: float=5.5\n    detect_channel_radius: Union[float, None]=None\n    detect_time_radius_msec: float=0.5\n    detect_sign: int=-1\n    snippet_T1: int=20\n    snippet_T2: int=20\n    snippet_mask_radius: Union[float, None]=None\n    npca_per_channel: int=3\n    npca_per_subdivision: int=10\n    pairwise_merge_step: bool=False # deprecated\n\n    def check_valid(self, *, M: int, N: int, sampling_frequency: float, channel_locations: npt.NDArray[np.float32]):\n        \"\"\"Internal function for checking validity of parameters\"\"\"\n        assert channel_locations.shape[0] == M, 'Shape mismatch between traces and channel locations'\n        D = channel_locations.shape[1]\n        assert N >= self.snippet_T1 + self.snippet_T2\n        if self.snippet_mask_radius is not None:\n            assert self.snippet_mask_radius >= 0\n        assert M >= 1 and M < 1e6\n        assert D >= 1 and D <= 3\n        assert sampling_frequency > 0 and sampling_frequency <= 1e7\n        if self.detect_channel_radius is not None:\n            assert self.detect_channel_radius > 0\n        assert self.detect_time_radius_msec > 0 and self.detect_time_radius_msec <= 1e4\n        assert self.detect_threshold > 0\n        assert self.detect_sign in [-1, 0, 1]\n        assert self.npca_per_channel >= 1 and self.npca_per_channel <= 1e3\n        assert self.npca_per_subdivision >= 1 and self.npca_per_subdivision <= 1e3", "\n"]}
{"filename": "mountainsort5/schemes/sorting_scheme1.py", "chunked_list": ["import numpy as np\nimport numpy.typing as npt\nimport math\nimport spikeinterface as si\nfrom .Scheme1SortingParameters import Scheme1SortingParameters\nfrom ..core.detect_spikes import detect_spikes\nfrom ..core.extract_snippets import extract_snippets\nfrom ..core.isosplit6_subdivision_method import isosplit6_subdivision_method\nfrom ..core.compute_templates import compute_templates\nfrom ..core.compute_pca_features import compute_pca_features", "from ..core.compute_templates import compute_templates\nfrom ..core.compute_pca_features import compute_pca_features\n\n\ndef sorting_scheme1(\n    recording: si.BaseRecording, *,\n    sorting_parameters: Scheme1SortingParameters\n):\n    \"\"\"MountainSort 5 sorting scheme 1\n\n    Args:\n        recording (si.BaseRecording): SpikeInterface recording object\n        sorting_parameters (Scheme2SortingParameters): Sorting parameters\n\n    Returns:\n        si.BaseSorting: SpikeInterface sorting object\n    \"\"\"\n\n    ###################################################################\n    # Handle multi-segment recordings\n    if recording.get_num_segments() > 1:\n        print('Recording has multiple segments. Joining segments for sorting...')\n        recording_joined = si.concatenate_recordings(recording_list=[recording])\n        sorting_joined = sorting_scheme1(recording_joined, sorting_parameters=sorting_parameters)\n        print('Splitting sorting into segments to match original multisegment recording...')\n        sorting = si.split_sorting(sorting_joined, recording_joined)\n        return sorting\n    ###################################################################\n\n    M = recording.get_num_channels()\n    N = recording.get_num_frames()\n    sampling_frequency = recording.sampling_frequency\n\n    channel_locations = recording.get_channel_locations()\n\n    print(f'Number of channels: {M}')\n    print(f'Number of timepoints: {N}')\n    print(f'Sampling frequency: {sampling_frequency} Hz')\n    for m in range(M):\n        print(f'Channel {m}: {channel_locations[m]}')\n\n    sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n    \n    print('Loading traces')\n    traces = recording.get_traces()\n\n    print('Detecting spikes')\n    time_radius = int(math.ceil(sorting_parameters.detect_time_radius_msec / 1000 * sampling_frequency))\n    times, channel_indices = detect_spikes(\n        traces=traces,\n        channel_locations=channel_locations,\n        time_radius=time_radius,\n        channel_radius=sorting_parameters.detect_channel_radius,\n        detect_threshold=sorting_parameters.detect_threshold,\n        detect_sign=sorting_parameters.detect_sign,\n        margin_left=sorting_parameters.snippet_T1,\n        margin_right=sorting_parameters.snippet_T2,\n        verbose=True\n    )\n\n    # this is important because isosplit does not do well with duplicate points\n    times, channel_indices = remove_duplicate_times(times, channel_indices)\n\n    print(f'Extracting {len(times)} snippets')\n    snippets = extract_snippets( # L x T x M\n        traces=traces,\n        channel_locations=channel_locations,\n        mask_radius=sorting_parameters.snippet_mask_radius,\n        times=times,\n        channel_indices=channel_indices,\n        T1=sorting_parameters.snippet_T1,\n        T2=sorting_parameters.snippet_T2\n    )\n    L = snippets.shape[0]\n    T = snippets.shape[1]\n    assert snippets.shape[2] == M\n\n    print('Clustering snippets')\n    features = compute_pca_features(snippets.reshape((L, T * M)), npca=sorting_parameters.npca_per_channel * M)\n    labels = isosplit6_subdivision_method(\n        X=features,\n        npca_per_subdivision=sorting_parameters.npca_per_subdivision\n    )\n    K = int(np.max(labels))\n    print(f'Found {K} clusters')\n\n    print('Computing templates')\n    templates = compute_templates(snippets=snippets, labels=labels) # K x T x M\n    peak_channel_indices = [np.argmin(np.min(templates[i], axis=0)) for i in range(K)]\n\n    print('Determining optimal alignment of templates')\n    offsets = align_templates(templates)\n\n    print('Aligning snippets')\n    snippets = align_snippets(snippets, offsets, labels)\n    # this is tricky - we need to subtract the offset to correspond to shifting the template\n    times = offset_times(times, -offsets, labels)\n\n    print('Clustering aligned snippets')\n    features = compute_pca_features(snippets.reshape((L, T * M)), npca=sorting_parameters.npca_per_channel * M)\n    labels = isosplit6_subdivision_method(\n        X=features,\n        npca_per_subdivision=sorting_parameters.npca_per_subdivision\n    )\n    K = int(np.max(labels))\n    print(f'Found {K} clusters')\n\n    print('Computing templates')\n    templates = compute_templates(snippets=snippets, labels=labels) # K x T x M\n    peak_channel_indices = [np.argmin(np.min(templates[i], axis=0)) for i in range(K)]\n\n    print('Offsetting times to peak')\n    # Now we need to offset the times again so that the spike times correspond to actual peaks\n    offsets_to_peak = determine_offsets_to_peak(templates, detect_sign=sorting_parameters.detect_sign, T1=sorting_parameters.snippet_T1)\n    print('Offsets to peak:', offsets_to_peak)\n    # This time we need to add the offset\n    times = offset_times(times, offsets_to_peak, labels)\n\n    # Now we need to make sure the times are in order, because we have offset them\n    sort_inds = np.argsort(times)\n    times = times[sort_inds]\n    labels = labels[sort_inds]\n\n    # also make sure none of the times are out of bounds now that we have offset them a couple times\n    inds_okay = np.where((times >= sorting_parameters.snippet_T1) & (times < N - sorting_parameters.snippet_T2))[0]\n    times = times[inds_okay]\n    labels = labels[inds_okay]\n\n    print('Reordering units')\n    # relabel so that units are ordered by channel\n    # and we also put any labels that are not used at the end\n    aa = peak_channel_indices\n    for k in range(1, K + 1):\n        inds = np.where(labels == k)[0]\n        if len(inds) == 0:\n            aa[k - 1] = np.Inf\n    new_labels_mapping = np.argsort(np.argsort(aa)) + 1 # too tricky! my head aches right now\n    labels = new_labels_mapping[labels - 1]\n    \n    sorting = si.NumpySorting.from_times_labels(times_list=[times], labels_list=[labels], sampling_frequency=sampling_frequency)\n\n    return sorting", "\ndef remove_duplicate_times(times: npt.NDArray[np.int32], labels: npt.NDArray[np.int32]):\n    inds = np.where(np.diff(times) > 0)[0]\n    inds = np.concatenate([[0], inds + 1])\n    times2 = times[inds]\n    labels2 = labels[inds]\n    return times2, labels2\n\ndef align_templates(templates: npt.NDArray[np.float32]):\n    K = templates.shape[0]\n    T = templates.shape[1]\n    M = templates.shape[2]\n    offsets = np.zeros((K,), dtype=np.int32)\n    pairwise_optimal_offsets = np.zeros((K, K), dtype=np.int32)\n    pairwise_inner_products = np.zeros((K, K), dtype=np.float32)\n    for k1 in range(K):\n        for k2 in range(K):\n            offset, inner_product = compute_pairwise_optimal_offset(templates[k1], templates[k2])\n            pairwise_optimal_offsets[k1, k2] = offset\n            pairwise_inner_products[k1, k2] = inner_product\n    for passnum in range(20):\n        something_changed = False\n        for k1 in range(K):\n            weighted_sum = 0\n            total_weight = 0\n            for k2 in range(K):\n                if k1 != k2:\n                    offset = pairwise_optimal_offsets[k1, k2] + offsets[k2]\n                    weight = pairwise_inner_products[k1, k2]\n                    weighted_sum += weight * offset\n                    total_weight += weight\n            if total_weight > 0:\n                avg_offset = int(weighted_sum / total_weight)\n            else:\n                avg_offset = 0\n            if avg_offset != offsets[k1]:\n                something_changed = True\n                offsets[k1] = avg_offset\n        if not something_changed:\n            print('Template alignment converged.')\n            break\n    print('Align templates offsets: ', offsets)\n    return offsets", "def align_templates(templates: npt.NDArray[np.float32]):\n    K = templates.shape[0]\n    T = templates.shape[1]\n    M = templates.shape[2]\n    offsets = np.zeros((K,), dtype=np.int32)\n    pairwise_optimal_offsets = np.zeros((K, K), dtype=np.int32)\n    pairwise_inner_products = np.zeros((K, K), dtype=np.float32)\n    for k1 in range(K):\n        for k2 in range(K):\n            offset, inner_product = compute_pairwise_optimal_offset(templates[k1], templates[k2])\n            pairwise_optimal_offsets[k1, k2] = offset\n            pairwise_inner_products[k1, k2] = inner_product\n    for passnum in range(20):\n        something_changed = False\n        for k1 in range(K):\n            weighted_sum = 0\n            total_weight = 0\n            for k2 in range(K):\n                if k1 != k2:\n                    offset = pairwise_optimal_offsets[k1, k2] + offsets[k2]\n                    weight = pairwise_inner_products[k1, k2]\n                    weighted_sum += weight * offset\n                    total_weight += weight\n            if total_weight > 0:\n                avg_offset = int(weighted_sum / total_weight)\n            else:\n                avg_offset = 0\n            if avg_offset != offsets[k1]:\n                something_changed = True\n                offsets[k1] = avg_offset\n        if not something_changed:\n            print('Template alignment converged.')\n            break\n    print('Align templates offsets: ', offsets)\n    return offsets", "    \n\ndef compute_pairwise_optimal_offset(template1: npt.NDArray[np.float32], template2: npt.NDArray[np.float32]):\n    T = template1.shape[0]\n    best_inner_product = -np.Inf\n    best_offset = 0\n    for offset in range(T):\n        inner_product = np.sum(np.roll(template1, shift=offset, axis=0) * template2)\n        if inner_product > best_inner_product:\n            best_inner_product = inner_product\n            best_offset = offset\n    if best_offset > T // 2:\n        best_offset = best_offset - T\n    return best_offset, best_inner_product", "\ndef align_snippets(snippets: npt.NDArray[np.float32], offsets: npt.NDArray[np.int32], labels: npt.NDArray[np.int32]):\n    snippets2 = np.zeros_like(snippets)\n    for k in range(1, np.max(labels) + 1):\n        inds = np.where(labels == k)[0]\n        snippets2[inds] = np.roll(snippets[inds], shift=offsets[k - 1], axis=1)\n    return snippets2\n\ndef offset_times(times: npt.NDArray[np.int32], offsets: npt.NDArray[np.int32], labels: npt.NDArray[np.int32]):\n    times2 = np.zeros_like(times)\n    for k in range(1, np.max(labels) + 1):\n        inds = np.where(labels == k)[0]\n        times2[inds] = times[inds] + offsets[k - 1]\n    return times2", "def offset_times(times: npt.NDArray[np.int32], offsets: npt.NDArray[np.int32], labels: npt.NDArray[np.int32]):\n    times2 = np.zeros_like(times)\n    for k in range(1, np.max(labels) + 1):\n        inds = np.where(labels == k)[0]\n        times2[inds] = times[inds] + offsets[k - 1]\n    return times2\n\ndef determine_offsets_to_peak(templates: npt.NDArray[np.float32], *, detect_sign: int, T1: int):\n    K = templates.shape[0]\n\n    if detect_sign < 0:\n        A = -templates\n    elif detect_sign > 0: # pragma: no cover\n        A = templates # pragma: no cover\n    else:\n        A = np.abs(templates) # pragma: no cover\n    \n    offsets_to_peak = np.zeros((K,), dtype=np.int32)\n    for k in range(K):\n        peak_channel = np.argmax(np.max(A[k], axis=0))\n        peak_time = np.argmax(A[k][:, peak_channel])\n        offset_to_peak = peak_time - T1\n        offsets_to_peak[k] = offset_to_peak\n    return offsets_to_peak"]}
{"filename": "mountainsort5/schemes/sorting_scheme2.py", "chunked_list": ["from typing import Dict, Tuple, List, Union\nimport numpy as np\nimport numpy.typing as npt\nimport math\nimport spikeinterface as si\nfrom .Scheme2SortingParameters import Scheme2SortingParameters\nfrom .Scheme1SortingParameters import Scheme1SortingParameters\nfrom ..core.detect_spikes import detect_spikes\nfrom ..core.extract_snippets import extract_snippets, extract_snippets_in_channel_neighborhood\nfrom .sorting_scheme1 import sorting_scheme1", "from ..core.extract_snippets import extract_snippets, extract_snippets_in_channel_neighborhood\nfrom .sorting_scheme1 import sorting_scheme1\nfrom ..core.SnippetClassifier import SnippetClassifier\nfrom ..core.remove_duplicate_events import remove_duplicate_events\nfrom ..core.get_sampled_recording_for_training import get_sampled_recording_for_training\nfrom ..core.get_times_labels_from_sorting import get_times_labels_from_sorting\n\n\ndef sorting_scheme2(\n    recording: si.BaseRecording, *,\n    sorting_parameters: Scheme2SortingParameters,\n    return_snippet_classifiers: bool = False, # used in scheme 3\n    reference_snippet_classifiers: Union[Dict[int, SnippetClassifier], None] = None, # used in scheme 3\n    label_offset: int = 0 # used in scheme 3\n) -> Union[si.BaseSorting, Tuple[si.BaseSorting, Dict[int, SnippetClassifier]]]:\n    \"\"\"MountainSort 5 sorting scheme 2\n\n    Args:\n        recording (si.BaseRecording): SpikeInterface recording object\n        sorting_parameters (Scheme2SortingParameters): Sorting parameters\n        return_snippet_classifiers (bool): whether to return the snippet classifiers (used in scheme 3)\n        reference_snippet_classifiers: used in scheme 3\n        label_offset: used in scheme 3\n\n    Returns:\n        si.BaseSorting: SpikeInterface sorting object\n            or, if return_snippet_classifiers is True:\n        si.BaseSorting, snippet_classifiers\n    \"\"\"\n\n    ###################################################################\n    # Handle multi-segment recordings\n    if recording.get_num_segments() > 1:\n        print('Recording has multiple segments. Joining segments for sorting...')\n        recording_joined = si.concatenate_recordings(recording_list=[recording])\n        sorting_joined, snippet_classifiers = sorting_scheme2(\n            recording_joined,\n            sorting_parameters=sorting_parameters,\n            return_snippet_classifiers=True,\n            reference_snippet_classifiers=reference_snippet_classifiers,\n            label_offset=label_offset\n        )\n        print('Splitting sorting into segments to match original multisegment recording...')\n        sorting = si.split_sorting(sorting_joined, recording_joined)\n        if return_snippet_classifiers:\n            return sorting, snippet_classifiers\n        else:\n            return sorting\n    ###################################################################\n\n    M = recording.get_num_channels()\n    N = recording.get_num_frames()\n    sampling_frequency = recording.sampling_frequency\n    channel_locations = recording.get_channel_locations()\n\n    # check that the sorting parameters are valid\n    sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n\n    # Subsample the recording for training\n    if sorting_parameters.training_duration_sec is not None:\n        training_recording = get_sampled_recording_for_training(\n            recording=recording,\n            training_duration_sec=sorting_parameters.training_duration_sec,\n            mode=sorting_parameters.training_recording_sampling_mode\n        )\n    else:\n        training_recording = recording\n\n    # Run the first phase of spike sorting (same as sorting_scheme1)\n    sorting1 = sorting_scheme1(\n        recording=training_recording,\n        sorting_parameters=Scheme1SortingParameters(\n            detect_threshold=sorting_parameters.phase1_detect_threshold,\n            detect_sign=sorting_parameters.detect_sign,\n            detect_time_radius_msec=sorting_parameters.phase1_detect_time_radius_msec,\n            detect_channel_radius=sorting_parameters.phase1_detect_channel_radius,\n            snippet_mask_radius=sorting_parameters.snippet_mask_radius,\n            snippet_T1=sorting_parameters.snippet_T1,\n            snippet_T2=sorting_parameters.snippet_T2,\n            npca_per_channel=sorting_parameters.phase1_npca_per_channel,\n            npca_per_subdivision=sorting_parameters.phase1_npca_per_subdivision\n        )\n    )\n    times, labels = get_times_labels_from_sorting(sorting1)\n    K = np.max(labels) # number of clusters\n    labels = labels + label_offset # used in scheme 3\n\n    print('Loading training traces')\n    # Load the traces from the training recording\n    training_traces = training_recording.get_traces()\n    training_snippets = extract_snippets(\n        traces=training_traces,\n        channel_locations=None,\n        mask_radius=None,\n        times=times,\n        channel_indices=None,\n        T1=sorting_parameters.snippet_T1,\n        T2=sorting_parameters.snippet_T2\n    )\n\n    print('Training classifier')\n    # Train the classifier based on the labels obtained from the first phase sorting\n    channel_masks: Dict[int, Union[List[int], None]] = {} # by channel\n    for m in range(M):\n        channel_masks[m] = []\n        for m2 in range(M):\n            if sorting_parameters.snippet_mask_radius is not None:\n                if np.linalg.norm(channel_locations[m] - channel_locations[m2]) <= sorting_parameters.snippet_mask_radius:\n                    channel_masks[m].append(m2)\n            else:\n                channel_masks[m] = None\n    snippet_classifiers: Dict[int, SnippetClassifier] = {} # by channel\n    for m in range(M):\n        snippet_classifiers[m] = SnippetClassifier(npca=sorting_parameters.classifier_npca)\n        # Add random snippets to classifier with label 0 (a noise cluster for classification)\n        uniformly_spread_times = np.floor(np.linspace(sorting_parameters.snippet_T1, training_traces.shape[0] - sorting_parameters.snippet_T2 - 1, sorting_parameters.max_num_snippets_per_training_batch)).astype(np.int32)\n        random_snippets = extract_snippets_in_channel_neighborhood(\n            traces=training_traces,\n            times=uniformly_spread_times,\n            neighborhood=channel_masks[m],\n            T1=sorting_parameters.snippet_T1,\n            T2=sorting_parameters.snippet_T2\n        )\n        snippet_classifiers[m].add_training_snippets(random_snippets, label=0, offset=0)\n\n    for k in range(label_offset + 1, label_offset + K + 1):\n        inds0 = np.where(labels == k)[0]\n        snippets0 = training_snippets[inds0]\n        template0 = np.median(snippets0, axis=0) # T x M\n        if sorting_parameters.detect_sign < 0:\n            AA = -template0\n        elif sorting_parameters.detect_sign > 0: # pragma: no cover\n            AA = template0 # pragma: no cover\n        else:\n            AA = np.abs(template0) # pragma: no cover\n        peak_indices_over_channels = np.argmax(AA, axis=0)\n        peak_values_over_channels = np.max(AA, axis=0)\n        peaks_to_include: List[dict] = []\n        for m in range(M):\n            if peak_values_over_channels[m] >= sorting_parameters.detect_threshold * 0.4: # should be a parameter\n                peaks_to_include.append({\n                    'channel': m,\n                    'offset': peak_indices_over_channels[m] - sorting_parameters.snippet_T1\n                })\n        for peak in peaks_to_include:\n            m = peak['channel']\n            offset = peak['offset']\n            if channel_masks[m] is not None:\n                snippets0_masked = snippets0[:, :, channel_masks[m]]\n            else:\n                snippets0_masked = snippets0\n            snippet_classifiers[m].add_training_snippets(\n                snippets=subsample_snippets(np.roll(snippets0_masked, shift=-offset, axis=1), sorting_parameters.max_num_snippets_per_training_batch),\n                label=k,\n                offset=offset\n            )\n    training_snippets = None # Free up memory\n    print('Fitting models')\n    for m in range(M):\n        snippet_classifiers[m].fit()\n\n    # Now that we have the classifier, we can do the full sorting\n    # Iterate over time chunks, detect and classify all spikes, and collect the results\n    chunk_size = int(math.ceil(100e6 / recording.get_num_channels())) # size of chunks in samples\n    print(f'Chunk size: {chunk_size / recording.sampling_frequency} sec')\n    chunks = get_time_chunks(recording.get_num_samples(), chunk_size=chunk_size, padding=1000)\n    times_list: list[npt.NDArray[np.int64]] = []\n    labels_list: list[npt.NDArray[np.int32]] = []\n    labels_reference_list = [] if reference_snippet_classifiers is not None else None\n    for i, chunk in enumerate(chunks):\n        print(f'Time chunk {i + 1} of {len(chunks)}')\n        print('Loading traces')\n        traces_chunk = recording.get_traces(start_frame=chunk.start - chunk.padding_left, end_frame=chunk.end + chunk.padding_right)\n        print('Detecting spikes')\n        time_radius = int(math.ceil(sorting_parameters.detect_time_radius_msec / 1000 * sampling_frequency))\n        times_chunk, channel_indices_chunk = detect_spikes(\n            traces=traces_chunk,\n            channel_locations=channel_locations,\n            time_radius=time_radius,\n            channel_radius=sorting_parameters.detect_channel_radius,\n            detect_threshold=sorting_parameters.detect_threshold,\n            detect_sign=sorting_parameters.detect_sign,\n            margin_left=sorting_parameters.snippet_T1,\n            margin_right=sorting_parameters.snippet_T2,\n            verbose=False\n        )\n\n        print('Extracting and classifying snippets')\n        labels_chunk = np.zeros(len(times_chunk), dtype='int32')\n        labels_reference_chunk = np.zeros(len(times_chunk), dtype='int32') if reference_snippet_classifiers is not None else None\n        for m in range(M):\n            inds = np.where(channel_indices_chunk == m)[0]\n            if len(inds) > 0:\n                snippets2 = extract_snippets_in_channel_neighborhood(\n                    traces=traces_chunk,\n                    times=times_chunk[inds],\n                    neighborhood=channel_masks[m],\n                    T1=sorting_parameters.snippet_T1,\n                    T2=sorting_parameters.snippet_T2\n                )\n                labels_chunk_m, offsets_chunk_m = snippet_classifiers[m].classify_snippets(snippets2)\n                if labels_chunk_m is not None:\n                    labels_chunk[inds] = labels_chunk_m\n                    times_chunk[inds] = times_chunk[inds] - offsets_chunk_m\n                if reference_snippet_classifiers is not None:\n                    labels_reference_chunk_m, _ = reference_snippet_classifiers[m].classify_snippets(snippets2)\n                    if labels_reference_chunk_m is not None:\n                        labels_reference_chunk[inds] = labels_reference_chunk_m\n\n        # remove events with label 0\n        valid_inds = np.where(labels_chunk > 0)[0]\n        times_chunk: npt.NDArray[np.int32] = times_chunk[valid_inds]\n        labels_chunk: npt.NDArray[np.int32] = labels_chunk[valid_inds]\n        labels_reference_chunk = labels_reference_chunk[valid_inds] if reference_snippet_classifiers is not None else None\n\n        # now that we offset them we need to re-sort\n        sort_inds2 = np.argsort(times_chunk)\n        times_chunk: npt.NDArray[np.int32] = times_chunk[sort_inds2]\n        labels_chunk: npt.NDArray[np.int32] = labels_chunk[sort_inds2]\n        labels_reference_chunk = labels_reference_chunk[sort_inds2] if reference_snippet_classifiers is not None else None\n\n        print('Removing duplicates')\n        new_inds = remove_duplicate_events(times_chunk, labels_chunk, tol=time_radius)\n        times_chunk: npt.NDArray[np.int32] = times_chunk[new_inds]\n        labels_chunk: npt.NDArray[np.int32] = labels_chunk[new_inds]\n        labels_reference_chunk = labels_reference_chunk[new_inds] if reference_snippet_classifiers is not None else None\n\n        # remove events in the margins\n        valid_inds = np.where((chunk.padding_left <= times_chunk) & (times_chunk < chunk.total_size - chunk.padding_right))[0]\n        times_chunk: npt.NDArray[np.int32] = times_chunk[valid_inds]\n        labels_chunk: npt.NDArray[np.int32] = labels_chunk[valid_inds]\n        labels_reference_chunk = labels_reference_chunk[valid_inds] if reference_snippet_classifiers is not None else None\n\n        # don't forget to cast to int64 add the chunk start time\n        times_list.append(\n            times_chunk.astype(np.int64) + chunk.start - chunk.padding_left\n        )\n        labels_list.append(labels_chunk)\n        if reference_snippet_classifiers is not None:\n            labels_reference_list.append(labels_reference_chunk)\n\n    # Now concatenate the results\n    times_concat: npt.NDArray[np.int64] = np.concatenate(times_list)\n    labels_concat: npt.NDArray[np.int32] = np.concatenate(labels_list)\n    labels_reference_concat = np.concatenate(labels_reference_list) if reference_snippet_classifiers is not None else None\n\n    if reference_snippet_classifiers is not None:\n        mapping = get_labels_to_reference_labels_mapping(labels_concat, labels_reference_concat, label_offset=label_offset)\n        print('==== mapping =======================')\n        for k1, k2 in mapping.items():\n            print(f'{k1} -> {k2}')\n        print('====================================')\n        for m in range(M):\n            snippet_classifiers[m].apply_label_mapping(mapping)\n        for k1, k2 in mapping.items():\n            labels_concat[labels_concat == k1] = k2\n\n    # Now create a new sorting object from the times and labels results\n    sorting2 = si.NumpySorting.from_times_labels([times_concat], [labels_concat], sampling_frequency=recording.sampling_frequency)\n\n    if return_snippet_classifiers:\n        return sorting2, snippet_classifiers\n    else:\n        return sorting2", "def sorting_scheme2(\n    recording: si.BaseRecording, *,\n    sorting_parameters: Scheme2SortingParameters,\n    return_snippet_classifiers: bool = False, # used in scheme 3\n    reference_snippet_classifiers: Union[Dict[int, SnippetClassifier], None] = None, # used in scheme 3\n    label_offset: int = 0 # used in scheme 3\n) -> Union[si.BaseSorting, Tuple[si.BaseSorting, Dict[int, SnippetClassifier]]]:\n    \"\"\"MountainSort 5 sorting scheme 2\n\n    Args:\n        recording (si.BaseRecording): SpikeInterface recording object\n        sorting_parameters (Scheme2SortingParameters): Sorting parameters\n        return_snippet_classifiers (bool): whether to return the snippet classifiers (used in scheme 3)\n        reference_snippet_classifiers: used in scheme 3\n        label_offset: used in scheme 3\n\n    Returns:\n        si.BaseSorting: SpikeInterface sorting object\n            or, if return_snippet_classifiers is True:\n        si.BaseSorting, snippet_classifiers\n    \"\"\"\n\n    ###################################################################\n    # Handle multi-segment recordings\n    if recording.get_num_segments() > 1:\n        print('Recording has multiple segments. Joining segments for sorting...')\n        recording_joined = si.concatenate_recordings(recording_list=[recording])\n        sorting_joined, snippet_classifiers = sorting_scheme2(\n            recording_joined,\n            sorting_parameters=sorting_parameters,\n            return_snippet_classifiers=True,\n            reference_snippet_classifiers=reference_snippet_classifiers,\n            label_offset=label_offset\n        )\n        print('Splitting sorting into segments to match original multisegment recording...')\n        sorting = si.split_sorting(sorting_joined, recording_joined)\n        if return_snippet_classifiers:\n            return sorting, snippet_classifiers\n        else:\n            return sorting\n    ###################################################################\n\n    M = recording.get_num_channels()\n    N = recording.get_num_frames()\n    sampling_frequency = recording.sampling_frequency\n    channel_locations = recording.get_channel_locations()\n\n    # check that the sorting parameters are valid\n    sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n\n    # Subsample the recording for training\n    if sorting_parameters.training_duration_sec is not None:\n        training_recording = get_sampled_recording_for_training(\n            recording=recording,\n            training_duration_sec=sorting_parameters.training_duration_sec,\n            mode=sorting_parameters.training_recording_sampling_mode\n        )\n    else:\n        training_recording = recording\n\n    # Run the first phase of spike sorting (same as sorting_scheme1)\n    sorting1 = sorting_scheme1(\n        recording=training_recording,\n        sorting_parameters=Scheme1SortingParameters(\n            detect_threshold=sorting_parameters.phase1_detect_threshold,\n            detect_sign=sorting_parameters.detect_sign,\n            detect_time_radius_msec=sorting_parameters.phase1_detect_time_radius_msec,\n            detect_channel_radius=sorting_parameters.phase1_detect_channel_radius,\n            snippet_mask_radius=sorting_parameters.snippet_mask_radius,\n            snippet_T1=sorting_parameters.snippet_T1,\n            snippet_T2=sorting_parameters.snippet_T2,\n            npca_per_channel=sorting_parameters.phase1_npca_per_channel,\n            npca_per_subdivision=sorting_parameters.phase1_npca_per_subdivision\n        )\n    )\n    times, labels = get_times_labels_from_sorting(sorting1)\n    K = np.max(labels) # number of clusters\n    labels = labels + label_offset # used in scheme 3\n\n    print('Loading training traces')\n    # Load the traces from the training recording\n    training_traces = training_recording.get_traces()\n    training_snippets = extract_snippets(\n        traces=training_traces,\n        channel_locations=None,\n        mask_radius=None,\n        times=times,\n        channel_indices=None,\n        T1=sorting_parameters.snippet_T1,\n        T2=sorting_parameters.snippet_T2\n    )\n\n    print('Training classifier')\n    # Train the classifier based on the labels obtained from the first phase sorting\n    channel_masks: Dict[int, Union[List[int], None]] = {} # by channel\n    for m in range(M):\n        channel_masks[m] = []\n        for m2 in range(M):\n            if sorting_parameters.snippet_mask_radius is not None:\n                if np.linalg.norm(channel_locations[m] - channel_locations[m2]) <= sorting_parameters.snippet_mask_radius:\n                    channel_masks[m].append(m2)\n            else:\n                channel_masks[m] = None\n    snippet_classifiers: Dict[int, SnippetClassifier] = {} # by channel\n    for m in range(M):\n        snippet_classifiers[m] = SnippetClassifier(npca=sorting_parameters.classifier_npca)\n        # Add random snippets to classifier with label 0 (a noise cluster for classification)\n        uniformly_spread_times = np.floor(np.linspace(sorting_parameters.snippet_T1, training_traces.shape[0] - sorting_parameters.snippet_T2 - 1, sorting_parameters.max_num_snippets_per_training_batch)).astype(np.int32)\n        random_snippets = extract_snippets_in_channel_neighborhood(\n            traces=training_traces,\n            times=uniformly_spread_times,\n            neighborhood=channel_masks[m],\n            T1=sorting_parameters.snippet_T1,\n            T2=sorting_parameters.snippet_T2\n        )\n        snippet_classifiers[m].add_training_snippets(random_snippets, label=0, offset=0)\n\n    for k in range(label_offset + 1, label_offset + K + 1):\n        inds0 = np.where(labels == k)[0]\n        snippets0 = training_snippets[inds0]\n        template0 = np.median(snippets0, axis=0) # T x M\n        if sorting_parameters.detect_sign < 0:\n            AA = -template0\n        elif sorting_parameters.detect_sign > 0: # pragma: no cover\n            AA = template0 # pragma: no cover\n        else:\n            AA = np.abs(template0) # pragma: no cover\n        peak_indices_over_channels = np.argmax(AA, axis=0)\n        peak_values_over_channels = np.max(AA, axis=0)\n        peaks_to_include: List[dict] = []\n        for m in range(M):\n            if peak_values_over_channels[m] >= sorting_parameters.detect_threshold * 0.4: # should be a parameter\n                peaks_to_include.append({\n                    'channel': m,\n                    'offset': peak_indices_over_channels[m] - sorting_parameters.snippet_T1\n                })\n        for peak in peaks_to_include:\n            m = peak['channel']\n            offset = peak['offset']\n            if channel_masks[m] is not None:\n                snippets0_masked = snippets0[:, :, channel_masks[m]]\n            else:\n                snippets0_masked = snippets0\n            snippet_classifiers[m].add_training_snippets(\n                snippets=subsample_snippets(np.roll(snippets0_masked, shift=-offset, axis=1), sorting_parameters.max_num_snippets_per_training_batch),\n                label=k,\n                offset=offset\n            )\n    training_snippets = None # Free up memory\n    print('Fitting models')\n    for m in range(M):\n        snippet_classifiers[m].fit()\n\n    # Now that we have the classifier, we can do the full sorting\n    # Iterate over time chunks, detect and classify all spikes, and collect the results\n    chunk_size = int(math.ceil(100e6 / recording.get_num_channels())) # size of chunks in samples\n    print(f'Chunk size: {chunk_size / recording.sampling_frequency} sec')\n    chunks = get_time_chunks(recording.get_num_samples(), chunk_size=chunk_size, padding=1000)\n    times_list: list[npt.NDArray[np.int64]] = []\n    labels_list: list[npt.NDArray[np.int32]] = []\n    labels_reference_list = [] if reference_snippet_classifiers is not None else None\n    for i, chunk in enumerate(chunks):\n        print(f'Time chunk {i + 1} of {len(chunks)}')\n        print('Loading traces')\n        traces_chunk = recording.get_traces(start_frame=chunk.start - chunk.padding_left, end_frame=chunk.end + chunk.padding_right)\n        print('Detecting spikes')\n        time_radius = int(math.ceil(sorting_parameters.detect_time_radius_msec / 1000 * sampling_frequency))\n        times_chunk, channel_indices_chunk = detect_spikes(\n            traces=traces_chunk,\n            channel_locations=channel_locations,\n            time_radius=time_radius,\n            channel_radius=sorting_parameters.detect_channel_radius,\n            detect_threshold=sorting_parameters.detect_threshold,\n            detect_sign=sorting_parameters.detect_sign,\n            margin_left=sorting_parameters.snippet_T1,\n            margin_right=sorting_parameters.snippet_T2,\n            verbose=False\n        )\n\n        print('Extracting and classifying snippets')\n        labels_chunk = np.zeros(len(times_chunk), dtype='int32')\n        labels_reference_chunk = np.zeros(len(times_chunk), dtype='int32') if reference_snippet_classifiers is not None else None\n        for m in range(M):\n            inds = np.where(channel_indices_chunk == m)[0]\n            if len(inds) > 0:\n                snippets2 = extract_snippets_in_channel_neighborhood(\n                    traces=traces_chunk,\n                    times=times_chunk[inds],\n                    neighborhood=channel_masks[m],\n                    T1=sorting_parameters.snippet_T1,\n                    T2=sorting_parameters.snippet_T2\n                )\n                labels_chunk_m, offsets_chunk_m = snippet_classifiers[m].classify_snippets(snippets2)\n                if labels_chunk_m is not None:\n                    labels_chunk[inds] = labels_chunk_m\n                    times_chunk[inds] = times_chunk[inds] - offsets_chunk_m\n                if reference_snippet_classifiers is not None:\n                    labels_reference_chunk_m, _ = reference_snippet_classifiers[m].classify_snippets(snippets2)\n                    if labels_reference_chunk_m is not None:\n                        labels_reference_chunk[inds] = labels_reference_chunk_m\n\n        # remove events with label 0\n        valid_inds = np.where(labels_chunk > 0)[0]\n        times_chunk: npt.NDArray[np.int32] = times_chunk[valid_inds]\n        labels_chunk: npt.NDArray[np.int32] = labels_chunk[valid_inds]\n        labels_reference_chunk = labels_reference_chunk[valid_inds] if reference_snippet_classifiers is not None else None\n\n        # now that we offset them we need to re-sort\n        sort_inds2 = np.argsort(times_chunk)\n        times_chunk: npt.NDArray[np.int32] = times_chunk[sort_inds2]\n        labels_chunk: npt.NDArray[np.int32] = labels_chunk[sort_inds2]\n        labels_reference_chunk = labels_reference_chunk[sort_inds2] if reference_snippet_classifiers is not None else None\n\n        print('Removing duplicates')\n        new_inds = remove_duplicate_events(times_chunk, labels_chunk, tol=time_radius)\n        times_chunk: npt.NDArray[np.int32] = times_chunk[new_inds]\n        labels_chunk: npt.NDArray[np.int32] = labels_chunk[new_inds]\n        labels_reference_chunk = labels_reference_chunk[new_inds] if reference_snippet_classifiers is not None else None\n\n        # remove events in the margins\n        valid_inds = np.where((chunk.padding_left <= times_chunk) & (times_chunk < chunk.total_size - chunk.padding_right))[0]\n        times_chunk: npt.NDArray[np.int32] = times_chunk[valid_inds]\n        labels_chunk: npt.NDArray[np.int32] = labels_chunk[valid_inds]\n        labels_reference_chunk = labels_reference_chunk[valid_inds] if reference_snippet_classifiers is not None else None\n\n        # don't forget to cast to int64 add the chunk start time\n        times_list.append(\n            times_chunk.astype(np.int64) + chunk.start - chunk.padding_left\n        )\n        labels_list.append(labels_chunk)\n        if reference_snippet_classifiers is not None:\n            labels_reference_list.append(labels_reference_chunk)\n\n    # Now concatenate the results\n    times_concat: npt.NDArray[np.int64] = np.concatenate(times_list)\n    labels_concat: npt.NDArray[np.int32] = np.concatenate(labels_list)\n    labels_reference_concat = np.concatenate(labels_reference_list) if reference_snippet_classifiers is not None else None\n\n    if reference_snippet_classifiers is not None:\n        mapping = get_labels_to_reference_labels_mapping(labels_concat, labels_reference_concat, label_offset=label_offset)\n        print('==== mapping =======================')\n        for k1, k2 in mapping.items():\n            print(f'{k1} -> {k2}')\n        print('====================================')\n        for m in range(M):\n            snippet_classifiers[m].apply_label_mapping(mapping)\n        for k1, k2 in mapping.items():\n            labels_concat[labels_concat == k1] = k2\n\n    # Now create a new sorting object from the times and labels results\n    sorting2 = si.NumpySorting.from_times_labels([times_concat], [labels_concat], sampling_frequency=recording.sampling_frequency)\n\n    if return_snippet_classifiers:\n        return sorting2, snippet_classifiers\n    else:\n        return sorting2", "\n# Here's what this function does:\n# 1. For each unit, find the matching unit in the reference (has to be a MUTUAL >0.5 overlap)\n# 2. If the matching unit is found, then map the unit to the matching unit\n# 3. If the matching unit is not found, then map it to the smallest unused label starting with label_offset+1\ndef get_labels_to_reference_labels_mapping(labels: npt.NDArray[np.int32], labels_reference: npt.NDArray[np.int32], *, label_offset) -> Dict[int, int]:\n    mapping: Dict[int, int] = {}\n    unique_labels = np.sort(np.unique(labels))\n    last_used_k = label_offset\n    for k in unique_labels:\n        mapping[k] = None # initialize to None, if it stays as None, then we will need to create a new label\n        inds = np.where(labels == k)[0]\n        a = labels_reference[inds]\n        k_refs, k_ref_counts = np.unique(a, return_counts=True)\n        for ii in range(len(k_refs)):\n            if k_ref_counts[ii] > 0.5 * len(inds): # the 0.5 is chosen so we don't map to the same unit twice\n                inds_ref = np.where(labels_reference == k_refs[ii])[0] # import to test the other way around\n                if k_ref_counts[ii] > 0.5 * len(inds_ref): # mutual overlap\n                    mapping[k] = k_refs[ii] # map to the reference label\n                    break\n        if mapping[k] is None: # if not mapped to reference label, then create a new label\n            mapping[k] = last_used_k + 1\n            last_used_k = mapping[k]\n    return mapping", "\nclass TimeChunk:\n    def __init__(self, start: np.int64, end: np.int64, padding_left: np.int32, padding_right: np.int32):\n        self.start = start\n        self.end = end\n        self.padding_left = padding_left\n        self.padding_right = padding_right\n        self.total_size = self.end - self.start + np.int64(padding_left) + np.int64(padding_right)\n\ndef get_time_chunks(num_samples: np.int64, chunk_size: np.int32, padding: np.int32) -> List[TimeChunk]:\n    \"\"\"Get time chunks\n    Inputs:\n        num_samples: number of samples in the recording\n        chunk_size: size of each chunk in samples\n        padding: padding on each side of the chunk in samples\n    Returns:\n        chunks: list of TimeChunk objects\n    \"\"\"\n    chunks = []\n    start = np.int64(0)\n    while start < num_samples:\n        end = np.int64(start) + np.int64(chunk_size)\n        if end > num_samples:\n            end = num_samples\n        padding_left = min(padding, start)\n        padding_right = min(padding, num_samples - end)\n        chunks.append(TimeChunk(start=start, end=end, padding_left=padding_left, padding_right=padding_right))\n        start = end\n    return chunks", "\ndef get_time_chunks(num_samples: np.int64, chunk_size: np.int32, padding: np.int32) -> List[TimeChunk]:\n    \"\"\"Get time chunks\n    Inputs:\n        num_samples: number of samples in the recording\n        chunk_size: size of each chunk in samples\n        padding: padding on each side of the chunk in samples\n    Returns:\n        chunks: list of TimeChunk objects\n    \"\"\"\n    chunks = []\n    start = np.int64(0)\n    while start < num_samples:\n        end = np.int64(start) + np.int64(chunk_size)\n        if end > num_samples:\n            end = num_samples\n        padding_left = min(padding, start)\n        padding_right = min(padding, num_samples - end)\n        chunks.append(TimeChunk(start=start, end=end, padding_left=padding_left, padding_right=padding_right))\n        start = end\n    return chunks", "\ndef subsample_snippets(snippets: npt.NDArray[np.float32], max_num: int) -> np.ndarray:\n    \"\"\"Subsample snippets\n    Inputs:\n        snippets: 3D array of snippets (num_snippets x T x M)\n        max_num: maximum number of snippets to return\n    Returns:\n        snippets_out: 3D array of snippets (num_snippets x T x M)\n    \"\"\"\n    num_snippets = snippets.shape[0]\n    if num_snippets > max_num:\n        inds = np.arange(0, max_num) * num_snippets // max_num\n        snippets_out = snippets[inds]\n    else:\n        snippets_out = snippets\n    return snippets_out"]}
{"filename": "examples/scheme3/generate_visualization_output.py", "chunked_list": ["from typing import List\nimport os\nimport time\nimport json\nimport yaml\nimport numpy as np\nimport spikeinterface as si\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5", "import spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nimport spikeforest as sf\nimport figurl as fg\nimport sortingview.views as vv\nfrom mountainsort5.core.extract_snippets import extract_snippets\nfrom helpers.create_autocorrelograms_view import create_autocorrelograms_view\nfrom helpers.compute_correlogram_data import compute_correlogram_data\nfrom spikeforest.load_spikeforest_recordings import SFRecording\n", "from spikeforest.load_spikeforest_recordings import SFRecording\n\n\ndef generate_visualization_output(*, rec: SFRecording, recording_preprocessed: si.BaseRecording, sorting: si.BaseSorting, sorting_true: si.BaseSorting):\n    os.environ['KACHERY_STORE_FILE_DIR'] = f'output/{rec.recording_name}'\n    os.environ['KACHERY_STORE_FILE_PREFIX'] = f'$dir'\n\n    if not os.path.exists('output'):\n        os.mkdir('output')\n    output_dir = os.environ['KACHERY_STORE_FILE_DIR']\n    if not os.path.exists(output_dir):\n        os.mkdir(output_dir)\n    if not os.path.exists(f'{output_dir}/recording'):\n        print('Saving preprocessed recording')\n        recording_preprocessed.save(folder=f'{output_dir}/recording', format='binary')\n    \n    units_dict = {}\n    units_dict['true'] = sorting_true.get_unit_spike_train(sorting_true.unit_ids[0], segment_index=0).astype(np.int32)\n    for unit_id in sorting.unit_ids:\n        units_dict[str(unit_id)] = sorting.get_unit_spike_train(unit_id, segment_index=0).astype(np.int32)\n    sorting_with_true = si.NumpySorting.from_dict([units_dict], sampling_frequency=sorting.sampling_frequency)\n\n    print('Loading traces')\n    recording_preprocessed\n    traces = recording_preprocessed.get_traces()\n    channel_locations = recording_preprocessed.get_channel_locations()\n    \n    unit_ids = sorting_with_true.unit_ids\n    channel_ids = recording_preprocessed.channel_ids\n    K = len(unit_ids)\n    M = len(recording_preprocessed.channel_ids)\n    T1 = 20\n    T2 = 20\n    T = T1 + T2\n    print('Compute templates')\n    templates = np.zeros((K, T, M), dtype=np.float32)\n    for i in range(K):\n        unit_id = unit_ids[i]\n        times1 = sorting_with_true.get_unit_spike_train(unit_id, segment_index=0)\n        snippets1 = extract_snippets(traces, channel_locations=None, mask_radius=None, times=times1, channel_indices=None, T1=T1, T2=T2)\n        templates[i] = np.median(snippets1, axis=0)\n    peak_channels = {\n        str(unit_ids[i]): channel_ids[np.argmin(np.min(templates[i], axis=0))]\n        for i in range(K)\n    }\n    \n    sorting_data = {\n        'samplingFrequency': sorting_with_true.get_sampling_frequency(),\n        'units': [\n            {\n                'unitId': f'{unit_id}',\n                'peakChannelId': peak_channels[str(unit_id)],\n                'spikeTrain': sorting_with_true.get_unit_spike_train(unit_id).astype(np.int32)\n            }\n            for unit_id in sorting_with_true.unit_ids\n            if len(sorting_with_true.get_unit_spike_train(unit_id)) > 0\n        ]\n    }\n    with open(f'{output_dir}/sorting.json', 'w') as f:\n        json.dump(fg.serialize_data(sorting_data), f)\n    \n    v_et = vv.EphysTraces(\n        format='spikeinterface.binary',\n        uri=f'$dir/recording',\n        sorting_uri=f'$dir/sorting.json'\n    )\n\n    # v_et_2 = vv.EphysTraces(\n    #     format='spikeinterface.binary',\n    #     uri='$dir/generated/recording',\n    #     sorting_uri=f'$dir/generated/test_mountainsort_sorting.json'\n    # )\n\n    # auto-correlograms\n    print('Auto correlograms')\n    v_ac = create_autocorrelograms_view(sorting=sorting_with_true)\n\n    adjacency_radius = 100\n    adjacency = {}\n    for m in range(M):\n        adjacency[str(channel_ids[m])] = []\n        for m2 in range(M):\n            dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n            if dist0 <= adjacency_radius:\n                adjacency[str(channel_ids[m])].append(str(channel_ids[m2]))\n\n    # cross-correlograms\n    print('Cross correlograms')\n    cross_correlogram_items: List[vv.CrossCorrelogramItem] = []\n    for unit_id1 in sorting_with_true.unit_ids:\n        for unit_id2 in sorting_with_true.unit_ids:\n            if str(peak_channels[str(unit_id1)]) in adjacency[str(peak_channels[str(unit_id2)])]:\n                a = compute_correlogram_data(sorting=sorting_with_true, unit_id1=unit_id1, unit_id2=unit_id2, window_size_msec=80, bin_size_msec=1)\n                bin_edges_sec = a['bin_edges_sec']\n                bin_counts = a['bin_counts']\n                cross_correlogram_items.append(\n                    vv.CrossCorrelogramItem(\n                        unit_id1 = str(unit_id1),\n                        unit_id2 = str(unit_id2),\n                        bin_edges_sec = bin_edges_sec,\n                        bin_counts = bin_counts\n                    )\n                )\n    v_cc = vv.CrossCorrelograms(\n        cross_correlograms=cross_correlogram_items,\n        hide_unit_selector=True\n    )\n\n    # units table\n    print('Units table')\n    v_ut = vv.UnitsTable(\n        columns=[\n        ],\n        rows=[\n            vv.UnitsTableRow(str(unit_id), {\n            })\n            for unit_id in sorting_with_true.get_unit_ids()\n        ]\n    )\n\n    view = vv.Box(\n        direction='horizontal',\n        items=[\n            vv.LayoutItem(v_ut, stretch=0, min_size=150, max_size=150),\n            vv.LayoutItem(v_ac, stretch=0, min_size=400, max_size=400),\n            vv.LayoutItem(\n                vv.Splitter(\n                    direction='horizontal',\n                    item1=vv.LayoutItem(v_cc, stretch=1),\n                    item2=vv.LayoutItem(\n                        vv.TabLayout(\n                            items=[\n                                vv.TabLayoutItem(label='preprocessed', view=v_et),\n                                # vv.TabLayoutItem(label='full', view=v_et_2)\n                            ]\n                        ),\n                        stretch=1\n                    )\n                ), stretch=1\n            )\n        ]\n    )\n\n    dd = view.url_dict(label=f'{rec.recording_name}')\n    with open(f'{output_dir}/view.yaml', 'w') as f:\n        yaml.dump(dd, f)"]}
{"filename": "examples/scheme3/toy_example.py", "chunked_list": ["import os\nimport time\nimport shutil\nimport spikeinterface.extractors as se\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nfrom generate_visualization_output import generate_visualization_output\nfrom spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\nimport spikeinterface as si", "from spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\nimport spikeinterface as si\n\ndef main():\n    recording, sorting_true = se.toy_example(\n        duration=60 * 30,\n        num_channels=8,\n        num_units=16,\n        sampling_frequency=30000,\n        num_segments=1,\n        seed=0\n    )\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5 (scheme 3)')\n    sorting = ms5.sorting_scheme3(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme3SortingParameters(\n            block_sorting_parameters=ms5.Scheme2SortingParameters(\n                phase1_detect_channel_radius=150,\n                detect_channel_radius=50,\n                training_duration_sec=60\n            ),\n            block_duration_sec=60 * 5\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        if os.path.exists('output/toy_example'):\n            shutil.rmtree('output/toy_example')\n        rec = SFRecording({\n            'name': 'toy_example',\n            'studyName': 'toy_example',\n            'studySetName': 'toy_example',\n            'sampleRateHz': recording_preprocessed.get_sampling_frequency(),\n            'numChannels': recording_preprocessed.get_num_channels(),\n            'durationSec': recording_preprocessed.get_total_duration(),\n            'numTrueUnits': sorting_true.get_num_units(),\n            'sortingTrueObject': {},\n            'recordingObject': {}\n        })\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\nif __name__ == '__main__':\n    main()"]}
{"filename": "examples/scheme3/helpers/compute_correlogram_data.py", "chunked_list": ["from typing import Union\nimport spikeinterface as si\nimport numpy as np\n\ndef compute_correlogram_data(*, sorting: si.BaseSorting, unit_id1: int, unit_id2: Union[int, None]=None, window_size_msec: float, bin_size_msec: float):\n    times1 = sorting.get_unit_spike_train(unit_id=unit_id1, segment_index=0)\n    num_bins = int(window_size_msec / bin_size_msec)\n    if num_bins % 2 == 0: num_bins = num_bins - 1 # odd number of bins\n    num_bins_half = int((num_bins + 1) / 2)\n    bin_edges_msec = np.array((np.arange(num_bins + 1) - num_bins / 2) * bin_size_msec, dtype=np.float32)\n    bin_counts = np.zeros((num_bins,), dtype=np.int32)\n    if unit_id2 is None or unit_id1 == unit_id2:\n        # autocorrelogram\n        offset = 1\n        while True:\n            if offset >= len(times1): break\n            deltas_msec = (times1[offset:] - times1[:-offset]) / sorting.get_sampling_frequency() * 1000\n            deltas_msec = deltas_msec[deltas_msec <= bin_edges_msec[-1]]\n            if len(deltas_msec) == 0: break\n            for i in range(num_bins_half):\n                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n                end_msec = bin_edges_msec[num_bins_half + i]\n                ct = len(deltas_msec[(start_msec <= deltas_msec) & (deltas_msec < end_msec)])\n                bin_counts[num_bins_half - 1 + i] += ct\n                bin_counts[num_bins_half - 1 - i] += ct\n            offset = offset + 1\n    else:\n        # cross-correlogram\n        times2 = sorting.get_unit_spike_train(segment_index=0, unit_id=unit_id2)\n        all_times = np.concatenate((times1, times2))\n        all_labels = np.concatenate((1 * np.ones(times1.shape), 2 * np.ones(times2.shape)))\n        sort_inds = np.argsort(all_times)\n        all_times = all_times[sort_inds]\n        all_labels = all_labels[sort_inds]\n        offset = 1\n        while True:\n            if offset >= len(all_times): break\n            deltas_msec = (all_times[offset:] - all_times[:-offset]) / sorting.get_sampling_frequency() * 1000\n\n            deltas12_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 1)]\n            deltas21_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 2)]\n            deltas11_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 1)]\n            deltas22_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 2)]\n\n            deltas12_msec = deltas12_msec[deltas12_msec <= bin_edges_msec[-1]]\n            deltas21_msec = deltas21_msec[deltas21_msec <= bin_edges_msec[-1]]\n            deltas11_msec = deltas11_msec[deltas11_msec <= bin_edges_msec[-1]]\n            deltas22_msec = deltas22_msec[deltas22_msec <= bin_edges_msec[-1]]\n\n            if (len(deltas12_msec) + len(deltas21_msec) + len(deltas11_msec) + len(deltas22_msec)) == 0: break\n            \n            for i in range(num_bins_half):\n                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n                end_msec = bin_edges_msec[num_bins_half + i]\n                ct12 = len(deltas12_msec[(start_msec <= deltas12_msec) & (deltas12_msec < end_msec)])\n                ct21 = len(deltas21_msec[(start_msec <= deltas21_msec) & (deltas21_msec < end_msec)])\n                bin_counts[num_bins_half - 1 + i] += ct12\n                bin_counts[num_bins_half - 1 - i] += ct21\n            offset = offset + 1\n    return {\n        'bin_edges_sec': (bin_edges_msec / 1000).astype(np.float32),\n        'bin_counts': bin_counts.astype(np.int32)\n    }"]}
{"filename": "examples/scheme3/helpers/create_autocorrelograms_view.py", "chunked_list": ["from typing import List\nimport spikeinterface as si\nimport sortingview.views as vv\nfrom helpers.compute_correlogram_data import compute_correlogram_data\n\n\ndef create_autocorrelograms_view(*, sorting: si.BaseSorting, unit_id_prefix: str=''):\n    autocorrelogram_items: List[vv.AutocorrelogramItem] = []\n    for unit_id in sorting.get_unit_ids():\n        a = compute_correlogram_data(sorting=sorting, unit_id1=unit_id, unit_id2=None, window_size_msec=80, bin_size_msec=1)\n        bin_edges_sec = a['bin_edges_sec']\n        bin_counts = a['bin_counts']\n        autocorrelogram_items.append(\n            vv.AutocorrelogramItem(\n                unit_id=f'{unit_id_prefix}{unit_id}',\n                bin_edges_sec=bin_edges_sec,\n                bin_counts=bin_counts\n            )\n        )\n    view = vv.Autocorrelograms(\n        autocorrelograms=autocorrelogram_items\n    )\n    return view"]}
{"filename": "examples/scheme3/helpers/create_units_table.py", "chunked_list": ["from typing import List\nimport sortingview.views as vv\nimport spikeinterface as si\n\n\ndef create_units_table(*, sorting: si.BaseSorting):\n    columns: List[vv.UnitsTableColumn] = []\n    rows: List[vv.UnitsTableRow] = []\n    for unit_id in sorting.get_unit_ids():\n        rows.append(\n            vv.UnitsTableRow(\n                unit_id=unit_id,\n                values={\n                    'unitId': unit_id\n                }\n            )\n        )\n    view = vv.UnitsTable(\n        columns=columns,\n        rows=rows\n    )\n    return view", ""]}
{"filename": "examples/scheme2/generate_visualization_output.py", "chunked_list": ["from typing import List\nimport os\nimport time\nimport json\nimport yaml\nimport numpy as np\nimport spikeinterface as si\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5", "import spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nimport spikeforest as sf\nimport figurl as fg\nimport sortingview.views as vv\nfrom mountainsort5.core.extract_snippets import extract_snippets\nfrom helpers.create_autocorrelograms_view import create_autocorrelograms_view\nfrom helpers.compute_correlogram_data import compute_correlogram_data\nfrom spikeforest.load_spikeforest_recordings import SFRecording\n", "from spikeforest.load_spikeforest_recordings import SFRecording\n\n\ndef generate_visualization_output(*, rec: SFRecording, recording_preprocessed: si.BaseRecording, sorting: si.BaseSorting, sorting_true: si.BaseSorting):\n    os.environ['KACHERY_STORE_FILE_DIR'] = f'output/{rec.recording_name}'\n    os.environ['KACHERY_STORE_FILE_PREFIX'] = f'$dir'\n\n    if not os.path.exists('output'):\n        os.mkdir('output')\n    output_dir = os.environ['KACHERY_STORE_FILE_DIR']\n    if not os.path.exists(output_dir):\n        os.mkdir(output_dir)\n    if not os.path.exists(f'{output_dir}/recording'):\n        print('Saving preprocessed recording')\n        recording_preprocessed.save(folder=f'{output_dir}/recording', format='binary')\n    \n    units_dict = {}\n    units_dict['true'] = sorting_true.get_unit_spike_train(sorting_true.unit_ids[0], segment_index=0).astype(np.int32)\n    for unit_id in sorting.unit_ids:\n        units_dict[str(unit_id)] = sorting.get_unit_spike_train(unit_id, segment_index=0).astype(np.int32)\n    sorting_with_true = si.NumpySorting.from_dict([units_dict], sampling_frequency=sorting.sampling_frequency)\n\n    print('Loading traces')\n    recording_preprocessed\n    traces = recording_preprocessed.get_traces()\n    channel_locations = recording_preprocessed.get_channel_locations()\n    \n    unit_ids = sorting_with_true.unit_ids\n    channel_ids = recording_preprocessed.channel_ids\n    K = len(unit_ids)\n    M = len(recording_preprocessed.channel_ids)\n    T1 = 20\n    T2 = 20\n    T = T1 + T2\n    print('Compute templates')\n    templates = np.zeros((K, T, M), dtype=np.float32)\n    for i in range(K):\n        unit_id = unit_ids[i]\n        times1 = sorting_with_true.get_unit_spike_train(unit_id, segment_index=0)\n        snippets1 = extract_snippets(traces, channel_locations=None, mask_radius=None, times=times1, channel_indices=None, T1=T1, T2=T2)\n        templates[i] = np.median(snippets1, axis=0)\n    peak_channels = {\n        str(unit_ids[i]): channel_ids[np.argmin(np.min(templates[i], axis=0))]\n        for i in range(K)\n    }\n    \n    sorting_data = {\n        'samplingFrequency': sorting_with_true.get_sampling_frequency(),\n        'units': [\n            {\n                'unitId': f'{unit_id}',\n                'peakChannelId': peak_channels[str(unit_id)],\n                'spikeTrain': sorting_with_true.get_unit_spike_train(unit_id).astype(np.int32)\n            }\n            for unit_id in sorting_with_true.unit_ids\n            if len(sorting_with_true.get_unit_spike_train(unit_id)) > 0\n        ]\n    }\n    with open(f'{output_dir}/sorting.json', 'w') as f:\n        json.dump(fg.serialize_data(sorting_data), f)\n    \n    v_et = vv.EphysTraces(\n        format='spikeinterface.binary',\n        uri=f'$dir/recording',\n        sorting_uri=f'$dir/sorting.json'\n    )\n\n    # v_et_2 = vv.EphysTraces(\n    #     format='spikeinterface.binary',\n    #     uri='$dir/generated/recording',\n    #     sorting_uri=f'$dir/generated/test_mountainsort_sorting.json'\n    # )\n\n    # auto-correlograms\n    print('Auto correlograms')\n    v_ac = create_autocorrelograms_view(sorting=sorting_with_true)\n\n    adjacency_radius = 100\n    adjacency = {}\n    for m in range(M):\n        adjacency[str(channel_ids[m])] = []\n        for m2 in range(M):\n            dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n            if dist0 <= adjacency_radius:\n                adjacency[str(channel_ids[m])].append(str(channel_ids[m2]))\n\n    # cross-correlograms\n    print('Cross correlograms')\n    cross_correlogram_items: List[vv.CrossCorrelogramItem] = []\n    for unit_id1 in sorting_with_true.unit_ids:\n        for unit_id2 in sorting_with_true.unit_ids:\n            if str(peak_channels[str(unit_id1)]) in adjacency[str(peak_channels[str(unit_id2)])]:\n                a = compute_correlogram_data(sorting=sorting_with_true, unit_id1=unit_id1, unit_id2=unit_id2, window_size_msec=80, bin_size_msec=1)\n                bin_edges_sec = a['bin_edges_sec']\n                bin_counts = a['bin_counts']\n                cross_correlogram_items.append(\n                    vv.CrossCorrelogramItem(\n                        unit_id1 = str(unit_id1),\n                        unit_id2 = str(unit_id2),\n                        bin_edges_sec = bin_edges_sec,\n                        bin_counts = bin_counts\n                    )\n                )\n    v_cc = vv.CrossCorrelograms(\n        cross_correlograms=cross_correlogram_items,\n        hide_unit_selector=True\n    )\n\n    # units table\n    print('Units table')\n    v_ut = vv.UnitsTable(\n        columns=[\n        ],\n        rows=[\n            vv.UnitsTableRow(str(unit_id), {\n            })\n            for unit_id in sorting_with_true.get_unit_ids()\n        ]\n    )\n\n    view = vv.Box(\n        direction='horizontal',\n        items=[\n            vv.LayoutItem(v_ut, stretch=0, min_size=150, max_size=150),\n            vv.LayoutItem(v_ac, stretch=0, min_size=400, max_size=400),\n            vv.LayoutItem(\n                vv.Splitter(\n                    direction='horizontal',\n                    item1=vv.LayoutItem(v_cc, stretch=1),\n                    item2=vv.LayoutItem(\n                        vv.TabLayout(\n                            items=[\n                                vv.TabLayoutItem(label='preprocessed', view=v_et),\n                                # vv.TabLayoutItem(label='full', view=v_et_2)\n                            ]\n                        ),\n                        stretch=1\n                    )\n                ), stretch=1\n            )\n        ]\n    )\n\n    dd = view.url_dict(label=f'{rec.recording_name}')\n    with open(f'{output_dir}/view.yaml', 'w') as f:\n        yaml.dump(dd, f)"]}
{"filename": "examples/scheme2/toy_example.py", "chunked_list": ["import os\nimport time\nimport shutil\nimport spikeinterface.extractors as se\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nfrom generate_visualization_output import generate_visualization_output\nfrom spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\nimport spikeinterface as si", "from spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\nimport spikeinterface as si\n\ndef main():\n    recording, sorting_true = se.toy_example(duration=60 * 30, num_channels=16, num_units=32, sampling_frequency=30000, num_segments=1, seed=0)\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5 (scheme 2)')\n    sorting = ms5.sorting_scheme2(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme2SortingParameters(\n            phase1_detect_channel_radius=150,\n            detect_channel_radius=50,\n            training_duration_sec=60\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        if os.path.exists('output/toy_example'):\n            shutil.rmtree('output/toy_example')\n        rec = SFRecording({\n            'name': 'toy_example',\n            'studyName': 'toy_example',\n            'studySetName': 'toy_example',\n            'sampleRateHz': recording_preprocessed.get_sampling_frequency(),\n            'numChannels': recording_preprocessed.get_num_channels(),\n            'durationSec': recording_preprocessed.get_total_duration(),\n            'numTrueUnits': sorting_true.get_num_units(),\n            'sortingTrueObject': {},\n            'recordingObject': {}\n        })\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\nif __name__ == '__main__':\n    main()"]}
{"filename": "examples/scheme2/paired_english.py", "chunked_list": ["import os\nimport time\nimport spikeinterface as si\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nimport spikeforest as sf\nfrom generate_visualization_output import generate_visualization_output\n\ndef main():\n    paired_english_uri = 'sha1://dfb1fd134bfc209ece21fd5f8eefa992f49e8962?paired-english-spikeforest-recordings.json'\n\n    recordings = sf.load_spikeforest_recordings(paired_english_uri)\n\n    # list recordings\n    # for rec in recordings:\n    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # select recording\n    # rec = recordings[1] # m57_191105_160026 32 channels; 343.4533333333333 sec - amplitude too low\n    rec = recordings[13] # m15_190315_152315_cell1 32 channels; 669.3997 sec # classic example of need for final alignment merge step\n\n    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # this will download the recording/sorting_true from kachery\n    print('Loading recording and sorting_true')\n    recording = rec.get_recording_extractor()\n    sorting_true = rec.get_sorting_true_extractor()\n\n    channel_locations = recording.get_channel_locations()\n    for m in range(channel_locations.shape[0]):\n        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme2(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme2SortingParameters(\n            phase1_detect_channel_radius=200,\n            detect_channel_radius=30,\n            snippet_mask_radius=150,\n            training_duration_sec=300\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\ndef main():\n    paired_english_uri = 'sha1://dfb1fd134bfc209ece21fd5f8eefa992f49e8962?paired-english-spikeforest-recordings.json'\n\n    recordings = sf.load_spikeforest_recordings(paired_english_uri)\n\n    # list recordings\n    # for rec in recordings:\n    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # select recording\n    # rec = recordings[1] # m57_191105_160026 32 channels; 343.4533333333333 sec - amplitude too low\n    rec = recordings[13] # m15_190315_152315_cell1 32 channels; 669.3997 sec # classic example of need for final alignment merge step\n\n    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # this will download the recording/sorting_true from kachery\n    print('Loading recording and sorting_true')\n    recording = rec.get_recording_extractor()\n    sorting_true = rec.get_sorting_true_extractor()\n\n    channel_locations = recording.get_channel_locations()\n    for m in range(channel_locations.shape[0]):\n        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme2(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme2SortingParameters(\n            phase1_detect_channel_radius=200,\n            detect_channel_radius=30,\n            snippet_mask_radius=150,\n            training_duration_sec=300\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\nif __name__ == '__main__':\n    main()"]}
{"filename": "examples/scheme2/helpers/compute_correlogram_data.py", "chunked_list": ["from typing import Union\nimport spikeinterface as si\nimport numpy as np\n\ndef compute_correlogram_data(*, sorting: si.BaseSorting, unit_id1: int, unit_id2: Union[int, None]=None, window_size_msec: float, bin_size_msec: float):\n    times1 = sorting.get_unit_spike_train(unit_id=unit_id1, segment_index=0)\n    num_bins = int(window_size_msec / bin_size_msec)\n    if num_bins % 2 == 0: num_bins = num_bins - 1 # odd number of bins\n    num_bins_half = int((num_bins + 1) / 2)\n    bin_edges_msec = np.array((np.arange(num_bins + 1) - num_bins / 2) * bin_size_msec, dtype=np.float32)\n    bin_counts = np.zeros((num_bins,), dtype=np.int32)\n    if unit_id2 is None or unit_id1 == unit_id2:\n        # autocorrelogram\n        offset = 1\n        while True:\n            if offset >= len(times1): break\n            deltas_msec = (times1[offset:] - times1[:-offset]) / sorting.get_sampling_frequency() * 1000\n            deltas_msec = deltas_msec[deltas_msec <= bin_edges_msec[-1]]\n            if len(deltas_msec) == 0: break\n            for i in range(num_bins_half):\n                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n                end_msec = bin_edges_msec[num_bins_half + i]\n                ct = len(deltas_msec[(start_msec <= deltas_msec) & (deltas_msec < end_msec)])\n                bin_counts[num_bins_half - 1 + i] += ct\n                bin_counts[num_bins_half - 1 - i] += ct\n            offset = offset + 1\n    else:\n        # cross-correlogram\n        times2 = sorting.get_unit_spike_train(segment_index=0, unit_id=unit_id2)\n        all_times = np.concatenate((times1, times2))\n        all_labels = np.concatenate((1 * np.ones(times1.shape), 2 * np.ones(times2.shape)))\n        sort_inds = np.argsort(all_times)\n        all_times = all_times[sort_inds]\n        all_labels = all_labels[sort_inds]\n        offset = 1\n        while True:\n            if offset >= len(all_times): break\n            deltas_msec = (all_times[offset:] - all_times[:-offset]) / sorting.get_sampling_frequency() * 1000\n\n            deltas12_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 1)]\n            deltas21_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 2)]\n            deltas11_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 1)]\n            deltas22_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 2)]\n\n            deltas12_msec = deltas12_msec[deltas12_msec <= bin_edges_msec[-1]]\n            deltas21_msec = deltas21_msec[deltas21_msec <= bin_edges_msec[-1]]\n            deltas11_msec = deltas11_msec[deltas11_msec <= bin_edges_msec[-1]]\n            deltas22_msec = deltas22_msec[deltas22_msec <= bin_edges_msec[-1]]\n\n            if (len(deltas12_msec) + len(deltas21_msec) + len(deltas11_msec) + len(deltas22_msec)) == 0: break\n            \n            for i in range(num_bins_half):\n                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n                end_msec = bin_edges_msec[num_bins_half + i]\n                ct12 = len(deltas12_msec[(start_msec <= deltas12_msec) & (deltas12_msec < end_msec)])\n                ct21 = len(deltas21_msec[(start_msec <= deltas21_msec) & (deltas21_msec < end_msec)])\n                bin_counts[num_bins_half - 1 + i] += ct12\n                bin_counts[num_bins_half - 1 - i] += ct21\n            offset = offset + 1\n    return {\n        'bin_edges_sec': (bin_edges_msec / 1000).astype(np.float32),\n        'bin_counts': bin_counts.astype(np.int32)\n    }"]}
{"filename": "examples/scheme2/helpers/create_autocorrelograms_view.py", "chunked_list": ["from typing import List\nimport spikeinterface as si\nimport sortingview.views as vv\nfrom helpers.compute_correlogram_data import compute_correlogram_data\n\n\ndef create_autocorrelograms_view(*, sorting: si.BaseSorting, unit_id_prefix: str=''):\n    autocorrelogram_items: List[vv.AutocorrelogramItem] = []\n    for unit_id in sorting.get_unit_ids():\n        a = compute_correlogram_data(sorting=sorting, unit_id1=unit_id, unit_id2=None, window_size_msec=80, bin_size_msec=1)\n        bin_edges_sec = a['bin_edges_sec']\n        bin_counts = a['bin_counts']\n        autocorrelogram_items.append(\n            vv.AutocorrelogramItem(\n                unit_id=f'{unit_id_prefix}{unit_id}',\n                bin_edges_sec=bin_edges_sec,\n                bin_counts=bin_counts\n            )\n        )\n    view = vv.Autocorrelograms(\n        autocorrelograms=autocorrelogram_items\n    )\n    return view"]}
{"filename": "examples/scheme2/helpers/create_units_table.py", "chunked_list": ["from typing import List\nimport sortingview.views as vv\nimport spikeinterface as si\n\n\ndef create_units_table(*, sorting: si.BaseSorting):\n    columns: List[vv.UnitsTableColumn] = []\n    rows: List[vv.UnitsTableRow] = []\n    for unit_id in sorting.get_unit_ids():\n        rows.append(\n            vv.UnitsTableRow(\n                unit_id=unit_id,\n                values={\n                    'unitId': unit_id\n                }\n            )\n        )\n    view = vv.UnitsTable(\n        columns=columns,\n        rows=rows\n    )\n    return view", ""]}
{"filename": "examples/scheme1/generate_visualization_output.py", "chunked_list": ["from typing import List\nimport os\nimport time\nimport json\nimport yaml\nimport numpy as np\nimport spikeinterface as si\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5", "import spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nimport spikeforest as sf\nimport figurl as fg\nimport sortingview.views as vv\nfrom mountainsort5.core.extract_snippets import extract_snippets\nfrom helpers.create_autocorrelograms_view import create_autocorrelograms_view\nfrom helpers.compute_correlogram_data import compute_correlogram_data\nfrom spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\n", "from spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\n\n\ndef generate_visualization_output(*, rec: SFRecording, recording_preprocessed: si.BaseRecording, sorting: si.BaseSorting, sorting_true: si.BaseSorting):\n    os.environ['KACHERY_STORE_FILE_DIR'] = f'output/{rec.recording_name}'\n    os.environ['KACHERY_STORE_FILE_PREFIX'] = f'$dir'\n\n    if not os.path.exists('output'):\n        os.mkdir('output')\n    output_dir = os.environ['KACHERY_STORE_FILE_DIR']\n    if not os.path.exists(output_dir):\n        os.mkdir(output_dir)\n    if not os.path.exists(f'{output_dir}/recording'):\n        print('Saving preprocessed recording')\n        recording_preprocessed.save(folder=f'{output_dir}/recording', format='binary')\n    \n    units_dict = {}\n    units_dict['true'] = sorting_true.get_unit_spike_train(sorting_true.unit_ids[0], segment_index=0).astype(np.int32)\n    for unit_id in sorting.unit_ids:\n        units_dict[str(unit_id)] = sorting.get_unit_spike_train(unit_id, segment_index=0).astype(np.int32)\n    sorting_with_true = si.NumpySorting.from_dict([units_dict], sampling_frequency=sorting.sampling_frequency)\n\n    print('Loading traces')\n    recording_preprocessed\n    traces = recording_preprocessed.get_traces()\n    channel_locations = recording_preprocessed.get_channel_locations()\n    \n    unit_ids = sorting_with_true.unit_ids\n    channel_ids = recording_preprocessed.channel_ids\n    K = len(unit_ids)\n    M = len(recording_preprocessed.channel_ids)\n    T1 = 20\n    T2 = 20\n    T = T1 + T2\n    print('Compute templates')\n    templates = np.zeros((K, T, M), dtype=np.float32)\n    for i in range(K):\n        unit_id = unit_ids[i]\n        times1 = sorting_with_true.get_unit_spike_train(unit_id, segment_index=0)\n        snippets1 = extract_snippets(traces, channel_locations=None, mask_radius=None, times=times1, channel_indices=None, T1=T1, T2=T2)\n        templates[i] = np.median(snippets1, axis=0)\n    peak_channels = {\n        str(unit_ids[i]): channel_ids[np.argmin(np.min(templates[i], axis=0))]\n        for i in range(K)\n    }\n    \n    sorting_data = {\n        'samplingFrequency': sorting_with_true.get_sampling_frequency(),\n        'units': [\n            {\n                'unitId': f'{unit_id}',\n                'peakChannelId': peak_channels[str(unit_id)],\n                'spikeTrain': sorting_with_true.get_unit_spike_train(unit_id).astype(np.int32)\n            }\n            for unit_id in sorting_with_true.unit_ids\n            if len(sorting_with_true.get_unit_spike_train(unit_id)) > 0\n        ]\n    }\n    with open(f'{output_dir}/sorting.json', 'w') as f:\n        json.dump(fg.serialize_data(sorting_data), f)\n    \n    v_et = vv.EphysTraces(\n        format='spikeinterface.binary',\n        uri=f'$dir/recording',\n        sorting_uri=f'$dir/sorting.json'\n    )\n\n    # v_et_2 = vv.EphysTraces(\n    #     format='spikeinterface.binary',\n    #     uri='$dir/generated/recording',\n    #     sorting_uri=f'$dir/generated/test_mountainsort_sorting.json'\n    # )\n\n    # auto-correlograms\n    print('Auto correlograms')\n    v_ac = create_autocorrelograms_view(sorting=sorting_with_true)\n\n    adjacency_radius = 100\n    adjacency = {}\n    for m in range(M):\n        adjacency[str(channel_ids[m])] = []\n        for m2 in range(M):\n            dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n            if dist0 <= adjacency_radius:\n                adjacency[str(channel_ids[m])].append(str(channel_ids[m2]))\n\n    # cross-correlograms\n    print('Cross correlograms')\n    cross_correlogram_items: List[vv.CrossCorrelogramItem] = []\n    for unit_id1 in sorting_with_true.unit_ids:\n        for unit_id2 in sorting_with_true.unit_ids:\n            if str(peak_channels[str(unit_id1)]) in adjacency[str(peak_channels[str(unit_id2)])]:\n                a = compute_correlogram_data(sorting=sorting_with_true, unit_id1=unit_id1, unit_id2=unit_id2, window_size_msec=80, bin_size_msec=1)\n                bin_edges_sec = a['bin_edges_sec']\n                bin_counts = a['bin_counts']\n                cross_correlogram_items.append(\n                    vv.CrossCorrelogramItem(\n                        unit_id1 = str(unit_id1),\n                        unit_id2 = str(unit_id2),\n                        bin_edges_sec = bin_edges_sec,\n                        bin_counts = bin_counts\n                    )\n                )\n    v_cc = vv.CrossCorrelograms(\n        cross_correlograms=cross_correlogram_items,\n        hide_unit_selector=True\n    )\n\n    # units table\n    print('Units table')\n    v_ut = vv.UnitsTable(\n        columns=[\n        ],\n        rows=[\n            vv.UnitsTableRow(str(unit_id), {\n            })\n            for unit_id in sorting_with_true.get_unit_ids()\n        ]\n    )\n\n    view = vv.Box(\n        direction='horizontal',\n        items=[\n            vv.LayoutItem(v_ut, stretch=0, min_size=150, max_size=150),\n            vv.LayoutItem(v_ac, stretch=0, min_size=400, max_size=400),\n            vv.LayoutItem(\n                vv.Splitter(\n                    direction='horizontal',\n                    item1=vv.LayoutItem(v_cc, stretch=1),\n                    item2=vv.LayoutItem(\n                        vv.TabLayout(\n                            items=[\n                                vv.TabLayoutItem(label='preprocessed', view=v_et),\n                                # vv.TabLayoutItem(label='full', view=v_et_2)\n                            ]\n                        ),\n                        stretch=1\n                    )\n                ), stretch=1\n            )\n        ]\n    )\n\n    dd = view.url_dict(label=f'{rec.recording_name}')\n    with open(f'{output_dir}/view.yaml', 'w') as f:\n        yaml.dump(dd, f)"]}
{"filename": "examples/scheme1/toy_example.py", "chunked_list": ["import os\nimport time\nimport spikeinterface.extractors as se\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nfrom generate_visualization_output import generate_visualization_output\nfrom spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\nimport spikeinterface as si\n\ndef main():\n    recording, sorting_true = se.toy_example(duration=60 * 2, num_channels=8, num_units=16, sampling_frequency=30000, num_segments=1, seed=0)\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme1(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme1SortingParameters()\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        rec = SFRecording({\n            'name': 'toy_example',\n            'studyName': 'toy_example',\n            'studySetName': 'toy_example',\n            'sampleRateHz': recording_preprocessed.get_sampling_frequency(),\n            'numChannels': recording_preprocessed.get_num_channels(),\n            'durationSec': recording_preprocessed.get_total_duration(),\n            'numTrueUnits': sorting_true.get_num_units(),\n            'sortingTrueObject': {},\n            'recordingObject': {}\n        })\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "import spikeinterface as si\n\ndef main():\n    recording, sorting_true = se.toy_example(duration=60 * 2, num_channels=8, num_units=16, sampling_frequency=30000, num_segments=1, seed=0)\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme1(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme1SortingParameters()\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        rec = SFRecording({\n            'name': 'toy_example',\n            'studyName': 'toy_example',\n            'studySetName': 'toy_example',\n            'sampleRateHz': recording_preprocessed.get_sampling_frequency(),\n            'numChannels': recording_preprocessed.get_num_channels(),\n            'durationSec': recording_preprocessed.get_total_duration(),\n            'numTrueUnits': sorting_true.get_num_units(),\n            'sortingTrueObject': {},\n            'recordingObject': {}\n        })\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\nif __name__ == '__main__':\n    main()"]}
{"filename": "examples/scheme1/paired_kampff.py", "chunked_list": ["import os\nimport time\nimport spikeinterface as si\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nimport spikeforest as sf\nfrom generate_visualization_output import generate_visualization_output\n\ndef main():\n    paired_kampff_uri = 'sha1://b8b571d001f9a531040e79165e8f492d758ec5e0?paired-kampff-spikeforest-recordings.json'\n\n    recordings = sf.load_spikeforest_recordings(paired_kampff_uri)\n\n    # list recordings\n    # for rec in recordings:\n    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # select recording\n    rec = recordings[1] # 2015_09_03_Pair_9_0A 32 channels; 593.248 sec # example of bursting with lower amplitude spikes after the initial spike\n\n    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # this will download the recording/sorting_true from kachery\n    print('Loading recording and sorting_true')\n    recording = rec.get_recording_extractor()\n    sorting_true = rec.get_sorting_true_extractor()\n\n    channel_locations = recording.get_channel_locations()\n    for m in range(channel_locations.shape[0]):\n        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme1(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme1SortingParameters(\n            detect_channel_radius=100,\n            snippet_mask_radius=100\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\ndef main():\n    paired_kampff_uri = 'sha1://b8b571d001f9a531040e79165e8f492d758ec5e0?paired-kampff-spikeforest-recordings.json'\n\n    recordings = sf.load_spikeforest_recordings(paired_kampff_uri)\n\n    # list recordings\n    # for rec in recordings:\n    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # select recording\n    rec = recordings[1] # 2015_09_03_Pair_9_0A 32 channels; 593.248 sec # example of bursting with lower amplitude spikes after the initial spike\n\n    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # this will download the recording/sorting_true from kachery\n    print('Loading recording and sorting_true')\n    recording = rec.get_recording_extractor()\n    sorting_true = rec.get_sorting_true_extractor()\n\n    channel_locations = recording.get_channel_locations()\n    for m in range(channel_locations.shape[0]):\n        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme1(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme1SortingParameters(\n            detect_channel_radius=100,\n            snippet_mask_radius=100\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\nif __name__ == '__main__':\n    main()"]}
{"filename": "examples/scheme1/paired_english.py", "chunked_list": ["import os\nimport time\nimport spikeinterface as si\nimport spikeinterface.preprocessing as spre\nimport spikeinterface.comparison as sc\nimport mountainsort5 as ms5\nimport spikeforest as sf\nfrom generate_visualization_output import generate_visualization_output\n\ndef main():\n    paired_english_uri = 'sha1://dfb1fd134bfc209ece21fd5f8eefa992f49e8962?paired-english-spikeforest-recordings.json'\n\n    recordings = sf.load_spikeforest_recordings(paired_english_uri)\n\n    # list recordings\n    # for rec in recordings:\n    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # select recording\n    # rec = recordings[1] # m57_191105_160026 32 channels; 343.4533333333333 sec - amplitude too low\n    rec = recordings[13] # m15_190315_152315_cell1 32 channels; 669.3997 sec # classic example of need for final alignment merge step\n\n    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # this will download the recording/sorting_true from kachery\n    print('Loading recording and sorting_true')\n    recording = rec.get_recording_extractor()\n    sorting_true = rec.get_sorting_true_extractor()\n\n    channel_locations = recording.get_channel_locations()\n    for m in range(channel_locations.shape[0]):\n        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme1(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme1SortingParameters(\n            detect_channel_radius=50,\n            snippet_mask_radius=100\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\ndef main():\n    paired_english_uri = 'sha1://dfb1fd134bfc209ece21fd5f8eefa992f49e8962?paired-english-spikeforest-recordings.json'\n\n    recordings = sf.load_spikeforest_recordings(paired_english_uri)\n\n    # list recordings\n    # for rec in recordings:\n    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # select recording\n    # rec = recordings[1] # m57_191105_160026 32 channels; 343.4533333333333 sec - amplitude too low\n    rec = recordings[13] # m15_190315_152315_cell1 32 channels; 669.3997 sec # classic example of need for final alignment merge step\n\n    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\n    # this will download the recording/sorting_true from kachery\n    print('Loading recording and sorting_true')\n    recording = rec.get_recording_extractor()\n    sorting_true = rec.get_sorting_true_extractor()\n\n    channel_locations = recording.get_channel_locations()\n    for m in range(channel_locations.shape[0]):\n        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\n    timer = time.time()\n\n    # lazy preprocessing\n    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\n    # sorting\n    print('Starting MountainSort5')\n    sorting = ms5.sorting_scheme1(\n        recording_preprocessed,\n        sorting_parameters=ms5.Scheme1SortingParameters(\n            detect_channel_radius=50,\n            snippet_mask_radius=100\n        )\n    )\n    \n    elapsed_sec = time.time() - timer\n    duration_sec = recording.get_total_duration()\n    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\n    print('Comparing with truth')\n    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n    print(comparison.get_performance())\n\n    #######################################################################\n\n    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)", "\nif __name__ == '__main__':\n    main()"]}
{"filename": "examples/scheme1/helpers/compute_correlogram_data.py", "chunked_list": ["from typing import Union\nimport spikeinterface as si\nimport numpy as np\n\ndef compute_correlogram_data(*, sorting: si.BaseSorting, unit_id1: int, unit_id2: Union[int, None]=None, window_size_msec: float, bin_size_msec: float):\n    times1 = sorting.get_unit_spike_train(unit_id=unit_id1, segment_index=0)\n    num_bins = int(window_size_msec / bin_size_msec)\n    if num_bins % 2 == 0: num_bins = num_bins - 1 # odd number of bins\n    num_bins_half = int((num_bins + 1) / 2)\n    bin_edges_msec = np.array((np.arange(num_bins + 1) - num_bins / 2) * bin_size_msec, dtype=np.float32)\n    bin_counts = np.zeros((num_bins,), dtype=np.int32)\n    if unit_id2 is None or unit_id1 == unit_id2:\n        # autocorrelogram\n        offset = 1\n        while True:\n            if offset >= len(times1): break\n            deltas_msec = (times1[offset:] - times1[:-offset]) / sorting.get_sampling_frequency() * 1000\n            deltas_msec = deltas_msec[deltas_msec <= bin_edges_msec[-1]]\n            if len(deltas_msec) == 0: break\n            for i in range(num_bins_half):\n                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n                end_msec = bin_edges_msec[num_bins_half + i]\n                ct = len(deltas_msec[(start_msec <= deltas_msec) & (deltas_msec < end_msec)])\n                bin_counts[num_bins_half - 1 + i] += ct\n                bin_counts[num_bins_half - 1 - i] += ct\n            offset = offset + 1\n    else:\n        # cross-correlogram\n        times2 = sorting.get_unit_spike_train(segment_index=0, unit_id=unit_id2)\n        all_times = np.concatenate((times1, times2))\n        all_labels = np.concatenate((1 * np.ones(times1.shape), 2 * np.ones(times2.shape)))\n        sort_inds = np.argsort(all_times)\n        all_times = all_times[sort_inds]\n        all_labels = all_labels[sort_inds]\n        offset = 1\n        while True:\n            if offset >= len(all_times): break\n            deltas_msec = (all_times[offset:] - all_times[:-offset]) / sorting.get_sampling_frequency() * 1000\n\n            deltas12_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 1)]\n            deltas21_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 2)]\n            deltas11_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 1)]\n            deltas22_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 2)]\n\n            deltas12_msec = deltas12_msec[deltas12_msec <= bin_edges_msec[-1]]\n            deltas21_msec = deltas21_msec[deltas21_msec <= bin_edges_msec[-1]]\n            deltas11_msec = deltas11_msec[deltas11_msec <= bin_edges_msec[-1]]\n            deltas22_msec = deltas22_msec[deltas22_msec <= bin_edges_msec[-1]]\n\n            if (len(deltas12_msec) + len(deltas21_msec) + len(deltas11_msec) + len(deltas22_msec)) == 0: break\n            \n            for i in range(num_bins_half):\n                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n                end_msec = bin_edges_msec[num_bins_half + i]\n                ct12 = len(deltas12_msec[(start_msec <= deltas12_msec) & (deltas12_msec < end_msec)])\n                ct21 = len(deltas21_msec[(start_msec <= deltas21_msec) & (deltas21_msec < end_msec)])\n                bin_counts[num_bins_half - 1 + i] += ct12\n                bin_counts[num_bins_half - 1 - i] += ct21\n            offset = offset + 1\n    return {\n        'bin_edges_sec': (bin_edges_msec / 1000).astype(np.float32),\n        'bin_counts': bin_counts.astype(np.int32)\n    }"]}
{"filename": "examples/scheme1/helpers/create_autocorrelograms_view.py", "chunked_list": ["from typing import List\nimport spikeinterface as si\nimport sortingview.views as vv\nfrom helpers.compute_correlogram_data import compute_correlogram_data\n\n\ndef create_autocorrelograms_view(*, sorting: si.BaseSorting, unit_id_prefix: str=''):\n    autocorrelogram_items: List[vv.AutocorrelogramItem] = []\n    for unit_id in sorting.get_unit_ids():\n        a = compute_correlogram_data(sorting=sorting, unit_id1=unit_id, unit_id2=None, window_size_msec=80, bin_size_msec=1)\n        bin_edges_sec = a['bin_edges_sec']\n        bin_counts = a['bin_counts']\n        autocorrelogram_items.append(\n            vv.AutocorrelogramItem(\n                unit_id=f'{unit_id_prefix}{unit_id}',\n                bin_edges_sec=bin_edges_sec,\n                bin_counts=bin_counts\n            )\n        )\n    view = vv.Autocorrelograms(\n        autocorrelograms=autocorrelogram_items\n    )\n    return view"]}
{"filename": "examples/scheme1/helpers/create_units_table.py", "chunked_list": ["from typing import List\nimport sortingview.views as vv\nimport spikeinterface as si\n\n\ndef create_units_table(*, sorting: si.BaseSorting):\n    columns: List[vv.UnitsTableColumn] = []\n    rows: List[vv.UnitsTableRow] = []\n    for unit_id in sorting.get_unit_ids():\n        rows.append(\n            vv.UnitsTableRow(\n                unit_id=unit_id,\n                values={\n                    'unitId': unit_id\n                }\n            )\n        )\n    view = vv.UnitsTable(\n        columns=columns,\n        rows=rows\n    )\n    return view", ""]}
