{"filename": "cli/newprojfiles/assets/bake.py", "chunked_list": ["from cakework import Client\nimport time\nfrom pathlib import Path\n\nif __name__ == \"__main__\":\n    p = Path(__file__).with_name('.env')\n    with p.open('r') as f:\n        CAKEWORK_CLIENT_TOKEN = f.readline().strip('\\n')\n\n        client = Client(\"REPLACE_APPNAME\", CAKEWORK_CLIENT_TOKEN)\n\n        run_id = client.run(\"say_hello\", {\"name\":\"from Cakework\"}, compute={})\n        print(\"Your run id is \" + run_id)\n        \n        status = client.get_run_status(run_id)\n\n        while status == \"PENDING\" or status == \"IN_PROGRESS\":\n            print(\"Still baking...!\")\n            time.sleep(1)\n            status = client.get_run_status(run_id)\n        \n        if status == \"SUCCEEDED\":\n            result = client.get_run_result(run_id)\n            print(result)\n        else:\n            print(\"Task stopped  with status: \" + status)", ""]}
{"filename": "cli/newprojfiles/assets/main.py", "chunked_list": ["from cakework import Cakework\nimport time\n\ndef say_hello(params):\n    time.sleep(5)\n    return \"Hello \" + params['name'] + \"!\"\n\nif __name__ == \"__main__\":\n    cakework = Cakework(\"REPLACE_APPNAME\")\n    cakework.add_task(say_hello)"]}
{"filename": "sdk/python/__init__.py", "chunked_list": [""]}
{"filename": "sdk/python/src/cakework/client.py", "chunked_list": ["from __future__ import print_function\n\n# import logging\n\nimport json\nimport sys\nimport uuid\nfrom random import randrange # TODO remove this\nimport requests\nimport logging", "import requests\nimport logging\nfrom cakework import exceptions\nfrom urllib3.exceptions import NewConnectionError\nimport os\n\n# TODO: need to re-enable TLS for the handlers in the fly.toml file. Try these settings: https://community.fly.io/t/urgent-grpc-server-unreachable-via-grpcurl/2694/12 for alpn\n# TODO figure out how to configure the settings for fly.toml for grpc!\n# TODO also need to make sure different runs don't interfere with each other\n# TODO add a parameter for an entry point into the system (currently, assume that using cakework_app.py)", "# TODO also need to make sure different runs don't interfere with each other\n# TODO add a parameter for an entry point into the system (currently, assume that using cakework_app.py)\nlogging.basicConfig(level=logging.INFO)\n\nclass Client:\n    def __init__(self, project, client_token, local=False): # TODO: infer user id // TODO revert local back to False\n        self.project = project\n        self.client_token = client_token\n\n        if local:\n            self.frontend_url = \"http://localhost:8080\"\n        else:\n            self.frontend_url = \"https://cakework-frontend.fly.dev\"\n\n        self.local = local\n        \n    def get_run_status(self, run_id):\n        response = None\n        try:\n            # Q: status 200 vs 201??? what's the diff?\n            # TODO strip app from everywhere\n            response = requests.get(f\"{self.frontend_url}/client/runs/{run_id}/status\", params={\"token\": self.client_token})                \n            response.raise_for_status()\n            # TODO: handle http error, or request id not found error\n        except requests.exceptions.HTTPError as err:\n            raise exceptions.CakeworkError(\"Http error while connecting to Cakework frontend\") from err\n        except requests.exceptions.Timeout as err:\n            raise exceptions.CakeworkError(\"Timed out connecting to Cakework frontend\") from err\n        except requests.exceptions.RequestException as err:\n            raise exceptions.CakeworkError(\"Request exception connecting Cakework frontend\") from err\n        except (ConnectionRefusedError, ConnectionResetError) as err:\n            raise exceptions.CakeworkError(\"Failed to connect to Cakework frontend service\") from err\n        except Exception as err:\n            # TODO catch and raise specific errors? \n            raise exceptions.CakeworkError(\"Error happened while getting status\") from err\n        if response is not None:\n            if response.status_code == 200:\n                status = response.text\n                return json.loads(status)\n            elif response.status_code == 404:\n                return None\n            else:\n                raise exceptions.CakeworkError(\"Internal server exception\")\n        else:\n            raise exceptions.CakeworkError(\"Internal server exception\") \n\n    # TODO figure out how to refactor get_result and get_status  \n    def get_run_result(self, run_id):\n        response = None\n        try:\n            # Q: status 200 vs 201??? what's the diff?\n            response = requests.get(f\"{self.frontend_url}/client/runs/{run_id}/result\", params={\"token\": self.client_token})                \n            response.raise_for_status() # TODO delete this?\n            # TODO: handle http error, or request id not found error\n        except requests.exceptions.HTTPError as errh:\n            raise exceptions.CakeworkError(\"Http error while connecting to Cakework frontend\")\n        except requests.exceptions.Timeout as errt:\n            raise exceptions.CakeworkError(\"Timed out connecting to Cakework frontend\")\n        except requests.exceptions.RequestException as err:\n            raise exceptions.CakeworkError(\"Request exception connecting Cakework frontend\")\n        except (ConnectionRefusedError, ConnectionResetError) as e:\n            raise exceptions.CakeworkError(\"Failed to connect to Cakework frontend service\")\n        except Exception as e:\n            # TODO catch and raise specific errors? \n            raise exceptions.CakeworkError(\"Something unexpected happened\")\n        if response is not None:\n            if response.status_code == 200:\n                result = json.loads(response.json())\n                return result\n            elif response.status_code == 404:\n                return None\n            else:\n                raise exceptions.CakeworkError(\"Internal server exception\")\n        else:\n            raise exceptions.CakeworkError(\"Internal server exception\") \n    \n    def run(self, task, params, compute ={\"cpu\":1, \"memory\": 256}):\n        request = {\n            \"parameters\": params,\n            \"compute\": {}\n        }\n\n        cpu = compute.get(\"cpu\")\n        if cpu is not None:\n            if cpu < 1 or cpu > 8:\n                raise exceptions.CakeworkError(\"Number of cpus must be between 1 and 8\")\n            else:\n                request[\"compute\"][\"cpu\"] = cpu\n        else:\n            request[\"compute\"]['cpu'] = 1\n                \n        memory = compute.get(\"memory\")\n        if memory is not None:\n            if memory < 256 or memory > 16384:\n                raise exceptions.CakeworkError(\"Amount of memory must be between 256 and 16384 mb\")\n            else:\n                request[\"compute\"][\"memory\"] = memory\n        else:\n            request[\"compute\"]['memory'] = 256\n    \n        request[\"token\"] = self.client_token\n        response = requests.post(f\"{self.frontend_url}/client/projects/{self.project}/tasks/{task}/runs\", json=request, params={\"token\": self.client_token})\n        response_json = response.json()\n        if response is None:\n            raise exceptions.CakeworkError(\"Did not get a response from the frontend\")  \n        if response.status_code == 201:\n            run_id = response_json[\"runId\"]\n            return run_id\n        elif response.status_code == 404:\n            raise exceptions.CakeworkError(\"Task \" + task + \" for project \" + self.project + \" not found. Have you tried running `cakework deploy` first?\")  \n        else:\n            print(response) # TODO delete? \n            raise exceptions.CakeworkError(\"Internal server exception\")  "]}
{"filename": "sdk/python/src/cakework/__init__.py", "chunked_list": ["from .cakework import Cakework\nfrom .client import Client\nfrom .exceptions import CakeworkError"]}
{"filename": "sdk/python/src/cakework/cakework_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: cakework.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x0e\\x63\\x61kework.proto\\x12\\x08\\x63\\x61kework\\\"M\\n\\x07Request\\x12\\x12\\n\\nparameters\\x18\\x01 \\x01(\\t\\x12\\x0e\\n\\x06userId\\x18\\x02 \\x01(\\t\\x12\\x0f\\n\\x07project\\x18\\x03 \\x01(\\t\\x12\\r\\n\\x05runId\\x18\\x04 \\x01(\\t\\\"\\x17\\n\\x05Reply\\x12\\x0e\\n\\x06result\\x18\\x01 \\x01(\\t27\\n\\x08\\x43\\x61kework\\x12+\\n\\x03Run\\x12\\x11.cakework.Request\\x1a\\x0f.cakework.Reply\\\"\\x00\\x62\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())", "\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'cakework_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  _REQUEST._serialized_start=28\n  _REQUEST._serialized_end=105\n  _REPLY._serialized_start=107\n  _REPLY._serialized_end=130\n  _CAKEWORK._serialized_start=132\n  _CAKEWORK._serialized_end=187", "# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "sdk/python/src/cakework/cakework_pb2_grpc.py", "chunked_list": ["# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!\n\"\"\"Client and server classes corresponding to protobuf-defined services.\"\"\"\nimport grpc\n\n# import cakework_pb2 as cakework__pb2\n# TODO programatically fix this\nfrom cakework import cakework_pb2 as cakework__pb2\n\nclass CakeworkStub(object):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\n    def __init__(self, channel):\n        \"\"\"Constructor.\n\n        Args:\n            channel: A grpc.Channel.\n        \"\"\"\n        self.Run = channel.unary_unary(\n                '/cakework.Cakework/Run',\n                request_serializer=cakework__pb2.Request.SerializeToString,\n                response_deserializer=cakework__pb2.Reply.FromString,\n                )", "class CakeworkStub(object):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\n    def __init__(self, channel):\n        \"\"\"Constructor.\n\n        Args:\n            channel: A grpc.Channel.\n        \"\"\"\n        self.Run = channel.unary_unary(\n                '/cakework.Cakework/Run',\n                request_serializer=cakework__pb2.Request.SerializeToString,\n                response_deserializer=cakework__pb2.Reply.FromString,\n                )", "\n\nclass CakeworkServicer(object):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\n    def Run(self, request, context):\n        \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')", "\n\ndef add_CakeworkServicer_to_server(servicer, server):\n    rpc_method_handlers = {\n            'Run': grpc.unary_unary_rpc_method_handler(\n                    servicer.Run,\n                    request_deserializer=cakework__pb2.Request.FromString,\n                    response_serializer=cakework__pb2.Reply.SerializeToString,\n            ),\n    }\n    generic_handler = grpc.method_handlers_generic_handler(\n            'cakework.Cakework', rpc_method_handlers)\n    server.add_generic_rpc_handlers((generic_handler,))", "\n\n # This class is part of an EXPERIMENTAL API.\nclass Cakework(object):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\n    @staticmethod\n    def Run(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/cakework.Cakework/Run',\n            cakework__pb2.Request.SerializeToString,\n            cakework__pb2.Reply.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)", ""]}
{"filename": "sdk/python/src/cakework/task_server.py", "chunked_list": ["from concurrent import futures\nimport logging\nimport grpc\nfrom cakework import cakework_pb2\nfrom cakework import cakework_pb2_grpc\nimport json\nimport threading\nimport requests\nimport os\nimport logging", "import os\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\n\ndef get_token(context):\n    metadict = dict(context.invocation_metadata())\n    authorization = metadict['authorization']\n    split = authorization.split(' ')\n    return split[1]", "\nclass Cakework(cakework_pb2_grpc.CakeworkServicer):\n    def __init__(self, user_task, local=False):\n        self.user_task = user_task\n        self.local = local\n        if self.local:\n            self.frontend_url = \"http://localhost:8080\"\n        else:\n            self.frontend_url = \"https://cakework-frontend.fly.dev\"\n\n    def Run(self, request, context):\n        token = get_token(context)\n        headers = {'content-type': 'application/json', 'authorization': 'Bearer ' + token, 'project': request.project}\n        response = requests.post(f\"{self.frontend_url}/runs/{request.runId}/status\", json={\"runId\": request.runId, \"status\": \"IN_PROGRESS\"}, headers=headers)\n        # TODO check the response\n        parameters = json.loads(request.parameters)\n        # parameters = json.loads(request.parameters) # instead of passing a dict (parameters), pass a variable number of parameters \n        task = threading.Thread(target=self.background, args=[request.userId, request.project, request.runId, parameters, token])\n        task.daemon = True # Q: does returning kill the task?\n        task.start()\n        # what should we return? now, the client is no longer hitting the grpc server\n        return cakework_pb2.Reply(result=json.dumps(\"worker started task\")) # TODO this should return the request id\n\n    # note: we need to get the request id in here as well\n    def background(self, user_id, project, run_id, parameters, token):\n        res = \"\"\n        # logging.info(\"starting background task with parameters: \" + str(parameters))\n        headers = {'content-type': 'application/json', 'authorization': 'Bearer ' + token, 'project': project}\n\n        try:\n            logging.info(\"Starting run with id:\" + run_id)\n            res = self.user_task(parameters)\n            # TODO call the frontend api to update the status and result\n            \n            logging.info(\"Finished request \" + run_id)\n            response = requests.post(f\"{self.frontend_url}/runs/{run_id}/result\", json={\"runId\": run_id, \"result\": json.dumps(res)}, headers=headers)\n            if response.status_code != 200:\n                logging.error(\"Failed to update run status\")\n                response.raise_for_status()\n            logging.info(\"Got successful response to update status\")\n            # TODO check the response\n            response = requests.post(f\"{self.frontend_url}/runs/{run_id}/status\", json={\"runId\": run_id, \"status\": \"SUCCEEDED\"}, headers=headers)\n            if response.status_code != 200:\n                logging.error(\"Failed to update run status\")\n                response.raise_for_status()\n            logging.info(\"Got successful response to update result\")\n\n        except Exception as e:\n            logging.exception(\"Error occurred while running task\", exc_info=True)\n            # logging.info(e)\n            response = requests.post(f\"{self.frontend_url}/runs/{run_id}/status\", json={\"runId\": run_id, \"status\": \"FAILED\"}, headers=headers)\n            # TODO: handle case if updating the status in the db failed; then user may keep polling forever\n            return cakework_pb2.Reply(result=None)\n        finally:\n            logging.info(\"Request complete, exiting\")\n            os._exit(1)\n\n        # Q: who are we returning to here? instead of returning, we can just write this to the database. or emit a message and have the poller be in charge of writing to db\n        return cakework_pb2.Reply(result=json.dumps(res))", "\ndef serve():\n    port = '50051'\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=1)) # what should the default be?\n    cakework_pb2_grpc.add_CakeworkServicer_to_server(Cakework(), server)\n    server.add_insecure_port('[::]:' + port)\n    server.start()\n    logging.info(\"Server started, listening on \" + port)\n    server.wait_for_termination()\n\nif __name__ == '__main__':\n    logging.basicConfig()\n    serve()", "\nif __name__ == '__main__':\n    logging.basicConfig()\n    serve()\n\nclass TaskServer:\n    def __init__(self, user_task, local=False):\n        self.user_task = user_task\n        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=1)) # what should the default be?\n        self.local = local\n\n    def start(self):        \n        port = '50051'\n        cakework_pb2_grpc.add_CakeworkServicer_to_server(Cakework(self.user_task, self.local), self.server)\n        self.server.add_insecure_port('[::]:' + port)\n        self.server.start()\n        logging.info(\"Server started, listening on \" + port)\n        self.server.wait_for_termination()"]}
{"filename": "sdk/python/src/cakework/cakework.py", "chunked_list": ["import subprocess\nimport os\nimport shutil\nimport sys\nimport inspect\nimport json\n\nfrom concurrent import futures\nfrom cakework import cakework_pb2\nfrom cakework import cakework_pb2_grpc", "from cakework import cakework_pb2\nfrom cakework import cakework_pb2_grpc\nfrom .task_server import TaskServer\nimport importlib\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nclass Cakework:\n\tdef __init__(self, name, local=False): # TODO remove local when release as open source\n\t\tself.name = name\n\t\tself.local = local\n\n\t\tlogging.info(\"Created project with name: \" + self.name)\n\n\tdef add_task(self, task):\n\t\tactivity_server = TaskServer(task, self.local)\n\t\tactivity_server.start()", "\ndef serve():\n    port = '50051'\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=1)) # what should the default be?\n    cakework_pb2_grpc.add_CakeworkServicer_to_server(cakework_pb2_grpc.Cakework(), server)\n    server.add_insecure_port('[::]:' + port)\n    server.start()\n    logging.info(\"Server started, listening on \" + port)\n    server.wait_for_termination()"]}
{"filename": "sdk/python/src/cakework/frontend_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: proto/frontend.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x14proto/frontend.proto\\x12\\x08\\x66rontend\\\"P\\n\\x0f\\x43\\x61llTaskRequest\\x12\\x0e\\n\\x06userId\\x18\\x01 \\x01(\\t\\x12\\x0b\\n\\x03\\x61pp\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04task\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nparameters\\x18\\x04 \\x01(\\t\\\"1\\n\\rCallTaskReply\\x12\\x11\\n\\trequestId\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05\\x65rror\\x18\\x02 \\x01(\\t2L\\n\\x08\\x46rontend\\x12@\\n\\x08\\x43\\x61llTask\\x12\\x19.frontend.CallTaskRequest\\x1a\\x17.frontend.CallTaskReply\\\"\\x00\\x42\\x0cZ\\n.;frontendb\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())", "\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'proto.frontend_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  DESCRIPTOR._serialized_options = b'Z\\n.;frontend'\n  _CALLTASKREQUEST._serialized_start=34\n  _CALLTASKREQUEST._serialized_end=114\n  _CALLTASKREPLY._serialized_start=116\n  _CALLTASKREPLY._serialized_end=165\n  _FRONTEND._serialized_start=167\n  _FRONTEND._serialized_end=243", "# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "sdk/python/src/cakework/exceptions.py", "chunked_list": ["__all__ = (\n    # TODO add more specific errors and warnings\n    # Core errors\n    'CakeworkError'\n)\n\nclass CakeworkError(Exception):\n    \"\"\"Base class for all Cakework errors.\"\"\"\n\n", "\n"]}
{"filename": "sdk/python/src/cakework/frontend_pb2_grpc.py", "chunked_list": ["# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!\n\"\"\"Client and server classes corresponding to protobuf-defined services.\"\"\"\nimport grpc\n\nfrom cakework import frontend_pb2 as proto_dot_frontend__pb2\n\n\nclass FrontendStub(object):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\n    def __init__(self, channel):\n        \"\"\"Constructor.\n\n        Args:\n            channel: A grpc.Channel.\n        \"\"\"\n        self.CallTask = channel.unary_unary(\n                '/frontend.Frontend/CallTask',\n                request_serializer=proto_dot_frontend__pb2.CallTaskRequest.SerializeToString,\n                response_deserializer=proto_dot_frontend__pb2.CallTaskReply.FromString,\n                )", "\n\nclass FrontendServicer(object):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\n    def CallTask(self, request, context):\n        \"\"\"Sends a greeting\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')", "\n\ndef add_FrontendServicer_to_server(servicer, server):\n    rpc_method_handlers = {\n            'CallTask': grpc.unary_unary_rpc_method_handler(\n                    servicer.CallTask,\n                    request_deserializer=proto_dot_frontend__pb2.CallTaskRequest.FromString,\n                    response_serializer=proto_dot_frontend__pb2.CallTaskReply.SerializeToString,\n            ),\n    }\n    generic_handler = grpc.method_handlers_generic_handler(\n            'frontend.Frontend', rpc_method_handlers)\n    server.add_generic_rpc_handlers((generic_handler,))", "\n\n # This class is part of an EXPERIMENTAL API.\nclass Frontend(object):\n    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\n    @staticmethod\n    def CallTask(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/frontend.Frontend/CallTask',\n            proto_dot_frontend__pb2.CallTaskRequest.SerializeToString,\n            proto_dot_frontend__pb2.CallTaskReply.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)", ""]}
{"filename": "examples/react-example/react-example-backend/react_example_backend/main.py", "chunked_list": ["from cakework import Cakework\nimport time\n\ndef say_hello(params):\n    time.sleep(5)\n    return \"Hello \" + params['name'] + \"!\"\n\nif __name__ == \"__main__\":\n    cakework = Cakework(\"react-example-backend\")\n    cakework.add_task(say_hello)"]}
{"filename": "examples/react-example/react-example-backend/react_example_backend/__init__.py", "chunked_list": [""]}
{"filename": "examples/react-example/react-example-backend/tests/bake.py", "chunked_list": ["from cakework import Client\nimport time\nfrom pathlib import Path\n\nif __name__ == \"__main__\":\n    p = Path(__file__).with_name('.env')\n    with p.open('r') as f:\n        CAKEWORK_CLIENT_TOKEN = f.readline().strip('\\n')\n\n        client = Client(\"REPLACE_APPNAME\", CAKEWORK_CLIENT_TOKEN, local=False)\n\n        run_id = client.run(\"say_hello\", {\"name\":\"from Cakework\"}, compute={})\n        print(\"Your run id is \" + run_id)\n        \n        status = client.get_run_status(run_id)\n\n        while status == \"PENDING\" or status == \"IN_PROGRESS\":\n            print(\"Still baking...!\")\n            time.sleep(1)\n            status = client.get_run_status(run_id)\n        \n        if status == \"SUCCEEDED\":\n            result = client.get_run_result(run_id)\n            print(result)\n        else:\n            print(\"Task stopped  with status: \" + status)", ""]}
{"filename": "examples/react-example/react-example-backend/tests/__init__.py", "chunked_list": [""]}
{"filename": "examples/image_generation/backend/backend/main.py", "chunked_list": ["from cakework import Cakework\nimport banana_dev as banana\nimport base64\nfrom io import BytesIO\nfrom PIL import Image\nimport boto3\nfrom nanoid import generate\n\nAWS_ACCESS_KEY_ID = \"YOUR_ACCESS_KEY_ID\"\nAWS_SECRET_ACCESS_KEY = \"YOUR_SECRET_KEY\"", "AWS_ACCESS_KEY_ID = \"YOUR_ACCESS_KEY_ID\"\nAWS_SECRET_ACCESS_KEY = \"YOUR_SECRET_KEY\"\nAWS_BUCKET = \"YOUR_AWS_BUCKET\"\nBANANA_API_KEY = \"YOUR_API_KEY\"\nBANANA_MODEL_KEY = \"YOUR_MODEL_KEY\"\n\n# Run image generation model, returning the image as bytes.\n# We are running stable diffusion hosted on banana.\ndef run_image_generation_model(prompt):\n    model_inputs = {\n        \"prompt\": prompt,\n        \"num_inference_steps\": 50,\n        \"guidance_scale\": 9,\n        \"height\": 512,\n        \"width\": 512,\n        \"seed\": 3242\n    }\n    \n    output = banana.run(BANANA_API_KEY, BANANA_MODEL_KEY, model_inputs)\n    image_byte_string = output[\"modelOutputs\"][0][\"image_base64\"]\n    image_encoded = image_byte_string.encode('utf-8')\n    image_bytes = BytesIO(base64.b64decode(image_encoded))\n    return Image.open(image_bytes)", "def run_image_generation_model(prompt):\n    model_inputs = {\n        \"prompt\": prompt,\n        \"num_inference_steps\": 50,\n        \"guidance_scale\": 9,\n        \"height\": 512,\n        \"width\": 512,\n        \"seed\": 3242\n    }\n    \n    output = banana.run(BANANA_API_KEY, BANANA_MODEL_KEY, model_inputs)\n    image_byte_string = output[\"modelOutputs\"][0][\"image_base64\"]\n    image_encoded = image_byte_string.encode('utf-8')\n    image_bytes = BytesIO(base64.b64decode(image_encoded))\n    return Image.open(image_bytes)", "\n# Converts the image to a .jpg and uploads it to S3\ndef upload_image(image):\n    s3 = boto3.client(\n    's3',\n    aws_access_key_id=AWS_ACCESS_KEY_ID,\n    aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n\n    id = generate(size=10)\n    filename = id + \".png\"\n\n    file = BytesIO()\n    image.save(file, \"png\")\n    file.seek(0)\n\n    s3.upload_fileobj(file, AWS_BUCKET, filename)\n    return filename", "\n# Generates a stable diffusion prompt from input\ndef generate_prompt(object, style):\n    return object + \" in \" + style + \" style \"\n\n# Run the image generation process and save to S3\ndef generate_image(object, style):\n    prompt = generate_prompt(object, style)\n    image = run_image_generation_model(prompt)\n    s3_location = upload_image(image)\n\n    return {\n        \"s3Location\": s3_location\n    }", "\nif __name__ == \"__main__\":\n    app = Cakework(\"backend\")\n    app.add_task(generate_image)"]}
{"filename": "examples/image_generation/backend/backend/__init__.py", "chunked_list": [""]}
{"filename": "examples/image_generation/backend/tests/bake.py", "chunked_list": ["from cakework import Client\nimport time\nfrom pathlib import Path\n\nif __name__ == \"__main__\":\n    p = Path(__file__).with_name('.env')\n    with p.open('r') as f:\n        CAKEWORK_CLIENT_TOKEN = f.readline().strip('\\n')\n\n        client = Client(\"backend\", CAKEWORK_CLIENT_TOKEN)\n\n        # You can persist this run ID to get status of the job later\n        run_id = client.say_hello(\"from Cakework\")\n        print(\"Your run id is \" + run_id)\n\n        status = client.get_status(run_id)\n        while (status == \"PENDING\" or status == \"IN_PROGRESS\"):\n            print(\"Still baking...!\")\n            status = client.get_status(run_id)\n            time.sleep(1)\n\n        if (client.get_status(run_id) == \"SUCCEEDED\"):\n            result = client.get_result(run_id)\n            print(result)"]}
{"filename": "examples/image_generation/backend/tests/__init__.py", "chunked_list": [""]}
{"filename": "examples/image_generation/client/tests/__init__.py", "chunked_list": [""]}
{"filename": "examples/image_generation/client/client/main.py", "chunked_list": ["from cakework import Client\nimport time\nimport json\n\nS3_BUCKET_URL = \"YOUR_S3_BUCKET_URL\"\nCAKEWORK_CLIENT_TOKEN = \"YOUR_CAKEWORK_CLIENT_TOKEN\"\n\nif __name__ == \"__main__\":\n    client = Client(\"image_generation\", CAKEWORK_CLIENT_TOKEN)\n    \n    # You can persist this run ID to get status of the job later\n    run_id = client.generate_image(\"cute piece of cake\", \"cartoon\")\n    print(run_id)\n\n    status = client.get_status(run_id)\n    while (status == \"PENDING\" or status == \"IN_PROGRESS\"):\n        print(\"Still baking that cake!\")\n        status = client.get_status(run_id)\n        time.sleep(1)\n\n    if (client.get_status(run_id) == \"SUCCEEDED\"):\n        result = json.loads(client.get_result(run_id))\n        url = S3_BUCKET_URL + result[\"s3Location\"]\n        print(url)", ""]}
{"filename": "examples/image_generation/client/client/__init__.py", "chunked_list": [""]}
