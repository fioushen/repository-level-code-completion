{"filename": "setup.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport io\nimport os\nfrom setuptools import setup, find_packages\n\npackage_root = os.path.abspath(os.path.dirname(__file__))", "\npackage_root = os.path.abspath(os.path.dirname(__file__))\n\nreadme_filename = os.path.join(package_root, \"README.md\")\nwith io.open(readme_filename, encoding=\"utf-8\") as readme_file:\n    readme = readme_file.read()\n\npackages = [package for package in find_packages() if package.startswith(\"google\")]\n\n# Determine which namespaces are needed.", "\n# Determine which namespaces are needed.\nnamespaces = [\"google\"]\nif \"google.cloud\" in packages:\n    namespaces.append(\"google.cloud\")\n\nname = \"google-cloud-alloydb-connector\"\ndescription = \"A Python client library for connecting securely to your Google Cloud AlloyDB instances.\"\n\nversion = {}\nwith open(\"google/cloud/alloydb/connector/version.py\") as fp:\n    exec(fp.read(), version)", "\nversion = {}\nwith open(\"google/cloud/alloydb/connector/version.py\") as fp:\n    exec(fp.read(), version)\nversion = version[\"__version__\"]\n\nrelease_status = \"Development Status :: 4 - Beta\"\ncore_dependencies = [\n    \"aiohttp\",\n    \"cryptography>=38.0.3\",", "    \"aiohttp\",\n    \"cryptography>=38.0.3\",\n    \"requests\",\n    \"google-auth\",\n]\n\nsetup(\n    name=name,\n    version=version,\n    description=description,", "    version=version,\n    description=description,\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    author=\"Google LLC\",\n    author_email=\"googleapis-packages@google.com\",\n    license=\"Apache 2.0\",\n    url=\"https://github.com/GoogleCloudPlatform/alloydb-python-connector\",\n    classifiers=[\n        release_status,", "    classifiers=[\n        release_status,\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n    ],", "        \"Programming Language :: Python :: 3.11\",\n    ],\n    platforms=\"Posix; MacOS X; Windows\",\n    packages=packages,\n    namespace_packages=namespaces,\n    install_requires=core_dependencies,\n    extras_require={\n        \"pg8000\": [\"pg8000==1.29.8\"],\n    },\n    python_requires=\">=3.8\",", "    },\n    python_requires=\">=3.8\",\n    include_package_data=True,\n    zip_safe=False,\n)\n"]}
{"filename": "noxfile.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nimport os\n\nimport nox", "\nimport nox\n\n\nBLACK_VERSION = \"black==22.3.0\"\nLINT_PATHS = [\"google\", \"tests\", \"noxfile.py\", \"setup.py\"]\n\nSYSTEM_TEST_PYTHON_VERSIONS = [\"3.8\", \"3.9\", \"3.10\", \"3.11\"]\nUNIT_TEST_PYTHON_VERSIONS = [\"3.8\", \"3.9\", \"3.10\", \"3.11\"]\n", "UNIT_TEST_PYTHON_VERSIONS = [\"3.8\", \"3.9\", \"3.10\", \"3.11\"]\n\n\n@nox.session\ndef lint(session):\n    \"\"\"Run linters.\n\n    Returns a failure if the linters find linting errors or sufficiently\n    serious code quality issues.\n    \"\"\"\n    session.install(\"-r\", \"requirements-test.txt\")\n    session.install(\"-r\", \"requirements.txt\")\n    session.install(\n        \"flake8\",\n        \"flake8-import-order\",\n        \"flake8-annotations\",\n        \"mypy\",\n        BLACK_VERSION,\n        \"types-setuptools\",\n        \"twine\",\n    )\n    session.run(\n        \"black\",\n        \"--check\",\n        *LINT_PATHS,\n    )\n    session.run(\n        \"flake8\",\n        \"--import-order-style=google\",\n        \"--application-import-names=google,tests\",\n        \"google\",\n        \"tests\",\n    )\n    session.run(\"mypy\", \"google\", \"--install-types\", \"--non-interactive\")\n    session.run(\"python\", \"setup.py\", \"sdist\")\n    session.run(\"twine\", \"check\", \"dist/*\")", "\n\n@nox.session\ndef blacken(session):\n    \"\"\"Run black.\n\n    Format code to uniform standard.\n    \"\"\"\n    session.install(BLACK_VERSION)\n    session.run(\n        \"black\",\n        *LINT_PATHS,\n    )", "\n\n@nox.session()\ndef cover(session):\n    \"\"\"Run the final coverage report.\n\n    This outputs the coverage report aggregating coverage from the unit\n    test runs (not system test runs), and then erases coverage data.\n    \"\"\"\n    session.install(\"coverage\", \"pytest-cov\")\n    session.run(\"coverage\", \"report\", \"--show-missing\", \"--fail-under=0\")\n\n    session.run(\"coverage\", \"erase\")", "\n\ndef default(session, path):\n    # Install all test dependencies, then install this package in-place.\n    session.install(\"-r\", \"requirements-test.txt\")\n    session.install(\"-e\", \".\")\n    session.install(\"-r\", \"requirements.txt\")\n    # Run pytest with coverage.\n    session.run(\n        \"pytest\",\n        \"--cov=google.cloud.alloydb.connector\",\n        \"-v\",\n        \"--cov-config=.coveragerc\",\n        \"--cov-report=\",\n        \"--cov-fail-under=0\",\n        \"--junitxml=sponge_log.xml\",\n        path,\n        *session.posargs,\n    )", "\n\n@nox.session(python=UNIT_TEST_PYTHON_VERSIONS)\ndef unit(session):\n    \"\"\"Run the unit test suite.\"\"\"\n    default(session, os.path.join(\"tests\", \"unit\"))\n\n\n@nox.session(python=SYSTEM_TEST_PYTHON_VERSIONS)\ndef system(session):\n    default(session, os.path.join(\"tests\", \"system\"))", "@nox.session(python=SYSTEM_TEST_PYTHON_VERSIONS)\ndef system(session):\n    default(session, os.path.join(\"tests\", \"system\"))\n"]}
{"filename": "tests/system/test_pg8000_connection.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import datetime\nimport os\n\nimport pg8000", "\nimport pg8000\nimport sqlalchemy\n\nfrom google.cloud.alloydb.connector import Connector\n\n\ndef init_connection_engine(connector: Connector) -> sqlalchemy.engine.Engine:\n    def getconn() -> pg8000.dbapi.Connection:\n        conn: pg8000.dbapi.Connection = connector.connect(\n            os.environ[\"ALLOYDB_INSTANCE_URI\"],\n            \"pg8000\",\n            user=os.environ[\"ALLOYDB_USER\"],\n            password=os.environ[\"ALLOYDB_PASS\"],\n            db=os.environ[\"ALLOYDB_DB\"],\n        )\n        return conn\n\n    # create SQLAlchemy connection pool\n    pool = sqlalchemy.create_engine(\n        \"postgresql+pg8000://\",\n        creator=getconn,\n    )\n    pool.dialect.description_encoding = None\n    return pool", "\n\ndef test_pg8000_time() -> None:\n    \"\"\"Basic test to get time from database.\"\"\"\n    with Connector() as connector:\n        pool = init_connection_engine(connector)\n        with pool.connect() as conn:\n            time = conn.execute(sqlalchemy.text(\"SELECT NOW()\")).fetchone()\n            conn.commit()\n            curr_time = time[0]\n            assert type(curr_time) == datetime", ""]}
{"filename": "tests/unit/test_connector.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nfrom threading import Thread\n\nfrom mock import patch", "\nfrom mock import patch\nfrom mocks import FakeAlloyDBClient, FakeCredentials\nimport pytest\n\nfrom google.cloud.alloydb.connector import Connector\n\n\ndef test_Connector_init(credentials: FakeCredentials) -> None:\n    \"\"\"\n    Test to check whether the __init__ method of Connector\n    properly sets default attributes.\n    \"\"\"\n    connector = Connector(credentials)\n    assert connector._quota_project is None\n    assert connector._alloydb_api_endpoint == \"https://alloydb.googleapis.com\"\n    assert connector._client is None\n    assert connector._credentials == credentials\n    connector.close()", "def test_Connector_init(credentials: FakeCredentials) -> None:\n    \"\"\"\n    Test to check whether the __init__ method of Connector\n    properly sets default attributes.\n    \"\"\"\n    connector = Connector(credentials)\n    assert connector._quota_project is None\n    assert connector._alloydb_api_endpoint == \"https://alloydb.googleapis.com\"\n    assert connector._client is None\n    assert connector._credentials == credentials\n    connector.close()", "\n\ndef test_Connector_context_manager(credentials: FakeCredentials) -> None:\n    \"\"\"\n    Test to check whether the __init__ method of Connector\n    properly sets defaults as context manager.\n    \"\"\"\n    with Connector(credentials) as connector:\n        assert connector._quota_project is None\n        assert connector._alloydb_api_endpoint == \"https://alloydb.googleapis.com\"\n        assert connector._client is None\n        assert connector._credentials == credentials", "\n\ndef test_Connector_close(credentials: FakeCredentials) -> None:\n    \"\"\"\n    Test that Connector's close method stops event loop and\n    background thread.\n    \"\"\"\n    with Connector(credentials) as connector:\n        loop: asyncio.AbstractEventLoop = connector._loop\n        thread: Thread = connector._thread\n        assert loop.is_running() is True\n        assert thread.is_alive() is True\n    assert loop.is_running() is False\n    assert thread.is_alive() is False", "\n\ndef test_connect(credentials: FakeCredentials) -> None:\n    \"\"\"\n    Test that connector.connect returns connection object.\n    \"\"\"\n    client = FakeAlloyDBClient()\n    with Connector(credentials) as connector:\n        connector._client = client\n        # patch db connection creation\n        with patch(\"pg8000.dbapi.connect\") as mock_connect:\n            mock_connect.return_value = True\n            connection = connector.connect(\n                \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n                \"pg8000\",\n                user=\"test-user\",\n                password=\"test-password\",\n                db=\"test-db\",\n            )\n        # check connection is returned\n        assert connection is True", "\n\ndef test_connect_unsupported_driver(credentials: FakeCredentials) -> None:\n    \"\"\"\n    Test that connector.connect errors with unsupported database driver.\n    \"\"\"\n    client = FakeAlloyDBClient()\n    with Connector(credentials) as connector:\n        connector._client = client\n        # try to connect using unsupported driver, should raise ValueError\n        with pytest.raises(ValueError) as exc_info:\n            connector.connect(\n                \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n                \"bad_driver\",\n            )\n        # assert custom error message for unsupported driver is present\n        assert (\n            exc_info.value.args[0]\n            == \"Driver 'bad_driver' is not a supported database driver.\"\n        )", ""]}
{"filename": "tests/unit/test_rate_limiter.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\n\nimport pytest\n", "import pytest\n\nfrom google.cloud.alloydb.connector.rate_limiter import AsyncRateLimiter\n\n\n@pytest.mark.asyncio\nasync def test_rate_limiter_throttles_requests() -> None:\n    \"\"\"Test to check whether rate limiter will throttle incoming requests.\"\"\"\n    counter = 0\n    # allow 2 requests to go through every 10 seconds", "    counter = 0\n    # allow 2 requests to go through every 10 seconds\n    rate_limiter = AsyncRateLimiter(max_capacity=2, rate=1 / 10)\n\n    async def increment() -> None:\n        await rate_limiter.acquire()\n        nonlocal counter\n        counter += 1\n\n    # create 5 tasks calling increment()", "\n    # create 5 tasks calling increment()\n    tasks = [asyncio.create_task(increment()) for _ in range(5)]\n\n    # wait 5 seconds and check tasks\n    done, pending = await asyncio.wait(tasks, timeout=5)\n\n    # verify 2 tasks completed and 3 pending due to rate limiter\n    assert counter == 2\n    assert len(done) == 2", "    assert counter == 2\n    assert len(done) == 2\n    assert len(pending) == 3\n\n    # cleanup pending tasks\n    for task in pending:\n        task.cancel()\n\n\n@pytest.mark.asyncio", "\n@pytest.mark.asyncio\nasync def test_rate_limiter_completes_all_tasks() -> None:\n    \"\"\"Test to check all requests will go through rate limiter successfully.\"\"\"\n    counter = 0\n    # allow 1 request to go through per second\n    rate_limiter = AsyncRateLimiter(max_capacity=1, rate=1)\n\n    async def increment() -> None:\n        await rate_limiter.acquire()", "    async def increment() -> None:\n        await rate_limiter.acquire()\n        nonlocal counter\n        counter += 1\n\n    # create 5 tasks calling increment()\n    tasks = [asyncio.create_task(increment()) for _ in range(5)]\n\n    done, pending = await asyncio.wait(tasks, timeout=6)\n", "    done, pending = await asyncio.wait(tasks, timeout=6)\n\n    # verify all tasks done and none pending\n    assert counter == 5\n    assert len(done) == 5\n    assert len(pending) == 0\n"]}
{"filename": "tests/unit/mocks.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import datetime, timedelta\nfrom typing import Any, Callable, List, Optional, Tuple\n\nfrom cryptography import x509", "\nfrom cryptography import x509\nfrom cryptography.hazmat.primitives import hashes, serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom cryptography.x509.oid import NameOID\n\nfrom google.cloud.alloydb.connector.utils import _create_certificate_request\n\n\nclass FakeCredentials:\n    def __init__(self) -> None:\n        self.token: Optional[str] = None\n        self.expiry: Optional[datetime] = None\n\n    def refresh(self, request: Callable) -> None:\n        \"\"\"Refreshes the access token.\"\"\"\n        self.token = \"12345\"\n        self.expiry = datetime.now() + timedelta(minutes=60)\n\n    @property\n    def expired(self) -> bool:\n        \"\"\"Checks if the credentials are expired.\n\n        Note that credentials can be invalid but not expired because\n        Credentials with expiry set to None are considered to never\n        expire.\n        \"\"\"\n        return False if not self.expiry else True\n\n    @property\n    def valid(self) -> bool:\n        \"\"\"Checks the validity of the credentials.\n\n        This is True if the credentials have a token and the token\n        is not expired.\n        \"\"\"\n        return self.token is not None and not self.expired", "\nclass FakeCredentials:\n    def __init__(self) -> None:\n        self.token: Optional[str] = None\n        self.expiry: Optional[datetime] = None\n\n    def refresh(self, request: Callable) -> None:\n        \"\"\"Refreshes the access token.\"\"\"\n        self.token = \"12345\"\n        self.expiry = datetime.now() + timedelta(minutes=60)\n\n    @property\n    def expired(self) -> bool:\n        \"\"\"Checks if the credentials are expired.\n\n        Note that credentials can be invalid but not expired because\n        Credentials with expiry set to None are considered to never\n        expire.\n        \"\"\"\n        return False if not self.expiry else True\n\n    @property\n    def valid(self) -> bool:\n        \"\"\"Checks the validity of the credentials.\n\n        This is True if the credentials have a token and the token\n        is not expired.\n        \"\"\"\n        return self.token is not None and not self.expired", "\n\ndef generate_cert(\n    common_name: str, expires_in: int = 60\n) -> Tuple[x509.CertificateBuilder, rsa.RSAPrivateKey]:\n    \"\"\"\n    Generate a private key and cert object to be used in testing.\n\n    Args:\n        common_name (str): The Common Name for the certificate.\n        expires_in (int): Time in minutes until expiry of certificate.\n\n    Returns:\n        Tuple[x509.CertificateBuilder, rsa.RSAPrivateKey]\n    \"\"\"\n    # generate private key\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    # calculate expiry time\n    now = datetime.now()\n    expiration = now + timedelta(minutes=expires_in)\n    # configure cert subject\n    subject = issuer = x509.Name(\n        [\n            x509.NameAttribute(NameOID.COUNTRY_NAME, \"US\"),\n            x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME, \"California\"),\n            x509.NameAttribute(NameOID.LOCALITY_NAME, \"Mountain View\"),\n            x509.NameAttribute(NameOID.ORGANIZATION_NAME, \"Google Inc\"),\n            x509.NameAttribute(NameOID.COMMON_NAME, common_name),\n        ]\n    )\n    # build cert\n    cert = (\n        x509.CertificateBuilder()\n        .subject_name(subject)\n        .issuer_name(issuer)\n        .public_key(key.public_key())\n        .serial_number(x509.random_serial_number())\n        .not_valid_before(now)\n        .not_valid_after(expiration)\n    )\n    return cert, key", "\n\nclass FakeInstance:\n    \"\"\"Fake AlloyDB instance to use for testing\"\"\"\n\n    def __init__(\n        self,\n        project: str = \"test-project\",\n        region: str = \"test-region\",\n        cluster: str = \"test-cluster\",\n        name: str = \"test-instance\",\n        ip_address: str = \"127.0.0.1\",\n        server_name: str = \"00000000-0000-0000-0000-000000000000.server.alloydb\",\n        cert_before: datetime = datetime.now(),\n        cert_expiry: datetime = datetime.now() + timedelta(hours=1),\n    ) -> None:\n        self.project = project\n        self.region = region\n        self.cluster = cluster\n        self.name = name\n        self.ip_address = ip_address\n        self.server_name = server_name\n        self.cert_before = cert_before\n        self.cert_expiry = cert_expiry\n\n    def generate_certs(self) -> None:\n        \"\"\"\n        Build certs required for chain of trust with testing server.\n        \"\"\"\n        # build root cert\n        self.root_cert, self.root_key = generate_cert(\"root.alloydb\")\n        # create self signed root cert\n        self.root_cert = self.root_cert.sign(self.root_key, hashes.SHA256())\n        # build intermediate cert\n        self.intermediate_cert, self.intermediate_key = generate_cert(\"client.alloydb\")\n        # create intermediate cert signed by root cert\n        self.intermediate_cert = self.intermediate_cert.sign(\n            self.root_key, hashes.SHA256()\n        )\n        # build server cert\n        self.server_cert, self.server_key = generate_cert(self.server_name)\n        # create server cert signed by root cert\n        self.server_cert = self.server_cert.sign(self.root_key, hashes.SHA256())\n\n    def get_pem_certs(self) -> Tuple[str, str, str]:\n        \"\"\"Helper method to get all certs in pem string format.\"\"\"\n        pem_root = self.root_cert.public_bytes(\n            encoding=serialization.Encoding.PEM\n        ).decode(\"UTF-8\")\n        pem_intermediate = self.intermediate_cert.public_bytes(\n            encoding=serialization.Encoding.PEM\n        ).decode(\"UTF-8\")\n        pem_server = self.server_cert.public_bytes(\n            encoding=serialization.Encoding.PEM\n        ).decode(\"UTF-8\")\n        return (pem_root, pem_intermediate, pem_server)", "\n\nclass FakeAlloyDBClient:\n    \"\"\"Fake class for testing AlloyDBClient\"\"\"\n\n    def __init__(self) -> None:\n        self.instance = FakeInstance()\n\n    async def _get_metadata(*args: Any, **kwargs: Any) -> str:\n        return \"127.0.0.1\"\n\n    async def _get_client_certificate(\n        self,\n        project: str,\n        region: str,\n        cluster: str,\n        key: rsa.RSAPrivateKey,\n    ) -> Tuple[str, List[str]]:\n        self.instance.generate_certs()\n        root_cert, intermediate_cert, _ = self.instance.get_pem_certs()\n        csr = _create_certificate_request(key)\n        # build client cert\n        client_cert = (\n            x509.CertificateBuilder()\n            .subject_name(csr.subject)\n            .issuer_name(self.instance.intermediate_cert.issuer)\n            .public_key(csr.public_key())\n            .serial_number(x509.random_serial_number())\n            .not_valid_before(self.instance.cert_before)\n            .not_valid_after(self.instance.cert_expiry)\n        )\n        # sign client cert with intermediate cert\n        client_cert = client_cert.sign(self.instance.intermediate_key, hashes.SHA256())\n        client_cert = client_cert.public_bytes(\n            encoding=serialization.Encoding.PEM\n        ).decode(\"UTF-8\")\n        return (client_cert, [intermediate_cert, root_cert])\n\n    async def close(self) -> None:\n        pass", ""]}
{"filename": "tests/unit/test_instance.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nfrom datetime import datetime, timedelta\n\nimport aiohttp", "\nimport aiohttp\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom mocks import FakeAlloyDBClient\nimport pytest\n\nfrom google.cloud.alloydb.connector.exceptions import RefreshError\nfrom google.cloud.alloydb.connector.instance import Instance\nfrom google.cloud.alloydb.connector.refresh import _is_valid, RefreshResult\n", "from google.cloud.alloydb.connector.refresh import _is_valid, RefreshResult\n\n\n@pytest.mark.asyncio\nasync def test_Instance_init() -> None:\n    \"\"\"\n    Test to check whether the __init__ method of Instance\n    can tell if the instance URI that's passed in is formatted correctly.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)", "    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    async with aiohttp.ClientSession() as client:\n        instance = Instance(\n            \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n            client,\n            key,\n        )\n        assert (\n            instance._project == \"test-project\"", "        assert (\n            instance._project == \"test-project\"\n            and instance._region == \"test-region\"\n            and instance._cluster == \"test-cluster\"\n            and instance._name == \"test-instance\"\n        )\n\n\n@pytest.mark.asyncio\nasync def test_Instance_init_invalid_instant_uri() -> None:", "@pytest.mark.asyncio\nasync def test_Instance_init_invalid_instant_uri() -> None:\n    \"\"\"\n    Test to check whether the __init__ method of Instance\n    will throw error for invalid instance URI.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    async with aiohttp.ClientSession() as client:\n        with pytest.raises(ValueError):\n            Instance(\"invalid/instance/uri/\", client, key)", "        with pytest.raises(ValueError):\n            Instance(\"invalid/instance/uri/\", client, key)\n\n\n@pytest.mark.asyncio\nasync def test_Instance_close() -> None:\n    \"\"\"\n    Test that Instance's close method\n    cancels tasks gracefully.\n    \"\"\"", "    cancels tasks gracefully.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    client = FakeAlloyDBClient()\n    instance = Instance(\n        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n        client,\n        key,\n    )\n    # make sure tasks aren't cancelled", "    )\n    # make sure tasks aren't cancelled\n    assert instance._current.cancelled() is False\n    assert instance._next.cancelled() is False\n    # run close() to cancel tasks\n    await instance.close()\n    # verify tasks are cancelled\n    assert (instance._current.done() or instance._current.cancelled()) is True\n    assert instance._next.cancelled() is True\n", "    assert instance._next.cancelled() is True\n\n\n@pytest.mark.asyncio\nasync def test_perform_refresh() -> None:\n    \"\"\"Test that _perform refresh returns valid RefreshResult\"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    client = FakeAlloyDBClient()\n    instance = Instance(\n        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",", "    instance = Instance(\n        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n        client,\n        key,\n    )\n    refresh = await instance._perform_refresh()\n    assert refresh.instance_ip == \"127.0.0.1\"\n    assert refresh.expiration == client.instance.cert_expiry.replace(microsecond=0)\n    # close instance\n    await instance.close()", "    # close instance\n    await instance.close()\n\n\n@pytest.mark.asyncio\nasync def test_schedule_refresh_replaces_result() -> None:\n    \"\"\"\n    Test to check whether _schedule_refresh replaces a valid refresh result\n    with another refresh result.\n    \"\"\"", "    with another refresh result.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    client = FakeAlloyDBClient()\n    instance = Instance(\n        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n        client,\n        key,\n    )\n    # check current refresh is valid", "    )\n    # check current refresh is valid\n    assert await _is_valid(instance._current) is True\n    current_refresh = instance._current\n    # schedule new refresh\n    await instance._schedule_refresh(0)\n    new_refresh = instance._current\n    # verify current has been replaced with new refresh\n    assert current_refresh != new_refresh\n    # check new refresh is valid", "    assert current_refresh != new_refresh\n    # check new refresh is valid\n    assert await _is_valid(new_refresh) is True\n    # close instance\n    await instance.close()\n\n\n@pytest.mark.asyncio\nasync def test_schedule_refresh_wont_replace_valid_result_with_invalid() -> None:\n    \"\"\"", "async def test_schedule_refresh_wont_replace_valid_result_with_invalid() -> None:\n    \"\"\"\n    Test to check whether _schedule_refresh won't replace a valid\n    refresh result with an invalid one.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    client = FakeAlloyDBClient()\n    instance = Instance(\n        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n        client,", "        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n        client,\n        key,\n    )\n    # check current refresh is valid\n    assert await _is_valid(instance._current) is True\n    current_refresh = instance._current\n    # set certificate to be expired\n    client.instance.cert_before = datetime.now() - timedelta(minutes=20)\n    client.instance.cert_expiry = datetime.now() - timedelta(minutes=10)", "    client.instance.cert_before = datetime.now() - timedelta(minutes=20)\n    client.instance.cert_expiry = datetime.now() - timedelta(minutes=10)\n    # schedule new refresh\n    new_refresh = instance._schedule_refresh(0)\n    # check new refresh is invalid\n    assert await _is_valid(new_refresh) is False\n    # check current was not replaced\n    assert current_refresh == instance._current\n    # close instance\n    await instance.close()", "    # close instance\n    await instance.close()\n\n\n@pytest.mark.asyncio\nasync def test_schedule_refresh_expired_cert() -> None:\n    \"\"\"\n    Test to check whether _schedule_refresh will throw RefreshError on\n    expired certificate.\n    \"\"\"", "    expired certificate.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    client = FakeAlloyDBClient()\n    # set certificate to be expired\n    client.instance.cert_before = datetime.now() - timedelta(minutes=20)\n    client.instance.cert_expiry = datetime.now() - timedelta(minutes=10)\n    instance = Instance(\n        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n        client,", "        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n        client,\n        key,\n    )\n    # check RefreshError is thrown\n    with pytest.raises(RefreshError):\n        await instance._current\n    # close instance\n    await instance.close()\n", "    await instance.close()\n\n\n@pytest.mark.asyncio\nasync def test_force_refresh_cancels_pending_refresh() -> None:\n    \"\"\"\n    Test that force_refresh cancels pending task if refresh_in_progress event is not set.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    client = FakeAlloyDBClient()", "    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    client = FakeAlloyDBClient()\n    instance = Instance(\n        \"projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance\",\n        client,\n        key,\n    )\n    # make sure initial refresh is finished\n    await instance._current\n    # since the pending refresh isn't for another ~56 min, the refresh_in_progress event", "    await instance._current\n    # since the pending refresh isn't for another ~56 min, the refresh_in_progress event\n    # shouldn't be set\n    pending_refresh = instance._next\n    assert instance._refresh_in_progress.is_set() is False\n    instance.force_refresh()\n    # pending_refresh has to be awaited for it to raised as cancelled\n    with pytest.raises(asyncio.CancelledError):\n        assert await pending_refresh\n    # verify pending_refresh has now been cancelled", "    # verify pending_refresh has now been cancelled\n    assert pending_refresh.cancelled() is True\n    assert isinstance(await instance._current, RefreshResult)\n    # close instance\n    await instance.close()\n"]}
{"filename": "tests/unit/test_refresh.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom datetime import datetime, timedelta\nimport ssl\n\nfrom cryptography import x509", "\nfrom cryptography import x509\nfrom cryptography.hazmat.primitives import hashes, serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom mocks import FakeInstance\n\nfrom google.cloud.alloydb.connector.refresh import (\n    _seconds_until_refresh,\n    RefreshResult,\n)", "    RefreshResult,\n)\nfrom google.cloud.alloydb.connector.utils import _create_certificate_request\n\n\ndef test_seconds_until_refresh_over_1_hour() -> None:\n    \"\"\"\n    Test _seconds_until_refresh returns proper time in seconds.\n    If expiration is over 1 hour, should return duration/2.\n    \"\"\"\n    now = datetime.now()\n    assert _seconds_until_refresh(now + timedelta(minutes=62), now) == 31 * 60", "\n\ndef test_seconds_until_refresh_under_1_hour_over_4_mins() -> None:\n    \"\"\"\n    Test _seconds_until_refresh returns proper time in seconds.\n    If expiration is under 1 hour and over 4 minutes,\n    should return duration-refresh_buffer (refresh_buffer = 4 minutes).\n    \"\"\"\n    now = datetime.now()\n    assert _seconds_until_refresh(now + timedelta(minutes=5), now) == 60", "\n\ndef test_seconds_until_refresh_under_4_mins() -> None:\n    \"\"\"\n    Test _seconds_until_refresh returns proper time in seconds.\n    If expiration is under 4 minutes, should return 0.\n    \"\"\"\n    assert _seconds_until_refresh(datetime.now() + timedelta(minutes=3)) == 0\n\n\ndef test_RefreshResult_init_(fake_instance: FakeInstance) -> None:\n    \"\"\"\n    Test to check whether the __init__ method of RefreshResult\n    can correctly initialize TLS context.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    fake_instance.generate_certs()\n    root_cert, intermediate_cert, _ = fake_instance.get_pem_certs()\n    csr = _create_certificate_request(key)\n    # build client cert\n    client_cert = (\n        x509.CertificateBuilder()\n        .subject_name(csr.subject)\n        .issuer_name(fake_instance.intermediate_cert.issuer)\n        .public_key(csr.public_key())\n        .serial_number(x509.random_serial_number())\n        .not_valid_before(datetime.now())\n        .not_valid_after(datetime.now() + timedelta(minutes=10))\n    )\n    # sign client cert with intermediate cert\n    client_cert = client_cert.sign(fake_instance.intermediate_key, hashes.SHA256())\n    client_cert = client_cert.public_bytes(encoding=serialization.Encoding.PEM).decode(\n        \"UTF-8\"\n    )\n    certs = (client_cert, [intermediate_cert, root_cert])\n    refresh = RefreshResult(fake_instance.ip_address, key, certs)\n    # verify TLS requirements\n    assert refresh.context.minimum_version == ssl.TLSVersion.TLSv1_3\n    assert refresh.context.request_ssl is False", "\n\ndef test_RefreshResult_init_(fake_instance: FakeInstance) -> None:\n    \"\"\"\n    Test to check whether the __init__ method of RefreshResult\n    can correctly initialize TLS context.\n    \"\"\"\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    fake_instance.generate_certs()\n    root_cert, intermediate_cert, _ = fake_instance.get_pem_certs()\n    csr = _create_certificate_request(key)\n    # build client cert\n    client_cert = (\n        x509.CertificateBuilder()\n        .subject_name(csr.subject)\n        .issuer_name(fake_instance.intermediate_cert.issuer)\n        .public_key(csr.public_key())\n        .serial_number(x509.random_serial_number())\n        .not_valid_before(datetime.now())\n        .not_valid_after(datetime.now() + timedelta(minutes=10))\n    )\n    # sign client cert with intermediate cert\n    client_cert = client_cert.sign(fake_instance.intermediate_key, hashes.SHA256())\n    client_cert = client_cert.public_bytes(encoding=serialization.Encoding.PEM).decode(\n        \"UTF-8\"\n    )\n    certs = (client_cert, [intermediate_cert, root_cert])\n    refresh = RefreshResult(fake_instance.ip_address, key, certs)\n    # verify TLS requirements\n    assert refresh.context.minimum_version == ssl.TLSVersion.TLSv1_3\n    assert refresh.context.request_ssl is False", ""]}
{"filename": "tests/unit/test_client.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nfrom typing import Any\n\nfrom aiohttp import web", "\nfrom aiohttp import web\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom mocks import FakeCredentials\nimport pytest\n\nfrom google.cloud.alloydb.connector.client import AlloyDBClient\nfrom google.cloud.alloydb.connector.version import __version__ as version\n\n", "\n\nasync def connectionInfo(request: Any) -> web.Response:\n    response = {\n        \"ipAddress\": \"127.0.0.1\",\n        \"instanceUid\": \"123456789\",\n    }\n    return web.Response(content_type=\"application/json\", body=json.dumps(response))\n\n", "\n\nasync def generateClientCertificate(request: Any) -> web.Response:\n    response = {\n        \"pemCertificate\": \"This is the client cert\",\n        \"pemCertificateChain\": [\n            \"This is the intermediate cert\",\n            \"This is the root cert\",\n        ],\n    }", "        ],\n    }\n    return web.Response(content_type=\"application/json\", body=json.dumps(response))\n\n\n@pytest.fixture\nasync def client(aiohttp_client: Any) -> Any:\n    app = web.Application()\n    metadata_uri = \"/v1beta/projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance/connectionInfo\"\n    app.router.add_get(metadata_uri, connectionInfo)", "    metadata_uri = \"/v1beta/projects/test-project/locations/test-region/clusters/test-cluster/instances/test-instance/connectionInfo\"\n    app.router.add_get(metadata_uri, connectionInfo)\n    client_cert_uri = \"/v1beta/projects/test-project/locations/test-region/clusters/test-cluster:generateClientCertificate\"\n    app.router.add_post(client_cert_uri, generateClientCertificate)\n    return await aiohttp_client(app)\n\n\n@pytest.mark.asyncio\nasync def test__get_metadata(client: Any, credentials: FakeCredentials) -> None:\n    \"\"\"", "async def test__get_metadata(client: Any, credentials: FakeCredentials) -> None:\n    \"\"\"\n    Test _get_metadata returns successfully.\n    \"\"\"\n    test_client = AlloyDBClient(\"\", \"\", credentials, client)\n    ip_address = await test_client._get_metadata(\n        \"test-project\",\n        \"test-region\",\n        \"test-cluster\",\n        \"test-instance\",", "        \"test-cluster\",\n        \"test-instance\",\n    )\n    assert ip_address == \"127.0.0.1\"\n\n\n@pytest.mark.asyncio\nasync def test__get_client_certificate(\n    client: Any, credentials: FakeCredentials\n) -> None:", "    client: Any, credentials: FakeCredentials\n) -> None:\n    \"\"\"\n    Test _get_client_certificate returns successfully.\n    \"\"\"\n    test_client = AlloyDBClient(\"\", \"\", credentials, client)\n    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n    certs = await test_client._get_client_certificate(\n        \"test-project\", \"test-region\", \"test-cluster\", key\n    )", "        \"test-project\", \"test-region\", \"test-cluster\", key\n    )\n    client_cert, cert_chain = certs\n    assert client_cert == \"This is the client cert\"\n    assert cert_chain[0] == \"This is the intermediate cert\"\n    assert cert_chain[1] == \"This is the root cert\"\n\n\n@pytest.mark.asyncio\nasync def test_AlloyDBClient_init_(credentials: FakeCredentials) -> None:", "@pytest.mark.asyncio\nasync def test_AlloyDBClient_init_(credentials: FakeCredentials) -> None:\n    \"\"\"\n    Test to check whether the __init__ method of AlloyDBClient\n    can correctly initialize a client.\n    \"\"\"\n    client = AlloyDBClient(\"www.test-endpoint.com\", \"my-quota-project\", credentials)\n    # verify base endpoint is set\n    assert client._alloydb_api_endpoint == \"www.test-endpoint.com\"\n    # verify proper headers are set", "    assert client._alloydb_api_endpoint == \"www.test-endpoint.com\"\n    # verify proper headers are set\n    assert client._client.headers[\"User-Agent\"] == f\"alloydb-python-connector/{version}\"\n    assert client._client.headers[\"x-goog-user-project\"] == \"my-quota-project\"\n    # close client\n    await client.close()\n"]}
{"filename": "tests/unit/conftest.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom mocks import (\n    FakeCredentials,\n    FakeInstance,\n)", "    FakeInstance,\n)\nimport pytest\n\n\n@pytest.fixture\ndef credentials() -> FakeCredentials:\n    return FakeCredentials()\n\n", "\n\n@pytest.fixture\ndef fake_instance() -> FakeInstance:\n    return FakeInstance()\n"]}
{"filename": "google/__init__.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\ntry:\n    import pkg_resources\n\n    pkg_resources.declare_namespace(__name__)\nexcept ImportError:\n    import pkgutil\n\n    __path__ = pkgutil.extend_path(__path__, __name__)", ""]}
{"filename": "google/cloud/__init__.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\ntry:\n    import pkg_resources\n\n    pkg_resources.declare_namespace(__name__)\nexcept ImportError:\n    import pkgutil\n\n    __path__ = pkgutil.extend_path(__path__, __name__)", ""]}
{"filename": "google/cloud/alloydb/__init__.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\ntry:\n    import pkg_resources\n\n    pkg_resources.declare_namespace(__name__)\nexcept ImportError:\n    import pkgutil\n\n    __path__ = pkgutil.extend_path(__path__, __name__)", ""]}
{"filename": "google/cloud/alloydb/connector/instance.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport asyncio\nimport logging", "import asyncio\nimport logging\nfrom typing import Tuple, TYPE_CHECKING\n\nfrom google.cloud.alloydb.connector.exceptions import RefreshError\nfrom google.cloud.alloydb.connector.rate_limiter import AsyncRateLimiter\nfrom google.cloud.alloydb.connector.refresh import (\n    _is_valid,\n    _seconds_until_refresh,\n    RefreshResult,", "    _seconds_until_refresh,\n    RefreshResult,\n)\n\nif TYPE_CHECKING:\n    import ssl\n    from cryptography.hazmat.primitives.asymmetric import rsa\n    from google.cloud.alloydb.connector.client import AlloyDBClient\n\nlogger = logging.getLogger(name=__name__)", "\nlogger = logging.getLogger(name=__name__)\n\n\nclass Instance:\n    \"\"\"\n    Manages the information used to connect to the AlloyDB instance.\n\n    Periodically calls the AlloyDB Admin API, automatically refreshing the\n    required information approximately 4 minutes before the previous\n    certificate expires (every ~56 minutes).\n\n    Args:\n        instance_uri (str): The instance URI of the AlloyDB instance.\n            ex. projects/<PROJECT>/locations/<REGION>/clusters/<CLUSTER>/instances/<INSTANCE>\n        client (AlloyDBClient): Client used to make requests to AlloyDB Admin APIs.\n        key (rsa.RSAPrivateKey): Client private key used in refresh operation\n            to generate client certificate.\n    \"\"\"\n\n    def __init__(\n        self, instance_uri: str, client: AlloyDBClient, key: rsa.RSAPrivateKey\n    ) -> None:\n        # validate and parse instance_uri\n        instance_uri_split = instance_uri.split(\"/\")\n        # should take form \"projects/<PROJECT>/locations/<REGION>/clusters/<CLUSTER>/instances/<INSTANCE>\"\n        if len(instance_uri_split) == 8:\n            self._instance_uri = instance_uri\n            self._project = instance_uri_split[1]\n            self._region = instance_uri_split[3]\n            self._cluster = instance_uri_split[5]\n            self._name = instance_uri_split[7]\n        else:\n            raise ValueError(\n                \"Arg `instance_uri` must have \"\n                \"format: projects/<PROJECT>/locations/<REGION>/clusters/<CLUSTER>/instances/<INSTANCE>, \"\n                f\"got {instance_uri}.\"\n            )\n\n        self._client = client\n        self._key = key\n        self._refresh_rate_limiter = AsyncRateLimiter(\n            max_capacity=2,\n            rate=1 / 30,\n        )\n        self._refresh_in_progress = asyncio.locks.Event()\n        # For the initial refresh operation, set current = next so that\n        # connection requests block until the first refresh is complete.\n        self._current: asyncio.Task = self._schedule_refresh(0)\n        self._next: asyncio.Task = self._current\n\n    async def _perform_refresh(self) -> RefreshResult:\n        \"\"\"\n        Perform a refresh operation on an AlloyDB instance.\n\n        Retrieves metadata and generates new client certificate\n        required to connect securely to the AlloyDB instance.\n\n        Returns:\n            RefreshResult: Result of the refresh operation.\n        \"\"\"\n        self._refresh_in_progress.set()\n        logger.debug(f\"['{self._instance_uri}']: Entered _perform_refresh\")\n\n        try:\n            await self._refresh_rate_limiter.acquire()\n\n            # fetch metadata\n            metadata_task = asyncio.create_task(\n                self._client._get_metadata(\n                    self._project,\n                    self._region,\n                    self._cluster,\n                    self._name,\n                )\n            )\n            # generate client and CA certs\n            certs_task = asyncio.create_task(\n                self._client._get_client_certificate(\n                    self._project,\n                    self._region,\n                    self._cluster,\n                    self._key,\n                )\n            )\n\n            ip_addr, certs = await asyncio.gather(metadata_task, certs_task)\n\n        except Exception:\n            logger.debug(\n                f\"['{self._instance_uri}']: Error occurred during _perform_refresh.\"\n            )\n            raise\n\n        finally:\n            self._refresh_in_progress.clear()\n\n        return RefreshResult(ip_addr, self._key, certs)\n\n    def _schedule_refresh(self, delay: int) -> asyncio.Task:\n        \"\"\"\n        Schedule a refresh operation.\n\n        Args:\n            delay (int): Time in seconds to sleep before performing refresh.\n\n        Returns:\n            asyncio.Task[RefreshResult]: A task representing the scheduled\n                refresh operation.\n        \"\"\"\n        return asyncio.create_task(self._refresh_operation(delay))\n\n    async def _refresh_operation(self, delay: int) -> RefreshResult:\n        \"\"\"\n        A coroutine that sleeps for the specified amount of time before\n        running _perform_refresh.\n\n        Args:\n            delay (int): Time in seconds to sleep before performing refresh.\n\n        Returns:\n            RefreshResult: Refresh result for an AlloyDB instance.\n        \"\"\"\n        refresh_task: asyncio.Task\n        try:\n            if delay > 0:\n                logger.debug(f\"['{self._instance_uri}']: Entering sleep\")\n                await asyncio.sleep(delay)\n            refresh_task = asyncio.create_task(self._perform_refresh())\n            refresh_result = await refresh_task\n            # check that refresh is valid\n            if not await _is_valid(refresh_task):\n                raise RefreshError(\n                    f\"['{self._instance_uri}']: Invalid refresh operation. Certficate appears to be expired.\"\n                )\n        # bad refresh attempt\n        except Exception:\n            logger.info(\n                f\"['{self._instance_uri}']: \"\n                \"An error occurred while performing refresh. \"\n                \"Scheduling another refresh attempt immediately\"\n            )\n            # check if current refresh result is invalid (expired),\n            # don't want to replace valid result with invalid refresh\n            if not await _is_valid(self._current):\n                self._current = refresh_task\n            # schedule new refresh attempt immediately\n            self._next = self._schedule_refresh(0)\n            raise\n        # if valid refresh, replace current with valid refresh result and schedule next refresh\n        self._current = refresh_task\n        # calculate refresh delay based on certificate expiration\n        delay = _seconds_until_refresh(refresh_result.expiration)\n        self._next = self._schedule_refresh(delay)\n\n        return refresh_result\n\n    def force_refresh(self) -> None:\n        \"\"\"\n        Schedules a new refresh operation immediately to be used\n        for future connection attempts.\n        \"\"\"\n        # if next refresh is not already in progress, cancel it and schedule new one immediately\n        if not self._refresh_in_progress.is_set():\n            self._next.cancel()\n            self._next = self._schedule_refresh(0)\n        # block all sequential connection attempts on the next refresh result\n        self._current = self._next\n\n    async def connection_info(self) -> Tuple[str, ssl.SSLContext]:\n        \"\"\"\n        Return connection info for current refresh result.\n\n        Returns:\n            Tuple[str, ssl.SSLContext]: AlloyDB instance IP address\n                and configured TLS connection.\n        \"\"\"\n        refresh: RefreshResult = await self._current\n        return refresh.instance_ip, refresh.context\n\n    async def close(self) -> None:\n        \"\"\"\n        Cancel refresh tasks.\n        \"\"\"\n        logger.debug(f\"['{self._instance_uri}']: Waiting for _current to be cancelled\")\n        self._current.cancel()\n        logger.debug(f\"['{self._instance_uri}']: Waiting for _next to be cancelled\")\n        self._next.cancel()\n        # gracefully wait for tasks to cancel\n        tasks = asyncio.gather(self._current, self._next, return_exceptions=True)\n        await asyncio.wait_for(tasks, timeout=2.0)", ""]}
{"filename": "google/cloud/alloydb/connector/version.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n__version__ = \"0.1.3-dev\"\n"]}
{"filename": "google/cloud/alloydb/connector/rate_limiter.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\n\n\nclass AsyncRateLimiter(object):\n    \"\"\"\n    An asyncio-compatible rate limiter.\n\n    Uses the Token Bucket algorithm (https://en.wikipedia.org/wiki/Token_bucket)\n    to limit the number of function calls over a time interval using an event queue.\n\n    Args:\n        max_capacity (int): The maximum capacity of tokens the bucket\n            will store at any one time. Defaults to 1.\n\n        rate (float): The number of tokens that should be added per second.\n            Defaults to 1 / 60.\n    \"\"\"\n\n    def __init__(\n        self,\n        max_capacity: int = 1,\n        rate: float = 1 / 60,\n    ) -> None:\n        self._rate = rate\n        self._max_capacity = max_capacity\n        self._loop = asyncio.get_running_loop()\n        self._tokens: float = max_capacity\n        self._last_token_update = self._loop.time()\n        self._lock = asyncio.Lock()\n\n    def _update_token_count(self) -> None:\n        \"\"\"\n        Calculates how much time has passed since the last leak and removes the\n        appropriate amount of events from the queue.\n        Leaking is done lazily, meaning that if there is a large time gap between\n        leaks, the next set of calls might be a burst if burst_size > 1\n        \"\"\"\n        now = self._loop.time()\n        time_elapsed = now - self._last_token_update\n        new_tokens = time_elapsed * self._rate\n        self._tokens = min(new_tokens + self._tokens, self._max_capacity)\n        self._last_token_update = now\n\n    async def _wait_for_next_token(self) -> None:\n        \"\"\"\n        Wait until enough time has elapsed to add another token.\n        \"\"\"\n        token_deficit = 1 - self._tokens\n        if token_deficit > 0:\n            wait_time = token_deficit / self._rate\n            await asyncio.sleep(wait_time)\n\n    async def acquire(self) -> None:\n        \"\"\"\n        Waits for a token to become available, if necessary, then subtracts token and allows\n        request to go through.\n        \"\"\"\n        async with self._lock:\n            self._update_token_count()\n            if self._tokens < 1:\n                await self._wait_for_next_token()\n                self._update_token_count()\n            self._tokens -= 1", "\nclass AsyncRateLimiter(object):\n    \"\"\"\n    An asyncio-compatible rate limiter.\n\n    Uses the Token Bucket algorithm (https://en.wikipedia.org/wiki/Token_bucket)\n    to limit the number of function calls over a time interval using an event queue.\n\n    Args:\n        max_capacity (int): The maximum capacity of tokens the bucket\n            will store at any one time. Defaults to 1.\n\n        rate (float): The number of tokens that should be added per second.\n            Defaults to 1 / 60.\n    \"\"\"\n\n    def __init__(\n        self,\n        max_capacity: int = 1,\n        rate: float = 1 / 60,\n    ) -> None:\n        self._rate = rate\n        self._max_capacity = max_capacity\n        self._loop = asyncio.get_running_loop()\n        self._tokens: float = max_capacity\n        self._last_token_update = self._loop.time()\n        self._lock = asyncio.Lock()\n\n    def _update_token_count(self) -> None:\n        \"\"\"\n        Calculates how much time has passed since the last leak and removes the\n        appropriate amount of events from the queue.\n        Leaking is done lazily, meaning that if there is a large time gap between\n        leaks, the next set of calls might be a burst if burst_size > 1\n        \"\"\"\n        now = self._loop.time()\n        time_elapsed = now - self._last_token_update\n        new_tokens = time_elapsed * self._rate\n        self._tokens = min(new_tokens + self._tokens, self._max_capacity)\n        self._last_token_update = now\n\n    async def _wait_for_next_token(self) -> None:\n        \"\"\"\n        Wait until enough time has elapsed to add another token.\n        \"\"\"\n        token_deficit = 1 - self._tokens\n        if token_deficit > 0:\n            wait_time = token_deficit / self._rate\n            await asyncio.sleep(wait_time)\n\n    async def acquire(self) -> None:\n        \"\"\"\n        Waits for a token to become available, if necessary, then subtracts token and allows\n        request to go through.\n        \"\"\"\n        async with self._lock:\n            self._update_token_count()\n            if self._tokens < 1:\n                await self._wait_for_next_token()\n                self._update_token_count()\n            self._tokens -= 1", ""]}
{"filename": "google/cloud/alloydb/connector/client.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport logging\nfrom typing import List, Optional, Tuple, TYPE_CHECKING", "import logging\nfrom typing import List, Optional, Tuple, TYPE_CHECKING\n\nimport aiohttp\nfrom cryptography.hazmat.primitives import serialization\n\nfrom google.auth.transport.requests import Request\nfrom google.cloud.alloydb.connector.utils import _create_certificate_request\nfrom google.cloud.alloydb.connector.version import __version__ as version\n\nif TYPE_CHECKING:\n    from cryptography.hazmat.primitives.asymmetric import rsa\n    from google.auth.credentials import Credentials", "from google.cloud.alloydb.connector.version import __version__ as version\n\nif TYPE_CHECKING:\n    from cryptography.hazmat.primitives.asymmetric import rsa\n    from google.auth.credentials import Credentials\n\nUSER_AGENT: str = f\"alloydb-python-connector/{version}\"\nAPI_VERSION: str = \"v1beta\"\n\nlogger = logging.getLogger(name=__name__)", "\nlogger = logging.getLogger(name=__name__)\n\n\nclass AlloyDBClient:\n    def __init__(\n        self,\n        alloydb_api_endpoint: str,\n        quota_project: Optional[str],\n        credentials: Credentials,\n        client: Optional[aiohttp.ClientSession] = None,\n    ) -> None:\n        \"\"\"\n        Establish the client to be used for AlloyDB Admin API requests.\n\n        Args:\n            alloydb_api_endpoint (str): Base URL to use when calling\n                the AlloyDB API endpoint.\n            quota_project (str): The Project ID for an existing Google Cloud\n                project. The project specified is used for quota and\n                billing purposes.\n            credentials (google.auth.credentials.Credentials):\n                A credentials object created from the google-auth Python library.\n                Must have the AlloyDB Admin scopes. For more info check out\n                https://google-auth.readthedocs.io/en/latest/.\n            client (aiohttp.ClientSession): Async client used to make requests to\n                AlloyDB Admin APIs.\n                Optional, defaults to None and creates new client.\n        \"\"\"\n        headers = {\n            \"x-goog-api-client\": USER_AGENT,\n            \"User-Agent\": USER_AGENT,\n            \"Content-Type\": \"application/json\",\n        }\n        if quota_project:\n            headers[\"x-goog-user-project\"] = quota_project\n\n        self._client = client if client else aiohttp.ClientSession(headers=headers)\n        self._credentials = credentials\n        self._alloydb_api_endpoint = alloydb_api_endpoint\n\n    async def _get_metadata(\n        self,\n        project: str,\n        region: str,\n        cluster: str,\n        name: str,\n    ) -> str:\n        \"\"\"\n        Fetch the metadata for a given AlloyDB instance.\n\n        Call the AlloyDB Admin APIs connectInfo method to retrieve the\n        information about an AlloyDB instance that is used to create secure\n        connections.\n\n        Args:\n            project (str): Google Cloud project ID that the AlloyDB instance\n                resides in.\n            region (str): Google Cloud region of the AlloyDB instance.\n            cluster (str): The name of the AlloyDB cluster.\n            name (str): The name of the AlloyDB instance.\n\n        Returns:\n            str: IP address of the AlloyDB instance.\n        \"\"\"\n        logger.debug(f\"['{project}/{region}/{cluster}/{name}']: Requesting metadata\")\n\n        if not self._credentials.valid:\n            request = Request()\n            self._credentials.refresh(request)\n\n        headers = {\n            \"Authorization\": f\"Bearer {self._credentials.token}\",\n        }\n\n        url = f\"{self._alloydb_api_endpoint}/{API_VERSION}/projects/{project}/locations/{region}/clusters/{cluster}/instances/{name}/connectionInfo\"\n\n        resp = await self._client.get(url, headers=headers, raise_for_status=True)\n        resp_dict = await resp.json()\n\n        return resp_dict[\"ipAddress\"]\n\n    async def _get_client_certificate(\n        self,\n        project: str,\n        region: str,\n        cluster: str,\n        key: rsa.RSAPrivateKey,\n    ) -> Tuple[str, List[str]]:\n        \"\"\"\n        Fetch a client certificate for the given AlloyDB cluster.\n\n        Call the AlloyDB Admin API's generateClientCertificate\n        method to create a signed TLS certificate that is authorized to connect via the\n        AlloyDB instance's serverside proxy. The cert is valid for twenty-four hours.\n\n        Args:\n            project (str): Google Cloud project ID that the AlloyDB instance\n                resides in.\n            region (str): Google Cloud region of the AlloyDB instance.\n            cluster (str): The name of the AlloyDB cluster.\n            key (rsa.RSAPrivateKey): Client private key used in refresh operation\n                to generate client certificate.\n\n        Returns:\n            Tuple[str, list[str]]: Tuple containing the client certificate\n                and certificate chain for the AlloyDB instance.\n        \"\"\"\n        logger.debug(f\"['{project}/{region}/{cluster}']: Requesting client certificate\")\n\n        if not self._credentials.valid:\n            request = Request()\n            self._credentials.refresh(request)\n\n        headers = {\n            \"Authorization\": f\"Bearer {self._credentials.token}\",\n        }\n\n        url = f\"{self._alloydb_api_endpoint}/{API_VERSION}/projects/{project}/locations/{region}/clusters/{cluster}:generateClientCertificate\"\n\n        # create the certificate signing request\n        csr = _create_certificate_request(key)\n        csr_str = csr.public_bytes(encoding=serialization.Encoding.PEM).decode(\"utf-8\")\n\n        data = {\n            \"pemCsr\": csr_str,\n            \"certDuration\": \"3600s\",\n        }\n\n        resp = await self._client.post(\n            url, headers=headers, json=data, raise_for_status=True\n        )\n        resp_dict = await resp.json()\n\n        return (resp_dict[\"pemCertificate\"], resp_dict[\"pemCertificateChain\"])\n\n    async def close(self) -> None:\n        \"\"\"Close AlloyDBClient gracefully.\"\"\"\n        await self._client.close()", ""]}
{"filename": "google/cloud/alloydb/connector/__init__.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom .connector import Connector\n\n__ALL__ = [Connector]\n\ntry:\n    import pkg_resources\n\n    pkg_resources.declare_namespace(__name__)\nexcept ImportError:\n    import pkgutil\n\n    __path__ = pkgutil.extend_path(__path__, __name__)", "\ntry:\n    import pkg_resources\n\n    pkg_resources.declare_namespace(__name__)\nexcept ImportError:\n    import pkgutil\n\n    __path__ = pkgutil.extend_path(__path__, __name__)\n", ""]}
{"filename": "google/cloud/alloydb/connector/connector.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom functools import partial", "import asyncio\nfrom functools import partial\nfrom threading import Thread\nfrom types import TracebackType\nfrom typing import Any, Dict, Optional, Type, TYPE_CHECKING\n\nfrom cryptography.hazmat.primitives.asymmetric import rsa\n\nfrom google.auth import default\nfrom google.auth.credentials import with_scopes_if_required", "from google.auth import default\nfrom google.auth.credentials import with_scopes_if_required\nfrom google.cloud.alloydb.connector.client import AlloyDBClient\nfrom google.cloud.alloydb.connector.instance import Instance\nimport google.cloud.alloydb.connector.pg8000 as pg8000\n\nif TYPE_CHECKING:\n    from google.auth.credentials import Credentials\n\n\nclass Connector:\n    \"\"\"A class to configure and create connections to Cloud SQL instances.\n\n    Args:\n        credentials (google.auth.credentials.Credentials):\n            A credentials object created from the google-auth Python library.\n            If not specified, Application Default Credentials are used.\n        quota_project (str): The Project ID for an existing Google Cloud\n            project. The project specified is used for quota and\n            billing purposes.\n            Defaults to None, picking up project from environment.\n        alloydb_api_endpoint (str): Base URL to use when calling\n            the AlloyDB API endpoint. Defaults to \"https://alloydb.googleapis.com\".\n    \"\"\"\n\n    def __init__(\n        self,\n        credentials: Optional[Credentials] = None,\n        quota_project: Optional[str] = None,\n        alloydb_api_endpoint: str = \"https://alloydb.googleapis.com\",\n    ) -> None:\n        # create event loop and start it in background thread\n        self._loop: asyncio.AbstractEventLoop = asyncio.new_event_loop()\n        self._thread = Thread(target=self._loop.run_forever, daemon=True)\n        self._thread.start()\n        self._instances: Dict[str, Instance] = {}\n        # initialize default params\n        self._quota_project = quota_project\n        self._alloydb_api_endpoint = alloydb_api_endpoint\n        # initialize credentials\n        scopes = [\"https://www.googleapis.com/auth/cloud-platform\"]\n        if credentials:\n            self._credentials = with_scopes_if_required(credentials, scopes=scopes)\n        # otherwise use application default credentials\n        else:\n            self._credentials, _ = default(scopes=scopes)\n        self._key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n        self._client: Optional[AlloyDBClient] = None\n\n    def connect(self, instance_uri: str, driver: str, **kwargs: Any) -> Any:\n        \"\"\"\n        Prepares and returns a database DBAPI connection object.\n\n        Starts background tasks to refresh the certificates and get\n        AlloyDB instance IP address. Creates a secure TLS connection\n        to establish connection to AlloyDB instance.\n\n        Args:\n            instance_uri (str): The instance URI of the AlloyDB instance.\n                ex. projects/<PROJECT>/locations/<REGION>/clusters/<CLUSTER>/instances/<INSTANCE>\n            driver (str): A string representing the database driver to connect with.\n                Supported drivers are pg8000.\n            **kwargs: Pass in any database driver-specific arguments needed\n                to fine tune connection.\n\n        Returns:\n            connection: A DBAPI connection to the specified AlloyDB instance.\n        \"\"\"\n        # call async connect and wait on result\n        connect_task = asyncio.run_coroutine_threadsafe(\n            self.connect_async(instance_uri, driver, **kwargs), self._loop\n        )\n        return connect_task.result()\n\n    async def connect_async(self, instance_uri: str, driver: str, **kwargs: Any) -> Any:\n        \"\"\"\n        Asynchronously prepares and returns a database connection object.\n\n        Starts tasks to refresh the certificates and get\n        AlloyDB instance IP address. Creates a secure TLS connection\n        to establish connection to AlloyDB instance.\n\n        Args:\n            instance_uri (str): The instance URI of the AlloyDB instance.\n                ex. projects/<PROJECT>/locations/<REGION>/clusters/<CLUSTER>/instances/<INSTANCE>\n            driver (str): A string representing the database driver to connect with.\n                Supported drivers are pg8000.\n            **kwargs: Pass in any database driver-specific arguments needed\n                to fine tune connection.\n\n        Returns:\n            connection: A DBAPI connection to the specified AlloyDB instance.\n        \"\"\"\n        if self._client is None:\n            # lazy init client as it has to be initialized in async context\n            self._client = AlloyDBClient(\n                self._alloydb_api_endpoint, self._quota_project, self._credentials\n            )\n        # use existing connection info if possible\n        if instance_uri in self._instances:\n            instance = self._instances[instance_uri]\n        else:\n            instance = Instance(\n                instance_uri,\n                self._client,\n                self._key,\n            )\n            self._instances[instance_uri] = instance\n\n        connect_func = {\n            \"pg8000\": pg8000.connect,\n        }\n        # only accept supported database drivers\n        try:\n            connector = connect_func[driver]\n        except KeyError:\n            raise ValueError(f\"Driver '{driver}' is not a supported database driver.\")\n\n        # Host and ssl options come from the certificates and instance IP address\n        # so we don't want the user to specify them.\n        kwargs.pop(\"host\", None)\n        kwargs.pop(\"ssl\", None)\n        kwargs.pop(\"port\", None)\n\n        # get connection info for AlloyDB instance\n        ip_address, context = await instance.connection_info()\n\n        # synchronous drivers are blocking and run using executor\n        try:\n            connect_partial = partial(connector, ip_address, context, **kwargs)\n            return await self._loop.run_in_executor(None, connect_partial)\n        except Exception:\n            # we attempt a force refresh, then throw the error\n            instance.force_refresh()\n            raise\n\n    def __enter__(self) -> \"Connector\":\n        \"\"\"Enter context manager by returning Connector object\"\"\"\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        \"\"\"Exit context manager by closing Connector\"\"\"\n        self.close()\n\n    def close(self) -> None:\n        \"\"\"Close Connector by stopping tasks and releasing resources.\"\"\"\n        close_future = asyncio.run_coroutine_threadsafe(\n            self.close_async(), loop=self._loop\n        )\n        # Will attempt to gracefully shut down tasks for 3s\n        close_future.result(timeout=3)\n        # if background thread exists for Connector, clean it up\n        if self._thread:\n            # stop event loop running in background thread\n            self._loop.call_soon_threadsafe(self._loop.stop)\n            # wait for thread to finish closing (i.e. loop to stop)\n            self._thread.join()\n\n    async def close_async(self) -> None:\n        \"\"\"Helper function to cancel Instances' tasks\n        and close client.\"\"\"\n        await asyncio.gather(\n            *[instance.close() for instance in self._instances.values()]\n        )\n        if self._client:\n            await self._client.close()", "\n\nclass Connector:\n    \"\"\"A class to configure and create connections to Cloud SQL instances.\n\n    Args:\n        credentials (google.auth.credentials.Credentials):\n            A credentials object created from the google-auth Python library.\n            If not specified, Application Default Credentials are used.\n        quota_project (str): The Project ID for an existing Google Cloud\n            project. The project specified is used for quota and\n            billing purposes.\n            Defaults to None, picking up project from environment.\n        alloydb_api_endpoint (str): Base URL to use when calling\n            the AlloyDB API endpoint. Defaults to \"https://alloydb.googleapis.com\".\n    \"\"\"\n\n    def __init__(\n        self,\n        credentials: Optional[Credentials] = None,\n        quota_project: Optional[str] = None,\n        alloydb_api_endpoint: str = \"https://alloydb.googleapis.com\",\n    ) -> None:\n        # create event loop and start it in background thread\n        self._loop: asyncio.AbstractEventLoop = asyncio.new_event_loop()\n        self._thread = Thread(target=self._loop.run_forever, daemon=True)\n        self._thread.start()\n        self._instances: Dict[str, Instance] = {}\n        # initialize default params\n        self._quota_project = quota_project\n        self._alloydb_api_endpoint = alloydb_api_endpoint\n        # initialize credentials\n        scopes = [\"https://www.googleapis.com/auth/cloud-platform\"]\n        if credentials:\n            self._credentials = with_scopes_if_required(credentials, scopes=scopes)\n        # otherwise use application default credentials\n        else:\n            self._credentials, _ = default(scopes=scopes)\n        self._key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n        self._client: Optional[AlloyDBClient] = None\n\n    def connect(self, instance_uri: str, driver: str, **kwargs: Any) -> Any:\n        \"\"\"\n        Prepares and returns a database DBAPI connection object.\n\n        Starts background tasks to refresh the certificates and get\n        AlloyDB instance IP address. Creates a secure TLS connection\n        to establish connection to AlloyDB instance.\n\n        Args:\n            instance_uri (str): The instance URI of the AlloyDB instance.\n                ex. projects/<PROJECT>/locations/<REGION>/clusters/<CLUSTER>/instances/<INSTANCE>\n            driver (str): A string representing the database driver to connect with.\n                Supported drivers are pg8000.\n            **kwargs: Pass in any database driver-specific arguments needed\n                to fine tune connection.\n\n        Returns:\n            connection: A DBAPI connection to the specified AlloyDB instance.\n        \"\"\"\n        # call async connect and wait on result\n        connect_task = asyncio.run_coroutine_threadsafe(\n            self.connect_async(instance_uri, driver, **kwargs), self._loop\n        )\n        return connect_task.result()\n\n    async def connect_async(self, instance_uri: str, driver: str, **kwargs: Any) -> Any:\n        \"\"\"\n        Asynchronously prepares and returns a database connection object.\n\n        Starts tasks to refresh the certificates and get\n        AlloyDB instance IP address. Creates a secure TLS connection\n        to establish connection to AlloyDB instance.\n\n        Args:\n            instance_uri (str): The instance URI of the AlloyDB instance.\n                ex. projects/<PROJECT>/locations/<REGION>/clusters/<CLUSTER>/instances/<INSTANCE>\n            driver (str): A string representing the database driver to connect with.\n                Supported drivers are pg8000.\n            **kwargs: Pass in any database driver-specific arguments needed\n                to fine tune connection.\n\n        Returns:\n            connection: A DBAPI connection to the specified AlloyDB instance.\n        \"\"\"\n        if self._client is None:\n            # lazy init client as it has to be initialized in async context\n            self._client = AlloyDBClient(\n                self._alloydb_api_endpoint, self._quota_project, self._credentials\n            )\n        # use existing connection info if possible\n        if instance_uri in self._instances:\n            instance = self._instances[instance_uri]\n        else:\n            instance = Instance(\n                instance_uri,\n                self._client,\n                self._key,\n            )\n            self._instances[instance_uri] = instance\n\n        connect_func = {\n            \"pg8000\": pg8000.connect,\n        }\n        # only accept supported database drivers\n        try:\n            connector = connect_func[driver]\n        except KeyError:\n            raise ValueError(f\"Driver '{driver}' is not a supported database driver.\")\n\n        # Host and ssl options come from the certificates and instance IP address\n        # so we don't want the user to specify them.\n        kwargs.pop(\"host\", None)\n        kwargs.pop(\"ssl\", None)\n        kwargs.pop(\"port\", None)\n\n        # get connection info for AlloyDB instance\n        ip_address, context = await instance.connection_info()\n\n        # synchronous drivers are blocking and run using executor\n        try:\n            connect_partial = partial(connector, ip_address, context, **kwargs)\n            return await self._loop.run_in_executor(None, connect_partial)\n        except Exception:\n            # we attempt a force refresh, then throw the error\n            instance.force_refresh()\n            raise\n\n    def __enter__(self) -> \"Connector\":\n        \"\"\"Enter context manager by returning Connector object\"\"\"\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        \"\"\"Exit context manager by closing Connector\"\"\"\n        self.close()\n\n    def close(self) -> None:\n        \"\"\"Close Connector by stopping tasks and releasing resources.\"\"\"\n        close_future = asyncio.run_coroutine_threadsafe(\n            self.close_async(), loop=self._loop\n        )\n        # Will attempt to gracefully shut down tasks for 3s\n        close_future.result(timeout=3)\n        # if background thread exists for Connector, clean it up\n        if self._thread:\n            # stop event loop running in background thread\n            self._loop.call_soon_threadsafe(self._loop.stop)\n            # wait for thread to finish closing (i.e. loop to stop)\n            self._thread.join()\n\n    async def close_async(self) -> None:\n        \"\"\"Helper function to cancel Instances' tasks\n        and close client.\"\"\"\n        await asyncio.gather(\n            *[instance.close() for instance in self._instances.values()]\n        )\n        if self._client:\n            await self._client.close()", ""]}
{"filename": "google/cloud/alloydb/connector/utils.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nfrom typing import List, Tuple, TYPE_CHECKING\n", "from typing import List, Tuple, TYPE_CHECKING\n\nfrom cryptography import x509\nfrom cryptography.hazmat.primitives import hashes, serialization\nfrom cryptography.x509.oid import NameOID\n\nif TYPE_CHECKING:\n    from cryptography.hazmat.primitives.asymmetric import rsa\n\n\ndef _write_to_file(\n    dir_path: str, cert_chain: List[str], client_cert: str, key: rsa.RSAPrivateKey\n) -> Tuple[str, str, str]:\n    \"\"\"\n    Helper function to write the server_ca, client certificate and\n    private key to .pem files in a given directory.\n    \"\"\"\n    ca_filename = f\"{dir_path}/ca.pem\"\n    cert_chain_filename = f\"{dir_path}/chain.pem\"\n    key_filename = f\"{dir_path}/priv.pem\"\n\n    key_bytes = key.private_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PrivateFormat.TraditionalOpenSSL,\n        encryption_algorithm=serialization.NoEncryption(),\n    )\n\n    # add client cert to beginning of cert chain\n    full_chain = [client_cert] + cert_chain\n\n    with open(ca_filename, \"w+\") as ca_out:\n        ca_out.write(\"\".join(cert_chain))\n    with open(cert_chain_filename, \"w+\") as chain_out:\n        chain_out.write(\"\".join(full_chain))\n    with open(key_filename, \"wb\") as priv_out:\n        priv_out.write(key_bytes)\n\n    return (ca_filename, cert_chain_filename, key_filename)", "\n\ndef _write_to_file(\n    dir_path: str, cert_chain: List[str], client_cert: str, key: rsa.RSAPrivateKey\n) -> Tuple[str, str, str]:\n    \"\"\"\n    Helper function to write the server_ca, client certificate and\n    private key to .pem files in a given directory.\n    \"\"\"\n    ca_filename = f\"{dir_path}/ca.pem\"\n    cert_chain_filename = f\"{dir_path}/chain.pem\"\n    key_filename = f\"{dir_path}/priv.pem\"\n\n    key_bytes = key.private_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PrivateFormat.TraditionalOpenSSL,\n        encryption_algorithm=serialization.NoEncryption(),\n    )\n\n    # add client cert to beginning of cert chain\n    full_chain = [client_cert] + cert_chain\n\n    with open(ca_filename, \"w+\") as ca_out:\n        ca_out.write(\"\".join(cert_chain))\n    with open(cert_chain_filename, \"w+\") as chain_out:\n        chain_out.write(\"\".join(full_chain))\n    with open(key_filename, \"wb\") as priv_out:\n        priv_out.write(key_bytes)\n\n    return (ca_filename, cert_chain_filename, key_filename)", "\n\ndef _create_certificate_request(\n    private_key: rsa.RSAPrivateKey,\n) -> x509.CertificateSigningRequest:\n    csr = (\n        x509.CertificateSigningRequestBuilder()\n        .subject_name(\n            x509.Name(\n                [\n                    x509.NameAttribute(NameOID.COMMON_NAME, \"alloydb-connector\"),\n                    x509.NameAttribute(NameOID.COUNTRY_NAME, \"US\"),\n                    x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME, \"CA\"),\n                    x509.NameAttribute(NameOID.LOCALITY_NAME, \"Sunnyvale\"),\n                    x509.NameAttribute(NameOID.ORGANIZATION_NAME, \"Google LLC\"),\n                    x509.NameAttribute(NameOID.ORGANIZATIONAL_UNIT_NAME, \"Cloud\"),\n                ]\n            )\n        )\n        .sign(private_key, hashes.SHA256())\n    )\n    return csr", ""]}
{"filename": "google/cloud/alloydb/connector/pg8000.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport ssl\nfrom typing import Any, TYPE_CHECKING\n\nSERVER_PROXY_PORT = 5433", "\nSERVER_PROXY_PORT = 5433\n\nif TYPE_CHECKING:\n    import pg8000\n\n\ndef connect(\n    ip_address: str, ctx: ssl.SSLContext, **kwargs: Any\n) -> \"pg8000.dbapi.Connection\":\n    \"\"\"Create a pg8000 DBAPI connection object.\n\n    Args:\n        ip_address (str): IP address of AlloyDB instance to connect to.\n        ctx (ssl.SSLContext): Context used to create a TLS connection\n            with AlloyDB instance ssl certificates.\n\n    Returns:\n        pg8000.dbapi.Connection: A pg8000 Connection object for\n        the AlloyDB instance.\n    \"\"\"\n    # Connecting through pg8000 is done by passing in an SSL Context and setting the\n    # \"request_ssl\" attr to false. This works because when \"request_ssl\" is false,\n    # the driver skips the database level SSL/TLS exchange, but still uses the\n    # ssl_context (if it is not None) to create the connection.\n    try:\n        import pg8000\n    except ImportError:\n        raise ImportError(\n            'Unable to import module \"pg8000.\" Please install and try again.'\n        )\n    user = kwargs.pop(\"user\")\n    db = kwargs.pop(\"db\")\n    passwd = kwargs.pop(\"password\")\n    setattr(ctx, \"request_ssl\", False)\n    return pg8000.dbapi.connect(\n        user,\n        database=db,\n        password=passwd,\n        host=ip_address,\n        port=SERVER_PROXY_PORT,\n        ssl_context=ctx,\n        **kwargs,\n    )", ""]}
{"filename": "google/cloud/alloydb/connector/exceptions.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nclass RefreshError(Exception):\n    pass\n", ""]}
{"filename": "google/cloud/alloydb/connector/refresh.py", "chunked_list": ["# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom datetime import datetime", "import asyncio\nfrom datetime import datetime\nimport logging\nimport ssl\nfrom tempfile import TemporaryDirectory\nfrom typing import List, Tuple, TYPE_CHECKING\n\nfrom cryptography import x509\n\nfrom google.cloud.alloydb.connector.utils import _write_to_file", "\nfrom google.cloud.alloydb.connector.utils import _write_to_file\n\nif TYPE_CHECKING:\n    from cryptography.hazmat.primitives.asymmetric import rsa\n\nlogger = logging.getLogger(name=__name__)\n\n# _refresh_buffer is the amount of time before a refresh's result expires\n# that a new refresh operation begins.", "# _refresh_buffer is the amount of time before a refresh's result expires\n# that a new refresh operation begins.\n_refresh_buffer: int = 4 * 60  # 4 minutes\n\n\ndef _seconds_until_refresh(expiration: datetime, now: datetime = datetime.now()) -> int:\n    \"\"\"\n    Calculates the duration to wait before starting the next refresh.\n    Usually the duration will be half of the time until certificate\n    expiration.\n\n    Args:\n        expiration (datetime.datetime): Time of certificate expiration.\n        now (datetime.datetime): Current time. Defaults to datetime.now()\n    Returns:\n        int: Time in seconds to wait before performing next refresh.\n    \"\"\"\n\n    duration = int((expiration - now).total_seconds())\n\n    # if certificate duration is less than 1 hour\n    if duration < 3600:\n        # something is wrong with certificate, refresh now\n        if duration < _refresh_buffer:\n            return 0\n        # otherwise wait until 4 minutes before expiration for next refresh\n        return duration - _refresh_buffer\n    return duration // 2", "\n\nclass RefreshResult:\n    \"\"\"\n    Manages the result of a refresh operation.\n\n    Holds the certificates and IP address of an AlloyDB instance.\n    Builds the TLS context required to connect to AlloyDB database.\n\n    Args:\n        instance_ip (str): The IP address of the AlloyDB instance.\n        key (rsa.RSAPrivateKey): Private key for the client connection.\n        certs (Tuple[str, List(str)]): Client cert and CA certs for establishing\n            the chain of trust used in building the TLS context.\n    \"\"\"\n\n    def __init__(\n        self, instance_ip: str, key: rsa.RSAPrivateKey, certs: Tuple[str, List[str]]\n    ) -> None:\n        self.instance_ip = instance_ip\n        self._key = key\n        self._certs = certs\n\n        # create TLS context\n        self.context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n        # update ssl.PROTOCOL_TLS_CLIENT default\n        self.context.check_hostname = False\n        # force TLSv1.3\n        self.context.minimum_version = ssl.TLSVersion.TLSv1_3\n        # add request_ssl attribute to ssl.SSLContext, required for pg8000 driver\n        self.context.request_ssl = False  # type: ignore\n\n        client_cert, cert_chain = self._certs\n        # get expiration from client certificate\n        cert_obj = x509.load_pem_x509_certificate(client_cert.encode(\"UTF-8\"))\n        self.expiration = cert_obj.not_valid_after\n\n        # tmpdir and its contents are automatically deleted after the CA cert\n        # and cert chain are loaded into the SSLcontext. The values\n        # need to be written to files in order to be loaded by the SSLContext\n        with TemporaryDirectory() as tmpdir:\n            ca_filename, cert_chain_filename, key_filename = _write_to_file(\n                tmpdir, cert_chain, client_cert, self._key\n            )\n            self.context.load_cert_chain(cert_chain_filename, keyfile=key_filename)\n            self.context.load_verify_locations(cafile=ca_filename)", "\n\nasync def _is_valid(task: asyncio.Task) -> bool:\n    try:\n        result = await task\n        # valid if current time is before cert expiration\n        if datetime.now() < result.expiration:\n            return True\n    except Exception:\n        # suppress any errors from task\n        logger.debug(\"Current refresh result is invalid.\")", "    return False\n"]}
