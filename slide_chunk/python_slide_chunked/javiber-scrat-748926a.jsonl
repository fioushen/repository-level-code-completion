{"filename": "tests/test_basic.py", "chunked_list": ["import pytest\n\n# TODO: The method of a nonlocal counter is not great\n#       There should be a way to setup a fixture or a mock\n#       to check how many times the underlying function is called\n\n\ndef test_no_params(patched_decorator):\n    counter = 0\n\n    def no_params_func():\n        nonlocal counter\n        counter += 1\n        return counter\n\n    cached_func = patched_decorator()(no_params_func)\n\n    assert cached_func() == 1\n    assert cached_func() == 1\n    assert counter == 1", "\n\ndef test_method(patched_decorator):\n    counter = 0\n\n    class A:\n        def f(self):\n            nonlocal counter\n            counter += 1\n            return 1\n\n    a = A()\n\n    cached_func = patched_decorator()(a.f)\n\n    assert cached_func() == 1\n    assert cached_func() == 1\n    assert counter == 1", "\n\ndef test_one_arg(patched_decorator):\n    counter = 0\n\n    def one_arg_func(a):\n        nonlocal counter\n        counter += 1\n        return a + a\n\n    cached_func = patched_decorator()(one_arg_func)\n\n    assert cached_func(1) == 2\n    assert counter == 1\n    assert cached_func(1) == 2\n    assert cached_func(a=1) == 2\n    assert counter == 1\n\n    assert cached_func(2) == 4\n    assert counter == 2\n    assert cached_func(2) == 4\n    assert cached_func(a=2) == 4\n    assert counter == 2\n\n    assert cached_func(\"1\") == \"11\"\n    assert counter == 3\n    assert cached_func(\"1\") == \"11\"\n    assert cached_func(a=\"1\") == \"11\"\n    assert counter == 3", "\n\ndef test_multiple_args(patched_decorator):\n    counter = 0\n\n    def multiple_args_func(a, b):\n        nonlocal counter\n        counter += 1\n        return a + b\n\n    cached_func = patched_decorator()(multiple_args_func)\n\n    assert cached_func(1, 1) == 2\n    assert counter == 1\n    assert cached_func(1, 1) == 2\n    assert cached_func(1, b=1) == 2\n    assert cached_func(a=1, b=1) == 2\n    assert counter == 1\n\n    assert cached_func(1, 2) == 3\n    assert counter == 2\n    assert cached_func(1, 2) == 3\n    assert cached_func(1, b=2) == 3\n    assert cached_func(a=1, b=2) == 3\n    assert counter == 2", "\n\ndef test_keyword_only_args(patched_decorator):\n    counter = 0\n\n    def keyword_only_args_func(a, *, b):\n        nonlocal counter\n        counter += 1\n        return a + b\n\n    cached_func = patched_decorator()(keyword_only_args_func)\n\n    #\n    # Test that the cached function raises the same exception\n    # as the non-cached function\n    #\n    try:\n        keyword_only_args_func(1, 1)\n    except Exception as e:\n        expected_exception = e.__class__\n\n    with pytest.raises(expected_exception):\n        cached_func(1, 1)\n\n    assert cached_func(1, b=1) == 2\n    assert counter == 1\n    assert cached_func(1, b=1) == 2\n    assert cached_func(a=1, b=1) == 2\n    assert counter == 1\n\n    assert cached_func(1, b=2) == 3\n    assert counter == 2\n    assert cached_func(1, b=2) == 3\n    assert cached_func(a=1, b=2) == 3\n    assert counter == 2", "\n\ndef test_var_args(patched_decorator):\n    counter = 0\n\n    def var_args_func(*args, **kwargs):\n        nonlocal counter\n        counter += 1\n        return sum(args) + sum(kwargs.values())\n\n    cached_func = patched_decorator()(var_args_func)\n\n    assert cached_func(1, b=1) == 2\n    assert counter == 1\n    assert cached_func(1, b=1) == 2\n    assert counter == 1\n\n    assert cached_func(1, b=2) == 3\n    assert counter == 2\n    assert cached_func(1, b=2) == 3\n    assert counter == 2\n\n    # for these types of function scrat can't know if\n    # f(1, 2) is the same as f(1, b=2) so it's run again\n    assert cached_func(1, 2) == 3\n    assert counter == 3\n    assert cached_func(1, 2) == 3\n    assert counter == 3\n\n    assert cached_func(a=1, b=2) == 3\n    assert counter == 4\n    assert cached_func(a=1, b=2) == 3\n    assert counter == 4", "\n\ndef test_code_changes(patched_decorator):\n    counter = 0\n\n    def code_changes_func():\n        nonlocal counter\n        counter += 1\n        return 1\n\n    cached_func = patched_decorator()(code_changes_func)\n\n    assert cached_func() == 1\n    assert cached_func() == 1\n    assert counter == 1\n\n    # a new function with the same name and code should re-use the nut\n    def code_changes_func():\n        nonlocal counter\n        counter += 1\n        return 1\n\n    cached_func = patched_decorator()(code_changes_func)\n\n    assert cached_func() == 1\n    assert cached_func() == 1\n    assert counter == 1\n\n    # a new function with the same name but different code should create a new nut\n    def code_changes_func():\n        nonlocal counter\n        counter += 1\n        return 2  # <- difference\n\n    cached_func = patched_decorator()(code_changes_func)\n\n    assert cached_func() == 2\n    assert cached_func() == 2\n    assert counter == 2", "\n\ndef test_multiple_func(patched_decorator):\n    counter_1 = 0\n\n    def multi_func_1():\n        nonlocal counter_1\n        counter_1 += 1\n        return 1\n\n    cached_func_1 = patched_decorator()(multi_func_1)\n\n    counter_2 = 0\n\n    def multi_func_2():\n        nonlocal counter_2\n        counter_2 += 1\n        return 1\n\n    cached_func_2 = patched_decorator()(multi_func_2)\n\n    assert cached_func_1() == 1\n    assert cached_func_2() == 1\n    assert counter_1 == 1\n    assert counter_2 == 1\n\n    assert cached_func_1() == 1\n    assert cached_func_2() == 1\n    assert counter_1 == 1\n    assert counter_2 == 1", ""]}
{"filename": "tests/test_watch.py", "chunked_list": ["def test_watch_functions(patched_decorator):\n    counter = 0\n\n    def aux_func():\n        return 1\n\n    @patched_decorator(watch_functions=[aux_func])\n    def watch_test_func():\n        nonlocal counter\n        counter += 1\n        return aux_func()\n\n    assert watch_test_func() == 1\n    assert watch_test_func() == 1\n    assert counter == 1\n\n    #\n    # Simulate a code change in aux_func\n    #\n    def aux_func():\n        return 2\n\n    @patched_decorator(watch_functions=[aux_func])\n    def watch_test_func():\n        nonlocal counter\n        counter += 1\n        return aux_func()\n\n    assert watch_test_func() == 2\n    assert watch_test_func() == 2\n    assert counter == 2", "\n\ndef test_watch_globals(patched_decorator):\n    g1 = 1\n    counter = 0\n\n    @patched_decorator(watch_globals=[\"g1\"])\n    def test_global_func():\n        nonlocal counter\n        counter += 1\n        return g1\n\n    assert test_global_func() == 1\n    assert test_global_func() == 1\n    assert counter == 1\n\n    #\n    # Change global var\n    #\n    g1 = 2\n    assert test_global_func() == 2\n    assert test_global_func() == 2\n    assert counter == 2", ""]}
{"filename": "tests/test_limits.py", "chunked_list": ["def test_size_limit(patched_decorator):\n    import os\n\n    # Function returns a random string so the only\n    # we get the same result is that the result was cached\n    @patched_decorator(max_size=29)\n    def size_limit_test_func(a):\n        return os.urandom(10)\n\n    # Add 3 entries\n    r1 = size_limit_test_func(1)  # resulting stash: 1\n    r2 = size_limit_test_func(2)  # resulting stash: 1, 2\n    # The size should not be enough to hold 3 results so the last call\n    # should have removed the result for 1 (oldest)\n    r3 = size_limit_test_func(3)  # resulting stash: 2, 3\n\n    assert size_limit_test_func(2) == r2  # resulting stash: 3, 2\n    assert size_limit_test_func(3) == r3  # resulting stash: 2, 3\n    # Notice this last call should remove result for 2\n    r12 = size_limit_test_func(1)  # resulting stash: 3, 1\n    assert r12 != r1\n\n    # result 3 should be the next in line to be removed,\n    # but let's test what happens if we use it\n    assert size_limit_test_func(3) == r3  # resulting stash: 1, 3\n    # add a new entry should remove the result for 1 and leave the rest\n    r4 = size_limit_test_func(4)  # resulting stash: 3, 4\n    assert size_limit_test_func(4) == r4  # resulting stash: 3, 4\n    assert size_limit_test_func(3) == r3  # resulting stash: 4, 3\n    assert size_limit_test_func(1) != r1  # resulting stash: 3, 1\n\n    # finally test that result 2 was removed before\n    assert size_limit_test_func(2) != r2  # resulting stash: 1, 2", ""]}
{"filename": "tests/conftest.py", "chunked_list": ["import logging\nimport os\nfrom pathlib import Path\nfrom tempfile import gettempdir\n\nimport pytest\nfrom sqlalchemy import create_engine\n\nfrom scrat import stash\nfrom scrat.config import Config", "from scrat import stash\nfrom scrat.config import Config\nfrom scrat.db import DBConnector\n\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\" %(name)s :: %(levelname)-8s :: %(message)s\",\n    force=True,\n)\n", ")\n\n\n@pytest.fixture\ndef in_memory_engine():\n    return create_engine(\"sqlite://\")\n\n\n@pytest.fixture\ndef patched_decorator(mocker, in_memory_engine):\n    mocker.patch(\"scrat.db.connector.create_engine\", lambda _: in_memory_engine)\n    tmp_folder = gettempdir()\n    mocker.patch(\n        \"scrat.config.Config.load\", lambda *_: Config(base_path=Path(tmp_folder))\n    )\n    config = Config.load()\n    os.makedirs(config.cache_path, exist_ok=True)\n    DBConnector.create_db(\"\")\n    return stash", "@pytest.fixture\ndef patched_decorator(mocker, in_memory_engine):\n    mocker.patch(\"scrat.db.connector.create_engine\", lambda _: in_memory_engine)\n    tmp_folder = gettempdir()\n    mocker.patch(\n        \"scrat.config.Config.load\", lambda *_: Config(base_path=Path(tmp_folder))\n    )\n    config = Config.load()\n    os.makedirs(config.cache_path, exist_ok=True)\n    DBConnector.create_db(\"\")\n    return stash", ""]}
{"filename": "examples/many_entries/run.py", "chunked_list": ["import random\n\nimport scrat as sc\n\n\n@sc.stash()\ndef func(i):\n    return random.randbytes(random.randint(1000, 5000))\n\n\nif __name__ == \"__main__\":\n    for i in range(20):\n        func(i)", "\n\nif __name__ == \"__main__\":\n    for i in range(20):\n        func(i)\n"]}
{"filename": "examples/pandas/run.py", "chunked_list": ["import logging\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport scrat as sc\n\nlogging.basicConfig(level=logging.DEBUG)\n", "logging.basicConfig(level=logging.DEBUG)\n\n\n@sc.stash()\ndef slow_func(df):\n    sum = 0\n    for _, row in df.iterrows():\n        sum += row.sum()\n    return sum / (len(df) * len(df.columns))\n", "\n\nif __name__ == \"__main__\":\n    np.random.seed(0)\n    df = pd.DataFrame(np.random.rand(500_000, 10))\n    t0 = time.time()\n    result = slow_func(df)\n    print(f\"slow_func took: {time.time() - t0:.10f} seconds\")\n    print(f\"result: {result: .3f}\")\n", ""]}
{"filename": "scrat/decorator.py", "chunked_list": ["import functools\nimport logging\nimport typing as T\n\nfrom .hasher import Hasher\nfrom .serializer import Serializer, get_default_serializer\nfrom .squirrel import Squirrel\nfrom .utils import Timer\n\nlogger = logging.getLogger(__name__)", "\nlogger = logging.getLogger(__name__)\n\n\ndef stash(\n    serializer: T.Optional[Serializer] = None,\n    name: T.Optional[str] = None,\n    hashers: T.Optional[T.Dict[str, Hasher]] = None,\n    hash_code: T.Optional[bool] = True,\n    ignore_args: T.Optional[T.List[str]] = None,\n    watch_functions: T.Optional[T.List[T.Any]] = None,\n    watch_globals: T.Optional[T.List[str]] = None,\n    force: T.Optional[bool] = None,\n    disable: T.Optional[bool] = None,\n    max_size: T.Optional[int] = None,\n):\n    \"\"\"Wrap a function to stash the results\n\n    Parameters\n    ----------\n    serializer\n        Select a serializer for the function's result, by default a good\n        serializer is inferred from the typehint, using `PickleSerializer` as\n        the fallback.\n    name\n        Name that identifies this function, by default the function name is used.\n    hashers\n        Dictionary specifying hashers used for the arguments, by default hashers\n        are selected according to the type of the argument, using `ToStringHasher`\n        as the fallback.\n    hash_code\n        Control if the function's code should be used in the hash, by default True.\n    ignore_args\n        List of arguments to ignore from the hash, by default None\n    watch_functions\n        List of functions which code should be included in the hash, by default None\n    watch_globals\n        List of global variables to include in the hash, by default None\n    force\n        If set to True the stash is ignored, the function is called and the result\n        is saved to the stash, by default the global setting `scrat.Setting.force` is\n        used\n    disable\n        If set to True the stash is ignored, the function called and the result\n        is **not** saved, by default the global setting `scrat.Setting.disable` is used\n\n    Notes\n    -----\n    If possible, avoid using the default `PickleSerializer`. This serializer is used by\n    default because it works with most objects but pickle is not a good format to store\n    the results long-term. We encourage users to select one the other serializers\n    provided or writing a custom one.\n\n    Examples\n    --------\n\n    Simple example\n\n    >>> import scrat as sc\n    >>> @sc.stash()\n    >>> def funcion():\n    >>>     return 1\n\n    Custom serializer\n\n    >>> @sc.stash(serializer=sc.JsonSerializer())\n    >>> def funcion():\n    >>>     return {\"json\": True}\n    \"\"\"\n\n    def deco(func):\n        squirrel = Squirrel(\n            hashers=hashers,\n            name=name if name is not None else func.__name__,\n            ignore_args=ignore_args,\n            hash_code=hash_code,\n            watch_functions=watch_functions,\n            watch_globals=watch_globals,\n            serializer=serializer\n            if serializer is not None\n            else get_default_serializer(func),\n            force=force,\n            disable=disable,\n            max_size=max_size,\n        )\n\n        timer = Timer()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            hash_key = squirrel.hash(args, kwargs, func)\n            if squirrel.exists(hash_key):\n                logger.info(\"Cache hit %s\", hash_key)\n                return squirrel.fetch(hash_key)\n\n            logger.info(\"Cache miss %s\", hash_key)\n            timer.start()\n            result = func(*args, **kwargs)\n            func_time = timer.end()\n\n            squirrel.stash(hash_key=hash_key, time_s=func_time, result=result)\n\n            return result\n\n        return wrapper\n\n    return deco", ""]}
{"filename": "scrat/config.py", "chunked_list": ["import os\nimport typing as T\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom pathlib import Path\n\nimport yaml\n\n\nclass DeletionMethod(Enum):\n    lru = \"lru\"\n    lfu = \"lfu\"", "\nclass DeletionMethod(Enum):\n    lru = \"lru\"\n    lfu = \"lfu\"\n\n\n@dataclass(frozen=True)\nclass Config:\n    base_path: Path\n    \"path to `.scrat` forlder\"\n    # TODO: global max_size is not enforced yet\n    max_size: T.Optional[int] = None\n    \"size limit of the stash\"\n    # TODO: global ttl is not enforced yet\n    ttl: T.Optional[int] = None\n    \"Time-to-live of objects\"\n    deletion_method: DeletionMethod = DeletionMethod.lru\n    \"Cache policy used to remove entries\"\n    force: bool = False\n    \"Forcefully re-run all functions\"\n    disable: bool = False\n    \"Forcefully re-run all functions but not store the results\"\n\n    db_file: str = \"stash.db\"\n    stash_dir: str = \"stash\"\n    config_file: str = \"config.yaml\"\n\n    @property\n    def stash_path(self) -> Path:\n        return self.base_path / self.stash_dir\n\n    @property\n    def db_path(self) -> Path:\n        return self.base_path / self.db_file\n\n    @property\n    def cache_path(self) -> Path:\n        return self.base_path / self.stash_dir\n\n    @property\n    def config_path(self) -> Path:\n        return self.base_path / self.config_file\n\n    # TODO: find a way to automatically save and load to/from yaml\n    @classmethod\n    def load(cls, base_path: T.Optional[Path] = None) -> \"Config\":\n        \"Load the config from a yaml\"\n        if base_path is None:\n            # Search '.scrat' folder starting from the CWD and walking up\n            cwd = Path(os.getcwd())\n            while not os.path.isdir(cwd / \".scrat\") and cwd.parent != cwd:\n                cwd = cwd.parent\n            if not os.path.isdir(cwd / \".scrat\"):\n                raise ValueError(\"Scrat is not initialized, did you run `scrat init`\")\n            base_path = cwd / \".scrat\"\n\n        with open(base_path / cls.config_file) as f:\n            config_dict = yaml.load(f, Loader=yaml.Loader)\n\n        return cls(\n            base_path=Path(config_dict[\"base_path\"]),\n            max_size=config_dict[\"max_size\"],\n            ttl=config_dict[\"ttl\"],\n            deletion_method=DeletionMethod(config_dict[\"deletion_method\"]),\n            force=(os.getenv(\"SCRAT_FORCE\", \"False\").lower() in (\"true\", 1)),\n            disable=(os.getenv(\"SCRAT_DISABLE\", \"False\").lower() in (\"true\", 1)),\n        )\n\n    @classmethod\n    def create_config_file(cls, base_path: Path):\n        \"Initialize the yaml with the default settings\"\n        config = cls(base_path=base_path)\n        with open(base_path / cls.config_file, \"w\") as f:\n            yaml.dump(\n                {\n                    \"base_path\": str(config.base_path.absolute()),\n                    \"max_size\": config.max_size,\n                    \"ttl\": config.ttl,\n                    \"deletion_method\": config.deletion_method.value,\n                },\n                f,\n            )\n        return config", ""]}
{"filename": "scrat/squirrel.py", "chunked_list": ["import logging\nimport os\nimport typing as T\nfrom datetime import datetime\nfrom pathlib import Path\n\nfrom sqlalchemy.sql import exists, func, select\n\nfrom scrat.db import DBConnector, Nut\n", "from scrat.db import DBConnector, Nut\n\nfrom .config import Config, DeletionMethod\nfrom .hasher import Hasher, HashManager\nfrom .serializer import Serializer\n\nlogger = logging.getLogger(__name__)\n\n\nclass Squirrel:\n    \"\"\"\n    Stash manager, in charge of fetching and storing the Nuts.\n\n    Parameters\n    ----------\n    serializer\n        Select a serializer for the function's result, by default a good\n        serializer is inferred from the typehint, using `PickleSerializer` as\n        the fallback.\n    name\n        Name that identifies this function, by default the function name is used.\n    hashers\n        Dictionary specifying hashers used for the arguments, by default hashers\n        are selected according to the type of the argument, using `ToStringHasher`\n        as the fallback.\n    hash_code\n        Control if the function's code should be used in the hash, by default True.\n    ignore_args\n        List of arguments to ignore from the hash, by default None\n    watch_functions\n        List of functions which code should be included in the hash, by default None\n    watch_globals\n        List of global variables to include in the hash, by default None\n    force\n        If set to True the stash is ignored, the function is called and the result\n        is saved to the stash, by default the global setting `scrat.Setting.force` is\n        used\n    disable\n        If set to True the stash is ignored, the function called and the result\n        is **not** saved, by default the global setting `scrat.Setting.disable` is used\n\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        serializer: Serializer,\n        hashers: T.Optional[T.Dict[str, Hasher]] = None,\n        hash_code: T.Optional[bool] = True,\n        ignore_args: T.Optional[T.List[str]] = None,\n        watch_functions: T.Optional[T.List[T.Any]] = None,\n        watch_globals: T.Optional[T.List[str]] = None,\n        force: T.Optional[bool] = None,\n        disable: T.Optional[bool] = None,\n        max_size: T.Optional[int] = None,\n    ) -> None:\n        self.config = Config.load()\n        self.name = name\n        self.force = force if force is not None else self.config.force\n        self.disable = disable if disable is not None else self.config.disable\n        self.max_size = max_size\n        self.db_connector = DBConnector(self.config.db_path)\n        self.hash_manager = HashManager(\n            hashers=hashers,\n            ignore_args=ignore_args,\n            hash_code=hash_code,\n            watch_functions=watch_functions,\n            watch_globals=watch_globals,\n        )\n        self.serializer = serializer\n\n    def hash(\n        self, args: T.List[T.Any], kwargs: T.Dict[str, T.Any], func: T.Callable\n    ) -> str:\n        \"\"\"\n        Calculate the hash for a function call.\n\n        Parameters\n        ----------\n        args\n            positional arguments.\n        kwargs\n            keyword arguments.\n        func\n            the function to be called.\n\n        Returns\n        -------\n            the hash-string resulting of combining all argument and code hashes.\n        \"\"\"\n        hash_key = self.hash_manager.hash(args=args, kwargs=kwargs, func=func)\n        logger.debug(\"Hash key for %s is '%s'\", self.name, hash_key)\n        return hash_key\n\n    def exists(self, hash_key: str) -> bool:\n        \"\"\"\n        Check if the hash exists\n\n        Parameters\n        ----------\n        hash_key\n            The hash-string calculated in `Squirrel.hash`.\n\n        Returns\n        -------\n            Whether the hash exists or not.\n        \"\"\"\n        if self.force or self.disable:\n            logger.debug(\n                \"Forcing the result or scrat is disable, not reusing the result\"\n            )\n            return False\n\n        with self.db_connector.session() as session:\n            return session.query(exists().where(Nut.hash == hash_key)).scalar()\n\n    def fetch(self, hash_key: str) -> T.Any:\n        \"\"\"\n        Fetch and recover a result from the stash.\n\n        Parameters\n        ----------\n        hash_key\n            The hash-string calculated in `Squirrel.hash`.\n\n        Returns\n        -------\n            The result loaded into memory.\n        \"\"\"\n        logger.debug(\"Fetching '%s' for %s\", hash_key, self.name)\n\n        with self.db_connector.session() as session:\n            nut = session.scalar(select(Nut).where(Nut.hash == hash_key))\n            result = self.serializer.load(Path(nut.path))\n            nut.use_count = nut.use_count + 1\n            nut.used_at = datetime.now()\n            session.commit()\n        return result\n\n    def stash(self, hash_key: str, time_s: int, result: T.Any):\n        \"\"\"\n        Stores a result.\n\n        Parameters\n        ----------\n        hash_key\n            The hash-string calculated in `Squirrel.hash`.\n        time_s\n            Execution time of the underlying function.\n        result\n            the result of the underlying function.\n        \"\"\"\n        if self.disable:\n            logger.debug(\"Scrat is disable, not saving\")\n            return\n\n        with self.db_connector.session() as session:\n            if self.max_size is not None:\n                current_size, count = (\n                    session.query(func.sum(Nut.size), func.count(Nut.hash))\n                    .filter(Nut.name == self.name)\n                    .first()\n                )\n                if count == 0:\n                    current_size = 0\n\n                while current_size >= self.max_size:\n                    logger.debug(\"Size limit hit, freeing space\")\n\n                    if self.config.deletion_method == DeletionMethod.lru:\n                        to_delete = (\n                            session.query(Nut)\n                            .filter(Nut.name == self.name)\n                            .order_by(func.ifnull(Nut.used_at, Nut.created_at))\n                            .first()\n                        )\n                        logger.info(\"Removing %s\", to_delete)\n\n                    elif self.config.deletion_method == DeletionMethod.lru:\n                        to_delete = (\n                            session.query(Nut)\n                            .filter(Nut.name == self.name)\n                            .order_by(Nut.use_count)\n                            .first()\n                        )\n                        logger.info(\"Removing %s\", to_delete)\n                    else:\n                        logger.error(\n                            \"Incorrect DeletionMethod %s\", self.config.deletion_method\n                        )\n                        break\n\n                    os.remove(to_delete.path)\n                    session.delete(to_delete)\n                    session.commit()\n                    current_size -= to_delete.size\n\n            logger.debug(\"Storing '%s' for %s\", hash_key, self.name)\n            path = self.config.cache_path / f\"{self.name}_{hash_key}\"\n            self.serializer.dump(result, path)\n            file_size = round(os.stat(path).st_size)\n\n            nut = Nut(\n                hash=hash_key,\n                name=self.name,\n                path=str(path),\n                created_at=datetime.now(),\n                used_at=None,\n                size=file_size,\n                use_count=0,\n                time_s=time_s,\n            )\n            session.add(nut)\n            session.commit()", "\nclass Squirrel:\n    \"\"\"\n    Stash manager, in charge of fetching and storing the Nuts.\n\n    Parameters\n    ----------\n    serializer\n        Select a serializer for the function's result, by default a good\n        serializer is inferred from the typehint, using `PickleSerializer` as\n        the fallback.\n    name\n        Name that identifies this function, by default the function name is used.\n    hashers\n        Dictionary specifying hashers used for the arguments, by default hashers\n        are selected according to the type of the argument, using `ToStringHasher`\n        as the fallback.\n    hash_code\n        Control if the function's code should be used in the hash, by default True.\n    ignore_args\n        List of arguments to ignore from the hash, by default None\n    watch_functions\n        List of functions which code should be included in the hash, by default None\n    watch_globals\n        List of global variables to include in the hash, by default None\n    force\n        If set to True the stash is ignored, the function is called and the result\n        is saved to the stash, by default the global setting `scrat.Setting.force` is\n        used\n    disable\n        If set to True the stash is ignored, the function called and the result\n        is **not** saved, by default the global setting `scrat.Setting.disable` is used\n\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        serializer: Serializer,\n        hashers: T.Optional[T.Dict[str, Hasher]] = None,\n        hash_code: T.Optional[bool] = True,\n        ignore_args: T.Optional[T.List[str]] = None,\n        watch_functions: T.Optional[T.List[T.Any]] = None,\n        watch_globals: T.Optional[T.List[str]] = None,\n        force: T.Optional[bool] = None,\n        disable: T.Optional[bool] = None,\n        max_size: T.Optional[int] = None,\n    ) -> None:\n        self.config = Config.load()\n        self.name = name\n        self.force = force if force is not None else self.config.force\n        self.disable = disable if disable is not None else self.config.disable\n        self.max_size = max_size\n        self.db_connector = DBConnector(self.config.db_path)\n        self.hash_manager = HashManager(\n            hashers=hashers,\n            ignore_args=ignore_args,\n            hash_code=hash_code,\n            watch_functions=watch_functions,\n            watch_globals=watch_globals,\n        )\n        self.serializer = serializer\n\n    def hash(\n        self, args: T.List[T.Any], kwargs: T.Dict[str, T.Any], func: T.Callable\n    ) -> str:\n        \"\"\"\n        Calculate the hash for a function call.\n\n        Parameters\n        ----------\n        args\n            positional arguments.\n        kwargs\n            keyword arguments.\n        func\n            the function to be called.\n\n        Returns\n        -------\n            the hash-string resulting of combining all argument and code hashes.\n        \"\"\"\n        hash_key = self.hash_manager.hash(args=args, kwargs=kwargs, func=func)\n        logger.debug(\"Hash key for %s is '%s'\", self.name, hash_key)\n        return hash_key\n\n    def exists(self, hash_key: str) -> bool:\n        \"\"\"\n        Check if the hash exists\n\n        Parameters\n        ----------\n        hash_key\n            The hash-string calculated in `Squirrel.hash`.\n\n        Returns\n        -------\n            Whether the hash exists or not.\n        \"\"\"\n        if self.force or self.disable:\n            logger.debug(\n                \"Forcing the result or scrat is disable, not reusing the result\"\n            )\n            return False\n\n        with self.db_connector.session() as session:\n            return session.query(exists().where(Nut.hash == hash_key)).scalar()\n\n    def fetch(self, hash_key: str) -> T.Any:\n        \"\"\"\n        Fetch and recover a result from the stash.\n\n        Parameters\n        ----------\n        hash_key\n            The hash-string calculated in `Squirrel.hash`.\n\n        Returns\n        -------\n            The result loaded into memory.\n        \"\"\"\n        logger.debug(\"Fetching '%s' for %s\", hash_key, self.name)\n\n        with self.db_connector.session() as session:\n            nut = session.scalar(select(Nut).where(Nut.hash == hash_key))\n            result = self.serializer.load(Path(nut.path))\n            nut.use_count = nut.use_count + 1\n            nut.used_at = datetime.now()\n            session.commit()\n        return result\n\n    def stash(self, hash_key: str, time_s: int, result: T.Any):\n        \"\"\"\n        Stores a result.\n\n        Parameters\n        ----------\n        hash_key\n            The hash-string calculated in `Squirrel.hash`.\n        time_s\n            Execution time of the underlying function.\n        result\n            the result of the underlying function.\n        \"\"\"\n        if self.disable:\n            logger.debug(\"Scrat is disable, not saving\")\n            return\n\n        with self.db_connector.session() as session:\n            if self.max_size is not None:\n                current_size, count = (\n                    session.query(func.sum(Nut.size), func.count(Nut.hash))\n                    .filter(Nut.name == self.name)\n                    .first()\n                )\n                if count == 0:\n                    current_size = 0\n\n                while current_size >= self.max_size:\n                    logger.debug(\"Size limit hit, freeing space\")\n\n                    if self.config.deletion_method == DeletionMethod.lru:\n                        to_delete = (\n                            session.query(Nut)\n                            .filter(Nut.name == self.name)\n                            .order_by(func.ifnull(Nut.used_at, Nut.created_at))\n                            .first()\n                        )\n                        logger.info(\"Removing %s\", to_delete)\n\n                    elif self.config.deletion_method == DeletionMethod.lru:\n                        to_delete = (\n                            session.query(Nut)\n                            .filter(Nut.name == self.name)\n                            .order_by(Nut.use_count)\n                            .first()\n                        )\n                        logger.info(\"Removing %s\", to_delete)\n                    else:\n                        logger.error(\n                            \"Incorrect DeletionMethod %s\", self.config.deletion_method\n                        )\n                        break\n\n                    os.remove(to_delete.path)\n                    session.delete(to_delete)\n                    session.commit()\n                    current_size -= to_delete.size\n\n            logger.debug(\"Storing '%s' for %s\", hash_key, self.name)\n            path = self.config.cache_path / f\"{self.name}_{hash_key}\"\n            self.serializer.dump(result, path)\n            file_size = round(os.stat(path).st_size)\n\n            nut = Nut(\n                hash=hash_key,\n                name=self.name,\n                path=str(path),\n                created_at=datetime.now(),\n                used_at=None,\n                size=file_size,\n                use_count=0,\n                time_s=time_s,\n            )\n            session.add(nut)\n            session.commit()", ""]}
{"filename": "scrat/__init__.py", "chunked_list": ["\"Scrat Library\"\nfrom .config import Config  # noqa: F401\nfrom .decorator import stash  # noqa: F401\nfrom .hasher import *  # noqa: F401, F403\nfrom .serializer import *  # noqa: F401, F403\nfrom .squirrel import Squirrel  # noqa: F401\n\n__all__ = [\"stash\"]\n", ""]}
{"filename": "scrat/serializer/base.py", "chunked_list": ["import typing as T\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\n\n\nclass Serializer(ABC):\n    \"\"\"\n    Abstract class from which all Serializer inherit from.\n    \"\"\"\n\n    @abstractmethod\n    def dump(self, obj: T.Any, path: Path):\n        \"\"\"\n        Save an object to disk.\n\n        Parameters\n        ----------\n        obj\n            The result to save.\n        path\n            The target location in the filesystem.\n        \"\"\"\n        return NotImplemented\n\n    @abstractmethod\n    def load(self, path: Path) -> T.Any:\n        \"\"\"\n        Load a saved object from disk.\n\n        Parameters\n        ----------\n        path\n            Location of the stored result.\n\n        Returns\n        -------\n            The object loaded into memory.\n        \"\"\"\n        return NotImplemented", ""]}
{"filename": "scrat/serializer/dill.py", "chunked_list": ["import typing as T\nfrom pathlib import Path\n\n\nclass DillSerializer:\n    \"\"\"\n    Serializer using dill.\n\n    In order to use this Serializer dill needs to be installed.\n\n    Parameters\n    ----------\n    dump_kwargs\n        extra arguments for dill.dump, by default None\n    load_kwargs\n        extra arguments for dill.load, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        dump_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n        load_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n    ) -> None:\n        # test that dill is installed\n        import dill  # noqa: F401\n\n        self.dump_kwargs = dump_kwargs if dump_kwargs is not None else {}\n        self.load_kwargs = load_kwargs if load_kwargs is not None else {}\n\n    def dump(self, obj: T.Any, path: Path):\n        import dill\n\n        with open(path, \"wb\") as f:\n            dill.dump(obj, f, **self.dump_kwargs)\n\n    def load(self, path: Path) -> T.Any:\n        import dill\n\n        with open(path, \"rb\") as f:\n            return dill.load(f, **self.load_kwargs)", ""]}
{"filename": "scrat/serializer/pickle.py", "chunked_list": ["import pickle\nimport typing as T\nfrom pathlib import Path\n\n\nclass PickleSerializer:\n    \"\"\"\n    Pickle serializer.\n\n    Parameters\n    ----------\n    dump_kwargs\n        Extra arguments for pickle.dump, by default None\n    load_kwargs\n        Extra arguments for pickle.load, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        dump_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n        load_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n    ) -> None:\n        self.dump_kwargs = dump_kwargs if dump_kwargs is not None else {}\n        self.load_kwargs = load_kwargs if load_kwargs is not None else {}\n\n    def dump(self, obj: T.Any, path: Path):\n        with open(path, \"wb\") as f:\n            pickle.dump(obj, f, **self.dump_kwargs)\n\n    def load(self, path: Path) -> T.Any:\n        with open(path, \"rb\") as f:\n            return pickle.load(f, **self.load_kwargs)", ""]}
{"filename": "scrat/serializer/pandas.py", "chunked_list": ["import typing as T\nfrom enum import Enum\nfrom pathlib import Path\n\nif T.TYPE_CHECKING:\n    import pandas as pd\n\n\nclass Format(Enum):\n    parquet = \"parquet\"\n    hdf5 = \"hdf5\"\n    feather = \"feather\"\n    orc = \"orc\"\n    excel = \"excel\"\n    csv = \"csv\"\n    pickle = \"pickle\"\n    json = \"json\"\n    stata = \"stata\"", "class Format(Enum):\n    parquet = \"parquet\"\n    hdf5 = \"hdf5\"\n    feather = \"feather\"\n    orc = \"orc\"\n    excel = \"excel\"\n    csv = \"csv\"\n    pickle = \"pickle\"\n    json = \"json\"\n    stata = \"stata\"", "\n\nclass PandasSerializer:\n    \"\"\"\n    Serializer for Pandas Series and DataFrames.\n\n    In order to use this Serializer pandas needs to be installed,\n    some formats might need aditional libraries.\n\n    Parameters\n    ----------\n    format\n        Serialization method from the ones supported by pandas,\n        by default Format.parquet\n    to_kwargs\n        Extra arguments for the corresponding pandas.read_<format> function,\n        by default None\n    read_kwargs\n        Extra arguments for the corresponding pandas.to_<format> function,\n        by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        format: T.Union[str, Format] = Format.parquet,\n        to_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n        read_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n    ) -> None:\n        # test that pandas is installed\n        import pandas  # noqa: F401\n\n        self.format = format if isinstance(format, Format) else Format(format)\n\n        self.to_kwargs = to_kwargs if to_kwargs is not None else {}\n        self.read_kwargs = read_kwargs if read_kwargs is not None else {}\n\n    def dump(self, obj: \"pd.DataFrame\", path: Path):\n        to_method = getattr(obj, f\"to_{self.format.value}\")\n        to_method(path, **self.to_kwargs)\n\n    def load(self, path: Path) -> \"pd.DataFrame\":\n        import pandas\n\n        read_method = getattr(pandas, f\"read_{self.format.value}\")\n        return read_method(path, **self.read_kwargs)", ""]}
{"filename": "scrat/serializer/__init__.py", "chunked_list": ["\"Module containing all Serializers\"\nimport typing as T\n\nfrom .base import Serializer\nfrom .dill import DillSerializer  # noqa: F401\nfrom .json import JsonSerializer  # noqa: F401\nfrom .numpy import NumpySerializer\nfrom .pandas import PandasSerializer\nfrom .pickle import PickleSerializer\n", "from .pickle import PickleSerializer\n\nDEFAULT_SERIALIZERS = {\n    \"DataFrame\": PandasSerializer,\n    \"Series\": PandasSerializer,\n    \"ndarray\": NumpySerializer,\n}\n\n\ndef get_default_serializer(func: T.Callable) -> Serializer:\n    \"\"\"\n    Try to find a sane serializer using the function's typehint.\n\n    Defaults to `PickleSerializer`\n\n    Parameters\n    ----------\n    func\n        The user function to be called\n\n    Returns\n    -------\n        An instance of the chosen Serializer\n    \"\"\"\n    import inspect\n\n    sign = inspect.signature(func)\n    if hasattr(sign, \"return_annotations\"):\n        return DEFAULT_SERIALIZERS.get(\n            sign.return_annotation.__name__, PickleSerializer\n        )()\n\n    return PickleSerializer()", "\ndef get_default_serializer(func: T.Callable) -> Serializer:\n    \"\"\"\n    Try to find a sane serializer using the function's typehint.\n\n    Defaults to `PickleSerializer`\n\n    Parameters\n    ----------\n    func\n        The user function to be called\n\n    Returns\n    -------\n        An instance of the chosen Serializer\n    \"\"\"\n    import inspect\n\n    sign = inspect.signature(func)\n    if hasattr(sign, \"return_annotations\"):\n        return DEFAULT_SERIALIZERS.get(\n            sign.return_annotation.__name__, PickleSerializer\n        )()\n\n    return PickleSerializer()", "\n\n__all__ = [\n    \"Serializer\",\n    \"PickleSerializer\",\n    \"DillSerializer\",\n    \"JsonSerializer\",\n    \"NumpySerializer\",\n    \"PandasSerializer\",\n]", "    \"PandasSerializer\",\n]\n"]}
{"filename": "scrat/serializer/numpy.py", "chunked_list": ["import typing as T\nfrom pathlib import Path\n\nif T.TYPE_CHECKING:\n    import numpy as np\n\n\nclass NumpySerializer:\n    \"\"\"\n    Serializer for numpy arrays.\n\n    In order to use this Serializer numpy needs to be installed.\n\n\n    Parameters\n    ----------\n    save_kwargs\n        Extra arguments for numpy.save, by default None\n    load_kwargs\n        Extra arguments for numpy.load, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        save_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n        load_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n    ) -> None:\n        # test that numpy is installed\n        import numpy  # noqa: F401\n\n        self.save_kwargs = save_kwargs if save_kwargs is not None else {}\n        self.load_kwargs = load_kwargs if load_kwargs is not None else {}\n\n    def dump(self, obj: \"np.ndarray\", path: Path):\n        import numpy\n\n        numpy.save(path, obj, **self.save_kwargs)\n        obj.save(path)\n\n    def load(self, path: Path) -> \"np.ndarray\":\n        import numpy\n\n        return numpy.load(path, **self.load_kwargs)", ""]}
{"filename": "scrat/serializer/json.py", "chunked_list": ["import json\nimport typing as T\nfrom pathlib import Path\n\n\nclass JsonSerializer:\n    \"\"\"\n    Serializer that uses json from the python standard library.\n\n    Parameters\n    ----------\n    dump_kwargs\n        Extra arguments for json.dump, by default None\n    load_kwargs\n        Extra arguments for json.load, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        dump_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n        load_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n    ) -> None:\n        self.dump_kwargs = dump_kwargs if dump_kwargs is not None else {}\n        self.load_kwargs = load_kwargs if load_kwargs is not None else {}\n\n    def dump(self, obj: T.Any, path: Path):\n        with open(path, \"w\") as f:\n            json.dump(obj, f, **self.dump_kwargs)\n\n    def load(self, path: Path) -> T.Any:\n        with open(path, \"r\") as f:\n            return json.load(f, **self.load_kwargs)", ""]}
{"filename": "scrat/cli/setup.py", "chunked_list": ["import os\nfrom pathlib import Path\n\nimport click\n\nfrom scrat import Config\nfrom scrat.db import DBConnector\n\n\ndef _make_config(path) -> Config:\n    return Config.create_config_file(base_path=path)", "\ndef _make_config(path) -> Config:\n    return Config.create_config_file(base_path=path)\n\n\ndef _make_db(path):\n    DBConnector.create_db(path=path)\n\n\n@click.command()\ndef init():\n    \"\"\"Initialize Scrat's stash\"\"\"\n    cwd = Path(os.getcwd())\n    folder = cwd / \".scrat\"\n\n    if os.path.exists(folder):\n        click.secho(\"already initialized\", fg=\"red\")\n        exit(-1)\n\n    os.mkdir(folder)\n    config = _make_config(folder)\n    _make_db(config.db_path)\n    os.mkdir(config.stash_path)\n\n    if os.path.exists(cwd / \".git\"):\n        with open(folder / \".gitignore\", \"w\") as f:\n            f.write(f\"{config.stash_dir}\\n{config.db_file}\\n{config.config_file}\\n\")", "\n@click.command()\ndef init():\n    \"\"\"Initialize Scrat's stash\"\"\"\n    cwd = Path(os.getcwd())\n    folder = cwd / \".scrat\"\n\n    if os.path.exists(folder):\n        click.secho(\"already initialized\", fg=\"red\")\n        exit(-1)\n\n    os.mkdir(folder)\n    config = _make_config(folder)\n    _make_db(config.db_path)\n    os.mkdir(config.stash_path)\n\n    if os.path.exists(cwd / \".git\"):\n        with open(folder / \".gitignore\", \"w\") as f:\n            f.write(f\"{config.stash_dir}\\n{config.db_file}\\n{config.config_file}\\n\")", "\n\n@click.command()\ndef deinit():\n    \"\"\"Remove Scrat's stash\"\"\"\n    import shutil\n\n    cwd = Path(os.getcwd())\n    folder = cwd / \".scrat\"\n\n    if not os.path.exists(folder):\n        click.secho(\"not initialized\", fg=\"red\")\n        exit(-1)\n    click.confirm(\n        \"This will remove everything from the stash are you sure?\", abort=True\n    )\n    shutil.rmtree(folder)\n    click.secho(\"Scrat was deinitialized correctly\")", "\n\nif __name__ == \"__main__\":\n    init()\n"]}
{"filename": "scrat/cli/stash.py", "chunked_list": ["import os\nfrom datetime import timedelta\n\nimport click\nfrom sqlalchemy.sql import exists, select\n\nfrom scrat.config import Config\nfrom scrat.db import DBConnector, Nut\nfrom scrat.utils import humanize_size\n", "from scrat.utils import humanize_size\n\n\n@click.group()\ndef stash():\n    pass\n\n\nCOLUMNS = [\n    \"hash\",", "COLUMNS = [\n    \"hash\",\n    \"name\",\n    \"path\",\n    \"created_at\",\n    \"used_at\",\n    \"size_mb\",\n    \"use_count\",\n    \"time_s\",\n]", "    \"time_s\",\n]\n\n\ndef format_datetime(datetime):\n    if datetime is not None:\n        return datetime.isoformat(timespec=\"minutes\", sep=\" \")\n    return \"\"\n\n", "\n\n@stash.command()\n@click.option(\n    \"-s\",\n    \"--sort-by\",\n    type=click.Choice(COLUMNS),\n    default=\"created_at\",\n    help=\"Column to sort by\",\n)", "    help=\"Column to sort by\",\n)\n@click.option(\n    \"-d\", \"--desc\", default=False, is_flag=True, help=\"Use to sort descending\"\n)\ndef list(sort_by, desc):\n    \"\"\"List content of stash\"\"\"\n    config = Config.load()\n    db_connector = DBConnector(config.db_path)\n    with db_connector.session() as session:\n        sorting = getattr(Nut, sort_by)\n        if desc:\n            sorting = sorting.desc()\n        click.secho(f\"{'name':<15} {'hash':<32} {'created_at':<16} {'size':5}\")\n\n        for nut in session.query(Nut).order_by(sorting).all():\n            click.secho(\n                (\n                    f\"{nut.name if len(nut.name) <= 15 else nut.name[:13] + '..' :<15} \"\n                    f\"{nut.hash} \"\n                    f\"{format_datetime(nut.created_at)} \"\n                    f\"{humanize_size(nut.size)}\"\n                )\n            )", "\n\n@stash.command()\n@click.argument(\"hash_key\")\ndef delete(hash_key):\n    \"\"\"Removes one nut from the stash\"\"\"\n    config = Config.load()\n    db_connector = DBConnector(config.db_path)\n    with db_connector.session() as session:\n        nut = session.scalar(select(Nut).where(Nut.hash == hash_key))\n        if nut is None:\n            click.secho(\"Nut does not exists\", fg=\"red\")\n            exit(-1)\n        try:\n            os.remove(nut.path)\n        except FileNotFoundError:\n            pass\n        session.query(Nut).filter_by(hash=hash_key).delete()\n        session.commit()", "\n\n@stash.command()\ndef clear():\n    \"\"\"Empty the stash\"\"\"\n    config = Config.load()\n    click.confirm(\n        \"This will remove everything from the stash are you sure?\", abort=True\n    )\n    try:\n        os.remove(config.db_path)\n    except FileNotFoundError:\n        click.secho(\"DB not found\")\n    for file in os.listdir(config.cache_path):\n        os.remove(config.cache_path / file)", "\n\n@stash.command()\ndef stats():\n    \"\"\"Print stash stats\"\"\"\n    config = Config.load()\n    db_connector = DBConnector(config.db_path)\n    seconds_saved = 0\n    size = 0\n    entries = 0\n    with db_connector.session() as session:\n        for nut in session.query(Nut).all():\n            seconds_saved += nut.use_count * nut.time_s\n            size += nut.size\n            entries += 1\n\n    click.secho(f\"Total entries: {entries}\")\n    if entries == 0:\n        return\n\n    click.secho(f\"Total size: {humanize_size(size)}\")\n\n    if seconds_saved > 0:\n        click.secho(f\"time saved: {timedelta(seconds=seconds_saved)}\")", "\n\n@stash.command()\ndef check():\n    \"\"\"Check the integrity of the stash\"\"\"\n    config = Config.load()\n    db_connector = DBConnector(config.db_path)\n    with db_connector.session() as session:\n        for nut in session.query(Nut).all():\n            if not os.path.exists(nut.path):\n                click.secho(f\"Missing file '{nut.hash}'\")\n        for file in os.listdir(config.cache_path):\n            if not session.query(exists().where(Nut.hash == file)).scalar():\n                click.secho(f\"File not indexed: '{file}'\")", "\n\nif __name__ == \"__main__\":\n    stash()\n"]}
{"filename": "scrat/cli/__init__.py", "chunked_list": ["\"Scrat CLI\"\nimport click\n\nfrom .setup import deinit, init\nfrom .stash import stash\n\n\n@click.group()\ndef scrat():\n    pass", "def scrat():\n    pass\n\n\nscrat.add_command(init)\nscrat.add_command(deinit)\nscrat.add_command(stash)\n\nif __name__ == \"__main__\":\n    scrat()", "if __name__ == \"__main__\":\n    scrat()\n"]}
{"filename": "scrat/utils/__init__.py", "chunked_list": ["import typing as T\nfrom pathlib import Path\n\nfrom .timer import Timer  # noqa\n\nPathLike = T.Union[str, Path]\n\n\n_SUFFIXES = list(reversed(list(enumerate([\"B\", \"KB\", \"MB\", \"GB\"]))))\n", "_SUFFIXES = list(reversed(list(enumerate([\"B\", \"KB\", \"MB\", \"GB\"]))))\n\n\ndef humanize_size(size: int) -> str:\n    \"Format file size in bytes into a human-readable string\"\n    base = 1024\n    for exp, suffix in _SUFFIXES:\n        if size >= base**exp:\n            return f\"{size/base**exp:.1f}{suffix}\"\n    raise ValueError(\"could not format int %s\", int)", ""]}
{"filename": "scrat/utils/timer.py", "chunked_list": ["import time\n\n\nclass Timer:\n    \"Simple timer.\"\n\n    def __init__(self) -> None:\n        self._start_time = None\n\n    def start(self):\n        self._start_time = time.time()\n\n    def end(self) -> float:\n        try:\n            delta = time.time() - self._start_time\n        except TypeError:\n            raise RuntimeError(\"Trying to stop a timer that has not been started\")\n        self._start_time = None\n        return delta", ""]}
{"filename": "scrat/db/models.py", "chunked_list": ["import typing as T\nfrom datetime import datetime\n\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n\n\nclass Base(DeclarativeBase):\n    pass\n\n\nclass Nut(Base):\n    \"\"\"Represents an entry to the stash database\"\"\"\n\n    __tablename__ = \"nut\"\n\n    # TODO: hash should not be the PK because it could be repeated with a different name\n    hash: Mapped[str] = mapped_column(primary_key=True)\n    \"Resulting hash for this result\"\n    name: Mapped[str]\n    \"Name of the function that produced this result\"\n    path: Mapped[str]\n    \"Path where the result is stored\"\n\n    created_at: Mapped[datetime]\n    \"DateTime when the result was produced\"\n    used_at: Mapped[T.Optional[datetime]]\n    \"DateTime when the result was last used\"\n    size: Mapped[int]\n    \"Size of the store file, in bytes\"\n    use_count: Mapped[int]\n    \"Count of how many times the result was used\"\n    time_s: Mapped[int]\n    \"Execution time of the function, in seconds\"\n\n    def __repr__(self) -> str:\n        return f\"Nut(name={self.name!r}, hash={self.hash!r})\"", "\n\nclass Nut(Base):\n    \"\"\"Represents an entry to the stash database\"\"\"\n\n    __tablename__ = \"nut\"\n\n    # TODO: hash should not be the PK because it could be repeated with a different name\n    hash: Mapped[str] = mapped_column(primary_key=True)\n    \"Resulting hash for this result\"\n    name: Mapped[str]\n    \"Name of the function that produced this result\"\n    path: Mapped[str]\n    \"Path where the result is stored\"\n\n    created_at: Mapped[datetime]\n    \"DateTime when the result was produced\"\n    used_at: Mapped[T.Optional[datetime]]\n    \"DateTime when the result was last used\"\n    size: Mapped[int]\n    \"Size of the store file, in bytes\"\n    use_count: Mapped[int]\n    \"Count of how many times the result was used\"\n    time_s: Mapped[int]\n    \"Execution time of the function, in seconds\"\n\n    def __repr__(self) -> str:\n        return f\"Nut(name={self.name!r}, hash={self.hash!r})\"", ""]}
{"filename": "scrat/db/__init__.py", "chunked_list": ["\"Module that contains the SQLAlchemy models and the connection to the database\"\nfrom .connector import DBConnector  # noqa\nfrom .models import Nut  # noqa\n"]}
{"filename": "scrat/db/connector.py", "chunked_list": ["from sqlalchemy import create_engine\nfrom sqlalchemy.orm import Session, sessionmaker\n\nfrom scrat.utils import PathLike\n\nfrom .models import Base\n\n\nclass DBConnector:\n    \"\"\"\n    Wrapper to handle the connection to sqlite.\n\n    Parameters\n    ----------\n    path\n        Path to the sqlite file.\n    \"\"\"\n\n    def __init__(self, path: PathLike) -> None:\n        self.engine = create_engine(\"sqlite:///\" + str(path))\n        Base.metadata.create_all(self.engine)\n        self.session_maker = sessionmaker(self.engine)\n\n    @classmethod\n    def create_db(cls, path: PathLike):\n        \"\"\"\n        Initialize the database.\n\n        Parameters\n        ----------\n        path\n            Path to the sqlite file.\n        \"\"\"\n        engine = create_engine(\"sqlite:///\" + str(path))\n        Base.metadata.create_all(engine)\n\n    def session(self) -> Session:\n        \"\"\"\n        Create a session\n\n        Returns\n        -------\n            SQLAlchemy's session\n        \"\"\"\n        return self.session_maker()", "class DBConnector:\n    \"\"\"\n    Wrapper to handle the connection to sqlite.\n\n    Parameters\n    ----------\n    path\n        Path to the sqlite file.\n    \"\"\"\n\n    def __init__(self, path: PathLike) -> None:\n        self.engine = create_engine(\"sqlite:///\" + str(path))\n        Base.metadata.create_all(self.engine)\n        self.session_maker = sessionmaker(self.engine)\n\n    @classmethod\n    def create_db(cls, path: PathLike):\n        \"\"\"\n        Initialize the database.\n\n        Parameters\n        ----------\n        path\n            Path to the sqlite file.\n        \"\"\"\n        engine = create_engine(\"sqlite:///\" + str(path))\n        Base.metadata.create_all(engine)\n\n    def session(self) -> Session:\n        \"\"\"\n        Create a session\n\n        Returns\n        -------\n            SQLAlchemy's session\n        \"\"\"\n        return self.session_maker()", ""]}
{"filename": "scrat/hasher/manager.py", "chunked_list": ["import inspect\nimport logging\nimport typing as T\nfrom collections import OrderedDict\n\nfrom .base import Hasher\nfrom .iterable import IterableHasher\nfrom .numpy import NumpyHasher\nfrom .pandas import PandasHasher\nfrom .to_string import ToStringHasher", "from .pandas import PandasHasher\nfrom .to_string import ToStringHasher\n\nlogger = logging.getLogger(__name__)\n\n\nFALLBACK = ToStringHasher()\nDEFAULTS: T.Dict[T.Any, Hasher] = OrderedDict()\ntry:\n    import numpy as np\n\n    DEFAULTS[np.ndarray] = NumpyHasher()\nexcept ImportError:\n    logger.debug(\"numpy not installed, NumpyHasher disabled\")", "try:\n    import numpy as np\n\n    DEFAULTS[np.ndarray] = NumpyHasher()\nexcept ImportError:\n    logger.debug(\"numpy not installed, NumpyHasher disabled\")\ntry:\n    import pandas as pd\n\n    DEFAULTS[pd.DataFrame] = PandasHasher()\n    DEFAULTS[pd.Series] = PandasHasher()\nexcept ImportError:\n    logger.debug(\"pandas not installed, NumpyHasher disabled\")", "\nDEFAULTS[list] = IterableHasher(FALLBACK)\nDEFAULTS[tuple] = IterableHasher(FALLBACK)\n\n\nclass HashManager:\n    \"\"\"\n    Coordinate the hashing of the arguments, code, etc\n\n    Parameters\n    ----------\n    hashers\n        Dictionary to override the Hasher used for certain arguments,\n        by default None\n    hash_code\n        If True the function's code is included in the hash, by default True\n    ignore_args\n        List of argument names to be ignored, by default None\n    watch_functions\n        Extra functions to include in the hash, by default None\n    watch_globals\n        Global variables to include in the hash, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        hashers: T.Optional[T.Dict[str, Hasher]] = None,\n        hash_code: T.Optional[bool] = True,\n        ignore_args: T.Optional[T.List[str]] = None,\n        watch_functions: T.Optional[T.List[T.Any]] = None,\n        watch_globals: T.Optional[T.List[str]] = None,\n    ) -> None:\n        # TODO: enforce unique names?\n        self.hash_code = hash_code\n        self.hashers = hashers if hashers is not None else {}\n        self.ignore_args = set(ignore_args if ignore_args is not None else [])\n        self.watch_functions = watch_functions if watch_functions is not None else []\n        self.watch_globals = watch_globals if watch_globals is not None else []\n\n    def hash(\n        self, args: T.List[T.Any], kwargs: T.Dict[str, T.Any], func: T.Callable\n    ) -> str:\n        \"\"\"\n        Calculate the hash for a function call.\n\n        Parameters\n        ----------\n        args\n            positional arguments.\n        kwargs\n            keyword arguments.\n        func\n            the function to be called.\n\n        Returns\n        -------\n            the hash-string resulting of combining all argument and code hashes.\n        \"\"\"\n        #\n        # hash arguments\n        #\n        hashed_args = []\n        for arg_name, arg_value in self._normalize_args(args, kwargs, func).items():\n            hashed_args.append(self.hash_argument(arg_name, arg_value))\n        hash_result = Hasher.md5_hash(*hashed_args)\n\n        #\n        # hash funcion's code if necessary\n        #\n        if self.hash_code:\n            hashed_code = self._hash_code(func)\n            hash_result = Hasher.md5_hash(hash_result, hashed_code)\n\n        #\n        # hash the code of any other watched function\n        #\n        if len(self.watch_functions):\n            hash_result = Hasher.md5_hash(\n                hash_result, *[self._hash_code(f) for f in self.watch_functions]\n            )\n\n        #\n        # hash any other watched global variable\n        #\n        if len(self.watch_globals):\n            closure = inspect.getclosurevars(func)\n            global_vars = closure.globals.copy()\n            global_vars.update(closure.nonlocals)\n            globals_hash = []\n            for global_name in self.watch_globals:\n                gloval_value = global_vars[global_name]\n                globals_hash.append(self.hash_argument(global_name, gloval_value))\n\n            hash_result = Hasher.md5_hash(hash_result, *globals_hash)\n\n        return hash_result\n\n    def hash_argument(self, name: str, value: T.Any) -> str:\n        \"\"\"\n        Generate the hash for a single argument.\n\n        Parameters\n        ----------\n        name\n            argument name normalized.\n        value\n            argument value.\n\n        Returns\n        -------\n            the hash-string corresponding to this argument.\n        \"\"\"\n        hasher = self._get_hasher(name, value)\n        logger.debug(\"using '%s' for argument '%s'\", hasher.__class__.__name__, name)\n        hashed_value = hasher.hash(value)\n        return Hasher.md5_hash(name, hashed_value, type(value).__name__)\n\n    def _get_hasher(self, arg_name: str, arg: T.Any) -> Hasher:\n        if arg_name in self.hashers:\n            return self.hashers[arg_name]\n        for cls, hasher in DEFAULTS.items():\n            if isinstance(arg, cls):\n                return hasher\n        return FALLBACK\n\n    def _hash_code(self, func) -> str:\n        return Hasher.md5_hash(inspect.getsource(func).encode())\n\n    def _normalize_args(\n        self, args: T.List[T.Any], kwargs: T.Dict[str, T.Any], func: T.Callable\n    ) -> T.Dict[str, T.Any]:\n        \"\"\"\n        Normalize args and kwargs.\n\n        The same function can be called with the same arguments but changing which\n        are passed by position (args) and which are passed by name (kwargs),\n        this function aims to normalize all those different forms of calling into a\n        single form that corresponds to call the function passing all arguments by name,\n        in the order they appear in the function's signature.\n\n        Parameters\n        ----------\n        args\n            positional arguments\n        kwargs\n            named or keyword arguments\n        func\n            function to be called\n\n        Returns\n        -------\n            keyword mapping\n\n        Examples\n        --------\n        >>> from scrat.hasher import HashManager\n        >>> manager = HashManager()\n        >>> def f(a, b):\n        >>>     pass\n        >>> manager._normalize_args(args=[1, 2], kwargs={}, func=f)\n        OrderedDict([('a', 1), ('b', 2)])\n        >>> manager._normalize_args(args=[1], kwargs={\"b\":2}, func=f)\n        OrderedDict([('a', 1), ('b', 2)])\n        >>> manager._normalize_args(args=[], kwargs={\"b\":2, \"a\":1}, func=f)\n        OrderedDict([('a', 1), ('b', 2)])\n        \"\"\"\n        args = list(args)\n        normalized_args = OrderedDict()\n\n        sign = inspect.signature(func)\n\n        for arg_name, param in sign.parameters.items():\n            if param.kind == param.POSITIONAL_ONLY:\n                # NOTE: Value must be supplied as a positional argument.\n                #       Python has no explicit syntax for defining positional-only\n                #       parameters, but many built-in and extension module functions\n                #       (especially those that accept only one or two parameters)\n                #       accept them.\n                normalized_args[arg_name] = args.pop(0)\n            elif param.kind == param.POSITIONAL_OR_KEYWORD:\n                # NOTE: Value may be supplied as either a keyword or positional\n                #       argument. This is the standard binding behaviour for functions\n                #       implemented in Python.\n                if arg_name in kwargs:\n                    normalized_args[arg_name] = kwargs[arg_name]\n                elif len(args) > 0:\n                    normalized_args[arg_name] = args.pop(0)\n                else:\n                    normalized_args[arg_name] = param.default\n\n            elif param.kind == param.VAR_POSITIONAL:\n                # NOTE: A tuple of positional arguments that aren\u2019t bound to any other\n                #       parameter. This corresponds to a *args parameter in a Python\n                #       function definition.\n\n                # consume all remainder args\n                for i, arg in enumerate(args):\n                    normalized_args[f\"*{i}\"] = arg\n                args = []\n            elif param.kind == param.KEYWORD_ONLY:\n                # NOTE: Value must be supplied as a keyword argument.\n                #       Keyword only parameters are those which appear after a * or\n                #       *args nut in a Python function definition.\n\n                # If the param is keyword only then it must be passed as a kwarg,\n                # however we are not enforncing it here so that we don't fail and\n                # instead the user gets the normal python error\n                normalized_args[arg_name] = kwargs.get(arg_name)\n            if param.kind == param.VAR_KEYWORD:\n                # NOTE: A dict of keyword arguments that aren\u2019t bound to any other\n                #       parameter.  This corresponds to a **kwargs parameter in a\n                #       Python function definition.\n\n                # consume all remainder kwargs\n                for arg_name, arg in kwargs.items():\n                    normalized_args[f\"**{arg_name}\"] = arg\n                kwargs = {}\n        return normalized_args", ""]}
{"filename": "scrat/hasher/base.py", "chunked_list": ["import hashlib\nimport typing as T\nfrom abc import ABC, abstractmethod\n\n\nclass Hasher(ABC):\n    \"Abstract class from which all Hashers inherit from\"\n\n    @abstractmethod\n    def hash(self, value: T.Any) -> str:\n        \"\"\"Calculate the hash-string corresponding to a value\n\n        Parameters\n        ----------\n        value\n            The argument value\n\n        Returns\n        -------\n            The hash-string\n        \"\"\"\n        return NotImplemented\n\n    @classmethod\n    def md5_hash(cls, *args) -> str:\n        \"\"\"\n        Generate the hash for strings and bytes using md5\n\n        Returns\n        -------\n            the resulting hexdigest\n        \"\"\"\n        h = hashlib.md5()\n        for value in args:\n            if isinstance(value, str):\n                value = value.encode()\n            h.update(value)\n        return h.hexdigest()", ""]}
{"filename": "scrat/hasher/iterable.py", "chunked_list": ["import logging\nimport typing as T\n\nfrom .base import Hasher\n\nlogger = logging.getLogger(__name__)\n\n\nclass IterableHasher(Hasher):\n    \"\"\"\n    Apply one Hasher to each element of a iterable\n\n    Parameters\n    ----------\n    item_hasher\n        A Hasher to hash each value in the iterable\n\n    Examples\n    --------\n    >>> import scrat as sc\n    >>> import numpy as np\n    >>> hasher = sc.IterableHasher(sc.NumpyHasher())\n    >>> hasher.hash([np.zeros(5), np.ones(3)])\n    'f86f4d4c12a426ce5d54d715723584be'\n    \"\"\"\n\n    def __init__(self, item_hasher: Hasher) -> None:\n        super().__init__()\n        self.item_hasher = item_hasher\n\n    def hash(self, value: T.Iterable) -> str:\n        return self.md5_hash(*[self.item_hasher.hash(x) for x in value])", "class IterableHasher(Hasher):\n    \"\"\"\n    Apply one Hasher to each element of a iterable\n\n    Parameters\n    ----------\n    item_hasher\n        A Hasher to hash each value in the iterable\n\n    Examples\n    --------\n    >>> import scrat as sc\n    >>> import numpy as np\n    >>> hasher = sc.IterableHasher(sc.NumpyHasher())\n    >>> hasher.hash([np.zeros(5), np.ones(3)])\n    'f86f4d4c12a426ce5d54d715723584be'\n    \"\"\"\n\n    def __init__(self, item_hasher: Hasher) -> None:\n        super().__init__()\n        self.item_hasher = item_hasher\n\n    def hash(self, value: T.Iterable) -> str:\n        return self.md5_hash(*[self.item_hasher.hash(x) for x in value])", ""]}
{"filename": "scrat/hasher/pandas.py", "chunked_list": ["import typing as T\n\nfrom .base import Hasher\n\n\nclass PandasHasher(Hasher):\n    \"\"\"\n    Hasher for Pandas Series and DataFrames\n\n    Parameters\n    ----------\n    use_values\n        If False, only the index of the dataframe is included in the hash\n        This can help with the speed of the hasher on big dataframes where\n        you only care what rows are included but you know the values\n        don't change, by default True\n    \"\"\"\n\n    def __init__(self, use_values: bool = True) -> None:\n        super().__init__()\n        self.use_values = use_values\n\n    def hash(self, value: T.Any) -> str:\n        if self.use_values:\n            return self.md5_hash(value.index.values, value.values)\n        return self.md5_hash(value.index.values)", ""]}
{"filename": "scrat/hasher/__init__.py", "chunked_list": ["\"Module containing all Hashers\"\nfrom .base import Hasher  # noqa: F401\nfrom .iterable import IterableHasher  # noqa: F401\nfrom .manager import HashManager  # noqa: F401\nfrom .numpy import NumpyHasher  # noqa: F401\nfrom .pandas import PandasHasher  # noqa: F401\nfrom .to_string import ToStringHasher  # noqa: F401\n\n__all__ = [\"NumpyHasher\", \"PandasHasher\", \"ToStringHasher\", \"IterableHasher\", \"Hasher\"]\n", "__all__ = [\"NumpyHasher\", \"PandasHasher\", \"ToStringHasher\", \"IterableHasher\", \"Hasher\"]\n"]}
{"filename": "scrat/hasher/numpy.py", "chunked_list": ["import typing as T\n\nfrom .base import Hasher\n\n\nclass NumpyHasher(Hasher):\n    \"Hasher for numpy arrays\"\n\n    def hash(self, value: T.Any) -> str:\n        return self.md5_hash(value)", ""]}
{"filename": "scrat/hasher/to_string.py", "chunked_list": ["import typing as T\n\nfrom .base import Hasher\n\n\nclass ToStringHasher(Hasher):\n    \"Naive hasher that tries to conver the value to str and then hash it\"\n\n    def hash(self, value: T.Any) -> str:\n        return self.md5_hash(str(value))", ""]}
