{"filename": "training_pipeline/kubeflow_runner.py", "chunked_list": ["from absl import logging\n\nfrom tfx import v1 as tfx\nfrom tfx.orchestration.kubeflow.v2 import kubeflow_v2_dag_runner as runner\nfrom tfx.proto import tuner_pb2\n\nfrom pipeline import configs\nfrom pipeline import kubeflow_pipeline\n\n\ndef run():\n    runner_config = runner.KubeflowV2DagRunnerConfig(\n        default_image=configs.PIPELINE_IMAGE\n    )\n\n    runner.KubeflowV2DagRunner(\n        config=runner_config,\n        output_filename=configs.PIPELINE_NAME + \"_pipeline.json\",\n    ).run(\n        kubeflow_pipeline.create_pipeline(\n            pipeline_name=configs.PIPELINE_NAME,\n            pipeline_root=configs.PIPELINE_ROOT,\n            data_path=configs.DATA_PATH,\n            schema_path=configs.SCHEMA_PATH,\n            modules={\n                \"training_fn\": configs.TRAINING_FN,\n                \"preprocessing_fn\": configs.PREPROCESSING_FN,\n                \"tuner_fn\": configs.TUNER_FN,\n            },\n            eval_configs=configs.EVAL_CONFIGS,\n            ai_platform_training_args=configs.GCP_AI_PLATFORM_TRAINING_ARGS,\n            ai_platform_tuner_args=configs.GCP_AI_PLATFORM_TUNER_ARGS,\n            tuner_args=tuner_pb2.TuneArgs(\n                num_parallel_trials=configs.NUM_PARALLEL_TRIALS\n            ),\n            ai_platform_serving_args=configs.GCP_AI_PLATFORM_SERVING_ARGS,\n            example_gen_beam_args=configs.EXAMPLE_GEN_BEAM_ARGS,\n            transform_beam_args=configs.TRANSFORM_BEAM_ARGS,\n            wandb_pusher_args=configs.WANDB_PUSHER_ARGS,\n        )\n    )", "\n\ndef run():\n    runner_config = runner.KubeflowV2DagRunnerConfig(\n        default_image=configs.PIPELINE_IMAGE\n    )\n\n    runner.KubeflowV2DagRunner(\n        config=runner_config,\n        output_filename=configs.PIPELINE_NAME + \"_pipeline.json\",\n    ).run(\n        kubeflow_pipeline.create_pipeline(\n            pipeline_name=configs.PIPELINE_NAME,\n            pipeline_root=configs.PIPELINE_ROOT,\n            data_path=configs.DATA_PATH,\n            schema_path=configs.SCHEMA_PATH,\n            modules={\n                \"training_fn\": configs.TRAINING_FN,\n                \"preprocessing_fn\": configs.PREPROCESSING_FN,\n                \"tuner_fn\": configs.TUNER_FN,\n            },\n            eval_configs=configs.EVAL_CONFIGS,\n            ai_platform_training_args=configs.GCP_AI_PLATFORM_TRAINING_ARGS,\n            ai_platform_tuner_args=configs.GCP_AI_PLATFORM_TUNER_ARGS,\n            tuner_args=tuner_pb2.TuneArgs(\n                num_parallel_trials=configs.NUM_PARALLEL_TRIALS\n            ),\n            ai_platform_serving_args=configs.GCP_AI_PLATFORM_SERVING_ARGS,\n            example_gen_beam_args=configs.EXAMPLE_GEN_BEAM_ARGS,\n            transform_beam_args=configs.TRANSFORM_BEAM_ARGS,\n            wandb_pusher_args=configs.WANDB_PUSHER_ARGS,\n        )\n    )", "\n\nif __name__ == \"__main__\":\n    logging.set_verbosity(logging.INFO)\n    run()\n"]}
{"filename": "training_pipeline/local_runner.py", "chunked_list": ["import os\nfrom absl import logging\n\nfrom tfx import v1 as tfx\nfrom pipeline import configs\nfrom pipeline import local_configs\nfrom pipeline import local_pipeline\n\nOUTPUT_DIR = \".\"\n", "OUTPUT_DIR = \".\"\n\nPIPELINE_ROOT = os.path.join(OUTPUT_DIR, \"tfx_pipeline_output\", configs.PIPELINE_NAME)\nMETADATA_PATH = os.path.join(\n    OUTPUT_DIR, \"tfx_metadata\", configs.PIPELINE_NAME, \"metadata.db\"\n)\nSERVING_MODEL_DIR = os.path.join(PIPELINE_ROOT, \"serving_model\")\n\n\ndef run():\n    tfx.orchestration.LocalDagRunner().run(\n        local_pipeline.create_pipeline(\n            pipeline_name=configs.PIPELINE_NAME,\n            pipeline_root=PIPELINE_ROOT,\n            data_path=local_configs.DATA_PATH,\n            schema_path=configs.SCHEMA_PATH,\n            modules={\n                \"training_fn\": configs.TRAINING_FN,\n                \"preprocessing_fn\": configs.PREPROCESSING_FN,\n                \"tuner_fn\": configs.TUNER_FN,\n            },\n            hyperparameters=local_configs.HYPER_PARAMETERS,\n            eval_configs=configs.EVAL_CONFIGS,\n            serving_model_dir=SERVING_MODEL_DIR,\n            metadata_connection_config=tfx.orchestration.metadata.sqlite_metadata_connection_config(\n                METADATA_PATH\n            ),\n        )\n    )", "\ndef run():\n    tfx.orchestration.LocalDagRunner().run(\n        local_pipeline.create_pipeline(\n            pipeline_name=configs.PIPELINE_NAME,\n            pipeline_root=PIPELINE_ROOT,\n            data_path=local_configs.DATA_PATH,\n            schema_path=configs.SCHEMA_PATH,\n            modules={\n                \"training_fn\": configs.TRAINING_FN,\n                \"preprocessing_fn\": configs.PREPROCESSING_FN,\n                \"tuner_fn\": configs.TUNER_FN,\n            },\n            hyperparameters=local_configs.HYPER_PARAMETERS,\n            eval_configs=configs.EVAL_CONFIGS,\n            serving_model_dir=SERVING_MODEL_DIR,\n            metadata_connection_config=tfx.orchestration.metadata.sqlite_metadata_connection_config(\n                METADATA_PATH\n            ),\n        )\n    )", "\n\nif __name__ == \"__main__\":\n    logging.set_verbosity(logging.INFO)\n    run()\n"]}
{"filename": "training_pipeline/pipeline/configs.py", "chunked_list": ["import os\nimport string\nimport random\nimport tensorflow_model_analysis as tfma\nimport tfx.extensions.google_cloud_ai_platform.constants as vertex_const\nimport tfx.extensions.google_cloud_ai_platform.trainer.executor as vertex_training_const\nimport tfx.extensions.google_cloud_ai_platform.tuner.executor as vertex_tuner_const\n\nPIPELINE_NAME = \"tfx-vit-pipeline\"\n\ntry:\n    import google.auth  # pylint: disable=g-import-not-at-top  # pytype: disable=import-error\n\n    try:\n        _, GOOGLE_CLOUD_PROJECT = google.auth.default()\n    except google.auth.exceptions.DefaultCredentialsError:\n        GOOGLE_CLOUD_PROJECT = \"gcp-ml-172005\"\nexcept ImportError:\n    GOOGLE_CLOUD_PROJECT = \"gcp-ml-172005\"", "PIPELINE_NAME = \"tfx-vit-pipeline\"\n\ntry:\n    import google.auth  # pylint: disable=g-import-not-at-top  # pytype: disable=import-error\n\n    try:\n        _, GOOGLE_CLOUD_PROJECT = google.auth.default()\n    except google.auth.exceptions.DefaultCredentialsError:\n        GOOGLE_CLOUD_PROJECT = \"gcp-ml-172005\"\nexcept ImportError:\n    GOOGLE_CLOUD_PROJECT = \"gcp-ml-172005\"", "\nGOOGLE_CLOUD_REGION = \"us-central1\"\n\nGCS_BUCKET_NAME = GOOGLE_CLOUD_PROJECT + \"-complete-mlops\"\nPIPELINE_IMAGE = f\"gcr.io/{GOOGLE_CLOUD_PROJECT}/{PIPELINE_NAME}\"\n\nOUTPUT_DIR = os.path.join(\"gs://\", GCS_BUCKET_NAME)\nPIPELINE_ROOT = os.path.join(OUTPUT_DIR, \"tfx_pipeline_output\", PIPELINE_NAME)\n\nDATA_PATH = \"gs://beans-lowres/tfrecords/\"", "\nDATA_PATH = \"gs://beans-lowres/tfrecords/\"\nSCHEMA_PATH = \"pipeline/schema.pbtxt\"\n\nTRAINING_FN = \"modules.train.run_fn\"\nTUNER_FN = \"modules.tuning.tuner_fn\"\nPREPROCESSING_FN = \"modules.preprocessing.preprocessing_fn\"\n\nEXAMPLE_GEN_BEAM_ARGS = None\nTRANSFORM_BEAM_ARGS = None", "EXAMPLE_GEN_BEAM_ARGS = None\nTRANSFORM_BEAM_ARGS = None\n\ndef id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n    return ''.join(random.choice(chars) for _ in range(size))\n\nWANDB_RUN_ID = f\"full-training-{id_generator()}\"\n\nWANDB_CONFIGS = {\n    \"API_KEY\": \"$WANDB_ACCESS_TOKEN\",", "WANDB_CONFIGS = {\n    \"API_KEY\": \"$WANDB_ACCESS_TOKEN\",\n    \"PROJECT\": PIPELINE_NAME,\n    \"FINAL_RUN_ID\": WANDB_RUN_ID\n}\n\nHYPER_PARAMETERS = {\n    \"finetune_epochs\": {\n        \"type\": \"choice\",\n        \"values\": [10]", "        \"type\": \"choice\",\n        \"values\": [10]\n    },\n\n    \"fulltrain_epochs\": {\n        \"type\": \"choice\",\n        \"values\": [30]\n    },    \n\n    \"optimizer_type\": {", "\n    \"optimizer_type\": {\n        \"type\": \"choice\",\n        \"values\": [\"Adam\", \"AdamW\"],\n    },\n\n    \"learning_rate\": {\n        \"type\": \"float\",\n        \"min_value\": 0.00001,\n        \"max_value\": 0.1,", "        \"min_value\": 0.00001,\n        \"max_value\": 0.1,\n        \"sampling\": \"log\",\n        \"step\": 10\n    },\n\n    \"weight_decay\": {\n        \"type\": \"choice\",\n        \"values\": [0.0, 0.1, 0.2, 0.3, 0.5, 0.6]\n    }", "        \"values\": [0.0, 0.1, 0.2, 0.3, 0.5, 0.6]\n    }\n}\n\nTUNER_CONFIGS = {\n    \"num_trials\": 15\n}\n\nEVAL_CONFIGS = tfma.EvalConfig(\n    model_specs=[", "EVAL_CONFIGS = tfma.EvalConfig(\n    model_specs=[\n        tfma.ModelSpec(\n            signature_name=\"from_examples\",\n            preprocessing_function_names=[\"transform_features\"],\n            label_key=\"labels\",\n            prediction_key=\"labels\",\n        )\n    ],\n    slicing_specs=[tfma.SlicingSpec()],", "    ],\n    slicing_specs=[tfma.SlicingSpec()],\n    metrics_specs=[\n        tfma.MetricsSpec(\n            metrics=[\n                tfma.MetricConfig(\n                    class_name=\"SparseCategoricalAccuracy\",\n                    threshold=tfma.MetricThreshold(\n                        value_threshold=tfma.GenericValueThreshold(\n                            lower_bound={\"value\": 0.55}", "                        value_threshold=tfma.GenericValueThreshold(\n                            lower_bound={\"value\": 0.55}\n                        ),\n                        # Change threshold will be ignored if there is no\n                        # baseline model resolved from MLMD (first run).\n                        change_threshold=tfma.GenericChangeThreshold(\n                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                            absolute={\"value\": -1e-3},\n                        ),\n                    ),", "                        ),\n                    ),\n                )\n            ]\n        )\n    ],\n)\n\nGCP_AI_PLATFORM_TRAINING_ARGS = {\n    vertex_const.ENABLE_VERTEX_KEY: True,", "GCP_AI_PLATFORM_TRAINING_ARGS = {\n    vertex_const.ENABLE_VERTEX_KEY: True,\n    vertex_const.VERTEX_REGION_KEY: GOOGLE_CLOUD_REGION,\n    vertex_training_const.TRAINING_ARGS_KEY: {\n        \"project\": GOOGLE_CLOUD_PROJECT,\n        \"worker_pool_specs\": [\n            {\n                \"machine_spec\": {\n                    \"machine_type\": \"n1-standard-4\",\n                    \"accelerator_type\": \"NVIDIA_TESLA_K80\",", "                    \"machine_type\": \"n1-standard-4\",\n                    \"accelerator_type\": \"NVIDIA_TESLA_K80\",\n                    \"accelerator_count\": 1,\n                },\n                \"replica_count\": 1,\n                \"container_spec\": {\n                    \"image_uri\": PIPELINE_IMAGE,\n                },\n            }\n        ],", "            }\n        ],\n    },\n    \"use_gpu\": True,\n    \"wandb\": WANDB_CONFIGS\n}\n\nfullres_data = os.environ.get(\"FULL_RES_DATA\", \"false\")\n\nif fullres_data.lower() == \"true\":\n    DATA_PATH = \"gs://beans-fullres/tfrecords/\"\n\n    DATAFLOW_SERVICE_ACCOUNT = \"csp-gde-dataflow@gcp-ml-172005.iam.gserviceaccount.com\"\n    DATAFLOW_MACHINE_TYPE = \"n1-standard-4\"\n    DATAFLOW_MAX_WORKERS = 4\n    DATAFLOW_DISK_SIZE_GB = 100\n\n    EXAMPLE_GEN_BEAM_ARGS = [\n        \"--runner=DataflowRunner\",\n        \"--project=\" + GOOGLE_CLOUD_PROJECT,\n        \"--region=\" + GOOGLE_CLOUD_REGION,\n        \"--service_account_email=\" + DATAFLOW_SERVICE_ACCOUNT,\n        \"--machine_type=\" + DATAFLOW_MACHINE_TYPE,\n        \"--experiments=use_runner_v2\",\n        \"--max_num_workers=\" + str(DATAFLOW_MAX_WORKERS),\n        \"--disk_size_gb=\" + str(DATAFLOW_DISK_SIZE_GB),\n    ]\n\n    TRANSFORM_BEAM_ARGS = [\n        \"--runner=DataflowRunner\",\n        \"--project=\" + GOOGLE_CLOUD_PROJECT,\n        \"--region=\" + GOOGLE_CLOUD_REGION,\n        \"--service_account_email=\" + DATAFLOW_SERVICE_ACCOUNT,\n        \"--machine_type=\" + DATAFLOW_MACHINE_TYPE,\n        \"--experiments=use_runner_v2\",\n        \"--max_num_workers=\" + str(DATAFLOW_MAX_WORKERS),\n        \"--disk_size_gb=\" + str(DATAFLOW_DISK_SIZE_GB),\n        \"--worker_harness_container_image=\" + PIPELINE_IMAGE,\n    ]\n\n    GCP_AI_PLATFORM_TRAINING_ARGS[vertex_training_const.TRAINING_ARGS_KEY][\n        \"worker_pool_specs\"\n    ] = [\n        {\n            \"machine_spec\": {\n                \"machine_type\": \"n1-standard-8\",\n                \"accelerator_type\": \"NVIDIA_TESLA_V100\",\n                \"accelerator_count\": 1,\n            },\n            \"replica_count\": 1,\n            \"container_spec\": {\n                \"image_uri\": PIPELINE_IMAGE,\n            },\n        }\n    ]", "\nif fullres_data.lower() == \"true\":\n    DATA_PATH = \"gs://beans-fullres/tfrecords/\"\n\n    DATAFLOW_SERVICE_ACCOUNT = \"csp-gde-dataflow@gcp-ml-172005.iam.gserviceaccount.com\"\n    DATAFLOW_MACHINE_TYPE = \"n1-standard-4\"\n    DATAFLOW_MAX_WORKERS = 4\n    DATAFLOW_DISK_SIZE_GB = 100\n\n    EXAMPLE_GEN_BEAM_ARGS = [\n        \"--runner=DataflowRunner\",\n        \"--project=\" + GOOGLE_CLOUD_PROJECT,\n        \"--region=\" + GOOGLE_CLOUD_REGION,\n        \"--service_account_email=\" + DATAFLOW_SERVICE_ACCOUNT,\n        \"--machine_type=\" + DATAFLOW_MACHINE_TYPE,\n        \"--experiments=use_runner_v2\",\n        \"--max_num_workers=\" + str(DATAFLOW_MAX_WORKERS),\n        \"--disk_size_gb=\" + str(DATAFLOW_DISK_SIZE_GB),\n    ]\n\n    TRANSFORM_BEAM_ARGS = [\n        \"--runner=DataflowRunner\",\n        \"--project=\" + GOOGLE_CLOUD_PROJECT,\n        \"--region=\" + GOOGLE_CLOUD_REGION,\n        \"--service_account_email=\" + DATAFLOW_SERVICE_ACCOUNT,\n        \"--machine_type=\" + DATAFLOW_MACHINE_TYPE,\n        \"--experiments=use_runner_v2\",\n        \"--max_num_workers=\" + str(DATAFLOW_MAX_WORKERS),\n        \"--disk_size_gb=\" + str(DATAFLOW_DISK_SIZE_GB),\n        \"--worker_harness_container_image=\" + PIPELINE_IMAGE,\n    ]\n\n    GCP_AI_PLATFORM_TRAINING_ARGS[vertex_training_const.TRAINING_ARGS_KEY][\n        \"worker_pool_specs\"\n    ] = [\n        {\n            \"machine_spec\": {\n                \"machine_type\": \"n1-standard-8\",\n                \"accelerator_type\": \"NVIDIA_TESLA_V100\",\n                \"accelerator_count\": 1,\n            },\n            \"replica_count\": 1,\n            \"container_spec\": {\n                \"image_uri\": PIPELINE_IMAGE,\n            },\n        }\n    ]", "\nNUM_PARALLEL_TRIALS = 3\nGCP_AI_PLATFORM_TUNER_ARGS = {\n    vertex_const.ENABLE_VERTEX_KEY: True,\n    vertex_const.VERTEX_REGION_KEY: GOOGLE_CLOUD_REGION,\n    vertex_tuner_const.TUNING_ARGS_KEY: {\n        \"project\": GOOGLE_CLOUD_PROJECT,\n        \"job_spec\": {\n            \"worker_pool_specs\": [\n                {", "            \"worker_pool_specs\": [\n                {\n                    \"machine_spec\": {\n                        \"machine_type\": \"n1-standard-8\",\n                        \"accelerator_type\": \"NVIDIA_TESLA_V100\",\n                        \"accelerator_count\": 1,\n                    },\n                    \"replica_count\": 1,\n                    \"container_spec\": {\n                        \"image_uri\": PIPELINE_IMAGE,", "                    \"container_spec\": {\n                        \"image_uri\": PIPELINE_IMAGE,\n                    },\n                }\n            ],\n        },\n    },\n    vertex_tuner_const.REMOTE_TRIALS_WORKING_DIR_KEY: os.path.join(\n        PIPELINE_ROOT, \"trials\"\n    ),", "        PIPELINE_ROOT, \"trials\"\n    ),\n    \"use_gpu\": True,\n    \"hyperparameters\": HYPER_PARAMETERS,\n    \"tuner\": TUNER_CONFIGS,\n    \"wandb\": WANDB_CONFIGS\n}\n\nGCP_AI_PLATFORM_SERVING_ARGS = {\n    vertex_const.ENABLE_VERTEX_KEY: True,", "GCP_AI_PLATFORM_SERVING_ARGS = {\n    vertex_const.ENABLE_VERTEX_KEY: True,\n    vertex_const.VERTEX_REGION_KEY: GOOGLE_CLOUD_REGION,\n    vertex_const.VERTEX_CONTAINER_IMAGE_URI_KEY: \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\",\n    vertex_const.SERVING_ARGS_KEY: {\n        \"project_id\": GOOGLE_CLOUD_PROJECT,\n        \"deployed_model_display_name\": PIPELINE_NAME.replace(\"-\", \"_\"),\n        \"endpoint_name\": \"prediction-\" + PIPELINE_NAME.replace(\"-\", \"_\"),\n        \"traffic_split\": {\"0\": 100},\n        \"machine_type\": \"n1-standard-4\",", "        \"traffic_split\": {\"0\": 100},\n        \"machine_type\": \"n1-standard-4\",\n        \"min_replica_count\": 1,\n        \"max_replica_count\": 1,\n    },\n}\n\nGRADIO_APP_PATH = \"huggingface.apps.gradio\"\n\nWANDB_PUSHER_ARGS = {", "\nWANDB_PUSHER_ARGS = {\n    \"access_token\": \"$WANDB_ACCESS_TOKEN\",\n    \"project_name\": PIPELINE_NAME,\n    \"run_name\": WANDB_RUN_ID,\n    \"model_name\": \"final_model\",\n    \"aliases\": [\"test_aliases\"],\n    \"space_config\": {\n        \"app_path\": GRADIO_APP_PATH,\n        \"hf_username\": \"chansung\",", "        \"app_path\": GRADIO_APP_PATH,\n        \"hf_username\": \"chansung\",\n        \"hf_repo_name\": PIPELINE_NAME,\n        \"hf_access_token\": \"$HF_ACCESS_TOKEN\"\n    },\n}"]}
{"filename": "training_pipeline/pipeline/local_configs.py", "chunked_list": ["DATA_PATH = \"local-data/\"\n\nHYPER_PARAMETERS = {\n    \"epochs\": {\n        \"type\": \"choice\",\n        \"values\": [1]\n    },\n\n    \"optimizer_type\": {\n        \"type\": \"choice\",", "    \"optimizer_type\": {\n        \"type\": \"choice\",\n        \"values\": [\"Adam\"],\n    },\n\n    \"learning_rate\": {\n        \"type\": \"float\",\n        \"min_value\": 0.00001,\n        \"max_value\": 0.00001,\n        \"sampling\": \"log\",", "        \"max_value\": 0.00001,\n        \"sampling\": \"log\",\n        \"step\": 10\n    },\n\n    \"weight_decay\": {\n        \"type\": \"choice\",\n        \"values\": [0.1]\n    }\n}", "    }\n}"]}
{"filename": "training_pipeline/pipeline/kubeflow_pipeline.py", "chunked_list": ["from typing import Any, Dict, List, Optional, Text\n\nimport tensorflow_model_analysis as tfma\n\nfrom tfx import v1 as tfx\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.proto import example_gen_pb2\n\nfrom tfx.components import ImportExampleGen", "\nfrom tfx.components import ImportExampleGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Transform\nfrom tfx.components import Evaluator\nfrom tfx.extensions.google_cloud_ai_platform.trainer.component import (\n    Trainer as VertexTrainer,\n)\nfrom tfx.extensions.google_cloud_ai_platform.pusher.component import (", ")\nfrom tfx.extensions.google_cloud_ai_platform.pusher.component import (\n    Pusher as VertexPusher,\n)\nfrom tfx.extensions.google_cloud_ai_platform.tuner.component import Tuner as VertexTuner\nfrom tfx.orchestration import pipeline\nfrom tfx.proto import example_gen_pb2\nfrom tfx.proto import tuner_pb2\n\nfrom tfx.types import Channel", "\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.dsl.components.common import resolver\nfrom tfx.dsl.experimental.latest_blessed_model_resolver import (\n    LatestBlessedModelResolver,\n)\n\nfrom pipeline.components.WandBPusher.component import WandBPusher", "\nfrom pipeline.components.WandBPusher.component import WandBPusher\n\ndef create_pipeline(\n    pipeline_name: Text,\n    pipeline_root: Text,\n    data_path: Text,\n    schema_path: Text,\n    modules: Dict[Text, Text],\n    eval_configs: tfma.EvalConfig,\n    metadata_connection_config: Optional[metadata_store_pb2.ConnectionConfig] = None,\n    ai_platform_training_args: Optional[Dict[Text, Text]] = None,\n    ai_platform_tuner_args: Optional[Dict[Text, Text]] = None,\n    tuner_args: tuner_pb2.TuneArgs = None,\n    ai_platform_serving_args: Optional[Dict[Text, Any]] = None,\n    example_gen_beam_args: Optional[List] = None,\n    transform_beam_args: Optional[List] = None,\n    wandb_pusher_args: Optional[Dict[Text, Any]] = None,\n) -> tfx.dsl.Pipeline:\n    components = []\n\n    input_config = example_gen_pb2.Input(\n        splits=[\n            example_gen_pb2.Input.Split(name=\"train\", pattern=\"train-*.tfrec\"),\n            example_gen_pb2.Input.Split(name=\"eval\", pattern=\"val-*.tfrec\"),\n        ]\n    )\n    example_gen = ImportExampleGen(input_base=data_path, input_config=input_config)\n    components.append(example_gen)\n\n    statistics_gen = StatisticsGen(examples=example_gen.outputs[\"examples\"])\n    components.append(statistics_gen)\n\n    schema_gen = tfx.components.ImportSchemaGen(schema_file=schema_path)\n    components.append(schema_gen)\n\n    example_validator = ExampleValidator(\n        statistics=statistics_gen.outputs[\"statistics\"],\n        schema=schema_gen.outputs[\"schema\"],\n    )\n    components.append(example_validator)\n\n    transform_args = {\n        \"examples\": example_gen.outputs[\"examples\"],\n        \"schema\": schema_gen.outputs[\"schema\"],\n        \"preprocessing_fn\": modules[\"preprocessing_fn\"],\n    }\n    transform = Transform(**transform_args)\n    components.append(transform)\n\n    # tuner\n\n    tune_input_config = example_gen_pb2.Input(\n        splits=[\n            example_gen_pb2.Input.Split(name=\"train\", pattern=\"train-00-*.tfrec\"),\n            example_gen_pb2.Input.Split(name=\"eval\", pattern=\"val-*.tfrec\"),\n        ]\n    )\n    tune_example_gen = ImportExampleGen(\n        input_base=data_path, \n        input_config=tune_input_config\n    ).with_id(\"Tune_ExampleGen\")\n    components.append(tune_example_gen)\n\n    tune_statistics_gen = StatisticsGen(\n        examples=tune_example_gen.outputs[\"examples\"]\n    ).with_id(\"Tune_StatisticsGen\")\n    components.append(tune_statistics_gen)\n\n    tune_example_validator = ExampleValidator(\n        statistics=tune_statistics_gen.outputs[\"statistics\"],\n        schema=schema_gen.outputs[\"schema\"],\n    ).with_id(\"Tune_ExampleValidator\")\n    components.append(tune_example_validator)\n\n    tune_transform_args = {\n        \"examples\": tune_example_gen.outputs[\"examples\"],\n        \"schema\": schema_gen.outputs[\"schema\"],\n        \"preprocessing_fn\": modules[\"preprocessing_fn\"],\n    }\n    tune_transform = Transform(**tune_transform_args).with_id(\"Tune_Transform\")\n    components.append(tune_transform)\n\n    tuner = VertexTuner(\n        tuner_fn=modules[\"tuner_fn\"],\n        examples=tune_transform.outputs[\"transformed_examples\"],\n        transform_graph=tune_transform.outputs[\"transform_graph\"],\n        tune_args=tuner_args,\n        custom_config=ai_platform_tuner_args,\n    )\n    components.append(tuner)\n\n    trainer_args = {\n        \"run_fn\": modules[\"training_fn\"],\n        \"transformed_examples\": transform.outputs[\"transformed_examples\"],\n        \"transform_graph\": transform.outputs[\"transform_graph\"],\n        \"schema\": schema_gen.outputs[\"schema\"],\n        \"hyperparameters\": tuner.outputs[\"best_hyperparameters\"],\n        \"custom_config\": ai_platform_training_args,\n    }\n    trainer = VertexTrainer(**trainer_args)\n    components.append(trainer)\n\n    model_resolver = resolver.Resolver(\n        strategy_class=LatestBlessedModelResolver,\n        model=Channel(type=Model),\n        model_blessing=Channel(type=ModelBlessing),\n    ).with_id(\"latest_blessed_model_resolver\")\n    components.append(model_resolver)\n\n    # evaluator = Evaluator(\n    #     examples=example_gen.outputs[\"examples\"],\n    #     model=trainer.outputs[\"model\"],\n    #     baseline_model=model_resolver.outputs[\"model\"],\n    #     eval_config=eval_configs,\n    # )\n    # components.append(evaluator)\n\n    # pusher_args = {\n    #     \"model\": trainer.outputs[\"model\"],\n    #     \"model_blessing\": evaluator.outputs[\"blessing\"],\n    #     \"custom_config\": ai_platform_serving_args,\n    # }\n    # pusher = VertexPusher(**pusher_args)  # pylint: disable=unused-variable\n    # components.append(pusher)\n\n    wandb_pusher_args[\"model\"] = trainer.outputs[\"model\"]\n    # wandb_pusher_args[\"model_blessing\"] = evaluator.outputs[\"blessing\"]    \n    pusher = WandBPusher(**wandb_pusher_args)\n    components.append(pusher)\n\n    return pipeline.Pipeline(\n        pipeline_name=pipeline_name,\n        pipeline_root=pipeline_root,\n        components=components,\n        enable_cache=True,\n        metadata_connection_config=metadata_connection_config,\n    )", ""]}
{"filename": "training_pipeline/pipeline/local_pipeline.py", "chunked_list": ["from typing import Dict, Optional, Text\n\nimport tensorflow_model_analysis as tfma\n\nfrom tfx import v1 as tfx\n\nfrom ml_metadata.proto import metadata_store_pb2\nfrom tfx.proto import example_gen_pb2\n\nfrom tfx.components import ImportExampleGen", "\nfrom tfx.components import ImportExampleGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import ExampleValidator\nfrom tfx.components import Transform\nfrom tfx.components import Tuner\nfrom tfx.components import Trainer\nfrom tfx.components import Evaluator\nfrom tfx.components import Pusher\nfrom tfx.orchestration import pipeline", "from tfx.components import Pusher\nfrom tfx.orchestration import pipeline\nfrom tfx.proto import example_gen_pb2\n\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model\nfrom tfx.types.standard_artifacts import ModelBlessing\nfrom tfx.dsl.components.common import resolver\nfrom tfx.dsl.experimental.latest_blessed_model_resolver import (\n    LatestBlessedModelResolver,", "from tfx.dsl.experimental.latest_blessed_model_resolver import (\n    LatestBlessedModelResolver,\n)\n\n\ndef create_pipeline(\n    pipeline_name: Text,\n    pipeline_root: Text,\n    data_path: Text,\n    schema_path: Text,\n    modules: Dict[Text, Text],\n    hyperparameters: Dict[Text, Text],\n    eval_configs: tfma.EvalConfig,\n    serving_model_dir: Text,\n    metadata_connection_config: Optional[metadata_store_pb2.ConnectionConfig] = None,\n) -> tfx.dsl.Pipeline:\n    components = []\n\n    input_config = example_gen_pb2.Input(\n        splits=[\n            example_gen_pb2.Input.Split(name=\"train\", pattern=\"train-00-*.tfrec\"),\n            example_gen_pb2.Input.Split(name=\"eval\", pattern=\"val-00-*.tfrec\"),\n        ]\n    )\n    example_gen = ImportExampleGen(input_base=data_path, input_config=input_config)\n    components.append(example_gen)\n\n    statistics_gen = StatisticsGen(examples=example_gen.outputs[\"examples\"])\n    components.append(statistics_gen)\n\n    schema_gen = tfx.components.ImportSchemaGen(schema_file=schema_path)\n    components.append(schema_gen)\n\n    example_validator = ExampleValidator(\n        statistics=statistics_gen.outputs[\"statistics\"],\n        schema=schema_gen.outputs[\"schema\"],\n    )\n    components.append(example_validator)\n\n    transform_args = {\n        \"examples\": example_gen.outputs[\"examples\"],\n        \"schema\": schema_gen.outputs[\"schema\"],\n        \"preprocessing_fn\": modules[\"preprocessing_fn\"],\n    }\n    transform = Transform(**transform_args)\n    components.append(transform)\n\n    tuner = Tuner(\n        tuner_fn=modules[\"tuner_fn\"],\n        examples=transform.outputs[\"transformed_examples\"],\n        schema=schema_gen.outputs[\"schema\"],\n        transform_graph=transform.outputs[\"transform_graph\"],\n        custom_config={\"hyperparameters\": hyperparameters},\n    )\n    components.append(tuner)\n\n    trainer_args = {\n        \"run_fn\": modules[\"training_fn\"],\n        \"transformed_examples\": transform.outputs[\"transformed_examples\"],\n        \"transform_graph\": transform.outputs[\"transform_graph\"],\n        \"schema\": schema_gen.outputs[\"schema\"],\n        \"hyperparameters\": tuner.outputs[\"best_hyperparameters\"],\n        \"custom_config\": {\"is_local\": True},\n    }\n    trainer = Trainer(**trainer_args)\n    components.append(trainer)\n\n    model_resolver = resolver.Resolver(\n        strategy_class=LatestBlessedModelResolver,\n        model=Channel(type=Model),\n        model_blessing=Channel(type=ModelBlessing),\n    ).with_id(\"latest_blessed_model_resolver\")\n    components.append(model_resolver)\n\n    evaluator = Evaluator(\n        examples=example_gen.outputs[\"examples\"],\n        model=trainer.outputs[\"model\"],\n        baseline_model=model_resolver.outputs[\"model\"],\n        eval_config=eval_configs,\n    )\n    components.append(evaluator)\n\n    pusher_args = {\n        \"model\": trainer.outputs[\"model\"],\n        \"model_blessing\": evaluator.outputs[\"blessing\"],\n        \"push_destination\": tfx.proto.PushDestination(\n            filesystem=tfx.proto.PushDestination.Filesystem(\n                base_directory=serving_model_dir\n            )\n        ),\n    }\n    pusher = Pusher(**pusher_args)  # pylint: disable=unused-variable\n    components.append(pusher)\n\n    return pipeline.Pipeline(\n        pipeline_name=pipeline_name,\n        pipeline_root=pipeline_root,\n        components=components,\n        enable_cache=False,\n        metadata_connection_config=metadata_connection_config,\n    )", ""]}
{"filename": "training_pipeline/pipeline/components/__init__.py", "chunked_list": [""]}
{"filename": "training_pipeline/pipeline/components/WandBPusher/runner.py", "chunked_list": ["\"\"\"WandB Pusher runner module.\nThis module handles the workflow to publish machine \nlearning model to Weights & Biases Model Registry.\n\"\"\"\nfrom typing import Text, List, Any, Dict, Optional\n\nimport os\nimport mimetypes\nimport tempfile\nimport ast", "import tempfile\nimport ast\nimport tarfile\nimport tensorflow as tf\nfrom absl import logging\nfrom tfx.utils import io_utils\nfrom pathlib import Path\n\nfrom huggingface_hub import Repository\nfrom huggingface_hub import HfApi", "from huggingface_hub import Repository\nfrom huggingface_hub import HfApi\nfrom requests.exceptions import HTTPError\n\nimport wandb\n\n_MODEL_PROJECT_KEY = \"MODEL_REPO_ID\"\n_MODEL_RUN_KEY = \"MODEL_RUN_ID\"\n_MODEL_NAME_KEY = \"MODEL_REPO_URL\"\n_MODEL_VERSION_KEY = \"MODEL_VERSION\"", "_MODEL_NAME_KEY = \"MODEL_REPO_URL\"\n_MODEL_VERSION_KEY = \"MODEL_VERSION\"\n_MODEL_FILENAME_KEY = \"MODEL_FILENAME\"\n\n_DEFAULT_MODEL_REPO_PLACEHOLDER_KEY = \"$MODEL_PROJECT\"\n_DEFAULT_RUN_PLACEHOLDER_KEY = \"$MODEL_RUN\"\n_DEFAULT_MODEL_URL_PLACEHOLDER_KEY = \"$MODEL_NAME\"\n_DEFAULT_MODEL_VERSION_PLACEHOLDER_KEY = \"$MODEL_VERSION\"\n_DEFAULT_MODEL_FILENAME_KEY = \"$MODEL_FILENAME\"\n\ndef _is_text_file(path):\n    mimetype = mimetypes.guess_type(path)\n    if mimetype[0] != None:\n        return 'text' in mimetype[0]\n    \n    return False", "_DEFAULT_MODEL_FILENAME_KEY = \"$MODEL_FILENAME\"\n\ndef _is_text_file(path):\n    mimetype = mimetypes.guess_type(path)\n    if mimetype[0] != None:\n        return 'text' in mimetype[0]\n    \n    return False\n\ndef _replace_files(src_paths, dst_path):\n    \"\"\"replace the contents(files/folders) of the repository with the\n    latest contents\"\"\"\n\n    not_to_delete = [\".gitattributes\", \".git\"]\n\n    inside_root_dst_path = tf.io.gfile.listdir(dst_path)\n\n    for content_name in inside_root_dst_path:\n        content = f\"{dst_path}/{content_name}\"\n\n        if content_name not in not_to_delete:\n            if tf.io.gfile.isdir(content):\n                tf.io.gfile.rmtree(content)\n            else:\n                tf.io.gfile.remove(content)\n\n    for src_path in src_paths:\n        try:\n            inside_root_src_path = tf.io.gfile.listdir(src_path)\n\n            for content_name in inside_root_src_path:\n                content = f\"{src_path}/{content_name}\"\n                dst_content = f\"{dst_path}/{content_name}\"\n\n                if tf.io.gfile.isdir(content):\n                    io_utils.copy_dir(content, dst_content)\n                else:\n                    tf.io.gfile.copy(content, dst_content)\n\n        except tf.errors.NotFoundError as e:\n            logging.warning(f\"Path not found: {src_path}\")", "\ndef _replace_files(src_paths, dst_path):\n    \"\"\"replace the contents(files/folders) of the repository with the\n    latest contents\"\"\"\n\n    not_to_delete = [\".gitattributes\", \".git\"]\n\n    inside_root_dst_path = tf.io.gfile.listdir(dst_path)\n\n    for content_name in inside_root_dst_path:\n        content = f\"{dst_path}/{content_name}\"\n\n        if content_name not in not_to_delete:\n            if tf.io.gfile.isdir(content):\n                tf.io.gfile.rmtree(content)\n            else:\n                tf.io.gfile.remove(content)\n\n    for src_path in src_paths:\n        try:\n            inside_root_src_path = tf.io.gfile.listdir(src_path)\n\n            for content_name in inside_root_src_path:\n                content = f\"{src_path}/{content_name}\"\n                dst_content = f\"{dst_path}/{content_name}\"\n\n                if tf.io.gfile.isdir(content):\n                    io_utils.copy_dir(content, dst_content)\n                else:\n                    tf.io.gfile.copy(content, dst_content)\n\n        except tf.errors.NotFoundError as e:\n            logging.warning(f\"Path not found: {src_path}\")", "\ndef _replace_placeholders_in_files(\n    root_dir: str, placeholder_to_replace: Dict[str, str]\n):\n    \"\"\"Recursively open every files under the root_dir, and then\n    replace special tokens with the given values in placeholder_\n    to_replace\"\"\"\n    files = tf.io.gfile.listdir(root_dir)\n    for file in files:\n        path = tf.io.gfile.join(root_dir, file)\n\n        if tf.io.gfile.isdir(path):\n            _replace_placeholders_in_files(path, placeholder_to_replace)\n        else:\n            _replace_placeholders_in_file(path, placeholder_to_replace)", "\n\ndef _replace_placeholders_in_file(\n    filepath: str, placeholder_to_replace: Dict[str, str]\n):\n    \"\"\"replace special tokens with the given values in placeholder_\n    to_replace. This function gets called by _replace_placeholders\n    _in_files function\"\"\"\n    if _is_text_file(filepath):\n        with tf.io.gfile.GFile(filepath, \"r\") as f:\n            source_code = f.read()\n\n        for placeholder in placeholder_to_replace:\n            if placeholder_to_replace[placeholder] is not None:\n                source_code = source_code.replace(\n                    placeholder, placeholder_to_replace[placeholder]\n                )\n\n        with tf.io.gfile.GFile(filepath, \"w\") as f:\n            f.write(source_code)", "\n\ndef _replace_placeholders(\n    target_dir: str,\n    placeholders: Dict[str, str],\n    model_project: str,\n    model_run: str,\n    model_name: str,\n    model_version: str,\n    model_filename: str,\n    additional_replacements: Optional[Dict[str, str]]\n):\n    # tfx-vit-pipeline/final_model:latest\n    \"\"\"set placeholder_to_replace before calling _replace_placeholde\n    rs_in_files function\"\"\"\n\n    if placeholders is None:\n        placeholders = {\n            _MODEL_PROJECT_KEY: _DEFAULT_MODEL_REPO_PLACEHOLDER_KEY,\n            _MODEL_RUN_KEY: _DEFAULT_RUN_PLACEHOLDER_KEY,\n            _MODEL_NAME_KEY: _DEFAULT_MODEL_URL_PLACEHOLDER_KEY,\n            _MODEL_VERSION_KEY: _DEFAULT_MODEL_VERSION_PLACEHOLDER_KEY,\n            _MODEL_FILENAME_KEY: _DEFAULT_MODEL_FILENAME_KEY,\n        }\n\n    placeholder_to_replace = {\n        placeholders[_MODEL_PROJECT_KEY]: model_project,\n        placeholders[_MODEL_NAME_KEY]: model_name,\n        placeholders[_MODEL_VERSION_KEY]: model_version,\n        placeholders[_MODEL_FILENAME_KEY]: model_filename,\n        placeholders[_MODEL_RUN_KEY]: model_run\n    }\n    if additional_replacements is not None:\n        placeholder_to_replace = {**placeholder_to_replace, **additional_replacements}\n    _replace_placeholders_in_files(target_dir, placeholder_to_replace)", "\ndef _create_remote_repo(\n    access_token: str, repo_id: str, repo_type: str = \"space\", space_sdk: str = None\n):\n    \"\"\"create a remote repository on HuggingFace Hub platform. HTTPError\n    exception is raised when the repository already exists\"\"\"\n\n    logging.info(f\"repo_id: {repo_id}\")\n    try:\n        HfApi().create_repo(\n            token=access_token,\n            repo_id=repo_id,\n            repo_type=repo_type,\n            space_sdk=space_sdk,\n        )\n    except HTTPError:\n        logging.warning(\n            f\"this warning is expected if {repo_id} repository already exists\"\n        )", "\ndef _clone_and_checkout(\n    repo_url: str, local_path: str, access_token: str, version: Optional[str] = None\n) -> Repository:\n    \"\"\"clone the remote repository to the given local_path\"\"\"\n\n    repository = Repository(\n        local_dir=local_path, clone_from=repo_url, use_auth_token=access_token\n    )\n\n    if version is not None:\n        repository.git_checkout(revision=version, create_branch_ok=True)\n\n    return repository", "\n\ndef _push_to_remote_repo(repo: Repository, commit_msg: str, branch: str = \"main\"):\n    \"\"\"push any changes to the remote repository\"\"\"\n\n    repo.git_add(pattern=\".\", auto_lfs_track=True)\n    repo.git_commit(commit_message=commit_msg)\n    repo.git_push(upstream=f\"origin {branch}\")\n\ndef deploy_model_for_wandb_model_registry(\n    access_token: str,\n    project_name: str,\n    run_name: str,\n    model_name: str,\n    aliases: List[str],\n    model_path: str,\n    model_version: str,\n    space_config: Optional[Dict[Text, Any]] = None,\n) -> Dict[str, str]:\n    \"\"\"Executes ML model deployment workflow to Weights & Biases Model\n    Registry. Refer to the WandBPusher component in component.py for g\n    eneric description of each parameter. This docstring only explains\n    how the workflow works.\n    step 1. push model to the Weights & Biases Model Registry\n    step 1-1.\n        login to the Weights & Biases w/ access token\n    step 1-2.\n        find the run path which is a unique ID of a certain Run belonin\n        g to the project_name w/ run_name\n    step 1-3.\n        init wandb w/ project_name and the run path from 1-2\n    step 1-4\n        create an Weights & Biases Artifact and log the model file\n    step 1-5.\n        finish wandb\n    step 2. push application to the Space Hub\n    step 2-1.\n        create a repository on the HuggingFace Hub. if there is an existing r\n        epository with the given repo_name, that rpository will be overwritten.\n    step 2-2.\n        copies directory where the application related files are stored to a\n        temporary directory. Since the files could be hosted in GCS bucket, t\n        his process ensures every necessary files are located in the local fil\n        e system.\n    step 2-3.\n        replace speical tokens in every files under the given directory.\n    step 2-4.\n        clone the created or existing remote repository to the local path.\n    step 2-5.\n        remove every files under the cloned repository(local), and copies the\n        application related files to the cloned local repository path.\n    step 2-6.\n        push the updated repository to the remote Space Hub. note that the br\n        anch is always set to \"main\", so that HuggingFace Space could build t\n        he application automatically when pushed.\n    \"\"\"\n    outputs = {}\n\n    # 1-1\n    wandb.login(key=access_token)\n\n    # 1-2\n    found_run = None\n    for run in wandb.Api().runs(project_name):\n        if run.name == run_name:\n            found_run = run\n\n    if found_run:\n        print(f\"found_run: {found_run.path}\")\n\n        # 1-3\n        wandb.init(\n            project=project_name,\n            id=found_run.path[-1],\n            resume=True\n        )\n        print(f\"wandb initialized w/ project({project_name}), id({'/'.join(found_run.path)})\")\n\n        # 1-4\n        tmp_dir = \"model\"\n        os.mkdir(tmp_dir)\n        print(f\"created temporary dir({tmp_dir})\")\n\n        inside_model_path = tf.io.gfile.listdir(model_path)\n        for content_name in inside_model_path:\n            content = f\"{model_path}/{content_name}\"\n            dst_content = f\"{tmp_dir}/{content_name}\"\n\n            if tf.io.gfile.isdir(content):\n                io_utils.copy_dir(content, dst_content)\n            else:\n                tf.io.gfile.copy(content, dst_content)\n\n        print(f\"copied SavedModel from {model_path} to the temporary dir({tmp_dir})\")\n\n        compressed_model_file = \"model.tar.gz\"\n        \n        tar = tarfile.open(compressed_model_file, \"w:gz\")\n        tar.add(tmp_dir)\n        tar.close()\n        print(f\"SavedModel compressed into {compressed_model_file}\")\n        \n        art = wandb.Artifact(model_name, type=\"model\")\n        print(f\"wandb Artifact({model_name}) is created\")\n\n        art.add_file(compressed_model_file)\n        list_aliases = ast.literal_eval(aliases)\n        list_aliases.append(model_version)\n        print(list_aliases)\n        wandb.log_artifact(art, aliases=list_aliases)\n        print(f\"added {compressed_model_file} to the Artifact\")\n\n        # step 1-5\n        wandb.finish()\n        print(\"finish up w/ wandb.finish()\")\n\n        outputs[\"run_path\"] = '/'.join(found_run.path) if found_run else \"not found\"\n        outputs[\"model_name\"] = model_name\n        outputs[\"model_version\"] = model_version\n        outputs[\"file\"] = compressed_model_file\n\n        if space_config is not None:\n            if \"app_path\" not in space_config:\n                raise RuntimeError(\n                    \"the app_path is not provided. \"\n                    \"app_path is required when space_config is set.\"\n                )\n\n            if \"hf_username\" not in space_config \\\n                or \"hf_repo_name\" not in space_config:\n                raise RuntimeError(\n                    \"the username or repo_name is not provided. \"\n                )\n\n            if \"hf_access_token\" not in space_config:\n                raise RuntimeError(\n                    \"the access token to Hugging Face Hub is not provided. \"\n                )            \n\n            repo_url_prefix = \"https://huggingface.co\"\n            repo_id = f'{space_config[\"hf_username\"]}/{space_config[\"hf_repo_name\"]}'\n            repo_url = f\"{repo_url_prefix}/spaces/{repo_id}\"\n\n            app_path = space_config[\"app_path\"]\n            app_path = app_path.replace(\".\", \"/\")\n\n            access_token = space_config[\"hf_access_token\"]\n            space_sdk = space_config.get(\"space_sdk\", \"gradio\")\n\n            # step 2-1\n            _create_remote_repo(\n                access_token=access_token,\n                repo_id=repo_id,\n                space_sdk=space_sdk\n            )\n\n            # step 2-2\n            tmp_dir = tempfile.mkdtemp()\n            io_utils.copy_dir(app_path, tmp_dir)\n\n            # step 2-3\n            _replace_placeholders(\n                target_dir=tmp_dir,\n                placeholders=space_config[\"placeholders\"]\n                if \"placeholders\" in space_config\n                else None,\n                model_project=project_name,\n                model_run=found_run.path[-1],\n                model_name=model_name,\n                model_version=model_version,\n                model_filename=compressed_model_file,\n                additional_replacements=space_config.get(\"additional_replacements\", None),\n            )\n\n            # step 2-4\n            local_path = \"hf_space\"\n            repository = _clone_and_checkout(\n                repo_url=repo_url,\n                local_path=local_path,\n                access_token=access_token,\n            )\n\n            # step 2-5\n            _replace_files([tmp_dir], local_path)\n\n            # step 2-6\n            _push_to_remote_repo(\n                repo=repository,\n                commit_msg=f\"upload {model_version} model\",\n            )\n\n            outputs[\"space_url\"] = repo_url\n\n    return outputs", "\ndef deploy_model_for_wandb_model_registry(\n    access_token: str,\n    project_name: str,\n    run_name: str,\n    model_name: str,\n    aliases: List[str],\n    model_path: str,\n    model_version: str,\n    space_config: Optional[Dict[Text, Any]] = None,\n) -> Dict[str, str]:\n    \"\"\"Executes ML model deployment workflow to Weights & Biases Model\n    Registry. Refer to the WandBPusher component in component.py for g\n    eneric description of each parameter. This docstring only explains\n    how the workflow works.\n    step 1. push model to the Weights & Biases Model Registry\n    step 1-1.\n        login to the Weights & Biases w/ access token\n    step 1-2.\n        find the run path which is a unique ID of a certain Run belonin\n        g to the project_name w/ run_name\n    step 1-3.\n        init wandb w/ project_name and the run path from 1-2\n    step 1-4\n        create an Weights & Biases Artifact and log the model file\n    step 1-5.\n        finish wandb\n    step 2. push application to the Space Hub\n    step 2-1.\n        create a repository on the HuggingFace Hub. if there is an existing r\n        epository with the given repo_name, that rpository will be overwritten.\n    step 2-2.\n        copies directory where the application related files are stored to a\n        temporary directory. Since the files could be hosted in GCS bucket, t\n        his process ensures every necessary files are located in the local fil\n        e system.\n    step 2-3.\n        replace speical tokens in every files under the given directory.\n    step 2-4.\n        clone the created or existing remote repository to the local path.\n    step 2-5.\n        remove every files under the cloned repository(local), and copies the\n        application related files to the cloned local repository path.\n    step 2-6.\n        push the updated repository to the remote Space Hub. note that the br\n        anch is always set to \"main\", so that HuggingFace Space could build t\n        he application automatically when pushed.\n    \"\"\"\n    outputs = {}\n\n    # 1-1\n    wandb.login(key=access_token)\n\n    # 1-2\n    found_run = None\n    for run in wandb.Api().runs(project_name):\n        if run.name == run_name:\n            found_run = run\n\n    if found_run:\n        print(f\"found_run: {found_run.path}\")\n\n        # 1-3\n        wandb.init(\n            project=project_name,\n            id=found_run.path[-1],\n            resume=True\n        )\n        print(f\"wandb initialized w/ project({project_name}), id({'/'.join(found_run.path)})\")\n\n        # 1-4\n        tmp_dir = \"model\"\n        os.mkdir(tmp_dir)\n        print(f\"created temporary dir({tmp_dir})\")\n\n        inside_model_path = tf.io.gfile.listdir(model_path)\n        for content_name in inside_model_path:\n            content = f\"{model_path}/{content_name}\"\n            dst_content = f\"{tmp_dir}/{content_name}\"\n\n            if tf.io.gfile.isdir(content):\n                io_utils.copy_dir(content, dst_content)\n            else:\n                tf.io.gfile.copy(content, dst_content)\n\n        print(f\"copied SavedModel from {model_path} to the temporary dir({tmp_dir})\")\n\n        compressed_model_file = \"model.tar.gz\"\n        \n        tar = tarfile.open(compressed_model_file, \"w:gz\")\n        tar.add(tmp_dir)\n        tar.close()\n        print(f\"SavedModel compressed into {compressed_model_file}\")\n        \n        art = wandb.Artifact(model_name, type=\"model\")\n        print(f\"wandb Artifact({model_name}) is created\")\n\n        art.add_file(compressed_model_file)\n        list_aliases = ast.literal_eval(aliases)\n        list_aliases.append(model_version)\n        print(list_aliases)\n        wandb.log_artifact(art, aliases=list_aliases)\n        print(f\"added {compressed_model_file} to the Artifact\")\n\n        # step 1-5\n        wandb.finish()\n        print(\"finish up w/ wandb.finish()\")\n\n        outputs[\"run_path\"] = '/'.join(found_run.path) if found_run else \"not found\"\n        outputs[\"model_name\"] = model_name\n        outputs[\"model_version\"] = model_version\n        outputs[\"file\"] = compressed_model_file\n\n        if space_config is not None:\n            if \"app_path\" not in space_config:\n                raise RuntimeError(\n                    \"the app_path is not provided. \"\n                    \"app_path is required when space_config is set.\"\n                )\n\n            if \"hf_username\" not in space_config \\\n                or \"hf_repo_name\" not in space_config:\n                raise RuntimeError(\n                    \"the username or repo_name is not provided. \"\n                )\n\n            if \"hf_access_token\" not in space_config:\n                raise RuntimeError(\n                    \"the access token to Hugging Face Hub is not provided. \"\n                )            \n\n            repo_url_prefix = \"https://huggingface.co\"\n            repo_id = f'{space_config[\"hf_username\"]}/{space_config[\"hf_repo_name\"]}'\n            repo_url = f\"{repo_url_prefix}/spaces/{repo_id}\"\n\n            app_path = space_config[\"app_path\"]\n            app_path = app_path.replace(\".\", \"/\")\n\n            access_token = space_config[\"hf_access_token\"]\n            space_sdk = space_config.get(\"space_sdk\", \"gradio\")\n\n            # step 2-1\n            _create_remote_repo(\n                access_token=access_token,\n                repo_id=repo_id,\n                space_sdk=space_sdk\n            )\n\n            # step 2-2\n            tmp_dir = tempfile.mkdtemp()\n            io_utils.copy_dir(app_path, tmp_dir)\n\n            # step 2-3\n            _replace_placeholders(\n                target_dir=tmp_dir,\n                placeholders=space_config[\"placeholders\"]\n                if \"placeholders\" in space_config\n                else None,\n                model_project=project_name,\n                model_run=found_run.path[-1],\n                model_name=model_name,\n                model_version=model_version,\n                model_filename=compressed_model_file,\n                additional_replacements=space_config.get(\"additional_replacements\", None),\n            )\n\n            # step 2-4\n            local_path = \"hf_space\"\n            repository = _clone_and_checkout(\n                repo_url=repo_url,\n                local_path=local_path,\n                access_token=access_token,\n            )\n\n            # step 2-5\n            _replace_files([tmp_dir], local_path)\n\n            # step 2-6\n            _push_to_remote_repo(\n                repo=repository,\n                commit_msg=f\"upload {model_version} model\",\n            )\n\n            outputs[\"space_url\"] = repo_url\n\n    return outputs"]}
{"filename": "training_pipeline/pipeline/components/WandBPusher/executor.py", "chunked_list": ["# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"HF Pusher TFX Component Executor. The HF Pusher Executor calls \nthe workflow handler runner.deploy_model_for_hf_hub().\n\"\"\"\n", "\"\"\"\n\nimport ast\nimport time\nfrom typing import Any, Dict, List\n\nfrom tfx import types\nfrom tfx.components.pusher import executor as tfx_pusher_executor\nfrom tfx.types import artifact_utils, standard_component_specs\n", "from tfx.types import artifact_utils, standard_component_specs\n\nfrom pipeline.components.WandBPusher import runner\n\n_ACCESS_TOKEN_KEY = \"access_token\"\n_PROJECT_NAME = \"project_name\"\n_RUN_NAME = \"run_name\"\n_MODEL_NAME = \"model_name\"\n_ALIASES = \"aliases\"\n_SPACE_CONFIG_KEY = \"space_config\"", "_ALIASES = \"aliases\"\n_SPACE_CONFIG_KEY = \"space_config\"\n\nclass Executor(tfx_pusher_executor.Executor):\n    \"\"\"Pushes a model and an app to HuggingFace Model and Space Hubs respectively\"\"\"\n\n    def Do(\n        self,\n        input_dict: Dict[str, List[types.Artifact]],\n        output_dict: Dict[str, List[types.Artifact]],\n        exec_properties: Dict[str, Any],\n    ):\n        \"\"\"Overrides the tfx_pusher_executor to leverage some of utility methods\n        Args:\n          input_dict: Input dict from input key to a list of artifacts, including:\n            - model_export: a TFX input channel containing a Model artifact.\n            - model_blessing: a TFX input channel containing a ModelBlessing\n              artifact.\n          output_dict: Output dict from key to a list of artifacts, including:\n            - pushed_model: a TFX output channel containing a PushedModel arti\n              fact. It contains information where the model is published at an\n              d whether the model is pushed or not. furthermore, pushed model\n              carries the following information.\n              - pushed : integer value to denote if the model is pushed or not.\n                This is set to 0 when the input model is not blessed, and it is\n                set to 1 when the model is successfully pushed.\n          exec_properties: An optional dict of execution properties, including:\n            ...\n        \"\"\"\n        self._log_startup(input_dict, output_dict, exec_properties)\n\n        model_push = artifact_utils.get_single_instance(\n            output_dict[standard_component_specs.PUSHED_MODEL_KEY]\n        )\n\n        # if the model is not blessed\n        if not self.CheckBlessing(input_dict):\n            self._MarkNotPushed(model_push)\n            return\n        model_path = self.GetModelPath(input_dict)\n        model_version_name = f\"{int(time.time())}\"\n\n        space_config = exec_properties.get(_SPACE_CONFIG_KEY, None)\n        if space_config is not None:\n            space_config = ast.literal_eval(space_config)\n\n        pushed_properties = runner.deploy_model_for_wandb_model_registry(\n            access_token=exec_properties.get(_ACCESS_TOKEN_KEY, None),\n            project_name=exec_properties.get(_PROJECT_NAME, None),\n            run_name=exec_properties.get(_RUN_NAME, None),\n            model_name=exec_properties.get(_MODEL_NAME, None),\n            model_version=model_version_name,\n            aliases=exec_properties.get(_ALIASES, []),\n            model_path=model_path,\n            space_config=space_config,\n        )\n\n        self._MarkPushed(model_push, pushed_destination=pushed_properties[\"run_path\"])\n        for key in pushed_properties:\n            value = pushed_properties[key]\n\n            if key != \"run_path\":\n                model_push.set_string_custom_property(key, value)"]}
{"filename": "training_pipeline/pipeline/components/WandBPusher/__init__.py", "chunked_list": [""]}
{"filename": "training_pipeline/pipeline/components/WandBPusher/component_test.py", "chunked_list": ["\"\"\"Tests for TFX WandB Pusher Custom Component.\"\"\"\n\nimport tensorflow as tf\nfrom tfx.types import standard_artifacts\nfrom tfx.types import channel_utils\n\nfrom pipeline.components.WandBPusher.component import WandBPusher\n\n\nclass HFPusherTest(tf.test.TestCase):\n    def testConstruct(self):\n        test_model = channel_utils.as_channel([standard_artifacts.Model()])\n        wandb_pusher = WandBPusher(\n            access_token=\"test_access_token\",\n            run_name=\"run_name\",\n            model_name=\"model_name\",\n            aliases=\"aliases\",\n            model=test_model,\n        )\n\n        self.assertEqual(\n            standard_artifacts.PushedModel.TYPE_NAME,\n            wandb_pusher.outputs[\"pushed_model\"].type_name,\n        )", "\nclass HFPusherTest(tf.test.TestCase):\n    def testConstruct(self):\n        test_model = channel_utils.as_channel([standard_artifacts.Model()])\n        wandb_pusher = WandBPusher(\n            access_token=\"test_access_token\",\n            run_name=\"run_name\",\n            model_name=\"model_name\",\n            aliases=\"aliases\",\n            model=test_model,\n        )\n\n        self.assertEqual(\n            standard_artifacts.PushedModel.TYPE_NAME,\n            wandb_pusher.outputs[\"pushed_model\"].type_name,\n        )", "\n\nif __name__ == \"__main__\":\n    tf.test.main()"]}
{"filename": "training_pipeline/pipeline/components/WandBPusher/component.py", "chunked_list": ["\"\"\"WandB(W&B) Pusher TFX Component.\nThe WandBPusher is used to push model to Model Registry of Weights and Biases \nand optionally prototype application to HuggingFace Space Hub.\n\"\"\"\nfrom typing import Text, List, Dict, Any, Optional\n\nfrom tfx import types\nfrom tfx.dsl.components.base import base_component, executor_spec\nfrom tfx.types import standard_artifacts\nfrom tfx.types.component_spec import ChannelParameter, ExecutionParameter", "from tfx.types import standard_artifacts\nfrom tfx.types.component_spec import ChannelParameter, ExecutionParameter\n\nfrom pipeline.components.WandBPusher import executor\n\nMODEL_KEY = \"model\"\nPUSHED_MODEL_KEY = \"pushed_model\"\nMODEL_BLESSING_KEY = \"model_blessing\"\n\n\nclass WandBPusherSpec(types.ComponentSpec):\n    \"\"\"ComponentSpec for TFX HFPusher Component.\"\"\"\n\n    PARAMETERS = {\n        \"access_token\": ExecutionParameter(type=str),\n        \"project_name\": ExecutionParameter(type=str),\n        \"run_name\":  ExecutionParameter(type=str),\n        \"model_name\": ExecutionParameter(type=str),\n        \"aliases\": ExecutionParameter(type=List[str], optional=True),\n        \"space_config\": ExecutionParameter(type=Dict[Text, Any], optional=True),\n    }\n    INPUTS = {\n        MODEL_KEY: ChannelParameter(type=standard_artifacts.Model, optional=True),\n        MODEL_BLESSING_KEY: ChannelParameter(\n            type=standard_artifacts.ModelBlessing, optional=True\n        ),\n    }\n    OUTPUTS = {\n        PUSHED_MODEL_KEY: ChannelParameter(type=standard_artifacts.PushedModel),\n    }", "\n\nclass WandBPusherSpec(types.ComponentSpec):\n    \"\"\"ComponentSpec for TFX HFPusher Component.\"\"\"\n\n    PARAMETERS = {\n        \"access_token\": ExecutionParameter(type=str),\n        \"project_name\": ExecutionParameter(type=str),\n        \"run_name\":  ExecutionParameter(type=str),\n        \"model_name\": ExecutionParameter(type=str),\n        \"aliases\": ExecutionParameter(type=List[str], optional=True),\n        \"space_config\": ExecutionParameter(type=Dict[Text, Any], optional=True),\n    }\n    INPUTS = {\n        MODEL_KEY: ChannelParameter(type=standard_artifacts.Model, optional=True),\n        MODEL_BLESSING_KEY: ChannelParameter(\n            type=standard_artifacts.ModelBlessing, optional=True\n        ),\n    }\n    OUTPUTS = {\n        PUSHED_MODEL_KEY: ChannelParameter(type=standard_artifacts.PushedModel),\n    }", "\n\nclass WandBPusher(base_component.BaseComponent):\n    \"\"\"Component for pushing model and application to Weights & Biases\n    Model Registry and HuggingFace Space Hub respectively.\n\n    The `WandBPusher` is a [TFX Component](https://www.tensorflow.org/tfx\n    /guide/understanding_tfx_pipelines#component), and its primary purpose \n    is to push a model from an upstream component such as [`Trainer`](http\n    s://www.tensorflow.org/tfx/guide/trainer) to Weights & Biases Model Re\n    gistry. It also provides a secondary feature that pushes an application \n    to HuggingFace Space Hub.\n    \"\"\"\n\n    SPEC_CLASS = WandBPusherSpec\n    EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n\n    def __init__(\n        self,\n        access_token: str,\n        project_name: str,\n        run_name: str,\n        model_name: str,\n        aliases: Optional[List[str]] = None,\n        space_config: Optional[Dict[Text, Any]] = None,\n        model: Optional[types.Channel] = None,\n        model_blessing: Optional[types.Channel] = None,        \n    ):\n        \"\"\"The WandBPusher TFX component.\n\n        WandBPusher pushes a trained or blessed model to Weights & Biases M\n        odel Registry. This is designed to work as a downstream component of \n        Trainer and optionally Evaluator(optional) components. Trainer gives \n        trained model, and Evaluator gives information whether the trained m\n        odel is blessed or not after evaluation of the model. HFPusher compo\n        nent only publishes a model when it is blessed. If Evaluator is not \n        specified, the input model will always be pushed.\n\n        Args:\n        access_token: the access token obtained from Weights & Biases Refer \n            to [this document](https://wandb.ai/authorize) to know how to o\n            btain one.\n        run_name: a run name given to a particular run. This is used to ret\n            rieve the underlying unique Run ID. \n        model_name: \n        aliases: \n        space_config: optional configurations set when to push an application\n            to HuggingFace Space Hub. This is a dictionary, and the following\n            information could be set.\n            app_path: the path where the application related files are stored.\n                this should follow the form either of app.gradio.segmentation\n                or app/gradio/segmentation. This is a required parameter when\n                space_config is set. This could be a local or GCS paths.\n            space_sdk: Space Hub supports gradio, streamit, and static types\n                of application. The default is set to gradio.\n            placeholders: placeholders to replace in every files under the a\n                pp_path. This is used to replace special string with the mod\n                el related values. If this is not set, the default placehold\n                ers will be used as follows.\n                ```\n                placeholders = {\n                    \"MODEL_REPO_ID\" : \"$MODEL_REPO_ID\",\n                    \"MODEL_REPO_URL\": \"$MODEL_REPO_URL\",\n                    \"MODEL_VERSION\" : \"$MODEL_VERSION\",\n                }\n                ```\n                In this case, \"$MODEL_REPO_ID\", \"$MODEL_REPO_URL\", \"$MODEL_VE\n                RSION\" strings will be replaced with appropriate values at ru\n                ntime. If placeholders are set, custom strings will be used.\n            repo_name: the name of Space Hub repository where the application\n                will be pushed. This should be unique name under the username\n                within the Space Hub. repository is identified as {username}/\n                {repo_name}. If this is not set, the same name to the Model H\n                ub repository will be used.\n\n        model: a TFX input channel containing a Model artifact. this is usually\n            comes from the standard [`Trainer`]\n            (https://www.tensorflow.org/tfx/guide/trainer) component.\n        model_blessing: a TFX input channel containing a ModelBlessing artifact.\n            this is usually comes from the standard [`Evaluator`]\n            (https://www.tensorflow.org/tfx/guide/evaluator) component.\n        Returns:\n        a TFX output channel containing a PushedModel artifact. It contains\n        information where the model is published at and whether the model is\n        pushed or not.\n\n        Raises:\n            RuntimeError: if app_path is not set when space_config is provided.\n        Example:\n\n        Basic usage example:\n        ```py\n        trainer = Trainer(...)\n        evaluator = Evaluator(...)\n        hf_pusher = WandBPusher(\n            access_token=<YOUR-HUGGINGFACE-ACCESS-TOKEN>,\n            run_name=\"run_name\",\n            model_name=\"model_name\",\n            aliases=\"best\",\n            model=trainer.outputs[\"model\"],\n            model_blessing=evaluator.outputs[\"blessing\"],\n            space_config={\n                \"app_path\": \"apps.gradio.semantic_segmentation\"\n            }\n        )\n        ```\n        \"\"\"\n\n        pushed_model = types.Channel(type=standard_artifacts.PushedModel)\n\n        spec = WandBPusherSpec(\n            access_token=access_token,\n            project_name=project_name,\n            run_name=run_name,\n            model_name=model_name,\n            aliases=aliases,\n            space_config=space_config,\n            model=model,\n            model_blessing=model_blessing,\n            pushed_model=pushed_model,\n        )\n\n        super().__init__(spec=spec)"]}
{"filename": "training_pipeline/huggingface/apps/gradio/app.py", "chunked_list": ["import tarfile\nimport wandb\n\nimport gradio as gr\nimport numpy as np\nfrom PIL import Image\nimport tensorflow as tf\nfrom transformers import ViTFeatureExtractor\n\nPRETRAIN_CHECKPOINT = \"google/vit-base-patch16-224-in21k\"", "\nPRETRAIN_CHECKPOINT = \"google/vit-base-patch16-224-in21k\"\nfeature_extractor = ViTFeatureExtractor.from_pretrained(PRETRAIN_CHECKPOINT)\n\nMODEL = None \n\nRESOLTUION = 224\n\nlabels = []\n\nwith open(r\"labels.txt\", \"r\") as fp:\n    for line in fp:\n        labels.append(line[:-1])", "labels = []\n\nwith open(r\"labels.txt\", \"r\") as fp:\n    for line in fp:\n        labels.append(line[:-1])\n\ndef normalize_img(\n    img, mean=feature_extractor.image_mean, std=feature_extractor.image_std\n):\n    img = img / 255\n    mean = tf.constant(mean)\n    std = tf.constant(std)\n    return (img - mean) / std", "\ndef preprocess_input(image):\n    image = np.array(image)\n    image = tf.convert_to_tensor(image)\n\n    image = tf.image.resize(image, (RESOLTUION, RESOLTUION))\n    image = normalize_img(image)\n\n    image = tf.transpose(\n        image, (2, 0, 1)\n    )  # Since HF models are channel-first.\n\n    return {\n        \"pixel_values\": tf.expand_dims(image, 0)\n    }", "\ndef get_predictions(wb_token, image):\n    global MODEL\n    \n    if MODEL is None:\n        wandb.login(key=wb_token)\n        wandb.init(project=\"$MODEL_PROJECT\", id=\"$MODEL_RUN\", resume=True)\n        path = wandb.use_artifact('tfx-vit-pipeline/$MODEL_NAME:$MODEL_VERSION', type='model').download()\n\n        tar = tarfile.open(f\"{path}/$MODEL_FILENAME\")\n        tar.extractall(path=\".\")\n\n        MODEL = tf.keras.models.load_model(\"./model\")\n    \n    preprocessed_image = preprocess_input(image)\n    prediction = MODEL.predict(preprocessed_image)\n    probs = tf.nn.softmax(prediction['logits'], axis=1)\n\n    confidences = {labels[i]: float(probs[0][i]) for i in range(3)}\n    return confidences", "\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## Simple demo for a Image Classification of the Beans Dataset with HF ViT model\")\n\n    wb_token_if = gr.Textbox(interactive=True, label=\"Your Weight & Biases API Key\")\n\n    with gr.Row():\n        image_if = gr.Image()\n        label_if = gr.Label(num_top_classes=3)\n\n    classify_if = gr.Button()\n\n    classify_if.click(\n        get_predictions,\n        [wb_token_if, image_if],\n        label_if\n    )", "\ndemo.launch(debug=True)"]}
{"filename": "training_pipeline/modules/preprocessing.py", "chunked_list": ["import tensorflow as tf\nfrom .common import IMAGE_TFREC_KEY, LABEL_TFREC_KEY\nfrom .common import IMAGE_MODEL_KEY, LABEL_MODEL_KEY\nfrom .hyperparams import INPUT_IMG_SIZE\n\n\ndef preprocessing_fn(inputs):\n    \"\"\"tf.transform's callback function for preprocessing inputs.\n    Args:\n      inputs: map from feature keys to raw not-yet-transformed features.\n    Returns:\n      Map from string feature key to transformed feature operations.\n    \"\"\"\n    # print(inputs)\n    outputs = {}\n\n    inputs[IMAGE_TFREC_KEY] = tf.image.resize(\n        inputs[IMAGE_TFREC_KEY], [INPUT_IMG_SIZE, INPUT_IMG_SIZE]\n    )\n\n    inputs[IMAGE_TFREC_KEY] = inputs[IMAGE_TFREC_KEY] / 255.0\n    inputs[IMAGE_TFREC_KEY] = tf.transpose(inputs[IMAGE_TFREC_KEY], [0, 3, 1, 2])\n\n    outputs[IMAGE_MODEL_KEY] = inputs[IMAGE_TFREC_KEY]\n    outputs[LABEL_MODEL_KEY] = inputs[LABEL_TFREC_KEY]\n\n    return outputs", ""]}
{"filename": "training_pipeline/modules/signatures.py", "chunked_list": ["from typing import Dict\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\nfrom transformers import ViTFeatureExtractor\n\nfrom .common import PRETRAIN_CHECKPOINT\nfrom .common import CONCRETE_INPUT\nfrom .common import LABEL_MODEL_KEY\n", "from .common import LABEL_MODEL_KEY\n\nfeature_extractor = ViTFeatureExtractor.from_pretrained(PRETRAIN_CHECKPOINT)\n\n\ndef _normalize_img(\n    img, mean=feature_extractor.image_mean, std=feature_extractor.image_std\n):\n    img = img / 255\n    mean = tf.constant(mean)\n    std = tf.constant(std)\n    return (img - mean) / std", "\n\ndef _preprocess_serving(string_input):\n    decoded_input = tf.io.decode_base64(string_input)\n    decoded = tf.io.decode_jpeg(decoded_input, channels=3)\n    resized = tf.image.resize(decoded, size=(224, 224))\n    normalized = _normalize_img(resized)\n    normalized = tf.transpose(\n        normalized, (2, 0, 1)\n    )  # Since HF models are channel-first.\n    return normalized", "\n\n@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\ndef _preprocess_fn(string_input):\n    decoded_images = tf.map_fn(\n        _preprocess_serving, string_input, dtype=tf.float32, back_prop=False\n    )\n    return {CONCRETE_INPUT: decoded_images}\n\n\ndef model_exporter(model: tf.keras.Model):\n    m_call = tf.function(model.call).get_concrete_function(\n        tf.TensorSpec(shape=[None, 3, 224, 224], dtype=tf.float32, name=CONCRETE_INPUT)\n    )\n\n    @tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n    def serving_fn(string_input):\n        labels = tf.constant(list(model.config.id2label.values()), dtype=tf.string)\n        images = _preprocess_fn(string_input)\n\n        predictions = m_call(**images)\n        indices = tf.argmax(predictions.logits, axis=1)\n        pred_source = tf.gather(params=labels, indices=indices)\n        probs = tf.nn.softmax(predictions.logits, axis=1)\n        pred_confidence = tf.reduce_max(probs, axis=1)\n        return {\"label\": pred_source, \"confidence\": pred_confidence}\n\n    return serving_fn", "\n\ndef model_exporter(model: tf.keras.Model):\n    m_call = tf.function(model.call).get_concrete_function(\n        tf.TensorSpec(shape=[None, 3, 224, 224], dtype=tf.float32, name=CONCRETE_INPUT)\n    )\n\n    @tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n    def serving_fn(string_input):\n        labels = tf.constant(list(model.config.id2label.values()), dtype=tf.string)\n        images = _preprocess_fn(string_input)\n\n        predictions = m_call(**images)\n        indices = tf.argmax(predictions.logits, axis=1)\n        pred_source = tf.gather(params=labels, indices=indices)\n        probs = tf.nn.softmax(predictions.logits, axis=1)\n        pred_confidence = tf.reduce_max(probs, axis=1)\n        return {\"label\": pred_source, \"confidence\": pred_confidence}\n\n    return serving_fn", "\n\ndef transform_features_signature(\n    model: tf.keras.Model, tf_transform_output: tft.TFTransformOutput\n):\n    \"\"\"\n    transform_features_signature simply returns a function that transforms\n    any data of the type of tf.Example which is denoted as the type of sta\n    ndard_artifacts.Examples in TFX. The purpose of this function is to ap\n    ply Transform Graph obtained from Transform component to the data prod\n    uced by ImportExampleGen. This function will be used in the Evaluator\n    component, so the raw evaluation inputs from ImportExampleGen can be a\n    pporiately transformed that the model could understand.\n    \"\"\"\n\n    # basically, what Transform component emits is a SavedModel that knows\n    # how to transform data. transform_features_layer() simply returns the\n    # layer from the Transform.\n    model.tft_layer = tf_transform_output.transform_features_layer()\n\n    @tf.function(\n        input_signature=[tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")]\n    )\n    def serve_tf_examples_fn(serialized_tf_examples):\n        \"\"\"\n        raw_feature_spec returns a set of feature maps(dict) for the input\n        TFRecords based on the knowledge that Transform component has lear\n        ned(learn doesn't mean training here). By using this information,\n        the raw data from ImportExampleGen could be parsed with tf.io.parse\n        _example utility function.\n        Then, it is passed to the model.tft_layer, so the final output we\n        get is the transformed data of the raw input.\n        \"\"\"\n        feature_spec = tf_transform_output.raw_feature_spec()\n        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n\n        transformed_features = model.tft_layer(parsed_features)\n\n        return transformed_features\n\n    return serve_tf_examples_fn", "\n\ndef tf_examples_serving_signature(model, tf_transform_output):\n    \"\"\"\n    tf_examples_serving_signature simply returns a function that performs\n    data transformation(preprocessing) and model prediction in a sequential\n    manner. How data transformation is done is idential to the process of\n    transform_features_signature function.\n    \"\"\"\n\n    model.tft_layer = tf_transform_output.transform_features_layer()\n\n    @tf.function(\n        input_signature=[tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")]\n    )\n    def serve_tf_examples_fn(\n        serialized_tf_example: tf.Tensor,\n    ) -> Dict[str, tf.Tensor]:\n        raw_feature_spec = tf_transform_output.raw_feature_spec()\n        raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n\n        transformed_features = model.tft_layer(raw_features)\n        logits = model(transformed_features).logits\n\n        return {LABEL_MODEL_KEY: logits}\n\n    return serve_tf_examples_fn", ""]}
{"filename": "training_pipeline/modules/train.py", "chunked_list": ["import tensorflow as tf\nimport keras_tuner\nimport tensorflow_transform as tft\nfrom tfx.components.trainer.fn_args_utils import FnArgs\n\nimport wandb\n\nfrom .train_data import input_fn\nfrom .ViT import MyHyperModel\nfrom .signatures import (", "from .ViT import MyHyperModel\nfrom .signatures import (\n    model_exporter,\n    transform_features_signature,\n    tf_examples_serving_signature,\n)\n\nfrom .hyperparams import TRAIN_BATCH_SIZE, EVAL_BATCH_SIZE\nfrom .hyperparams import TRAIN_LENGTH, EVAL_LENGTH\nfrom .hyperparams import EPOCHS", "from .hyperparams import TRAIN_LENGTH, EVAL_LENGTH\nfrom .hyperparams import EPOCHS\n\nfrom .utils import INFO\n\n\ndef run_fn(fn_args: FnArgs):\n    hp = keras_tuner.HyperParameters.from_config(fn_args.hyperparameters)\n    INFO(f\"HyperParameters for training: {hp.get_config()}\")\n\n    wandb_project = None\n    if fn_args.custom_config and \"wandb\" in fn_args.custom_config:\n        wandb_configs = fn_args.custom_config[\"wandb\"]\n\n        wandb.login(key=wandb_configs[\"API_KEY\"])\n        wandb_project = wandb_configs[\"PROJECT\"]\n\n    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n    train_dataset = input_fn(\n        fn_args.train_files,\n        fn_args.data_accessor,\n        tf_transform_output,\n        is_train=True,\n        batch_size=TRAIN_BATCH_SIZE,\n    )\n\n    eval_dataset = input_fn(\n        fn_args.eval_files,\n        fn_args.data_accessor,\n        tf_transform_output,\n        is_train=False,\n        batch_size=EVAL_BATCH_SIZE,\n    )\n\n    optimizer_type = hp.get(\"optimizer_type\")\n    learning_rate = hp.get(\"learning_rate\")\n    weight_decay = hp.get(\"weight_decay\")\n    epochs = hp.get(\"fulltrain_epochs\")\n    INFO(f\"hps: {optimizer_type}, {learning_rate}, {weight_decay}, {epochs}\")\n    callbacks = [tf.keras.callbacks.EarlyStopping(patience=2)]\n\n    if wandb_project:\n        unique_id = wandb_configs[\"FINAL_RUN_ID\"]\n\n        wandb.init(\n            project=wandb_project,\n            config=hp.values,\n            name=unique_id,\n        )\n    \n        wandb.log({\"optimizer_type\": optimizer_type})\n        wandb.log({\"learning_rate\": learning_rate})\n        wandb.log({\"weight_decay\": weight_decay})\n        callbacks.append(wandb.keras.WandbMetricsLogger(log_freq='epoch'))\n\n    model = MyHyperModel().build(hp)\n    model.fit(\n        train_dataset,\n        steps_per_epoch=TRAIN_LENGTH // TRAIN_BATCH_SIZE,\n        validation_data=eval_dataset,\n        validation_steps=EVAL_LENGTH // TRAIN_BATCH_SIZE,\n        epochs=epochs,\n        callbacks=callbacks,\n    )\n\n    if wandb_project:\n        wandb.finish()\n\n    model.save(\n        fn_args.serving_model_dir,\n        save_format=\"tf\",\n        signatures={\n            \"serving_default\": model_exporter(model),\n            \"transform_features\": transform_features_signature(\n                model, tf_transform_output\n            ),\n            \"from_examples\": tf_examples_serving_signature(model, tf_transform_output),\n        },\n    )", ""]}
{"filename": "training_pipeline/modules/train_data.py", "chunked_list": ["from typing import List\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx_bsl.tfxio import dataset_options\nfrom tfx.components.trainer.fn_args_utils import DataAccessor\n\nfrom .utils import INFO\nfrom .common import LABEL_MODEL_KEY", "from .utils import INFO\nfrom .common import LABEL_MODEL_KEY\nfrom .hyperparams import BATCH_SIZE\n\n\ndef input_fn(\n    file_pattern: List[str],\n    data_accessor: DataAccessor,\n    tf_transform_output: tft.TFTransformOutput,\n    is_train: bool = False,\n    batch_size: int = BATCH_SIZE,\n) -> tf.data.Dataset:\n    INFO(f\"Reading data from: {file_pattern}\")\n\n    dataset = data_accessor.tf_dataset_factory(\n        file_pattern,\n        dataset_options.TensorFlowDatasetOptions(\n            batch_size=batch_size, label_key=LABEL_MODEL_KEY\n        ),\n        tf_transform_output.transformed_metadata.schema,\n    )\n\n    return dataset", ""]}
{"filename": "training_pipeline/modules/tuning.py", "chunked_list": ["import keras_tuner\nimport tensorflow_transform as tft\nfrom tfx.components.trainer.fn_args_utils import FnArgs\nfrom tfx.v1.components import TunerFnResult\n\nimport wandb\n\nfrom .train_data import input_fn\nfrom .ViT import MyHyperModel, MyTuner\n", "from .ViT import MyHyperModel, MyTuner\n\nfrom .hyperparams import TRAIN_BATCH_SIZE, EVAL_BATCH_SIZE\nfrom .hyperparams import TRAIN_LENGTH, EVAL_LENGTH\nfrom .hyperparams import get_hyperparameters\n\n\ndef tuner_fn(fn_args: FnArgs) -> TunerFnResult:\n    wandb_project = None\n    if fn_args.custom_config and \"wandb\" in fn_args.custom_config:\n        wandb_configs = fn_args.custom_config[\"wandb\"]\n\n        wandb.login(key=wandb_configs[\"API_KEY\"])\n        wandb_project = wandb_configs[\"PROJECT\"]\n\n    hyperparameters = fn_args.custom_config[\"hyperparameters\"]\n    tuner_configs = fn_args.custom_config[\"tuner\"]\n\n    tuner = MyTuner(\n        wandb_project,\n        MyHyperModel(),\n        max_trials=tuner_configs[\"num_trials\"],\n        hyperparameters=get_hyperparameters(hyperparameters),\n        allow_new_entries=False,\n        objective=keras_tuner.Objective(\"val_accuracy\", \"max\"),\n        directory=fn_args.working_dir,\n        project_name=\"ViT MLOps Advanced Part2\",\n    )\n\n    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n\n    train_dataset = input_fn(\n        fn_args.train_files,\n        fn_args.data_accessor,\n        tf_transform_output,\n        is_train=True,\n        batch_size=TRAIN_BATCH_SIZE,\n    )\n\n    eval_dataset = input_fn(\n        fn_args.eval_files,\n        fn_args.data_accessor,\n        tf_transform_output,\n        is_train=False,\n        batch_size=EVAL_BATCH_SIZE,\n    )\n\n    return TunerFnResult(\n        tuner=tuner,\n        fit_kwargs={\n            \"x\": train_dataset,\n            \"validation_data\": eval_dataset,\n            \"steps_per_epoch\": 1,\n            \"validation_steps\": 1,\n        },\n    )", ""]}
{"filename": "training_pipeline/modules/hyperparams.py", "chunked_list": ["import keras_tuner\n\nEPOCHS = 10\nBATCH_SIZE = 32\n\nTRAIN_BATCH_SIZE = 32\nEVAL_BATCH_SIZE = 32\n\nTRAIN_LENGTH = 1034\nEVAL_LENGTH = 128", "TRAIN_LENGTH = 1034\nEVAL_LENGTH = 128\n\nINPUT_IMG_SIZE = 224\n\ndef get_hyperparameters(hyperparameters) -> keras_tuner.HyperParameters:\n    hp_set = keras_tuner.HyperParameters()\n\n    for hp in hyperparameters:\n        if hyperparameters[hp][\"type\"] == \"choice\":\n            hp_set.Choice(\n                hp,\n                hyperparameters[hp][\"values\"]\n            )\n        elif hyperparameters[hp][\"type\"] == \"float\":\n            hp_set.Float(\n                hp,\n                hyperparameters[hp][\"min_value\"],\n                hyperparameters[hp][\"max_value\"],\n                sampling=hyperparameters[hp][\"sampling\"],\n                step=hyperparameters[hp][\"step\"]\n            )\n\n    return hp_set", ""]}
{"filename": "training_pipeline/modules/utils.py", "chunked_list": ["import absl\n\n\ndef INFO(text: str):\n    absl.logging.info(text)\n"]}
{"filename": "training_pipeline/modules/ViT.py", "chunked_list": ["import tensorflow as tf\nimport keras_tuner\nfrom transformers import TFViTForImageClassification\n\nimport wandb\n\nfrom .common import LABELS\nfrom .common import PRETRAIN_CHECKPOINT\nfrom .utils import INFO\n\nclass MyHyperModel(keras_tuner.HyperModel):\n  def build(self, hp):\n    id2label={str(i): c for i, c in enumerate(LABELS)}\n    label2id={c: str(i) for i, c in enumerate(LABELS)}\n\n    model = TFViTForImageClassification.from_pretrained(\n      PRETRAIN_CHECKPOINT,\n      num_labels=len(LABELS),\n      label2id=label2id,\n      id2label=id2label,\n    )\n\n    model.layers[0].trainable=False\n\n    with hp.conditional_scope(\"optimizer_type\", [\"AdamW\"]):\n      optimizer = tf.keras.optimizers.experimental.AdamW(\n          learning_rate= hp.get(\"learning_rate\"),\n          weight_decay=hp.get(\"weight_decay\"),\n      )\n    with hp.conditional_scope(\"optimizer_type\", [\"Adam\"]):\n      optimizer = tf.keras.optimizers.Adam(\n          learning_rate=hp.get(\"learning_rate\"),\n          weight_decay=hp.get(\"weight_decay\"),\n      )      \n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n\n    INFO(model.summary())\n\n    return model", "from .utils import INFO\n\nclass MyHyperModel(keras_tuner.HyperModel):\n  def build(self, hp):\n    id2label={str(i): c for i, c in enumerate(LABELS)}\n    label2id={c: str(i) for i, c in enumerate(LABELS)}\n\n    model = TFViTForImageClassification.from_pretrained(\n      PRETRAIN_CHECKPOINT,\n      num_labels=len(LABELS),\n      label2id=label2id,\n      id2label=id2label,\n    )\n\n    model.layers[0].trainable=False\n\n    with hp.conditional_scope(\"optimizer_type\", [\"AdamW\"]):\n      optimizer = tf.keras.optimizers.experimental.AdamW(\n          learning_rate= hp.get(\"learning_rate\"),\n          weight_decay=hp.get(\"weight_decay\"),\n      )\n    with hp.conditional_scope(\"optimizer_type\", [\"Adam\"]):\n      optimizer = tf.keras.optimizers.Adam(\n          learning_rate=hp.get(\"learning_rate\"),\n          weight_decay=hp.get(\"weight_decay\"),\n      )      \n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n\n    INFO(model.summary())\n\n    return model", "\nclass MyTuner(keras_tuner.RandomSearch):\n  def __init__(self, wandb_project, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n\n    self.wandb_project = wandb_project\n\n  def run_trial(self, trial, *args, **kwargs):\n    hp = trial.hyperparameters\n    model = self.hypermodel.build(hp)\n\n    optimizer_type = hp.get(\"optimizer_type\")\n    learning_rate = hp.get(\"learning_rate\")\n    weight_decay = hp.get(\"weight_decay\")\n    epochs = hp.get(\"finetune_epochs\")\n\n    callbacks = []\n    if self.wandb_project:\n      log_name = f\"tuning@opt-{optimizer_type}@lr-{learning_rate}@wd-{weight_decay}\"\n      wandb.init(\n        project=self.wandb_project,\n        config=hp.values,\n        name=log_name,\n      )\n\n      wandb.log({\"optimizer_type\": optimizer_type})\n      wandb.log({\"learning_rate\": learning_rate})\n      wandb.log({\"weight_decay\": weight_decay})\n\n      callbacks.append(wandb.keras.WandbMetricsLogger(log_freq='epoch'))\n\n    result = self.hypermodel.fit(\n      hp,\n      model,\n      *args,\n      epochs=epochs,\n      callbacks=callbacks,\n      **kwargs\n    )\n\n    if self.wandb_project:\n      wandb.finish()\n      \n    return result"]}
{"filename": "training_pipeline/modules/common.py", "chunked_list": ["IMAGE_TFREC_KEY = \"image\"\nIMAGE_SHAPE_TFREC_KEY = \"image_shape\"\nLABEL_TFREC_KEY = \"label\"\n\nMODEL_INPUT_IMAGE_KEY = \"pixel_values\"\nMODEL_INPUT_LABEL_KEY = \"labels\"\nIMAGE_MODEL_KEY = \"pixel_values\"\nLABEL_MODEL_KEY = \"labels\"\n\nCONCRETE_INPUT = \"pixel_values\"", "\nCONCRETE_INPUT = \"pixel_values\"\n\nPRETRAIN_CHECKPOINT = \"google/vit-base-patch16-224-in21k\"\n\nLABELS = [\"angular_leaf_spot\", \"bean_rust\", \"healthy\"]\n"]}
