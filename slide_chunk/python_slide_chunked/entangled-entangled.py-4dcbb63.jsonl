{"filename": "test/test_properties.py", "chunked_list": ["from entangled.properties import read_properties, Id, Class, Attribute\n\n\ndef test_id():\n    assert read_properties(\"#myid\") == [Id(\"myid\")]\n    assert str(Id(\"myid\")) == \"#myid\"\n\n\ndef test_class():\n    assert read_properties(\".myclass\") == [Class(\"myclass\")]\n    assert str(Class(\"myclass\") == \".myclass\")", "def test_class():\n    assert read_properties(\".myclass\") == [Class(\"myclass\")]\n    assert str(Class(\"myclass\") == \".myclass\")\n\n\ndef test_attribute():\n    assert read_properties(\"key=value\") == [Attribute(\"key\", \"value\")]\n    assert read_properties('key =   \"value\"') == [Attribute(\"key\", \"value\")]\n\n\ndef test_properties():\n    assert read_properties(\".class #id key=value\") == [\n        Class(\"class\"),\n        Id(\"id\"),\n        Attribute(\"key\", \"value\"),\n    ]", "\n\ndef test_properties():\n    assert read_properties(\".class #id key=value\") == [\n        Class(\"class\"),\n        Id(\"id\"),\n        Attribute(\"key\", \"value\"),\n    ]\n", ""]}
{"filename": "test/test_cycles.py", "chunked_list": ["from pathlib import Path\nimport pytest\n\nfrom entangled.tangle import tangle_ref\nfrom entangled.markdown_reader import MarkdownReader\nfrom entangled.errors.user import CyclicReference\nfrom entangled.document import AnnotationMethod\n\n\nmd_source = \"\"\"", "\nmd_source = \"\"\"\nThis should raise a `CyclicReference` error.\n\n``` {.python #hello}\n<<hello>>\n```\n\nSo should this:\n", "So should this:\n\n``` {.python #phobos}\n<<deimos>>\n```\n\n``` {.python #deimos}\n<<phobos>>\n```\n", "```\n\nalso when tangling from something else:\n\n``` {.python #mars}\n<<phobos>>\n```\n\nWhat should not throw an error is doubling a reference:\n", "What should not throw an error is doubling a reference:\n\n``` {.python #helium}\n<<electron>>\n<<electron>>\n```\n\n``` {.python #electron}\nnegative charge\n```", "negative charge\n```\n\"\"\"\n\n\ndef test_cycles():\n    mr = MarkdownReader(\"-\")\n    mr.run(md_source)\n    refs = mr.reference_map\n\n    with pytest.raises(CyclicReference):\n        tangle_ref(refs, \"hello\")\n\n    with pytest.raises(CyclicReference):\n        result, _ = tangle_ref(refs, \"phobos\")\n        print(result)\n\n    try:\n        tangle_ref(refs, \"mars\")\n    except CyclicReference as e:\n        assert e.cycle == [\"mars\", \"phobos\", \"deimos\"]\n\n    result, _ = tangle_ref(refs, \"helium\", AnnotationMethod.NAKED)\n    assert result == \"negative charge\\nnegative charge\"", ""]}
{"filename": "test/test_markdown_reader.py", "chunked_list": ["from entangled.markdown_reader import MarkdownReader\nfrom entangled.commands.stitch import stitch_markdown\nfrom entangled.main import configure\n\n\ndef test_retrieve_same_content(data):\n    file = data / \"hello-world\" / \"hello-world.md\"\n    with open(file, \"r\") as f:\n        md = MarkdownReader(str(file))\n        markdown = f.read()\n        md.run(markdown)\n        assert stitch_markdown(md.reference_map, md.content) == markdown", "\n\nmd_ignore = \"\"\"\nhello\n\n~~~markdown\nThis should be ignored.\n\n``` {.python #hello}\n```", "``` {.python #hello}\n```\n~~~\n\nThis shouldn't\n\n``` {.python #goodbye}\n```\n\"\"\"\n", "\"\"\"\n\n\ndef test_ignore():\n    mr = MarkdownReader(\"-\")\n    mr.run(md_ignore)\n\n    assert \"hello\" not in mr.reference_map\n    assert \"goodbye\" in mr.reference_map\n", "\n\nmd_backtics = \"\"\"\n``` {.python #hello}\n  ```\n```\n\"\"\"\n\n\ndef test_backtic_content():\n    mr = MarkdownReader(\"-\")\n    mr.run(md_backtics)\n    assert next(mr.reference_map[\"hello\"]).source == \"  ```\"", "\ndef test_backtic_content():\n    mr = MarkdownReader(\"-\")\n    mr.run(md_backtics)\n    assert next(mr.reference_map[\"hello\"]).source == \"  ```\"\n\n\nmd_unknown_lang = \"\"\"\n``` {.too_obscure #hello}\n```", "``` {.too_obscure #hello}\n```\n\"\"\"\n\n\ndef test_unknown_language():\n    mr = MarkdownReader(\"-\")\n    mr.run(md_unknown_lang)\n    assert len(mr.reference_map.map) == 0\n", ""]}
{"filename": "test/test_watch_dir.py", "chunked_list": ["from entangled.config import config\nfrom entangled.status import find_watch_dirs, list_input_files\nfrom contextlib import chdir\nfrom entangled.commands.tangle import tangle\nfrom pathlib import Path\n\nindex_md_1 = \"\"\"\n# Test\n\n``` {.c file=src/test.c}", "\n``` {.c file=src/test.c}\n#include <stdio.h>\nint main() { printf(\"Hello, World!\\\\n\"); return 0; }\n```\n\"\"\"\n\nindex_md_2 = \"\"\"\n``` {.makefile file=Makefile}\n.RECIPEPREFIX = >", "``` {.makefile file=Makefile}\n.RECIPEPREFIX = >\n\n%.o: %.c\n> gcc -c $< -o $@\n\nhello: test.o\n> gcc $^ -o $@\n```\n\"\"\"", "```\n\"\"\"\n\ndata_md = \"\"\"\nDon't tangle me!\n\"\"\"\n\ndef test_watch_dirs(tmp_path):\n    with chdir(tmp_path):\n        Path(\"./docs\").mkdir()\n        Path(\"./data\").mkdir()\n        Path(\"./docs/index.md\").write_text(index_md_1)\n        Path(\"./data/data.md\").write_text(data_md)\n        with config(watch_list=[\"docs/*.md\"]):\n            assert set(find_watch_dirs()) == set([Path(\"./docs\")])\n            tangle()\n            assert set(find_watch_dirs()) == set([Path(\"./docs\"), Path(\"./src\")])\n            Path(\"./docs/index.md\").write_text(index_md_1 + \"\\n\" + index_md_2)\n            tangle()\n            assert set(find_watch_dirs()) == set([Path(\".\"), Path(\"./docs\"), Path(\"./src\")])\n\n            assert sorted(list_input_files()) == [Path(\"./docs/index.md\")]", "    \n"]}
{"filename": "test/test_modes.py", "chunked_list": ["from contextlib import chdir\nfrom entangled.commands import tangle, stitch\nfrom entangled.config import config\nfrom entangled.filedb import stat\nfrom entangled.errors.user import UserError\n\nimport pytest\nfrom time import sleep\nfrom pathlib import Path\n", "from pathlib import Path\n\n\ndef test_modes(tmp_path: Path):\n    with chdir(tmp_path):\n        (tmp_path / \"entangled.toml\").write_text(\n            'version = \"2.0\"\\n' 'watch_list = [\"docs/**/*.md\"]\\n'\n        )\n        config.read()\n        md = tmp_path / \"docs\" / \"index.md\"\n        md.parent.mkdir(parents=True, exist_ok=True)\n        md.write_text(\"``` {.python file=src/hello.py}\\n\" 'print(\"hello\")\\n' \"```\\n\")\n\n        tangle()\n        sleep(0.1)\n        target = tmp_path / \"src\" / \"hello.py\"\n        assert target.exists()\n        hello_stat1 = stat(target)\n        hello_src = target.read_text().splitlines()\n        assert hello_src[1] == 'print(\"hello\")'\n\n        md.write_text(\"``` {.python file=src/hello.py}\\n\" 'print(\"goodbye\")\\n' \"```\\n\")\n        sleep(0.1)\n        md_stat1 = stat(md)\n\n        tangle(show=True)\n        sleep(0.1)\n        hello_stat2 = stat(target)\n        assert hello_stat2 == hello_stat1\n        assert not (hello_stat2 > hello_stat1)\n\n        hello_src[1] = 'print(\"bonjour\")'\n        (tmp_path / \"src\" / \"hello.py\").write_text(\"\\n\".join(hello_src))\n        sleep(0.1)\n        hello_stat1 = stat(target)\n\n        # with pytest.raises(UserError):\n        tangle()\n        sleep(0.1)\n        hello_stat2 = stat(target)\n        assert hello_stat2 == hello_stat1\n        assert not (hello_stat2 > hello_stat1)\n\n        # with pytest.raises(UserError):\n        stitch()\n        sleep(0.1)\n        md_stat2 = stat(md)\n        print(md.read_text())\n        assert md_stat1 == md_stat2\n        assert not (md_stat2 > md_stat1)\n\n        stitch(force=True)\n        sleep(0.1)\n        md_stat2 = stat(md)\n        assert md_stat1 != md_stat2\n        assert md_stat2 > md_stat1", ""]}
{"filename": "test/__init__.py", "chunked_list": [""]}
{"filename": "test/test_config.py", "chunked_list": ["from entangled.config.version import Version\nfrom entangled.config.language import Language, Comment\nfrom entangled.config import config, Config, AnnotationMethod, default\nfrom entangled.commands import tangle\nfrom entangled.construct import construct\n\nfrom contextlib import chdir\nfrom time import sleep\nfrom pathlib import Path\n", "from pathlib import Path\n\n\ndef test_config_constructable():\n    assert construct(Version, \"1.2.3\") == Version((1, 2, 3))\n    assert construct(\n        Language,\n        {\"name\": \"French\", \"identifiers\": [\"fr\"], \"comment\": {\"open\": \"excusez moi\"}},\n    ) == Language(\"French\", [\"fr\"], Comment(\"excusez moi\"))\n    assert construct(Config, {\"version\": \"2.0\"}) == Config(version=Version((2, 0)))\n    assert construct(Config, {\"version\": \"2.0\", \"annotation\": \"naked\"}) == Config(\n        version=Version((2, 0)), annotation=AnnotationMethod.NAKED\n    )", "\n\nconfig_with_language = \"\"\"\nversion = \"2.0\"\nannotation = \"naked\"\n\n[[languages]]\nname = \"Fish\"\nidentifiers = [\"fish\"]\ncomment = { open = \"#\" }", "identifiers = [\"fish\"]\ncomment = { open = \"#\" }\n\"\"\"\n\nmd_source = \"\"\"\n``` {.fish file=test.fish}\necho hello world\n```\n\"\"\"\n", "\"\"\"\n\n\ndef test_new_language(tmp_path):\n    with chdir(tmp_path):\n        Path(\"entangled.toml\").write_text(config_with_language)\n        Path(\"test.md\").write_text(md_source)\n        sleep(0.1)\n        config.read()\n        assert config.annotation == AnnotationMethod.NAKED\n        tangle()\n        sleep(0.1)\n        assert Path(\"test.fish\").exists()\n        assert Path(\"test.fish\").read_text() == \"echo hello world\"", "\n\nconfig_with_more = \"\"\"\n# required: the minimum version of Entangled\nversion = \"2.0\"            \n\n# default watch_list is [\"**/*.md\"]\nwatch_list = [\"docs/**/*.md\"]\n\n[[languages]]", "\n[[languages]]\nname = \"Custom Java\"\nidentifiers = [\"java\"]\ncomment = { open = \"//\" }\n\n[[languages]]\nname = \"XML\"\nidentifiers = [\"xml\", \"html\", \"svg\"]\ncomment = { open = \"<!--\", close = \"-->\" }", "identifiers = [\"xml\", \"html\", \"svg\"]\ncomment = { open = \"<!--\", close = \"-->\" }\n\"\"\"\n\n\ndef test_more_language(tmp_path):\n    with chdir(tmp_path):\n        Path(\"entangled.toml\").write_text(config_with_more)\n        sleep(0.1)\n        config.read()\n\n        assert config.get_language(\"html\").name == \"XML\"\n        assert config.get_language(\"java\").name == \"Custom Java\"", "\n\nconfig_in_pyproject = \"\"\"\n[tool.entangled]\nversion = \"2.0\"\nwatch_list = [\"docs/*.md\"]\n\"\"\"\n\n\ndef test_pyproject_toml(tmp_path):\n    with chdir(tmp_path):\n        Path(\"pyproject.toml\").write_text(\"answer=42\")\n        sleep(0.1)\n        config.read()\n\n        assert config.config == default\n\n        Path(\"pyproject.toml\").write_text(config_in_pyproject)\n        sleep(0.1)\n        config.read()\n\n        assert config.watch_list == [\"docs/*.md\"]", "\ndef test_pyproject_toml(tmp_path):\n    with chdir(tmp_path):\n        Path(\"pyproject.toml\").write_text(\"answer=42\")\n        sleep(0.1)\n        config.read()\n\n        assert config.config == default\n\n        Path(\"pyproject.toml\").write_text(config_in_pyproject)\n        sleep(0.1)\n        config.read()\n\n        assert config.watch_list == [\"docs/*.md\"]", ""]}
{"filename": "test/test_cli.py", "chunked_list": ["from entangled.main import cli\nfrom entangled.version import __version__\n\nfrom contextlib import contextmanager, chdir\nimport sys\nimport pytest\nfrom pathlib import Path\nfrom time import sleep\n\n", "\n\n@contextmanager\ndef argv(*args):\n    old = sys.argv\n    sys.argv = [\"entangled\"] + list(args)\n    yield\n    sys.argv = old\n\n\ndef test_version(capsys):\n    with argv(\"--version\"):\n        with pytest.raises(SystemExit):\n            cli()\n        captured = capsys.readouterr()\n        assert captured.out.strip() == f\"Entangled {__version__}\"", "\n\ndef test_version(capsys):\n    with argv(\"--version\"):\n        with pytest.raises(SystemExit):\n            cli()\n        captured = capsys.readouterr()\n        assert captured.out.strip() == f\"Entangled {__version__}\"\n\n\ndef test_watch(tmp_path):\n    with chdir(tmp_path):\n        Path(\"./entangled.toml\").write_text(\"\\n\".join(['version=\"2.0\"']))\n        Path(\"./test.md\").write_text(\n            \"\\n\".join([\"``` {.python file=test.py}\", 'print(\"hello\")', \"```\"])\n        )\n\n        with argv(\"--debug\", \"tangle\"):\n            cli()\n            assert Path(\"./test.py\").exists()", "\n\ndef test_watch(tmp_path):\n    with chdir(tmp_path):\n        Path(\"./entangled.toml\").write_text(\"\\n\".join(['version=\"2.0\"']))\n        Path(\"./test.md\").write_text(\n            \"\\n\".join([\"``` {.python file=test.py}\", 'print(\"hello\")', \"```\"])\n        )\n\n        with argv(\"--debug\", \"tangle\"):\n            cli()\n            assert Path(\"./test.py\").exists()", ""]}
{"filename": "test/test_missing_ref.py", "chunked_list": ["from entangled.tangle import tangle_ref\nfrom entangled.config import AnnotationMethod\nfrom entangled.markdown_reader import MarkdownReader\nfrom entangled.errors.user import MissingReference\n\nimport pytest\n\nmd_source = \"\"\"\n``` {.scheme #hello}\n(display \"hello\") (newline)", "``` {.scheme #hello}\n(display \"hello\") (newline)\n<<goodbye>>\n```\n\"\"\"\n\n\ndef test_missing_ref(tmp_path):\n    with pytest.raises(MissingReference):\n        mr = MarkdownReader(\"-\")\n        mr.run(md_source)\n        tangle_ref(mr.reference_map, \"hello\", AnnotationMethod.NAKED)", ""]}
{"filename": "test/test_daemon.py", "chunked_list": ["from pathlib import Path\nimport time\nimport os\nfrom entangled.config import config\nfrom entangled.filedb import stat\nimport threading\nfrom entangled.commands.watch import _watch\nfrom entangled.main import configure\n\nfrom contextlib import chdir", "\nfrom contextlib import chdir\n\ndef test_daemon(tmp_path: Path):\n    config.read()\n    with chdir(tmp_path):\n        try:\n            configure(debug=True)\n            stop = threading.Event()\n            t = threading.Thread(target=_watch, args=(stop,))\n            t.start()\n            Path(\"main.md\").write_text(\n                \"``` {.scheme file=hello.scm}\\n\" '(display \"hello\") (newline)\\n' \"```\\n\"\n            )\n            time.sleep(0.1)\n            md_stat1 = stat(Path(\"main.md\"))\n            assert Path(\"hello.scm\").exists()\n\n            lines = Path(\"hello.scm\").read_text().splitlines()\n            goodbye = '(display \"goodbye\") (newline)'\n            lines.insert(2, goodbye)\n            Path(\"hello.scm\").write_text(\"\\n\".join(lines))\n            time.sleep(0.2)\n            md_stat2 = stat(Path(\"main.md\"))\n            assert md_stat1 != md_stat2\n            assert md_stat1 < md_stat2\n\n            lines = Path(\"main.md\").read_text().splitlines()\n            assert lines[2] == goodbye\n\n            lines[0] = \"``` {.scheme file=foo.scm}\"\n            Path(\"main.md\").write_text(\"\\n\".join(lines))\n            time.sleep(0.1)\n\n            assert not Path(\"hello.scm\").exists()\n            assert Path(\"foo.scm\").exists()\n\n        finally:\n            stop.set()\n            t.join()\n            time.sleep(0.1)", ""]}
{"filename": "test/test_transaction.py", "chunked_list": ["from contextlib import chdir\nfrom pathlib import Path\n\nfrom entangled.transaction import Transaction, Create, Write, Delete\nfrom entangled.filedb import file_db\n\n\ndef test_transaction(tmp_path: Path):\n    with chdir(tmp_path):\n        with file_db() as db:\n            t = Transaction(db)\n            t.write(Path(\"a\"), \"hello\", [])\n            t.write(Path(\"b\"), \"goodbye\", [Path(\"a\")])\n\n            assert all(isinstance(a, Create) for a in t.actions)\n            t.run()\n            assert Path(\"a\").exists()\n            assert Path(\"b\").exists()\n\n        with open(Path(\"a\"), \"w\") as f:\n            f.write(\"ciao\")\n\n        with file_db() as db:\n            assert Path(\"a\") in db\n            assert Path(\"b\") in db\n            assert list(db.changed()) == [Path(\"a\")]\n\n            t = Transaction(db)\n            t.write(Path(\"b\"), \"goodbye\", [])\n            assert t.actions == []\n\n            t.write(Path(\"a\"), \"buongiorno\", [])\n            assert isinstance(t.actions[0], Write)\n            assert not t.all_ok()\n\n        with file_db() as db:\n            t = Transaction(db)\n            t.write(Path(\"a\"), \"goodbye\", [])\n            assert isinstance(t.actions[0], Write)\n            t.clear_orphans()\n            assert isinstance(t.actions[1], Delete)\n            t.run()\n            assert not Path(\"b\").exists()", ""]}
{"filename": "test/test_build_hook.py", "chunked_list": ["from contextlib import chdir\n\nfrom entangled.config import config\nfrom entangled.commands import tangle\n\nfrom uuid import uuid4\nfrom time import sleep\nfrom pathlib import Path\n\nimport os", "\nimport os\n\nmd_input = \"\"\"\nCreate a file:\n\n``` {{.python file=script.py}}\nprint(\"{message}\", end=\"\")\n```\n", "```\n\n``` {{.makefile #build target=test.dat}}\ntest.dat: script.py\n> python $< > $@\n```\n\"\"\"\n\n\ndef test_build(tmp_path):\n    message = uuid4().hex\n    with chdir(tmp_path):\n        with open(\"test.md\", \"w\") as f:\n            f.write(md_input.format(message=message))\n\n        with config(hooks=[\"build\"]):\n            # normally, build hooks are disabled in CI,\n            # here we need to make an exception\n            if \"CI\" in os.environ:\n                del os.environ[\"CI\"]\n                tangle()\n                os.environ[\"CI\"] = \"true\"\n            else:\n                tangle()\n\n        sleep(0.1)\n        tgt = Path(\"test.dat\")\n        assert tgt.exists()\n        contents = open(tgt, \"r\").read()\n        assert contents == message", "\ndef test_build(tmp_path):\n    message = uuid4().hex\n    with chdir(tmp_path):\n        with open(\"test.md\", \"w\") as f:\n            f.write(md_input.format(message=message))\n\n        with config(hooks=[\"build\"]):\n            # normally, build hooks are disabled in CI,\n            # here we need to make an exception\n            if \"CI\" in os.environ:\n                del os.environ[\"CI\"]\n                tangle()\n                os.environ[\"CI\"] = \"true\"\n            else:\n                tangle()\n\n        sleep(0.1)\n        tgt = Path(\"test.dat\")\n        assert tgt.exists()\n        contents = open(tgt, \"r\").read()\n        assert contents == message", ""]}
{"filename": "test/test_filedb.py", "chunked_list": ["from entangled.filedb import file_db, stat\nfrom time import sleep\nfrom pathlib import Path\nimport pytest\nfrom contextlib import chdir\n\n@pytest.fixture(scope=\"session\")\ndef example_files(tmp_path_factory: pytest.TempPathFactory):\n    tmp_path = tmp_path_factory.mktemp(\"test-filedb\")\n    with open(tmp_path / \"a\", \"w\") as f:\n        f.write(\"hello\")\n    sleep(0.01)\n    with open(tmp_path / \"b\", \"w\") as f:\n        f.write(\"hello\")\n    with open(tmp_path / \"c\", \"w\") as f:\n        f.write(\"goodbye\")\n    with open(tmp_path / \"d\", \"w\") as f:\n        f.write(\"earth\")\n    return tmp_path", "\n\ndef test_stat(example_files: Path):\n    with chdir(example_files):\n        stat_a = stat(example_files / \"a\")\n        stat_b = stat(example_files / \"b\")\n        stat_c = stat(example_files / \"c\")\n        assert stat_a == stat_b\n        assert stat_c != stat_b\n        assert stat_a < stat_b", "\n\ndef test_filedb(example_files: Path):\n    with chdir(example_files):\n        with file_db() as db:\n            for n in \"abcd\":\n                db.update(Path(n))\n\n        with open(example_files / \"d\", \"w\") as f:\n            f.write(\"mars\")\n\n        with file_db() as db:\n            assert db.changed() == [Path(\"d\")]\n            db.update(Path(\"d\"))\n            assert db.changed() == []", ""]}
{"filename": "test/conftest.py", "chunked_list": ["import pytest\nfrom pathlib import Path\n\n\n@pytest.fixture\ndef data():\n    return Path(__file__).parent / \"data\"\n\n\n@pytest.fixture(params=list((Path(__file__).parent / \"data\").glob(\"*.md\")))\ndef markdown(request):\n    with open(request.param, \"r\") as f:\n        yield f.read()", "\n@pytest.fixture(params=list((Path(__file__).parent / \"data\").glob(\"*.md\")))\ndef markdown(request):\n    with open(request.param, \"r\") as f:\n        yield f.read()\n"]}
{"filename": "test/test_tangle.py", "chunked_list": ["from entangled.markdown_reader import read_markdown\nfrom entangled.tangle import tangle_ref\nfrom entangled.code_reader import CodeReader\nfrom pathlib import Path\nimport os\nfrom shutil import copytree, move\nfrom contextlib import chdir\n\n\ndef test_tangle_ref(data, tmp_path):\n    copytree(data / \"hello-world\", tmp_path / \"hello-world\")\n    with chdir(tmp_path / \"hello-world\"):\n        refs, _ = read_markdown(Path(\"hello-world.md\"))\n        tangled, deps = tangle_ref(refs, \"hello_world.cc\")\n        assert deps == {\"hello-world.md\"}\n        with open(\"hello_world.cc\", \"r\") as f:\n            assert f.read() == tangled\n\n        cb_old = next(refs[\"hello-world\"]).source\n        cr = CodeReader(\"-\", refs).run(Path(\"hello_universe.cc\").read_text())\n        cb_new = next(refs[\"hello-world\"]).source\n        assert cb_old != cb_new", "\ndef test_tangle_ref(data, tmp_path):\n    copytree(data / \"hello-world\", tmp_path / \"hello-world\")\n    with chdir(tmp_path / \"hello-world\"):\n        refs, _ = read_markdown(Path(\"hello-world.md\"))\n        tangled, deps = tangle_ref(refs, \"hello_world.cc\")\n        assert deps == {\"hello-world.md\"}\n        with open(\"hello_world.cc\", \"r\") as f:\n            assert f.read() == tangled\n\n        cb_old = next(refs[\"hello-world\"]).source\n        cr = CodeReader(\"-\", refs).run(Path(\"hello_universe.cc\").read_text())\n        cb_new = next(refs[\"hello-world\"]).source\n        assert cb_old != cb_new", ""]}
{"filename": "test/test_indentation_errors.py", "chunked_list": ["from entangled.commands import tangle, stitch\nfrom entangled.markdown_reader import MarkdownReader, read_markdown\nfrom entangled.code_reader import CodeReader\nfrom entangled.errors.user import IndentationError\n\nfrom contextlib import chdir\nfrom pathlib import Path\nfrom time import sleep\n\nimport pytest", "\nimport pytest\n\nmd_source = \"\"\"\n``` {.scheme file=hello.scm}\n(display \"hello\") (newline)\n\n(let (x 42)\n  <<print-x>>\n)", "  <<print-x>>\n)\n```\n\n``` {.scheme #print-x}\n(display x)\n  <<newline>>\n```\n\n``` {.scheme #newline}", "\n``` {.scheme #newline}\n(newline)\n```\n\"\"\"\n\nscm_output1 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n(display \"hello\") (newline)\n\n(let (x 42)", "\n(let (x 42)\n  ; ~/~ begin <<test.md#print-x>>[init]\n  (display x)\n    ; ~/~ begin <<test.md#newline>>[init]\n    (newline)\n    ; ~/~ end\n  ; ~/~ end\n)\n; ~/~ end\"\"\"", ")\n; ~/~ end\"\"\"\n\n\nscm_changed1 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n(display \"goodbye\") (newline)\n\n(let (x 42)\n  ; ~/~ begin <<test.md#print-x>>[init]\n  (display x)", "  ; ~/~ begin <<test.md#print-x>>[init]\n  (display x)\n    ; ~/~ begin <<test.md#newline>>[init]\n    (newline)\n    ; ~/~ end\n  ; ~/~ end\n)\n    ; ~/~ end\"\"\"\n\n", "\n\nscm_changed2 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n(display \"hello\") (newline)\n\n(let (x 42)\n  ; ~/~ begin <<test.md#print-x>>[init]\n  (display x)\n;   ; ~/~ begin <<test.md#newline>>[init]\n    (newline)", ";   ; ~/~ begin <<test.md#newline>>[init]\n    (newline)\n    ; ~/~ end\n  ; ~/~ end\n)\n; ~/~ end\"\"\"\n\n\nscm_changed3 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n(display \"hello\") (newline)", "scm_changed3 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n(display \"hello\") (newline)\n\n(let (x 42)\n  ; ~/~ begin <<test.md#print-x>>[init]\n  (display x)\n    ; ~/~ begin <<test.md#newline>>[init]\n  (newline)\n    ; ~/~ end\n  ; ~/~ end", "    ; ~/~ end\n  ; ~/~ end\n)\n; ~/~ end\"\"\"\n\n\ndef test_code_indentation(tmp_path):\n    with chdir(tmp_path):\n        src = Path(\"test.md\")\n        src.write_text(md_source)\n        sleep(0.1)\n        tangle()\n        sleep(0.1)\n        tgt = Path(\"hello.scm\")\n        assert tgt.exists() and tgt.read_text() == scm_output1\n        refs, _ = read_markdown(src)\n\n        tgt.write_text(scm_changed1)\n        sleep(0.1)\n        with pytest.raises(IndentationError):\n            CodeReader(tgt, refs).run(tgt.read_text())\n        stitch()\n        sleep(0.1)\n        assert src.read_text() == md_source\n\n        for errs in [scm_changed1, scm_changed2, scm_changed3]:\n            with pytest.raises(IndentationError):\n                CodeReader(\"-\", refs).run(errs)", "\n\nmd_source_error = \"\"\"\n  ``` {.scheme file=hello.scm}\n(display \"hello\") (newline)\n```\n\"\"\"\n\n\ndef test_md_indentation():\n    with pytest.raises(IndentationError):\n        MarkdownReader(\"-\").run(md_source_error)", "\ndef test_md_indentation():\n    with pytest.raises(IndentationError):\n        MarkdownReader(\"-\").run(md_source_error)\n"]}
{"filename": "entangled/code_reader.py", "chunked_list": ["from dataclasses import dataclass, field\nfrom pathlib import Path\n\nimport mawk\nimport re\n\nfrom .document import ReferenceId, TextLocation, ReferenceMap\nfrom .errors.user import IndentationError\n\n", "\n\n@dataclass\nclass Frame:\n    ref: ReferenceId\n    indent: str\n    content: list[str] = field(default_factory=list)\n\n\nclass CodeReader(mawk.RuleSet):\n    \"\"\"Reads an annotated code file.\"\"\"\n\n    def __init__(self, path: str, refs: ReferenceMap):\n        self.location = TextLocation(path, 0)\n        self.stack: list[Frame] = [Frame(ReferenceId(\"root\", \"\", -1), \"\")]\n        self.refs: ReferenceMap = refs\n\n    @property\n    def current(self) -> Frame:\n        return self.stack[-1]\n\n    @mawk.always\n    def increase_line_number(self, _):\n        self.location.line_number += 1\n\n    @mawk.on_match(\n        r\"^(?P<indent>\\s*).* ~/~ begin <<(?P<source>[^#<>]+)#(?P<ref_name>[^#<>]+)>>\\[(?P<ref_count>init|\\d+)\\]\"\n    )\n    def on_block_begin(self, m: re.Match):\n        ref_name = m[\"ref_name\"]\n        if m[\"ref_count\"] == \"init\":\n            ref_count = 0\n            if not m[\"indent\"].startswith(self.current.indent):\n                raise IndentationError(self.location)\n            indent = m[\"indent\"].removeprefix(self.current.indent)\n            self.current.content.append(f\"{indent}<<{ref_name}>>\")\n        else:\n            ref_count = int(m[\"ref_count\"])\n\n        self.stack.append(\n            Frame(ReferenceId(m[\"ref_name\"], m[\"source\"], ref_count), m[\"indent\"])\n        )\n        return []\n\n    @mawk.on_match(r\"^(?P<indent>\\s*).* ~/~ end\")\n    def on_block_end(self, m: re.Match):\n        if m[\"indent\"] != self.current.indent:\n            raise IndentationError(self.location)\n        self.refs[self.current.ref].source = \"\\n\".join(self.current.content)\n        self.stack.pop()\n        return []\n\n    @mawk.always\n    def otherwise(self, line: str):\n        if line.strip() == \"\":\n            self.current.content.append(\"\")\n            return []\n        if not line.startswith(self.current.indent):\n            raise IndentationError(self.location)\n        self.current.content.append(line.removeprefix(self.current.indent))\n        return []", "\nclass CodeReader(mawk.RuleSet):\n    \"\"\"Reads an annotated code file.\"\"\"\n\n    def __init__(self, path: str, refs: ReferenceMap):\n        self.location = TextLocation(path, 0)\n        self.stack: list[Frame] = [Frame(ReferenceId(\"root\", \"\", -1), \"\")]\n        self.refs: ReferenceMap = refs\n\n    @property\n    def current(self) -> Frame:\n        return self.stack[-1]\n\n    @mawk.always\n    def increase_line_number(self, _):\n        self.location.line_number += 1\n\n    @mawk.on_match(\n        r\"^(?P<indent>\\s*).* ~/~ begin <<(?P<source>[^#<>]+)#(?P<ref_name>[^#<>]+)>>\\[(?P<ref_count>init|\\d+)\\]\"\n    )\n    def on_block_begin(self, m: re.Match):\n        ref_name = m[\"ref_name\"]\n        if m[\"ref_count\"] == \"init\":\n            ref_count = 0\n            if not m[\"indent\"].startswith(self.current.indent):\n                raise IndentationError(self.location)\n            indent = m[\"indent\"].removeprefix(self.current.indent)\n            self.current.content.append(f\"{indent}<<{ref_name}>>\")\n        else:\n            ref_count = int(m[\"ref_count\"])\n\n        self.stack.append(\n            Frame(ReferenceId(m[\"ref_name\"], m[\"source\"], ref_count), m[\"indent\"])\n        )\n        return []\n\n    @mawk.on_match(r\"^(?P<indent>\\s*).* ~/~ end\")\n    def on_block_end(self, m: re.Match):\n        if m[\"indent\"] != self.current.indent:\n            raise IndentationError(self.location)\n        self.refs[self.current.ref].source = \"\\n\".join(self.current.content)\n        self.stack.pop()\n        return []\n\n    @mawk.always\n    def otherwise(self, line: str):\n        if line.strip() == \"\":\n            self.current.content.append(\"\")\n            return []\n        if not line.startswith(self.current.indent):\n            raise IndentationError(self.location)\n        self.current.content.append(line.removeprefix(self.current.indent))\n        return []", ""]}
{"filename": "entangled/markdown_reader.py", "chunked_list": ["from typing import Optional\nfrom copy import copy\nfrom pathlib import Path\n\nimport re\nimport mawk\nimport logging\n\nfrom .config import config\nfrom .utility import first", "from .config import config\nfrom .utility import first\nfrom .document import TextLocation, CodeBlock, ReferenceMap, Content, PlainText\nfrom .properties import read_properties, get_attribute, get_classes, get_id\nfrom .hooks.base import HookBase\nfrom .errors.user import ParseError, IndentationError\nfrom . import parsing\n\n\nclass MarkdownReader(mawk.RuleSet):\n    \"\"\"Reads a Markdown file, and splits it up into code blocks and other\n    content. The contents of the code blocks get stored in `reference_map`.\n    \"\"\"\n\n    def __init__(\n        self,\n        filename: str,\n        refs: Optional[ReferenceMap] = None,\n        hooks: Optional[list[HookBase]] = None,\n    ):\n        self.location = TextLocation(filename)\n        self.reference_map = refs or ReferenceMap()\n        self.content: list[Content] = []\n        self.inside_codeblock: bool = False\n        self.current_content: list[str] = []\n        self.ignore = False\n        self.hooks = hooks or []\n\n    def flush_plain_text(self):\n        self.content.append(PlainText(\"\\n\".join(self.current_content)))\n        self.current_content = []\n\n    @mawk.always\n    def on_next_line(self, _):\n        self.location.line_number += 1\n\n    @mawk.on_match(config.markers.begin_ignore)\n    def on_begin_ignore(self, _):\n        self.ignore = True\n        logging.debug(\"ignoring markdown block %s\", self.location)\n\n    @mawk.on_match(config.markers.end_ignore)\n    def on_end_ignore(self, _):\n        self.ignore = False\n        logging.debug(\"end of ignore\")\n\n    @mawk.on_match(config.markers.open)\n    def on_open_codeblock(self, m: re.Match) -> Optional[list[str]]:\n        if self.ignore:\n            return None\n        if self.inside_codeblock:\n            return None\n        self.current_codeblock_indent = m[\"indent\"]\n        self.current_codeblock_location = copy(self.location)\n        self.current_content.append(m[0])\n        try:\n            self.current_codeblock_properties = read_properties(m[\"properties\"])\n            self.flush_plain_text()\n            self.inside_codeblock = True\n        except parsing.Failure as f:\n            logging.error(\"Parsing error at %s: %s\", self.location, f)\n            logging.error(\"Continuing parsing rest of document.\")\n        return []\n\n    @mawk.on_match(config.markers.close)\n    def on_close_codeblock(self, m: re.Match):\n        if self.ignore:\n            return\n        if not self.inside_codeblock:\n            return\n\n        if len(m[\"indent\"]) < len(self.current_codeblock_indent):\n            raise IndentationError(self.location)\n\n        if m[\"indent\"] != self.current_codeblock_indent:\n            return  # treat this as code-block content\n\n        # add block to reference-map\n        language_class = first(get_classes(self.current_codeblock_properties))\n        block_id = get_id(self.current_codeblock_properties)\n        target_file = get_attribute(self.current_codeblock_properties, \"file\")\n        ref_name = block_id or target_file\n        language = config.get_language(language_class) if language_class else None\n\n        if ref_name is None or language is None:\n            self.flush_plain_text()\n        else:\n            ref = self.reference_map.new_id(\n                self.current_codeblock_location.filename, ref_name\n            )\n            code = CodeBlock(\n                language,\n                self.current_codeblock_properties,\n                self.current_codeblock_indent,\n                \"\\n\".join(\n                    line.removeprefix(self.current_codeblock_indent)\n                    for line in self.current_content\n                ),\n                self.current_codeblock_location,\n            )\n            # logging.debug(repr(code))\n            self.reference_map[ref] = code\n            if target_file is not None:\n                self.reference_map.targets.add(target_file)\n            self.content.append(ref)\n            self.current_content = []\n\n            for h in self.hooks:\n                if h.condition(self.current_codeblock_properties):\n                    h.on_read(ref, code)\n\n        self.current_content.append(m[0])\n        self.inside_codeblock = False\n        return []\n\n    @mawk.always\n    def add_line(self, line: str):\n        self.current_content.append(line)\n        return []\n\n    def on_eof(self):\n        self.flush_plain_text()\n        return []", "\nclass MarkdownReader(mawk.RuleSet):\n    \"\"\"Reads a Markdown file, and splits it up into code blocks and other\n    content. The contents of the code blocks get stored in `reference_map`.\n    \"\"\"\n\n    def __init__(\n        self,\n        filename: str,\n        refs: Optional[ReferenceMap] = None,\n        hooks: Optional[list[HookBase]] = None,\n    ):\n        self.location = TextLocation(filename)\n        self.reference_map = refs or ReferenceMap()\n        self.content: list[Content] = []\n        self.inside_codeblock: bool = False\n        self.current_content: list[str] = []\n        self.ignore = False\n        self.hooks = hooks or []\n\n    def flush_plain_text(self):\n        self.content.append(PlainText(\"\\n\".join(self.current_content)))\n        self.current_content = []\n\n    @mawk.always\n    def on_next_line(self, _):\n        self.location.line_number += 1\n\n    @mawk.on_match(config.markers.begin_ignore)\n    def on_begin_ignore(self, _):\n        self.ignore = True\n        logging.debug(\"ignoring markdown block %s\", self.location)\n\n    @mawk.on_match(config.markers.end_ignore)\n    def on_end_ignore(self, _):\n        self.ignore = False\n        logging.debug(\"end of ignore\")\n\n    @mawk.on_match(config.markers.open)\n    def on_open_codeblock(self, m: re.Match) -> Optional[list[str]]:\n        if self.ignore:\n            return None\n        if self.inside_codeblock:\n            return None\n        self.current_codeblock_indent = m[\"indent\"]\n        self.current_codeblock_location = copy(self.location)\n        self.current_content.append(m[0])\n        try:\n            self.current_codeblock_properties = read_properties(m[\"properties\"])\n            self.flush_plain_text()\n            self.inside_codeblock = True\n        except parsing.Failure as f:\n            logging.error(\"Parsing error at %s: %s\", self.location, f)\n            logging.error(\"Continuing parsing rest of document.\")\n        return []\n\n    @mawk.on_match(config.markers.close)\n    def on_close_codeblock(self, m: re.Match):\n        if self.ignore:\n            return\n        if not self.inside_codeblock:\n            return\n\n        if len(m[\"indent\"]) < len(self.current_codeblock_indent):\n            raise IndentationError(self.location)\n\n        if m[\"indent\"] != self.current_codeblock_indent:\n            return  # treat this as code-block content\n\n        # add block to reference-map\n        language_class = first(get_classes(self.current_codeblock_properties))\n        block_id = get_id(self.current_codeblock_properties)\n        target_file = get_attribute(self.current_codeblock_properties, \"file\")\n        ref_name = block_id or target_file\n        language = config.get_language(language_class) if language_class else None\n\n        if ref_name is None or language is None:\n            self.flush_plain_text()\n        else:\n            ref = self.reference_map.new_id(\n                self.current_codeblock_location.filename, ref_name\n            )\n            code = CodeBlock(\n                language,\n                self.current_codeblock_properties,\n                self.current_codeblock_indent,\n                \"\\n\".join(\n                    line.removeprefix(self.current_codeblock_indent)\n                    for line in self.current_content\n                ),\n                self.current_codeblock_location,\n            )\n            # logging.debug(repr(code))\n            self.reference_map[ref] = code\n            if target_file is not None:\n                self.reference_map.targets.add(target_file)\n            self.content.append(ref)\n            self.current_content = []\n\n            for h in self.hooks:\n                if h.condition(self.current_codeblock_properties):\n                    h.on_read(ref, code)\n\n        self.current_content.append(m[0])\n        self.inside_codeblock = False\n        return []\n\n    @mawk.always\n    def add_line(self, line: str):\n        self.current_content.append(line)\n        return []\n\n    def on_eof(self):\n        self.flush_plain_text()\n        return []", "\n\ndef read_markdown(path: Path) -> tuple[ReferenceMap, list[Content]]:\n    with open(path, \"r\") as f:\n        path_str = str(path.resolve().relative_to(Path.cwd()))\n        md = MarkdownReader(path_str)\n        md.run(f.read())\n    return md.reference_map, md.content\n", ""]}
{"filename": "entangled/status.py", "chunked_list": ["from .config import config\nfrom .filedb import file_db\n\nfrom itertools import chain\nfrom pathlib import Path\n\n\ndef find_watch_dirs():\n    \"\"\"List all directories that contain files that need watching.\"\"\"\n    input_file_list = list_input_files()\n    markdown_dirs = set(p.parent for p in input_file_list)\n    with file_db(readonly=True) as db:\n        code_dirs = set(p.parent for p in db.managed)\n    return code_dirs.union(markdown_dirs)", "\n\ndef list_input_files():\n    \"\"\"List all input files.\"\"\"\n    return chain.from_iterable(map(Path(\".\").glob, config.watch_list))\n\n\ndef list_dependent_files():\n    with file_db(readonly=True) as db:\n        result = list(db.managed)\n    return result", ""]}
{"filename": "entangled/version.py", "chunked_list": ["import importlib.metadata\n\n__version__ = importlib.metadata.version(\"entangled-cli\")\n"]}
{"filename": "entangled/utility.py", "chunked_list": ["from typing import Iterable, Optional, TypeVar, TypeGuard, Union\nfrom dataclasses import is_dataclass\nfrom contextlib import contextmanager\nimport os\nfrom pathlib import Path\n\nimport typing\nimport types\n\n", "\n\nT = TypeVar(\"T\")\n\n\n\n\ndef first(it: Iterable[T]) -> Optional[T]:\n    try:\n        return next(iter(it))\n    except StopIteration:\n        return None", "\n\ndef normal_relative(path: Path) -> Path:\n    return path.resolve().relative_to(Path.cwd())\n\n\ndef ensure_parent(path: Path) -> Path:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    return path\n", "\n\ndef cat_maybes(it: Iterable[Optional[T]]) -> Iterable[T]:\n    def pred(x: Optional[T]) -> TypeGuard[T]:\n        return x is not None\n\n    return filter(pred, it)\n"]}
{"filename": "entangled/construct.py", "chunked_list": ["from typing import Union\nfrom dataclasses import is_dataclass\nfrom enum import Enum\n\nimport typing\nimport types\n\nfrom .parsing import Parser\n\n\ndef isgeneric(annot):\n    return hasattr(annot, \"__origin__\") and hasattr(annot, \"__args__\")", "\n\ndef isgeneric(annot):\n    return hasattr(annot, \"__origin__\") and hasattr(annot, \"__args__\")\n\n\ndef construct(annot, json):\n    \"\"\"Construct an object from a given type from a JSON stream.\n\n    The `annot` type should be one of: str, int, list[T], Optional[T],\n    or a dataclass, and the JSON data should match exactly the given\n    definitions in the dataclass hierarchy.\n    \"\"\"\n    if annot is str:\n        assert isinstance(json, str)\n        return json\n    if annot is int:\n        assert isinstance(json, int)\n        return json\n    if isinstance(json, str) and isinstance(annot, Parser):\n        result, _ = annot.read(json)\n        return result\n    if isgeneric(annot) and typing.get_origin(annot) is list:\n        assert isinstance(json, list)\n        return [construct(typing.get_args(annot)[0], item) for item in json]\n    if (\n        isgeneric(annot)\n        and typing.get_origin(annot) is Union\n        and typing.get_args(annot)[1] is types.NoneType\n    ):\n        if json is None:\n            return None\n        else:\n            return construct(typing.get_args(annot)[0], json)\n    if is_dataclass(annot):\n        assert isinstance(json, dict)\n        arg_annot = typing.get_type_hints(annot)\n        # assert all(k in json for k in arg_annot)\n        args = {k: construct(arg_annot[k], json[k]) for k in json}\n        return annot(**args)\n    if isinstance(json, str) and issubclass(annot, Enum):\n        options = {opt.name.lower(): opt for opt in annot}\n        assert json.lower() in options\n        return options[json.lower()]\n    raise ValueError(f\"Couldn't construct {annot} from {repr(json)}\")", ""]}
{"filename": "entangled/tangle.py", "chunked_list": ["from typing import Optional, TypeVar, Generic, Union\nfrom dataclasses import dataclass, field\nfrom textwrap import indent\nfrom contextlib import contextmanager\nfrom copy import copy\n\nimport re\nimport mawk\n\nfrom .document import (", "\nfrom .document import (\n    ReferenceMap,\n    AnnotationMethod,\n    TextLocation,\n    ReferenceId,\n    CodeBlock,\n)\nfrom .errors.user import CyclicReference, MissingReference\nfrom .config import config", "from .errors.user import CyclicReference, MissingReference\nfrom .config import config\n\n\nT = TypeVar(\"T\")\n\n\n@dataclass\nclass Visitor(Generic[T]):\n    _visited: dict[T, int] = field(default_factory=dict)\n\n    def in_order(self) -> list[T]:\n        return [k for k, v in sorted(self._visited.items(), key=lambda kv: kv[1])]\n\n    @contextmanager\n    def visit(self, x: T):\n        if x in self._visited:\n            raise CyclicReference(str(x), list(map(str, self.in_order())))\n        self._visited[x] = len(self._visited)\n        yield\n        del self._visited[x]", "class Visitor(Generic[T]):\n    _visited: dict[T, int] = field(default_factory=dict)\n\n    def in_order(self) -> list[T]:\n        return [k for k, v in sorted(self._visited.items(), key=lambda kv: kv[1])]\n\n    @contextmanager\n    def visit(self, x: T):\n        if x in self._visited:\n            raise CyclicReference(str(x), list(map(str, self.in_order())))\n        self._visited[x] = len(self._visited)\n        yield\n        del self._visited[x]", "\n\n@dataclass\nclass Tangler(mawk.RuleSet):\n    refs: ReferenceMap\n    ref: ReferenceId\n    init: bool\n    visited: Visitor[str]\n    deps: set[str] = field(init=False)\n    cb: CodeBlock = field(init=False)\n    location: TextLocation = field(init=False)\n\n    def __post_init__(self):\n        self.cb = self.refs[self.ref]\n        self.location = copy(self.cb.origin)\n        self.deps = set((self.cb.origin.filename,))\n\n    @mawk.always\n    def lineno(self, _):\n        self.location.line_number += 1\n\n    @mawk.on_match(r\"^(?P<indent>\\s*)<<(?P<refname>[\\w-]+)>>\\s*$\")\n    def on_noweb(self, m: re.Match):\n        try:\n            result, deps = tangle_ref(self.refs, m[\"refname\"], type(self), self.visited)\n\n        except KeyError:\n            raise MissingReference(m[\"refname\"], self.location)\n\n        self.deps.update(deps)\n        return [indent(result, m[\"indent\"])]\n\n    def run(self):\n        return super().run(self.cb.source)", "\n\n@dataclass\nclass AnnotatedTangler(Tangler):\n    close_comment: str = field(init=False)\n\n    def __post_init__(self):\n        super().__post_init__()\n        self.close_comment = (\n            \"\"\n            if self.cb.language.comment.close is None\n            else f\" {self.cb.language.comment.close}\"\n        )\n\n    def on_begin(self):\n        count = \"init\" if self.init else str(self.ref.ref_count)\n        return [\n            f\"{self.cb.language.comment.open} ~/~ begin <<{self.ref.file}#{self.ref.name}>>[{count}]{self.close_comment}\"\n        ]\n\n    def on_eof(self):\n        return [f\"{self.cb.language.comment.open} ~/~ end{self.close_comment}\"]", "\n\ntanglers = {\n    AnnotationMethod.NAKED: Tangler,\n    AnnotationMethod.STANDARD: AnnotatedTangler,\n    AnnotationMethod.SUPPLEMENTED: AnnotatedTangler,\n}\n\n\ndef tangle_ref(\n    refs: ReferenceMap,\n    ref_name: str,\n    annotation: Union[type[Tangler], AnnotationMethod] = config.annotation,\n    _visited: Optional[Visitor[str]] = None,\n) -> tuple[str, set[str]]:\n    if ref_name not in refs:\n        raise KeyError(ref_name)\n    v = _visited or Visitor()\n\n    if isinstance(annotation, AnnotationMethod):\n        tangler = tanglers[annotation]\n    else:\n        tangler = annotation\n\n    with v.visit(ref_name):\n        init = True\n        result = []\n        deps = set()\n        for ref in refs.index[ref_name]:\n            t = tangler(refs, ref, init, v)\n            result.append(t.run())\n            deps.update(t.deps)\n            init = False\n\n    return \"\\n\".join(result), deps", "\ndef tangle_ref(\n    refs: ReferenceMap,\n    ref_name: str,\n    annotation: Union[type[Tangler], AnnotationMethod] = config.annotation,\n    _visited: Optional[Visitor[str]] = None,\n) -> tuple[str, set[str]]:\n    if ref_name not in refs:\n        raise KeyError(ref_name)\n    v = _visited or Visitor()\n\n    if isinstance(annotation, AnnotationMethod):\n        tangler = tanglers[annotation]\n    else:\n        tangler = annotation\n\n    with v.visit(ref_name):\n        init = True\n        result = []\n        deps = set()\n        for ref in refs.index[ref_name]:\n            t = tangler(refs, ref, init, v)\n            result.append(t.run())\n            deps.update(t.deps)\n            init = False\n\n    return \"\\n\".join(result), deps", ""]}
{"filename": "entangled/main.py", "chunked_list": ["import argh  # type: ignore\nimport logging\nimport sys\n\n\ntry:\n    from rich.logging import RichHandler\n    from rich.highlighter import RegexHighlighter\n\n    WITH_RICH = True\nexcept ImportError:\n    WITH_RICH = False", "\n\nfrom .commands import tangle, stitch, sync, watch, status\nfrom .errors.internal import bug_contact\nfrom .errors.user import UserError\nfrom .version import __version__\n\n\nif WITH_RICH:\n\n    class BackTickHighlighter(RegexHighlighter):\n        highlights = [r\"`(?P<bold>[^`]*)`\"]", "if WITH_RICH:\n\n    class BackTickHighlighter(RegexHighlighter):\n        highlights = [r\"`(?P<bold>[^`]*)`\"]\n\n\ndef configure(debug=False):\n    if debug:\n        level = logging.DEBUG\n    else:\n        level = logging.INFO\n\n    if WITH_RICH:\n        FORMAT = \"%(message)s\"\n        logging.basicConfig(\n            level=level,\n            format=FORMAT,\n            datefmt=\"[%X]\",\n            handlers=[RichHandler(show_path=debug, highlighter=BackTickHighlighter())],\n        )\n        logging.debug(\"Rich logging enabled\")\n    else:\n        logging.basicConfig(level=level)\n        logging.debug(\"Plain logging enabled\")\n\n    logging.info(f\"Entangled {__version__} (https://entangled.github.io/)\")", "\n\ndef cli():\n    import argparse\n\n    try:\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            \"-d\", \"--debug\", action=\"store_true\", help=\"enable debug messages\"\n        )\n        parser.add_argument(\n            \"-v\", \"--version\", action=\"store_true\", help=\"show version number\"\n        )\n        argh.add_commands(parser, [tangle, stitch, sync, watch, status])\n        args = parser.parse_args()\n\n        if args.version:\n            print(f\"Entangled {__version__}\")\n            sys.exit(0)\n\n        configure(args.debug)\n        argh.dispatch(parser)\n    except KeyboardInterrupt:\n        logging.info(\"Goodbye\")\n        sys.exit(0)\n    except UserError as e:\n        logging.info(str(e))\n        sys.exit(0)\n    except Exception as e:\n        logging.error(str(e))\n        bug_contact(e)\n        sys.exit(1)", "\n\nif __name__ == \"__main__\":\n    cli()\n"]}
{"filename": "entangled/properties.py", "chunked_list": ["\"\"\"Properties of code blocks. These properties are the same as CSS selector\nproperties: id, class and attribute.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Optional, Union, ClassVar, Iterable\nfrom dataclasses import dataclass\nimport re\n\nfrom .parsing import (", "\nfrom .parsing import (\n    Parser,\n    many,\n    choice,\n    tokenize,\n    matching,\n    Parsable,\n    starmap,\n    Failure,", "    starmap,\n    Failure,\n)\n\n\n@dataclass\nclass Id(Parsable):\n    value: str\n    _pattern: ClassVar[Parser] = matching(r\"#([a-zA-Z]\\S*)\")\n\n    def __str__(self):\n        return f\"#{self.value}\"\n\n    @staticmethod\n    def __parser__():\n        return Id._pattern >> starmap(Id)", "\n\n@dataclass\nclass Class(Parsable):\n    value: str\n    _pattern: ClassVar[Parser] = matching(r\"\\.([a-zA-Z]\\S*)\")\n\n    def __str__(self):\n        return f\".{self.value}\"\n\n    @staticmethod\n    def __parser__():\n        return Class._pattern >> starmap(Class)", "\n\n@dataclass\nclass Attribute(Parsable):\n    key: str\n    value: str\n\n    _pattern1: ClassVar[Parser] = matching(\n        r\"([a-zA-Z]\\S*)\\s*=\\s*\\\"([^\\\"\\\\]*(?:\\\\.[^\\\"\\\\]*)*)\\\"\"\n    )\n    _pattern2: ClassVar[Parser] = matching(r\"([a-zA-Z]\\S*)\\s*=\\s*(\\S+)\")\n\n    def __str__(self):\n        return f'{self.key}=\"{self.value}\"'\n\n    @staticmethod\n    def __parser__():\n        return choice(Attribute._pattern1, Attribute._pattern2) >> starmap(Attribute)", "\n\nProperty = Union[Attribute, Class, Id]\n\n\ndef read_properties(inp: str) -> list[Property]:\n    \"\"\"Read properties from a string. Example:\n\n    >>> read_properties(\".python #foo file=bar.py\")\n    [Id(\"python\"), Class(\"foo\"), Attribute(\"file\", \"bar.py\")]\n    \"\"\"\n    # Explicit typing is needed to convince MyPy of correctness\n    # parsers: list[Parser[Property]] = [Id, Class, Attribute]\n    result, _ = many(tokenize(choice(Id, Class, Attribute))).read(inp)\n    return result", "\n\ndef get_id(props: list[Property]) -> Optional[str]:\n    \"\"\"Get the first given Id in a property list.\"\"\"\n    try:\n        return next(p.value for p in props if isinstance(p, Id))\n    except StopIteration:\n        return None\n\n\ndef get_classes(props: list[Property]) -> Iterable[str]:\n    \"\"\"Get all given Classes in a property list.\"\"\"\n    return (p.value for p in props if isinstance(p, Class))", "\n\ndef get_classes(props: list[Property]) -> Iterable[str]:\n    \"\"\"Get all given Classes in a property list.\"\"\"\n    return (p.value for p in props if isinstance(p, Class))\n\n\ndef get_attribute(props: list[Property], key: str) -> Optional[str]:\n    \"\"\"Get the value of an Attribute in a property list.\"\"\"\n    try:\n        return next(p.value for p in props if isinstance(p, Attribute) and p.key == key)\n    except StopIteration:\n        return None", ""]}
{"filename": "entangled/document.py", "chunked_list": ["from typing import Union, Iterable, Any\nfrom dataclasses import dataclass, field\nfrom collections import defaultdict\nfrom functools import singledispatchmethod\nfrom itertools import chain\n\nfrom .config import Language, AnnotationMethod, config\nfrom .properties import Property, get_attribute\nfrom .errors.internal import InternalError\n", "from .errors.internal import InternalError\n\n\ndef length(iter: Iterable[Any]) -> int:\n    return sum(1 for _ in iter)\n\n\n@dataclass\nclass ReferenceId:\n    name: str\n    file: str\n    ref_count: int\n\n    def __hash__(self):\n        return hash((self.name, self.file, self.ref_count))", "class ReferenceId:\n    name: str\n    file: str\n    ref_count: int\n\n    def __hash__(self):\n        return hash((self.name, self.file, self.ref_count))\n\n\n@dataclass\nclass PlainText:\n    content: str", "\n@dataclass\nclass PlainText:\n    content: str\n\n\nContent = Union[PlainText, ReferenceId]\n\n\n@dataclass\nclass TextLocation:\n    filename: str\n    line_number: int = 0\n\n    def __str__(self):\n        return f\"{self.filename}:{self.line_number}\"", "\n@dataclass\nclass TextLocation:\n    filename: str\n    line_number: int = 0\n\n    def __str__(self):\n        return f\"{self.filename}:{self.line_number}\"\n\n", "\n\n@dataclass\nclass CodeBlock:\n    language: Language\n    properties: list[Property]\n    indent: str\n    source: str\n    origin: TextLocation\n", "\n\n@dataclass\nclass ReferenceMap:\n    map: dict[ReferenceId, CodeBlock] = field(default_factory=dict)\n    index: defaultdict[str, list[ReferenceId]] = field(\n        default_factory=lambda: defaultdict(list)\n    )\n    targets: set[str] = field(default_factory=set)\n\n    def names(self) -> Iterable[str]:\n        return self.index.keys()\n\n    def by_name(self, n: str) -> Iterable[CodeBlock]:\n        return (self.map[r] for r in self.index[n])\n\n    def new_id(self, filename: str, name: str) -> ReferenceId:\n        c = length(filter(lambda r: r.file == filename, self.index[name]))\n        return ReferenceId(name, filename, c)\n\n    def __setitem__(self, key: ReferenceId, value: CodeBlock):\n        if key in self.map:\n            raise InternalError(\"Duplicate key in ReferenceMap\", [key])\n        self.map[key] = value\n        self.index[key.name].append(key)\n\n    def __contains__(self, key: str) -> bool:\n        return key in self.index\n\n    @singledispatchmethod\n    def __getitem__(self, key):\n        raise NotImplementedError(f\"Invalid key: {type(key)}\")\n\n    @__getitem__.register\n    def _(self, key: ReferenceId) -> CodeBlock:\n        return self.map[key]\n\n    @__getitem__.register\n    def _(self, key: str) -> Iterable[CodeBlock]:\n        return self.by_name(key)", ""]}
{"filename": "entangled/__init__.py", "chunked_list": ["\n"]}
{"filename": "entangled/transaction.py", "chunked_list": ["from typing import Optional, Iterable\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom enum import Enum\n\nimport logging\n\ntry:\n    import rich", "try:\n    import rich\n\n    WITH_RICH = True\nexcept ImportError:\n    WITH_RICH = False\n\nfrom .utility import cat_maybes\nfrom .filedb import FileDB, stat, file_db\nfrom .errors.internal import InternalError", "from .filedb import FileDB, stat, file_db\nfrom .errors.internal import InternalError\n\n\n@dataclass\nclass Action:\n    target: Path\n\n    def conflict(self, _: FileDB) -> Optional[str]:\n        \"\"\"Indicate wether the action might have conflicts. This could be", "    def conflict(self, _: FileDB) -> Optional[str]:\n        \"\"\"Indicate wether the action might have conflicts. This could be\n        inconsistency in the modification times of files, or overwriting\n        a file that is not managed by Entangled.\"\"\"\n        raise NotImplementedError()\n\n    def run(self, _: FileDB):\n        \"\"\"Run the action, if `interact` is `True` then confirmation is\n        asked in case of a conflict.\"\"\"\n        raise NotImplementedError()", "        asked in case of a conflict.\"\"\"\n        raise NotImplementedError()\n\n\n@dataclass\nclass Create(Action):\n    content: str\n    sources: list[Path]\n\n    def conflict(self, _) -> Optional[str]:", "\n    def conflict(self, _) -> Optional[str]:\n        if self.target.exists():\n            return f\"{self.target} already exists and is not managed by Entangled\"\n        return None\n\n    def run(self, db: FileDB):\n        self.target.parent.mkdir(parents=True, exist_ok=True)\n        with open(self.target, \"w\") as f:\n            f.write(self.content)", "        with open(self.target, \"w\") as f:\n            f.write(self.content)\n        db.update(self.target, self.sources)\n        if self.sources != []:\n            db.managed.add(self.target)\n\n    def __str__(self):\n        return f\"create `{self.target}`\"\n\n", "\n\n@dataclass\nclass Write(Action):\n    content: str\n    sources: list[Path]\n\n    def conflict(self, db: FileDB) -> Optional[str]:\n        st = stat(self.target)\n        if st != db[self.target]:", "        st = stat(self.target)\n        if st != db[self.target]:\n            return f\"`{self.target}` seems to have changed outside the control of Entangled\"\n        if self.sources:\n            newest_src = max(stat(s) for s in self.sources)\n            if st > newest_src:\n                return f\"`{self.target}` seems to be newer than `{newest_src.path}`\"\n        return None\n\n    def run(self, db: FileDB):", "\n    def run(self, db: FileDB):\n        with open(self.target, \"w\") as f:\n            f.write(self.content)\n        db.update(self.target, self.sources)\n\n    def __str__(self):\n        return f\"write `{self.target}`\"\n\n", "\n\n@dataclass\nclass Delete(Action):\n    def conflict(self, db: FileDB) -> Optional[str]:\n        st = stat(self.target)\n        if st != db[self.target]:\n            return (\n                f\"{self.target} seems to have changed outside the control of Entangled\"\n            )", "                f\"{self.target} seems to have changed outside the control of Entangled\"\n            )\n        return None\n\n    def run(self, db: FileDB):\n        self.target.unlink()\n        parent = self.target.parent\n        while list(parent.iterdir()) == []:\n            parent.rmdir()\n            parent = parent.parent", "            parent.rmdir()\n            parent = parent.parent\n        del db[self.target]\n\n    def __str__(self):\n        return f\"delete `{self.target}`\"\n\n\n@dataclass\nclass Transaction:", "@dataclass\nclass Transaction:\n    db: FileDB\n    updates: list[Path] = field(default_factory=list)\n    actions: list[Action] = field(default_factory=list)\n    passed: set[Path] = field(default_factory=set)\n\n    def update(self, path: Path):\n        self.updates.append(path)\n", "        self.updates.append(path)\n\n    def write(self, path: Path, content: str, sources: list[Path]):\n        if path in self.passed:\n            raise InternalError(\"Path is being written to twice\", [path])\n        self.passed.add(path)\n        if path not in self.db:\n            logging.debug(\"creating target `%s`\", path)\n            self.actions.append(Create(path, content, sources))\n        elif not self.db.check(path, content):", "            self.actions.append(Create(path, content, sources))\n        elif not self.db.check(path, content):\n            logging.debug(\"target `%s` changed\", path)\n            self.actions.append(Write(path, content, sources))\n        else:\n            logging.debug(\"target `%s` unchanged\", path)\n\n    def clear_orphans(self):\n        orphans = self.db.managed - self.passed\n        if not orphans:", "        orphans = self.db.managed - self.passed\n        if not orphans:\n            return\n\n        logging.info(\"orphans found: `%s`\", \", \".join(map(str, orphans)))\n        for p in orphans:\n            self.actions.append(Delete(p))\n\n    def check_conflicts(self) -> list[str]:\n        return list(cat_maybes(a.conflict(self.db) for a in self.actions))", "    def check_conflicts(self) -> list[str]:\n        return list(cat_maybes(a.conflict(self.db) for a in self.actions))\n\n    def all_ok(self) -> bool:\n        return all(a.conflict(self.db) is None for a in self.actions)\n\n    def print_plan(self):\n        if not self.actions:\n            logging.info(\"Nothing to be done.\")\n        for a in self.actions:", "            logging.info(\"Nothing to be done.\")\n        for a in self.actions:\n            logging.info(str(a))\n        for c in self.check_conflicts():\n            logging.warning(str(c))\n\n    def run(self):\n        for a in self.actions:\n            a.run(self.db)\n        for f in self.updates:", "            a.run(self.db)\n        for f in self.updates:\n            self.db.update(f)\n\n\nclass TransactionMode(Enum):\n    SHOW = 1\n    FAIL = 2\n    CONFIRM = 3\n    FORCE = 4", "    CONFIRM = 3\n    FORCE = 4\n\n\n@contextmanager\ndef transaction(mode: TransactionMode = TransactionMode.FAIL):\n    with file_db() as db:\n        tr = Transaction(db)\n\n        logging.debug(\"Open transaction\")", "\n        logging.debug(\"Open transaction\")\n        yield tr\n\n        tr.print_plan()\n\n        match mode:\n            case TransactionMode.SHOW:\n                logging.info(\"nothing is done\")\n                return", "                logging.info(\"nothing is done\")\n                return\n            case TransactionMode.FAIL:\n                if not tr.all_ok():\n                    logging.error(\n                        \"conflicts found, breaking off (use `--force` to run anyway)\"\n                    )\n                    return\n            case TransactionMode.CONFIRM:\n                if not tr.all_ok():", "            case TransactionMode.CONFIRM:\n                if not tr.all_ok():\n                    reply = input(\"Ok to continue? (y/n) \")\n                    if not (reply == \"y\" or reply == \"yes\"):\n                        return\n            case TransactionMode.FORCE:\n                logging.warning(\"conflicts found, but continuing anyway\")\n\n        logging.debug(\"Executing transaction\")\n        tr.run()", "        logging.debug(\"Executing transaction\")\n        tr.run()\n"]}
{"filename": "entangled/filedb.py", "chunked_list": ["from __future__ import annotations\nfrom typing import Optional, Iterable\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom contextlib import contextmanager\nfrom pathlib import Path\n\nimport hashlib\nimport json\nimport os", "import json\nimport os\nimport logging\n\nfrom filelock import FileLock\n\nfrom .version import __version__\nfrom .utility import normal_relative, ensure_parent\n\n", "\n\n@dataclass\nclass FileStat:\n    path: Path\n    deps: Optional[list[Path]]\n    modified: datetime\n    hexdigest: str\n\n    @staticmethod\n    def from_path(path: Path, deps: Optional[list[Path]]):\n        stat = os.stat(path)\n        with open(path, \"rb\") as f:\n            hash = hashlib.sha256(f.read())\n        return FileStat(\n            path, deps, datetime.fromtimestamp(stat.st_mtime), hash.hexdigest()\n        )\n\n    def __lt__(self, other: FileStat) -> bool:\n        return self.modified < other.modified\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, FileStat) and self.hexdigest == other.hexdigest\n\n    @staticmethod\n    def from_json(data) -> FileStat:\n        return FileStat(\n            Path(data[\"path\"]),\n            None if data[\"deps\"] is None else [Path(d) for d in data[\"deps\"]],\n            datetime.fromisoformat(data[\"modified\"]),\n            data[\"hexdigest\"],\n        )\n\n    def to_json(self):\n        return {\n            \"path\": str(self.path),\n            \"deps\": None if self.deps is None else [str(p) for p in self.deps],\n            \"modified\": self.modified.isoformat(),\n            \"hexdigest\": self.hexdigest,\n        }", "\n\ndef stat(path: Path, deps: Optional[list[Path]] = None) -> FileStat:\n    path = normal_relative(path)\n    deps = None if deps is None else [normal_relative(d) for d in deps]\n    return FileStat.from_path(path, deps)\n\n\n@dataclass\nclass FileDB:\n    \"\"\"Persistent storage for file stats of both Markdown and generated\n    files. We can use this to detect conflicts.\n\n    This data is stored in `.entangled/files.json`. It is recommended to\n    keep this file under version control. That way entangled shouldn't get\n    too confused when switching branches.\n\n    All files are stored in a single dictionary, the distinction between\n    source and target files is made in two separate indices.\"\"\"\n\n    _files: dict[Path, FileStat]\n    _source: set[Path]\n    _target: set[Path]\n\n    @staticmethod\n    def path():\n        return Path(\".\") / \".entangled\" / \"filedb.json\"\n\n    @staticmethod\n    def read() -> FileDB:\n        logging.debug(\"Reading FileDB\")\n        raw = json.load(open(FileDB.path()))\n        return FileDB(\n            {stat.path: stat for stat in (FileStat.from_json(r) for r in raw[\"files\"])},\n            set(map(Path, raw[\"source\"])),\n            set(map(Path, raw[\"target\"])),\n        )\n\n    @property\n    def managed(self) -> set[Path]:\n        return self._target\n\n    def write(self):\n        logging.debug(\"Writing FileDB\")\n        raw = {\n            \"version\": __version__,\n            \"files\": [stat.to_json() for stat in self._files.values()],\n            \"source\": list(map(str, self._source)),\n            \"target\": list(map(str, self._target)),\n        }\n        json.dump(raw, open(FileDB.path(), \"w\"), indent=2)\n\n    def changed(self) -> list[Path]:\n        \"\"\"List all target files that have changed w.r.t. the database.\"\"\"\n        return [p for p, s in self._files.items() if s != stat(p)]\n\n    def has_changed(self, path: Path) -> bool:\n        return stat(path) != self[path]\n\n    def update(self, path: Path, deps: Optional[list[Path]] = None):\n        \"\"\"Update the given path to a new stat.\"\"\"\n        path = normal_relative(path)\n        if path in self.managed and deps is None:\n            deps = self[path].deps\n        self._files[path] = stat(path, deps)\n\n    def __contains__(self, path: Path) -> bool:\n        return path in self._files\n\n    def __getitem__(self, path: Path) -> FileStat:\n        return self._files[path]\n\n    def __delitem__(self, path: Path):\n        if path in self._target:\n            self._target.remove(path)\n        del self._files[path]\n\n    @property\n    def files(self) -> Iterable[Path]:\n        return self._files.keys()\n\n    def check(self, path: Path, content: str) -> bool:\n        return (\n            hashlib.sha256(content.encode()).hexdigest() == self._files[path].hexdigest\n        )\n\n    @staticmethod\n    def initialize() -> FileDB:\n        if FileDB.path().exists():\n            db = FileDB.read()\n            undead = list(filter(lambda p: not p.exists(), db.files))\n            for path in undead:\n                logging.warning(\n                    \"File `%s` in DB doesn't exist. Removing entry from DB.\", path\n                )\n                del db[path]\n            return db\n\n        FileDB.path().parent.mkdir(parents=True, exist_ok=True)\n        data = {\"version\": __version__, \"files\": [], \"source\": [], \"target\": []}\n        json.dump(data, open(FileDB.path(), \"w\"))\n        return FileDB.read()", "@dataclass\nclass FileDB:\n    \"\"\"Persistent storage for file stats of both Markdown and generated\n    files. We can use this to detect conflicts.\n\n    This data is stored in `.entangled/files.json`. It is recommended to\n    keep this file under version control. That way entangled shouldn't get\n    too confused when switching branches.\n\n    All files are stored in a single dictionary, the distinction between\n    source and target files is made in two separate indices.\"\"\"\n\n    _files: dict[Path, FileStat]\n    _source: set[Path]\n    _target: set[Path]\n\n    @staticmethod\n    def path():\n        return Path(\".\") / \".entangled\" / \"filedb.json\"\n\n    @staticmethod\n    def read() -> FileDB:\n        logging.debug(\"Reading FileDB\")\n        raw = json.load(open(FileDB.path()))\n        return FileDB(\n            {stat.path: stat for stat in (FileStat.from_json(r) for r in raw[\"files\"])},\n            set(map(Path, raw[\"source\"])),\n            set(map(Path, raw[\"target\"])),\n        )\n\n    @property\n    def managed(self) -> set[Path]:\n        return self._target\n\n    def write(self):\n        logging.debug(\"Writing FileDB\")\n        raw = {\n            \"version\": __version__,\n            \"files\": [stat.to_json() for stat in self._files.values()],\n            \"source\": list(map(str, self._source)),\n            \"target\": list(map(str, self._target)),\n        }\n        json.dump(raw, open(FileDB.path(), \"w\"), indent=2)\n\n    def changed(self) -> list[Path]:\n        \"\"\"List all target files that have changed w.r.t. the database.\"\"\"\n        return [p for p, s in self._files.items() if s != stat(p)]\n\n    def has_changed(self, path: Path) -> bool:\n        return stat(path) != self[path]\n\n    def update(self, path: Path, deps: Optional[list[Path]] = None):\n        \"\"\"Update the given path to a new stat.\"\"\"\n        path = normal_relative(path)\n        if path in self.managed and deps is None:\n            deps = self[path].deps\n        self._files[path] = stat(path, deps)\n\n    def __contains__(self, path: Path) -> bool:\n        return path in self._files\n\n    def __getitem__(self, path: Path) -> FileStat:\n        return self._files[path]\n\n    def __delitem__(self, path: Path):\n        if path in self._target:\n            self._target.remove(path)\n        del self._files[path]\n\n    @property\n    def files(self) -> Iterable[Path]:\n        return self._files.keys()\n\n    def check(self, path: Path, content: str) -> bool:\n        return (\n            hashlib.sha256(content.encode()).hexdigest() == self._files[path].hexdigest\n        )\n\n    @staticmethod\n    def initialize() -> FileDB:\n        if FileDB.path().exists():\n            db = FileDB.read()\n            undead = list(filter(lambda p: not p.exists(), db.files))\n            for path in undead:\n                logging.warning(\n                    \"File `%s` in DB doesn't exist. Removing entry from DB.\", path\n                )\n                del db[path]\n            return db\n\n        FileDB.path().parent.mkdir(parents=True, exist_ok=True)\n        data = {\"version\": __version__, \"files\": [], \"source\": [], \"target\": []}\n        json.dump(data, open(FileDB.path(), \"w\"))\n        return FileDB.read()", "\n\n@contextmanager\ndef file_db(readonly=False):\n    lock = FileLock(ensure_parent(Path.cwd() / \".entangled\" / \"filedb.lock\"))\n    with lock:\n        db = FileDB.initialize()\n        yield db\n        if not readonly:\n            db.write()", ""]}
{"filename": "entangled/parsing.py", "chunked_list": ["\"\"\"Monadic recursive descent parser combinator. This is used to custom \nlight weight parsing within Entangled, mainly parsing the class, id and\nattribute properties of code blocks in markdown.\"\"\"\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom typing import (\n    TypeVar,\n    TypeVarTuple,", "    TypeVar,\n    TypeVarTuple,\n    Generic,\n    Callable,\n    Union,\n    Any,\n    Optional,\n    ParamSpec,\n)\nimport re", ")\nimport re\n\n\nT = TypeVar(\"T\")\nTs = TypeVarTuple(\"Ts\")\nU = TypeVar(\"U\")\nP = ParamSpec(\"P\")\nT_co = TypeVar(\"T_co\", covariant=True)\n", "T_co = TypeVar(\"T_co\", covariant=True)\n\n\n@dataclass\nclass Failure(Exception):\n    \"\"\"Base class for parser failures.\"\"\"\n\n    msg: str\n\n    def __str__(self):\n        return self.msg", "\n\nclass EndOfInput(Failure):\n    \"\"\"Raised at end of input.\"\"\"\n\n    def __init__(self):\n        super().__init__(\"end of input\")\n\n\n@dataclass\nclass Expected(Failure):\n    \"\"\"Input was different than expected.\"\"\"\n\n    inp: str\n\n    @property\n    def expected(self):\n        return self.msg\n\n    def __str__(self):\n        if len(inp) > 20:\n            inp = f\"{inp[:20]} ...\"\n        return f'expected: {self.expected}, got: \"{self.inp}\"'", "\n@dataclass\nclass Expected(Failure):\n    \"\"\"Input was different than expected.\"\"\"\n\n    inp: str\n\n    @property\n    def expected(self):\n        return self.msg\n\n    def __str__(self):\n        if len(inp) > 20:\n            inp = f\"{inp[:20]} ...\"\n        return f'expected: {self.expected}, got: \"{self.inp}\"'", "\n\n@dataclass\nclass ChoiceFailure(Expected):\n    \"\"\"All options of a choice parser failed.\"\"\"\n\n    failures: list[Failure]\n\n    @property\n    def expected(self):\n        return \" | \".join(str(f) for f in self.failures)", "\n\nclass Parser(Generic[T]):\n    \"\"\"Base class for parsers.\"\"\"\n\n    def read(self, inp: str) -> tuple[T, str]:\n        \"\"\"Read a string and return an object the remainder of the string.\"\"\"\n        raise NotImplementedError()\n\n    def __rshift__(self, f: Callable[[T], Parser[U]]) -> Parser[U]:\n        return bind(self, f)\n\n    def then(self, p: Parser[U]) -> Parser[U]:\n        return bind(self, lambda _: p)", "\n\ndef starmap(f: Callable[..., U]) -> Callable[[tuple], Parser[U]]:\n    return lambda args: pure(f(*args))\n\n\nclass ParserMeta(Generic[T], Parser[T], type):\n    def read(cls, inp: str) -> tuple[T, str]:\n        return cls.__parser__().read(inp)  # type: ignore\n", "\n\nclass Parsable(Generic[T], metaclass=ParserMeta):\n    \"\"\"Base class for Parsable objects. Parsables need to define a\n    `__parser__()` method that should return a `Parser[Self]`. That\n    way a Parsable class is also a `Parser` object for itself.\n    This allows for nicely expressive grammars.\"\"\"\n\n    pass\n", "\n\n@dataclass\nclass ParserWrapper(Generic[T], Parser[T]):\n    \"\"\"Wrapper class for functional parser.\"\"\"\n\n    f: Callable[[str], tuple[T, str]]\n\n    def read(self, inp: str) -> tuple[T, str]:\n        return self.f(inp)", "\n\ndef fmap(f: Callable[[T], U]) -> Callable[[T], Parser[U]]:\n    \"\"\"Map a parser action over a function.\"\"\"\n    return lambda x: pure(f(x))\n\n\ndef parser(f: Callable[[str], tuple[T, str]]) -> Parser[T]:\n    \"\"\"Parser decorator.\"\"\"\n    return ParserWrapper(f)", "\n\ndef pure(x: T) -> Parser[T]:\n    \"\"\"Parser that always succeeds and returns value `x`.\"\"\"\n    return parser(lambda inp: (x, inp))\n\n\ndef fail(msg: str) -> Parser[Any]:\n    \"\"\"Parser that always fails with a message `msg`.\"\"\"\n\n    @parser\n    def _fail(_: str) -> tuple[Any, str]:\n        raise Failure(msg)\n\n    return _fail", "\n\n@parser\ndef item(inp: str) -> tuple[str, str]:\n    \"\"\"Parser that takes a single character from a string.\"\"\"\n    if len(inp) == 0:\n        raise EndOfInput\n    return inp[0], inp[1:]\n\n\ndef bind(p: Parser[T], f: Callable[[T], Parser[U]]) -> Parser[U]:\n    \"\"\"Fundamental monadic combinator. First parses `p`, then passes\n    the value to `f`, giving a new parser that also knows the result\n    of the first one.\"\"\"\n\n    @parser\n    def bound(inp: str):\n        x, inp = p.read(inp)\n        return f(x).read(inp)\n\n    return bound", "\n\ndef bind(p: Parser[T], f: Callable[[T], Parser[U]]) -> Parser[U]:\n    \"\"\"Fundamental monadic combinator. First parses `p`, then passes\n    the value to `f`, giving a new parser that also knows the result\n    of the first one.\"\"\"\n\n    @parser\n    def bound(inp: str):\n        x, inp = p.read(inp)\n        return f(x).read(inp)\n\n    return bound", "\n\n# class Sequence(Generic[*Ts], ParserWrapper[tuple[*Ts]]):\n#     \"\"\"Parses a sequence of parsers to a tuple of results. A Sequence\n#     parser can be extended using the `*` operator.\"\"\"\n#     def __mul__(self, q: Parser[U]):\n#         return Sequence(self >> (lambda t: q >> (lambda x: pure(t + (x,)))))\n\n# seq = Sequence(pure(()))\n", "# seq = Sequence(pure(()))\n\n\ndef choice(*options: Parser[Any]) -> Parser[Any]:\n    @parser\n    def _choice(inp: str) -> tuple[T, str]:\n        failures = []\n\n        for o in options:\n            try:\n                return o.read(inp)\n            except Failure as f:\n                failures.append(f)\n                continue\n\n        raise ChoiceFailure(\"\", inp, failures)\n\n    return _choice", "\n\ndef optional(p: Parser[T], default: Optional[U] = None) -> Parser[Union[T, U]]:\n    return choice(p, pure(default))\n\n\ndef many(p: Parser[T]) -> Parser[list[T]]:\n    @parser\n    def _many(inp: str) -> tuple[list[T], str]:\n        result: list[T] = []\n        while True:\n            try:\n                value, inp = p.read(inp)\n                result.append(value)\n            except Failure:\n                break\n        return result, inp\n\n    return _many", "\n\ndef matching(regex: str) -> Parser[re.Match]:\n    pattern = re.compile(f\"^{regex}\")\n\n    @parser\n    def _matching(inp: str):\n        if m := pattern.match(inp):\n            return m.groups(), inp[m.end() :]\n        raise Expected(f\"/^{regex}/\", inp)\n\n    return _matching", "\n\ndef fullmatch(regex: str) -> Parser[str]:\n    pattern = re.compile(f\"^{regex}\")\n\n    @parser\n    def _fullmatch(inp: str):\n        if m := pattern.match(inp):\n            return m[0], inp[m.end() :]\n        raise Expected(f\"/^{regex}/\", inp)\n\n    return _fullmatch", "\n\nspace = matching(r\"\\s+\")\n\n\ndef tokenize(p: Parser[T]) -> Parser[T]:\n    return optional(space).then(p)\n"]}
{"filename": "entangled/commands/status.py", "chunked_list": ["from __future__ import annotations\nfrom ..status import find_watch_dirs, list_input_files, list_dependent_files\nfrom ..config import config\nfrom pathlib import Path\n\ntry:\n    from rich.console import Console, Group\n    from rich.columns import Columns\n    from rich.table import Table\n    from rich.panel import Panel\n    from rich.tree import Tree\n\n    WITH_RICH = True\nexcept ImportError:\n    WITH_RICH = False", "\n\ndef tree_from_files(files):\n    tree = Tree(label=\".\")\n    dirs = { Path(\".\"): tree }\n    for f in sorted(files):\n        for p in reversed(f.parents):\n            if p not in dirs:\n                dirs[p] = dirs[p.parent].add(p.name, style=\"repr.path\")\n        dirs[f.parent].add(f.name, style=\"repr.filename\")\n    return tree", "\n\ndef files_panel(file_list: list[str], title: str) -> Panel:\n    tree = tree_from_files(file_list)\n    return Panel(tree, title=title, border_style=\"dark_cyan\")\n\n\ndef rich_status():\n    cfg = config.config\n    config_table = Table()\n    config_table.add_column(\"name\")\n    config_table.add_column(\"value\")\n    config_table.add_row(\"Watch list\", \", \".join(f\"'{pat}'\" for pat in cfg.watch_list))\n    config_table.add_row(\"Hooks enabled\", \", \".join(cfg.hooks))\n\n    console = Console(color_system=\"auto\")\n    group = Group(\n        Panel(config_table, title=\"config\", border_style=\"dark_cyan\"),\n        Columns([\n            files_panel(list_input_files(), \"input files\"),\n            files_panel(list_dependent_files(), \"dependent files\"),\n        ]),\n    )\n\n    console.print(group)", "\n\ndef status():\n    if WITH_RICH:\n        rich_status()\n    else:\n        print(config)\n        print(\"---\")\n        print(\"input files:\", sorted(list_input_files()))\n", ""]}
{"filename": "entangled/commands/tangle.py", "chunked_list": ["from typing import Optional\nfrom itertools import chain\nfrom pathlib import Path\n\nimport argh  # type: ignore\nimport logging\n\nfrom ..document import ReferenceMap\nfrom ..config import config, AnnotationMethod\nfrom ..markdown_reader import MarkdownReader", "from ..config import config, AnnotationMethod\nfrom ..markdown_reader import MarkdownReader\nfrom ..transaction import transaction, TransactionMode\nfrom ..tangle import tangle_ref\nfrom ..hooks import get_hooks\nfrom ..errors.user import UserError\n\n\n@argh.arg(\n    \"-a\",", "@argh.arg(\n    \"-a\",\n    \"--annotate\",\n    choices=[m.name.lower() for m in AnnotationMethod],\n    help=\"annotation method\",\n)\n@argh.arg(\"--force\", help=\"force overwrite on conflict\")\n@argh.arg(\"-s\", \"--show\", help=\"only show, don't act\")\ndef tangle(*, annotate: Optional[str] = None, force: bool = False, show: bool = False):\n    \"\"\"Tangle codes from Markdown\"\"\"\n    if annotate is None:\n        annotation_method = config.annotation\n    else:\n        annotation_method = AnnotationMethod[annotate.upper()]\n\n    input_file_list = chain.from_iterable(map(Path(\".\").glob, config.watch_list))\n    refs = ReferenceMap()\n    hooks = get_hooks()\n\n    if show:\n        mode = TransactionMode.SHOW\n    elif force:\n        mode = TransactionMode.FORCE\n    else:\n        mode = TransactionMode.FAIL\n\n    try:\n        with transaction(mode) as t:\n            for path in input_file_list:\n                logging.debug(\"reading `%s`\", path)\n                t.update(path)\n                with open(path, \"r\") as f:\n                    MarkdownReader(str(path), refs, hooks).run(f.read())\n\n            for tgt in refs.targets:\n                result, deps = tangle_ref(refs, tgt, annotation_method)\n                t.write(Path(tgt), result, list(map(Path, deps)))\n            t.clear_orphans()\n\n        for h in hooks:\n            h.post_tangle(refs)\n\n    except UserError as e:\n        logging.error(str(e))", "def tangle(*, annotate: Optional[str] = None, force: bool = False, show: bool = False):\n    \"\"\"Tangle codes from Markdown\"\"\"\n    if annotate is None:\n        annotation_method = config.annotation\n    else:\n        annotation_method = AnnotationMethod[annotate.upper()]\n\n    input_file_list = chain.from_iterable(map(Path(\".\").glob, config.watch_list))\n    refs = ReferenceMap()\n    hooks = get_hooks()\n\n    if show:\n        mode = TransactionMode.SHOW\n    elif force:\n        mode = TransactionMode.FORCE\n    else:\n        mode = TransactionMode.FAIL\n\n    try:\n        with transaction(mode) as t:\n            for path in input_file_list:\n                logging.debug(\"reading `%s`\", path)\n                t.update(path)\n                with open(path, \"r\") as f:\n                    MarkdownReader(str(path), refs, hooks).run(f.read())\n\n            for tgt in refs.targets:\n                result, deps = tangle_ref(refs, tgt, annotation_method)\n                t.write(Path(tgt), result, list(map(Path, deps)))\n            t.clear_orphans()\n\n        for h in hooks:\n            h.post_tangle(refs)\n\n    except UserError as e:\n        logging.error(str(e))", ""]}
{"filename": "entangled/commands/stitch.py", "chunked_list": ["from itertools import chain\nfrom pathlib import Path\nfrom textwrap import indent\n\nimport logging\nimport argh  # type: ignore\n\nfrom ..config import config\nfrom ..code_reader import CodeReader\nfrom ..markdown_reader import MarkdownReader", "from ..code_reader import CodeReader\nfrom ..markdown_reader import MarkdownReader\nfrom ..document import ReferenceMap, Content, PlainText, ReferenceId\nfrom ..transaction import transaction, TransactionMode\nfrom ..errors.user import UserError\n\n\ndef stitch_markdown(reference_map: ReferenceMap, content: list[Content]) -> str:\n    def get(item: Content):\n        match item:", "    def get(item: Content):\n        match item:\n            case PlainText(s):\n                return s\n            case ReferenceId():\n                return indent(reference_map[item].source, reference_map[item].indent)\n\n    return \"\\n\".join(get(i) for i in content) + \"\\n\"\n\n", "\n\n@argh.arg(\"--force\", help=\"force overwrite on conflict\")\n@argh.arg(\"-s\", \"--show\", help=\"only show, don't act\")\ndef stitch(*, force: bool = False, show: bool = False):\n    \"\"\"Stitch code changes back into the Markdown\"\"\"\n    input_file_list = list(chain.from_iterable(map(Path(\".\").glob, config.watch_list)))\n\n    if show:\n        mode = TransactionMode.SHOW", "    if show:\n        mode = TransactionMode.SHOW\n    elif force:\n        mode = TransactionMode.FORCE\n    else:\n        mode = TransactionMode.FAIL\n\n    refs = ReferenceMap()\n    content: dict[Path, list[Content]] = {}\n    try:", "    content: dict[Path, list[Content]] = {}\n    try:\n        for path in input_file_list:\n            logging.debug(\"reading `%s`\", path)\n            with open(path, \"r\") as f:\n                mr = MarkdownReader(str(path), refs)\n                mr.run(f.read())\n                content[path] = mr.content\n\n        with transaction(mode) as t:", "\n        with transaction(mode) as t:\n            for path in t.db.managed:\n                logging.debug(\"reading `%s`\", path)\n                t.update(path)\n                with open(path, \"r\") as f:\n                    CodeReader(str(path), refs).run(f.read())\n\n            for path in input_file_list:\n                t.write(path, stitch_markdown(refs, content[path]), [])", "            for path in input_file_list:\n                t.write(path, stitch_markdown(refs, content[path]), [])\n\n    except UserError as e:\n        logging.error(str(e))\n"]}
{"filename": "entangled/commands/__init__.py", "chunked_list": ["from .tangle import tangle\nfrom .stitch import stitch\nfrom .sync import sync\nfrom .watch import watch\nfrom .status import status\n\n\n__all__ = [\"tangle\", \"stitch\", \"sync\", \"watch\", \"status\"]\n", ""]}
{"filename": "entangled/commands/watch.py", "chunked_list": ["from typing import Optional\nfrom pathlib import Path\nfrom itertools import chain\nfrom threading import Event\n\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler, FileSystemEvent\n\nfrom .sync import sync\nfrom ..config import config", "from .sync import sync\nfrom ..config import config\nfrom ..status import find_watch_dirs\n\n\nclass EventHandler(FileSystemEventHandler):\n    def __init__(self):\n        self.update_watched()\n\n    def update_watched(self):\n        self.watched = find_watch_dirs()\n\n    def on_any_event(self, event: FileSystemEvent):\n        if event.event_type == \"opened\":\n            return\n        config.read()\n        path = Path(event.src_path)\n        if path.is_relative_to(Path(\"./.entangled\")):\n            return\n        if any(path.is_relative_to(p) for p in self.watched):\n            sync()\n        self.update_watched()", "\n\ndef _watch(_stop_event: Optional[Event] = None):\n    \"\"\"Keep a loop running, watching for changes. This interface is separated\n    from the CLI one, so that it can be tested using threading instead of\n    subprocess.\"\"\"\n\n    def stop() -> bool:\n        return _stop_event is not None and _stop_event.is_set()\n\n    sync()\n\n    event_handler = EventHandler()\n    observer = Observer()\n    observer.schedule(event_handler, \".\", recursive=True)\n    observer.start()\n\n    try:\n        while observer.is_alive() and not stop():\n            observer.join(0.1)\n    finally:\n        observer.stop()\n        observer.join()", "\n\ndef watch():\n    \"\"\"Keep a loop running, watching for changes.\"\"\"\n    _watch()\n"]}
{"filename": "entangled/commands/init.py", "chunked_list": [""]}
{"filename": "entangled/commands/sync.py", "chunked_list": ["from typing import Optional, Callable\nfrom itertools import chain\nfrom pathlib import Path\n\nimport logging\n\nfrom ..filedb import file_db\nfrom ..config import config\nfrom .stitch import stitch\nfrom .tangle import tangle", "from .stitch import stitch\nfrom .tangle import tangle\n\n\ndef _stitch_then_tangle():\n    stitch()\n    tangle()\n\n\ndef sync_action() -> Optional[Callable[[], None]]:\n    input_file_list = list(chain.from_iterable(map(Path(\".\").glob, config.watch_list)))\n\n    with file_db(readonly=True) as db:\n        changed = set(db.changed())\n\n        if not all(f in db for f in input_file_list):\n            return tangle\n\n        if not changed:\n            return None\n\n        if changed.isdisjoint(db.managed):\n            logging.info(\"Tangling\")\n            return tangle\n\n        if changed.issubset(db.managed):\n            logging.info(\"Stitching\")\n            return _stitch_then_tangle\n\n        logging.error(\"changed: %s\", [str(p) for p in changed])\n        logging.error(\n            \"Both markdown and code seem to have changed. \" \"Don't know what to do now.\"\n        )\n        return None", "\ndef sync_action() -> Optional[Callable[[], None]]:\n    input_file_list = list(chain.from_iterable(map(Path(\".\").glob, config.watch_list)))\n\n    with file_db(readonly=True) as db:\n        changed = set(db.changed())\n\n        if not all(f in db for f in input_file_list):\n            return tangle\n\n        if not changed:\n            return None\n\n        if changed.isdisjoint(db.managed):\n            logging.info(\"Tangling\")\n            return tangle\n\n        if changed.issubset(db.managed):\n            logging.info(\"Stitching\")\n            return _stitch_then_tangle\n\n        logging.error(\"changed: %s\", [str(p) for p in changed])\n        logging.error(\n            \"Both markdown and code seem to have changed. \" \"Don't know what to do now.\"\n        )\n        return None", "\n\ndef sync():\n    \"\"\"Be smart wether to tangle or stich\"\"\"\n    action = sync_action()\n    if action is not None:\n        action()\n"]}
{"filename": "entangled/config/version.py", "chunked_list": ["from __future__ import annotations\nfrom typing import ClassVar\nfrom dataclasses import dataclass\n\nfrom ..parsing import Parser, Parsable, fmap, fullmatch\n\n\n@dataclass\nclass Version(Parsable):\n    numbers: tuple[int, ...]\n    _pattern: ClassVar[Parser] = fullmatch(r\"[0-9]+(\\.[0-9]+)*\")\n\n    def __str__(self):\n        return \".\".join(str(i) for i in self.numbers)\n\n    @staticmethod\n    def from_string(s: str) -> Version:\n        return Version(tuple(int(sv) for sv in s.split(\".\")))\n\n    @staticmethod\n    def __parser__() -> Parser[Version]:\n        return Version._pattern >> fmap(Version.from_string)", "class Version(Parsable):\n    numbers: tuple[int, ...]\n    _pattern: ClassVar[Parser] = fullmatch(r\"[0-9]+(\\.[0-9]+)*\")\n\n    def __str__(self):\n        return \".\".join(str(i) for i in self.numbers)\n\n    @staticmethod\n    def from_string(s: str) -> Version:\n        return Version(tuple(int(sv) for sv in s.split(\".\")))\n\n    @staticmethod\n    def __parser__() -> Parser[Version]:\n        return Version._pattern >> fmap(Version.from_string)", ""]}
{"filename": "entangled/config/language.py", "chunked_list": ["from typing import Optional\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Comment:\n    \"\"\"Comment method for a language. For example: `Comment(\"/*\", \"*/\")` works\n    for C/C++ etc, `Comment(\"#\")` works for Python, and so on.\n    \"\"\"\n\n    open: str\n    close: Optional[str] = None", "\n\n@dataclass\nclass Language:\n    \"\"\"Language information. Given a language we may have any number of short-hands\n    to indicate a code block is written in that language. If a language supports\n    line directives this can be used to redirect compiler messages directly to the\n    markdown files.\"\"\"\n\n    name: str\n    identifiers: list[str]\n    comment: Comment\n    line_directive: Optional[str] = None", "\n\nlanguages = [\n    Language(\"Shell\", [\"sh\", \"bash\", \"fish\", \"zsh\"], Comment(\"#\")),\n    Language(\"C\", [\"c\", \"cpp\", \"c++\"], Comment(\"/*\", \"*/\")),\n    Language(\"Python\", [\"python\"], Comment(\"#\")),\n    Language(\"Rust\", [\"rust\"], Comment(\"//\")),\n    Language(\"Haskell\", [\"haskell\"], Comment(\"--\")),\n    Language(\n        \"Lisp\", [\"scheme\", \"r5rs\", \"r6rs\", \"r7rs\", \"racket\", \"clojure\"], Comment(\";\")", "    Language(\n        \"Lisp\", [\"scheme\", \"r5rs\", \"r6rs\", \"r7rs\", \"racket\", \"clojure\"], Comment(\";\")\n    ),\n    Language(\"Julia\", [\"julia\"], Comment(\"#\")),\n    Language(\"Java\", [\"java\"], Comment(\"//\")),\n    Language(\"PureScript\", [\"pure\", \"purs\", \"purescript\"], Comment(\"--\")),\n    Language(\"CSS\", [\"css\"], Comment(\"/*\", \"*/\")),\n    Language(\"Lua\", [\"lua\"], Comment(\"--\")),\n    Language(\"Make\", [\"make\", \"makefile\"], Comment(\"#\")),\n    Language(\"Gnuplot\", [\"gnuplot\"], Comment(\"#\")),", "    Language(\"Make\", [\"make\", \"makefile\"], Comment(\"#\")),\n    Language(\"Gnuplot\", [\"gnuplot\"], Comment(\"#\")),\n    Language(\"TOML\", [\"toml\"], Comment(\"#\")),\n]\n"]}
{"filename": "entangled/config/__init__.py", "chunked_list": ["\"\"\"Configuration. The variable `config` should be automatically populated with\ndefaults and config loaded from `entangled.toml` in the work directory.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Optional, ClassVar, TypeVar\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom copy import copy", "from dataclasses import dataclass, field\nfrom copy import copy\nfrom pathlib import Path\nfrom contextlib import contextmanager\n\nfrom ..construct import construct\nfrom .version import Version\nfrom .language import Language, languages\n\nimport threading", "\nimport threading\nimport tomllib\nimport logging\n\n\nclass AnnotationMethod(Enum):\n    \"\"\"Annotation methods.\n\n    - `STANDARD` is the default. Comments tell where a piece of code\n       came from in enough detail to reconstruct the markdown if some\n       of the code is changed.\n    - `NAKED` adds no comments to the tangled files. Stitching is not\n       possible with this setting.\n    - `SUPPLEMENTED` adds extra information to the comment lines.\n    \"\"\"\n\n    STANDARD = 1\n    NAKED = 2\n    SUPPLEMENTED = 3", "\n\n@dataclass\nclass Markers:\n    \"\"\"Markers can be used to configure the Markdown dialect. Currently not used.\"\"\"\n\n    open: str\n    close: str\n    begin_ignore: str\n    end_ignore: str", "\n\nmarkers = Markers(\n    r\"^(?P<indent>\\s*)```\\s*{(?P<properties>[^{}]*)}\\s*$\",\n    r\"^(?P<indent>\\s*)```\\s*$\",\n    r\"^\\s*\\~\\~\\~markdown\\s*$\",\n    r\"^\\s*\\~\\~\\~\\s*$\",\n)\n\n", "\n\n@dataclass\nclass Config(threading.local):\n    \"\"\"Main config class. This class is made thread-local to make\n    it possible to test in parallel.\"\"\"\n\n    version: Version\n    languages: list[Language] = field(default_factory=list)\n    markers: Markers = field(default_factory=lambda: copy(markers))\n    watch_list: list[str] = field(default_factory=lambda: [\"**/*.md\"])\n    annotation_format: Optional[str] = None\n    annotation: AnnotationMethod = AnnotationMethod.STANDARD\n    use_line_directives: bool = False\n    hooks: list[str] = field(default_factory=list)\n\n    def __post_init__(self):\n        self.languages = languages + self.languages\n        self.make_language_index()\n\n    def make_language_index(self):\n        self.language_index = dict()\n        for l in self.languages:\n            for i in l.identifiers:\n                self.language_index[i] = l", "\n\ndefault = Config(Version.from_string(\"2.0\"))\n\n\ndef read_config_from_toml(path: Path, section: Optional[str] = None) -> Optional[Config]:\n    \"\"\"Read a config from given `path` in given `section`. The path should refer to\n    a TOML file that should decode to a `Config` object. If `section` is given, only\n    that section is decoded to a `Config` object. The `section` string may contain\n    periods to indicate deeper nesting.\n\n    Example:\n\n    ```python\n    read_config_from_toml(Path(\"./pyproject.toml\"), \"tool.entangled\")\n    ```\n    \"\"\"\n    if not path.exists():\n        return None\n    try:\n        with open(path, \"rb\") as f:\n            json = tomllib.load(f)\n            if section is not None:\n                for s in section.split(\".\"):\n                    json = json[s]\n            return construct(Config, json)\n    except ValueError as e:\n        logging.error(\"Could not read config: %s\", e)\n        return None\n    except KeyError as e:\n        logging.debug(\"%s\", e)\n        logging.debug(\"The config file %s should contain a section %s\", path, section)\n        return None", "\n\ndef read_config():\n    if Path(\"./entangled.toml\").exists():\n        return read_config_from_toml(Path(\"./entangled.toml\")) or default\n    if Path(\"./pyproject.toml\").exists():\n        return read_config_from_toml(Path(\"./pyproject.toml\"), \"tool.entangled\") or default\n    return default\n\n\nclass ConfigWrapper:\n    def __init__(self, config):\n        self.config = config\n\n    def read(self):\n        self.config = read_config()\n\n    def __getattr__(self, attr):\n        return getattr(self.config, attr)\n\n    @contextmanager\n    def __call__(self, **kwargs):\n        backup = {k: getattr(self.config, k) for k in kwargs}\n        for k, v in kwargs.items():\n            setattr(self.config, k, v)\n        yield\n        for k in kwargs.keys():\n            setattr(self.config, k, backup[k])\n\n    def get_language(self, lang_name: str) -> Optional[Language]:\n        return self.config.language_index.get(lang_name, None)", "\n\nclass ConfigWrapper:\n    def __init__(self, config):\n        self.config = config\n\n    def read(self):\n        self.config = read_config()\n\n    def __getattr__(self, attr):\n        return getattr(self.config, attr)\n\n    @contextmanager\n    def __call__(self, **kwargs):\n        backup = {k: getattr(self.config, k) for k in kwargs}\n        for k, v in kwargs.items():\n            setattr(self.config, k, v)\n        yield\n        for k in kwargs.keys():\n            setattr(self.config, k, backup[k])\n\n    def get_language(self, lang_name: str) -> Optional[Language]:\n        return self.config.language_index.get(lang_name, None)", "\n\nconfig = ConfigWrapper(read_config())\n\"\"\"The `config.config` variable is changed when the `config` module is loaded.\nConfig is read from `entangled.toml` file.\"\"\"\n\n"]}
{"filename": "entangled/hooks/base.py", "chunked_list": ["from dataclasses import dataclass\n\nfrom ..properties import Property\nfrom ..document import ReferenceMap, ReferenceId, CodeBlock\n\n\n@dataclass\nclass PrerequisitesFailed(Exception):\n    msg: str\n\n    def __str__(self):\n        return self.msg", "\n\nclass HookBase:\n    @staticmethod\n    def check_prerequisites():\n        \"\"\"When prerequisites aren't met, raise PrerequisitesFailed.\"\"\"\n        return\n\n    def condition(self, props: list[Property]):\n        raise NotImplementedError()\n\n    def on_read(self, refs: ReferenceId, code: CodeBlock):\n        raise NotImplementedError()\n\n    def post_tangle(self, refs: ReferenceMap):\n        pass", ""]}
{"filename": "entangled/hooks/__init__.py", "chunked_list": ["import logging\nfrom .base import HookBase\nfrom .build import BuildHook, PrerequisitesFailed\nfrom ..config import config\n\n\nhooks: dict[str, type[HookBase]] = {\"build\": BuildHook}\n\n\ndef get_hooks() -> list[HookBase]:\n    active_hooks = []\n    for h in config.hooks:\n        if h in hooks:\n            try:\n                hooks[h].check_prerequisites()\n                active_hooks.append(hooks[h]())\n            except PrerequisitesFailed as e:\n                logging.error(\"hook `%s`: %s\", h, str(e))\n        else:\n            logging.error(\"no such hook available: `%s`\", h)\n    return active_hooks", "\ndef get_hooks() -> list[HookBase]:\n    active_hooks = []\n    for h in config.hooks:\n        if h in hooks:\n            try:\n                hooks[h].check_prerequisites()\n                active_hooks.append(hooks[h]())\n            except PrerequisitesFailed as e:\n                logging.error(\"hook `%s`: %s\", h, str(e))\n        else:\n            logging.error(\"no such hook available: `%s`\", h)\n    return active_hooks", "\n\n__all__ = [\"hooks\", \"PrerequisitesFailed\"]\n"]}
{"filename": "entangled/hooks/build.py", "chunked_list": ["\"\"\"\nThe `build` hook collects code blocks that are tagged with the `#build`\nidentifier and have a `target=` attribute defined.  These code blocks are put\ntogether into a temporary Makefile that is run from the current working\ndirectory.\n\"\"\"\n\nfrom tempfile import TemporaryDirectory\nfrom pathlib import Path\nfrom subprocess import run, SubprocessError, DEVNULL", "from pathlib import Path\nfrom subprocess import run, SubprocessError, DEVNULL\n\nimport logging\nimport os\n\nfrom ..properties import Property, get_id, get_attribute\nfrom ..tangle import tangle_ref, Tangler\nfrom ..document import ReferenceMap, CodeBlock\n", "from ..document import ReferenceMap, CodeBlock\n\nfrom .base import HookBase, PrerequisitesFailed\n\n\"\"\"\nThe Makefile is generated with `preamble` as a format string.  The\n`.RECIPEPREFIX` is set to `>` , and `target` attributes are collected into an\n`all` target.\n\"\"\"\npreamble = \"\"\"", "\"\"\"\npreamble = \"\"\"\n.RECIPEPREFIX = >\n.PHONY = all\n\nall: {targets}\n\n{rules}\n\"\"\"\n", "\"\"\"\n\n\nclass BuildHook(HookBase):\n    def __init__(self):\n        self.targets = []\n\n    @staticmethod\n    def check_prerequisites():\n        \"\"\"Check that `make` is installed.\"\"\"\n        try:\n            run([\"make\", \"--version\"], stdout=DEVNULL)\n        except (SubprocessError, FileNotFoundError):\n            raise PrerequisitesFailed(\"GNU Make needs to be installed\")\n\n    def condition(self, props: list[Property]):\n        \"\"\"Condition by which a CodeBlock is processed: should have `#build` id\n        and `target=` attribute.\"\"\"\n        return get_id(props) == \"build\" and get_attribute(props, \"target\") is not None\n\n    def on_read(self, _, code: CodeBlock):\n        \"\"\"Add a CodeBlock's target attribute to the list of targets.\"\"\"\n        target = get_attribute(code.properties, \"target\")\n        if target is None:\n            return\n        self.targets.append(target)\n\n    def post_tangle(self, refs: ReferenceMap):\n        \"\"\"After all code is tangled: retrieve the `#build` script and run it.\"\"\"\n        if \"CI\" in os.environ:\n            logging.info(\"CI run detected, skipping `build` hook.\")\n            return\n\n        try:\n            rules = tangle_ref(refs, \"build\", Tangler)[0]\n        except KeyError:\n            logging.warning(\"No targets specified, skipping `build` hook.\")\n            return\n\n        logging.info(\"Building artifacts with `make`.\")\n        with TemporaryDirectory() as _pwd:\n            pwd = Path(_pwd)\n            script = preamble.format(targets=\" \".join(self.targets), rules=rules)\n            (pwd / \"Makefile\").write_text(script)\n            run([\"make\", \"-f\", str(pwd / \"Makefile\")], stdout=DEVNULL)", ""]}
{"filename": "entangled/errors/internal.py", "chunked_list": ["from typing import Any\nfrom dataclasses import dataclass, field\nfrom textwrap import wrap\nimport logging\n\n\n@dataclass\nclass InternalError(Exception):\n    msg: str\n    irritants: list[Any] = field(default_factory=list)\n\n    def __str__(self):\n        return f\"Internal error: {self.msg}\"", "\n\ndef bug_contact():\n    logging.error(\n        \"This error is due to an internal bug in Entangled. Please file an \"\n        \"issue including the above stack trace \"\n        \"and example content to \"\n        \"reproduce the exception at https://github.com/entangled/entangled.py/.\"\n    )\n", ""]}
{"filename": "entangled/errors/__init__.py", "chunked_list": [""]}
{"filename": "entangled/errors/user.py", "chunked_list": ["from dataclasses import dataclass\nfrom textwrap import wrap\n\nfrom ..document import TextLocation\n\n\nclass UserError(Exception):\n    def __str__(self):\n        return \"Unknown user error.\"\n", "\n\n@dataclass\nclass IndentationError(UserError):\n    location: TextLocation\n\n    def __str__(self):\n        return f\"indentation error at `{self.location}`\"\n\n", "\n\n@dataclass\nclass ParseError(UserError):\n    location: TextLocation\n    msg: str\n\n    def __str__(self):\n        return f\"parse error at {self.location}: {self.msg}\"\n", "\n\n@dataclass\nclass CyclicReference(UserError):\n    ref_name: str\n    cycle: list[str]\n\n    def __str__(self):\n        cycle_str = \" -> \".join(self.cycle)\n        return f\"Cyclic reference in <<{self.ref_name}>>: {cycle_str}\"", "\n\n@dataclass\nclass MissingReference(UserError):\n    ref_name: str\n    location: TextLocation\n\n    def __str__(self):\n        return f\"Missing reference `{self.ref_name}` at `{self.location}`\"\n", ""]}
