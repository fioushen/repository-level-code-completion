{"filename": "aiofauna/typedefs.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import Any, Dict, Generic, Iterable, List, Type, TypeVar, Union, cast\n\nfrom pydantic import BaseModel  # pylint: disable=no-name-in-module\n\nVector = List[float]\nMetaData = Dict[str, str]\n\nT = TypeVar(\"T\")\n", "T = TypeVar(\"T\")\n\n\nclass LazyProxy(Generic[T], ABC):\n    def __init__(self) -> None:\n        self.__proxied: Union[T, None] = None\n\n    def __getattr__(self, attr: str) -> object:\n        return getattr(self.__get_proxied__(), attr)\n\n    def __repr__(self) -> str:\n        return repr(self.__get_proxied__())\n\n    def __dir__(self) -> Iterable[str]:\n        return self.__get_proxied__().__dir__()\n\n    def __get_proxied__(self) -> T:\n        proxied = self.__proxied\n        if proxied is not None:\n            return proxied\n\n        self.__proxied = proxied = self.__load__()\n        return proxied\n\n    def __set_proxied__(self, value: T) -> None:\n        self.__proxied = value\n\n    def __as_proxied__(self) -> T:\n        \"\"\"Helper method that returns the current proxy, typed as the loaded object\"\"\"\n        return cast(T, self)\n\n    @abstractmethod\n    def __load__(self) -> T:\n        ...", "\n\nclass FunctionType(BaseModel, ABC):\n    _subclasses: List[Type[\"FunctionType\"]] = []\n\n    @classmethod\n    def __init_subclass__(cls, **kwargs):\n        super().__init_subclass__(**kwargs)\n        _schema = cls.schema()\n        if cls.__doc__ is None:\n            raise ValueError(\n                f\"FunctionType subclass {cls.__name__} must have a docstring\"\n            )\n        cls.openaischema = {\n            \"name\": cls.__name__,\n            \"description\": cls.__doc__,\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": _schema[\"properties\"],\n                \"required\": _schema[\"required\"],\n            },\n        }\n        cls._subclasses.append(cls)\n\n    @abstractmethod\n    async def run(self) -> Any:\n        ...", "\n\nF = TypeVar(\"F\", bound=FunctionType)\n"]}
{"filename": "aiofauna/__main__.py", "chunked_list": ["import os\nimport subprocess\n\nimport click\n\nfrom .utils import setup_logging\n\nlogger = setup_logging(__name__)\n\n", "\n\n@click.group()\ndef main():\n    pass\n\n\ndef print_tree(dirname, pref=\"\"):\n    for item in os.listdir(dirname):\n        if item.startswith(\".\"):\n            continue\n        print(pref + item)\n        if os.path.isdir(os.path.join(dirname, item)):\n            logger.info(\n                os.path.join(dirname, item), \" \" * len(pref) + \"|\" + (\"_\" * 5) + \" \"\n            )", "\n\n@main.command()\ndef tree():\n    print_tree(os.getcwd())\n\n\n@main.command()\n@click.option(\"--port\", default=5000)\n@click.option(\"--host\", default=\"0.0.0.0\")", "@click.option(\"--port\", default=5000)\n@click.option(\"--host\", default=\"0.0.0.0\")\n@click.option(\"--reload\", default=True)\n@click.option(\"--worker\", default=1)\n@click.option(\"--threads\", default=1)\n@click.argument(\"name\")\ndef run(name, port, host, reload, worker, threads):\n    subprocess.run(\n        [\n            \"gunicorn\",\n            \"-b\",\n            f\"{host}:{port}\",\n            \"--reload\" if reload else \"\",\n            \"--workers\",\n            str(worker),\n            \"--threads\",\n            str(threads),\n            name,\n        ],\n        check=True,\n    )", ""]}
{"filename": "aiofauna/docs.py", "chunked_list": ["\"\"\"Automatically generate OpenAPI documentation for your AioFauna API.\"\"\"\nfrom json import JSONDecoder, loads\nfrom typing import Any, Dict\n\nfrom aiohttp.web import Request\nfrom aiohttp.web_request import FileField\nfrom multidict import CIMultiDict\nfrom pydantic import BaseModel  # pylint: disable=no-name-in-module\n\nfrom .json import parse_json", "\nfrom .json import parse_json\n\n\ndef extract(params: dict, path: str):\n    \"\"\"\n    Extract OpenAPI parameters from the function parameters.\n\n    Args:\n        params (dict): The parameters of the function.\n        path (str): The URL path of the endpoint.\n\n    Returns:\n        Dict[str, Any]: The extracted OpenAPI parameters.\n    \"\"\"\n    open_api_params = {}\n\n    for name, param in params.items():\n        type_ = param.annotation\n\n        if type_ in (str, int, float, bool) and name:\n            if f\"{{{name}}}\" in path:\n                param_location = \"path\"\n            else:\n                param_location = \"query\"\n\n            open_api_params[name] = {\n                \"in\": param_location,\n                \"name\": name,\n                \"required\": True,\n                \"schema\": {\"type\": type_, \"default\": param.default, \"required\": True},\n            }\n\n        elif type_ in [FileField]:\n            open_api_params[name] = {\n                \"in\": \"formData\",\n                \"name\": name,\n                \"required\": True,\n                \"schema\": {\"type\": \"file\", \"format\": \"binary\"},\n                \"consumes\": [\"multipart/form-data\"],\n                \"headers\": {\n                    \"Content-Type\": {\"type\": \"string\", \"default\": \"multipart/form-data\"}\n                },\n            }\n\n        elif issubclass(type_, (BaseModel)):\n            open_api_params[name] = {\n                \"in\": \"body\",\n                \"name\": name,\n                \"required\": True,\n                \"schema\": type_.schema(),\n            }\n\n        else:\n            continue\n\n    return open_api_params", "\n\ndef transform(\n    open_api: Dict[str, Any],\n    path: str,\n    method: str,\n    func: Any,\n    open_api_params: Dict[str, Any],\n):\n    \"\"\"\n    Update the OpenAPI documentation with the endpoint information.\n\n    Args:\n        open_api (Dict[str, Any]): The OpenAPI documentation.\n        path (str): The URL path of the endpoint.\n        method (str): The HTTP method of the endpoint.\n        func (Any): The function being documented.\n        open_api_params (Dict[str, Any]): The OpenAPI parameters of the function.\n    \"\"\"\n    if path in [\"/openapi.json\", \"/docs\"]:\n        return\n\n    _scalars = []\n    _body = None\n    _is_file_upload = False\n\n    for param in open_api_params.values():\n        if isinstance(param[\"schema\"], dict):\n            if \"type\" in param[\"schema\"] and param[\"schema\"][\"type\"] != \"object\":\n                _scalars.append(param)\n            else:\n                _body = {\"content\": {\"application/json\": {\"schema\": param[\"schema\"]}}}\n        elif param[\"in\"] == \"formData\" and param[\"schema\"][\"type\"] == \"file\":\n            _is_file_upload = True\n            _scalars.append(param)\n        else:\n            continue\n\n    if _body:\n        open_api[\"paths\"].setdefault(path, {})[method.lower()] = {\n            \"summary\": func.__name__,\n            \"description\": func.__doc__,\n            \"parameters\": _scalars,\n            \"requestBody\": _body\n            if not _is_file_upload\n            else {\n                \"content\": {\n                    \"multipart/form-data\": {\n                        \"schema\": {\n                            \"properties\": {\n                                \"file\": {\n                                    \"type\": \"array\",\n                                    \"items\": {\"type\": \"string\", \"format\": \"binary\"},\n                                }\n                            }\n                        }\n                    }\n                }\n            },\n            \"responses\": {\"200\": {\"description\": \"OK\"}},\n        }\n\n    else:\n        open_api[\"paths\"].setdefault(path, {})[method.lower()] = {\n            \"summary\": func.__name__,\n            \"description\": func.__doc__,\n            \"parameters\": _scalars,\n            \"responses\": {\"200\": {\"description\": \"OK\"}},\n        }", "\n\nasync def load(request: Request, params: dict):\n    \"\"\"\n    Shape the endpoint function parameters to match the request.\n\n    Args:\n        request (Request): The HTTP request.\n        params (dict): The parameters of the function.\n", "        params (dict): The parameters of the function.\n\n    Returns:\n        Dict[str, Any]: The updated parameters to apply to the function.\n    \"\"\"\n    args_to_apply = {}\n\n    for name, param in params.items():\n        annotation = param.annotation\n        if annotation in (str, int, float, bool) and name in request.match_info:\n            args_to_apply[name] = request.match_info[name]\n        elif annotation in (str, int, float, bool) and name in request.query:\n            args_to_apply[name] = annotation(request.query[name])\n        elif annotation in [FileField]:\n            headers = dict(request.headers)\n            new_headers = CIMultiDict(\n                **headers, **{\"content-type\": \"multipart/form-data\"}  # type: ignore\n            )\n            new_request = request.clone(headers=new_headers)\n            args_to_apply[name] = new_request\n        elif issubclass(annotation, BaseModel):\n            data = await request.json(loads=JSONDecoder().decode)\n            if isinstance(data, (str, bytes)):\n                data = loads(data, object_hook=parse_json)\n            args_to_apply[name] = annotation(**data)\n        else:\n            args_to_apply[name] = request", "    return args_to_apply\n\n\nhtml = \"\"\"<!DOCTYPE html>\n            <html lang=\"en\">\n            <head>\n                <meta charset=\"UTF-8\">\n                <title>AioFauna</title>\n                <link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui.css\" >\n                <link rel=\"icon\" type=\"image/png\" href=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/favicon-32x32.png\" sizes=\"32x32\" />", "                <link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui.css\" >\n                <link rel=\"icon\" type=\"image/png\" href=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/favicon-32x32.png\" sizes=\"32x32\" />\n                <link rel=\"icon\" type=\"image/png\" href=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/favicon-16x16.png\" sizes=\"16x16\" />\n                <style>\n                html\n                {\n                    box-sizing: border-box;\n                    overflow: -moz-scrollbars-vertical;\n                    overflow-y: scroll;\n                }", "                    overflow-y: scroll;\n                }\n                \n                .swagger-ui .topbar\n                {\n                    display: none;\n                }\n                    \n                    \n                *,", "                    \n                *,\n                *:before,\n                *:after\n                {\n                    box-sizing: inherit;\n                }\n\n                body\n                {", "                body\n                {\n                    margin:0;\n                    background: #fafafa;\n                }\n                </style>\n            </head>\n\n            <body>\n                <script src=\"https://cdn.jsdelivr.net/npm/@unocss/runtime/mini.global.js\"></script>", "            <body>\n                <script src=\"https://cdn.jsdelivr.net/npm/@unocss/runtime/mini.global.js\"></script>\n                <nav class=\"bg-gray-800 text-white w-full\">\n                    <div class=\"container mx-auto px-6 py-3\">\n                        <div class=\"flex flex-col md:flex-row md:justify-between md:items-center\">\n                            <div class=\"flex justify-between items-center\">\n                                My API\n                            </div>\n                            <div class=\"flex mt-2 md:mt-0\">\n                                <a class=\"block md:inline-block mt-0 text-gray-200 hover:text-white mr-4\" href=\"/docs\">Documentation</a>", "                            <div class=\"flex mt-2 md:mt-0\">\n                                <a class=\"block md:inline-block mt-0 text-gray-200 hover:text-white mr-4\" href=\"/docs\">Documentation</a>\n                            </div>\n                        </div>\n                    </div>\n                </nav>\n                <div id=\"swagger-ui\"></div>\n\n                <script src=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui-bundle.js\"> </script>\n                <script src=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui-standalone-preset.js\"> </script>", "                <script src=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui-bundle.js\"> </script>\n                <script src=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui-standalone-preset.js\"> </script>\n                <script>\n                window.onload = function() {\n                const ui = SwaggerUIBundle({\n                    url: \"/openapi.json\",\n                    dom_id: '#swagger-ui',\n                    deepLinking: true,\n                    presets: [\n                    SwaggerUIBundle.presets.apis,", "                    presets: [\n                    SwaggerUIBundle.presets.apis,\n                    SwaggerUIStandalonePreset\n                    ],\n                    plugins: [\n                    SwaggerUIBundle.plugins.DownloadUrl\n                    ],\n                    layout: \"StandaloneLayout\"\n                })\n                window.ui = ui", "                })\n                window.ui = ui\n                }\n            </script>\n            </body>\n            </html>\n            \"\"\"\n"]}
{"filename": "aiofauna/client.py", "chunked_list": ["from __future__ import annotations\n\nimport asyncio\nimport json\nimport logging\nimport os\nimport typing\nfrom dataclasses import dataclass, field\nfrom functools import wraps\nfrom re import T", "from functools import wraps\nfrom re import T\nfrom threading import Lock\nfrom typing import Any, AsyncGenerator, Dict, List, Literal, Optional, Type, Union\n\nfrom aiohttp import (\n    ClientConnectionError,\n    ClientConnectorSSLError,\n    ClientResponse,\n    ClientSession,", "    ClientResponse,\n    ClientSession,\n    ClientTimeout,\n    TCPConnector,\n)\nfrom aiohttp.web_exceptions import HTTPException\nfrom dotenv import load_dotenv\nfrom multidict import CIMultiDict\nfrom pydantic import BaseModel\n", "from pydantic import BaseModel\n\nfrom aiofauna.faunadb.query import sin\n\nfrom .faunadb.errors import FaunaException\nfrom .faunadb.objects import Expr\nfrom .json import to_json\nfrom .typedefs import LazyProxy\nfrom .utils import setup_logging\n", "from .utils import setup_logging\n\nload_dotenv()\n\nMethod = Literal[\"GET\", \"POST\", \"PUT\", \"PATCH\", \"DELETE\"]\nJson = Union[Dict[str, Any], List[Dict[str, Any]]]\nMaybeJson = Optional[Json]\nHeaders = Dict[str, str]\nMaybeHeaders = Optional[Headers]\n", "MaybeHeaders = Optional[Headers]\n\n\nclass MissingEnvironmentVariable(Exception):\n    \"\"\"Exception for missing environment variable.\"\"\"\n\n    ...\n\n\nif \"FAUNA_SECRET\" not in os.environ:\n    raise MissingEnvironmentVariable(\n        \"The FAUNA_SECRET environment variable is not set.\"\n    )", "\nif \"FAUNA_SECRET\" not in os.environ:\n    raise MissingEnvironmentVariable(\n        \"The FAUNA_SECRET environment variable is not set.\"\n    )\n\n\nFAUNA_SECRET = os.environ[\"FAUNA_SECRET\"]\nHEADERS = {\n    \"Authorization\": f\"Bearer {FAUNA_SECRET}\",", "HEADERS = {\n    \"Authorization\": f\"Bearer {FAUNA_SECRET}\",\n    \"Content-type\": \"application/json\",\n    \"Accept\": \"application/json\",\n    \"User-Agent\": \"aiofauna-framework\",\n}\n\nT = typing.TypeVar(\"T\")\n\nlogger = setup_logging(__name__)", "\nlogger = setup_logging(__name__)\n\nFAUNA_EXCEPTIONS = (\n    HTTPException,\n    FaunaException,\n    ValueError,\n    KeyError,\n    TypeError,\n    Exception,", "    TypeError,\n    Exception,\n    UnicodeError,\n    json.JSONDecodeError,\n    RuntimeError,\n    ClientConnectionError,\n    ClientConnectorSSLError,\n)\n\nHTTP_EXCEPTIONS = (", "\nHTTP_EXCEPTIONS = (\n    HTTPException,\n    FaunaException,\n    ValueError,\n    KeyError,\n    TypeError,\n    Exception,\n)\n", ")\n\n\ndef singleton(cls: typing.Type[T]) -> typing.Callable[..., T]:  # type: ignore\n    instance = None\n    lock = Lock()\n\n    @wraps(cls)\n    def wrapper(*args, **kwargs):\n        nonlocal instance\n        if instance is None:\n            with lock:\n                if instance is None:\n                    instance = cls(*args, **kwargs)\n        return instance\n\n    return wrapper", "\n\nclass APIException(HTTPException):\n    \"\"\"Base class for all exceptions raised by an API client.\"\"\"\n\n    def __init__(self, message: str, status_code: int = 500) -> None:\n        self.message = message\n        self.status_code = status_code\n        super().__init__(\n            text=json.dumps({\"message\": message, \"status\": status_code}),\n            content_type=\"application/json\",\n        )", "\n\n@dataclass(frozen=True)\nclass ConnectorConfig:\n    ssl: bool = field(default=False)\n    limit: int = field(default=1000)\n    keepalive_timeout: int = field(default=10)\n\n\n@dataclass(init=True, repr=True, unsafe_hash=False, frozen=False)\nclass APIConfig:\n    base_url: str\n    headers: Headers\n    logger: logging.Logger = field(default=setup_logging(__name__))\n    exception_class: Type[HTTPException] = field(default=APIException)\n    session: Optional[ClientSession] = field(default=None)\n    connector_config: ConnectorConfig = field(default_factory=ConnectorConfig)\n    read_bufsize: int = field(default=2**16)\n    connector_owner: bool = field(default=True)\n    trust_env: bool = field(default=True)", "\n@dataclass(init=True, repr=True, unsafe_hash=False, frozen=False)\nclass APIConfig:\n    base_url: str\n    headers: Headers\n    logger: logging.Logger = field(default=setup_logging(__name__))\n    exception_class: Type[HTTPException] = field(default=APIException)\n    session: Optional[ClientSession] = field(default=None)\n    connector_config: ConnectorConfig = field(default_factory=ConnectorConfig)\n    read_bufsize: int = field(default=2**16)\n    connector_owner: bool = field(default=True)\n    trust_env: bool = field(default=True)", "\n\n@dataclass(init=True, repr=True, unsafe_hash=False, frozen=False)\nclass FaunaClient(LazyProxy[ClientSession]):\n    \"\"\"\n    FaunaDB Client\n\n    Args:\n        config (APIConfig): APIConfig object\n    \"\"\"\n\n    config: APIConfig = APIConfig(\n        base_url=\"https://db.fauna.com\",\n        headers=HEADERS,\n        logger=setup_logging(__name__),\n        exception_class=APIException,\n        session=None,\n        connector_config=ConnectorConfig(),\n    )\n    session_creation_lock = asyncio.Lock()\n\n    def __load__(self) -> ClientSession:\n        if self.config.session is None:\n            return ClientSession(\n                \"https://db.fauna.com\",\n                headers=CIMultiDict(self.config.headers),  # type: ignore\n                connector=TCPConnector(\n                    keepalive_timeout=self.config.connector_config.keepalive_timeout,\n                    ssl=self.config.connector_config.ssl,\n                    limit=self.config.connector_config.limit,\n                ),\n                connector_owner=self.config.connector_owner,\n                trust_env=self.config.trust_env,\n                read_bufsize=self.config.read_bufsize,\n            )\n        return self.config.session\n\n    async def query(self, expr: Expr) -> Any:\n        async with self.session_creation_lock:\n            if self.config.session is None:\n                self.config.session = self.__load__()\n        session = self.config.session\n        async with session.post(\n            \"/\",\n            data=to_json(expr),\n        ) as response:\n            try:\n                data = await response.json()\n                self.config.logger.info(data)\n                if data.get(\"resource\") is not None:\n                    return data[\"resource\"]\n                if data.get(\"error\") is not None:\n                    return data[\"error\"]\n                return data\n\n            except FAUNA_EXCEPTIONS as exc:  # pylint:disable=all\n                self.config.logger.error(exc)\n                raise self.config.exception_class from exc\n\n    async def stream(self, expr: Expr) -> AsyncGenerator[str, None]:\n        session = self.__load__()\n        async with session.post(\n            \"\",\n            data=to_json(expr),\n            headers={\n                \"Authorization\": f\"Bearer {self.secret}\",\n                \"Content-type\": \"application/json\",\n                \"Accept\": \"text/event-stream\",\n                \"Keep-Alive\": \"timeout=5, max=900\",\n                \"Connection\": \"keep-alive\",\n                \"Cache-Control\": \"no-cache\",\n                \"X-Last-Seen-Txn\": \"0\",\n                \"X-Request-By\": \"aiofauna\",\n                \"X-Query-By\": \"@obahamonde\",\n            },\n        ) as response:\n            async for chunk in response.content.iter_any():\n                try:\n                    yield chunk.decode()\n                except FAUNA_EXCEPTIONS as exc:\n                    self.config.logger.error(exc)\n                    yield str(exc)\n\n    async def cleanup(self):\n        if self.config.session is not None:\n            await self.config.session.close()", "\n\n@dataclass(init=True, repr=True, unsafe_hash=False, frozen=False)\nclass APIClient(LazyProxy[ClientSession]):\n    \"\"\"\n    HTTP Client:\n    Base class to create HTTP clients that wrap `aiohttp.ClientSession`.\n    Provides Lazy Loading through proxy objects and session reuse using the singleton pattern.\n    Constructor Signature:\n    `base_url` (str): Base URL of the API. For example: `https://api.openai.com`. Must the an absolute URL.\n    `headers` (dict): Headers that will proxide the authentication credentials, content_type, etc.\n    \"\"\"\n\n    base_url: str = field(init=True, repr=True)\n    headers: Dict[str, str] = field(default_factory=dict)\n    _subclasses: Optional[List[Type[APIClient]]] = None\n    _session_creation_lock = asyncio.Lock()\n    _session: Optional[ClientSession] = None\n\n    @classmethod\n    def __init_subclass__(cls, **kwargs):\n        super().__init_subclass__(**kwargs)\n        if cls._subclasses is None:\n            cls._subclasses = []\n        cls._subclasses.append(cls)\n\n    @classmethod\n    async def cleanup(cls):\n        if hasattr(cls, \"_subclasses\") and cls._subclasses is not None:\n            tasks = []\n            for subclass in cls._subclasses:\n                if subclass._session is not None:\n                    tasks.append(subclass._session.close())\n            await asyncio.gather(*tasks)\n            cls._subclasses = None\n\n    async def __load__(self) -> ClientSession:\n        async with self._session_creation_lock:\n            if self._session is None:\n                self._session = ClientSession(\n                    base_url=self.base_url,\n                    headers=CIMultiDict(self.headers),\n                    response_class=ClientResponse,\n                    connector=TCPConnector(\n                        keepalive_timeout=60,\n                        ssl=False,\n                        limit=1000,\n                    ),\n                    timeout=ClientTimeout(total=60),\n                    connector_owner=False,\n                    trust_env=False,\n                    read_bufsize=2**18,\n                )\n        return self._session\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__} {self.base_url}>\"\n\n    async def fetch(\n        self,\n        url: str,\n        method: Method = \"GET\",\n        json: MaybeJson = None,\n    ):\n        session = await self.__load__()\n        async with session.request(\n            method, url, headers=self.headers, json=json\n        ) as response:\n            try:\n                return await response.json()\n            except (\n                HTTP_EXCEPTIONS\n            ) as exc:  # pylint:disable=broad-exception-caught, unused-variable\n                logger.error(exc)\n                raise APIException(str(exc)) from exc\n\n    async def text(self, url: str, method: Method = \"GET\", json: MaybeJson = None):\n        session = await self.__load__()\n        async with session.request(\n            method, url, headers=self.headers, json=json\n        ) as response:\n            try:\n                return await response.text()\n            except (\n                HTTP_EXCEPTIONS\n            ) as exc:  # pylint:disable=broad-exception-caught, unused-variable\n                logger.error(exc)\n                raise APIException(str(exc)) from exc\n\n    async def stream(\n        self,\n        url: str,\n        method: Method = \"GET\",\n        json: MaybeJson = None,\n    ):\n        session = await self.__load__()\n        async with session.request(\n            method, url, headers=self.headers, json=json\n        ) as response:\n            async for chunk in response.content.iter_any():\n                try:\n                    yield chunk.decode()\n                except HTTP_EXCEPTIONS as exc:\n                    logger.error(exc)\n                    yield str(exc)\n                    raise APIException(str(exc)) from exc\n\n    async def get(self, url: str):\n        return await self.fetch(url=url, method=\"GET\")\n\n    async def post(self, url: str, json: MaybeJson = None):\n        return await self.fetch(url=url, method=\"POST\", json=json)\n\n    async def put(self, url: str, json: MaybeJson = None):\n        return await self.fetch(url=url, method=\"PUT\", json=json)\n\n    async def patch(self, url: str, json: MaybeJson = None):\n        return await self.fetch(url=url, method=\"PATCH\", json=json)\n\n    async def delete(self, url: str, json: MaybeJson = None):\n        return await self.fetch(url=url, method=\"DELETE\", json=json)\n\n    def update_headers(self, headers: Dict[str, str]):\n        \"\"\"\n        Update the headers used by this API client.\n\n        Returns:\n            self: Allows method chaining.\n        \"\"\"\n        self.headers.update(headers)\n        return self", ""]}
{"filename": "aiofauna/__init__.py", "chunked_list": ["\"\"\"\n\n\n\n\nAioFauna\n\n\n\n", "\n\n\"\"\"\n\n\n__version__ = (0, 2, 0)\n\n\n__author__ = \"obahamonde\"\n", "__author__ = \"obahamonde\"\n\n\n__license__ = \"MIT\"\n\n\n__doc__ = \"\"\"\n\n\n", "\n\n\n---\n\n\n\n\ntitle: AioFauna\n", "title: AioFauna\n\n\n\n\n---\n\n\n\n", "\n\n# AioFauna\n\n\n\n\n\n\ud83d\ude80 Introducing aiofauna: A full-stack framework built on top of Aiohttp, Pydantic and Faun\n", "\ud83d\ude80 Introducing aiofauna: A full-stack framework built on top of Aiohttp, Pydantic and Faun\n\n\n\n\n\n\ud83d\udd25 Inspired by FastAPI focuses on Developer Experience, Productivity and Versatil\n\n\n", "\n\n\n\n\ud83c\udf1f Featu\n\n\n\n\n", "\n\n\u2705 Supports Python 3.7+, comes with an opinionated ODM (Object Document Mapper) out of the box for FaunaDB that abstracts out complex FQL expressions into pythonic, fully typed asynchronous methods for all CRUD operations.\n\n\n\n\n\n\u2705 Performant and scalable: Built on top of Aiohttp a powerful http server and client and FaunaDB an scalable serverless database for modern applications.\n", "\u2705 Performant and scalable: Built on top of Aiohttp a powerful http server and client and FaunaDB an scalable serverless database for modern applications.\n\n\n\n\n\n\u2705 Async/await coroutines: Leverage the power of async programming for enhanced performance and responsiveness, being ASGI compliant is compatible with most async python frameworks.\n\n\n", "\n\n\n\n\u2705 Automatic Swagger UI generation: Automatic generation of interactive Swagger UI documentation for instant testing of your API.\n\n\n\n\n", "\n\n\u2705 SSE (Server Sent Events): Built-in support for SSE (Server Sent Events) for real-time streaming of data from FaunaDB to your application.\n\n\n\n\n\n\u2705 Robust data validation: Built-in support for Pydantic models for robust data validation and serialization.\n", "\u2705 Robust data validation: Built-in support for Pydantic models for robust data validation and serialization.\n\n\n\n\n\n\u2705 Auto-provisioning: Automatic management of indexes, unique indexes, and collections with FaunaModel ODM.\n\n\n", "\n\n\n\n\u2705 Full JSON communication: Custom encoder to ensure seamless data exchange between your application and FaunaDB backend.\n\n\n\n\n", "\n\n\u2705 Markdown and Jinja support with live reload: experiment an smooth frontend devserver experience without leaving your backend code.\n\n\n\n\n\n\u2705 Inspired by fastapi, you will work with almost the same syntax and features like path operations, path parameters, query parameters, request body, status codes and more.\n", "\u2705 Inspired by fastapi, you will work with almost the same syntax and features like path operations, path parameters, query parameters, request body, status codes and more.\n\n\n\n\n\n\ud83d\udca1 With aiofauna, you can build fast, scalable, and reliable modern applications, while building seamless integrations thanks to the fastest http client aiohttp and the most versatile database FaunaDB, you will enjoy integrating with third party services such as APIs, Data Sources and Cloud Servi\n\n\n", "\n\n\n\n\ud83d\udcda Check out the aiofauna library, and start building your next-gen applications tod\n\n\n\n\n", "\n\n#Python #FaunaDB #Async #Pydantic #aiofauna\n\n\n\n\n\n\u2699\ufe0f If you are using a synchronous framework check out [Faudantic](https://github.com/obahamonde/faudantic) for a similar experience with FaunaDB and Pydantic.\n", "\u2699\ufe0f If you are using a synchronous framework check out [Faudantic](https://github.com/obahamonde/faudantic) for a similar experience with FaunaDB and Pydantic.\n\n\n\n\n\n\ud83d\udcda [Documentation](https://obahamonde-aiofauna-docs.smartpro.solutions) (Built with aiofa\n\n\n", "\n\n\n\n\ud83d\udce6 [PyPi](https://pypi.org/project/aiofau\n\n\n\n\n", "\n\n\ud83d\udce6 [GitHub](https://github.com/obahamonde/aiofa\n\n\n\n\n\n\ud83d\udce6 [Demo](https://aiofaunastreams-fwuw7gz7oq-uc.a.run.app/) (Real time Latency Monitoring between FaunaDB and Google Cloud \n", "\ud83d\udce6 [Demo](https://aiofaunastreams-fwuw7gz7oq-uc.a.run.app/) (Real time Latency Monitoring between FaunaDB and Google Cloud \n\n\n\n)\n\n\n\n\"\"\"\n", "\"\"\"\n\n\nfrom typing import *  # pylint: disable=wildcard-import,unused-wildcard-import\n\nfrom aiohttp.web import Request, Response\nfrom aiohttp.web_request import FileField\nfrom aiohttp.web_ws import WebSocketResponse\nfrom aiohttp_sse import EventSourceResponse\nfrom pydantic import BaseModel  # pylint: disable=no-name-in-module", "from aiohttp_sse import EventSourceResponse\nfrom pydantic import BaseModel  # pylint: disable=no-name-in-module\n\nfrom .client import APIClient, APIConfig, FaunaClient\nfrom .faunadb import query as q\nfrom .fields import Field\nfrom .helpers import aio, asyncify\nfrom .json import FaunaJSONEncoder as JSONEncoder\nfrom .json import _parse_json_hook as default\nfrom .json import parse_json as loads", "from .json import _parse_json_hook as default\nfrom .json import parse_json as loads\nfrom .json import to_json as dumps\nfrom .odm import FaunaModel\nfrom .server import APIServer\nfrom .typedefs import LazyProxy\nfrom .utils import setup_logging\n"]}
{"filename": "aiofauna/utils.py", "chunked_list": ["\"\"\"Logging and error handling utilities for the OpenAI Function Python package.\"\"\"\nimport logging\nfrom typing import Any, Callable, Coroutine, TypeVar, cast\n\nfrom aiohttp.web_exceptions import HTTPException\nfrom rich.console import Console\nfrom rich.logging import RichHandler\nfrom rich.pretty import install\nfrom rich.traceback import install as ins\n", "from rich.traceback import install as ins\n\nT = TypeVar(\"T\")\n\n\ndef setup_logging(name: str) -> logging.Logger:\n    \"\"\"\n    Set's up logging using the Rich library for pretty and informative terminal logs.\n\n    Arguments:\n    name -- Name for the logger instance. It's best practice to use the name of the module where logger is defined. # pylint: disable=line-too-long\n    \"\"\"\n\n    # Install pretty representations of data structures using Rich library.\n    install()\n\n    # Install Rich traceback handler.\n    ins()\n\n    # Create a Console object that can record terminal output.\n    console = Console(record=True, force_terminal=True)\n\n    # Create a RichHandler for rich logging.\n    console_handler = RichHandler(\n        console=console,\n        show_time=True,\n        show_path=True,\n        markup=True,\n        rich_tracebacks=True,\n        tracebacks_show_locals=True,\n        tracebacks_extra_lines=5,\n        tracebacks_theme=\"solarized\",\n    )\n\n    # Set the log level and formatter for the console handler.\n    console_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n    console_handler.setLevel(logging.INFO)\n\n    # Setup basic configuration for logging.\n    logging.basicConfig(level=logging.INFO, handlers=[console_handler])\n\n    # Create and return a logger with the specified name.\n    logger_ = logging.getLogger(name)\n    logger_.setLevel(logging.INFO)\n\n    return logger_", "\n\n# Set up a logger for this module.\nlogger = setup_logging(__name__)\n\n\ndef handle_errors(\n    func: Callable[..., Coroutine[Any, Any, T]]\n) -> Callable[..., Coroutine[Any, Any, T]]:  # pylint: disable=line-too-long\n    \"\"\"\n    A decorator to handle errors in an asynchronous function.\n\n    Arguments:\n    func -- The asynchronous function whose errors are to be handled.\n    \"\"\"\n\n    async def wrapper(*args: Any, **kwargs: Any) -> T:\n        \"\"\"\n        Wrapper function to handle errors in the function call.\n        \"\"\"\n        try:\n            logger.info(\"Calling %s\", func.__name__)\n            return await func(*args, **kwargs)\n        except HTTPException as exc:\n            logger.error(exc.__class__.__name__)\n            logger.error(exc.reason)\n            raise exc from exc\n        except Exception as exc:\n            logger.error(exc.__class__.__name__)\n            logger.error(str(exc))\n            raise exc from exc\n\n    return wrapper", "\n\ndef chunker(seq, size):\n    return (seq[pos : pos + size] for pos in range(0, len(seq), size))\n\n\ndef gen_emptystr() -> str:\n    return cast(str, None)\n", ""]}
{"filename": "aiofauna/json.py", "chunked_list": ["import base64\nfrom base64 import urlsafe_b64decode, urlsafe_b64encode\nfrom datetime import date, datetime\nfrom enum import Enum\nfrom json import JSONEncoder, dumps, loads\nfrom time import time\nfrom typing import Any, Dict, List, Literal, TypeVar\nfrom uuid import UUID\n\nfrom iso8601 import parse_date", "\nfrom iso8601 import parse_date\nfrom pydantic import BaseModel  # pylint: disable=no-name-in-module\nfrom typing_extensions import override\n\nfrom .faunadb.objects import FaunaTime, Native, Query, Ref, SetRef\nfrom .faunadb.query import Expr\n\nT = TypeVar(\"T\")\n", "T = TypeVar(\"T\")\n\nFaunaKey = Literal[\n    \"@ref\", \"@obj\", \"@set\", \"@query\", \"@ts\", \"@date\", \"@bytes\", \"@index\", \"@class\"\n]\n\n\ndef _parse_json_hook(dct: Dict[FaunaKey, Any]):\n    if \"@ref\" in dct:\n        ref = dct[\"@ref\"]\n        if not \"collection\" in ref and not \"database\" in ref:\n            return Native.from_name(ref[\"id\"])\n        return Ref(ref[\"id\"], ref.get(\"collection\"), ref.get(\"database\"))\n    if \"@obj\" in dct:\n        return dct[\"@obj\"]\n    if \"@set\" in dct:\n        return SetRef(dct[\"@set\"])\n    if \"@query\" in dct:\n        return Query(dct[\"@query\"])\n    if \"@ts\" in dct:\n        return FaunaTime(dct[\"@ts\"])\n    if \"@date\" in dct:\n        return parse_date(dct[\"@date\"]).date()\n    if \"@bytes\" in dct:\n        return bytearray(urlsafe_b64decode(dct[\"@bytes\"].encode()))\n    return dct", "\n\ndef parse_json(json_string):\n    try:\n        return loads(json_string, object_hook=_parse_json_hook)\n    except ValueError:\n        pass\n\n\ndef to_json(dct, pretty=True, sort_keys=True):\n    if pretty:\n        return dumps(\n            dct,\n            cls=FaunaJSONEncoder,\n            sort_keys=True,\n            indent=4,\n            separators=(\", \", \": \"),\n            allow_nan=False,\n            ensure_ascii=True,\n        )\n    return dumps(\n        dct,\n        cls=FaunaJSONEncoder,\n        sort_keys=sort_keys,\n        separators=(\",\", \":\"),\n        allow_nan=False,\n        ensure_ascii=True,\n        exclude_none=True,\n    )", "\ndef to_json(dct, pretty=True, sort_keys=True):\n    if pretty:\n        return dumps(\n            dct,\n            cls=FaunaJSONEncoder,\n            sort_keys=True,\n            indent=4,\n            separators=(\", \", \": \"),\n            allow_nan=False,\n            ensure_ascii=True,\n        )\n    return dumps(\n        dct,\n        cls=FaunaJSONEncoder,\n        sort_keys=sort_keys,\n        separators=(\",\", \":\"),\n        allow_nan=False,\n        ensure_ascii=True,\n        exclude_none=True,\n    )", "\n\nclass FaunaJSONEncoder(JSONEncoder):\n    @override\n    def default(self, obj):\n        if isinstance(obj, (Ref, SetRef, FaunaTime, Query)):\n            return obj.to_fauna_json()\n        if isinstance(obj, Expr):\n            return obj.to_fauna_json()\n        elif isinstance(obj, datetime):\n            return obj.astimezone().isoformat()\n        elif isinstance(obj, date):\n            return {\"@date\": obj.isoformat()}\n        elif isinstance(obj, (bytes, bytearray)):\n            _val = None\n            try:\n                _val = obj.decode()\n            except:\n                _val = urlsafe_b64encode(obj).decode()  # pylint: disable=all\n            return {\"@bytes\": _val}\n        elif isinstance(obj, BaseModel):\n            return obj.dict()\n        elif isinstance(obj, Enum):\n            return obj.value\n        elif isinstance(obj, UUID):\n            return {\"@uuid\": str(obj)}\n        else:\n            return super().default(obj)", "\n\nclass JSONModel(BaseModel):\n    def to_dict(self, **kwargs):\n        return parse_json(self.to_json(**kwargs))\n\n    def to_json(self, **kwargs) -> str:\n        return to_json(super().dict(exclude_none=True, **kwargs))\n\n    @override\n    def dict(self, **kwargs):\n        return self.to_dict(**kwargs)\n\n    @override\n    def json(self, **kwargs) -> str:\n        return self.to_json(exclude_none=True, **kwargs)", "\n\ndef jsonable_encoder(\n    obj: Any,\n    *,\n    include: List[str] = [],\n    exclude: List[str] = [],\n    by_alias: bool = False,\n    skip_defaults: bool = False,\n    custom_encoder: Any = None,\n) -> Any:\n    \"\"\"\n    Convert any object to a JSON-serializable object.\n\n    This function is used by Aiofauna to convert objects to JSON-serializable objects.\n\n    It supports all the types supported by the standard json library, plus:\n\n    * datetime.datetime\n    * datetime.date\n    * datetime.time\n    * uuid.UUID\n    * enum.Enum\n    * pydantic.BaseModel\n    \"\"\"\n\n    if custom_encoder is None:\n        custom_encoder = FaunaJSONEncoder\n\n    if obj is str:\n        return \"string\"\n    if obj is int or obj is float:\n        return \"integer\"\n    if obj is bool:\n        return \"boolean\"\n    if obj is None:\n        return \"null\"\n    if obj is list:\n        return \"array\"\n    if obj is dict:\n        return \"object\"\n    if obj is bytes:\n        return \"binary\"\n    if obj is datetime:\n        return \"date-time\"\n    if obj is date:\n        return \"date\"\n    if obj is time:\n        return \"time\"\n    if obj is UUID:\n        return \"uuid\"\n    if obj is Enum:\n        return \"enum\"\n    if isinstance(obj, (str, int, float, bool, type(None))):\n        return obj\n    if isinstance(obj, (list, tuple, set, frozenset)):\n        return [\n            jsonable_encoder(\n                v,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                skip_defaults=skip_defaults,\n                custom_encoder=custom_encoder,\n            )\n            for v in obj\n        ]\n    if isinstance(obj, dict):\n        return {\n            jsonable_encoder(\n                k,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                skip_defaults=skip_defaults,\n                custom_encoder=custom_encoder,\n            ): jsonable_encoder(\n                v,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                skip_defaults=skip_defaults,\n                custom_encoder=custom_encoder,\n            )\n            for k, v in obj.items()\n        }\n    if isinstance(obj, bytes):\n        return base64.b64encode(obj).decode()\n    if isinstance(obj, (set, frozenset)):\n        return [\n            jsonable_encoder(\n                v,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                skip_defaults=skip_defaults,\n                custom_encoder=custom_encoder,\n            )\n            for v in obj\n        ]\n    if isinstance(obj, datetime):\n        return obj.isoformat()\n    if isinstance(obj, Enum):\n        return obj.value\n    if isinstance(obj, UUID):\n        return str(obj)\n    if isinstance(obj, type):\n        return jsonable_encoder(\n            obj.__name__,\n            include=include,\n            exclude=exclude,\n            by_alias=by_alias,\n            skip_defaults=skip_defaults,\n            custom_encoder=custom_encoder,\n        )\n\n    return custom_encoder().default(obj)", ""]}
{"filename": "aiofauna/fields.py", "chunked_list": ["from pydantic.fields import Field as F  # pylint: disable=no-name-in-module\n\n\ndef Field(*args, index: bool = False, unique: bool = False, **kwargs):\n    \"\"\"Field Factory\"\"\"\n    return F(*args, index=index, unique=unique, **kwargs)\n"]}
{"filename": "aiofauna/odm.py", "chunked_list": ["from __future__ import annotations\n\nimport asyncio\nfrom typing import Any, List, Optional, Type, TypeVar\n\nfrom dotenv import load_dotenv\nfrom pydantic import Field\nfrom pydantic.main import ModelMetaclass\n\nfrom .client import FaunaClient", "\nfrom .client import FaunaClient\nfrom .faunadb import query as q\nfrom .faunadb.errors import FaunaException\nfrom .json import JSONModel\nfrom .utils import gen_emptystr, setup_logging\n\nload_dotenv()\n\nT = TypeVar(\"T\", bound=\"FaunaModel\")", "\nT = TypeVar(\"T\", bound=\"FaunaModel\")\n\n\nclass FaunaModelMetaclass(ModelMetaclass):\n    def __new__(cls, name, bases, attrs):\n        new_cls = super().__new__(cls, name, bases, attrs)\n        cls.Metadata.__subclasses__.append(new_cls)\n        return new_cls\n\n    class Metadata:\n        __subclasses__: List[Type[FaunaModel]] = []", "\n\nclass FaunaModel(JSONModel, metaclass=FaunaModelMetaclass):\n    ref: str = Field(default_factory=gen_emptystr)\n    ts: str = Field(default_factory=gen_emptystr)\n\n    @classmethod\n    @property\n    def logger(cls):\n        return setup_logging(cls.__name__)\n\n    @classmethod\n    async def create_all(cls):\n        await asyncio.gather(\n            *[model.provision() for model in cls.Metadata.__subclasses__]\n        )\n\n    @classmethod\n    def client(cls):\n        return FaunaClient()\n\n    @classmethod\n    def q(cls):\n        return cls.client().query\n\n    @classmethod\n    async def provision(cls) -> bool:\n        _q = cls.q()\n\n        try:\n            if not await _q(q.exists(q.collection(cls.__name__.lower()))):\n                await _q(q.create_collection({\"name\": cls.__name__.lower()}))\n\n                cls.logger.info(\"Created collection %s\", cls.__name__.lower())\n\n            if not await _q(q.exists(q.index(cls.__name__.lower()))):\n                await _q(\n                    q.create_index(\n                        {\n                            \"name\": cls.__name__.lower(),\n                            \"source\": q.collection(cls.__name__.lower()),\n                        }\n                    )\n                )\n\n                cls.logger.info(\"Created index %s\", cls.__name__.lower())\n\n            for field in cls.__fields__.values():\n                if field.field_info.extra.get(\"unique\"):\n                    if not await _q(\n                        q.exists(q.index(f\"{cls.__name__.lower()}_{field.name}_unique\"))\n                    ):\n                        await _q(\n                            q.create_index(\n                                {\n                                    \"name\": f\"{cls.__name__.lower()}_{field.name}_unique\",\n                                    \"source\": q.collection(cls.__name__.lower()),\n                                    \"terms\": [{\"field\": [\"data\", field.name]}],\n                                    \"unique\": True,\n                                }\n                            )\n                        )\n\n                        cls.logger.info(\n                            \"Created unique index %s_%s\",\n                            cls.__name__.lower(),\n                            field.name,\n                        )\n                    continue\n\n                if field.field_info.extra.get(\"index\"):\n                    if not await _q(\n                        q.exists(q.index(f\"{cls.__name__.lower()}_{field.name}\"))\n                    ):\n                        await _q(\n                            q.create_index(\n                                {\n                                    \"name\": f\"{cls.__name__.lower()}_{field.name}\",\n                                    \"source\": q.collection(cls.__name__.lower()),\n                                    \"terms\": [{\"field\": [\"data\", field.name]}],\n                                }\n                            )\n                        )\n\n                        cls.logger.info(\n                            \"Created index %s_%s\", cls.__name__.lower(), field.name\n                        )\n                        continue\n\n            return True\n\n        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n            cls.logger.error(exc.__class__.__name__)\n            cls.logger.error(exc)\n\n            return False\n\n    @classmethod\n    async def find_unique(cls: Type[T], **kwargs: Any) -> T:\n        try:\n            field, value = list(kwargs.items())[0]\n            data = await cls.q()(\n                q.get(q.match(q.index(f\"{cls.__name__.lower()}_{field}_unique\"), value))\n            )\n            return cls(\n                **{\n                    **data[\"data\"],  # type: ignore\n                    \"ref\": data[\"ref\"][\"@ref\"][\"id\"],  # type: ignore\n                    \"ts\": data[\"ts\"] / 1000,  # type: ignore\n                }\n            )\n\n        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n            cls.logger.error(exc.__class__.__name__)\n            cls.logger.error(exc)\n            return None  # type: ignore\n\n    @classmethod\n    async def find_many(cls: Type[T], limit: int = 50, **kwargs: Any) -> List[T]:\n        try:\n            _q = cls.q()\n            field, value = list(kwargs.items())[0]\n            refs = await _q(\n                q.paginate(q.match(q.index(f\"{cls.__name__.lower()}_{field}\"), value))\n            )\n            refs = refs[\"data\"][:limit]\n            return await asyncio.gather(*[cls.get(item[\"@ref\"][\"id\"]) for item in refs])\n\n        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n            cls.logger.error(exc.__class__.__name__)\n            cls.logger.error(exc)\n            return []\n\n    @classmethod\n    async def get(cls: Type[T], ref: str) -> T:\n        try:\n            data = await cls.q()(q.get(q.ref(q.collection(cls.__name__.lower()), ref)))\n            return cls(\n                **{\n                    **data[\"data\"],  # type: ignore\n                    \"ref\": data[\"ref\"][\"@ref\"][\"id\"],  # type: ignore\n                    \"ts\": data[\"ts\"] / 1000,  # type: ignore\n                }\n            )\n\n        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n            cls.logger.error(exc.__class__.__name__)\n            cls.logger.error(exc)\n            raise exc\n\n    @classmethod\n    async def all(cls: Type[T], limit: int = 100, offset: int = 0) -> List[T]:\n        try:\n            _q = cls.q()\n\n            query = q.paginate(q.match(q.index(f\"{cls.__name__.lower()}\")))\n\n            refs = (await _q(query))[\"data\"][offset:limit]\n\n            return await asyncio.gather(*[cls.get(item[\"@ref\"][\"id\"]) for item in refs])\n\n        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n            cls.logger.error(exc.__class__.__name__)\n            cls.logger.error(exc)\n            raise exc\n\n    @classmethod\n    async def delete_one(cls: Type[T], **kwargs: Any) -> bool:\n        try:\n            field, value = list(kwargs.items())[0]\n            _q = cls.q()\n\n            ref = await _q(\n                q.get(q.match(q.index(f\"{cls.__name__.lower()}_{field}_unique\"), value))\n            )\n\n            await _q(q.delete(ref))\n\n            return True\n\n        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n            cls.logger.error(exc.__class__.__name__)\n            cls.logger.error(exc)\n            return False\n\n    @classmethod\n    async def delete(cls, ref: str) -> bool:\n        try:\n            await cls.q()(q.delete(q.ref(q.collection(cls.__name__.lower()), ref)))\n\n            return True\n\n        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n            cls.logger.error(exc.__class__.__name__)\n            cls.logger.error(exc)\n            return False\n\n    async def create(self: T) -> T:\n        try:\n            for field in self.__fields__.values():\n                if field.field_info.extra.get(\"unique\"):\n                    instance = await self.find_unique(\n                        **{field.name: self.__dict__[field.name]}\n                    )\n\n                    if instance is None:\n                        continue\n\n                    if issubclass(instance.__class__, FaunaModel):\n                        return instance\n\n            data = await self.__class__.q()(\n                q.create(\n                    q.collection(self.__class__.__name__.lower()), {\"data\": self.dict()}\n                )\n            )\n\n            self.ref = data[\"ref\"][\"@ref\"][\"id\"]  # type: ignore\n\n            self.ts = data[\"ts\"] / 1000  # type: ignore\n            return self\n\n        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n            self.logger.error(exc.__class__.__name__)\n            self.logger.error(exc)\n            raise exc\n\n    @classmethod\n    async def update(cls: Type[T], ref: str, **kwargs: Any) -> T:\n        try:\n            instance = await cls.q()(\n                q.update(\n                    q.ref(q.collection(cls.__name__.lower()), ref),\n                    {\"data\": kwargs.get(\"kwargs\", kwargs)},\n                )\n            )\n            return cls(\n                **{\n                    **instance[\"data\"],  # type: ignore\n                    \"ref\": instance[\"ref\"][\"@ref\"][\"id\"],  # type: ignore\n                    \"ts\": instance[\"ts\"] / 1000,  # type: ignore\n                }\n            )\n        except (FaunaException, KeyError, TypeError) as exc:\n            cls.logger.error(exc.__class__.__name__)\n            cls.logger.error(exc)\n            raise ValueError(f\"Field {ref} not found\")  # pylint: disable=all\n\n    async def save(self: T) -> Optional[T]:\n        if isinstance(self.ref, str) and len(self.ref) == 18:\n            return await self.update(self.ref, kwargs=self.dict())\n        return await self.create()\n\n    @classmethod\n    async def cleanup(cls):\n        await cls.client().cleanup()", ""]}
{"filename": "aiofauna/server.py", "chunked_list": ["\"\"\"REST API Module with automatic OpenAPI generation.\"\"\"\nimport asyncio\nimport os\nfrom functools import wraps\nfrom inspect import signature\nfrom typing import Awaitable, Callable\n\nfrom aiohttp.typedefs import Handler\nfrom aiohttp.web import Application, FileResponse, Request, Response, StreamResponse\nfrom aiohttp.web_middlewares import middleware", "from aiohttp.web import Application, FileResponse, Request, Response, StreamResponse\nfrom aiohttp.web_middlewares import middleware\nfrom aiohttp.web_ws import WebSocketResponse\nfrom aiohttp_sse import EventSourceResponse, sse_response\n\nfrom .client import APIClient\nfrom .docs import extract, html, load, transform\nfrom .helpers import do_response\nfrom .json import jsonable_encoder\nfrom .odm import FaunaModel", "from .json import jsonable_encoder\nfrom .odm import FaunaModel\nfrom .utils import setup_logging\n\nMiddleware = Callable[[Request, Handler], Awaitable[StreamResponse]]\n\n\nclass APIServer(Application):\n    \"\"\"Aiohttp Application with automatic OpenAPI generation.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, logger=setup_logging(self.__class__.__name__), **kwargs)\n        self.openapi = {\n            \"openapi\": \"3.0.0\",\n            \"info\": {\"title\": \"AioFauna\", \"version\": \"1.0.0\"},\n            \"paths\": {},\n            \"components\": {\"schemas\": {}},\n            \"description\": \"AioFauna API\",\n        }\n        self._route_open_api_params = {}\n\n        @self.get(\"/openapi.json\")\n        async def openapi():\n            response = jsonable_encoder(self.openapi)\n            return response\n\n        @self.get(\"/docs\")\n        async def docs():\n            return Response(text=html, content_type=\"text/html\")\n\n        @self.on_event(\"startup\")\n        async def startup(_):\n            await FaunaModel.create_all()\n\n        @self.on_event(\"shutdown\")\n        async def shutdown(_):\n            await APIClient.cleanup()\n            await FaunaModel.cleanup()\n\n    def document(self, path: str, method: str):\n        \"\"\"\n\n        Decorator to document a function.\n\n        \"\"\"\n\n        def decorator(func):\n            sig = signature(func)\n            params = sig.parameters\n            open_api_params = extract(params.copy(), path)\n            self._route_open_api_params[(path, method)] = open_api_params\n            transform(self.openapi, path, method, func, open_api_params)\n\n            async def wrapper(*args, **kwargs):\n                request: Request = args[0]\n                args = args[1:]\n                args_to_apply = await load(request, params.copy())\n                definitive_args = {}\n                for name, param in params.items():\n                    if name in args_to_apply:\n                        definitive_args[name] = args_to_apply[name]\n                    elif param.default is not param.empty:\n                        definitive_args[name] = param.default\n                    else:\n                        raise ValueError(\n                            f\"Missing parameter {name} for {func.__name__}\"\n                        )\n                if asyncio.iscoroutinefunction(func):\n                    response = await func(*args, **kwargs, **definitive_args)\n                else:\n                    response = func(*args, **kwargs, **definitive_args)\n                return do_response(response)\n\n            func.injectable = True\n            wrapper._handler = func\n            return wrapper\n\n        return decorator\n\n    def get(self, path: str, **kwargs):\n        \"\"\"GET decorator\"\"\"\n\n        def decorator(func):\n            self.router.add_get(path, self.document(path, \"GET\")(func), **kwargs)\n            return func\n\n        return decorator\n\n    def post(self, path: str, **kwargs):\n        \"\"\"POST decorator\"\"\"\n\n        def decorator(func):\n            self.router.add_post(path, self.document(path, \"POST\")(func), **kwargs)\n            return func\n\n        return decorator\n\n    def put(self, path: str, **kwargs):\n        \"\"\"PUT decorator\"\"\"\n\n        def decorator(func):\n            self.router.add_put(path, self.document(path, \"PUT\")(func), **kwargs)\n            return func\n\n        return decorator\n\n    def delete(self, path: str, **kwargs):\n        \"\"\"DELETE decorator\"\"\"\n\n        def decorator(func):\n            self.router.add_delete(path, self.document(path, \"DELETE\")(func), **kwargs)\n            return func\n\n        return decorator\n\n    def patch(self, path: str, **kwargs):\n        \"\"\"PATCH decorator\"\"\"\n\n        def decorator(func):\n            self.router.add_patch(path, self.document(path, \"PATCH\")(func), **kwargs)\n            return func\n\n        return decorator\n\n    def head(self, path: str, **kwargs):\n        \"\"\"HEAD decorator\"\"\"\n\n        def decorator(func):\n            self.router.add_head(path, self.document(path, \"HEAD\")(func), **kwargs)\n            return func\n\n        return decorator\n\n    def options(self, path: str, **kwargs):\n        \"\"\"OPTIONS decorator\"\"\"\n\n        def decorator(func):\n            self.router.add_options(\n                path, self.document(path, \"OPTIONS\")(func), **kwargs\n            )\n            return func\n\n        return decorator\n\n    def on_event(self, event: str):\n        \"\"\"On event handler\"\"\"\n\n        def decorator(func):\n            if event not in (\"startup\", \"shutdown\"):\n                raise ValueError(\"Event must be startup or shutdown\")\n            elif event == \"startup\":\n                self.on_startup.append(func)\n            else:\n                self.on_shutdown.append(func)\n            return func\n\n        return decorator\n\n    def sse(self, path: str) -> Callable:  # pylint: disable=invalid-name\n        \"\"\"Server-Sent Events decorator\"\"\"\n\n        def decorator(func: Callable) -> Callable:\n            @wraps(func)\n            async def wrapper(request: Request) -> EventSourceResponse:\n                async with sse_response(request) as resp:\n                    args_to_apply = await load(\n                        request, signature(func).parameters.copy()\n                    )\n                    definitive_args = {}\n                    for name, param in signature(func).parameters.items():\n                        if param.annotation == EventSourceResponse:\n                            definitive_args[name] = resp\n                        elif name in args_to_apply:\n                            definitive_args[name] = args_to_apply[name]\n                            args_to_apply.pop(name)\n                        elif param.default is not param.empty:\n                            definitive_args[name] = param.default\n                        else:\n                            raise ValueError(\n                                f\"Missing parameter {name} for {func.__name__}\"\n                            )\n                    await func(**definitive_args)\n                    return resp\n\n            self.router.add_get(path, wrapper)\n            return wrapper\n\n        return decorator\n\n    def websocket(self, path: str) -> Callable:  # pylint: disable=invalid-name\n        \"\"\"Websocket decorator\"\"\"\n\n        def decorator(func: Callable) -> Callable:\n            @wraps(func)\n            async def wrapper(request: Request):\n                args_to_apply = await load(request, signature(func).parameters.copy())\n                ws = WebSocketResponse()\n                await ws.prepare(request)\n                definitive_args = {}\n                for name, param in signature(func).parameters.items():\n                    if param.annotation == WebSocketResponse:\n                        definitive_args[name] = ws\n                    elif name in args_to_apply:\n                        definitive_args[name] = args_to_apply[name]\n                        args_to_apply.pop(name)\n                    elif param.default is not param.empty:\n                        definitive_args[name] = param.default\n                    else:\n                        raise ValueError(\n                            f\"Missing parameter {name} for {func.__name__}\"\n                        )\n                await func(**definitive_args)\n                return ws\n\n            self.router.add_get(path, wrapper)\n            return wrapper\n\n        return decorator\n\n    def static(self):\n        \"\"\"Static folder creation and serving\"\"\"\n        try:\n            os.makedirs(\"static\", exist_ok=True)\n        except OSError:\n            pass\n        self.router.add_static(\"/\", \"static\")\n\n        @self.get(\"/\")\n        def index():\n            return FileResponse(\"static/index.html\")\n\n        return self\n\n    def middleware(self, func: Middleware) -> Middleware:\n        @wraps(func)\n        @middleware\n        async def wrapper(request: Request, handler: Handler) -> Response:\n            response = await func(request, handler)\n            if isinstance(response, Response):\n                return response\n            return do_response(response)\n\n        self.middlewares.append(wrapper)\n        return wrapper", ""]}
{"filename": "aiofauna/helpers.py", "chunked_list": ["\"\"\"\nFlaskaesque helper functions for aiohttp.\n\"\"\"\nimport asyncio\nimport functools\nimport json\nimport types\nimport typing\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import singledispatch", "from concurrent.futures import ThreadPoolExecutor\nfrom functools import singledispatch\nfrom typing import Any, List, Union\n\nfrom aiohttp.web import HTTPException, Request, Response, json_response\nfrom pydantic import BaseModel\n\nfrom aiofauna.json import FaunaJSONEncoder\n\nfrom .json import parse_json, to_json", "\nfrom .json import parse_json, to_json\nfrom .odm import FaunaModel\n\nT = typing.TypeVar(\"T\")\n\n\ndef asyncify(\n    func: typing.Callable[..., typing.Any],\n) -> typing.Callable[..., typing.Awaitable[typing.Any]]:\n    @functools.wraps(func)\n    def wrapper(self, *args, **kwargs):\n        bound = functools.partial(func, self, *args, **kwargs)\n        if asyncio.get_event_loop().is_running():\n            loop = asyncio.get_event_loop()\n            return loop.run_in_executor(self.executor, bound)\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        return loop.run_in_executor(self.executor, bound)\n\n    return typing.cast(typing.Callable[..., typing.Awaitable[typing.Any]], wrapper)", "\n\ndef aio(max_workers: int = 5) -> typing.Callable[[typing.Type], typing.Type]:\n    \"\"\"Decorator that converts all the methods of a class into async methods.\"\"\"\n\n    def decorator(cls: typing.Type) -> typing.Type:\n        attrs: typing.Dict[str, typing.Any] = {}\n        attrs[\"executor\"] = ThreadPoolExecutor(max_workers=max_workers)\n        for attr_name, attr_value in cls.__dict__.items():\n            if (\n                isinstance(attr_value, types.FunctionType)\n                and attr_name.startswith(\"__\") is False\n            ):\n                attrs[attr_name] = asyncify(attr_value)\n            else:\n                attrs[attr_name] = attr_value\n        return type(cls.__name__, cls.__bases__, attrs)\n\n    return decorator", "\n\n@singledispatch\ndef do_response(response: Any) -> Response:\n    \"\"\"\n    Flask-esque function to make a response from a function.\n    \"\"\"\n    return response\n\n", "\n\n@do_response.register(BaseModel)\ndef _(response: BaseModel) -> Response:\n    return json_response(response.dict(exclude_none=True), dumps=to_json)\n\n\n@do_response.register(FaunaModel)\ndef _(response: FaunaModel) -> Response:\n    return json_response(response.dict(), dumps=to_json)", "def _(response: FaunaModel) -> Response:\n    return json_response(response.dict(), dumps=to_json)\n\n\n@do_response.register(dict)\ndef _(response: dict) -> Response:\n    return json_response(response, dumps=to_json)\n\n\n@do_response.register(str)\ndef _(response: str) -> Response:\n    if response.startswith(\"<\") and response.endswith(\">\"):\n        return Response(status=200, text=response, content_type=\"text/html\")\n    return Response(status=200, text=response, content_type=\"text/plain\")", "\n@do_response.register(str)\ndef _(response: str) -> Response:\n    if response.startswith(\"<\") and response.endswith(\">\"):\n        return Response(status=200, text=response, content_type=\"text/html\")\n    return Response(status=200, text=response, content_type=\"text/plain\")\n\n\n@do_response.register(bytes)\ndef _(response: bytes) -> Response:\n    return Response(status=200, body=response, content_type=\"application/octet-stream\")", "@do_response.register(bytes)\ndef _(response: bytes) -> Response:\n    return Response(status=200, body=response, content_type=\"application/octet-stream\")\n\n\n@do_response.register(int)\ndef _(response: int) -> Response:\n    return Response(status=200, text=str(response), content_type=\"text/plain\")\n\n", "\n\n@do_response.register(float)\ndef _(response: float) -> Response:\n    return Response(status=200, text=str(response), content_type=\"text/plain\")\n\n\n@do_response.register(bool)\ndef _(response: bool) -> Response:\n    return Response(status=200, text=str(response), content_type=\"text/plain\")", "def _(response: bool) -> Response:\n    return Response(status=200, text=str(response), content_type=\"text/plain\")\n\n\n@do_response.register(list)\ndef _(response: List[Union[FaunaModel, BaseModel, dict, str, int, float]]) -> Response:\n    return json_response([x for x in response], dumps=to_json)\n"]}
{"filename": "aiofauna/llm/schemas.py", "chunked_list": ["\"\"\"Chat Completions Schemas\"\"\"\nfrom typing import List, Literal, NamedTuple, Union\n\nimport numpy as np\n\nfrom ..odm import FaunaModel\n\nVector = Union[np.ndarray, List[float]]\n\nRole = Literal[\"assistant\", \"user\", \"system\", \"function\"]", "\nRole = Literal[\"assistant\", \"user\", \"system\", \"function\"]\nModel = Literal[\"gpt-4-0613\", \"gpt-3.5-turbo-16k-0613\"]\n\n\nclass Message(NamedTuple):\n    \"\"\"Defines a message within a conversation.\"\"\"\n\n    role: Role\n    content: str", "\n\nclass ChatCompletionRequest(NamedTuple):\n    \"\"\"Defines a request for a chat completion.\"\"\"\n\n    model: Model\n    messages: List[Message]\n    temperature: float\n    max_tokens: int\n    stream: bool", "\n\nclass ChatCompletionUssage(NamedTuple):\n    \"\"\"Defines the usage of the tokens for a chat completion.\"\"\"\n\n    prompt_tokens: int\n    completion_tokens: int\n    total_tokens: int\n\n\nclass ChatCompletionChoice(NamedTuple):\n    \"\"\"Defines a choice in a chat completion.\"\"\"\n\n    index: int\n    message: Message\n    finish_reason: str", "\n\nclass ChatCompletionChoice(NamedTuple):\n    \"\"\"Defines a choice in a chat completion.\"\"\"\n\n    index: int\n    message: Message\n    finish_reason: str\n\n\nclass ChatCompletionResponse(NamedTuple):\n    \"\"\"Defines a response for a chat completion.\"\"\"\n\n    id: str\n    object: str\n    created: int\n    model: Model\n    choices: List[ChatCompletionChoice]\n    usage: ChatCompletionUssage\n    stream: bool", "\n\nclass ChatCompletionResponse(NamedTuple):\n    \"\"\"Defines a response for a chat completion.\"\"\"\n\n    id: str\n    object: str\n    created: int\n    model: Model\n    choices: List[ChatCompletionChoice]\n    usage: ChatCompletionUssage\n    stream: bool", "\n\nclass VectorResponse(NamedTuple):\n    text: str\n    score: float\n\n\nclass Embedding(FaunaModel):\n    \"\"\"Defines an embedding.\"\"\"\n\n    vector: Vector\n    namespace: str\n    text: str\n\n    async def similarity_search(\n        self, vector: Vector, namespace: str, limit: int = 1000, k: int = 10\n    ) -> List[VectorResponse]:\n        \"\"\"\n        Searches for similar embeddings.\n\n        Args:\n            vector: The vector to search for.\n            namespace: The namespace to search in.\n            limit: The maximum number of results to return.\n            k: The number of results to return per query.\n\n        Returns:\n            A list of VectorResponse.\n        \"\"\"\n        results = await self.find_many(limit=limit, namespace=namespace)\n        similarities = [\n            VectorResponse(text=result.text, score=result.similarity(vector))\n            for result in results\n        ]\n        return sorted(similarities, key=lambda x: x.score, reverse=True)[:k]\n\n    def similarity(self, vector: Vector):\n        return (np.dot(self.vector, vector)) / (\n            (np.linalg.norm(self.vector) * np.linalg.norm(vector))\n        )", ""]}
{"filename": "aiofauna/llm/llm.py", "chunked_list": ["import json\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Any, AsyncGenerator, Dict, List, NamedTuple, Optional, Type\nfrom uuid import uuid4\n\nimport openai\nfrom pydantic import Field  # pylint: disable=no-name-in-module\nfrom tqdm import tqdm\n", "from tqdm import tqdm\n\nfrom ..client import APIClient, APIException\nfrom ..typedefs import F, FunctionType, MetaData, Vector\nfrom ..utils import chunker, handle_errors, setup_logging\nfrom .schemas import List, Model\n\nlogger = setup_logging(__name__)\n\n\nclass Greet(FunctionType):\n    \"\"\"Placeholder function for greeting the user.\"\"\"\n\n    prompt: str = Field(..., description=\"The prompt to use for the completion.\")\n\n    async def run(self):\n        return \"Hello, I am a chatbot. How are you?\"", "\n\nclass Greet(FunctionType):\n    \"\"\"Placeholder function for greeting the user.\"\"\"\n\n    prompt: str = Field(..., description=\"The prompt to use for the completion.\")\n\n    async def run(self):\n        return \"Hello, I am a chatbot. How are you?\"\n", "\n\nclass UpsertVector(NamedTuple):\n    id: str = Field(default_factory=lambda: str(uuid4()))\n    values: Vector = Field(...)\n    metadata: MetaData = Field(...)\n\n\nclass UpsertRequest(NamedTuple):\n    vectors: List[UpsertVector]\n    namespace: str", "class UpsertRequest(NamedTuple):\n    vectors: List[UpsertVector]\n    namespace: str\n\n\nclass UpsertResponse(NamedTuple):\n    upsertedCount: int\n\n\nclass QueryRequest(NamedTuple):\n    topK: int\n    namespace: str\n    vector: Vector\n    includeMetadata: bool", "\nclass QueryRequest(NamedTuple):\n    topK: int\n    namespace: str\n    vector: Vector\n    includeMetadata: bool\n\n\nclass QueryMatch(NamedTuple):\n    id: str\n    score: float\n    values: Vector\n    metadata: MetaData", "class QueryMatch(NamedTuple):\n    id: str\n    score: float\n    values: Vector\n    metadata: MetaData\n\n\nclass QueryResponse(NamedTuple):\n    matches: List[QueryMatch]\n    namespace: str\n    results: int", "\n\nclass IngestRequest(NamedTuple):\n    namespace: str\n    texts: List[str]\n\n\n@dataclass\nclass LLMStack(APIClient):\n    base_url: str = field(default_factory=lambda: os.environ.get(\"PINECONE_URL\"))  # type: ignore\n    headers: Dict[str, str] = field(default_factory=lambda: {\"api-key\": os.environ.get(\"PINECONE_API_KEY\")})  # type: ignore\n    model:Model = field(default_factory=lambda:\"gpt-3.5-turbo-16k-0613\")\n\n    @handle_errors\n    async def upsert_vectors(self, request: UpsertRequest) -> UpsertResponse:\n        response = await self.fetch(\n            \"/vectors/upsert\", method=\"POST\", json=request._asdict()\n        )\n        return UpsertResponse(**response)\n\n    @handle_errors\n    async def query_vectors(self, request: QueryRequest) -> QueryResponse:\n        response = await self.fetch(\"/query\", method=\"POST\", json=request._asdict())\n        return QueryResponse(**response)\n\n    @handle_errors\n    async def upsert_messages(\n        self,\n        user_embedding: Vector,\n        openai_embedding: Vector,\n        prompt: str,\n        text: str,\n        namespace: str,\n    ) -> None:\n        upsert_request = UpsertRequest(\n            vectors=[\n                UpsertVector(values=user_embedding, metadata={\"text\": prompt}),\n                UpsertVector(values=openai_embedding, metadata={\"text\": text}),\n            ],\n            namespace=namespace,\n        )\n        await self.upsert_vectors(upsert_request)\n\n    @handle_errors\n    async def chat(self, text: str, context: str) -> str:\n        \"\"\"Chat completion with no functions.\"\"\"\n        messages = [\n            {\"role\": \"user\", \"content\": text},\n            {\"role\": \"system\", \"content\": context},\n        ]\n        logger.info(\"Chat messages: %s\", messages)\n        response = await openai.ChatCompletion.acreate(\n            model=self.model, messages=messages\n        )\n        logger.info(\"Chat response: %s\", response)\n        assert isinstance(response, dict)\n        return response[\"choices\"][0][\"message\"][\"content\"]\n\n    @handle_errors\n    async def chat_with_memory(self, text: str, namespace: str, context: str) -> str:\n        \"\"\"Chat completion with similarity search retrieval from pinecone\"\"\"\n        try:\n            embedding = await self.create_embeddings(text)\n            query_request = QueryRequest(\n                vector=embedding, namespace=namespace, topK=3, includeMetadata=True\n            )\n            query_response = await self.query_vectors(query_request)\n            similar_text_chunks = [\n                i.get(\"metadata\", {}).get(\"text\", \"\") for i in query_response.matches  # type: ignore\n            ]\n            similar_text = \"Previous Similar results:\" + \"\\n\".join(similar_text_chunks)\n            messages = [\n                {\"role\": \"user\", \"content\": text},\n                {\"role\": \"system\", \"content\": similar_text},\n                {\"role\": \"system\", \"content\": context},\n            ]\n            response = await openai.ChatCompletion.acreate(\n                model=self.model,\n                messages=messages,\n            )\n            return response[\"choices\"][0][\"message\"][\"content\"]  # type: ignore\n        except Exception as exc:\n            logger.exception(exc)\n            raise APIException(message=str(exc)) from exc\n\n    @handle_errors\n    async def chat_with_functions(\n        self,\n        text: str,\n        context: Optional[str] = None,\n        functions: List[Type[F]] = FunctionType._subclasses,\n    ) -> Any:\n        \"\"\"Chat completion with functions.\"\"\"\n        return await function_call(text, context=context, functions=functions)\n\n    @handle_errors\n    async def create_embeddings(self, text: str) -> Vector:\n        \"\"\"Creates embeddings for the given texts.\"\"\"\n        response = await openai.Embedding.acreate(\n            model=\"text-embedding-ada-002\",\n            input=text,\n        )\n        return response[\"data\"][0][\"embedding\"]  # type: ignore\n\n    async def chat_stream(self, text: str) -> AsyncGenerator[str, None]:\n        \"\"\"Chat completion stream with no functions.\"\"\"\n        response = openai.ChatCompletion.acreate(\n            model=self.model,\n            messages=[{\"role\": \"user\", \"content\": text}],\n            stream=True,\n        )\n        async for i in response:  # type: ignore\n            assert isinstance(i, dict)\n            delta = i[\"choices\"][0][\"delta\"]\n            if \"content\" in delta:\n                yield delta[\"content\"]\n\n    async def chat_stream_with_memory(\n        self, text: str, namespace: str = \"default\"\n    ) -> AsyncGenerator[str, None]:\n        \"\"\"Chat completion stream with similarity search retrieval from pinecone\"\"\"\n        try:\n            embedding = await self.create_embeddings(text)\n            query_response: QueryResponse = await self.query_vectors(\n                QueryRequest(\n                    vector=embedding, namespace=namespace, topK=3, includeMetadata=True\n                )\n            )\n            similar_text_chunks = [\n                i.metadata.get(\"text\", \"\") for i in query_response.matches\n            ]\n            similar_text = \"Previous Similar results:\" + \"\\n\".join(similar_text_chunks)\n            response = openai.ChatCompletion.acreate(\n                model=self.model,\n                messages=[\n                    {\"role\": \"user\", \"content\": text},\n                    {\"role\": \"system\", \"content\": similar_text},\n                ],\n                stream=True,\n            )\n            assert isinstance(response, AsyncGenerator)\n            async for i in response:\n                assert isinstance(i, dict)\n                delta = i[\"choices\"][0][\"delta\"]\n                if \"content\" in delta:\n                    yield delta[\"content\"]\n        except Exception as exc:\n            logger.exception(exc.__class__.__name__)\n            logger.exception(exc)\n            raise APIException(message=str(exc)) from exc\n\n    @handle_errors\n    async def chatgpt(\n        self, text: str, context: str, namespace: str = \"default\", memory: bool = False\n    ):\n        \"\"\"ChatGPT4 is a function that allows you to chat with GPT-4, with the option of using memory or functions.\"\"\"\n        if memory:\n            return await self.chat_with_memory(\n                text=text, namespace=namespace, context=context\n            )\n        return await self.chat(text=text, context=context)\n\n    @handle_errors\n    async def ingest_bulk(self, data: IngestRequest, chunksize: int = 32):\n        total_chunks = len(data.texts) // chunksize + (len(data.texts) % chunksize > 0)\n\n        for chunk in tqdm(\n            chunker(data.texts, chunksize),\n            total=total_chunks,\n            desc=\"Ingesting\",\n            unit=\"chunks\",\n        ):\n            await self.upsert_vectors(\n                UpsertRequest(\n                    vectors=[\n                        UpsertVector(\n                            values=await self.create_embeddings(text),\n                            metadata={\"text\": text},\n                        )\n                        for text in chunk\n                    ],\n                    namespace=data.namespace,\n                )\n            )", "class LLMStack(APIClient):\n    base_url: str = field(default_factory=lambda: os.environ.get(\"PINECONE_URL\"))  # type: ignore\n    headers: Dict[str, str] = field(default_factory=lambda: {\"api-key\": os.environ.get(\"PINECONE_API_KEY\")})  # type: ignore\n    model:Model = field(default_factory=lambda:\"gpt-3.5-turbo-16k-0613\")\n\n    @handle_errors\n    async def upsert_vectors(self, request: UpsertRequest) -> UpsertResponse:\n        response = await self.fetch(\n            \"/vectors/upsert\", method=\"POST\", json=request._asdict()\n        )\n        return UpsertResponse(**response)\n\n    @handle_errors\n    async def query_vectors(self, request: QueryRequest) -> QueryResponse:\n        response = await self.fetch(\"/query\", method=\"POST\", json=request._asdict())\n        return QueryResponse(**response)\n\n    @handle_errors\n    async def upsert_messages(\n        self,\n        user_embedding: Vector,\n        openai_embedding: Vector,\n        prompt: str,\n        text: str,\n        namespace: str,\n    ) -> None:\n        upsert_request = UpsertRequest(\n            vectors=[\n                UpsertVector(values=user_embedding, metadata={\"text\": prompt}),\n                UpsertVector(values=openai_embedding, metadata={\"text\": text}),\n            ],\n            namespace=namespace,\n        )\n        await self.upsert_vectors(upsert_request)\n\n    @handle_errors\n    async def chat(self, text: str, context: str) -> str:\n        \"\"\"Chat completion with no functions.\"\"\"\n        messages = [\n            {\"role\": \"user\", \"content\": text},\n            {\"role\": \"system\", \"content\": context},\n        ]\n        logger.info(\"Chat messages: %s\", messages)\n        response = await openai.ChatCompletion.acreate(\n            model=self.model, messages=messages\n        )\n        logger.info(\"Chat response: %s\", response)\n        assert isinstance(response, dict)\n        return response[\"choices\"][0][\"message\"][\"content\"]\n\n    @handle_errors\n    async def chat_with_memory(self, text: str, namespace: str, context: str) -> str:\n        \"\"\"Chat completion with similarity search retrieval from pinecone\"\"\"\n        try:\n            embedding = await self.create_embeddings(text)\n            query_request = QueryRequest(\n                vector=embedding, namespace=namespace, topK=3, includeMetadata=True\n            )\n            query_response = await self.query_vectors(query_request)\n            similar_text_chunks = [\n                i.get(\"metadata\", {}).get(\"text\", \"\") for i in query_response.matches  # type: ignore\n            ]\n            similar_text = \"Previous Similar results:\" + \"\\n\".join(similar_text_chunks)\n            messages = [\n                {\"role\": \"user\", \"content\": text},\n                {\"role\": \"system\", \"content\": similar_text},\n                {\"role\": \"system\", \"content\": context},\n            ]\n            response = await openai.ChatCompletion.acreate(\n                model=self.model,\n                messages=messages,\n            )\n            return response[\"choices\"][0][\"message\"][\"content\"]  # type: ignore\n        except Exception as exc:\n            logger.exception(exc)\n            raise APIException(message=str(exc)) from exc\n\n    @handle_errors\n    async def chat_with_functions(\n        self,\n        text: str,\n        context: Optional[str] = None,\n        functions: List[Type[F]] = FunctionType._subclasses,\n    ) -> Any:\n        \"\"\"Chat completion with functions.\"\"\"\n        return await function_call(text, context=context, functions=functions)\n\n    @handle_errors\n    async def create_embeddings(self, text: str) -> Vector:\n        \"\"\"Creates embeddings for the given texts.\"\"\"\n        response = await openai.Embedding.acreate(\n            model=\"text-embedding-ada-002\",\n            input=text,\n        )\n        return response[\"data\"][0][\"embedding\"]  # type: ignore\n\n    async def chat_stream(self, text: str) -> AsyncGenerator[str, None]:\n        \"\"\"Chat completion stream with no functions.\"\"\"\n        response = openai.ChatCompletion.acreate(\n            model=self.model,\n            messages=[{\"role\": \"user\", \"content\": text}],\n            stream=True,\n        )\n        async for i in response:  # type: ignore\n            assert isinstance(i, dict)\n            delta = i[\"choices\"][0][\"delta\"]\n            if \"content\" in delta:\n                yield delta[\"content\"]\n\n    async def chat_stream_with_memory(\n        self, text: str, namespace: str = \"default\"\n    ) -> AsyncGenerator[str, None]:\n        \"\"\"Chat completion stream with similarity search retrieval from pinecone\"\"\"\n        try:\n            embedding = await self.create_embeddings(text)\n            query_response: QueryResponse = await self.query_vectors(\n                QueryRequest(\n                    vector=embedding, namespace=namespace, topK=3, includeMetadata=True\n                )\n            )\n            similar_text_chunks = [\n                i.metadata.get(\"text\", \"\") for i in query_response.matches\n            ]\n            similar_text = \"Previous Similar results:\" + \"\\n\".join(similar_text_chunks)\n            response = openai.ChatCompletion.acreate(\n                model=self.model,\n                messages=[\n                    {\"role\": \"user\", \"content\": text},\n                    {\"role\": \"system\", \"content\": similar_text},\n                ],\n                stream=True,\n            )\n            assert isinstance(response, AsyncGenerator)\n            async for i in response:\n                assert isinstance(i, dict)\n                delta = i[\"choices\"][0][\"delta\"]\n                if \"content\" in delta:\n                    yield delta[\"content\"]\n        except Exception as exc:\n            logger.exception(exc.__class__.__name__)\n            logger.exception(exc)\n            raise APIException(message=str(exc)) from exc\n\n    @handle_errors\n    async def chatgpt(\n        self, text: str, context: str, namespace: str = \"default\", memory: bool = False\n    ):\n        \"\"\"ChatGPT4 is a function that allows you to chat with GPT-4, with the option of using memory or functions.\"\"\"\n        if memory:\n            return await self.chat_with_memory(\n                text=text, namespace=namespace, context=context\n            )\n        return await self.chat(text=text, context=context)\n\n    @handle_errors\n    async def ingest_bulk(self, data: IngestRequest, chunksize: int = 32):\n        total_chunks = len(data.texts) // chunksize + (len(data.texts) % chunksize > 0)\n\n        for chunk in tqdm(\n            chunker(data.texts, chunksize),\n            total=total_chunks,\n            desc=\"Ingesting\",\n            unit=\"chunks\",\n        ):\n            await self.upsert_vectors(\n                UpsertRequest(\n                    vectors=[\n                        UpsertVector(\n                            values=await self.create_embeddings(text),\n                            metadata={\"text\": text},\n                        )\n                        for text in chunk\n                    ],\n                    namespace=data.namespace,\n                )\n            )", "\n\nasync def parse_openai_response(  # pylint: disable=dangerous-default-value\n    response: dict,\n    functions: List[\n        Type[F]\n    ] = FunctionType._subclasses,  # pylint: disable=protected-access\n) -> Any:\n    \"\"\"Parse the response from OpenAI and return the result.\"\"\"\n    choice = response[\"choices\"][0][\"message\"]\n    if \"function_call\" in choice:\n        function_call_ = choice[\"function_call\"]\n        name = function_call_[\"name\"]\n        arguments = function_call_[\"arguments\"]\n        for i in functions:\n            if i.__name__ == name:\n                result = await i.run(i(**json.loads(arguments)))\n                break\n        else:\n            raise ValueError(f\"Function {name} not found\")\n        return result", "    \"\"\"Parse the response from OpenAI and return the result.\"\"\"\n    choice = response[\"choices\"][0][\"message\"]\n    if \"function_call\" in choice:\n        function_call_ = choice[\"function_call\"]\n        name = function_call_[\"name\"]\n        arguments = function_call_[\"arguments\"]\n        for i in functions:\n            if i.__name__ == name:\n                result = await i.run(i(**json.loads(arguments)))\n                break\n        else:\n            raise ValueError(f\"Function {name} not found\")\n        return result", "    return choice[\"content\"]\n\n\n@handle_errors\nasync def function_call(  # pylint: disable=dangerous-default-value\n    text: str,\n    context: Optional[str] = None,\n    model: Model = \"gpt-3.5-turbo-16k-0613\",\n    functions: List[\n        Type[F]", "    functions: List[\n        Type[F]\n    ] = FunctionType._subclasses,  # pylint: disable=protected-access\n) -> Any:\n    \"\"\"\n    Function to call a OpenAI function with given text and context.\n\n    Arguments:\n    text -- Input text for the function\n    context -- Optional context for the function", "    text -- Input text for the function\n    context -- Optional context for the function\n    model -- Model to be used. Defaults to \"gpt-4-0613\"\n    functions -- List of function types. Defaults to all subclasses of FunctionType.\n    \"\"\"\n    if context is not None:\n        messages = [\n            {\"role\": \"user\", \"content\": text},\n            {\"role\": \"system\", \"content\": context},\n        ]\n    else:\n        messages = [{\"role\": \"user\", \"content\": text}]", "    response = await openai.ChatCompletion.acreate(\n        model=model, messages=messages, functions=[i.openaischema for i in functions]\n    )\n    return await parse_openai_response(response, functions=functions)  # type: ignore\n"]}
{"filename": "aiofauna/llm/__init__.py", "chunked_list": ["from .llm import LLMStack, function_call\n"]}
{"filename": "aiofauna/faunadb/page.py", "chunked_list": ["from . import query\n\n\nclass Page:\n    @staticmethod\n    def from_raw(raw):\n        return Page(raw[\"data\"], raw.get(\"before\"), raw.get(\"after\"))\n\n    def __init__(self, data, before=None, after=None):\n        self.data = data\n        self.before = before\n        self.after = after\n\n    def map_data(self, func):\n        return Page([func(x) for x in self.data], self.before, self.after)\n\n    def __repr__(self):\n        return \"Page(data=%s, before=%s, after=%s)\" % (\n            self.data,\n            self.before,\n            self.after,\n        )\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, Page)\n            and self.data == other.data\n            and self.before == other.before\n            and self.after == other.after\n        )\n\n    @staticmethod\n    def set_iterator(client, set_query, map_lambda=None, mapper=None, page_size=None):\n        def get_page(**kwargs):\n            queried = query.paginate(set_query, **kwargs)\n            if map_lambda is not None:\n                queried = query.map_(map_lambda, queried)\n            return Page.from_raw(client.query(queried))\n\n        page = get_page(size=page_size)\n        for val in page.data:\n            yield val if mapper is None else mapper(val)\n        next_cursor = \"after\" if page.after is not None else \"before\"\n        while getattr(page, next_cursor) is not None:\n            page = get_page(\n                **{\"size\": page_size, next_cursor: getattr(page, next_cursor)}\n            )\n            for val in page.data:\n                yield val if mapper is None else mapper(val)", ""]}
{"filename": "aiofauna/faunadb/objects.py", "chunked_list": ["\"\"\"\nTypes used in queries and responses.\nSee the `docs <https://app.fauna.com/documentation/reference/queryapi#simple-type>`__.\n\"\"\"\nfrom datetime import datetime\n\nfrom iso8601 import parse_date\n\nfrom .query import Expr\n", "from .query import Expr\n\n\nclass Ref(Expr):\n    \"\"\"\n    ```python\n    Ref(id, cls=None, db=None)\n    ```\n    A reference to a document in a collection or index.\n\n    :param id: The document's ID.\n    :param cls: The collection or index class.\n    :param db: The database.\n\n    `Ref`\n\n    Is a special type in FaunaDB. It is used to represent a document in a collection or index.\n\n    It is serialized to JSON as an object with the `@ref` key. Passing the `id` to the response.\n\n    \"\"\"\n\n    def __init__(self, id, cls=None, db=None):\n        if id is None:\n            raise ValueError(\"The Ref must have an id.\")\n\n        value = {\"id\": id}\n\n        if cls != None:\n            value[\"collection\"] = cls\n\n        if db != None:\n            value[\"database\"] = db\n\n        super(Ref, self).__init__(value)\n\n    def collection(self):\n        \"\"\"\n        Gets the collection part out of the Ref.\n        \"\"\"\n        return self.value.get(\"collection\")\n\n    def database(self):\n        \"\"\"\n        Gets the database part out of the Ref.\n        \"\"\"\n        return self.value.get(\"database\")\n\n    def id(self):\n        \"\"\"\n        Gets the id part out of the Ref.\n        \"\"\"\n        return self.value[\"id\"]\n\n    def to_fauna_json(self):\n        return {\"@ref\": self.value}\n\n    def __str__(self):\n        col = (\n            f\", collection={self.value['collection']}\"\n            if \"collection\" in self.value\n            else \"\"\n        )\n        db = (\n            f\", database={self.value.get('database')}\"\n            if \"database\" in self.value\n            else \"\"\n        )\n        return \"Ref(id=%s%s%s)\" % (self.value[\"id\"], col, db)\n\n    def __repr__(self):\n        col = (\n            f\", collection={self.value['collection']}\"\n            if \"collection\" in self.value\n            else \"\"\n        )\n        db = (\n            f\", database={self.value.get('database')}\"\n            if \"database\" in self.value\n            else \"\"\n        )\n        return \"Ref(id=%s%s%s)\" % (self.value[\"id\"], col, db)\n\n    def __eq__(self, other):\n        return isinstance(other, Ref) and self.value == other.value\n\n    def __ne__(self, other):\n        # pylint: disable=unneeded-not\n        return not self == other", "\n\nclass Native(object):\n    COLLECTIONS = Ref(\"collections\")\n    INDEXES = Ref(\"indexes\")\n    DATABASES = Ref(\"databases\")\n    FUNCTIONS = Ref(\"functions\")\n    KEYS = Ref(\"keys\")\n    TOKENS = Ref(\"tokens\")\n    CREDENTIALS = Ref(\"credentials\")\n    ROLES = Ref(\"roles\")\n    ACCESS_PROVIDERS = Ref(\"access_providers\")\n\n    def __init__(self):\n        raise TypeError\n\n    @classmethod\n    def from_name(cls, name):\n        return getattr(cls, name.upper(), Ref(name))", "\n\nclass SetRef(Expr):\n    \"\"\"\n    FaunaDB Set.\n    This represents a set returned as part of a response.\n    For query sets see :doc:`query`.\n    \"\"\"\n\n    def __init__(self, set_ref):\n        if isinstance(set_ref, Expr):\n            value = set_ref.value\n        else:\n            value = set_ref\n\n        super(SetRef, self).__init__(value)\n\n    def to_fauna_json(self):\n        return {\"@set\": self.value}\n\n    def __repr__(self):\n        return f\"SetRef({repr(self.value)})\"\n\n    def __eq__(self, other):\n        return isinstance(other, SetRef) and self.value == other.value\n\n    def __ne__(self, other):\n        # pylint: disable=unneeded-not\n        return not self == other", "\n\nclass FaunaTime(Expr):\n    \"\"\"\n    FaunaDB time. See the `docs <https://app.fauna.com/documentation/reference/queryapi#special-type>`__.\n\n    For dates, regular :class:`datetime.date` objects are used.\n    \"\"\"\n\n    def __init__(self, value):\n        \"\"\"\n        :param value:\n          If a :class:`datetime.datetime` is passed, it is converted to a string.\n          Must include an offset.\n        \"\"\"\n        if isinstance(value, datetime):\n            if value.utcoffset() is None:\n                raise ValueError(\"FaunaTime requires offset-aware datetimes\")\n            value = value.isoformat()\n\n        # Convert +00:00 offset to zulu for comparison equality\n        # We don't check for +0000 or +00 as they are not valid in FaunaDB\n        super(FaunaTime, self).__init__(value.replace(\"+00:00\", \"Z\"))\n\n    def to_datetime(self):\n        \"\"\"\n        Convert to an offset-aware datetime object.\n        This is lossy as datetimes have microsecond rather than nanosecond precision.\n        \"\"\"\n        return parse_date(self.value)\n\n    def to_fauna_json(self):\n        return {\"@ts\": self.value}\n\n    def __repr__(self):\n        return \"FaunaTime(%s)\" % repr(self.value)\n\n    def __eq__(self, other):\n        return isinstance(other, FaunaTime) and self.value == other.value\n\n    def __ne__(self, other):\n        # pylint: disable=unneeded-not\n        return not self == other", "\n\nclass Query(Expr):\n    \"\"\"\n    Represents a `@query` type in FaunaDB.\n    See the `docs <https://app.fauna.com/documentation/reference/queryapi#special-type>`__.\n    \"\"\"\n\n    def to_fauna_json(self):\n        return {\"@query\": self.value}\n\n    def __repr__(self):\n        return \"Query(%s)\" % repr(self.value)\n\n    def __eq__(self, other):\n        return isinstance(other, Query) and self.value == other.value\n\n    def __ne__(self, other):\n        # pylint: disable=unneeded-not\n        return not self == other", ""]}
{"filename": "aiofauna/faunadb/errors.py", "chunked_list": ["\"\"\"Error types that methods in the FaunaDB client throw.\"\"\"\n\n\nclass codes:\n\n    \"\"\"HTTP status codes.\"\"\"\n\n    bad_request = 400\n\n    unauthorized = 401\n\n    forbidden = 403\n\n    not_found = 404\n\n    internal_server_error = 500\n\n    unavailable = 503", "\n\ndef _get_or_raise(request_result, dct, key):\n    if isinstance(dct, dict) and key in dct:\n        return dct[key]\n\n    else:\n        raise UnexpectedError(\n            \"Response JSON does not contain expected key %s\" % key, request_result\n        )", "\n\n# region FaunaError\n\n\nclass FaunaError(Exception):\n    \"\"\"\n\n    Error returned by the FaunaDB server.\n\n    For documentation of error types, see the `docs <https://fauna.com/documentation#errors>`__.\n    \"\"\"\n\n    @staticmethod\n    def raise_for_status_code(request_result):\n        code = request_result.status_code\n\n        # pylint: disable=no-member, too-many-return-statements\n\n        if 200 <= code <= 299:\n            pass\n\n        elif code == codes.bad_request:\n            raise BadRequest(request_result)\n\n        elif code == codes.unauthorized:\n            raise Unauthorized(request_result)\n\n        elif code == codes.forbidden:\n            raise PermissionDenied(request_result)\n\n        elif code == codes.not_found:\n            raise NotFound(request_result)\n\n        elif code == codes.internal_server_error:\n            raise InternalError(request_result)\n\n        elif code == codes.unavailable:\n            raise UnavailableError(request_result)\n\n        else:\n            raise UnexpectedError(\"Unexpected status code.\", request_result)\n\n    def __init__(self, description, request_result):\n        super(FaunaError, self).__init__(description)\n\n        self.request_result = request_result\n\n        \"\"\":any:`RequestResult` for the request that caused this error.\"\"\"", "\n\nclass UnexpectedError(FaunaError):\n\n    \"\"\"Error for when the server returns an unexpected kind of response.\"\"\"\n\n    pass\n\n\nclass HttpError(FaunaError):\n    def __init__(self, request_result):\n        self.errors = HttpError._get_errors(request_result)\n\n        \"\"\"List of all :py:class:`ErrorData` objects sent by the server.\"\"\"\n\n        super(HttpError, self).__init__(self._get_description(), request_result)\n\n    @staticmethod\n    def _get_errors(request_result):\n        response = request_result.response_content\n\n        errors = _get_or_raise(request_result, response, \"errors\")\n\n        return [ErrorData.from_dict(error, request_result) for error in errors]\n\n    def __str__(self):\n        return repr(self.errors[0])\n\n    def _get_description(self):\n        return self.errors[0].description if self.errors else \"(empty `errors`)\"", "\nclass HttpError(FaunaError):\n    def __init__(self, request_result):\n        self.errors = HttpError._get_errors(request_result)\n\n        \"\"\"List of all :py:class:`ErrorData` objects sent by the server.\"\"\"\n\n        super(HttpError, self).__init__(self._get_description(), request_result)\n\n    @staticmethod\n    def _get_errors(request_result):\n        response = request_result.response_content\n\n        errors = _get_or_raise(request_result, response, \"errors\")\n\n        return [ErrorData.from_dict(error, request_result) for error in errors]\n\n    def __str__(self):\n        return repr(self.errors[0])\n\n    def _get_description(self):\n        return self.errors[0].description if self.errors else \"(empty `errors`)\"", "\n\nclass BadRequest(HttpError):\n\n    \"\"\"HTTP 400 error.\"\"\"\n\n    pass\n\n\nclass Unauthorized(HttpError):\n    def __init__(self, request_result):\n        super(Unauthorized, self).__init__(request_result)\n\n        self.errors[\n            0\n        ].description = \"Unauthorized. Check that endpoint, schema, port and secret are correct during client\u2019s instantiation\"", "\nclass Unauthorized(HttpError):\n    def __init__(self, request_result):\n        super(Unauthorized, self).__init__(request_result)\n\n        self.errors[\n            0\n        ].description = \"Unauthorized. Check that endpoint, schema, port and secret are correct during client\u2019s instantiation\"\n\n\nclass PermissionDenied(HttpError):\n\n    \"\"\"HTTP 403 error.\"\"\"\n\n    pass", "\n\nclass PermissionDenied(HttpError):\n\n    \"\"\"HTTP 403 error.\"\"\"\n\n    pass\n\n\nclass NotFound(HttpError):\n\n    \"\"\"HTTP 404 error.\"\"\"\n\n    pass", "\nclass NotFound(HttpError):\n\n    \"\"\"HTTP 404 error.\"\"\"\n\n    pass\n\n\nclass InternalError(HttpError):\n\n    \"\"\"HTTP 500 error.\"\"\"\n\n    pass", "class InternalError(HttpError):\n\n    \"\"\"HTTP 500 error.\"\"\"\n\n    pass\n\n\nclass UnavailableError(HttpError):\n\n    \"\"\"HTTP 503 error.\"\"\"\n\n    pass", "\n\n# endregion\n\n\nclass ErrorData(object):\n    \"\"\"\n\n    Data for one error returned by the server.\n    \"\"\"\n\n    @staticmethod\n    def from_dict(dct, request_result):\n        return ErrorData(\n            _get_or_raise(request_result, dct, \"code\"),\n            _get_or_raise(request_result, dct, \"description\"),\n            dct.get(\"position\"),\n            ErrorData.get_failures(dct, request_result),\n            ErrorData.get_cause(dct, request_result),\n        )\n\n    @staticmethod\n    def get_failures(dct, request_result):\n        if \"failures\" in dct:\n            return [\n                Failure.from_dict(failure, request_result)\n                for failure in dct[\"failures\"]\n            ]\n\n        return None\n\n    @staticmethod\n    def get_cause(dct, request_result):\n        if \"cause\" in dct:\n            return [\n                ErrorData.from_dict(cause, request_result) for cause in dct[\"cause\"]\n            ]\n\n        return None\n\n    def __init__(self, code, description, position, failures, cause=None):\n        self.code = code\n\n        \"\"\"Error code. See all error codes `here <https://fauna.com/documentation#errors>`__.\"\"\"\n\n        self.description = description\n\n        \"\"\"Error description.\"\"\"\n\n        self.position = position\n\n        \"\"\"Position of the error in a query. May be None.\"\"\"\n\n        self.failures = failures\n\n        \"\"\"Cause of the error. May be None.\"\"\"\n\n        self.cause = cause\n        \"\"\"\n\n    List of all :py:class:`Failure` objects returned by the server.\n\n    None unless code == \"validation failed\".\n    \"\"\"\n\n    def __repr__(self):\n        return (\n            \"ErrorData(code=%s, description=%s, position=%s, failures=%s, cause=%s)\"\n            % (\n                repr(self.code),\n                repr(self.description),\n                repr(self.position),\n                repr(self.failures),\n                repr(self.cause),\n            )\n        )\n\n    def __eq__(self, other):\n        return (\n            self.__class__ == other.__class__\n            and self.description == other.description\n            and self.position == other.position\n            and self.failures == other.failures\n            and self.cause == other.cause\n        )\n\n    def __ne__(self, other):\n        # pylint: disable=unneeded-not\n\n        return not self == other", "\n\nclass Failure(object):\n    \"\"\"\n\n    Part of the ``failures`` of an :py:class:`ErrorData`.\n\n    See the ``Invalid Data`` section of the `docs <https://fauna.com/documentation#errors>`__.\n    \"\"\"\n\n    @staticmethod\n    def from_dict(dct, request_result):\n        return Failure(\n            _get_or_raise(request_result, dct, \"code\"),\n            _get_or_raise(request_result, dct, \"description\"),\n            _get_or_raise(request_result, dct, \"field\"),\n        )\n\n    def __init__(self, code, description, field):\n        self.code = code\n\n        \"\"\"Failure code.\"\"\"\n\n        self.description = description\n\n        \"\"\"Failure description.\"\"\"\n\n        self.field = field\n\n        \"\"\"Field of the failure in the instance.\"\"\"\n\n    def __repr__(self):\n        return \"Failure(code=%s, description=%s, field=%s)\" % (\n            repr(self.code),\n            repr(self.description),\n            repr(self.field),\n        )\n\n    def __eq__(self, other):\n        return (\n            self.code == other.code\n            and self.description == other.description\n            and self.field == other.field\n        )\n\n    def __ne__(self, other):\n        # pylint: disable=unneeded-not\n\n        return not self == other", "\n\nclass FaunaException(Exception):\n    STATUS_MAP = {\n        100: \"primary\",\n        200: \"success\",\n        300: \"info\",\n        400: \"warning\",\n        500: \"error\",\n    }\n\n    def __init__(self, status: int, message: str, request_result):\n        super(FaunaException, self).__init__(message, request_result)\n        self.status = status\n        self.message = message\n\n    def json(self):\n        return {\"status\": self.raise_for_status(), \"message\": self.message}\n\n    def raise_for_status(self) -> str:\n        for key, value in self.STATUS_MAP.items():\n            if self.status < key + 100:\n                return value\n        return \"error\"", ""]}
{"filename": "aiofauna/faunadb/query.py", "chunked_list": ["from types import FunctionType\n\n\ndef abort(msg):\n    return _fn({\"abort\": msg})\n\n\ndef ref(collection_ref, id=None):\n    if id is None:\n        return _fn({\"@ref\": collection_ref})\n    return _fn({\"ref\": collection_ref, \"id\": id})", "\n\ndef collections(scope=None):\n    return _fn({\"collections\": scope})\n\n\ndef documents(collections):\n    return _fn({\"documents\": collections})\n\n\ndef databases(scope=None):\n    return _fn({\"databases\": scope})", "\n\ndef databases(scope=None):\n    return _fn({\"databases\": scope})\n\n\ndef indexes(scope=None):\n    return _fn({\"indexes\": scope})\n\n\ndef functions(scope=None):\n    return _fn({\"functions\": scope})", "\n\ndef functions(scope=None):\n    return _fn({\"functions\": scope})\n\n\ndef roles(scope=None):\n    return _fn({\"roles\": scope})\n\n\ndef access_providers(scope=None):\n    return _fn({\"access_providers\": scope})", "\n\ndef access_providers(scope=None):\n    return _fn({\"access_providers\": scope})\n\n\ndef keys(scope=None):\n    return _fn({\"keys\": scope})\n\n\ndef tokens(scope=None):\n    return _fn({\"tokens\": scope})", "\n\ndef tokens(scope=None):\n    return _fn({\"tokens\": scope})\n\n\ndef credentials(scope=None):\n    return _fn({\"credentials\": scope})\n\n\ndef at(timestamp, expr):\n    return _fn({\"at\": timestamp, \"expr\": expr})", "\n\ndef at(timestamp, expr):\n    return _fn({\"at\": timestamp, \"expr\": expr})\n\n\nclass LetBindings:\n    def __init__(self, bindings):\n        self._bindings = bindings\n\n    def in_(self, inExpr):\n        return _fn({\"let\": self._bindings, \"in\": inExpr})", "\n\ndef let(*args, **kwargs):\n    if kwargs:\n        return LetBindings([_fn({k: v}) for (k, v) in kwargs.items()])\n    else:\n        bindings = [_fn({k: v}) for (k, v) in args[0].items()]\n        inExpr = args[1]\n        return _fn({\"let\": bindings, \"in\": inExpr})\n", "\n\ndef var(var_name):\n    return _fn({\"var\": var_name})\n\n\ndef if_(condition, then, else_):\n    return _fn({\"if\": condition, \"then\": then, \"else\": else_})\n\n\ndef do(*expressions):\n    return _fn({\"do\": expressions})", "\n\ndef do(*expressions):\n    return _fn({\"do\": expressions})\n\n\ndef lambda_query(func):\n    vars = func.__code__.co_varnames\n    n_args = len(vars)\n    if n_args == 0:\n        raise ValueError(\"Function must take at least 1 argument.\")\n    elif n_args == 1:\n        v = vars[0]\n        return lambda_(v, func(var(v)))\n    else:\n        return lambda_(vars, func(*[var(v) for v in vars]))", "\n\ndef lambda_(var_name_or_pattern, expr):\n    return _fn({\"lambda\": var_name_or_pattern, \"expr\": expr})\n\n\ndef call(ref_, *arguments):\n    return _fn({\"call\": ref_, \"arguments\": _varargs(arguments)})\n\n\ndef query(_lambda):\n    if isinstance(_lambda, FunctionType):\n        _lambda = lambda_query(_lambda)\n    return _fn({\"query\": _lambda})", "\n\ndef query(_lambda):\n    if isinstance(_lambda, FunctionType):\n        _lambda = lambda_query(_lambda)\n    return _fn({\"query\": _lambda})\n\n\ndef map_(expr, collection):\n    return _fn({\"map\": expr, \"collection\": collection})", "def map_(expr, collection):\n    return _fn({\"map\": expr, \"collection\": collection})\n\n\ndef foreach(expr, collection):\n    return _fn({\"foreach\": expr, \"collection\": collection})\n\n\ndef filter_(expr, collection):\n    return _fn({\"filter\": expr, \"collection\": collection})", "def filter_(expr, collection):\n    return _fn({\"filter\": expr, \"collection\": collection})\n\n\ndef take(number, collection):\n    return _fn({\"take\": number, \"collection\": collection})\n\n\ndef drop(number, collection):\n    return _fn({\"drop\": number, \"collection\": collection})", "def drop(number, collection):\n    return _fn({\"drop\": number, \"collection\": collection})\n\n\ndef prepend(elements, collection):\n    return _fn({\"prepend\": elements, \"collection\": collection})\n\n\ndef append(elements, collection):\n    return _fn({\"append\": elements, \"collection\": collection})", "def append(elements, collection):\n    return _fn({\"append\": elements, \"collection\": collection})\n\n\ndef is_empty(collection):\n    return _fn({\"is_empty\": collection})\n\n\ndef is_nonempty(collection):\n    return _fn({\"is_nonempty\": collection})", "def is_nonempty(collection):\n    return _fn({\"is_nonempty\": collection})\n\n\ndef is_number(expr):\n    return _fn({\"is_number\": expr})\n\n\ndef is_double(expr):\n    return _fn({\"is_double\": expr})", "def is_double(expr):\n    return _fn({\"is_double\": expr})\n\n\ndef is_integer(expr):\n    return _fn({\"is_integer\": expr})\n\n\ndef is_boolean(expr):\n    return _fn({\"is_boolean\": expr})", "def is_boolean(expr):\n    return _fn({\"is_boolean\": expr})\n\n\ndef is_null(expr):\n    return _fn({\"is_null\": expr})\n\n\ndef is_bytes(expr):\n    return _fn({\"is_bytes\": expr})", "def is_bytes(expr):\n    return _fn({\"is_bytes\": expr})\n\n\ndef is_timestamp(expr):\n    return _fn({\"is_timestamp\": expr})\n\n\ndef is_date(expr):\n    return _fn({\"is_date\": expr})", "def is_date(expr):\n    return _fn({\"is_date\": expr})\n\n\ndef is_string(expr):\n    return _fn({\"is_string\": expr})\n\n\ndef is_array(expr):\n    return _fn({\"is_array\": expr})", "def is_array(expr):\n    return _fn({\"is_array\": expr})\n\n\ndef is_object(expr):\n    return _fn({\"is_object\": expr})\n\n\ndef is_ref(expr):\n    return _fn({\"is_ref\": expr})", "def is_ref(expr):\n    return _fn({\"is_ref\": expr})\n\n\ndef is_set(expr):\n    return _fn({\"is_set\": expr})\n\n\ndef is_doc(expr):\n    return _fn({\"is_doc\": expr})", "def is_doc(expr):\n    return _fn({\"is_doc\": expr})\n\n\ndef is_lambda(expr):\n    return _fn({\"is_lambda\": expr})\n\n\ndef is_collection(expr):\n    return _fn({\"is_collection\": expr})", "def is_collection(expr):\n    return _fn({\"is_collection\": expr})\n\n\ndef is_database(expr):\n    return _fn({\"is_database\": expr})\n\n\ndef is_index(expr):\n    return _fn({\"is_index\": expr})", "def is_index(expr):\n    return _fn({\"is_index\": expr})\n\n\ndef is_function(expr):\n    return _fn({\"is_function\": expr})\n\n\ndef is_key(expr):\n    return _fn({\"is_key\": expr})", "def is_key(expr):\n    return _fn({\"is_key\": expr})\n\n\ndef is_token(expr):\n    return _fn({\"is_token\": expr})\n\n\ndef is_credentials(expr):\n    return _fn({\"is_credentials\": expr})", "def is_credentials(expr):\n    return _fn({\"is_credentials\": expr})\n\n\ndef is_role(expr):\n    return _fn({\"is_role\": expr})\n\n\ndef get(ref_, ts=None):\n    return _params({\"get\": ref_}, {\"ts\": ts})", "def get(ref_, ts=None):\n    return _params({\"get\": ref_}, {\"ts\": ts})\n\n\ndef key_from_secret(secret):\n    return _fn({\"key_from_secret\": secret})\n\n\ndef paginate(\n    set, size=None, ts=None, after=None, before=None, events=None, sources=None\n):\n    opts = {\n        \"size\": size,\n        \"ts\": ts,\n        \"after\": after,\n        \"before\": before,\n        \"events\": events,\n        \"sources\": sources,\n    }\n    return _params({\"paginate\": set}, opts)", "def paginate(\n    set, size=None, ts=None, after=None, before=None, events=None, sources=None\n):\n    opts = {\n        \"size\": size,\n        \"ts\": ts,\n        \"after\": after,\n        \"before\": before,\n        \"events\": events,\n        \"sources\": sources,\n    }\n    return _params({\"paginate\": set}, opts)", "\n\ndef exists(ref_, ts=None):\n    return _params({\"exists\": ref_}, {\"ts\": ts})\n\n\ndef create(collection_ref, params):\n    return _fn({\"create\": collection_ref, \"params\": params})\n\n\ndef update(ref_, params):\n    return _fn({\"update\": ref_, \"params\": params})", "\n\ndef update(ref_, params):\n    return _fn({\"update\": ref_, \"params\": params})\n\n\ndef replace(ref_, params):\n    return _fn({\"replace\": ref_, \"params\": params})\n\n\ndef delete(ref_):\n    return _fn({\"delete\": ref_})", "\n\ndef delete(ref_):\n    return _fn({\"delete\": ref_})\n\n\ndef insert(ref_, ts, action, params):\n    return _fn({\"insert\": ref_, \"ts\": ts, \"action\": action, \"params\": params})\n\n\ndef remove(ref_, ts, action):\n    return _fn({\"remove\": ref_, \"ts\": ts, \"action\": action})", "\n\ndef remove(ref_, ts, action):\n    return _fn({\"remove\": ref_, \"ts\": ts, \"action\": action})\n\n\ndef create_collection(collection_params):\n    return _fn({\"create_collection\": collection_params})\n\n\ndef create_database(db_params):\n    return _fn({\"create_database\": db_params})", "\n\ndef create_database(db_params):\n    return _fn({\"create_database\": db_params})\n\n\ndef create_index(index_params):\n    return _fn({\"create_index\": index_params})\n\n\ndef create_function(func_params):\n    return _fn({\"create_function\": func_params})", "\n\ndef create_function(func_params):\n    return _fn({\"create_function\": func_params})\n\n\ndef create_role(func_params):\n    return _fn({\"create_role\": func_params})\n\n\ndef create_access_provider(provider_params):\n    return _fn({\"create_access_provider\": provider_params})", "\n\ndef create_access_provider(provider_params):\n    return _fn({\"create_access_provider\": provider_params})\n\n\ndef move_database(from_, to):\n    return _fn({\"move_database\": from_, \"to\": to})\n\n\ndef create_key(key_params):\n    return _fn({\"create_key\": key_params})", "\n\ndef create_key(key_params):\n    return _fn({\"create_key\": key_params})\n\n\ndef singleton(ref_):\n    return _fn({\"singleton\": ref_})\n\n\ndef events(ref_set):\n    return _fn({\"events\": ref_set})", "\n\ndef events(ref_set):\n    return _fn({\"events\": ref_set})\n\n\ndef match(index, *terms):\n    m = {\"match\": index}\n    if len(terms) >= 1:\n        m[\"terms\"] = _varargs(terms)\n    return _fn(m)", "\n\ndef reverse(set_array_or_page):\n    return _fn({\"reverse\": set_array_or_page})\n\n\ndef merge(merge, with_, lambda_=None):\n    return _params({\"merge\": merge, \"with\": with_}, {\"lambda\": lambda_})\n\n\ndef union(*sets):\n    return _fn({\"union\": _varargs(sets)})", "\n\ndef union(*sets):\n    return _fn({\"union\": _varargs(sets)})\n\n\ndef reduce(lambda_, initial, collection):\n    return _fn({\"reduce\": lambda_, \"initial\": initial, \"collection\": collection})\n\n\ndef intersection(*sets):\n    return _fn({\"intersection\": _varargs(sets)})", "\n\ndef intersection(*sets):\n    return _fn({\"intersection\": _varargs(sets)})\n\n\ndef difference(*sets):\n    return _fn({\"difference\": _varargs(sets)})\n\n\ndef distinct(set):\n    return _fn({\"distinct\": set})", "\n\ndef distinct(set):\n    return _fn({\"distinct\": set})\n\n\ndef join(source, target):\n    return _fn({\"join\": source, \"with\": target})\n\n\ndef range(set, from_, to):\n    return _fn({\"range\": set, \"from\": from_, \"to\": to})", "\n\ndef range(set, from_, to):\n    return _fn({\"range\": set, \"from\": from_, \"to\": to})\n\n\ndef login(ref_, params):\n    return _fn({\"login\": ref_, \"params\": params})\n\n\ndef logout(delete_tokens):\n    return _fn({\"logout\": delete_tokens})", "\n\ndef logout(delete_tokens):\n    return _fn({\"logout\": delete_tokens})\n\n\ndef identify(ref_, password):\n    return _fn({\"identify\": ref_, \"password\": password})\n\n\ndef current_identity():\n    return _fn({\"current_identity\": None})", "\n\ndef current_identity():\n    return _fn({\"current_identity\": None})\n\n\ndef has_current_identity():\n    return _fn({\"has_current_identity\": None})\n\n\ndef current_token():\n    return _fn({\"current_token\": None})", "\n\ndef current_token():\n    return _fn({\"current_token\": None})\n\n\ndef has_current_token():\n    return _fn({\"has_current_token\": None})\n\n\ndef has_identity():\n    return _fn({\"has_identity\": None})", "\n\ndef has_identity():\n    return _fn({\"has_identity\": None})\n\n\ndef format(string, *values):\n    return _fn({\"format\": string, \"values\": _varargs(values)})\n\n\ndef concat(strings, separator=None):\n    return _params({\"concat\": strings}, {\"separator\": separator})", "\n\ndef concat(strings, separator=None):\n    return _params({\"concat\": strings}, {\"separator\": separator})\n\n\ndef casefold(string, normalizer=None):\n    return _params({\"casefold\": string}, {\"normalizer\": normalizer})\n\n\ndef starts_with(value, search):\n    return _fn({\"startswith\": value, \"search\": search})", "\n\ndef starts_with(value, search):\n    return _fn({\"startswith\": value, \"search\": search})\n\n\ndef ends_with(value, search):\n    return _fn({\"endswith\": value, \"search\": search})\n\n\ndef contains_str(value, search):\n    return _fn({\"containsstr\": value, \"search\": search})", "\n\ndef contains_str(value, search):\n    return _fn({\"containsstr\": value, \"search\": search})\n\n\ndef contains_str_regex(value, pattern):\n    return _fn({\"containsstrregex\": value, \"pattern\": pattern})\n\n\ndef regex_escape(value):\n    return _fn({\"regexescape\": value})", "\n\ndef regex_escape(value):\n    return _fn({\"regexescape\": value})\n\n\ndef ngram(terms, min=None, max=None):\n    return _params({\"ngram\": terms}, {\"min\": min, \"max\": max})\n\n\ndef find_str(value, find, start=None):\n    return _params({\"findstr\": value, \"find\": find}, {\"start\": start})", "\n\ndef find_str(value, find, start=None):\n    return _params({\"findstr\": value, \"find\": find}, {\"start\": start})\n\n\ndef find_str_regex(value, pattern, start=None, numResults=None):\n    return _params(\n        {\"findstrregex\": value, \"pattern\": pattern},\n        {\"start\": start, \"num_results\": numResults},\n    )", "\n\ndef replace_str(value, find, replace):\n    return _fn({\"replacestr\": value, \"find\": find, \"replace\": replace})\n\n\ndef replace_str_regex(value, pattern, replace, first=None):\n    return _params(\n        {\"replacestrregex\": value, \"pattern\": pattern, \"replace\": replace},\n        {\"first\": first},\n    )", "\n\ndef length(value):\n    return _fn({\"length\": value})\n\n\ndef lowercase(value):\n    return _fn({\"lowercase\": value})\n\n\ndef uppercase(value):\n    return _fn({\"uppercase\": value})", "\n\ndef uppercase(value):\n    return _fn({\"uppercase\": value})\n\n\ndef titlecase(value):\n    return _fn({\"titlecase\": value})\n\n\ndef trim(value):\n    return _fn({\"trim\": value})", "\n\ndef trim(value):\n    return _fn({\"trim\": value})\n\n\ndef ltrim(value):\n    return _fn({\"ltrim\": value})\n\n\ndef rtrim(value):\n    return _fn({\"rtrim\": value})", "\n\ndef rtrim(value):\n    return _fn({\"rtrim\": value})\n\n\ndef space(count):\n    return _fn({\"space\": count})\n\n\ndef substring(value, start, length=None):\n    return _params({\"substring\": value, \"start\": start}, {\"length\": length})", "\n\ndef substring(value, start, length=None):\n    return _params({\"substring\": value, \"start\": start}, {\"length\": length})\n\n\ndef repeat(value, number=None):\n    return _params({\"repeat\": value}, {\"number\": number})\n\n\ndef time(string):\n    return _fn({\"time\": string})", "\n\ndef time(string):\n    return _fn({\"time\": string})\n\n\ndef epoch(number, unit):\n    return _fn({\"epoch\": number, \"unit\": unit})\n\n\ndef now():\n    return _fn({\"now\": None})", "\n\ndef now():\n    return _fn({\"now\": None})\n\n\ndef date(string):\n    return _fn({\"date\": string})\n\n\ndef time_add(base, offset, unit):\n    return _fn({\"time_add\": base, \"offset\": offset, \"unit\": unit})", "\n\ndef time_add(base, offset, unit):\n    return _fn({\"time_add\": base, \"offset\": offset, \"unit\": unit})\n\n\ndef time_subtract(base, offset, unit):\n    return _fn({\"time_subtract\": base, \"offset\": offset, \"unit\": unit})\n\n\ndef time_diff(start, finish, unit):\n    return _fn({\"time_diff\": start, \"other\": finish, \"unit\": unit})", "\n\ndef time_diff(start, finish, unit):\n    return _fn({\"time_diff\": start, \"other\": finish, \"unit\": unit})\n\n\ndef new_id():\n    return _fn({\"new_id\": None})\n\n\ndef database(db_name, scope=None):\n    return _params({\"database\": db_name}, {\"scope\": scope})", "\n\ndef database(db_name, scope=None):\n    return _params({\"database\": db_name}, {\"scope\": scope})\n\n\ndef index(index_name, scope=None):\n    return _params({\"index\": index_name}, {\"scope\": scope})\n\n\ndef collection(collection_name, scope=None):\n    return _params({\"collection\": collection_name}, {\"scope\": scope})", "\n\ndef collection(collection_name, scope=None):\n    return _params({\"collection\": collection_name}, {\"scope\": scope})\n\n\ndef function(fn_name, scope=None):\n    return _params({\"function\": fn_name}, {\"scope\": scope})\n\n\ndef role(role_name, scope=None):\n    return _params({\"role\": role_name}, {\"scope\": scope})", "\n\ndef role(role_name, scope=None):\n    return _params({\"role\": role_name}, {\"scope\": scope})\n\n\ndef access_provider(access_provider_name, scope=None):\n    return _params({\"access_provider\": access_provider_name}, {\"scope\": scope})\n\n\ndef equals(*values):\n    return _fn({\"equals\": _varargs(values)})", "\n\ndef equals(*values):\n    return _fn({\"equals\": _varargs(values)})\n\n\ndef contains_path(path, in_):\n    return _fn({\"contains_path\": path, \"in\": in_})\n\n\ndef contains_field(field, in_):\n    return _fn({\"contains_field\": field, \"in\": in_})", "\n\ndef contains_field(field, in_):\n    return _fn({\"contains_field\": field, \"in\": in_})\n\n\ndef contains_value(value, in_):\n    return _fn({\"contains_value\": value, \"in\": in_})\n\n", "\n\n_NO_DEFAULT = object()\n\n\ndef select(path, from_, default=_NO_DEFAULT):\n    _dict = {\"select\": path, \"from\": from_}\n    if default is not _NO_DEFAULT:\n        _dict[\"default\"] = default\n    return _fn(_dict)", "\n\ndef select_all(path, from_):\n    return _fn({\"select_all\": path, \"from\": from_})\n\n\ndef add(*numbers):\n    return _fn({\"add\": _varargs(numbers)})\n\n\ndef multiply(*numbers):\n    return _fn({\"multiply\": _varargs(numbers)})", "\n\ndef multiply(*numbers):\n    return _fn({\"multiply\": _varargs(numbers)})\n\n\ndef subtract(*numbers):\n    return _fn({\"subtract\": _varargs(numbers)})\n\n\ndef divide(*numbers):\n    return _fn({\"divide\": _varargs(numbers)})", "\n\ndef divide(*numbers):\n    return _fn({\"divide\": _varargs(numbers)})\n\n\ndef pow(base, exp):\n    return _fn({\"pow\": base, \"exp\": exp})\n\n\ndef max(*numbers):\n    return _fn({\"max\": _varargs(numbers)})", "\n\ndef max(*numbers):\n    return _fn({\"max\": _varargs(numbers)})\n\n\ndef min(*numbers):\n    return _fn({\"min\": _varargs(numbers)})\n\n\ndef abs(num):\n    return _fn({\"abs\": num})", "\n\ndef abs(num):\n    return _fn({\"abs\": num})\n\n\ndef trunc(num, precision=None):\n    return _params({\"trunc\": num}, {\"precision\": precision})\n\n\ndef bitor(*numbers):\n    return _fn({\"bitor\": _varargs(numbers)})", "\n\ndef bitor(*numbers):\n    return _fn({\"bitor\": _varargs(numbers)})\n\n\ndef cosh(num):\n    return _fn({\"cosh\": num})\n\n\ndef hypot(num, b):\n    return _fn({\"hypot\": num, \"b\": b})", "\n\ndef hypot(num, b):\n    return _fn({\"hypot\": num, \"b\": b})\n\n\ndef atan(num):\n    return _fn({\"atan\": num})\n\n\ndef log(num):\n    return _fn({\"log\": num})", "\n\ndef log(num):\n    return _fn({\"log\": num})\n\n\ndef bitnot(*num):\n    return _fn({\"bitnot\": _varargs(num)})\n\n\ndef bitxor(*num):\n    return _fn({\"bitxor\": _varargs(num)})", "\n\ndef bitxor(*num):\n    return _fn({\"bitxor\": _varargs(num)})\n\n\ndef bitand(*num):\n    return _fn({\"bitand\": _varargs(num)})\n\n\ndef ceil(num):\n    return _fn({\"ceil\": num})", "\n\ndef ceil(num):\n    return _fn({\"ceil\": num})\n\n\ndef degrees(num):\n    return _fn({\"degrees\": num})\n\n\ndef cos(num):\n    return _fn({\"cos\": num})", "\n\ndef cos(num):\n    return _fn({\"cos\": num})\n\n\ndef acos(num):\n    return _fn({\"acos\": num})\n\n\ndef sqrt(num):\n    return _fn({\"sqrt\": num})", "\n\ndef sqrt(num):\n    return _fn({\"sqrt\": num})\n\n\ndef tan(num):\n    return _fn({\"tan\": num})\n\n\ndef tanh(num):\n    return _fn({\"tanh\": num})", "\n\ndef tanh(num):\n    return _fn({\"tanh\": num})\n\n\ndef sin(num):\n    return _fn({\"sin\": num})\n\n\ndef asin(num):\n    return _fn({\"asin\": num})", "\n\ndef asin(num):\n    return _fn({\"asin\": num})\n\n\ndef round(num, precision=None):\n    return _params({\"round\": num}, {\"precision\": precision})\n\n\ndef radians(num):\n    return _fn({\"radians\": num})", "\n\ndef radians(num):\n    return _fn({\"radians\": num})\n\n\ndef floor(num):\n    return _fn({\"floor\": num})\n\n\ndef sign(num):\n    return _fn({\"sign\": num})", "\n\ndef sign(num):\n    return _fn({\"sign\": num})\n\n\ndef exp(num):\n    return _fn({\"exp\": num})\n\n\ndef ln(num):\n    return _fn({\"ln\": num})", "\n\ndef ln(num):\n    return _fn({\"ln\": num})\n\n\ndef any(collection):\n    return _fn({\"any\": collection})\n\n\ndef all(collection):\n    return _fn({\"all\": collection})", "\n\ndef all(collection):\n    return _fn({\"all\": collection})\n\n\ndef modulo(*numbers):\n    return _fn({\"modulo\": _varargs(numbers)})\n\n\ndef count(collection):\n    return _fn({\"count\": collection})", "\n\ndef count(collection):\n    return _fn({\"count\": collection})\n\n\ndef sum(collection):\n    return _fn({\"sum\": collection})\n\n\ndef mean(collection):\n    return _fn({\"mean\": collection})", "\n\ndef mean(collection):\n    return _fn({\"mean\": collection})\n\n\ndef lt(*values):\n    return _fn({\"lt\": _varargs(values)})\n\n\ndef lte(*values):\n    return _fn({\"lte\": _varargs(values)})", "\n\ndef lte(*values):\n    return _fn({\"lte\": _varargs(values)})\n\n\ndef gt(*values):\n    return _fn({\"gt\": _varargs(values)})\n\n\ndef gte(*values):\n    return _fn({\"gte\": _varargs(values)})", "\n\ndef gte(*values):\n    return _fn({\"gte\": _varargs(values)})\n\n\ndef and_(*booleans):\n    return _fn({\"and\": _varargs(booleans)})\n\n\ndef or_(*booleans):\n    return _fn({\"or\": _varargs(booleans)})", "\n\ndef or_(*booleans):\n    return _fn({\"or\": _varargs(booleans)})\n\n\ndef not_(boolean):\n    return _fn({\"not\": boolean})\n\n\ndef to_string(expr):\n    return _fn({\"to_string\": expr})", "\n\ndef to_string(expr):\n    return _fn({\"to_string\": expr})\n\n\ndef to_array(expr):\n    return _fn({\"to_array\": expr})\n\n\ndef to_object(expr):\n    return _fn({\"to_object\": expr})", "\n\ndef to_object(expr):\n    return _fn({\"to_object\": expr})\n\n\ndef to_double(expr):\n    return _fn({\"to_double\": expr})\n\n\ndef to_integer(expr):\n    return _fn({\"to_integer\": expr})", "\n\ndef to_integer(expr):\n    return _fn({\"to_integer\": expr})\n\n\ndef to_number(expr):\n    return _fn({\"to_number\": expr})\n\n\ndef to_time(expr):\n    return _fn({\"to_time\": expr})", "\n\ndef to_time(expr):\n    return _fn({\"to_time\": expr})\n\n\ndef to_seconds(expr):\n    return _fn({\"to_seconds\": expr})\n\n\ndef to_millis(expr):\n    return _fn({\"to_millis\": expr})", "\n\ndef to_millis(expr):\n    return _fn({\"to_millis\": expr})\n\n\ndef to_micros(expr):\n    return _fn({\"to_micros\": expr})\n\n\ndef day_of_month(expr):\n    return _fn({\"day_of_month\": expr})", "\n\ndef day_of_month(expr):\n    return _fn({\"day_of_month\": expr})\n\n\ndef day_of_week(expr):\n    return _fn({\"day_of_week\": expr})\n\n\ndef day_of_year(expr):\n    return _fn({\"day_of_year\": expr})", "\n\ndef day_of_year(expr):\n    return _fn({\"day_of_year\": expr})\n\n\ndef year(expr):\n    return _fn({\"year\": expr})\n\n\ndef month(expr):\n    return _fn({\"month\": expr})", "\n\ndef month(expr):\n    return _fn({\"month\": expr})\n\n\ndef hour(expr):\n    return _fn({\"hour\": expr})\n\n\ndef minute(expr):\n    return _fn({\"minute\": expr})", "\n\ndef minute(expr):\n    return _fn({\"minute\": expr})\n\n\ndef second(expr):\n    return _fn({\"second\": expr})\n\n\ndef to_date(expr):\n    return _fn({\"to_date\": expr})", "\n\ndef to_date(expr):\n    return _fn({\"to_date\": expr})\n\n\nclass Expr:\n    def __init__(self, value):\n        self.value = value\n\n    def to_fauna_json(self):\n        return self.value\n\n    def __repr__(self):\n        return \"Expr(%s)\" % repr(self.value)\n\n    def __eq__(self, other):\n        return isinstance(other, Expr) and self.value == other.value", "\n\ndef _wrap(value):\n    if isinstance(value, Expr):\n        return value\n    elif isinstance(value, FunctionType):\n        return lambda_query(value)\n    elif isinstance(value, dict):\n        return Expr({\"object\": _wrap_values(value)})\n    elif isinstance(value, (list, tuple)):\n        return Expr([_wrap(sub_value) for sub_value in value])\n    return value", "\n\ndef _wrap_values(dct):\n    return {key: _wrap(val) for (key, val) in dct.items()}\n\n\ndef _fn(dct):\n    return Expr(_wrap_values(dct))\n\n\ndef _params(main_params, optional_params):\n    for key, val in optional_params.items():\n        if val is not None:\n            main_params[key] = val\n    return _fn(main_params)", "\n\ndef _params(main_params, optional_params):\n    for key, val in optional_params.items():\n        if val is not None:\n            main_params[key] = val\n    return _fn(main_params)\n\n\ndef _varargs(values):\n    return values[0] if len(values) == 1 else values", "\ndef _varargs(values):\n    return values[0] if len(values) == 1 else values\n"]}
{"filename": "aiofauna/faunadb/__init__.py", "chunked_list": [""]}
{"filename": "aiofauna/ssr/ssr.py", "chunked_list": ["import functools\nfrom typing import Optional\n\nfrom aiohttp.web import HTTPException, Request, Response, StreamResponse\nfrom jinja2 import Environment, FileSystemLoader, select_autoescape\nfrom jinja2.exceptions import (\n    TemplateAssertionError,\n    TemplateError,\n    TemplateNotFound,\n    TemplateSyntaxError,", "    TemplateNotFound,\n    TemplateSyntaxError,\n    UndefinedError,\n)\nfrom markdown_it import MarkdownIt\nfrom markdown_it.renderer import RendererHTML\nfrom markdown_it.rules_block import StateBlock\nfrom pygments import highlight\nfrom pygments.formatters import HtmlFormatter\nfrom pygments.lexers import MarkdownLexer, get_lexer_by_name", "from pygments.formatters import HtmlFormatter\nfrom pygments.lexers import MarkdownLexer, get_lexer_by_name\n\nfrom ..utils import setup_logging\n\nEXCEPTIONS = (\n    TemplateAssertionError,\n    TemplateError,\n    TemplateNotFound,\n    TemplateSyntaxError,", "    TemplateNotFound,\n    TemplateSyntaxError,\n    UndefinedError,\n    Exception,\n)\n\nlogger = setup_logging(__name__)\n\n\ndef handle_template(func):\n    @functools.wraps(func)\n    async def wrapper(*args, **kwargs):\n        try:\n            return await func(*args, **kwargs)\n        except EXCEPTIONS as e:\n            logger.error(e)\n            raise HTTPException(reason=str(e)) from e\n\n    return wrapper", "\ndef handle_template(func):\n    @functools.wraps(func)\n    async def wrapper(*args, **kwargs):\n        try:\n            return await func(*args, **kwargs)\n        except EXCEPTIONS as e:\n            logger.error(e)\n            raise HTTPException(reason=str(e)) from e\n\n    return wrapper", "\n\nclass HighlightRenderer(RendererHTML):\n    def code_block(self, tokens, idx, options, env):\n        token = tokens[idx]\n        lexer = get_lexer_by_name(token.info.strip() if token.info else \"text\")\n        formatter = HtmlFormatter()\n        return highlight(token.content, lexer, formatter)\n\n\ndef highlight_code(code, name, attrs):\n    \"\"\"Highlight a block of code\"\"\"\n    lexer = get_lexer_by_name(name)\n    formatter = HtmlFormatter()\n\n    return highlight(code, lexer, formatter)", "\n\ndef highlight_code(code, name, attrs):\n    \"\"\"Highlight a block of code\"\"\"\n    lexer = get_lexer_by_name(name)\n    formatter = HtmlFormatter()\n\n    return highlight(code, lexer, formatter)\n\n\nclass ServerSideRenderer(StreamResponse):\n    def __init__(\n        self,\n        headers={\"Content-Type\": \"text/html\"},\n        *args,\n        **kwargs,\n    ) -> None:\n        super().__init__(*args, headers=headers, **kwargs)\n        self.env = Environment(\n            loader=FileSystemLoader(\"templates\"),\n            autoescape=select_autoescape([\"html\", \"xml\", \"jinja2\", \"md\"]),\n            enable_async=True,\n        )\n        self.md = MarkdownIt(\n            \"js-default\",\n            options_update={\n                \"html\": True,\n                \"linkify\": True,\n                \"typographer\": True,\n                \"highlight\": highlight_code,\n            },\n        )\n\n    @handle_template\n    async def render_markdown(self, template_name: str, request: Request, **context):\n        await self.prepare(request)\n        template = self.env.get_template(template_name)\n        response = self.md.render(await template.render_async(**context))\n        for chunk in response:\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def stream_markdown(self, template_name: str, request: Request, **context):\n        await self.prepare(request)\n        template = self.env.get_template(template_name)\n        async for chunk in template.generate_async(**context):\n            await self.write(self.md.render(chunk).encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def render_template(self, template_name: str, request: Request, **context):\n        await self.prepare(request)\n        template = self.env.get_template(template_name)\n        response = await template.render_async(**context)\n        for chunk in response:\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def stream_template(self, template_name: str, request: Request, **context):\n        await self.prepare(request)\n        template = self.env.get_template(template_name)\n        async for chunk in template.generate_async(**context):\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def markdown_string(self, string: str, request: Request):\n        await self.prepare(request)\n        response = self.md.render(string)\n        for chunk in response:\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def stream_markdown_string(self, string: str, request: Request):\n        await self.prepare(request)\n        for chunk in string:\n            await self.write(self.md.render(chunk).encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def render_html(self, string: str, request: Request):\n        await self.prepare(request)\n        for chunk in string:\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self", "\n\nclass ServerSideRenderer(StreamResponse):\n    def __init__(\n        self,\n        headers={\"Content-Type\": \"text/html\"},\n        *args,\n        **kwargs,\n    ) -> None:\n        super().__init__(*args, headers=headers, **kwargs)\n        self.env = Environment(\n            loader=FileSystemLoader(\"templates\"),\n            autoescape=select_autoescape([\"html\", \"xml\", \"jinja2\", \"md\"]),\n            enable_async=True,\n        )\n        self.md = MarkdownIt(\n            \"js-default\",\n            options_update={\n                \"html\": True,\n                \"linkify\": True,\n                \"typographer\": True,\n                \"highlight\": highlight_code,\n            },\n        )\n\n    @handle_template\n    async def render_markdown(self, template_name: str, request: Request, **context):\n        await self.prepare(request)\n        template = self.env.get_template(template_name)\n        response = self.md.render(await template.render_async(**context))\n        for chunk in response:\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def stream_markdown(self, template_name: str, request: Request, **context):\n        await self.prepare(request)\n        template = self.env.get_template(template_name)\n        async for chunk in template.generate_async(**context):\n            await self.write(self.md.render(chunk).encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def render_template(self, template_name: str, request: Request, **context):\n        await self.prepare(request)\n        template = self.env.get_template(template_name)\n        response = await template.render_async(**context)\n        for chunk in response:\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def stream_template(self, template_name: str, request: Request, **context):\n        await self.prepare(request)\n        template = self.env.get_template(template_name)\n        async for chunk in template.generate_async(**context):\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def markdown_string(self, string: str, request: Request):\n        await self.prepare(request)\n        response = self.md.render(string)\n        for chunk in response:\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def stream_markdown_string(self, string: str, request: Request):\n        await self.prepare(request)\n        for chunk in string:\n            await self.write(self.md.render(chunk).encode())\n        await self.write_eof()\n        return self\n\n    @handle_template\n    async def render_html(self, string: str, request: Request):\n        await self.prepare(request)\n        for chunk in string:\n            await self.write(chunk.encode())\n        await self.write_eof()\n        return self", ""]}
{"filename": "aiofauna/ssr/__init__.py", "chunked_list": ["from .ssr import ServerSideRenderer\n"]}
