{"filename": "noxfile.py", "chunked_list": ["import argparse\nfrom typing import cast\n\nimport nox\nfrom nox.command import CommandFailed\n\n\n@nox.session\ndef release(session: nox.Session) -> None:\n    \"\"\"\n    Kicks off an automated release process by creating and pushing a new tag.\n\n    Invokes bump2version with the posarg setting the version.\n\n    Usage:\n    $ nox -s release -- [major|minor|patch]\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Release a semver version.\")\n    parser.add_argument(\n        \"version\",\n        type=str,\n        nargs=1,\n    )\n    args: argparse.Namespace = parser.parse_args(args=session.posargs)\n    version: str = args.version.pop()\n\n    # If we get here, we should be good to go\n    # Let's do a final check for safety\n    release_confirm = (\n        input(f\"You are about to release {version!r} version. Are you sure? [y/n]: \")\n        .casefold()\n        .strip()\n    )\n\n    # Abort on anything other than 'y'\n    if release_confirm != \"y\":\n        session.error(f\"You said no when prompted to bump the {version!r} version.\")\n\n    session.run(\"poetry\", \"self\", \"add\", \"poetry-bumpversion\", external=True)\n\n    session.log(f\"Bumping the {version!r} version\")\n    session.run(\"poetry\", \"version\", version, external=True)\n    new_version = (\n        \"v\"\n        + cast(\n            str, session.run(\"poetry\", \"version\", \"--short\", silent=True, external=True)\n        ).strip()\n    )\n    session.log(f\"Creating {new_version} tag...\")\n    try:\n        session.run(\n            \"git\",\n            \"tag\",\n            \"-a\",\n            new_version,\n            \"-m\",\n            f\"Release {new_version}\",\n            external=True,\n        )\n    except CommandFailed:\n        session.log(f\"Failed to create {new_version} tag, probably already exists.\")\n    session.log(\"Pushing local tags...\")\n    session.run(\"git\", \"push\", \"--tags\", external=True)\n\n    session.run(\"git\", \"diff\", external=True)\n    commit_confirm = (\n        input(\n            \"You are about to commit auto-changed files due to version upgrade, \"\n            \"see the diff view above. Are you sure? [y/n]: \"\n        )\n        .casefold()\n        .strip()\n    )\n\n    if commit_confirm == \"y\":\n        session.run(\n            \"git\", \"commit\", \"-a\", \"-m\", f\"Release {new_version}\", external=True\n        )\n        session.run(\"git\", \"push\", external=True)\n    else:\n        session.log(\"Ok.\")", "def release(session: nox.Session) -> None:\n    \"\"\"\n    Kicks off an automated release process by creating and pushing a new tag.\n\n    Invokes bump2version with the posarg setting the version.\n\n    Usage:\n    $ nox -s release -- [major|minor|patch]\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Release a semver version.\")\n    parser.add_argument(\n        \"version\",\n        type=str,\n        nargs=1,\n    )\n    args: argparse.Namespace = parser.parse_args(args=session.posargs)\n    version: str = args.version.pop()\n\n    # If we get here, we should be good to go\n    # Let's do a final check for safety\n    release_confirm = (\n        input(f\"You are about to release {version!r} version. Are you sure? [y/n]: \")\n        .casefold()\n        .strip()\n    )\n\n    # Abort on anything other than 'y'\n    if release_confirm != \"y\":\n        session.error(f\"You said no when prompted to bump the {version!r} version.\")\n\n    session.run(\"poetry\", \"self\", \"add\", \"poetry-bumpversion\", external=True)\n\n    session.log(f\"Bumping the {version!r} version\")\n    session.run(\"poetry\", \"version\", version, external=True)\n    new_version = (\n        \"v\"\n        + cast(\n            str, session.run(\"poetry\", \"version\", \"--short\", silent=True, external=True)\n        ).strip()\n    )\n    session.log(f\"Creating {new_version} tag...\")\n    try:\n        session.run(\n            \"git\",\n            \"tag\",\n            \"-a\",\n            new_version,\n            \"-m\",\n            f\"Release {new_version}\",\n            external=True,\n        )\n    except CommandFailed:\n        session.log(f\"Failed to create {new_version} tag, probably already exists.\")\n    session.log(\"Pushing local tags...\")\n    session.run(\"git\", \"push\", \"--tags\", external=True)\n\n    session.run(\"git\", \"diff\", external=True)\n    commit_confirm = (\n        input(\n            \"You are about to commit auto-changed files due to version upgrade, \"\n            \"see the diff view above. Are you sure? [y/n]: \"\n        )\n        .casefold()\n        .strip()\n    )\n\n    if commit_confirm == \"y\":\n        session.run(\n            \"git\", \"commit\", \"-a\", \"-m\", f\"Release {new_version}\", external=True\n        )\n        session.run(\"git\", \"push\", external=True)\n    else:\n        session.log(\"Ok.\")", ""]}
{"filename": "configzen/decorators.py", "chunked_list": ["from __future__ import annotations\n\nimport contextlib\nimport functools\nfrom collections.abc import Callable, Coroutine, Iterator\nfrom typing import TYPE_CHECKING, Any, cast, overload\n\nfrom configzen.model import export_hook, export_model, export_model_async, field_hook\n\nif TYPE_CHECKING:\n    from configzen.typedefs import ConfigModelT, T", "\nif TYPE_CHECKING:\n    from configzen.typedefs import ConfigModelT, T\n\n__all__ = (\n    \"with_exporter\",\n    \"with_async_exporter\",\n    \"with_field_hook\",\n    \"with_export_hook\",\n)", "    \"with_export_hook\",\n)\n\n\n@overload\ndef with_export_hook(\n    func: Callable[[T], Any],\n    cls: None = None,\n) -> functools.partial[type[T]]:\n    ...", "\n\n@overload\ndef with_export_hook(\n    func: Callable[[T], Any],\n    cls: type[T],\n) -> type[T]:\n    ...\n\n\ndef with_export_hook(\n    func: Callable[[T], Any], cls: type[T] | None = None\n) -> type[T] | functools.partial[type[T]]:\n    \"\"\"\n    Register a pre-serialization converter function for a type.\n\n    Parameters\n    ----------\n    func\n        The converter function.\n\n    cls\n        The type to register the converter for.\n        Optional for the decoration syntax.\n\n    Returns\n    -------\n    The conversion result class.\n\n    Usage\n    -----\n    .. code-block:: python\n\n        @with_export_hook(converter_func)\n        class MyClass:\n            ...\n\n    \"\"\"\n    if cls is None:\n        return functools.partial(with_export_hook, func)\n\n    export_hook.register(cls, func)\n\n    if not hasattr(cls, \"__get_validators__\"):\n\n        def validator_gen() -> Iterator[Callable[[Any], Any]]:\n            hook_func = field_hook.dispatch(cls)\n            yield lambda value: hook_func(cls, value)\n\n        with contextlib.suppress(TypeError):\n            cls.__get_validators__ = validator_gen  # type: ignore[attr-defined]\n\n    return cls", "\n\ndef with_export_hook(\n    func: Callable[[T], Any], cls: type[T] | None = None\n) -> type[T] | functools.partial[type[T]]:\n    \"\"\"\n    Register a pre-serialization converter function for a type.\n\n    Parameters\n    ----------\n    func\n        The converter function.\n\n    cls\n        The type to register the converter for.\n        Optional for the decoration syntax.\n\n    Returns\n    -------\n    The conversion result class.\n\n    Usage\n    -----\n    .. code-block:: python\n\n        @with_export_hook(converter_func)\n        class MyClass:\n            ...\n\n    \"\"\"\n    if cls is None:\n        return functools.partial(with_export_hook, func)\n\n    export_hook.register(cls, func)\n\n    if not hasattr(cls, \"__get_validators__\"):\n\n        def validator_gen() -> Iterator[Callable[[Any], Any]]:\n            hook_func = field_hook.dispatch(cls)\n            yield lambda value: hook_func(cls, value)\n\n        with contextlib.suppress(TypeError):\n            cls.__get_validators__ = validator_gen  # type: ignore[attr-defined]\n\n    return cls", "\n\n@overload\ndef with_field_hook(\n    func: Callable[[type[T], Any], T],\n    cls: type[T],\n) -> type[T]:\n    ...\n\n", "\n\n@overload\ndef with_field_hook(\n    func: Callable[[type[T], Any], T],\n    cls: None = None,\n) -> functools.partial[type[T]]:\n    ...\n\n\ndef with_field_hook(\n    func: Callable[[type[T], Any], T], cls: type[T] | None = None\n) -> type[T] | functools.partial[type[T]]:\n    \"\"\"\n    Register a field hook for a type.\n\n    Parameters\n    ----------\n    func\n        The loader function.\n    cls\n        The type to register the loader for.\n\n    Returns\n    -------\n    The loading result class.\n    \"\"\"\n\n    if cls is None:\n        return functools.partial(with_field_hook, func)\n\n    field_hook.register(cls, func)\n    return cls", "\n\ndef with_field_hook(\n    func: Callable[[type[T], Any], T], cls: type[T] | None = None\n) -> type[T] | functools.partial[type[T]]:\n    \"\"\"\n    Register a field hook for a type.\n\n    Parameters\n    ----------\n    func\n        The loader function.\n    cls\n        The type to register the loader for.\n\n    Returns\n    -------\n    The loading result class.\n    \"\"\"\n\n    if cls is None:\n        return functools.partial(with_field_hook, func)\n\n    field_hook.register(cls, func)\n    return cls", "\n\ndef with_exporter(\n    func: Callable[[ConfigModelT], Any] | None = None,\n    cls: type[ConfigModelT] | None = None,\n    **predefined_kwargs: Any,\n) -> type[ConfigModelT] | Any:\n    \"\"\"\n    Register a custom exporter for a configuration model class.\n\n    Parameters\n    ----------\n    func\n        The exporter function.\n    cls\n        The type to register the exporter for.\n    \"\"\"\n    if cls is None:\n        return functools.partial(with_exporter, func)\n\n    if func and predefined_kwargs:\n        raise NotImplementedError(\n            \"specifying both a function and predefined kwargs is not supported\"\n        )\n\n    if func is None:\n\n        def func(obj: Any, **kwargs: Any) -> Any:\n            kwargs |= predefined_kwargs\n            return obj.export(**kwargs)\n\n        export_model.register(cls, func)\n\n        if export_model_async.dispatch(cls) is export_model_async:\n\n            async def default_async_func(obj: Any, **kwargs: Any) -> Any:\n                kwargs |= predefined_kwargs\n                return await obj.export_async(**kwargs)\n\n            export_model_async.register(cls, default_async_func)\n    else:\n        export_model.register(cls, func)\n        if export_model_async.dispatch(cls) is export_model_async:\n\n            async def default_async_func(obj: Any, **kwargs: Any) -> Any:\n                nonlocal func\n                if TYPE_CHECKING:\n                    func = cast(Callable[..., dict[str, Any]], func)\n\n                return func(obj, **kwargs)\n\n            export_model_async.register(cls, default_async_func)\n    return cls", "\n\ndef with_async_exporter(\n    func: Callable[[ConfigModelT], Coroutine[Any, Any, Any]] | None = None,\n    cls: type[ConfigModelT] | None = None,\n    **predefined_kwargs: Any,\n) -> type[ConfigModelT] | Any:\n    \"\"\"\n    Register a custom exporter for a configuration model class.\n\n    Parameters\n    ----------\n    func\n        The exporter function.\n    cls\n        The type to register the exporter for.\n    \"\"\"\n    if cls is None:\n        return functools.partial(with_exporter, func)\n\n    if func and predefined_kwargs:\n        raise NotImplementedError(\n            \"specifying both a function and default kwargs is not supported\"\n        )\n\n    if func is None:\n\n        async def default_async_func(obj: Any, **kwargs: Any) -> Any:\n            kwargs |= predefined_kwargs\n            return await obj.export_async(**kwargs)\n\n        export_model_async.register(cls, default_async_func)\n    else:\n        export_model_async.register(cls, func)\n    return cls", ""]}
{"filename": "configzen/model.py", "chunked_list": ["\"\"\"\nThe main module of the configzen library.\n\nThis module provides an API to manage configuration files and resources\nin a consistent way. It also provides tools to load and save configuration\nfiles in various formats and within a number of advanced methods.\n\n```python\nfrom configzen import ConfigModel, ConfigField, ConfigMeta\n", "from configzen import ConfigModel, ConfigField, ConfigMeta\n\nclass DatabaseConfig(ConfigModel):\n    host: str\n    port: int\n    user: str\n    password: str = ConfigField(exclude=True)\n\n    class Config(ConfigMeta):\n        resource = \"examples/database.json\"", "    class Config(ConfigMeta):\n        resource = \"examples/database.json\"\n\ndb_config = DatabaseConfig.load()\ndb_config.host = \"newhost\"\ndb_config.port = 5432\n\ndb_config.save()\n\ndb_config = DatabaseConfig.load()", "\ndb_config = DatabaseConfig.load()\nprint(db_config.host)\nprint(db_config.port)\n\n# Output:\n# newhost\n# 5432\n\ndb_config.host = \"otherhost\"", "\ndb_config.host = \"otherhost\"\ndb_config.port = 5433\n\ndb_config.at(\"host\").save()\n\nprint(db_config.host)\nprint(db_config.port)\n\n# Output:", "\n# Output:\n# otherhost\n# 5432  # <- not 5433, because we saved only host\n\ndb_config.host = \"anotherhost\"\ndb_config.at(\"port\").reload()\n\nprint(db_config.host)\nprint(db_config.port)", "print(db_config.host)\nprint(db_config.port)\n\n# Output:\n# otherhost  # <- not anotherhost, because we reloaded only port\n# 5432\n```\n\"\"\"\n# pyright: reportInvalidTypeVarUse=false, reportGeneralTypeIssues=false\n", "# pyright: reportInvalidTypeVarUse=false, reportGeneralTypeIssues=false\n\nfrom __future__ import annotations\n\nimport abc\nimport asyncio\nimport contextvars\nimport copy\nimport dataclasses\nimport functools", "import dataclasses\nimport functools\nimport importlib\nimport inspect\nimport io\nimport itertools\nimport os\nimport pathlib\nimport sys\nimport types", "import sys\nimport types\nimport urllib.parse\nimport urllib.request\nfrom collections.abc import Callable, Iterator, Mapping\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    ClassVar,\n    Generic,", "    ClassVar,\n    Generic,\n    Literal,\n    Optional,\n    Union,\n    cast,\n    get_args,\n    get_origin,\n    no_type_check,\n    overload,", "    no_type_check,\n    overload,\n)\n\nimport anyconfig\nimport pydantic\nfrom anyconfig.utils import filter_options, is_dict_like, is_list_like\nfrom pydantic.fields import make_generic_validator  # type: ignore[attr-defined]\nfrom pydantic.fields import ModelField, Undefined\nfrom pydantic.main import BaseModel, ModelMetaclass", "from pydantic.fields import ModelField, Undefined\nfrom pydantic.main import BaseModel, ModelMetaclass\nfrom pydantic.utils import ROOT_KEY\n\nfrom configzen._detach import (\n    detached_context_await,\n    detached_context_function,\n    detached_context_run,\n)\nfrom configzen.errors import (", ")\nfrom configzen.errors import (\n    ConfigAccessError,\n    InterpolationError,\n    ResourceLookupError,\n    UnavailableParserError,\n    UnspecifiedParserError,\n)\nfrom configzen.interpolation import (\n    EVALUATION_ENGINE,", "from configzen.interpolation import (\n    EVALUATION_ENGINE,\n    INTERPOLATOR,\n    BaseEvaluationEngine,\n    BaseInterpolator,\n    include,\n    include_const,\n    interpolate,\n)\nfrom configzen.module import MODULE, ConfigModule", ")\nfrom configzen.module import MODULE, ConfigModule\nfrom configzen.processor import EXPORT, DirectiveContext, Processor\nfrom configzen.route import ConfigRoute\nfrom configzen.typedefs import (\n    AsyncConfigIO,\n    ConfigIO,\n    ConfigModelT,\n    ConfigRouteLike,\n    IncludeExcludeT,", "    ConfigRouteLike,\n    IncludeExcludeT,\n    NormalizedResourceT,\n    RawResourceT,\n    T,\n)\n\ntry:\n    import aiofiles\nexcept ImportError:\n    aiofiles = None  # type: ignore[assignment]", "\n__all__ = (\n    \"ConfigAgent\",\n    \"ConfigAt\",\n    \"ConfigModel\",\n    \"ConfigMeta\",\n    \"export_hook\",\n    \"field_hook\",\n    \"export_model\",\n    \"export_model_async\",", "    \"export_model\",\n    \"export_model_async\",\n)\n\nALL_URL_SCHEMES: set[str] = set(\n    urllib.parse.uses_relative + urllib.parse.uses_netloc + urllib.parse.uses_params\n) - {\"\"}\n\nCONTEXT: str = \"__context__\"\nTOKEN: str = \"__context_token__\"", "CONTEXT: str = \"__context__\"\nTOKEN: str = \"__context_token__\"\nLOCAL: str = \"__local__\"\n\nINTERPOLATION_TRACKER: str = \"__interpolation_tracker__\"\nINTERPOLATION_INCLUSIONS: str = \"__interpolation_inclusions__\"\n\ncurrent_context: contextvars.ContextVar[\n    BaseContext[Any] | None\n] = contextvars.ContextVar(\"current_context\", default=None)", "    BaseContext[Any] | None\n] = contextvars.ContextVar(\"current_context\", default=None)\n\ncurrent_interpolation_tracker: contextvars.ContextVar[\n    dict[str, Any] | None\n] = contextvars.ContextVar(\"current_interpolation_tracker\", default=None)\n\n_exporting: contextvars.ContextVar[bool] = contextvars.ContextVar(\n    \"_exporting\", default=False\n)", "    \"_exporting\", default=False\n)\n\n\ndef _get_defaults_from_model_class(\n    model: type[pydantic.BaseModel],\n) -> dict[str, Any]:\n    defaults = {}\n    for field in model.__fields__.values():\n        default = field.default\n        if not field.field_info.exclude and not field.required:\n            if isinstance(default, pydantic.BaseModel):\n                default = default.dict()\n            defaults[field.alias] = default\n    return defaults", "\n\ndef _get_object_state(obj: Any) -> dict[str, Any]:\n    state = obj\n    if not isinstance(obj, dict):\n        state = obj.__dict__  # avoidance of vars() is intended\n    return cast(dict[str, Any], state)\n\n\n@functools.singledispatch\ndef export_hook(obj: Any) -> Any:\n    \"\"\"\n    Convert a value to a format that can be safely serialized.\n\n    This function is used to convert values that are not supported by\n    `anyconfig` to a format that can be safely serialized. It is used\n    internally by `ConfigModel` and `AsyncConfigModel` to convert\n    values before saving them to a file.\n\n    Parameters\n    ----------\n    obj\n        The value to convert.\n\n    Returns\n    -------\n    Any\n    \"\"\"\n    if dataclasses.is_dataclass(obj):\n        return export_hook(dataclasses.asdict(obj))\n    if isinstance(obj, tuple) and hasattr(obj, \"_asdict\") and hasattr(obj, \"_fields\"):\n        return _export_namedtuple(obj)\n    return obj", "\n@functools.singledispatch\ndef export_hook(obj: Any) -> Any:\n    \"\"\"\n    Convert a value to a format that can be safely serialized.\n\n    This function is used to convert values that are not supported by\n    `anyconfig` to a format that can be safely serialized. It is used\n    internally by `ConfigModel` and `AsyncConfigModel` to convert\n    values before saving them to a file.\n\n    Parameters\n    ----------\n    obj\n        The value to convert.\n\n    Returns\n    -------\n    Any\n    \"\"\"\n    if dataclasses.is_dataclass(obj):\n        return export_hook(dataclasses.asdict(obj))\n    if isinstance(obj, tuple) and hasattr(obj, \"_asdict\") and hasattr(obj, \"_fields\"):\n        return _export_namedtuple(obj)\n    return obj", "\n\n@functools.singledispatch\ndef _export_namedtuple(obj: tuple[Any, ...]) -> Any:\n    # Initially I wanted it to be export_hook(obj._asdict()), but\n    # pydantic doesn't seem to be friends with custom NamedTuple-s.\n    return export_hook(list(obj))\n\n\nfield_hook_registrars: Any = functools.singledispatch(lambda _cls, value: value)", "\nfield_hook_registrars: Any = functools.singledispatch(lambda _cls, value: value)\n\nif TYPE_CHECKING:\n\n    class _FieldHookType(Generic[T]):\n        def __call__(self, cls: type[T], value: Any) -> Any:\n            ...\n\n        def register(\n            self,\n            cls: type[T],\n            func: Callable[[type[T], Any], Any] | None = None,\n        ) -> Callable[\n            [Callable[[type[T], Any], Any]],\n            Callable[[type[T] | Any, Any], Any],\n        ]:\n            ...\n\n        def dispatch(self, cls: type[T]) -> Callable[[type[T] | Any, Any], Any]:\n            ...\n\n    field_hook: _FieldHookType[Any] = _FieldHookType()\n\nelse:\n\n    def field_hook(cls: type[Any], value: Any) -> Any:\n        \"\"\"\n        Automatically registered pre-validator for values in fields\n        where the outer type is `cls`.\n\n        This function is used to load values that are not supported by\n        `anyconfig` to a format that can be used at runtime. It is used\n        by pydantic while performing validation.\n\n        Parameters\n        ----------\n        cls\n            The type to load the value into.\n\n        value\n            The value to load.\n\n        Returns\n        -------\n        The loaded value.\n        \"\"\"\n        origin = get_origin(cls)\n        if origin in [Union] + (\n            [types.UnionType] if sys.version_info >= (3, 10) else []\n        ):\n            for result in itertools.starmap(\n                field_hook, zip(get_args(cls), itertools.repeat(value))\n            ):\n                if result != value:\n                    return result\n            return value\n        try:\n            if isinstance(value, origin or cls):\n                return value\n        except TypeError:\n            return value\n        if origin:\n            cls = origin\n\n        try:\n            cast_func = field_hook_registrars.dispatch(cls)\n        except KeyError:\n            return value\n        return cast_func(cls, value)\n\n    field_hook.register = field_hook_registrars.register", "\n\n@functools.singledispatch\ndef export_model(obj: Any, **kwargs: Any) -> dict[str, Any]:\n    \"\"\"\n    Export a ConfigModel to a safely-serializable format.\n    Register a custom exporter for a type using the `with_exporter` decorator,\n    which can help to exclude particular values from the export if needed.\n\n    Parameters\n    ----------\n    obj\n    \"\"\"\n    if isinstance(obj, ConfigModel) and not _exporting.get():\n        return obj.export(**kwargs)\n    return cast(dict[str, Any], obj.dict(**kwargs))", "\n\n@functools.singledispatch\nasync def export_model_async(obj: Any, **kwargs: Any) -> dict[str, Any]:\n    \"\"\"\n    Export a ConfigModel to a safely-serializable format.\n    Register a custom exporter for a type using the `with_exporter` decorator,\n    which can help to exclude particular values from the export if needed.\n\n    Parameters", "\n    Parameters\n    ----------\n    obj\n    \"\"\"\n    if isinstance(obj, ConfigModel) and not _exporting.get():\n        return await obj.export_async(**kwargs)\n    return cast(dict[str, Any], await obj.dict_async(**kwargs))\n\n\ndef _delegate_ac_options(\n    load_options: dict[str, Any], dump_options: dict[str, Any], options: dict[str, Any]\n) -> None:\n    for key, value in options.items():\n        if key.startswith(\"dump_\"):\n            actual_key = key.removeprefix(\"dump_\")\n            targets = [dump_options]\n        elif key.startswith(\"load_\"):\n            actual_key = key.removeprefix(\"load_\")\n            targets = [load_options]\n        else:\n            actual_key = key\n            targets = [load_options, dump_options]\n        for target in targets:\n            if actual_key in target:\n                msg = (\n                    f\"Option {key}={value!r} overlaps with \"\n                    f\"defined {actual_key}={target[actual_key]!r}\"\n                )\n                raise ValueError(msg)\n            target[actual_key] = value", "\n\ndef _delegate_ac_options(\n    load_options: dict[str, Any], dump_options: dict[str, Any], options: dict[str, Any]\n) -> None:\n    for key, value in options.items():\n        if key.startswith(\"dump_\"):\n            actual_key = key.removeprefix(\"dump_\")\n            targets = [dump_options]\n        elif key.startswith(\"load_\"):\n            actual_key = key.removeprefix(\"load_\")\n            targets = [load_options]\n        else:\n            actual_key = key\n            targets = [load_options, dump_options]\n        for target in targets:\n            if actual_key in target:\n                msg = (\n                    f\"Option {key}={value!r} overlaps with \"\n                    f\"defined {actual_key}={target[actual_key]!r}\"\n                )\n                raise ValueError(msg)\n            target[actual_key] = value", "\n\nclass ConfigAgent(Generic[ConfigModelT]):\n    \"\"\"\n    Configuration resource agent: loader and saver.\n\n    This class is used to broke between the model and the home resource, which\n    can be a file, a URL, or a file-like object. It is used internally\n    by `ConfigModel` and `AsyncConfigModel` to load and save\n    configuration files.\n\n    Attributes\n    ----------\n    create_if_missing\n        Whether to create the file if it doesn't exist.\n    parser_name\n        The name of the engines to use for loading and saving the\n        configuration. If not specified, the processor will be guessed\n        from the file extension.\n    allowed_url_schemes\n        The URL schemes that are allowed to be used.\n\n    Raises\n    ------\n    ValueError\n    \"\"\"\n\n    processor_class: type[Processor[ConfigModelT]]\n    create_if_missing: bool\n    is_relative: bool = False\n    allowed_url_schemes: set[str]\n    use_pydantic_json: bool = True\n    default_load_options: ClassVar[dict[str, Any]] = {}\n    default_dump_options: ClassVar[dict[str, Any]] = {\n        # These are usually desirable for configuration files.\n        # If you want to change them, you can do so by monkey-patching\n        # these variables. You can also change `load_options` and\n        # `dump_options` instance attributes to make a local change.\n        \"allow_unicode\": True,\n        \"ensure_ascii\": False,\n        \"indent\": 2,\n    }\n    _resource: NormalizedResourceT\n\n    predefined_default_kwargs: ClassVar[dict[str, Any]] = {\"encoding\": \"UTF-8\"}\n    default_allowed_url_schemes: ClassVar[set[str]] = {\"file\", \"http\", \"https\"}\n\n    OPEN_KWARGS: ClassVar[set[str]] = {\n        \"mode\",\n        \"buffering\",\n        \"encoding\",\n        \"errors\",\n        \"newline\",\n    }\n    URLOPEN_KWARGS: ClassVar[set[str]] = {\n        \"data\",\n        \"timeout\",\n        \"cafile\",\n        \"capath\",\n        \"cadefault\",\n        \"context\",\n    }\n    JSON_KWARGS: ClassVar[set[str]] = {\n        \"skipkeys\",\n        \"ensure_ascii\",\n        \"check_circular\",\n        \"allow_nan\",\n        \"cls\",\n        \"indent\",\n        \"separators\",\n        \"default\",\n        \"sort_keys\",\n    }\n    EXPORT_KWARGS: ClassVar[set[str]] = {\n        \"by_alias\",\n        \"include\",\n        \"exclude\",\n        \"exclude_unset\",\n        \"exclude_defaults\",\n        \"exclude_none\",\n    }\n    EXTRA_FILE_EXTENSIONS: ClassVar[dict[str, str]] = {\n        \"yml\": \"yaml\",\n        \"conf\": \"ini\",\n        \"cfg\": \"ini\",\n        # Note: CBOR (RFC 7049) is deprecated, use CBOR (RFC 8949) instead.\n        \"cbor\": \"cbor2\",\n        # https://github.com/msgpack/msgpack/issues/291#issuecomment-1370526984\n        \"mpk\": \"msgpack\",\n        \"pkl\": \"pickle\",\n    }\n    BINARY_DATA_PARSERS: ClassVar[set[str]] = {\n        \"ion\",\n        \"bson\",\n        \"cbor\",\n        \"cbor2\",\n        \"msgpack\",\n        \"pickle\",\n    }\n    SUPPORTED_PARSERS: list[str] = anyconfig.list_types()\n\n    def __init__(\n        self,\n        resource: RawResourceT,\n        parser_name: str | None = None,\n        processor_class: type[Processor[ConfigModelT]] | None = None,\n        *,\n        create_if_missing: bool = False,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Parameters\n        ----------\n        resource\n            The URL to the configuration file, or a file-like object.\n        parser_name\n            The name of the anyconfig parser to use\n            for loading and saving the configuration.\n        create_if_missing\n            Whether to automatically create missing keys when loading the configuration.\n        default_kwargs\n            Default keyword arguments to pass while opening the resource.\n        use_pydantic_json\n            Whether to use Pydantic's JSON encoder/decoder instead of the default\n            anyconfig one.\n        uses_binary_data\n            Whether to treat the data as binary.\n            Defaults to True for formats listed in `ConfigAgent.BINARY_DATA_PARSERS`.\n        **kwargs\n            Additional keyword arguments to pass to\n            `anyconfig.loads()` and `anyconfig.dumps()`.\n        \"\"\"\n        self._parser_name = None\n        self._uses_binary_data = kwargs.get(\"uses_binary_data\", False)\n\n        if processor_class is None:\n            processor_class = Processor[ConfigModelT]\n\n        self.processor_class = processor_class\n        self.parser_name = parser_name\n\n        if isinstance(resource, (str, os.PathLike)) and not (\n            isinstance(resource, str)\n            and urllib.parse.urlparse(str(resource)).scheme in ALL_URL_SCHEMES\n        ):\n            raw_path = os.fspath(resource)\n            resource = pathlib.Path(raw_path)\n            if (\n                raw_path.startswith(\".\")\n                and resource.parts\n                and not resource.parts[0].startswith(\".\")\n            ):\n                self.is_relative = True\n\n        self.resource = resource\n        self.create_if_missing = create_if_missing\n        self.use_pydantic_json = kwargs.pop(\"use_pydantic_json\", True)\n        self.default_kwargs = kwargs.pop(\n            \"default_kwargs\", self.predefined_default_kwargs.copy()\n        )\n        self.allowed_url_schemes = kwargs.pop(\n            \"allowed_url_schemes\", self.default_allowed_url_schemes.copy()\n        )\n\n        self.load_options = self.default_load_options.copy()\n        self.dump_options = self.default_dump_options.copy()\n\n        _delegate_ac_options(self.load_options, self.dump_options, kwargs)\n\n    @property\n    def resource(self) -> NormalizedResourceT:\n        \"\"\"\n        The resource of the configuration.\n\n        This can be a file path, a URL, or a file-like object.\n\n        Returns\n        -------\n        The resource of the configuration.\n        \"\"\"\n        return self._resource\n\n    @resource.setter\n    def resource(self, value: NormalizedResourceT) -> None:\n        \"\"\"\n        The resource of the configuration.\n\n        This can be a file path, a URL, or a file-like object.\n\n        .. note::\n            If the resource is a file path, the processor will be guessed\n            from the file extension.\n\n        Returns\n        -------\n        The resource of the configuration.\n        \"\"\"\n        self._resource = value\n        if self.parser_name is None:\n            self.parser_name = self._guess_parser_name()\n\n    @property\n    def parser_name(self) -> str | None:\n        return self._parser_name\n\n    @parser_name.setter\n    def parser_name(self, value: str | None) -> None:\n        if value is not None:\n            value = value.casefold()\n        self._parser_name = value\n\n    def _guess_parser_name(self) -> str | None:\n        parser_name = None\n        if isinstance(self.resource, pathlib.Path):\n            suffix = self.resource.suffix[1:].casefold()\n            supported_parsers = self.SUPPORTED_PARSERS\n            if not suffix:\n                recognized_file_extensions = supported_parsers + [\n                    alias + \"(-> \" + actual_parser_name + \")\"\n                    for alias, actual_parser_name in self.EXTRA_FILE_EXTENSIONS.items()\n                    if actual_parser_name in supported_parsers\n                ]\n                msg = (\n                    \"Could not guess the anyconfig parser to use for \"\n                    f\"{self.resource!r}.\\n\"\n                    f\"Recognized file extensions: {recognized_file_extensions}\"\n                )\n                raise UnspecifiedParserError(msg)\n            parser_name = self.EXTRA_FILE_EXTENSIONS.get(suffix, suffix)\n            if (\n                parser_name == \"cbor2\"\n                and \"cbor2\" not in supported_parsers\n                and \"cbor\" in supported_parsers\n            ):\n                parser_name = \"cbor\"\n        return parser_name\n\n    def load_into(\n        self,\n        config_class: type[ConfigModelT],\n        blob: str | bytes,\n        parser_name: str | None = None,\n        **kwargs: Any,\n    ) -> ConfigModelT:\n        \"\"\"\n        Load the configuration into a `ConfigModel` subclass.\n\n        Parameters\n        ----------\n        config_class\n            The `ConfigModel` subclass to load the configuration into.\n        blob\n            The configuration to load.\n        parser_name\n            The name of the engines to use for loading the configuration.\n        **kwargs\n            Additional keyword arguments to pass to `anyconfig.loads()`.\n\n        Returns\n        -------\n        The loaded configuration.\n        \"\"\"\n        dict_config = self.load_dict(blob, parser_name=parser_name, **kwargs)\n        if dict_config is None:\n            dict_config = {}\n        return config_class.parse_obj(dict_config)\n\n    async def async_load_into(\n        self,\n        config_class: type[ConfigModelT],\n        blob: str | bytes,\n        parser_name: str | None = None,\n        **kwargs: Any,\n    ) -> ConfigModelT:\n        \"\"\"\n        Load the configuration into a `ConfigModel` subclass asynchronously.\n\n        Parameters\n        ----------\n        config_class\n            The `ConfigModel` subclass to load the configuration into.\n        blob\n            The configuration to load.\n        parser_name\n            The name of the engines to use for loading the configuration.\n        **kwargs\n            Additional keyword arguments to pass to `anyconfig.loads()`.\n\n        Returns\n        -------\n        The loaded configuration.\n        \"\"\"\n        dict_config = await self.load_dict_async(\n            blob, parser_name=parser_name, **kwargs\n        )\n        if dict_config is None:\n            dict_config = {}\n        return config_class.parse_obj(dict_config)\n\n    def _load_dict_impl(\n        self,\n        blob: str | bytes,\n        parser_name: str | None = None,\n        **kwargs: Any,\n    ) -> dict[str, Any]:\n        parser_name = parser_name or self.parser_name or self._guess_parser_name()\n        if parser_name is None:\n            msg = \"Cannot read configuration because `parser_name` was not specified\"\n            raise UnspecifiedParserError(msg)\n        kwargs = self.load_options | kwargs\n        try:\n            loaded = anyconfig.loads(  # type: ignore[no-untyped-call]\n                blob, ac_parser=parser_name, **kwargs\n            )\n        except anyconfig.UnknownParserTypeError as exc:\n            raise UnavailableParserError(str(exc).split()[-1], self) from exc\n        if not isinstance(loaded, Mapping):\n            msg = (\n                f\"Expected a mapping as a result of loading {self.resource}, \"\n                f\"got {type(loaded).__name__}.\"\n            )\n            raise TypeError(msg)\n        return dict(loaded)\n\n    def load_dict(\n        self,\n        blob: str | bytes,\n        parser_name: str | None = None,\n        *,\n        preprocess: bool = True,\n        **kwargs: Any,\n    ) -> dict[str, Any]:\n        \"\"\"\n        Load the configuration into a dictionary. The dictionary is\n        usually used to initialize a `ConfigModel` subclass. If the\n        configuration is empty, None might be returned instead of a dictionary.\n\n        Parameters\n        ----------\n        blob\n            The configuration to load.\n        parser_name\n            The name of the anyconfig parser to use for loading the configuration.\n        preprocess\n        **kwargs\n            Additional keyword arguments to pass to `anyconfig.loads()`.\n\n        Returns\n        -------\n        The loaded configuration dictionary.\n        \"\"\"\n        loaded = self._load_dict_impl(blob, parser_name=parser_name, **kwargs)\n        if preprocess:\n            loaded = self.processor_class(self, loaded).preprocess()\n        return loaded\n\n    async def load_dict_async(\n        self,\n        blob: str | bytes,\n        parser_name: str | None = None,\n        *,\n        preprocess: bool = True,\n        **kwargs: Any,\n    ) -> dict[str, Any]:\n        \"\"\"\n        Load the configuration into a dictionary asynchronously.\n\n        Parameters\n        ----------\n        blob\n            The configuration to load.\n        parser_name\n            The name of the anyconfig parser to use for loading the configuration.\n        preprocess\n        **kwargs\n            Additional keyword arguments to pass to `anyconfig.loads()`.\n\n        Returns\n        -------\n        The loaded configuration dictionary.\n        \"\"\"\n        loaded = self._load_dict_impl(blob, parser_name, **kwargs)\n        if preprocess:\n            loaded = await self.processor_class(self, loaded).preprocess_async()\n        return loaded\n\n    def dump_config(\n        self,\n        config: ConfigModelT,\n        parser_name: str | None = None,\n        **kwargs: Any,\n    ) -> str:\n        \"\"\"\n        Dump the configuration to a string.\n\n        Parameters\n        ----------\n        config\n            The configuration to dump.\n        parser_name\n            The name of the anyconfig parser to use for saving the configuration.\n        **kwargs\n            Additional keyword arguments to pass to `anyconfig.dumps()`.\n\n        Returns\n        -------\n        The dumped configuration.\n        \"\"\"\n        if parser_name is None:\n            parser_name = self.parser_name\n        export_kwargs = filter_options(self.EXPORT_KWARGS, kwargs)\n        if parser_name == \"json\" and self.use_pydantic_json:\n            export_kwargs |= filter_options(\n                self.JSON_KWARGS, self.dump_options | kwargs\n            )\n            _exporting.set(True)  # noqa: FBT003\n            return detached_context_run(config.json, **export_kwargs)\n        data = export_model(config, **export_kwargs)\n        return self.dump_data(data, parser_name=parser_name, **kwargs)\n\n    async def dump_config_async(\n        self,\n        config: ConfigModelT,\n        parser_name: str | None = None,\n        **kwargs: Any,\n    ) -> str:\n        \"\"\"\n        Dump the configuration to a string.\n\n        Parameters\n        ----------\n        config\n            The configuration to dump.\n        parser_name\n            The name of the anyconfig parser to use for saving the configuration.\n        **kwargs\n            Additional keyword arguments to pass to `anyconfig.dumps()`.\n\n        Returns\n        -------\n        The dumped configuration.\n        \"\"\"\n        if parser_name is None:\n            parser_name = self.parser_name\n        export_kwargs = filter_options(self.EXPORT_KWARGS, kwargs)\n        if parser_name == \"json\" and self.use_pydantic_json:\n            export_kwargs |= filter_options(\n                self.JSON_KWARGS, self.dump_options | kwargs\n            )\n            _exporting.set(True)  # noqa: FBT003\n            return await detached_context_await(config.json_async, **export_kwargs)\n        data = await export_model_async(config, **export_kwargs)\n        return self.dump_data(data, parser_name=parser_name, **kwargs)\n\n    def dump_data(\n        self,\n        data: dict[str, Any],\n        parser_name: str | None = None,\n        **kwargs: Any,\n    ) -> str:\n        \"\"\"\n        Dump data to a string.\n\n        Parameters\n        ----------\n        data\n            The data to dump.\n        parser_name\n            The name of the anyconfig parser to use for saving the configuration.\n        kwargs\n            Additional keyword arguments to pass to `anyconfig.dumps()`.\n\n        Returns\n        -------\n        The dumped configuration.\n        \"\"\"\n        if parser_name is None:\n            parser_name = self.parser_name\n        if parser_name is None:\n            msg = (\n                \"Cannot write configuration because `parser_name` was not specified\"\n                f\"for agent {self}\"\n            )\n            raise UnspecifiedParserError(msg)\n        kwargs = self.dump_options | kwargs\n        return anyconfig.dumps(export_hook(data), ac_parser=parser_name, **kwargs)\n\n    @property\n    def is_url(self) -> bool:\n        \"\"\"\n        Whether the resource is a URL.\n\n        This simply checks if the resource object is a string, since local paths\n        are converted into `pathlib.Path` objects.\n        \"\"\"\n        return isinstance(self.resource, str)\n\n    @property\n    def uses_binary_data(self) -> bool:\n        \"\"\"\n        Whether the resource uses bytes for storing data, not str.\n        \"\"\"\n        return self._uses_binary_data or self.parser_name in self.BINARY_DATA_PARSERS\n\n    def open_resource(self, **kwds: Any) -> ConfigIO:\n        \"\"\"\n        Open the configuration file.\n\n        Parameters\n        ----------\n        **kwds\n            Keyword arguments to pass to the opening routine.\n            For URLs, these are passed to ``urllib.request.urllib.request.urlopen()``.\n            For local files, these are passed to ``builtins.open()``.\n\n        Returns\n        -------\n        The opened resource.\n        \"\"\"\n        if self.resource is None:\n            if self.uses_binary_data:\n                return io.BytesIO()\n            return io.StringIO()\n        if self.is_url:\n            url = urllib.parse.urlparse(cast(str, self.resource))\n            if url.scheme not in self.allowed_url_schemes:\n                msg = (\n                    f\"URL scheme {url.scheme!r} is not allowed, \"\n                    f\"must be one of {self.allowed_url_schemes!r}\"\n                )\n                raise ValueError(msg)\n            kwds = filter_options(self.URLOPEN_KWARGS, kwds)\n            request = urllib.request.Request(url.geturl())\n            return cast(ConfigIO, urllib.request.urlopen(request, **kwds))  # noqa: S310\n        if isinstance(self.resource, (int, pathlib.Path)):\n            kwds = filter_options(self.OPEN_KWARGS, kwds)\n            if isinstance(self.resource, int):\n                return cast(\n                    ConfigIO,\n                    # We intentionally do not use the context manager here\n                    # because we do not want to close the file.\n                    # Moreover, we want to allow the file to be opened\n                    # from a file descriptor, not supported by Path().\n                    open(self.resource, **kwds),  # noqa: PTH123, SIM115\n                )\n            return cast(ConfigIO, pathlib.Path(self.resource).open(**kwds))\n        return cast(ConfigIO, self.resource)\n\n    def open_resource_async(self, **kwds: Any) -> AsyncConfigIO:\n        \"\"\"\n        Open the configuration file asynchronously.\n\n        Parameters\n        ----------\n        **kwds\n            Keyword arguments to pass to the opening routine.\n\n        Returns\n        -------\n        The opened resource.\n        \"\"\"\n        if self.is_url:\n            msg = \"Asynchronous URL opening is not supported\"\n            raise NotImplementedError(msg)\n        if aiofiles is None:\n            msg = (\n                \"Aiofiles is not available, cannot open file \"\n                \"asynchronously (install with `pip install aiofiles`)\"\n            )\n            raise RuntimeError(msg)\n        if isinstance(self.resource, (int, pathlib.Path)):\n            kwds = filter_options(self.OPEN_KWARGS, kwds)\n            return aiofiles.open(self.resource, **kwds)\n        raise RuntimeError(\"cannot open resource asynchronously\")\n\n    def processor_open_resource(self, **kwargs: Any) -> ConfigIO:\n        \"\"\"\n        Called by the processor to open a configuration resource\n        with the reading intention.\n\n        Parameters\n        ----------\n        **kwargs\n            Keyword arguments to pass to the opening routine.\n            For URLs, these are passed to ``urllib.request.urlopen()``.\n            For local files, these are passed to ``builtins.open()``.\n\n        Returns\n        -------\n        The opened resource.\n        \"\"\"\n        kwargs = self._get_default_kwargs(\"read\", kwargs)\n        return self.open_resource(**kwargs)\n\n    def processor_open_resource_async(self, **kwargs: Any) -> AsyncConfigIO:\n        \"\"\"\n        Called by the processor to open a configuration resource asynchronously\n        with the reading intention.\n\n        Parameters\n        ----------\n        **kwargs\n            Keyword arguments to pass to the opening routine.\n            For URLs, these are passed to ``urllib.request.urlopen()``.\n            For local files, these are passed to ``builtins.open()``.\n\n        Returns\n        -------\n        The opened resource.\n        \"\"\"\n        kwargs = self._get_default_kwargs(\"read\", kwargs)\n        return self.open_resource_async(**kwargs)\n\n    def _get_default_kwargs(\n        self,\n        method: Literal[\"read\", \"write\"],\n        kwargs: dict[str, Any] | None = None,\n    ) -> dict[str, Any]:\n        if not kwargs:\n            kwargs = self.default_kwargs\n        new_kwargs = cast(dict[str, Any], kwargs).copy()\n        if not self.is_url:\n            if method == \"read\":\n                new_kwargs.setdefault(\"mode\", \"rb\" if self.uses_binary_data else \"r\")\n            elif method == \"write\":\n                new_kwargs.setdefault(\"mode\", \"wb\" if self.uses_binary_data else \"w\")\n            else:\n                msg = f\"Invalid resource access method: {method!r}\"\n                raise ValueError(msg)\n        if self.uses_binary_data:\n            new_kwargs.pop(\"encoding\", None)\n        return new_kwargs\n\n    def read(\n        self,\n        *,\n        config_class: type[ConfigModelT],\n        create_kwargs: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -> ConfigModelT:\n        \"\"\"\n        Read the configuration file.\n\n        Parameters\n        ----------\n        config_class\n            The configuration model class to load the configuration into.\n        create_kwargs\n            Keyword arguments to pass to the open method\n            when optionally creating the file.\n        **kwargs\n            Keyword arguments to pass to the open method.\n\n        Returns\n        -------\n        The loaded configuration.\n        \"\"\"\n        kwargs = self._get_default_kwargs(\"read\", kwargs=kwargs)\n        try:\n            with self.open_resource(**kwargs) as fp:\n                blob = fp.read()\n        except FileNotFoundError:\n            if self.create_if_missing:\n                defaults = _get_defaults_from_model_class(config_class)\n                blob = self.dump_data(defaults)\n                self.write(blob, **(create_kwargs or {}))\n            else:\n                raise\n        return self.load_into(config_class, blob, **self.load_options)\n\n    def write(self, blob: str | bytes, **kwargs: Any) -> int:\n        \"\"\"\n        Write the configuration file.\n\n        Parameters\n        ----------\n        blob\n            The string/bytes to write into the resource.\n        kwargs\n            Keyword arguments to pass to the opening routine.\n\n        Returns\n        -------\n        The number of bytes written.\n        \"\"\"\n        kwargs = self._get_default_kwargs(\"write\", kwargs=kwargs)\n        with self.open_resource(**kwargs) as fp:\n            return fp.write(cast(str, blob))\n\n    async def read_async(\n        self,\n        *,\n        config_class: type[ConfigModelT],\n        create_kwargs: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -> ConfigModelT:\n        \"\"\"\n        Read the configuration file asynchronously.\n\n        Parameters\n        ----------\n        config_class\n            The configuration model class to load the configuration into.\n        create_kwargs\n            Keyword arguments to pass to the open method\n            when optionally creating the file.\n        **kwargs\n            Keyword arguments to pass to the open method.\n\n        Returns\n        -------\n        The loaded configuration.\n        \"\"\"\n        kwargs = self._get_default_kwargs(\"read\", kwargs=kwargs)\n        try:\n            async with self.open_resource_async(**kwargs) as fp:\n                blob = await fp.read()\n        except FileNotFoundError:\n            if self.create_if_missing:\n                defaults = _get_defaults_from_model_class(config_class)\n                blob = self.dump_data(defaults)\n                await self.write_async(blob, **(create_kwargs or {}))\n            else:\n                raise\n        return await self.async_load_into(config_class, blob, **self.load_options)\n\n    async def write_async(\n        self,\n        blob: str | bytes,\n        **kwargs: Any,\n    ) -> int:\n        \"\"\"\n        Write the configuration file asynchronously.\n\n        Parameters\n        ----------\n        blob\n            The string/bytes to write into the resource.\n        kwargs\n            Keyword arguments to pass to the opening routine.\n\n        Returns\n        -------\n        The number of bytes written.\n        \"\"\"\n        kwargs = self._get_default_kwargs(\"write\", kwargs=kwargs)\n        async with self.open_resource_async(**kwargs) as fp:\n            # Technically those might be also bytes,\n            # todo(bswck): type hint it properly...\n            return await fp.write(cast(str, blob))\n\n    @classmethod\n    def from_directive_context(\n        cls,\n        ctx: DirectiveContext,\n        /,\n        route_separator: str = \":\",\n        route_class: type[ConfigRoute] | None = None,\n    ) -> tuple[ConfigAgent[ConfigModelT], ConfigRouteLike | None]:\n        \"\"\"\n        Create a configuration agent from a preprocessor directive context.\n        Return an optional scope that the context points to.\n\n        Parameters\n        ----------\n        route_class\n        route_separator\n        ctx\n\n        Returns\n        -------\n        The configuration agent.\n        \"\"\"\n        if route_class is None:\n            route_class = ConfigRoute\n        route: ConfigRouteLike | None = None\n        args: list[Any] = []\n        kwargs: dict[str, Any] = {}\n        if isinstance(ctx.snippet, str):\n            path, _, route = ctx.snippet.partition(route_separator)\n            route = ConfigRoute(\n                route.strip().replace(route_separator, route_class.TOK_DOT)\n            )\n            args.append(path)\n        elif isinstance(ctx.snippet, int):\n            args.append(ctx.snippet)\n        elif is_dict_like(ctx.snippet):\n            kwargs |= ctx.snippet\n        elif is_list_like(ctx.snippet):\n            args += list(ctx.snippet)\n        else:\n            msg = (\n                f\"Invalid snippet for the {ctx.directive!r} directive: {ctx.snippet!r}\"\n            )\n            raise ValueError(msg)\n        return cls(*args, **kwargs), str(route)\n\n    @classmethod\n    def register_file_extension(\n        cls,\n        file_extension: str,\n        *,\n        parser_name: str,\n    ) -> None:\n        \"\"\"\n        Register a file extension with the proper anyconfig parser to use.\n\n        Parameters\n        ----------\n        file_extension\n        parser_name\n\n        Returns\n        -------\n        \"\"\"\n        cls.EXTRA_FILE_EXTENSIONS[file_extension] = parser_name\n\n    def __repr__(self) -> str:\n        resource = self.resource\n        return f\"{type(self).__name__}({resource=!r})\"", "\n\ndef at(\n    mapping: Any,\n    route: ConfigRouteLike,\n    converter_func: Callable[[Any], dict[str, Any]] = _get_object_state,\n    agent: ConfigAgent[ConfigModelT] | None = None,\n) -> Any:\n    \"\"\"\n    Get an item at a route.\n\n    Parameters\n    ----------\n    mapping\n        The mapping to use.\n    route\n        The route to the item.\n    converter_func\n    agent\n\n    Returns\n    -------\n    The item at the route.\n    \"\"\"\n    route = ConfigRoute(route)\n    route_here = []\n    scope = converter_func(mapping)\n    try:\n        for part in route:\n            route_here.append(part)\n            scope = converter_func(scope)[part]\n    except KeyError:\n        raise ResourceLookupError(agent, route_here) from None\n    return scope", "\n\n@dataclasses.dataclass(frozen=True)\nclass ConfigAt(Generic[ConfigModelT]):\n    \"\"\"\n    A configuration item at a specific location.\n\n    Attributes\n    ----------\n    owner\n        The configuration model instance.\n    mapping\n        The mapping to use.\n    route\n        The route to the item.\n    \"\"\"\n\n    owner: ConfigModelT\n    mapping: dict[str, Any] | None\n    route: ConfigRouteLike\n\n    def get(\n        self, route: ConfigRouteLike | None = None, default: Any = Undefined\n    ) -> Any:\n        \"\"\"\n        Get the value of the item.\n\n        Parameters\n        ----------\n        route\n            The route to the item. If not given, the sole route of this item is used.\n            If given, the route is appended to the sole route of this item.\n        default\n            The default value to return if the item is not found.\n\n        Returns\n        -------\n        The value of the item.\n        \"\"\"\n        base_route = ConfigRoute(self.route)\n        if route is None:\n            route = base_route\n        else:\n            route = base_route.enter(ConfigRoute(route, allow_empty=True))\n        try:\n            scope = at(self.mapping or self.owner, route)\n        except ResourceLookupError as err:\n            if default is Undefined:\n                route_here = err.route\n                raise ConfigAccessError(self.owner, route_here) from None\n            scope = default\n        return scope\n\n    def update(self, value: Any) -> Any:\n        \"\"\"\n        Update the value of the item with regard to this item mapping.\n\n        Parameters\n        ----------\n        value\n            The new value.\n\n        Returns\n        -------\n        The updated mapping.\n        \"\"\"\n        route = list(ConfigRoute(self.route))\n        mapping = self.mapping or self.owner\n        key = route.pop()\n        scope = _get_object_state(mapping)\n        route_here = []\n        try:\n            for part in route:\n                route_here.append(part)\n                scope = _get_object_state(scope[part])\n            scope[key] = value\n        except KeyError:\n            raise ConfigAccessError(self.owner, route_here) from None\n        return mapping\n\n    async def save_async(self, **kwargs: Any) -> int:\n        \"\"\"\n        Save the configuration asynchronously.\n\n        Parameters\n        ----------\n        **kwargs\n            Keyword arguments to pass to the saving function.\n\n        Returns\n        -------\n        The number of bytes written.\n        \"\"\"\n        return await _partial_save_async(self, **kwargs)\n\n    def save(self, **kwargs: Any) -> int:\n        \"\"\"\n        Save the configuration.\n\n        Parameters\n        ----------\n        **kwargs\n            Keyword arguments to pass to the saving function.\n\n        Returns\n        -------\n        The number of bytes written.\n        \"\"\"\n        return _partial_save(self, **kwargs)\n\n    async def reload_async(self, **kwargs: Any) -> Any:\n        \"\"\"\n        Reload the configuration asynchronously.\n\n        Parameters\n        ----------\n        kwargs\n            Keyword arguments to pass to the reloading function.\n\n        Returns\n        -------\n        The reloaded configuration or its belonging item.\n        \"\"\"\n        return await _partial_reload_async(self, **kwargs)\n\n    def reload(self, **kwargs: Any) -> Any:\n        \"\"\"\n        Reload the configuration.\n\n        Parameters\n        ----------\n        kwargs\n            Keyword arguments to pass to the reloading function.\n\n        Returns\n        -------\n        The reloaded configuration or its belonging item.\n        \"\"\"\n        return _partial_reload(self, **kwargs)", "\n\ndef _partial_save(\n    section: ConfigModelT | ConfigAt[ConfigModelT],\n    write_kwargs: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -> int:\n    if isinstance(section, ConfigModel):\n        config = section\n        return config.save(write_kwargs=write_kwargs, **kwargs)\n\n    if write_kwargs is None:\n        write_kwargs = {}\n\n    config = section.owner\n    data = config.initial_state\n    scope = ConfigAt(config, data, section.route)\n    data = scope.update(section.get())\n    context = get_context(config)\n    blob = context.agent.dump_config(config.copy(update=data), **kwargs)\n    result = config.write(blob, **write_kwargs)\n    context.initial_state = data\n    return result", "\n\nasync def _partial_save_async(\n    section: ConfigModelT | ConfigAt[ConfigModelT],\n    write_kwargs: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -> int:\n    if isinstance(section, ConfigModel):\n        config = section\n        return await config.save_async(write_kwargs=write_kwargs, **kwargs)", "\n    if write_kwargs is None:\n        write_kwargs = {}\n\n    config = section.owner\n    data = config.initial_state\n    scope = ConfigAt(config, data, section.route)\n    data = scope.update(section.get())\n    context = get_context(config)\n    blob = context.agent.dump_config(config.copy(update=data), **kwargs)", "    context = get_context(config)\n    blob = context.agent.dump_config(config.copy(update=data), **kwargs)\n    result = await config.write_async(blob, **write_kwargs)\n    context.initial_state = data\n    return result\n\n\ndef _partial_reload(\n    section: ConfigModelT | ConfigAt[ConfigModelT], **kwargs: Any\n) -> Any:\n    if isinstance(section, ConfigModel):\n        config = section\n        return config.reload()\n\n    config = section.owner\n    context = get_context(config)\n    state = config.__dict__\n    newest = context.agent.read(config_class=type(config), **kwargs)\n    section_data = ConfigAt(newest, newest.__dict__, section.route).get()\n    ConfigAt(config, state, section.route).update(section_data)\n    return section_data", "\n\nasync def _partial_reload_async(\n    section: ConfigModelT | ConfigAt[ConfigModelT], **kwargs: Any\n) -> Any:\n    if isinstance(section, ConfigModel):\n        config = section\n        return await config.reload_async()\n\n    config = section.owner", "\n    config = section.owner\n    context = get_context(config)\n    state = config.__dict__\n    newest = await context.agent.read_async(config_class=type(config), **kwargs)\n    section_data = ConfigAt(newest, newest.__dict__, section.route).get()\n    ConfigAt(config, state, section.route).update(section_data)\n    return section_data\n\n\nclass BaseContext(abc.ABC, Generic[ConfigModelT]):\n    \"\"\"\n    The base class for configuration context.\n    Contexts are used to\n    - store configuration resource information,\n    - link configuration items to the configuration models they belong to,\n    - keep track of the route leading to particular configuration\n      items that are also ConfigModel subclasses.\n\n    Attributes\n    ----------\n    initial_state\n        The initial configuration state.\n\n    \"\"\"\n\n    initial_state: dict[str, Any]\n    interpolation_namespace: dict[str, Any]\n\n    @abc.abstractmethod\n    def trace_route(self) -> Iterator[str]:\n        \"\"\"Trace the route to where the configuration subcontext points to.\"\"\"\n\n    @property\n    def route(self) -> ConfigRoute:\n        \"\"\"The route to where the configuration subcontext points to.\"\"\"\n        return ConfigRoute(list(self.trace_route()))\n\n    @overload\n    def enter(self: BaseContext[ConfigModelT], part: None) -> BaseContext[ConfigModelT]:\n        ...\n\n    @overload\n    def enter(self, part: str) -> Subcontext[ConfigModelT]:\n        ...\n\n    def enter(\n        self, part: str | None\n    ) -> Subcontext[ConfigModelT] | BaseContext[ConfigModelT]:\n        \"\"\"\n        Enter a subcontext.\n\n        Parameters\n        ----------\n        part\n            The name of the item nested in the item this context points to.\n\n        Returns\n        -------\n        The new subcontext.\n        \"\"\"\n        if part is None:\n            return self\n        return Subcontext(self, part, self.interpolation_namespace.setdefault(part, {}))\n\n    @property\n    @abc.abstractmethod\n    def agent(self) -> ConfigAgent[ConfigModelT]:\n        \"\"\"The configuration agent responsible for loading and saving.\"\"\"\n\n    @property\n    @abc.abstractmethod\n    def toplevel_interpolation_namespace(self) -> dict[str, Any]:\n        \"\"\"Top-level interpolation namespace.\"\"\"\n\n    @property\n    @abc.abstractmethod\n    def owner(self) -> ConfigModelT | None:\n        \"\"\"\n        The top-level configuration model instance,\n        holding all adjacent contexts.\n        \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def at(self) -> ConfigModelT | ConfigAt[ConfigModelT] | None:\n        \"\"\"\n        The configuration model instance or the configuration item\n        this context points to.\n        \"\"\"", "\n\nclass BaseContext(abc.ABC, Generic[ConfigModelT]):\n    \"\"\"\n    The base class for configuration context.\n    Contexts are used to\n    - store configuration resource information,\n    - link configuration items to the configuration models they belong to,\n    - keep track of the route leading to particular configuration\n      items that are also ConfigModel subclasses.\n\n    Attributes\n    ----------\n    initial_state\n        The initial configuration state.\n\n    \"\"\"\n\n    initial_state: dict[str, Any]\n    interpolation_namespace: dict[str, Any]\n\n    @abc.abstractmethod\n    def trace_route(self) -> Iterator[str]:\n        \"\"\"Trace the route to where the configuration subcontext points to.\"\"\"\n\n    @property\n    def route(self) -> ConfigRoute:\n        \"\"\"The route to where the configuration subcontext points to.\"\"\"\n        return ConfigRoute(list(self.trace_route()))\n\n    @overload\n    def enter(self: BaseContext[ConfigModelT], part: None) -> BaseContext[ConfigModelT]:\n        ...\n\n    @overload\n    def enter(self, part: str) -> Subcontext[ConfigModelT]:\n        ...\n\n    def enter(\n        self, part: str | None\n    ) -> Subcontext[ConfigModelT] | BaseContext[ConfigModelT]:\n        \"\"\"\n        Enter a subcontext.\n\n        Parameters\n        ----------\n        part\n            The name of the item nested in the item this context points to.\n\n        Returns\n        -------\n        The new subcontext.\n        \"\"\"\n        if part is None:\n            return self\n        return Subcontext(self, part, self.interpolation_namespace.setdefault(part, {}))\n\n    @property\n    @abc.abstractmethod\n    def agent(self) -> ConfigAgent[ConfigModelT]:\n        \"\"\"The configuration agent responsible for loading and saving.\"\"\"\n\n    @property\n    @abc.abstractmethod\n    def toplevel_interpolation_namespace(self) -> dict[str, Any]:\n        \"\"\"Top-level interpolation namespace.\"\"\"\n\n    @property\n    @abc.abstractmethod\n    def owner(self) -> ConfigModelT | None:\n        \"\"\"\n        The top-level configuration model instance,\n        holding all adjacent contexts.\n        \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def at(self) -> ConfigModelT | ConfigAt[ConfigModelT] | None:\n        \"\"\"\n        The configuration model instance or the configuration item\n        this context points to.\n        \"\"\"", "\n\nclass Context(BaseContext[ConfigModelT], Generic[ConfigModelT]):\n    \"\"\"\n    The context of a configuration model.\n\n    Parameters\n    ----------\n    agent\n        The configuration resource agent.\n    owner\n        The top-level configuration model instance,\n        holding all belonging subcontexts.\n    \"\"\"\n\n    _initial_state: dict[str, Any]\n\n    def __init__(\n        self,\n        agent: ConfigAgent[ConfigModelT],\n        owner: ConfigModelT | None = None,\n    ) -> None:\n        self._initial_state = {}\n        self._owner = None\n        self._agent = agent\n        self.interpolation_namespace = {}\n        self.owner = owner\n\n    def trace_route(self) -> Iterator[str]:\n        yield from ()\n\n    @property\n    def agent(self) -> ConfigAgent[ConfigModelT]:\n        return self._agent\n\n    @property\n    def toplevel_interpolation_namespace(self) -> dict[str, Any]:\n        return self.interpolation_namespace\n\n    @property\n    def at(self) -> ConfigModelT | None:\n        return self.owner\n\n    @property\n    def owner(self) -> ConfigModelT | None:\n        return self._owner\n\n    @owner.setter\n    def owner(self, config: ConfigModelT | None) -> None:\n        if config is None:\n            return\n        self._owner = config\n\n    @property\n    def initial_state(self) -> dict[str, Any]:\n        return copy.deepcopy(self._initial_state)\n\n    @initial_state.setter\n    def initial_state(self, initial_state: dict[str, Any]) -> None:\n        self._initial_state = copy.deepcopy(initial_state)\n\n    def __repr__(self) -> str:\n        agent = self.agent\n        return (\n            f\"<{type(self).__name__} \"\n            f\"of {type(self.owner).__name__!r} configuration \"\n            f\"({agent=})>\"\n        )", "\n\nclass Subcontext(BaseContext[ConfigModelT], Generic[ConfigModelT]):\n    \"\"\"\n    The subcontext of a configuration model.\n\n    Parameters\n    ----------\n    parent\n        The parent context.\n    part\n        The name of the item nested in the item the parent context points to.\n    \"\"\"\n\n    __slots__ = (\"_parent\", \"_part\", \"_interpolation_namespace\")\n\n    def __init__(\n        self,\n        parent: BaseContext[ConfigModelT],\n        part: str,\n        interpolation_namespace: dict[str, Any],\n    ) -> None:\n        self._parent = parent\n        self._part = part\n        self.interpolation_namespace = interpolation_namespace\n\n    @property\n    def agent(self) -> ConfigAgent[ConfigModelT]:\n        return self._parent.agent\n\n    @property\n    def toplevel_interpolation_namespace(self) -> dict[str, Any]:\n        return self._parent.toplevel_interpolation_namespace\n\n    def trace_route(self) -> Iterator[str]:\n        yield from self._parent.trace_route()\n        yield self._part\n\n    @property\n    def at(self) -> ConfigAt[ConfigModelT]:\n        if self.owner is None:\n            msg = \"Cannot get at() of a model without parent model\"\n            raise ValueError(msg)\n        return ConfigAt(self.owner, None, self.route)\n\n    @property\n    def owner(self) -> ConfigModelT | None:\n        return self._parent.owner\n\n    @property\n    def initial_state(self) -> dict[str, Any]:\n        return self._parent.initial_state\n\n    @initial_state.setter\n    def initial_state(self, value: dict[str, Any]) -> None:\n        data = self._parent.initial_state\n        data[self._part] = copy.deepcopy(value)\n        self._parent.initial_state = data\n\n    def __repr__(self) -> str:\n        agent = self.agent\n        route = self.route\n        return (\n            f\"<{type(self).__name__} \"\n            f\"of {type(self.owner).__name__ + '.' + str(route)!r} configuration \"\n            f\"({agent=})>\"\n        )", "\n\ndef get_context(config: ConfigModelT) -> BaseContext[ConfigModelT]:\n    \"\"\"\n    Get the context of the configuration model.\n\n    Parameters\n    ----------\n    config\n        The configuration model instance.\n\n    Returns\n    -------\n    The context of the configuration model.\n    \"\"\"\n    context = get_context_or_none(config)\n    if context is None:\n        raise RuntimeError(\n            \"This model is either inside a list \"\n            \"or was not loaded by a configuration agent.\"\n        )\n    return context", "\n\ndef get_context_or_none(config: ConfigModelT) -> BaseContext[ConfigModelT] | None:\n    \"\"\"\n    Get the context of the configuration model safely.\n\n    Parameters\n    ----------\n    config\n        The configuration model instance.\n\n    Returns\n    -------\n    The context of the configuration model.\n    \"\"\"\n    return cast(\n        Optional[BaseContext[ConfigModelT]], getattr(config, LOCAL).get(current_context)\n    )", "\n\n# noinspection PyUnusedLocal\n@make_generic_validator\ndef _common_field_validator(\n    cls: type[ConfigModelT],\n    v: Any,\n    values: dict[str, Any],\n    field: pydantic.fields.ModelField,\n    config: pydantic.BaseConfig,\n) -> Any:\n    post_hook_value = field_hook(field.outer_type_, v)\n    disallow_interpolation = getattr(config, \"disallow_interpolation\", False)\n    disallowed_interpolation_fields = set()\n\n    interpolation_tracker = current_interpolation_tracker.get()\n\n    if interpolation_tracker is None:\n        interpolation_tracker = {}\n        current_interpolation_tracker.set(interpolation_tracker)\n\n    if not isinstance(disallow_interpolation, bool):\n        disallowed_interpolation_fields = set(disallow_interpolation)\n    if (\n        field.field_info.extra.get(\"interpolate\", True)\n        and field.alias not in disallowed_interpolation_fields\n    ):\n        old_value = post_hook_value\n        try:\n            interpolated = interpolate(\n                post_hook_value,\n                cls,\n                values.copy(),\n                field.outer_type_,\n            )\n        except InterpolationError as err:\n            err.message += f\" (encountered in {cls.__qualname__}.{field.alias})\"\n            raise\n\n        new_value = field_hook(field.outer_type_, interpolated)\n        if old_value != new_value:\n            interpolation_tracker[field.alias] = (old_value, copy.copy(new_value))\n        post_hook_value = new_value\n\n    return post_hook_value", "\n\ndef _json_encoder(model_encoder: Callable[..., Any], value: Any, **kwargs: Any) -> Any:\n    initial_state_type = type(value)\n    converted_value = export_hook(value)\n    if isinstance(converted_value, initial_state_type):\n        return model_encoder(value, **kwargs)\n    return converted_value\n\n\nclass ConfigModelMetaclass(ModelMetaclass):\n    def __new__(\n        cls,\n        name: str,\n        bases: tuple[type, ...],\n        namespace: dict[str, Any],\n        **kwargs: Any,\n    ) -> type:\n        namespace |= dict.fromkeys(\n            (EXPORT, CONTEXT, LOCAL, TOKEN, MODULE), pydantic.PrivateAttr()\n        ) | {INTERPOLATION_TRACKER: pydantic.PrivateAttr(default_factory=dict)}\n\n        if namespace.get(INTERPOLATION_INCLUSIONS) is None:\n            namespace[INTERPOLATION_INCLUSIONS] = {}\n\n        if namespace.get(INTERPOLATOR) is None:\n            namespace[INTERPOLATOR] = BaseInterpolator()\n\n        if namespace.get(EVALUATION_ENGINE) is None:\n            namespace[EVALUATION_ENGINE] = BaseEvaluationEngine()\n\n        if kwargs.pop(\"root\", None):\n            return type.__new__(cls, name, bases, namespace, **kwargs)\n\n        model = super().__new__(cls, name, bases, namespace, **kwargs)\n        for field in model.__fields__.values():\n            if field.pre_validators is None:\n                field.pre_validators = []\n            field.pre_validators[:] = [_common_field_validator, *field.pre_validators]\n            if type(field.outer_type_) is ConfigModelMetaclass:\n                validator = make_generic_validator(\n                    field.outer_type_.__field_setup__  # type: ignore[attr-defined]\n                )\n                field.pre_validators[:] = [\n                    _common_field_validator,\n                    validator,\n                    *field.pre_validators,\n                ]\n        model_encoder = model.__json_encoder__\n        model.__json_encoder__ = functools.partial(_json_encoder, model_encoder)\n        return cast(type, model)", "\n\nclass ConfigModelMetaclass(ModelMetaclass):\n    def __new__(\n        cls,\n        name: str,\n        bases: tuple[type, ...],\n        namespace: dict[str, Any],\n        **kwargs: Any,\n    ) -> type:\n        namespace |= dict.fromkeys(\n            (EXPORT, CONTEXT, LOCAL, TOKEN, MODULE), pydantic.PrivateAttr()\n        ) | {INTERPOLATION_TRACKER: pydantic.PrivateAttr(default_factory=dict)}\n\n        if namespace.get(INTERPOLATION_INCLUSIONS) is None:\n            namespace[INTERPOLATION_INCLUSIONS] = {}\n\n        if namespace.get(INTERPOLATOR) is None:\n            namespace[INTERPOLATOR] = BaseInterpolator()\n\n        if namespace.get(EVALUATION_ENGINE) is None:\n            namespace[EVALUATION_ENGINE] = BaseEvaluationEngine()\n\n        if kwargs.pop(\"root\", None):\n            return type.__new__(cls, name, bases, namespace, **kwargs)\n\n        model = super().__new__(cls, name, bases, namespace, **kwargs)\n        for field in model.__fields__.values():\n            if field.pre_validators is None:\n                field.pre_validators = []\n            field.pre_validators[:] = [_common_field_validator, *field.pre_validators]\n            if type(field.outer_type_) is ConfigModelMetaclass:\n                validator = make_generic_validator(\n                    field.outer_type_.__field_setup__  # type: ignore[attr-defined]\n                )\n                field.pre_validators[:] = [\n                    _common_field_validator,\n                    validator,\n                    *field.pre_validators,\n                ]\n        model_encoder = model.__json_encoder__\n        model.__json_encoder__ = functools.partial(_json_encoder, model_encoder)\n        return cast(type, model)", "\n\nclass ConfigMeta(pydantic.BaseSettings.Config):\n    \"\"\"\n    Meta-configuration for configuration models.\n\n    See https://docs.pydantic.dev/latest/usage/model_config/ for more information\n    on model configurations.\n\n    Attributes\n    ----------\n    resource\n        The configuration resource to read from/write to.\n\n        If a string, it will be interpreted as a path to a file.\n\n    parser_name\n        The anyconfig parser to use.\n\n    autoupdate_forward_refs\n        Whether to automatically update forward references\n        when `ConfigModel.load()` or `ConfigModel.load_async()`\n        methods are called. For convenience, defaults to `True`.\n\n    And all other attributes from `pydantic.BaseSettings.Config`.\n    \"\"\"\n\n    resource: ConfigAgent[ConfigModel] | RawResourceT | None = None\n    parser_name: str | None = None\n    validate_assignment: bool = True\n    autoupdate_forward_refs: bool = True\n\n    Extra = pydantic.Extra", "\n\nclass ConfigModel(\n    pydantic.BaseSettings,\n    metaclass=ConfigModelMetaclass,\n    root=True,\n):\n    \"\"\"The base class for configuration models.\"\"\"\n\n    __config__ = ConfigMeta\n\n    module_wrapper_class: ClassVar[type[ConfigModule[ConfigModel]]] = ConfigModule\n\n    def __init__(self, **kwargs: Any) -> None:\n        # Set private attributes via the constructor\n        # to allow preprocessor-related instances to exist.\n        for private_attr in self.__private_attributes__:\n            value = kwargs.pop(private_attr, Undefined)\n            if value is not Undefined:\n                if private_attr == CONTEXT:\n                    context = current_context.get()\n                    if context:\n                        value = context\n                    current_context.set(value)\n                object.__setattr__(self, private_attr, value)\n        super().__init__(**kwargs)\n\n    def __deepcopy__(\n        self: ConfigModelT, memodict: dict[Any, Any] | None = None\n    ) -> ConfigModelT:\n        state = dict(self._iter(to_dict=False))\n        state.pop(LOCAL, None)\n        state.pop(TOKEN, None)\n        clone = copy.deepcopy(state)\n        return type(self).parse_obj(\n            {\n                field.alias: clone[field_name]\n                for field_name, field in self.__fields__.items()\n            }\n        )\n\n    def __setattr__(self, key: str, value: Any) -> None:\n        getattr(self, LOCAL).run(super().__setattr__, key, value)\n\n    def _init_private_attributes(self) -> None:\n        super()._init_private_attributes()\n        local = contextvars.copy_context()\n        object.__setattr__(self, LOCAL, local)\n        tok = getattr(self, TOKEN, None)\n        if tok:\n            context = current_context.get()\n            if context is not None:\n                context.interpolation_namespace |= self.dict()\n            current_context.reset(tok)\n\n    def export(self, **kwargs: Any) -> dict[str, Any]:\n        \"\"\"\n        Export the configuration model.\n\n        Returns\n        -------\n        The exported configuration model.\n        \"\"\"\n        _exporting.set(True)  # noqa: FBT003\n        return detached_context_run(self.dict, **kwargs)\n\n    async def export_async(self, **kwargs: Any) -> dict[str, Any]:\n        \"\"\"\n        Export the configuration model.\n\n        Returns\n        -------\n        The exported configuration model.\n        \"\"\"\n        _exporting.set(True)  # noqa: FBT003\n        return await detached_context_await(self.dict_async, **kwargs)\n\n    async def dict_async(self, **kwargs: Any) -> dict[str, Any]:\n        \"\"\"\n        Get the dictionary representation of the configuration model.\n\n        Returns\n        -------\n        The dictionary representation of the configuration model.\n        \"\"\"\n        return dict(await self._iter_async(to_dict=True, **kwargs))\n\n    # noinspection PyShadowingNames\n    async def json_async(  # noqa: PLR0913\n        self,\n        include: IncludeExcludeT = None,\n        exclude: IncludeExcludeT = None,\n        *,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        encoder: Callable[[Any], Any] | None = None,\n        models_as_dict: bool = True,\n        **dumps_kwargs: Any,\n    ) -> str:\n        encoder = cast(Callable[[Any], Any], encoder or self.__json_encoder__)\n        data = dict(\n            await self._iter_async(\n                to_dict=models_as_dict,\n                by_alias=by_alias,\n                include=include,\n                exclude=exclude,\n                exclude_unset=exclude_unset,\n                exclude_defaults=exclude_defaults,\n                exclude_none=exclude_none,\n            )\n        )\n        if self.__custom_root_type__:\n            data = data[ROOT_KEY]\n        return self.__config__.json_dumps(data, default=encoder, **dumps_kwargs)\n\n    def _iter(  # type: ignore[override]\n        self, **kwargs: Any\n    ) -> Iterator[tuple[str, Any]]:\n        if kwargs.get(\"to_dict\", False) and _exporting.get():\n            state: dict[str, Any] = {}\n            for key, value in super()._iter(**kwargs):\n                state |= [self._export_iter_hook(key, value)]\n            metadata = getattr(self, EXPORT, None)\n            if metadata:\n                context = get_context(self)\n                context.agent.processor_class.export(state, metadata=metadata)\n            yield from state.items()\n        else:\n            yield from super()._iter(**kwargs)\n\n    async def _iter_async(self, **kwargs: Any) -> Iterator[tuple[str, Any]]:\n        if kwargs.get(\"to_dict\", False) and _exporting.get():\n            state: dict[str, Any] = {}\n            for key, value in super()._iter(**kwargs):\n                state |= [self._export_iter_hook(key, value)]\n            metadata = getattr(self, EXPORT, None)\n            if metadata:\n                context = get_context(self)\n                await context.agent.processor_class.export_async(\n                    state, metadata=metadata\n                )\n            return ((key, value) for key, value in state.items())\n        return super()._iter(**kwargs)\n\n    def _export_iter_hook(\n        self,\n        key: str,\n        value: Any,\n    ) -> tuple[str, Any]:\n        interpolation_tracker = getattr(self, LOCAL).get(current_interpolation_tracker)\n        field = self.__fields__.get(key)\n        actual_key = field.alias if field else key\n        if interpolation_tracker:\n            interpolation_track = interpolation_tracker.get(actual_key)\n            if interpolation_track:\n                old_value, new_value = interpolation_track\n                # if value != new_value:\n                #     raise InterpolationError(\n                #         f\"Cannot restore the value of {actual_key!r} \"\n                #         \"before interpolation.\"\n                #     )\n                value = old_value\n        return actual_key, value\n\n    @classmethod\n    @no_type_check\n    def _get_value(cls, value: Any, *, to_dict: bool, **kwds: Any) -> Any:\n        if _exporting.get():\n            exporter = export_model.dispatch(type(value))\n            if (\n                isinstance(value, BaseModel)\n                or exporter != export_model.dispatch(object)\n            ) and to_dict:\n                value_dict = export_model(value, **kwds)\n                if ROOT_KEY in value_dict:\n                    return value_dict[ROOT_KEY]\n                return value_dict\n        return super()._get_value(value, to_dict=to_dict, **kwds)\n\n    @classmethod\n    def _resolve_agent(\n        cls,\n        resource: ConfigAgent[ConfigModelT] | RawResourceT | None = None,\n        *,\n        create_if_missing: bool | None = None,\n        parser_name: str | None = None,\n    ) -> ConfigAgent[ConfigModelT]:\n        if resource is None:\n            resource = getattr(cls.__config__, \"resource\", None)\n        if resource is None:\n            raise ValueError(\"No resource specified\")\n        if parser_name is None:\n            parser_name = getattr(cls.__config__, \"parser_name\", None)\n        agent: ConfigAgent[ConfigModelT]\n        if isinstance(resource, ConfigAgent):\n            agent = resource\n        else:\n            agent = ConfigAgent(\n                resource,\n                parser_name=parser_name,\n            )\n        if create_if_missing is not None:\n            agent.create_if_missing = create_if_missing\n        if parser_name is not None:\n            agent.parser_name = cast(str, parser_name)\n        return agent\n\n    @property\n    def initial_state(self) -> dict[str, Any]:\n        \"\"\"\n        The initial configuration state.\n\n        It is a copy of the configuration state\n        at the last time of loading, reloading or saving.\n        \"\"\"\n        return get_context(self).initial_state\n\n    def at(\n        self: ConfigModelT,\n        route: ConfigRouteLike | None = None,\n    ) -> ConfigModelT | ConfigAt[ConfigModelT]:\n        \"\"\"\n        Lazily point to a specific item in the configuration.\n\n        Parameters\n        ----------\n        route\n            The access route to the item in this configuration.\n            If None, the whole configuration is returned.\n\n        Returns\n        -------\n        The configuration accessor.\n        \"\"\"\n        if route is None:\n            context = get_context_or_none(self)\n            self_at = None\n            if context is not None:\n                self_at = context.at\n            if self_at is not None:\n                return self_at\n            return self\n        return ConfigAt(self, None, route)\n\n    @overload\n    def get(self: ConfigModelT, route: None = None, default: Any = ...) -> ConfigModelT:\n        ...\n\n    @overload\n    def get(self, route: ConfigRouteLike = ..., default: Any = ...) -> Any:\n        ...\n\n    def get(\n        self, route: ConfigRouteLike | None = None, default: Any = Undefined\n    ) -> Any:\n        \"\"\"\n        Get a value from the configuration.\n\n        Parameters\n        ----------\n        route\n            Route to access the item. If None, the whole configuration is returned.\n        default\n        \"\"\"\n        if route is None:\n            return self\n        return self.at(route).get(default=default)\n\n    def update(self, kwargs: dict[str, Any]) -> None:\n        \"\"\"\n        Update the configuration with new values, in-place.\n\n        Parameters\n        ----------\n        kwargs\n            The new values to update the configuration with.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        # Crucial difference to self.__dict__.update():\n        # self.__dict__.update() would not trigger the validation\n        # of the new values.\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n    def rollback(self) -> None:\n        \"\"\"\n        Rollback the configuration to its initial state.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        context = get_context(self)\n        self.__dict__.update(context.initial_state)\n\n    @classmethod\n    def load(\n        cls: type[ConfigModelT],\n        resource: ConfigAgent[ConfigModelT] | RawResourceT | None = None,\n        *,\n        create_if_missing: bool | None = None,\n        parser_name: str | None = None,\n        **kwargs: Any,\n    ) -> ConfigModelT:\n        \"\"\"\n        Load the configuration file.\n        To reload the configuration, use the `reload()` method.\n\n        Parameters\n        ----------\n        resource\n            The configuration resource to read from/write to.\n        parser_name\n            The anyconfig parser to use.\n        create_if_missing\n            Whether to create the configuration file if it does not exist.\n        **kwargs\n            Keyword arguments to pass to the read method.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        agent = cls._resolve_agent(\n            resource,\n            parser_name=parser_name,\n            create_if_missing=create_if_missing,\n        )\n        current_context.set(Context(agent))\n        local = contextvars.copy_context()\n        if getattr(\n            cls.__config__,\n            \"autoupdate_forward_refs\",\n            ConfigMeta.autoupdate_forward_refs,\n        ):\n            cls.update_forward_refs()\n        config = local.run(agent.read, config_class=cls, **kwargs)\n        object.__setattr__(config, LOCAL, local)\n        context = cast(Context[ConfigModelT], local.get(current_context))\n        context.owner = config\n        context.initial_state = config.__dict__\n        return config\n\n    @classmethod\n    async def load_async(\n        cls: type[ConfigModelT],\n        resource: ConfigAgent[ConfigModelT] | RawResourceT | None = None,\n        *,\n        parser_name: str | None = None,\n        create_if_missing: bool | None = None,\n        **kwargs: Any,\n    ) -> ConfigModelT:\n        \"\"\"\n        Load the configuration file asynchronously.\n        To reload the configuration, use the `reload_async()` method.\n\n        Parameters\n        ----------\n        resource\n            The configuration resource.\n        parser_name\n            The anyconfig parser to use.\n        create_if_missing\n            Whether to create the configuration file if it does not exist.\n        **kwargs\n            Keyword arguments to pass to the read method.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        agent = cls._resolve_agent(\n            resource, create_if_missing=create_if_missing, parser_name=parser_name\n        )\n        current_context.set(Context(agent))\n        local = contextvars.copy_context()\n        if getattr(\n            cls.__config__,\n            \"autoupdate_forward_refs\",\n            ConfigMeta.autoupdate_forward_refs,\n        ):\n            cls.update_forward_refs()\n        reader = local.run(\n            asyncio.create_task, agent.read_async(config_class=cls, **kwargs)\n        )\n        config = await reader\n        object.__setattr__(config, LOCAL, local)\n        context = cast(Context[ConfigModelT], local.get(current_context))\n        context.owner = config\n        return config\n\n    def reload(self: ConfigModelT, **kwargs: Any) -> ConfigModelT:\n        \"\"\"\n        Reload the configuration file.\n\n        Parameters\n        ----------\n        **kwargs\n            Keyword arguments to pass to the read method.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        try:\n            context = get_context(self)\n        except RuntimeError:\n            wrapped_module = getattr(self, MODULE, None)\n            if wrapped_module is None:\n                raise\n            importlib.reload(wrapped_module)\n            self.update(\n                {\n                    key: value\n                    for key, value in vars(wrapped_module).items()\n                    if key in {field.alias for field in self.__fields__.values()}\n                }\n            )\n            return self\n        current_context.set(get_context(context.owner))\n        if context.owner is self:\n            changed = context.agent.read(config_class=type(self), **kwargs)\n        else:\n            changed = _partial_reload(cast(ConfigModelT, context.at), **kwargs)\n        state = changed.__dict__\n        context.initial_state = state\n        self.update(state)\n        return self\n\n    async def reload_async(self: ConfigModelT, **kwargs: Any) -> ConfigModelT:\n        \"\"\"\n        Reload the configuration file asynchronously.\n\n        Parameters\n        ----------\n        **kwargs\n            Keyword arguments to pass to the read method.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        context = get_context(self)\n        current_context.set(get_context(context.owner))\n        if context.owner is self:\n            changed = await context.agent.read_async(config_class=type(self), **kwargs)\n        else:\n            changed = await _partial_reload_async(\n                cast(ConfigAt[ConfigModelT], context.at), **kwargs\n            )\n        state = changed.__dict__\n        context.initial_state = state\n        self.update(state)\n        return self\n\n    def save(\n        self: ConfigModelT, write_kwargs: dict[str, Any] | None = None, **kwargs: Any\n    ) -> int:\n        \"\"\"\n        Save the configuration to the configuration file.\n\n        Parameters\n        ----------\n        write_kwargs\n            Keyword arguments to pass to the write method.\n        **kwargs\n            Keyword arguments to pass to the dumping method.\n\n        Returns\n        -------\n        The number of bytes written.\n        \"\"\"\n        context = get_context(self)\n        if context.owner is self:\n            if write_kwargs is None:\n                write_kwargs = {}\n            blob = context.agent.dump_config(self, **kwargs)\n            result = self.write(blob, **write_kwargs)\n            context.initial_state = self.__dict__\n            return result\n        return _partial_save(\n            cast(ConfigAt[ConfigModelT], context.at),\n            write_kwargs=write_kwargs,\n            **kwargs,\n        )\n\n    async def save_async(\n        self: ConfigModelT, write_kwargs: dict[str, Any] | None = None, **kwargs: Any\n    ) -> int:\n        \"\"\"\n        Save the configuration to the configuration file asynchronously.\n\n        Parameters\n        ----------\n        write_kwargs\n            Keyword arguments to pass to the write method.\n        **kwargs\n            Keyword arguments to pass to the dumping method.\n\n        Returns\n        -------\n        The number of bytes written.\n        \"\"\"\n        context = get_context(self)\n        if context.owner is self:\n            if write_kwargs is None:\n                write_kwargs = {}\n            _exporting.set(True)  # noqa: FBT003\n            blob = await context.agent.dump_config_async(self, **kwargs)\n            result = await self.write_async(blob, **write_kwargs)\n            context.initial_state = self.__dict__\n            return result\n        return await _partial_save_async(\n            cast(ConfigAt[ConfigModelT], context.at),\n            write_kwargs=write_kwargs,\n            **kwargs,\n        )\n\n    def write(self, blob: str | bytes, **kwargs: Any) -> int:\n        \"\"\"\n        Overwrite the configuration file with the given string or bytes.\n\n        Parameters\n        ----------\n        blob\n            The blob to write to the configuration file.\n        **kwargs\n            Keyword arguments to pass to the open method.\n\n        Returns\n        -------\n        The number of bytes written.\n        \"\"\"\n        context = get_context(self)\n        if context.agent.is_url:\n            msg = \"Writing to URLs is not yet supported\"\n            raise NotImplementedError(msg)\n        return context.agent.write(blob, **kwargs)\n\n    async def write_async(self, blob: str | bytes, **kwargs: Any) -> int:\n        \"\"\"\n        Overwrite the configuration file asynchronously with the given string or bytes.\n\n        Parameters\n        ----------\n        blob\n            The blob to write to the configuration file.\n        **kwargs\n            Keyword arguments to pass to the open method.\n\n        Returns\n        -------\n        The number of bytes written.\n        \"\"\"\n        context = get_context(self)\n        if context.agent.is_url:\n            msg = \"Saving to URLs is not yet supported\"\n            raise NotImplementedError(msg)\n        return await context.agent.write_async(blob, **kwargs)\n\n    @classmethod\n    def _evaluate_interpolation_namespaces(cls) -> dict[str | None, dict[str, Any]]:\n        inclusions = getattr(cls, INTERPOLATION_INCLUSIONS)\n        return {\n            namespace_id: evaluate_namespace()\n            for namespace_id, evaluate_namespace in inclusions.items()\n        }\n\n    @classmethod\n    def _evaluate_interpolation_expression(\n        cls,\n        expression: str,\n        *,\n        result_namespace: dict[str, Any],\n        namespaces: dict[str | None, dict[str, Any]],\n        closest_namespace: dict[str, Any],\n        target_type: type[Any],\n    ) -> Any:\n        evaluation_engine: BaseEvaluationEngine = getattr(cls, EVALUATION_ENGINE)\n        return evaluation_engine.evaluate_expression(\n            expression=expression,\n            result_namespace=result_namespace,\n            namespaces=namespaces,\n            closest_namespace=closest_namespace,\n            target_type=target_type,\n        )\n\n    @classmethod\n    def wrap_module(\n        cls: type[ConfigModelT],\n        module_name: str | types.ModuleType,\n        package: str | None = None,\n        /,\n        **values: Any,\n    ) -> ConfigModelT:\n        module_vars = None\n        if isinstance(module_name, str):\n            module_name = module_name\n            if module_name not in sys.modules:\n                if package is None and module_name.startswith(\".\"):\n                    current_frame = inspect.currentframe()\n                    assert current_frame is not None\n                    frame_back = current_frame.f_back\n                    assert frame_back is not None\n                    package = frame_back.f_globals[\"__package__\"]\n                module_vars = vars(\n                    importlib.import_module(module_name, package=package)\n                )\n        else:\n            module_name = module_name.__name__\n        config_module = cls.module_wrapper_class.wrap_module(\n            module_name, cls, module_vars, **values\n        )\n        return cast(ConfigModelT, config_module.get_model())\n\n    @classmethod\n    def wrap_this_module(\n        cls: type[ConfigModelT],\n        **values: Any,\n    ) -> ConfigModelT:\n        current_frame = inspect.currentframe()\n        assert current_frame is not None\n        frame_back = current_frame.f_back\n        assert frame_back is not None\n        return cls.wrap_module(frame_back.f_globals[\"__name__\"], **values)\n\n    @classmethod\n    def get_interpolation_namespace(\n        cls,\n        expressions: set[str],\n        closest_namespace: dict[str, Any],\n        target_type: type[Any],\n    ) -> dict[str, Any]:\n        \"\"\"Get the interpolation namespace according to occuring expressions.\"\"\"\n        context = current_context.get()\n        result_namespace: dict[str, Any] = {}\n\n        namespaces = cls._evaluate_interpolation_namespaces()\n        if context is not None:\n            namespaces.setdefault(None, {}).update(\n                context.toplevel_interpolation_namespace\n            )\n\n        for expression in expressions:\n            value = cls._evaluate_interpolation_expression(\n                expression=expression,\n                result_namespace=result_namespace,\n                namespaces=namespaces,\n                closest_namespace=closest_namespace,\n                target_type=target_type,\n            )\n            result_namespace[expression] = value\n\n        return result_namespace\n\n    @classmethod\n    def __field_setup__(cls, value: dict[str, Any], field: ModelField) -> Any:\n        \"\"\"\n        Called when this configuration model is being initialized as a field\n        of some other configuration model.\n        \"\"\"\n        context = current_context.get()\n        if context is not None:\n            subcontext = context.enter(field.name)\n            tok = current_context.set(subcontext)\n            return _get_object_state(value) | {\n                TOKEN: tok,\n                LOCAL: contextvars.copy_context(),\n            }\n        return value\n\n    if not TYPE_CHECKING:\n        load = detached_context_function(load)\n        load_async = detached_context_function(load_async)\n        reload = detached_context_function(reload)\n        reload_async = detached_context_function(reload_async)\n        save = detached_context_function(save)\n        save_async = detached_context_function(save_async)\n        export = detached_context_function(export)\n        export_async = detached_context_function(export_async)", "\n\nsetattr(ConfigModel, INTERPOLATION_INCLUSIONS, None)\ninclude.register(ConfigModel, include_const)\n\nif os.getenv(\"CONFIGZEN_SETUP\") != \"0\":\n    importlib.import_module(\"._setup\", package=__package__)\n"]}
{"filename": "configzen/typedefs.py", "chunked_list": ["import contextlib\nimport os\nimport pathlib\nimport sys\nfrom collections.abc import Mapping, Set\nfrom typing import TYPE_CHECKING, Any, Optional, TextIO, TypeVar, Union\n\nif sys.version_info >= (3, 10):\n    from typing import ParamSpec, TypeAlias\nelse:\n    from typing_extensions import ParamSpec, TypeAlias", "\nif TYPE_CHECKING:\n    from aiofiles.base import AiofilesContextManager\n    from aiofiles.threadpool.text import AsyncTextIOWrapper\n\n    # noinspection PyUnresolvedReferences\n    from configzen.model import ConfigModel\n    from configzen.route import ConfigRoute\n\nT = TypeVar(\"T\")", "\nT = TypeVar(\"T\")\nP = ParamSpec(\"P\")\n\nConfigModelT = TypeVar(\"ConfigModelT\", bound=\"ConfigModel\")\nConfigRouteLike: TypeAlias = Union[str, list[str], \"ConfigRoute\"]\n\nConfigIO: TypeAlias = contextlib.AbstractContextManager[TextIO]\nAsyncConfigIO: TypeAlias = \"AiofilesContextManager[None, None, AsyncTextIOWrapper]\"\nRawResourceT: TypeAlias = Union[ConfigIO, str, int, os.PathLike, pathlib.Path]", "AsyncConfigIO: TypeAlias = \"AiofilesContextManager[None, None, AsyncTextIOWrapper]\"\nRawResourceT: TypeAlias = Union[ConfigIO, str, int, os.PathLike, pathlib.Path]\nNormalizedResourceT: TypeAlias = Union[ConfigIO, str, int, pathlib.Path]\nIncludeExcludeT: TypeAlias = Optional[\n    Union[\n        Set[Union[int, str]],\n        Mapping[Union[int, str], Any],\n    ]\n]\n", "]\n"]}
{"filename": "configzen/__main__.py", "chunked_list": ["import argparse\n\nfrom configzen import ConfigMeta, ConfigModel\nfrom configzen.model import get_context\n\n\nclass Store(ConfigModel):\n    class Config(ConfigMeta):\n        extra = ConfigMeta.Extra.allow\n", "\n\nif __name__ == \"__main__\":\n    p = argparse.ArgumentParser()\n    p.add_argument(\"--source\", help=\"file to load from\")\n    p.add_argument(\"dest\", help=\"file to save into\")\n    p.add_argument(\"--async\", dest=\"use_async\", action=\"store_true\", help=\"use async\")\n\n    opt = p.parse_args()\n\n    if opt.use_async:\n        import asyncio\n\n        store = asyncio.run(Store.load_async(opt.source))\n        print(store)\n        context = get_context(store)\n        context.agent.resource = opt.dest\n        asyncio.run(store.save_async())\n    else:\n        store = Store.load(opt.source)\n        print(store)\n        context = get_context(store)\n        context.agent.resource = opt.dest\n        store.save()", ""]}
{"filename": "configzen/errors.py", "chunked_list": ["\"\"\"This module contains all the custom errors raised by _configzen_.\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nfrom collections.abc import Iterator\nfrom typing import TYPE_CHECKING, Any\n\nif TYPE_CHECKING:\n    from configzen.model import ConfigAgent\n    from configzen.typedefs import ConfigModelT", "if TYPE_CHECKING:\n    from configzen.model import ConfigAgent\n    from configzen.typedefs import ConfigModelT\n\n\nclass ConfigError(Exception):\n    \"\"\"An error occurred while loading a configuration.\"\"\"\n\n    def __init__(self, message: str) -> None:\n        self._message = message\n        super().__init__(message)\n\n    @property\n    def message(self) -> str:\n        \"\"\"The error message.\"\"\"\n        return self._message\n\n    @message.setter\n    def message(self, value: str) -> None:\n        self._message = value\n        super().__init__(self.message)", "\n\nclass InterpolationError(ConfigError):\n    \"\"\"An error occurred with regard to interpolating a configuration.\"\"\"\n\n\nclass InterpolationLookupError(ConfigError, LookupError):\n    \"\"\"An error occurred with regard to interpolating a configuration.\"\"\"\n\n    def __init__(self, message: str) -> None:\n        super().__init__(repr(message))", "\n\nclass IncorrectConfigError(ConfigError):\n    \"\"\"An error occurred while loading a configuration.\"\"\"\n\n\nclass InternalSyntaxError(ConfigError):\n    \"\"\"Syntax error in a _configzen_ component.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        index: Any = None,\n        prefix: str = \"\",\n        suffix: str = \"\",\n    ) -> None:\n        super().__init__(message)\n        self.index = index\n        self.prefix = prefix\n        self.suffix = suffix", "\n\nclass ConfigSyntaxError(ConfigError):\n    \"\"\"An error occurred while parsing arguments.\"\"\"\n\n\n@contextlib.contextmanager\ndef formatted_syntax_error(\n    source: str, error_cls: type[ConfigSyntaxError] = ConfigSyntaxError\n) -> Iterator[None]:\n    \"\"\"Raise a SyntaxError with a message and a source.\"\"\"\n    try:\n        yield\n    except InternalSyntaxError as exc:\n        idx = len(exc.prefix) + exc.index + 1\n        charlist = [\" \"] * len(exc.prefix + repr(source) + exc.suffix)\n        charlist[idx] = \"^\"\n        indicator = \"\".join(charlist)\n        msg = \"\\n\".join(\n            map(str, (exc, exc.prefix + repr(source) + exc.suffix, indicator))\n        )\n        raise error_cls(msg) from None", "\n\nclass UnspecifiedParserError(ConfigError):\n    \"\"\"Could not determine the parser to use.\"\"\"\n\n\nclass UnavailableParserError(ConfigError):\n    MISSING_DEPENDENCIES: dict[str, str] = {\n        \"yaml\": \"pyyaml (or ruamel.yaml)\",\n        \"toml\": \"toml\",\n        \"ion\": \"anyconfig-ion-backend\",\n        \"bson\": \"anyconfig-bson-backend\",\n        \"msgpack\": \"anyconfig-msgpack-backend\",\n        \"cbor\": \"anyconfig-cbor2-backend (or anyconfig-cbor-backend)\",\n        \"configobj\": \"anyconfig-configobj-backend\",\n    }\n\n    def __init__(self, parser_name: str, agent: ConfigAgent[ConfigModelT]) -> None:\n        missing_dependency: str = self.MISSING_DEPENDENCIES.get(\n            parser_name, f\"<the proper anyconfig backend for {parser_name!r} files>\"\n        )\n        super().__init__(\n            f\"The {parser_name!r} parser required to load configuration \"\n            f\"for agent {agent} is not available.\\n\"\n            f\"Install it with `pip install {missing_dependency}`.\"\n        )", "\n\nclass ConfigAccessError(ConfigError, LookupError):\n    \"\"\"An error occurred while accessing configuration part.\"\"\"\n\n    def __init__(self, config: ConfigModelT, route: str | list[str]) -> None:\n        if not isinstance(route, str):\n            route = \".\".join(route)\n        self.route = route\n        super().__init__(\n            f\"Could not access {type(config).__name__}.{route}\",\n        )", "\n\nclass ConfigProcessorError(ConfigError):\n    \"\"\"An error occurred while preprocessing/exporting a configuration.\"\"\"\n\n\nclass ResourceLookupError(ConfigError, LookupError):\n    \"\"\"An error occurred while looking up a resource.\"\"\"\n\n    def __init__(\n        self, resource: ConfigAgent[ConfigModelT] | None, route: list[str]\n    ) -> None:\n        resource_name = resource.resource if resource else \"the provided resource\"\n        self.route = route\n        super().__init__(f\"{route} not found in {resource_name}\")", "\n\nclass ConfigPreprocessingError(ConfigProcessorError, ValueError):\n    \"\"\"An error occurred while preprocessing a configuration value.\"\"\"\n"]}
{"filename": "configzen/field.py", "chunked_list": ["from typing import Any\n\nfrom pydantic.fields import Field, Undefined\n\n__all__ = (\"ConfigField\",)\n\n\n# noinspection PyPep8Naming\ndef ConfigField(default: Any = Undefined, **kwargs: Any) -> Any:  # noqa: N802\n    # Since configzen involves BaseSettings implicitly,\n    # this would be very convenient to have.\n    alias = kwargs.get(\"alias\")\n    env = kwargs.get(\"env\")\n    if alias is not None and env is None:\n        kwargs[\"env\"] = alias\n    return Field(default, **kwargs)", "def ConfigField(default: Any = Undefined, **kwargs: Any) -> Any:  # noqa: N802\n    # Since configzen involves BaseSettings implicitly,\n    # this would be very convenient to have.\n    alias = kwargs.get(\"alias\")\n    env = kwargs.get(\"env\")\n    if alias is not None and env is None:\n        kwargs[\"env\"] = alias\n    return Field(default, **kwargs)\n", ""]}
{"filename": "configzen/_setup.py", "chunked_list": ["\"\"\"\nConvenience hooks for quicker workflow with _configzen_.\n\nFor advanced use cases, you can prevent this module from executing\nby setting the environment variable ``CONFIGZEN_SETUP`` to ``0``.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport ast", "\nimport ast\nimport ipaddress\nimport pathlib\nfrom collections.abc import Mapping\nfrom typing import TYPE_CHECKING, Any\n\nfrom pydantic.json import ENCODERS_BY_TYPE\n\nfrom configzen.model import ConfigModel, export_hook, field_hook", "\nfrom configzen.model import ConfigModel, export_hook, field_hook\n\nif TYPE_CHECKING:\n    from configzen.typedefs import ConfigModelT\n\nfor obj_type, obj_encoder in ENCODERS_BY_TYPE.items():\n    export_hook.register(obj_type, obj_encoder)\n\n", "\n\n@export_hook.register(pathlib.WindowsPath)\n@export_hook.register(pathlib.PureWindowsPath)\ndef _export_windows_path(obj: pathlib.WindowsPath | pathlib.PureWindowsPath) -> str:\n    \"\"\"\n    This hook makes non-absolute paths in configurations cross-platform.\n\n    Parameters\n    ----------\n    obj\n        The path to convert.\n\n    Returns\n    -------\n    The converted path.\n    \"\"\"\n    return obj.as_posix()", "\n\n@export_hook.register(list)\ndef _export_list(obj: list[Any]) -> list[Any]:\n    return [export_hook(item) for item in obj]\n\n\n@export_hook.register(Mapping)\ndef _export_mapping(obj: Mapping[Any, Any]) -> dict[Any, Any]:\n    return {k: export_hook(v) for k, v in obj.items()}", "def _export_mapping(obj: Mapping[Any, Any]) -> dict[Any, Any]:\n    return {k: export_hook(v) for k, v in obj.items()}\n\n\n@field_hook.register(dict)\n@field_hook.register(list)\n@field_hook.register(set)\n@field_hook.register(tuple)\ndef _eval_literals(cls: type[Any], value: Any) -> Any:\n    \"\"\"\n    Load a value using literal evaluation.\n    Solves nested dictionaries problem in INI files.\n\n    Parameters\n    ----------\n    cls\n        The type to load the value into.\n\n    value\n        The value to load.\n\n    Returns\n    -------\n    The loaded value.\n    \"\"\"\n    if isinstance(value, str):\n        try:\n            data = ast.literal_eval(value)\n        except (SyntaxError, ValueError):\n            # There might be some following validator, let it be like that\n            return value\n        else:\n            return cls(data)\n    return value", "def _eval_literals(cls: type[Any], value: Any) -> Any:\n    \"\"\"\n    Load a value using literal evaluation.\n    Solves nested dictionaries problem in INI files.\n\n    Parameters\n    ----------\n    cls\n        The type to load the value into.\n\n    value\n        The value to load.\n\n    Returns\n    -------\n    The loaded value.\n    \"\"\"\n    if isinstance(value, str):\n        try:\n            data = ast.literal_eval(value)\n        except (SyntaxError, ValueError):\n            # There might be some following validator, let it be like that\n            return value\n        else:\n            return cls(data)\n    return value", "\n\n@field_hook.register(ipaddress.IPv4Address)\n@field_hook.register(ipaddress.IPv6Address)\ndef _eval_ipaddress(\n    cls: type[ipaddress.IPv4Address | ipaddress.IPv6Address], value: Any\n) -> ipaddress.IPv4Address | ipaddress.IPv6Address | Any:\n    if isinstance(value, str) and value.casefold() == \"localhost\":\n        if issubclass(cls, ipaddress.IPv6Address):\n            return cls(\"::1\")\n        return cls(\"127.0.0.1\")\n    return value", "\n\n@field_hook.register(ConfigModel)\ndef _eval_model(cls: type[ConfigModelT], value: Any) -> ConfigModelT | Any:\n    \"\"\"\n    Load a model using dict literal evaluation.\n    Solves nested dictionaries problem in INI files.\n\n    Parameters\n    ----------\n    cls\n        The type to load the value into.\n\n    value\n        The value to load.\n\n    Returns\n    -------\n    The loaded value.\n    \"\"\"\n    data = value\n    if isinstance(value, str):\n        try:\n            data = ast.literal_eval(value)\n        except (SyntaxError, ValueError):\n            # Note: Strings resembling models is probably not intended\n            # to be used with automatic pickle/JSON parsing.\n            # return cls.parse_raw(value)\n            return data\n        else:\n            return cls.parse_obj(data)\n    return data", ""]}
{"filename": "configzen/processor.py", "chunked_list": ["from __future__ import annotations\n\nimport asyncio\nimport copy\nimport dataclasses\nimport enum\nimport pathlib\nfrom collections.abc import Callable\nfrom typing import TYPE_CHECKING, Any, ClassVar, Generic, TypedDict, TypeVar, cast\n", "from typing import TYPE_CHECKING, Any, ClassVar, Generic, TypedDict, TypeVar, cast\n\nfrom anyconfig.utils import is_dict_like, is_list_like\nfrom pydantic.fields import Undefined\n\nfrom configzen.errors import ConfigPreprocessingError\nfrom configzen.typedefs import ConfigModelT, ConfigRouteLike\n\nif TYPE_CHECKING:\n    from configzen.model import BaseContext, ConfigAgent", "if TYPE_CHECKING:\n    from configzen.model import BaseContext, ConfigAgent\n\n__all__ = (\n    \"DirectiveContext\",\n    \"directive\",\n    \"Processor\",\n)\n\nDirectiveT = TypeVar(\"DirectiveT\")", "\nDirectiveT = TypeVar(\"DirectiveT\")\n\nEXPORT: str = \"__configzen_export__\"\nEXECUTES_DIRECTIVES: str = \"__configzen_executes_directives__\"\nEXECUTES_DIRECTIVES_ASYNC: str = \"__configzen_executes_directives_async__\"\n\n\ndef directive(\n    name: str | enum.Enum,\n    *,\n    asynchronous: bool | None = None,\n) -> Callable[..., Any]:\n    \"\"\"\n    Decorator for creating processor directives.\n\n    Parameters\n    ----------\n    name\n        The name of the directive.\n    asynchronous\n        Whether the decorated directive function is asynchronous.\n\n    Returns\n    -------\n    The decorated function.\n    \"\"\"\n    if isinstance(name, enum.Enum):\n        name = name.value.casefold()\n\n    def decorator(func: Any) -> Any:\n        nonlocal asynchronous\n        if asynchronous is None:\n            asynchronous = asyncio.iscoroutinefunction(func)\n        attr = EXECUTES_DIRECTIVES_ASYNC if asynchronous else EXECUTES_DIRECTIVES\n        if not hasattr(func, attr):\n            setattr(func, attr, set())\n        getattr(func, attr).add(name)\n        return func\n\n    return decorator", "def directive(\n    name: str | enum.Enum,\n    *,\n    asynchronous: bool | None = None,\n) -> Callable[..., Any]:\n    \"\"\"\n    Decorator for creating processor directives.\n\n    Parameters\n    ----------\n    name\n        The name of the directive.\n    asynchronous\n        Whether the decorated directive function is asynchronous.\n\n    Returns\n    -------\n    The decorated function.\n    \"\"\"\n    if isinstance(name, enum.Enum):\n        name = name.value.casefold()\n\n    def decorator(func: Any) -> Any:\n        nonlocal asynchronous\n        if asynchronous is None:\n            asynchronous = asyncio.iscoroutinefunction(func)\n        attr = EXECUTES_DIRECTIVES_ASYNC if asynchronous else EXECUTES_DIRECTIVES\n        if not hasattr(func, attr):\n            setattr(func, attr, set())\n        getattr(func, attr).add(name)\n        return func\n\n    return decorator", "\n\n@dataclasses.dataclass\nclass DirectiveContext:\n    \"\"\"\n    Context for processor directives.\n\n    Attributes\n    ----------\n    directive\n        The directive.\n    key\n        The key of the directive.\n    prefix\n        The prefix of the directive.\n    snippet\n        The config snippet where this directive was invoked.\n    container\n        The dictionary that contains the :attr:`dict`.\n\n    \"\"\"\n\n    directive: str\n    key: str\n    prefix: str\n    snippet: dict[str, Any]\n    container: dict[str, Any]", "\n\ndef parse_directive_call(\n    prefix: str,\n    directive_name: str,\n) -> str:\n    if directive_name.startswith(prefix):\n        directive_name = directive_name[len(prefix) :].casefold()\n\n        if not directive_name.isidentifier():\n            msg = f\"Invalid directive name: {directive_name}\"\n            raise ConfigPreprocessingError(msg)\n\n    return directive_name", "\n\nif TYPE_CHECKING:\n\n    class ExportMetadata(TypedDict, Generic[ConfigModelT]):\n        route: str | None\n        context: BaseContext[ConfigModelT]\n        key_order: list[str]\n        preprocess: bool\n\nelse:\n\n    class ExportMetadata(TypedDict):\n        \"\"\"\n        Metadata for exporting.\n\n        Attributes\n        ----------\n        route\n            The route to import from.\n        context\n            The context attached to the import.\n        \"\"\"\n\n        route: str | None\n        context: BaseContext[ConfigModelT]\n        key_order: list[str]\n        preprocess: bool", "\n\nclass BaseProcessor(Generic[ConfigModelT]):\n    \"\"\"\n    Processor that executes directives.\n\n    Attributes\n    ----------\n    dict_config\n        The dictionary config to parse and update.\n    directive_prefix\n        The prefix for directives.\n    \"\"\"\n\n    _directive_handlers: dict[str, Any] = None  # type: ignore[assignment]\n    _async_directive_handlers: dict[str, Any] = None  # type: ignore[assignment]\n    directive_prefix: ClassVar[str]\n    extension_prefix: ClassVar[str]\n\n    def __init__(\n        self,\n        agent: ConfigAgent[ConfigModelT],\n        dict_config: dict[str, Any],\n    ) -> None:\n        self.agent = agent\n        self.dict_config = dict_config\n\n    @classmethod\n    def export(\n        cls,\n        state: Any,\n        *,\n        metadata: ExportMetadata[ConfigModelT] | None = None,\n    ) -> None:\n        \"\"\"\n        Export the state.\n\n        Parameters\n        ----------\n        state\n            The state to export.\n        metadata\n            The metadata of the substitution.\n        \"\"\"\n        if is_dict_like(state):\n            if metadata is None:\n                from configzen.model import CONTEXT\n\n                state.pop(CONTEXT, None)\n                metadata = state.pop(EXPORT, None)\n            if metadata:\n                cls._export(state, metadata)\n            else:\n                cls.export(list(state.values()))\n        elif is_list_like(state):\n            for item in state:\n                cls.export(item)\n\n    @classmethod\n    async def export_async(\n        cls,\n        state: Any,\n        *,\n        metadata: ExportMetadata[ConfigModelT] | None = None,\n    ) -> None:\n        \"\"\"\n        Export the state asynchronously.\n\n        Parameters\n        ----------\n        state\n            The state to export.\n        metadata\n            The metadata of the substitution.\n        \"\"\"\n        if is_dict_like(state):\n            if metadata is None:\n                from configzen.model import CONTEXT\n\n                state.pop(CONTEXT, None)\n                metadata = state.pop(EXPORT, None)\n            if metadata:\n                await cls._export_async(state, metadata)\n            else:\n                await cls.export_async(list(state.values()))\n        elif is_list_like(state):\n            for item in state:\n                await cls.export_async(item)\n\n    @classmethod\n    def _export(\n        cls,\n        state: Any,\n        metadata: ExportMetadata[ConfigModelT],\n    ) -> None:\n        raise NotImplementedError\n\n    @classmethod\n    async def _export_async(\n        cls,\n        state: Any,\n        metadata: ExportMetadata[ConfigModelT],\n    ) -> None:\n        raise NotImplementedError\n\n    async def preprocess_async(self) -> dict[str, Any]:\n        \"\"\"\n        Parse the dictionary config and return the parsed config,\n        ready for instantiating the model.\n\n        Returns\n        -------\n        The parsed config.\n        \"\"\"\n        return cast(dict[str, Any], await self._preprocess_async(self.dict_config))\n\n    def preprocess(self) -> dict[str, Any]:\n        \"\"\"\n        Parse the dictionary config and return the parsed config,\n        ready for instantiating the model.\n\n        Returns\n        -------\n        The parsed config.\n        \"\"\"\n        return cast(dict[str, Any], self._preprocess(self.dict_config))\n\n    def _preprocess(self, container: Any) -> Any:\n        if not is_dict_like(container):\n            if is_list_like(container):\n                return [self._preprocess(v) for v in container]\n            return container\n\n        result: dict[str, Any] = {}\n\n        for key, value in sorted(\n            cast(dict[str, Any], container).items(),\n            key=lambda item: item[0] == self.directive_prefix,\n        ):\n            if key.startswith(self.extension_prefix):\n                actual_key = key.lstrip(self.extension_prefix)\n                overridden = result.get(actual_key, {})\n                if not is_dict_like(overridden):\n                    raise ConfigPreprocessingError(\n                        f\"{self.extension_prefix} can be used only for overriding \"\n                        f\"dictionary sections but item at {actual_key!r} \"\n                        f\"is not a dictionary\"\n                    )\n                replacement = overridden | value\n                result[actual_key] = self._preprocess(replacement)\n            elif key.startswith(self.directive_prefix):\n                directive_name = parse_directive_call(self.directive_prefix, key)\n                context_container = container.copy()\n                del context_container[key]\n                context = DirectiveContext(\n                    directive=directive_name,\n                    key=key,\n                    prefix=self.directive_prefix,\n                    snippet=value,\n                    container=context_container,\n                )\n                self._call_directive(context)\n                new_container = self._preprocess(context.container)\n                result |= new_container\n            else:\n                result[key] = self._preprocess(value)\n        return result\n\n    async def _preprocess_async(self, container: Any) -> Any:\n        if not is_dict_like(container):\n            if is_list_like(container):\n                return [await self._preprocess_async(v) for v in container]\n            return container\n\n        result: dict[str, Any] = {}\n\n        for key, value in sorted(\n            cast(dict[str, Any], container).items(),\n            key=lambda item: item[0] == self.directive_prefix,\n        ):\n            if key.startswith(self.extension_prefix):\n                actual_key = key.lstrip(self.extension_prefix)\n                overridden = result.get(actual_key, {})\n                if not is_dict_like(overridden):\n                    raise ConfigPreprocessingError(\n                        f\"{self.extension_prefix} can be used only for overriding \"\n                        f\"dictionary sections but item at {actual_key!r} \"\n                        f\"is not a dictionary\"\n                    )\n                replacement = overridden | value\n                result[actual_key] = await self._preprocess_async(replacement)\n            elif key.startswith(self.directive_prefix):\n                directive_name = parse_directive_call(self.directive_prefix, key)\n                context_container = container.copy()\n                del context_container[key]\n                context = DirectiveContext(\n                    directive=directive_name,\n                    key=key,\n                    prefix=self.directive_prefix,\n                    snippet=value,\n                    container=context_container,\n                )\n                await self._call_directive_async(context)\n                new_container = await self._preprocess_async(context.container)\n                result |= new_container\n            else:\n                result[key] = await self._preprocess_async(value)\n        return result\n\n    def _call_directive(self, context: DirectiveContext) -> None:\n        handler = self._directive_handlers.get(context.directive)\n        if handler is None:\n            raise ConfigPreprocessingError(\n                f\"unknown preprocessing directive: {context.directive!r}\"\n            )\n        handler(self, context)\n\n    async def _call_directive_async(self, context: DirectiveContext) -> None:\n        handler = self._async_directive_handlers.get(context.directive)\n        if handler is None:\n            raise ConfigPreprocessingError(\n                f\"unknown preprocessing directive: {context.directive!r}\"\n            )\n        await handler(self, context)\n\n    def __init_subclass__(cls, **kwargs: Any) -> None:\n        super().__init_subclass__(**kwargs)\n        if cls._directive_handlers is None:\n            cls._directive_handlers = {}\n        else:\n            cls._directive_handlers = cls._directive_handlers.copy()\n        if cls._async_directive_handlers is None:\n            cls._async_directive_handlers = {}\n        else:\n            cls._async_directive_handlers = cls._async_directive_handlers.copy()\n        for _name, func in cls.__dict__.items():\n            if hasattr(func, EXECUTES_DIRECTIVES):\n                for directive_name in getattr(func, EXECUTES_DIRECTIVES):\n                    cls._directive_handlers[directive_name] = func\n            elif hasattr(func, EXECUTES_DIRECTIVES_ASYNC):\n                for directive_name in getattr(func, EXECUTES_DIRECTIVES_ASYNC):\n                    cls._async_directive_handlers[directive_name] = func\n\n    @classmethod\n    def register_directive(cls, name: str, func: Any) -> None:\n        if cls._directive_handlers is None:\n            cls._directive_handlers = {}\n        cls._directive_handlers[name] = func\n\n    @classmethod\n    def directive(cls, directive_name: str) -> str:\n        \"\"\"\n        Create a directive call.\n\n        Parameters\n        ----------\n        directive_name\n            The name of the directive.\n\n        Returns\n        -------\n        The directive call.\n        \"\"\"\n        if isinstance(directive_name, enum.Enum):\n            directive_name = directive_name.value\n\n        return cls.directive_prefix + directive_name", "\n\nclass Directives(str, enum.Enum):\n    EXTEND = \"extend\"\n    INCLUDE = \"include\"\n    COPY = \"copy\"\n\n\nclass Processor(BaseProcessor[ConfigModelT]):\n    directive_prefix = \"^\"\n    extension_prefix = \"+\"\n    route_separator: ClassVar[str] = \":\"\n\n    @directive(Directives.EXTEND)\n    def extend(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Extend a configuration with another configuration.\n        Recursively preprocess the referenced configuration.\n        Preserve information about the referenced configuration.\n\n        Visual example\n        --------------\n\n        With `base.yaml` containing:\n        ```yaml\n        section:\n          foo: 1\n          bar: 2\n        ```\n\n        and `config.yaml` containing:\n\n        ```yaml\n        ^extend: base.yaml\n        +section:\n          foo: 3\n        ```\n\n        -> `load()` -> `save()` ->\n\n        ```yaml\n        ^extend: base.yaml\n        +section:\n          foo: 3\n        ```\n        \"\"\"\n        self._substitute(ctx, preprocess=True, preserve=True)\n\n    @directive(Directives.INCLUDE)\n    def include(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Include a configuration in another configuration.\n        Recursively preprocess the referenced configuration.\n        Do not preserve information about the referenced configuration.\n\n        Visual example\n        --------------\n        With `biz.yaml` containing:\n\n        ```yaml\n        section:\n          biz: 3\n        ```\n\n        and `base.yaml` containing:\n\n        ```yaml\n        ^extend: biz.yaml\n        +section:\n          foo: 1\n          bar: 2\n        ```\n\n        and `config.yaml` containing:\n\n        ```yaml\n        ^include: base.yaml\n        +section:\n          foo: 3\n        ```\n\n        -> `load()` -> `save()` ->\n\n        ```yaml\n        ^extend: biz.yaml\n        +section:\n          bar: 2\n          foo: 3\n        ```\n        \"\"\"\n        self._substitute(ctx, preprocess=True, preserve=False)\n\n    @directive(Directives.COPY)\n    def copy(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Copy a configuration and paste into another configuration.\n        This is just a literal copy-paste.\n        Do not preprocess the referenced configuration.\n        Do not preserve information about the referenced configuration.\n\n        Visual example\n        --------------\n        With `base.yaml` containing:\n\n        ```yaml\n        section:\n          foo: 1\n          bar: 2\n        ```\n\n        and `config.yaml` containing:\n\n        ```yaml\n        ^copy: base.yaml\n        +section:\n          foo: 3\n        ```\n\n        -> `load()` -> `save()` ->\n\n        ```yaml\n        section:\n          foo: 3\n          bar: 2\n        ```\n        \"\"\"\n        self._substitute(ctx, preprocess=False, preserve=False)\n\n    @directive(Directives.EXTEND)\n    async def extend_async(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Extend a configuration with another configuration asynchronously.\n        For more information see `extend`.\n        \"\"\"\n        await self._substitute_async(ctx, preprocess=True, preserve=True)\n\n    @directive(Directives.INCLUDE)\n    async def include_async(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Include a configuration in another configuration asynchronously.\n        For more information see `include`.\n        \"\"\"\n        await self._substitute_async(ctx, preprocess=True, preserve=False)\n\n    @directive(Directives.COPY)\n    async def copy_async(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Copy a configuration and paste into another configuration asynchronously.\n        For more information see `copy`.\n        \"\"\"\n        await self._substitute_async(ctx, preprocess=False, preserve=False)\n\n    def _get_substitution_means(\n        self, ctx: DirectiveContext  # , *, preserve: bool\n    ) -> tuple[\n        ConfigAgent[ConfigModelT], ConfigAgent[ConfigModelT], ConfigRouteLike | None\n    ]:\n        agent_class = type(self.agent)\n\n        # todo(bswck): raise on include and extend combined\n        # if preserve and ???:\n        #     msg = (\n        #         \"Using more than one ??? directive \"\n        #         \"in the same scope is not allowed\"\n        #     )\n        #     raise ConfigPreprocessingError(msg)\n\n        agent, route = agent_class.from_directive_context(\n            ctx, route_separator=self.route_separator\n        )\n\n        if agent.resource == self.agent.resource:\n            raise ConfigPreprocessingError(\n                f\"{agent.resource} tried to {ctx.directive!r} on itself\"\n            )\n\n        actual_agent = agent\n        if agent.is_relative:\n            parent = cast(pathlib.Path, self.agent.resource).parent\n            child = cast(pathlib.Path, agent.resource)\n\n            actual_agent = copy.copy(agent)\n            actual_agent.resource = parent / child\n\n        return actual_agent, agent, route\n\n    def _substitute(\n        self, ctx: DirectiveContext, *, preprocess: bool, preserve: bool\n    ) -> None:\n        agent, orig_agent, route = self._get_substitution_means(ctx)\n\n        with agent.processor_open_resource() as reader:\n            source = orig_agent.load_dict(reader.read(), preprocess=preprocess)\n\n        self._substitute_impl(\n            ctx,\n            route,\n            source=source,\n            agent=orig_agent,\n            preprocess=preprocess,\n            preserve=preserve,\n        )\n\n    async def _substitute_async(\n        self, ctx: DirectiveContext, *, preprocess: bool, preserve: bool\n    ) -> None:\n        agent, orig_agent, route = self._get_substitution_means(ctx)\n\n        async with agent.processor_open_resource_async() as reader:\n            source = orig_agent.load_dict(await reader.read(), preprocess=preprocess)\n\n        self._substitute_impl(\n            ctx,\n            route,\n            source=source,\n            agent=orig_agent,\n            preprocess=preprocess,\n            preserve=preserve,\n        )\n\n    @staticmethod\n    def _substitute_impl(  # noqa: PLR0913\n        ctx: DirectiveContext,\n        route: ConfigRouteLike | None,\n        *,\n        source: dict[str, Any],\n        agent: ConfigAgent[ConfigModelT],\n        preprocess: bool,\n        preserve: bool,\n    ) -> None:\n        from configzen.model import CONTEXT, Context, at\n\n        if route:\n            source = at(source, route, agent=agent)\n            if not is_dict_like(source):\n                raise ConfigPreprocessingError(\n                    f\"imported item {route!r} \"\n                    f\"from {agent.resource} is not a dictionary\"\n                )\n\n        context: Context[ConfigModelT] = Context(agent)\n        ctx.container = source | ctx.container\n\n        if preserve:\n            ctx.container |= {\n                CONTEXT: context,\n                EXPORT: ExportMetadata(\n                    route=str(route),\n                    context=context,\n                    preprocess=preprocess,\n                    key_order=list(ctx.container),\n                ),\n            }\n\n    @classmethod\n    def _export(  # noqa: C901\n        cls,\n        state: dict[str, Any],\n        metadata: ExportMetadata[ConfigModelT],\n    ) -> None:\n        \"\"\"\n        Exports model state preserving substition directive calls in the model state.\n\n        Parameters\n        ----------\n        metadata\n        state\n        \"\"\"\n        from configzen.model import CONTEXT, at, export_hook\n\n        overrides = {}\n\n        route = metadata[\"route\"]\n        context = metadata[\"context\"]\n        key_order = metadata[\"key_order\"]\n        agent = context.agent\n\n        with agent.processor_open_resource() as reader:\n            # Here we intentionally always preprocess the loaded configuration.\n            loaded = agent.load_dict(reader.read())\n\n            if route:\n                loaded = at(loaded, route, agent=agent)\n\n        substituted_values = loaded.copy()\n\n        for key, value in loaded.items():\n            counterpart_value = state.pop(key, Undefined)\n            if counterpart_value is Undefined:\n                continue\n            counterpart_value = export_hook(counterpart_value)\n\n            if is_dict_like(value):\n                if EXPORT in value:\n                    value.pop(CONTEXT, None)\n                    cls.export(value, metadata=value.pop(EXPORT))\n                overrides_for_key = {\n                    sub_key: comp\n                    for sub_key, comp in counterpart_value.items()\n                    if (\n                        (orig := value.get(sub_key, Undefined)) is Undefined\n                        or orig != comp\n                    )\n                }\n                if overrides_for_key:\n                    export_key = agent.processor_class.extension_prefix + key\n                    overrides[export_key] = overrides_for_key\n\n            elif is_list_like(value):\n                cls.export(value)\n                if value != counterpart_value:\n                    overrides[key] = counterpart_value\n\n            elif value != counterpart_value:\n                overrides[key] = counterpart_value\n                del substituted_values[key]\n\n        for value in state.values():\n            cls.export(value)\n\n        cls._export_finalize(\n            context=context,\n            state=state,\n            overrides=overrides,\n            values=substituted_values,\n            route=route,\n            key_order=key_order,\n        )\n\n    @classmethod\n    async def _export_async(  # noqa: C901\n        cls,\n        state: dict[str, Any],\n        metadata: ExportMetadata[ConfigModelT],\n    ) -> None:\n        \"\"\"\n        Exports model state preserving substition directive calls in the model state.\n\n        Parameters\n        ----------\n        metadata\n        state\n        \"\"\"\n        from configzen.model import CONTEXT, at, export_hook\n\n        overrides = {}\n\n        route = metadata[\"route\"]\n        context = metadata[\"context\"]\n        key_order = metadata[\"key_order\"]\n        agent = context.agent\n\n        async with agent.processor_open_resource_async() as reader:\n            # Here we intentionally always preprocess the loaded configuration.\n            loaded = await agent.load_dict_async(await reader.read())\n\n            if route:\n                loaded = at(loaded, route, agent=agent)\n\n        substituted_values = loaded.copy()\n\n        for key, value in loaded.items():\n            counterpart_value = state.pop(key, Undefined)\n            if counterpart_value is Undefined:\n                continue\n            counterpart_value = export_hook(counterpart_value)\n\n            if is_dict_like(value):\n                if EXPORT in value:\n                    value.pop(CONTEXT, None)\n                    await cls.export_async(value, metadata=value.pop(EXPORT))\n                overrides_for_key = {\n                    sub_key: comp\n                    for sub_key, comp in counterpart_value.items()\n                    if (\n                        (orig := value.get(sub_key, Undefined)) is Undefined\n                        or orig != comp\n                    )\n                }\n                if overrides_for_key:\n                    export_key = agent.processor_class.extension_prefix + key\n                    overrides[export_key] = overrides_for_key\n\n            elif is_list_like(value):\n                await cls.export_async(value)\n                if value != counterpart_value:\n                    overrides[key] = counterpart_value\n\n            elif counterpart_value != value:\n                overrides[key] = counterpart_value\n                del substituted_values[key]\n\n        for value in state.values():\n            await cls.export_async(value)\n\n        cls._export_finalize(\n            context=context,\n            state=state,\n            overrides=overrides,\n            values=substituted_values,\n            route=route,\n            key_order=key_order,\n        )\n\n    @classmethod\n    def _export_finalize(  # noqa: PLR0913\n        cls,\n        context: BaseContext[ConfigModelT],\n        *,\n        state: dict[str, Any],\n        overrides: dict[str, Any],\n        values: dict[str, Any],\n        route: str | None,\n        key_order: list[str],\n    ) -> None:\n        from configzen.model import export_hook\n\n        state |= overrides\n        extras: dict[str, Any] = {\n            key: state.pop(key) for key in set(state) if key not in key_order\n        }\n\n        if values:\n            substitution_directive = cls.directive(Directives.EXTEND)\n            resource = str(export_hook(context.agent.resource))\n            if route:\n                resource = cls.route_separator.join((resource, route))\n            # Put the substitution directive at the beginning of the state in-place.\n            state |= {substitution_directive: resource} | {\n                key: state.pop(key) for key in set(state)\n            }\n\n        # Preserve the order of keys in the original configuration.\n        for key in filter(state.__contains__, key_order):\n            state[key] = state.pop(key)\n\n        state |= extras", "class Processor(BaseProcessor[ConfigModelT]):\n    directive_prefix = \"^\"\n    extension_prefix = \"+\"\n    route_separator: ClassVar[str] = \":\"\n\n    @directive(Directives.EXTEND)\n    def extend(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Extend a configuration with another configuration.\n        Recursively preprocess the referenced configuration.\n        Preserve information about the referenced configuration.\n\n        Visual example\n        --------------\n\n        With `base.yaml` containing:\n        ```yaml\n        section:\n          foo: 1\n          bar: 2\n        ```\n\n        and `config.yaml` containing:\n\n        ```yaml\n        ^extend: base.yaml\n        +section:\n          foo: 3\n        ```\n\n        -> `load()` -> `save()` ->\n\n        ```yaml\n        ^extend: base.yaml\n        +section:\n          foo: 3\n        ```\n        \"\"\"\n        self._substitute(ctx, preprocess=True, preserve=True)\n\n    @directive(Directives.INCLUDE)\n    def include(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Include a configuration in another configuration.\n        Recursively preprocess the referenced configuration.\n        Do not preserve information about the referenced configuration.\n\n        Visual example\n        --------------\n        With `biz.yaml` containing:\n\n        ```yaml\n        section:\n          biz: 3\n        ```\n\n        and `base.yaml` containing:\n\n        ```yaml\n        ^extend: biz.yaml\n        +section:\n          foo: 1\n          bar: 2\n        ```\n\n        and `config.yaml` containing:\n\n        ```yaml\n        ^include: base.yaml\n        +section:\n          foo: 3\n        ```\n\n        -> `load()` -> `save()` ->\n\n        ```yaml\n        ^extend: biz.yaml\n        +section:\n          bar: 2\n          foo: 3\n        ```\n        \"\"\"\n        self._substitute(ctx, preprocess=True, preserve=False)\n\n    @directive(Directives.COPY)\n    def copy(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Copy a configuration and paste into another configuration.\n        This is just a literal copy-paste.\n        Do not preprocess the referenced configuration.\n        Do not preserve information about the referenced configuration.\n\n        Visual example\n        --------------\n        With `base.yaml` containing:\n\n        ```yaml\n        section:\n          foo: 1\n          bar: 2\n        ```\n\n        and `config.yaml` containing:\n\n        ```yaml\n        ^copy: base.yaml\n        +section:\n          foo: 3\n        ```\n\n        -> `load()` -> `save()` ->\n\n        ```yaml\n        section:\n          foo: 3\n          bar: 2\n        ```\n        \"\"\"\n        self._substitute(ctx, preprocess=False, preserve=False)\n\n    @directive(Directives.EXTEND)\n    async def extend_async(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Extend a configuration with another configuration asynchronously.\n        For more information see `extend`.\n        \"\"\"\n        await self._substitute_async(ctx, preprocess=True, preserve=True)\n\n    @directive(Directives.INCLUDE)\n    async def include_async(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Include a configuration in another configuration asynchronously.\n        For more information see `include`.\n        \"\"\"\n        await self._substitute_async(ctx, preprocess=True, preserve=False)\n\n    @directive(Directives.COPY)\n    async def copy_async(self, ctx: DirectiveContext) -> None:\n        \"\"\"\n        Copy a configuration and paste into another configuration asynchronously.\n        For more information see `copy`.\n        \"\"\"\n        await self._substitute_async(ctx, preprocess=False, preserve=False)\n\n    def _get_substitution_means(\n        self, ctx: DirectiveContext  # , *, preserve: bool\n    ) -> tuple[\n        ConfigAgent[ConfigModelT], ConfigAgent[ConfigModelT], ConfigRouteLike | None\n    ]:\n        agent_class = type(self.agent)\n\n        # todo(bswck): raise on include and extend combined\n        # if preserve and ???:\n        #     msg = (\n        #         \"Using more than one ??? directive \"\n        #         \"in the same scope is not allowed\"\n        #     )\n        #     raise ConfigPreprocessingError(msg)\n\n        agent, route = agent_class.from_directive_context(\n            ctx, route_separator=self.route_separator\n        )\n\n        if agent.resource == self.agent.resource:\n            raise ConfigPreprocessingError(\n                f\"{agent.resource} tried to {ctx.directive!r} on itself\"\n            )\n\n        actual_agent = agent\n        if agent.is_relative:\n            parent = cast(pathlib.Path, self.agent.resource).parent\n            child = cast(pathlib.Path, agent.resource)\n\n            actual_agent = copy.copy(agent)\n            actual_agent.resource = parent / child\n\n        return actual_agent, agent, route\n\n    def _substitute(\n        self, ctx: DirectiveContext, *, preprocess: bool, preserve: bool\n    ) -> None:\n        agent, orig_agent, route = self._get_substitution_means(ctx)\n\n        with agent.processor_open_resource() as reader:\n            source = orig_agent.load_dict(reader.read(), preprocess=preprocess)\n\n        self._substitute_impl(\n            ctx,\n            route,\n            source=source,\n            agent=orig_agent,\n            preprocess=preprocess,\n            preserve=preserve,\n        )\n\n    async def _substitute_async(\n        self, ctx: DirectiveContext, *, preprocess: bool, preserve: bool\n    ) -> None:\n        agent, orig_agent, route = self._get_substitution_means(ctx)\n\n        async with agent.processor_open_resource_async() as reader:\n            source = orig_agent.load_dict(await reader.read(), preprocess=preprocess)\n\n        self._substitute_impl(\n            ctx,\n            route,\n            source=source,\n            agent=orig_agent,\n            preprocess=preprocess,\n            preserve=preserve,\n        )\n\n    @staticmethod\n    def _substitute_impl(  # noqa: PLR0913\n        ctx: DirectiveContext,\n        route: ConfigRouteLike | None,\n        *,\n        source: dict[str, Any],\n        agent: ConfigAgent[ConfigModelT],\n        preprocess: bool,\n        preserve: bool,\n    ) -> None:\n        from configzen.model import CONTEXT, Context, at\n\n        if route:\n            source = at(source, route, agent=agent)\n            if not is_dict_like(source):\n                raise ConfigPreprocessingError(\n                    f\"imported item {route!r} \"\n                    f\"from {agent.resource} is not a dictionary\"\n                )\n\n        context: Context[ConfigModelT] = Context(agent)\n        ctx.container = source | ctx.container\n\n        if preserve:\n            ctx.container |= {\n                CONTEXT: context,\n                EXPORT: ExportMetadata(\n                    route=str(route),\n                    context=context,\n                    preprocess=preprocess,\n                    key_order=list(ctx.container),\n                ),\n            }\n\n    @classmethod\n    def _export(  # noqa: C901\n        cls,\n        state: dict[str, Any],\n        metadata: ExportMetadata[ConfigModelT],\n    ) -> None:\n        \"\"\"\n        Exports model state preserving substition directive calls in the model state.\n\n        Parameters\n        ----------\n        metadata\n        state\n        \"\"\"\n        from configzen.model import CONTEXT, at, export_hook\n\n        overrides = {}\n\n        route = metadata[\"route\"]\n        context = metadata[\"context\"]\n        key_order = metadata[\"key_order\"]\n        agent = context.agent\n\n        with agent.processor_open_resource() as reader:\n            # Here we intentionally always preprocess the loaded configuration.\n            loaded = agent.load_dict(reader.read())\n\n            if route:\n                loaded = at(loaded, route, agent=agent)\n\n        substituted_values = loaded.copy()\n\n        for key, value in loaded.items():\n            counterpart_value = state.pop(key, Undefined)\n            if counterpart_value is Undefined:\n                continue\n            counterpart_value = export_hook(counterpart_value)\n\n            if is_dict_like(value):\n                if EXPORT in value:\n                    value.pop(CONTEXT, None)\n                    cls.export(value, metadata=value.pop(EXPORT))\n                overrides_for_key = {\n                    sub_key: comp\n                    for sub_key, comp in counterpart_value.items()\n                    if (\n                        (orig := value.get(sub_key, Undefined)) is Undefined\n                        or orig != comp\n                    )\n                }\n                if overrides_for_key:\n                    export_key = agent.processor_class.extension_prefix + key\n                    overrides[export_key] = overrides_for_key\n\n            elif is_list_like(value):\n                cls.export(value)\n                if value != counterpart_value:\n                    overrides[key] = counterpart_value\n\n            elif value != counterpart_value:\n                overrides[key] = counterpart_value\n                del substituted_values[key]\n\n        for value in state.values():\n            cls.export(value)\n\n        cls._export_finalize(\n            context=context,\n            state=state,\n            overrides=overrides,\n            values=substituted_values,\n            route=route,\n            key_order=key_order,\n        )\n\n    @classmethod\n    async def _export_async(  # noqa: C901\n        cls,\n        state: dict[str, Any],\n        metadata: ExportMetadata[ConfigModelT],\n    ) -> None:\n        \"\"\"\n        Exports model state preserving substition directive calls in the model state.\n\n        Parameters\n        ----------\n        metadata\n        state\n        \"\"\"\n        from configzen.model import CONTEXT, at, export_hook\n\n        overrides = {}\n\n        route = metadata[\"route\"]\n        context = metadata[\"context\"]\n        key_order = metadata[\"key_order\"]\n        agent = context.agent\n\n        async with agent.processor_open_resource_async() as reader:\n            # Here we intentionally always preprocess the loaded configuration.\n            loaded = await agent.load_dict_async(await reader.read())\n\n            if route:\n                loaded = at(loaded, route, agent=agent)\n\n        substituted_values = loaded.copy()\n\n        for key, value in loaded.items():\n            counterpart_value = state.pop(key, Undefined)\n            if counterpart_value is Undefined:\n                continue\n            counterpart_value = export_hook(counterpart_value)\n\n            if is_dict_like(value):\n                if EXPORT in value:\n                    value.pop(CONTEXT, None)\n                    await cls.export_async(value, metadata=value.pop(EXPORT))\n                overrides_for_key = {\n                    sub_key: comp\n                    for sub_key, comp in counterpart_value.items()\n                    if (\n                        (orig := value.get(sub_key, Undefined)) is Undefined\n                        or orig != comp\n                    )\n                }\n                if overrides_for_key:\n                    export_key = agent.processor_class.extension_prefix + key\n                    overrides[export_key] = overrides_for_key\n\n            elif is_list_like(value):\n                await cls.export_async(value)\n                if value != counterpart_value:\n                    overrides[key] = counterpart_value\n\n            elif counterpart_value != value:\n                overrides[key] = counterpart_value\n                del substituted_values[key]\n\n        for value in state.values():\n            await cls.export_async(value)\n\n        cls._export_finalize(\n            context=context,\n            state=state,\n            overrides=overrides,\n            values=substituted_values,\n            route=route,\n            key_order=key_order,\n        )\n\n    @classmethod\n    def _export_finalize(  # noqa: PLR0913\n        cls,\n        context: BaseContext[ConfigModelT],\n        *,\n        state: dict[str, Any],\n        overrides: dict[str, Any],\n        values: dict[str, Any],\n        route: str | None,\n        key_order: list[str],\n    ) -> None:\n        from configzen.model import export_hook\n\n        state |= overrides\n        extras: dict[str, Any] = {\n            key: state.pop(key) for key in set(state) if key not in key_order\n        }\n\n        if values:\n            substitution_directive = cls.directive(Directives.EXTEND)\n            resource = str(export_hook(context.agent.resource))\n            if route:\n                resource = cls.route_separator.join((resource, route))\n            # Put the substitution directive at the beginning of the state in-place.\n            state |= {substitution_directive: resource} | {\n                key: state.pop(key) for key in set(state)\n            }\n\n        # Preserve the order of keys in the original configuration.\n        for key in filter(state.__contains__, key_order):\n            state[key] = state.pop(key)\n\n        state |= extras", ""]}
{"filename": "configzen/__init__.py", "chunked_list": ["# flake8: noqa\nfrom __future__ import annotations\n\nfrom pydantic import validator as field_validator\n\nfrom . import decorators, field, interpolation, model, module, processor, route\nfrom .decorators import *\nfrom .field import *\nfrom .interpolation import *\nfrom .model import *", "from .interpolation import *\nfrom .model import *\nfrom .module import *\nfrom .processor import *\nfrom .route import *\n\n__all__ = (\n    *model.__all__,\n    *field.__all__,\n    *interpolation.__all__,", "    *field.__all__,\n    *interpolation.__all__,\n    *processor.__all__,\n    *decorators.__all__,\n    *route.__all__,\n    *module.__all__,\n    \"field_validator\",\n)\n\ndel annotations", "\ndel annotations\n"]}
{"filename": "configzen/module.py", "chunked_list": ["from __future__ import annotations\n\nimport inspect\nimport sys\nimport types\nfrom typing import TYPE_CHECKING, Any, Generic, cast\n\nfrom configzen.typedefs import ConfigModelT\n\nif TYPE_CHECKING:\n    from configzen import ConfigModel", "\nif TYPE_CHECKING:\n    from configzen import ConfigModel\n\n__all__ = (\"ConfigModule\",)\n\nMODULE: str = \"__wrapped_module__\"\n\n\nclass ConfigModule(types.ModuleType, Generic[ConfigModelT]):\n    __model: ConfigModelT\n    __vars: dict[str, Any]\n\n    def __init__(\n        self,\n        name: str,\n        model: ConfigModelT,\n        module_vars: dict[str, Any] | None = None,\n        doc: str | None = None,\n    ) -> None:\n        object.__setattr__(self, f\"_{ConfigModule.__name__}__model\", model)\n        object.__setattr__(self, f\"_{ConfigModule.__name__}__vars\", module_vars)\n        object.__setattr__(model, MODULE, self)\n        super().__init__(name=name, doc=doc)\n        parts = name.split(\".\")\n\n        if len(parts) > 1:\n            # Set the proxy module as an attribute of its parent.\n            parent = sys.modules[\".\".join(parts[:-1])]\n            setattr(parent, parts[-1], self)\n\n        # Make reusable.\n        sys.modules[name] = self\n\n    def __getattribute__(self, name: str) -> Any:\n        if name.startswith(f\"_{ConfigModule.__name__}__\"):\n            return object.__getattribute__(self, name)\n\n        model = self.__model\n        try:\n            return getattr(model, name)\n        except AttributeError:\n            try:\n                return self.__vars[name]\n            except KeyError:\n                return object.__getattribute__(self, name)\n\n    def __setattr__(self, key: str, value: Any) -> None:\n        model = self.get_model()\n        if (\n            not key.startswith(f\"_{ConfigModule.__name__}__\")\n            and key in model.__fields__\n        ):\n            setattr(model, key, value)\n        self.__vars[key] = value\n\n    def __repr__(self) -> str:\n        return super().__repr__().replace(\"module\", \"configuration module\", 1)\n\n    def get_model(self) -> ConfigModelT:\n        return self.__model\n\n    @classmethod\n    def wrap_module(\n        cls,\n        module_name: str,\n        model_class: type[ConfigModelT] | None = None,\n        module_vars: dict[str, Any] | None = None,\n        /,\n        **values: Any,\n    ) -> ConfigModule[ConfigModelT]:\n        \"\"\"Wrap a Python module to interact with a config model.\"\"\"\n        from configzen.model import ConfigModel\n\n        if module_vars is None:\n            module_vars = vars(sys.modules[module_name])\n\n        if model_class is None:\n\n            class ModuleConfigModel(ConfigModel):\n                __module__ = module_name\n                __annotations__ = module_vars[\"__annotations__\"]  # type: ignore[index]\n                __ns = locals()\n                for key in __annotations__:\n                    __ns[key] = module_vars[key]  # type: ignore[index]\n                del __ns\n\n            model_class = cast(type[ConfigModelT], ModuleConfigModel)\n\n        module_values = {}\n        for key, value in module_vars.items():\n            if key in {field.alias for field in model_class.__fields__.values()}:\n                module_values[key] = value\n\n        config_module = cls(\n            model=cast(ConfigModelT, model_class).parse_obj(module_values | values),\n            module_vars=module_vars,\n            name=module_vars[\"__name__\"],\n            doc=module_vars[\"__doc__\"],\n        )\n        return config_module\n\n    @classmethod\n    def wrap_this_module(\n        cls,\n        model_class: type[ConfigModelT] | None = None,\n        /,\n        **values: Any,\n    ) -> ConfigModule[ConfigModelT]:\n        \"\"\"Wrap the current module to interact with a config model.\"\"\"\n        current_frame = inspect.currentframe()\n        assert current_frame is not None\n        frame_back = current_frame.f_back\n        assert frame_back is not None\n        return cls.wrap_module(\n            frame_back.f_globals[\"__name__\"],\n            model_class,\n            **values,\n        )", "\nclass ConfigModule(types.ModuleType, Generic[ConfigModelT]):\n    __model: ConfigModelT\n    __vars: dict[str, Any]\n\n    def __init__(\n        self,\n        name: str,\n        model: ConfigModelT,\n        module_vars: dict[str, Any] | None = None,\n        doc: str | None = None,\n    ) -> None:\n        object.__setattr__(self, f\"_{ConfigModule.__name__}__model\", model)\n        object.__setattr__(self, f\"_{ConfigModule.__name__}__vars\", module_vars)\n        object.__setattr__(model, MODULE, self)\n        super().__init__(name=name, doc=doc)\n        parts = name.split(\".\")\n\n        if len(parts) > 1:\n            # Set the proxy module as an attribute of its parent.\n            parent = sys.modules[\".\".join(parts[:-1])]\n            setattr(parent, parts[-1], self)\n\n        # Make reusable.\n        sys.modules[name] = self\n\n    def __getattribute__(self, name: str) -> Any:\n        if name.startswith(f\"_{ConfigModule.__name__}__\"):\n            return object.__getattribute__(self, name)\n\n        model = self.__model\n        try:\n            return getattr(model, name)\n        except AttributeError:\n            try:\n                return self.__vars[name]\n            except KeyError:\n                return object.__getattribute__(self, name)\n\n    def __setattr__(self, key: str, value: Any) -> None:\n        model = self.get_model()\n        if (\n            not key.startswith(f\"_{ConfigModule.__name__}__\")\n            and key in model.__fields__\n        ):\n            setattr(model, key, value)\n        self.__vars[key] = value\n\n    def __repr__(self) -> str:\n        return super().__repr__().replace(\"module\", \"configuration module\", 1)\n\n    def get_model(self) -> ConfigModelT:\n        return self.__model\n\n    @classmethod\n    def wrap_module(\n        cls,\n        module_name: str,\n        model_class: type[ConfigModelT] | None = None,\n        module_vars: dict[str, Any] | None = None,\n        /,\n        **values: Any,\n    ) -> ConfigModule[ConfigModelT]:\n        \"\"\"Wrap a Python module to interact with a config model.\"\"\"\n        from configzen.model import ConfigModel\n\n        if module_vars is None:\n            module_vars = vars(sys.modules[module_name])\n\n        if model_class is None:\n\n            class ModuleConfigModel(ConfigModel):\n                __module__ = module_name\n                __annotations__ = module_vars[\"__annotations__\"]  # type: ignore[index]\n                __ns = locals()\n                for key in __annotations__:\n                    __ns[key] = module_vars[key]  # type: ignore[index]\n                del __ns\n\n            model_class = cast(type[ConfigModelT], ModuleConfigModel)\n\n        module_values = {}\n        for key, value in module_vars.items():\n            if key in {field.alias for field in model_class.__fields__.values()}:\n                module_values[key] = value\n\n        config_module = cls(\n            model=cast(ConfigModelT, model_class).parse_obj(module_values | values),\n            module_vars=module_vars,\n            name=module_vars[\"__name__\"],\n            doc=module_vars[\"__doc__\"],\n        )\n        return config_module\n\n    @classmethod\n    def wrap_this_module(\n        cls,\n        model_class: type[ConfigModelT] | None = None,\n        /,\n        **values: Any,\n    ) -> ConfigModule[ConfigModelT]:\n        \"\"\"Wrap the current module to interact with a config model.\"\"\"\n        current_frame = inspect.currentframe()\n        assert current_frame is not None\n        frame_back = current_frame.f_back\n        assert frame_back is not None\n        return cls.wrap_module(\n            frame_back.f_globals[\"__name__\"],\n            model_class,\n            **values,\n        )", ""]}
{"filename": "configzen/route.py", "chunked_list": ["from __future__ import annotations\n\nimport functools\nfrom collections.abc import Iterator\nfrom typing import TYPE_CHECKING, Any, ClassVar\n\nfrom configzen.errors import InternalSyntaxError, formatted_syntax_error\n\nif TYPE_CHECKING:\n    from configzen.typedefs import ConfigRouteLike", "if TYPE_CHECKING:\n    from configzen.typedefs import ConfigRouteLike\n\n__all__ = (\"ConfigRoute\",)\n\n\nclass ConfigRoute:\n    TOK_DOT: ClassVar[str] = \".\"\n    TOK_ESCAPE: ClassVar[str] = \"\\\\\"\n    TOK_DOTLISTESC_ENTER: ClassVar[str] = \"[\"\n    TOK_DOTLISTESC_EXIT: ClassVar[str] = \"]\"\n\n    def __init__(self, route: ConfigRouteLike, *, allow_empty: bool = False) -> None:\n        items = self.parse(route)\n        if not (allow_empty or items):\n            raise ValueError(\"Empty configuration route\")\n        self.items = items\n\n    @classmethod\n    def parse(cls, route: ConfigRouteLike) -> list[str]:\n        if isinstance(route, ConfigRoute):\n            return route.items\n        if isinstance(route, list):\n            return route\n        if isinstance(route, str):\n            with formatted_syntax_error(route):\n                return cls._decompose(route)\n        raise TypeError(f\"Invalid route type {type(route)!r}\")\n\n    @classmethod\n    def _decompose(cls, route: str) -> list[str]:  # noqa: C901, PLR0912\n        tok_dot = cls.TOK_DOT\n        tok_escape = cls.TOK_ESCAPE\n        tok_dle_enter = cls.TOK_DOTLISTESC_ENTER\n        tok_dle_exit = cls.TOK_DOTLISTESC_EXIT\n\n        route = route.removesuffix(tok_dot) + tok_dot\n\n        part = \"\"\n        dle_ctx: int | None = None\n        items: list[str] = []\n        enter = items.append\n        error = functools.partial(InternalSyntaxError, prefix=\"Route(\", suffix=\")\")\n        escape = False\n\n        for index, char in enumerate(route):\n            if escape:\n                part += char\n                escape = False\n                continue\n            is_last = index == len(route) - 1\n            if char == tok_dot:\n                if dle_ctx is not None:\n                    part += char\n                else:\n                    enter(part)\n                    part = \"\"\n            elif char == tok_escape:\n                if is_last:\n                    part += char\n                else:\n                    escape = True\n            elif char == tok_dle_enter:\n                if dle_ctx is not None:\n                    # a special character at its place\n                    part += char\n                else:\n                    dle_ctx = index\n            elif char == tok_dle_exit:\n                if is_last or route[index + 1] == tok_dot:\n                    if dle_ctx is None:\n                        msg = (\n                            \"Dotlist escape sequence \"\n                            f\"was not opened with {tok_dle_enter!r}\"\n                        )\n                        raise error(msg, index=index)\n                    dle_ctx = None\n                else:\n                    # a special character at its place\n                    part += char\n            else:\n                part += char\n            if is_last and dle_ctx is not None:\n                msg = (\n                    \"Unclosed dotlist escape sequence \"\n                    f\"(expected {tok_dle_exit!r} token)\"\n                )\n                raise error(msg, index=dle_ctx)\n        return items\n\n    @classmethod\n    def decompose(cls, route: str) -> list[str]:\n        with formatted_syntax_error(route):\n            return cls._decompose(route)\n\n    def compose(self) -> str:\n        escape = (self.TOK_DOTLISTESC_ENTER, self.TOK_DOTLISTESC_EXIT)\n        raw = (\"\", \"\")\n        return self.TOK_DOT.join(\n            fragment.join(escape).replace(\n                self.TOK_DOTLISTESC_EXIT + self.TOK_DOT,\n                self.TOK_DOTLISTESC_EXIT + self.TOK_ESCAPE + self.TOK_DOT,\n            )\n            if self.TOK_DOT in fragment\n            else fragment.join(raw)\n            for fragment in self.items\n        )\n\n    def enter(self, subroute: ConfigRouteLike) -> ConfigRoute:\n        return type(self)(self.items + self.parse(subroute))\n\n    def __eq__(self, other: Any) -> bool:\n        if isinstance(other, ConfigRoute):\n            return self.items == other.items\n        if isinstance(other, str):\n            return self.items == self.decompose(other)\n        if isinstance(other, list):\n            return self.items == other\n        return NotImplemented\n\n    def __str__(self) -> str:\n        return self.compose()\n\n    def __iter__(self) -> Iterator[str]:\n        yield from self.items\n\n    def __repr__(self) -> str:\n        return f\"{type(self).__name__}({self.items})\"", ""]}
{"filename": "configzen/_detach.py", "chunked_list": ["from __future__ import annotations\n\nimport asyncio\nimport contextvars\nimport functools\nfrom collections.abc import Callable, Coroutine\nfrom typing import Any, cast\n\nfrom configzen.typedefs import P, T\n", "from configzen.typedefs import P, T\n\n\ndef detached_context_function(\n    func: Callable[P, T],\n) -> Callable[P, T]:\n    \"\"\"\n    Decorator to copy a function call context automatically (context isolation)\n    to prevent collisions.\n\n    This decorator will copy the current context and run the function\n    in this new isolated context.\n    \"\"\"\n    if isinstance(func, (classmethod, staticmethod)):\n        return type(func)(detached_context_function(func.__func__))\n\n    if asyncio.iscoroutinefunction(func):\n\n        @functools.wraps(func)\n        def _detaching_async_wrapper(*args: Any, **kwargs: Any) -> asyncio.Task[T]:\n            return detached_context_await(\n                cast(Callable[P, Coroutine[Any, Any, T]], func), *args, **kwargs\n            )\n\n        return cast(Callable[P, T], _detaching_async_wrapper)\n\n    @functools.wraps(func)\n    def _detaching_wrapper(*args: Any, **kwargs: Any) -> T:\n        return detached_context_run(func, *args, **kwargs)\n\n    return _detaching_wrapper", "\n\ndef detached_context_run(\n    func: Callable[..., T],\n    *args: Any,\n    **kwargs: Any,\n) -> T:\n    \"\"\"Utility for running a function in an isolated context.\"\"\"\n    context = contextvars.copy_context()\n    return context.run(func, *args, **kwargs)", "\n\ndef detached_context_await(\n    func: Callable[..., Coroutine[Any, Any, T]],\n    *args: Any,\n    **kwargs: Any,\n) -> asyncio.Task[T]:\n    \"\"\"Utility for awaiting a coroutine in an isolated context.\"\"\"\n    return asyncio.create_task(func(*args, **kwargs))\n", ""]}
{"filename": "configzen/interpolation.py", "chunked_list": ["from __future__ import annotations\n\nimport functools\nimport importlib\nimport inspect\nimport re\nimport string\nimport sys\nfrom collections import ChainMap\nfrom collections.abc import Callable, MutableMapping", "from collections import ChainMap\nfrom collections.abc import Callable, MutableMapping\nfrom typing import TYPE_CHECKING, Any, ClassVar, cast\n\nfrom pydantic.fields import Undefined, UndefinedType\n\nfrom configzen.errors import ResourceLookupError\n\nif TYPE_CHECKING:\n    from configzen.typedefs import ConfigModelT", "if TYPE_CHECKING:\n    from configzen.typedefs import ConfigModelT\n\n__all__ = (\n    \"interpolate\",\n    \"include\",\n)\n\nINTERPOLATOR: str = \"__interpolator__\"\nEVALUATES: str = \"__evaluates__\"", "INTERPOLATOR: str = \"__interpolator__\"\nEVALUATES: str = \"__evaluates__\"\nEVALUATION_ENGINE: str = \"__evaluation_engine__\"\nNAMESPACE_TOKEN: str = \"::\"\nAT_TOKEN: str = \"@\"\nOR_TOKEN: str = \"||\"\nSTRICT_TOKEN: str = \"!\"\n\n\nclass ConfigInterpolationTemplate(string.Template):\n    delimiter = re.escape(\"$\")\n    idpattern = r\"[^{}\\$]+\"\n    # noinspection PyClassVar\n    pattern: ClassVar[re.Pattern[str]] = rf\"\"\"\n    {delimiter}(?:\n      (?P<escaped>{delimiter})          | # Escape sequence of two delims\n      (?P<named>{idpattern})            | # delimiter and a Python ident\n      {{(?P<sbraced>{idpattern})}}      | # delimiter and a single-braced ident\n      {{{{(?P<braced>{idpattern})}}}}   | # delimiter and a double-braced ident\n      (?P<invalid>)                       # Other ill-formed delimiter expressions\n    )\n    \"\"\"  # type: ignore[assignment]\n    flags = re.VERBOSE | re.IGNORECASE\n\n    def _invalid(self, mo: re.Match[str]) -> None:\n        i = mo.start(\"invalid\")\n        lines = self.template[:i].splitlines(keepends=True)\n        if not lines:\n            colno = 1\n            lineno = 1\n        else:\n            colno = i - len(\"\".join(lines[:-1]))\n            lineno = len(lines)\n        raise ValueError(f\"Invalid placeholder in string: line {lineno}, col {colno}\")\n\n    def interpolate(\n        self, mapping: MutableMapping[str, Any] | None = None, /, **kwds: Any\n    ) -> str:\n        if mapping is None:\n            mapping = kwds\n        elif kwds:\n            mapping = ChainMap(kwds, mapping)\n\n        # Helper function for .sub()\n        def convert(mo: re.Match[str]) -> str:\n            named = mo.group(\"named\") or mo.group(\"braced\") or mo.group(\"sbraced\")\n            if named is not None:\n                try:\n                    return str(mapping[named])\n                except KeyError:\n                    return mo.group()\n            if mo.group(\"escaped\") is not None:\n                return self.delimiter\n            if mo.group(\"invalid\") is not None:\n                return mo.group()\n            raise ValueError(\"Unrecognized named group in pattern\", self.pattern)\n\n        return self.pattern.sub(convert, self.template)\n\n    if sys.version_info < (3, 11):\n\n        def get_identifiers(self) -> list[str]:\n            ids = []\n            for mo in self.pattern.finditer(self.template):\n                named = mo.group(\"named\") or mo.group(\"braced\") or mo.group(\"sbraced\")\n                if named is not None and named not in ids:\n                    # add a named group only the first time it appears\n                    ids.append(named)\n                elif (\n                    named is None\n                    and mo.group(\"invalid\") is None\n                    and mo.group(\"escaped\") is None\n                ):\n                    # If all the groups are None, there must be\n                    # another group we\"re not expecting\n                    raise ValueError(\n                        \"Unrecognized named group in pattern\", self.pattern\n                    )\n            return ids", "\nclass ConfigInterpolationTemplate(string.Template):\n    delimiter = re.escape(\"$\")\n    idpattern = r\"[^{}\\$]+\"\n    # noinspection PyClassVar\n    pattern: ClassVar[re.Pattern[str]] = rf\"\"\"\n    {delimiter}(?:\n      (?P<escaped>{delimiter})          | # Escape sequence of two delims\n      (?P<named>{idpattern})            | # delimiter and a Python ident\n      {{(?P<sbraced>{idpattern})}}      | # delimiter and a single-braced ident\n      {{{{(?P<braced>{idpattern})}}}}   | # delimiter and a double-braced ident\n      (?P<invalid>)                       # Other ill-formed delimiter expressions\n    )\n    \"\"\"  # type: ignore[assignment]\n    flags = re.VERBOSE | re.IGNORECASE\n\n    def _invalid(self, mo: re.Match[str]) -> None:\n        i = mo.start(\"invalid\")\n        lines = self.template[:i].splitlines(keepends=True)\n        if not lines:\n            colno = 1\n            lineno = 1\n        else:\n            colno = i - len(\"\".join(lines[:-1]))\n            lineno = len(lines)\n        raise ValueError(f\"Invalid placeholder in string: line {lineno}, col {colno}\")\n\n    def interpolate(\n        self, mapping: MutableMapping[str, Any] | None = None, /, **kwds: Any\n    ) -> str:\n        if mapping is None:\n            mapping = kwds\n        elif kwds:\n            mapping = ChainMap(kwds, mapping)\n\n        # Helper function for .sub()\n        def convert(mo: re.Match[str]) -> str:\n            named = mo.group(\"named\") or mo.group(\"braced\") or mo.group(\"sbraced\")\n            if named is not None:\n                try:\n                    return str(mapping[named])\n                except KeyError:\n                    return mo.group()\n            if mo.group(\"escaped\") is not None:\n                return self.delimiter\n            if mo.group(\"invalid\") is not None:\n                return mo.group()\n            raise ValueError(\"Unrecognized named group in pattern\", self.pattern)\n\n        return self.pattern.sub(convert, self.template)\n\n    if sys.version_info < (3, 11):\n\n        def get_identifiers(self) -> list[str]:\n            ids = []\n            for mo in self.pattern.finditer(self.template):\n                named = mo.group(\"named\") or mo.group(\"braced\") or mo.group(\"sbraced\")\n                if named is not None and named not in ids:\n                    # add a named group only the first time it appears\n                    ids.append(named)\n                elif (\n                    named is None\n                    and mo.group(\"invalid\") is None\n                    and mo.group(\"escaped\") is None\n                ):\n                    # If all the groups are None, there must be\n                    # another group we\"re not expecting\n                    raise ValueError(\n                        \"Unrecognized named group in pattern\", self.pattern\n                    )\n            return ids", "\n\n@functools.singledispatch\ndef interpolate(\n    value: Any,\n    _cls: type[ConfigModelT],\n    _closest_ns: dict[str, Any],\n    _target_type: type[Any],\n) -> Any:\n    return value", "\n\n@interpolate.register(str)\ndef _try_interpolate_str(\n    value: str,\n    cls: type[ConfigModelT],\n    closest_namespace: dict[str, Any],\n    target_type: type[Any],\n) -> Any:\n    template = ConfigInterpolationTemplate(value)\n    identifiers = set(template.get_identifiers())\n    if not identifiers:\n        return value\n\n    namespace = cls.get_interpolation_namespace(\n        expressions=identifiers,\n        closest_namespace=closest_namespace,\n        target_type=target_type,\n    )\n    interpolator: BaseInterpolator = getattr(cls, INTERPOLATOR)\n\n    if len(identifiers) == 1:\n        identifier = identifiers.pop()\n        value = namespace[identifier]\n        return interpolator.interpolate_one(\n            template=template,\n            identifier=identifier,\n            value=value,\n            target_type=target_type,\n        )\n\n    return interpolator.interpolate_many(\n        template=template, namespace=namespace, target_type=target_type\n    )", "\n\ndef _ensure_dispatchable_type(\n    target_type: type[Any],\n) -> type[Any]:\n    if not getattr(target_type, \"__mro__\", None):\n        target_type = object\n    return target_type\n\n\nclass BaseInterpolator:\n    def interpolate_many(\n        self,\n        template: ConfigInterpolationTemplate,\n        namespace: dict[str, Any],\n        target_type: type[Any],\n    ) -> Any:\n        dispatch_type = _ensure_dispatchable_type(target_type)\n        bulk_render = self.bulk_renderers.dispatch(dispatch_type)\n        return bulk_render(self, template, namespace)\n\n    # noinspection PyMethodMayBeStatic\n    def bulk_render_any(\n        self, template: ConfigInterpolationTemplate, namespace: dict[str, Any]\n    ) -> Any:\n        return template.interpolate(namespace)\n\n    def interpolate_one(\n        self,\n        template: ConfigInterpolationTemplate,\n        identifier: str,\n        value: Any,\n        target_type: type[Any],\n    ) -> Any:\n        dispatch_type = _ensure_dispatchable_type(target_type)\n        render = self.single_renderers.dispatch(dispatch_type)\n        return render(self, template, identifier, value)\n\n    # noinspection PyMethodMayBeStatic\n    def single_render_any(\n        self, _template: ConfigInterpolationTemplate, _identifier: str, value: Any\n    ) -> Any:\n        return value\n\n    bulk_renderers = functools.singledispatch(bulk_render_any)\n    single_renderers = functools.singledispatch(single_render_any)", "\n\nclass BaseInterpolator:\n    def interpolate_many(\n        self,\n        template: ConfigInterpolationTemplate,\n        namespace: dict[str, Any],\n        target_type: type[Any],\n    ) -> Any:\n        dispatch_type = _ensure_dispatchable_type(target_type)\n        bulk_render = self.bulk_renderers.dispatch(dispatch_type)\n        return bulk_render(self, template, namespace)\n\n    # noinspection PyMethodMayBeStatic\n    def bulk_render_any(\n        self, template: ConfigInterpolationTemplate, namespace: dict[str, Any]\n    ) -> Any:\n        return template.interpolate(namespace)\n\n    def interpolate_one(\n        self,\n        template: ConfigInterpolationTemplate,\n        identifier: str,\n        value: Any,\n        target_type: type[Any],\n    ) -> Any:\n        dispatch_type = _ensure_dispatchable_type(target_type)\n        render = self.single_renderers.dispatch(dispatch_type)\n        return render(self, template, identifier, value)\n\n    # noinspection PyMethodMayBeStatic\n    def single_render_any(\n        self, _template: ConfigInterpolationTemplate, _identifier: str, value: Any\n    ) -> Any:\n        return value\n\n    bulk_renderers = functools.singledispatch(bulk_render_any)\n    single_renderers = functools.singledispatch(single_render_any)", "\n\ndef evaluates(\n    evaluator_name: str,\n) -> Callable[[Callable[[Any], Any]], Callable[[Any], Any]]:\n    def decorator(evaluator: Callable[[Any], Any]) -> Callable[[Any], Any]:\n        setattr(evaluator, EVALUATES, evaluator_name.casefold())\n        return evaluator\n\n    return decorator", "\n\nclass BaseEvaluationEngine:\n    evaluators_by_name: ClassVar[dict[str, Any]] = {}\n\n    def evaluate_expression_impl(\n        self,\n        expression: str,\n        result_namespace: dict[str, Any],\n        namespaces: dict[str | None, dict[str, Any]],\n        closest_namespace: dict[str, Any],\n        target_type: type[Any],\n    ) -> Any:\n        from configzen import field_hook\n\n        result = Undefined\n        final_result = Undefined\n        for identifier in expression.strip().split(OR_TOKEN):\n            identifier = identifier.strip()\n            if identifier:\n                result = self.resolve_identifier(\n                    identifier=identifier,\n                    result_namespace=result_namespace,\n                    namespaces=namespaces,\n                    closest_namespace=closest_namespace,\n                )\n\n                if result is not Undefined:\n                    result = field_hook(target_type, result)\n                    result_namespace[identifier] = result\n\n                if result:\n                    final_result = result\n                    break\n\n        if final_result is not Undefined:\n            result_namespace[expression] = final_result\n        return result\n\n    @staticmethod\n    def resolve_identifier(\n        identifier: str,\n        result_namespace: dict[str, Any],\n        namespaces: dict[str | None, dict[str, Any]],\n        closest_namespace: dict[str, Any],\n        strict: bool | None = None,\n    ) -> Any:\n        from configzen.model import at\n\n        if (identifier.startswith('\"') and identifier.endswith('\"')) or (\n            identifier.startswith(\"'\") and identifier.endswith(\"'\")\n        ):\n            return identifier[1:-1]\n\n        if strict is None:\n            strict = identifier.startswith(\"!\")\n            if strict:\n                identifier = identifier[1:].strip()\n\n        ns_name, uses_ns, ident = identifier.rpartition(NAMESPACE_TOKEN)\n        namespaces_to_use = []\n        ns_at_ident = \"\"\n        global_namespace = namespaces[None]\n\n        if uses_ns:\n            # [namespace[[.member]*@ns_at_ident[.member]*]]::identifier\n\n            if ns_name and uses_ns:\n                ns_name, _, ns_at_ident = ns_name.rpartition(AT_TOKEN)\n                if ns_name in namespaces:\n                    namespaces_to_use.append(namespaces[ns_name])\n            namespaces_to_use.append(global_namespace)\n            namespaces_to_use.append(closest_namespace)\n            namespaces_to_use.append(result_namespace)\n        else:\n            # identifier[.member]*\n\n            namespaces_to_use.append(closest_namespace)\n            namespaces_to_use.append(result_namespace)\n            namespaces_to_use.append(global_namespace)\n\n        ident, _, ident_at = ident.partition(AT_TOKEN)\n\n        lookup_key = ns_name if uses_ns and ns_name else ident\n        lookup_value: dict[str, Any] | UndefinedType = Undefined\n\n        for namespace in namespaces_to_use:\n            try:\n                lookup_value = at(namespace, lookup_key)\n            except ResourceLookupError:\n                if strict:\n                    raise\n            if lookup_value is not Undefined:\n                break\n\n        if lookup_value is Undefined:\n            return identifier\n\n        value = lookup_value\n\n        if uses_ns and ns_name:\n            namespace = cast(\"dict[str, Any]\", value)\n\n            if ns_at_ident:\n                namespace = at(namespace, ns_at_ident)\n\n            try:\n                value = at(namespace, ident)\n            except ResourceLookupError:\n                if strict:\n                    raise\n\n            if value is Undefined:\n                return Undefined\n\n        if ident_at:\n            value = at(value, ident_at)\n\n        result_namespace[identifier] = value\n        return value\n\n    evaluators_by_class = functools.singledispatch(evaluate_expression_impl)\n\n    def evaluate_expression(\n        self,\n        expression: str,\n        result_namespace: dict[str, Any],\n        namespaces: dict[str | None, dict[str, Any]],\n        closest_namespace: dict[str, Any],\n        target_type: type[Any],\n    ) -> Any:\n        dispatch_type = _ensure_dispatchable_type(target_type)\n        evaluator = self.evaluators_by_class.dispatch(dispatch_type)\n        return evaluator(\n            self,\n            expression,\n            result_namespace,\n            namespaces,\n            closest_namespace,\n            target_type,\n        )\n\n    def __init_subclass__(cls, *, register_evaluators: bool = True) -> None:\n        super().__init_subclass__()\n        if cls.evaluators_by_name is None:\n            cls.evaluators_by_name = {}\n\n        if register_evaluators:\n            # TODO: Replace with `inspect.getmembers_static()` by 2026-10.\n            for _, func in inspect.getmembers(cls, inspect.isfunction):\n                name = getattr(func, EVALUATES, None)\n                if name is not None:\n                    cls.register_evaluator(name, func)\n\n    @classmethod\n    def register_evaluator(cls, name: str, evaluator: Callable[[Any], Any]) -> None:\n        cls.evaluators_by_name[name] = evaluator", "\n\nBaseEvaluationEngine.__init_subclass__()\n\n\ndef _include_wrapper(\n    cls: type[ConfigModelT],\n    namespace_name: str | None,\n    namespace_factory: Callable[[], dict[str, Any]],\n) -> type[ConfigModelT]:\n    from configzen.model import INTERPOLATION_INCLUSIONS\n\n    getattr(cls, INTERPOLATION_INCLUSIONS)[namespace_name] = namespace_factory\n    return cls", "\n\n# noinspection PyUnusedLocal\n@functools.singledispatch\ndef include(\n    namespace: Any,\n    /,\n    *,\n    name: str | None = None,  # noqa: ARG001\n    **kwargs: Any,  # noqa: ARG001\n) -> Callable[[type[ConfigModelT]], type[ConfigModelT]]:\n    raise TypeError(\n        f\"Cannot include {namespace} (unexpected type {type(namespace).__name__})\"\n    )", "\n\n@include.register(dict)\ndef include_const(\n    namespace: dict[str, Any] | ConfigModelT, /, *, name: str | None = None\n) -> Callable[[type[ConfigModelT]], type[ConfigModelT]]:\n    from configzen import ConfigModel\n\n    if isinstance(namespace, ConfigModel):\n        return lambda cls: _include_wrapper(\n            cls, name, lambda: namespace.dict()  # type: ignore\n        )\n    return lambda cls: _include_wrapper(cls, name, lambda: namespace)  # type: ignore", "\n\ndef _include_factory(\n    namespace_factory: Callable[[], dict[str, Any]],\n    /,\n    *,\n    name: str | None = None,\n) -> Callable[[type[ConfigModelT]], type[ConfigModelT]]:\n    return lambda cls: _include_wrapper(cls, name, namespace_factory)\n", "\n\nif not TYPE_CHECKING:\n    include.register(Callable, _include_factory)\n\n\n@include.register(str)\ndef _include_str(\n    namespace: str,\n    /,\n    *,\n    name: str | None = None,\n    stack_offset: int = 2,\n    module: str | None = None,\n    isolate_from_toplevel: bool = True,\n) -> Callable[[type[ConfigModelT]], type[ConfigModelT]]:\n    if module is None:\n        callers_globals = inspect.stack()[stack_offset].frame.f_globals\n    else:\n        callers_globals = None\n\n    if isolate_from_toplevel and name is None:\n        name = namespace\n\n    def namespace_factory() -> dict[str, Any]:\n        nonlocal callers_globals\n        from configzen import ConfigModel\n\n        if callers_globals is None:\n            assert module\n            module_obj = importlib.import_module(module)\n            callers_globals = module_obj.__dict__\n\n        try:\n            namespace_variable = callers_globals[namespace]\n        except KeyError:\n            raise NameError(\n                f\"Namespace {namespace!r} not found in {callers_globals['__name__']}\"\n            ) from None\n        if isinstance(namespace_variable, dict):\n            return namespace_variable\n        if isinstance(namespace_variable, ConfigModel):\n            return namespace_variable.dict()\n        raise TypeError(\n            f\"Cannot include {namespace!r} (unexpected type \"\n            f\"{type(namespace_variable).__name__})\"\n        )\n\n    return lambda cls: _include_wrapper(cls, name, namespace_factory)", ""]}
{"filename": "tests/test_processor.py", "chunked_list": [""]}
{"filename": "tests/conftest.py", "chunked_list": ["import functools\nimport pathlib\n\ntestpath = functools.partial(pathlib.Path(__file__).parent.joinpath)\n"]}
{"filename": "tests/test_supported_formats/conftest.py", "chunked_list": ["import configparser\nimport functools\nimport io\nimport json\nimport os\nfrom typing import Union\n\nimport bson\nimport cbor\nimport cbor2", "import cbor\nimport cbor2\nimport configobj\n\n# import msgpack\nimport pytest\nimport toml\nimport yaml\nfrom amazon.ion import simpleion as ion\nfrom anyconfig.backend import properties", "from amazon.ion import simpleion as ion\nfrom anyconfig.backend import properties\n\nfrom configzen import ConfigModel\nfrom tests.conftest import testpath\n\nfile_dir = testpath(\"test_supported_formats/data\")\nfile_dir.mkdir(exist_ok=True)\n\n\nclass IncorporatedModel(ConfigModel):\n    string: str", "\n\nclass IncorporatedModel(ConfigModel):\n    string: str\n\n\nclass SectionModel(ConfigModel):\n    integer: int\n    incorporated_model: IncorporatedModel = IncorporatedModel(string=\"Hello world!\")\n    union_value: Union[bool, float]\n    collection_value: list[str]\n    dict_value: dict[str, str] = {\"configzen\": \"is this\"}", "\n\nclass MockModel(ConfigModel):\n    main: SectionModel\n\n\ndef ini_compose(data):\n    config = configparser.ConfigParser()\n    config.read_dict(data)\n    fp = io.StringIO()\n    config.write(fp)\n    return fp.getvalue()", "\n\ndef configobj_compose(data):\n    config = configobj.ConfigObj()\n    config.merge(data)\n    fp = io.BytesIO()\n    config.write(fp)\n    return fp.getvalue().decode()\n\n\ndef shellvars_compose(data):\n    output = \"\"\n    for key, value in data.items():\n        output += f\"{key}='{value}'{os.linesep}\"\n    return output", "\n\ndef shellvars_compose(data):\n    output = \"\"\n    for key, value in data.items():\n        output += f\"{key}='{value}'{os.linesep}\"\n    return output\n\n\ndef properties_compose(data):\n    output = \"\"\n    for key, value in data.items():\n        output += f\"{key}={properties.escape(str(value))}{os.linesep}\"\n    return output", "\ndef properties_compose(data):\n    output = \"\"\n    for key, value in data.items():\n        output += f\"{key}={properties.escape(str(value))}{os.linesep}\"\n    return output\n\n\ncomposer = {\n    \"ini\": ini_compose,", "composer = {\n    \"ini\": ini_compose,\n    \"configobj\": configobj_compose,\n    \"json\": functools.partial(json.dumps, indent=4),\n    \"yaml\": yaml.dump,\n    \"toml\": toml.dumps,\n    \"ion\": ion.dumps,\n    \"bson\": bson.encode,\n    \"cbor2\": cbor2.dumps,\n    \"cbor\": cbor.dumps,", "    \"cbor2\": cbor2.dumps,\n    \"cbor\": cbor.dumps,\n    # \"msgpack\": msgpack.dumps,\n    \"shellvars\": shellvars_compose,\n    \"properties\": properties_compose,\n}\n\n\n@pytest.fixture(\n    name=\"mock_data\",", "@pytest.fixture(\n    name=\"mock_data\",\n    scope=\"session\",\n    params=[\n        {\n            \"main\": {\n                \"integer\": 0xDEADBEEF,\n                \"incorporated_model\": {\"string\": \"Hello world!\"},\n                \"union_value\": 0.2137,\n                \"collection_value\": [\"this\", \"is\", \"configzen\"],", "                \"union_value\": 0.2137,\n                \"collection_value\": [\"this\", \"is\", \"configzen\"],\n                \"dict_value\": {\"configzen\": \"is this\"},\n            }\n        }\n    ],\n)\ndef mock_data_fixture(request):\n    yield request.param\n", "\n\n@pytest.fixture(\n    scope=\"session\",\n    autouse=True,\n    params=[\n        (composer[\"ini\"], file_dir / \"data.ini\", False),\n        (composer[\"json\"], file_dir / \"data.json\", False),\n        (composer[\"yaml\"], file_dir / \"data.yaml\", False),\n        (composer[\"toml\"], file_dir / \"data.toml\", False),", "        (composer[\"yaml\"], file_dir / \"data.yaml\", False),\n        (composer[\"toml\"], file_dir / \"data.toml\", False),\n        (composer[\"bson\"], file_dir / \"data.bson\", True),\n        (composer[\"cbor2\"], file_dir / \"data.cbor2\", True),\n        (composer[\"cbor\"], file_dir / \"data.cbor\", True),\n        (composer[\"shellvars\"], file_dir / \"data.shellvars\", False),\n        (composer[\"properties\"], file_dir / \"data.properties\", False),\n        (composer[\"ion\"], file_dir / \"data.ion\", True),\n        (composer[\"configobj\"], file_dir / \"data.configobj\", False),\n        # (composer[\"msgpack\"], file_dir / \"data.msgpack\", True),", "        (composer[\"configobj\"], file_dir / \"data.configobj\", False),\n        # (composer[\"msgpack\"], file_dir / \"data.msgpack\", True),\n    ],\n)\ndef data_file(request, mock_data):\n    dumper, dest_file, uses_binary_data = request.param\n\n    if dumper in (composer[\"shellvars\"], composer[\"properties\"]):\n        used_mock_data = mock_data[\"main\"].copy()\n        mock_data = used_mock_data\n\n    dest_file.touch()\n    if uses_binary_data:\n        dest_file.write_bytes(dumper(mock_data))\n    else:\n        dest_file.write_text(dumper(mock_data))\n    yield dest_file", ""]}
{"filename": "tests/test_supported_formats/test_supported_formats.py", "chunked_list": ["from __future__ import annotations\n\nimport pydantic\n\nfrom tests.test_supported_formats.conftest import MockModel, SectionModel\n\n\ndef test_load_and_recreate(data_file, mock_data):\n    try:\n        model = MockModel.load(data_file)\n    except pydantic.ValidationError:\n        # key-value pairs, little workaround\n        assert data_file.suffix in (\".shellvars\", \".properties\")\n        model = MockModel(main=SectionModel.load(data_file))\n    model_dict = model.dict()\n    assert model_dict == mock_data\n    recreated = MockModel.parse_obj(model_dict)\n    assert recreated == model\n    assert recreated.dict() == mock_data", ""]}
{"filename": "tests/test_module_wrapping/config.py", "chunked_list": ["# from configzen.module import ConfigModule\nprint(\"MODULE EXECUTED\")\na: int = 1\nb: int = 2\n\n# ConfigModule.wrap_this_module()\n"]}
{"filename": "tests/test_module_wrapping/configempty.py", "chunked_list": [""]}
{"filename": "tests/test_module_wrapping/test_wrapping.py", "chunked_list": ["import importlib\nimport sys\nimport weakref\n\nfrom configzen import ConfigModel\n\n\nclass MyConfig(ConfigModel):\n    \"\"\"My config model\"\"\"\n\n    a: int = 5\n    b: int = 10", "\n\ndef test_module_wrapping():\n    from tests.test_module_wrapping import config as module\n\n    module_name = module.__name__\n    model = MyConfig.wrap_module(module)\n\n    ref = weakref.ref(module)\n    del module\n    assert ref() is None\n\n    module_wrapper = sys.modules[module_name]\n    from tests.test_module_wrapping import config as reimported_module  # reimport\n\n    assert reimported_module is module_wrapper\n    module_wrapper.a = \"100\"\n    assert reimported_module.a == model.a == 100\n    reimported_module.b = \"200\"\n    assert reimported_module.b == model.b == 200\n\n    old_wrapper = module_wrapper\n    reloaded_wrapper = importlib.reload(module_wrapper)\n    assert old_wrapper is reloaded_wrapper\n    assert reloaded_wrapper.a == 1  # config.py:3\n    assert reloaded_wrapper.b == 2  # config.py:4\n\n    MyConfig.wrap_module(\"tests.test_module_wrapping.configempty\")\n    wrapper = sys.modules[\"tests.test_module_wrapping.configempty\"]\n    model = sys.modules[\"tests.test_module_wrapping.configempty\"].get_model()\n    assert model == MyConfig()\n    assert wrapper.a == MyConfig().a\n    assert wrapper.b == MyConfig().b\n\n    wrapper.a = \"2137\"\n    wrapper.b = \"1337\"\n    assert wrapper.a == model.a == 2137\n    assert wrapper.b == model.b == 1337\n\n    model.reload()\n    assert wrapper.a == model.a == 2137  # config is empty, old values stay\n    assert wrapper.b == model.b == 1337  # config is empty, old values stay", ""]}
{"filename": "tests/test_config/test_agent.py", "chunked_list": [""]}
{"filename": "tests/test_config/test_hooks.py", "chunked_list": [""]}
{"filename": "tests/test_config/test_meta.py", "chunked_list": ["from __future__ import annotations\n\nimport io\n\nimport pytest\nfrom pydantic import ConfigError\n\nfrom configzen import ConfigAgent, ConfigMeta, ConfigModel\n\n\nclass NoAutoUpdateForwardRefs(ConfigModel):\n    item: Item\n\n    class Config(ConfigMeta):\n        autoupdate_forward_refs = False", "\n\nclass NoAutoUpdateForwardRefs(ConfigModel):\n    item: Item\n\n    class Config(ConfigMeta):\n        autoupdate_forward_refs = False\n\n\nclass AutoUpdateForwardRefs(ConfigModel):\n    item: Item", "\nclass AutoUpdateForwardRefs(ConfigModel):\n    item: Item\n\n\nclass Item(ConfigModel):\n    foo: int\n\n\ndef get_agent():\n    resource = io.StringIO(\"item:\\n  foo: 123\")\n    agent = ConfigAgent(resource=resource, parser_name=\"yaml\")\n    return agent", "\ndef get_agent():\n    resource = io.StringIO(\"item:\\n  foo: 123\")\n    agent = ConfigAgent(resource=resource, parser_name=\"yaml\")\n    return agent\n\n\ndef test_autoupdate_forward_refs():\n    assert AutoUpdateForwardRefs.load(get_agent()) == AutoUpdateForwardRefs(\n        item=Item(foo=123)\n    )\n\n    with pytest.raises(ConfigError):\n        NoAutoUpdateForwardRefs.load(get_agent())", "\n\ndef test_resource_and_parser_name():\n    class FixedResourceModel(ConfigModel):\n        class Config(ConfigMeta):\n            resource = io.StringIO(\"foo: 123\")\n            parser_name = \"yaml\"\n\n        foo: int\n\n    assert FixedResourceModel.load() == FixedResourceModel(foo=123)\n\n    overridden_resource = ConfigAgent(io.StringIO(\"foo: 456\"), parser_name=\"yaml\")\n    assert FixedResourceModel.load(overridden_resource) == FixedResourceModel(foo=456)", ""]}
{"filename": "tests/test_config/test_route.py", "chunked_list": ["from __future__ import annotations\n\nimport pytest\n\nfrom configzen.errors import ConfigSyntaxError\nfrom configzen.model import ConfigRoute\n\nSTRING_DECOMPOSITION_PARAMS = [\n    (\"a.b.c\", [\"a\", \"b\", \"c\"]),\n    (r\"a\\.b.c\", [\"a.b\", \"c\"]),", "    (\"a.b.c\", [\"a\", \"b\", \"c\"]),\n    (r\"a\\.b.c\", [\"a.b\", \"c\"]),\n    (\"a.b.[c.d]\", [\"a\", \"b\", \"c.d\"]),\n    (\"[a.b].c.[d.e]\", [\"a.b\", \"c\", \"d.e\"]),\n    (r\"a.[b.[c.d]\\.e].f\", [\"a\", \"b.[c.d].e\", \"f\"]),\n    (r\"[a.b][c.d]\", [\"a.b][c.d\"]),\n]\n\n\n@pytest.mark.parametrize(", "\n@pytest.mark.parametrize(\n    \"obj, expected\",\n    [\n        # List inputs\n        ([\"a\", \"b\", \"c\"], [\"a\", \"b\", \"c\"]),\n        ([\"a\", \"b\", \"c.d\"], [\"a\", \"b\", \"c.d\"]),\n        ([\"a.b\", \"c\", \"d.e\"], [\"a.b\", \"c\", \"d.e\"]),\n        # Route inputs\n        (ConfigRoute([\"a\", \"b\", \"c\"]), [\"a\", \"b\", \"c\"]),", "        # Route inputs\n        (ConfigRoute([\"a\", \"b\", \"c\"]), [\"a\", \"b\", \"c\"]),\n        (ConfigRoute([\"a\", \"b\", \"c.d\"]), [\"a\", \"b\", \"c.d\"]),\n        (ConfigRoute([\"a.b\", \"c\", \"d.e\"]), [\"a.b\", \"c\", \"d.e\"]),\n        # String inputs\n        *STRING_DECOMPOSITION_PARAMS,\n    ],\n)\ndef test_parse(obj, expected):\n    assert ConfigRoute.parse(obj) == expected", "def test_parse(obj, expected):\n    assert ConfigRoute.parse(obj) == expected\n\n\n@pytest.mark.parametrize(\"composed, decomposed\", STRING_DECOMPOSITION_PARAMS)\ndef test_decompose(composed, decomposed):\n    assert ConfigRoute.decompose(composed) == decomposed\n\n\n@pytest.mark.parametrize(", "\n@pytest.mark.parametrize(\n    \"illegal_input\",\n    [\n        # String inputs\n        \"a.b.[c.d\",\n        \"a.b.c]\",\n        \"[a.b.c\",\n    ],\n)\ndef test_illegal_inputs(illegal_input):\n    with pytest.raises(ConfigSyntaxError):\n        ConfigRoute(illegal_input)", "    ],\n)\ndef test_illegal_inputs(illegal_input):\n    with pytest.raises(ConfigSyntaxError):\n        ConfigRoute(illegal_input)\n\n\n@pytest.mark.parametrize(\n    \"route, expected\",\n    [", "    \"route, expected\",\n    [\n        (ConfigRoute(\"a.b.c\"), \"a.b.c\"),\n        (ConfigRoute(\"a.[b.c]\"), \"a.[b.c]\"),\n        (ConfigRoute(r\"a.b\\.c\"), \"a.[b.c]\"),\n        (ConfigRoute(r\"a.[b.[c.d]\\.e].f\"), r\"a.[b.[c.d]\\.e].f\"),\n        (ConfigRoute(r\"a.b\\.\\[c\\.d\\]\\.e.f\"), r\"a.[b.[c.d]\\.e].f\"),\n    ],\n)\ndef test_compose(route, expected):\n    assert route.compose() == expected", ")\ndef test_compose(route, expected):\n    assert route.compose() == expected\n\n\ndef test_enter():\n    assert ConfigRoute(\"a\").enter(\"b\") == ConfigRoute(\"a.b\")\n    assert ConfigRoute(\"a\").enter([\"b\", \"c\"]) == ConfigRoute(\"a.b.c\")\n    assert ConfigRoute(\"a\").enter(ConfigRoute(\"b.c\")) == ConfigRoute(\"a.b.c\")\n    assert ConfigRoute(\"a\").enter(ConfigRoute([\"b\", \"c\"])) == ConfigRoute(\"a.b.c\")\n    assert ConfigRoute(\"a\").enter(ConfigRoute(\"b.[c.d]\")) == ConfigRoute(\"a.b.[c.d]\")", "\n\ndef test_equality_operator():\n    assert ConfigRoute(\"a.b.c\") == ConfigRoute(\"a.b.c\")\n    assert ConfigRoute(\"a.b.c\") == [\"a\", \"b\", \"c\"]\n    assert ConfigRoute([\"a\", \"b\", \"c\"]) == [\"a\", \"b\", \"c\"]\n"]}
{"filename": "tests/test_config/test_model/test_load.py", "chunked_list": ["import io\nimport os\nimport sys\nimport tempfile\n\nimport pytest\n\nfrom configzen import ConfigAgent, ConfigModel\n\n\nclass Model(ConfigModel):\n    item: int", "\n\nclass Model(ConfigModel):\n    item: int\n\n\nclass ModelWithHeader(ConfigModel):\n    header: Model\n\n", "\n\ndefault_params = pytest.mark.parametrize(\n    \"blob, parser_name, expected\",\n    [\n        ('{\"item\": 123}', \"json\", Model(item=123)),\n        (\"item: 456\", \"yaml\", Model(item=456)),\n        (\"[header]\\nitem = 789\", \"toml\", ModelWithHeader(header=Model(item=789))),\n        (\"[header]\\nitem = 101\", \"ini\", ModelWithHeader(header=Model(item=101))),\n    ],", "        (\"[header]\\nitem = 101\", \"ini\", ModelWithHeader(header=Model(item=101))),\n    ],\n)\n\n\n@default_params\ndef test_load_stream(blob, parser_name, expected):\n    loaded_model: type[ConfigModel] = type(expected)\n    assert (\n        loaded_model.load(\n            ConfigAgent(resource=io.StringIO(blob), parser_name=parser_name)\n        )\n        == expected\n    )\n\n    loaded_model.__config__.resource = io.StringIO(blob)\n    loaded_model.__config__.parser_name = parser_name\n    assert loaded_model.load() == expected\n\n    loaded_model.__config__.resource = ConfigAgent(\n        resource=io.StringIO(blob), parser_name=parser_name\n    )\n    loaded_model.__config__.parser_name = None\n    assert loaded_model.load() == expected", "\n\ndef get_temp_file(blob):\n    file = tempfile.NamedTemporaryFile(\n        mode=\"w+\", encoding=sys.getdefaultencoding(), delete=False\n    )\n    file.write(blob)\n    file.close()\n    return file\n", "\n\n@default_params\ndef test_load_file(blob, parser_name, expected):\n    loaded_model: type[ConfigModel] = type(expected)\n\n    file = get_temp_file(blob)\n    assert (\n        loaded_model.load(ConfigAgent(resource=file.name, parser_name=parser_name))\n        == expected\n    )\n    os.unlink(file.name)\n\n    file = get_temp_file(blob)\n    loaded_model.__config__.resource = file.name\n    loaded_model.__config__.parser_name = parser_name\n    assert loaded_model.load() == expected\n    os.unlink(file.name)\n\n    file = get_temp_file(blob)\n    loaded_model.__config__.resource = ConfigAgent(\n        resource=file.name, parser_name=parser_name\n    )\n    loaded_model.__config__.parser_name = None\n    assert loaded_model.load() == expected\n    os.unlink(file.name)", ""]}
