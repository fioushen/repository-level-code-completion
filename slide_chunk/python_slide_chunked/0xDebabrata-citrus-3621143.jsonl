{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetup(\n    name=\"citrusdb\",\n    version=\"0.5.1\",\n    author=\"Debabrata Mondal\",\n    author_email=\"debabrata.js@protonmail.com\",", "    author=\"Debabrata Mondal\",\n    author_email=\"debabrata.js@protonmail.com\",\n    description=\"(distributed) vector database\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/0xDebabrata/citrus\",\n    packages=(\n        find_packages(\n            exclude=[\"demo\"]\n        ) +", "            exclude=[\"demo\"]\n        ) +\n        [\"citrusdb.db.index\", \"citrusdb.db.sqlite\", \"citrusdb.db.postgres\"]\n    ),\n    include_package_data=True,\n    install_requires=[\n        \"numpy\",\n        \"hnswlib\",\n        \"openai\",\n        \"psycopg[c]\",", "        \"openai\",\n        \"psycopg[c]\",\n        \"psycopg[pool]\"\n    ],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires='>=3.7',", "    ],\n    python_requires='>=3.7',\n)\n"]}
{"filename": "citrusdb/__init__.py", "chunked_list": ["from typing import Any, Dict, Optional\n\ndef Client(\n    persist_directory: Optional[str] = None,\n    database_type: Optional[str] = \"sqlite\",\n    **kwargs\n):\n    from citrusdb.api.local import LocalAPI\n\n    return LocalAPI(persist_directory, database_type=database_type, **kwargs)", ""]}
{"filename": "citrusdb/test/recall.py", "chunked_list": ["import hnswlib\nimport citrusdb\nimport numpy as np\n\nnum_vectors = 10000\ndim = 1536\nk = 50\n\ndata = np.random.rand(num_vectors, dim).astype(np.float32)\n", "data = np.random.rand(num_vectors, dim).astype(np.float32)\n\ncitrus_client = citrusdb.Client()\n\ncitrus_client.create_index(\n    max_elements=num_vectors,\n    M=128,\n    ef_construction=400\n)\ncitrus_client.set_ef(400)", ")\ncitrus_client.set_ef(400)\n\nbf_index = hnswlib.BFIndex(space='cosine', dim=dim)\nbf_index.init_index(max_elements=num_vectors)\n\ncitrus_client.add(\n    ids=[i for i in range(0, num_vectors)],\n    embedding=data\n)", "    embedding=data\n)\n\nbf_index.add_items(data)\n\nquery_embedding = np.random.rand(10, dim).astype(np.float32)\n\nresults_citrus, distances_citrus = citrus_client.query(query_embeddings=query_embedding, k=k)\nresults_bf, distances_bf = bf_index.knn_query(query_embedding, k=k)\n", "results_bf, distances_bf = bf_index.knn_query(query_embedding, k=k)\n\n# Measure recall\ncorrect = 0\nfor i in range(10):\n    for label in results_citrus[i]:\n        for correct_label in results_bf[i]:\n            if label == correct_label:\n                correct += 1\n                break", "\nprint(\"recall is :\", float(correct)/(k * 10))\n"]}
{"filename": "citrusdb/utils/types.py", "chunked_list": ["from numpy import float32\nfrom numpy._typing import NDArray\nfrom typing import List, Optional, TypedDict\n\nID = str\nIDs = List[ID]\n\nclass Document(TypedDict):\n    id: int\n    text: Optional[str]\n    embedding: Optional[NDArray[float32]]", ""]}
{"filename": "citrusdb/utils/__init__.py", "chunked_list": [""]}
{"filename": "citrusdb/utils/utils.py", "chunked_list": ["import os\nfrom typing import Dict, Optional, Tuple\n\ndef convert_row_to_dict(row: Tuple, include: Dict):\n    returning_dict = {\"id\": row[1]}\n    if include[\"document\"]:\n        returning_dict[\"document\"] = row[2]\n        if include[\"metadata\"]:\n            returning_dict[\"metadata\"] = row[3]\n    elif include[\"metadata\"]:\n        returning_dict[\"metadata\"] = row[2]\n\n    return returning_dict", "\ndef ensure_valid_path(persist_directory: str, file_name: Optional[str] = None) -> bool:\n    \"\"\"\n    Creates required directories if they do not exist.\n\n    If only persist_directory is passed, returns True.\n    When file_name is passed, function returns boolean based on whether the\n    file can be found in given path.\n    \"\"\"\n    # Ensure directory exists\n    if not (os.path.isdir(persist_directory)):\n        os.makedirs(persist_directory)\n\n    if file_name is None:\n        return True\n\n    if os.path.exists(\n        os.path.join(persist_directory, file_name)\n    ):\n        return True\n    else:\n        return False", ""]}
{"filename": "citrusdb/db/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Tuple, Optional\n\nfrom citrusdb.utils.types import IDs\n\n\nclass BaseDB(ABC):\n    @abstractmethod\n    def create_index(\n        self,\n        name: str,\n        max_elements: int,\n        M: int,\n        ef_construction: int,\n        allow_replace_deleted: bool,\n        dimensions: Optional[int] = 1536,\n    ):\n        pass\n\n    @abstractmethod\n    def delete_vectors_from_index(\n        self,\n        index_id: int,\n        ids: IDs\n    ) -> List[int]:\n        pass\n\n    @abstractmethod\n    def filter_vectors(self, index_name: str, filters: List[Dict]) -> List:\n        pass\n\n    @abstractmethod\n    def get_indices(self) -> List[Any]:\n        pass\n\n    @abstractmethod\n    def get_index_details(\n        self,\n        name: str\n    ) -> Optional[Tuple[int, str, int, int, int, int, int, bool]]:\n        pass\n\n    @abstractmethod\n    def get_vector_ids_of_results(\n        self,\n        name: str,\n        results: List[List[int]],\n        include: Dict\n    ) -> List[List[Dict]]:\n        pass\n\n    @abstractmethod\n    def insert_to_index(\n        self,\n        data\n    ) -> List[int]:\n        pass\n\n    @abstractmethod\n    def update_ef(\n        self,\n        name: str,\n        ef: int\n    ):\n        pass", "\n"]}
{"filename": "citrusdb/db/index/__init__.py", "chunked_list": [""]}
{"filename": "citrusdb/db/index/hnswlib.py", "chunked_list": ["import hnswlib\n\n\nclass HnswIndex:\n    _id: str\n    _index: hnswlib.Index\n\n    def __init__(self, id, space=\"cosine\", dim=1536):\n        self._id = id\n        self._index = hnswlib.Index(space=space, dim=dim)\n\n    def init_index(\n        self, max_elements=1000, M=64, ef_construction=200, allow_replace_deleted=False\n    ):\n        self._index.init_index(max_elements, M, ef_construction, allow_replace_deleted)\n\n    def add_items(self, data, ids, replace_deleted=False):\n        max_elements = self._index.max_elements\n        curr_elements = self._index.element_count\n\n        # Increase index size\n        if curr_elements + len(data) > max_elements:\n            new_size = max(curr_elements + len(data), 2 * max_elements)\n            self._index.resize_index(new_size)\n\n        self._index.add_items(data, ids, replace_deleted)\n\n    def knn_query(self, query_embeddings, k=1, filter_function=None):\n        labels, distances = self._index.knn_query(query_embeddings, k, filter=filter_function)\n        return labels, distances\n\n    def set_ef(self, ef: int):\n        self._index.set_ef(ef)\n\n    def get_dimension(self):\n        return self._index.dim\n\n    def load_index(self, path: str, allow_replace_deleted=False):\n        self._index.load_index(path, allow_replace_deleted=allow_replace_deleted)\n\n    def mark_deleted(self, label: int):\n        self._index.mark_deleted(label)\n\n    def save_index(self, path: str):\n        self._index.save_index(path)\n\n    def get_status(self):\n        print(\"Max elements\", self._index.max_elements)\n        print(\"Current elements\", self._index.element_count)", "\n"]}
{"filename": "citrusdb/db/postgres/query_builder.py", "chunked_list": ["from psycopg import Connection, sql\nfrom typing import Dict, List\n\nclass QueryBuilder:\n    _con: Connection\n\n    def __init__(self, connection):\n        self._con = connection\n\n    def build_query(self, filters):\n        # Building the base SQL query\n        sql_query = f\"SELECT d.vector_id, d.id, d.index_id, d.text FROM index_data d JOIN index_manager m ON m.index_id = d.index_id WHERE m.name = %s\"\n\n        # Adding the filter criteria to the SQL query\n        if filters:\n            sql_query += \" AND \"\n            conditions = []\n            for filter in filters:\n                field = filter[\"field\"]\n                operator = filter[\"operator\"]\n                value = filter[\"value\"]\n                # ->> returns text in postgres\n                #if isinstance(value, int) or isinstance(value, float):\n                #    condition = f\"metadata ->> '{field}' {operator} '{value}'\"\n                #else:\n                #    condition = f\"metadata ->> '{field}' {operator} '{value}'\"\n                condition = f\"metadata ->> '{field}' {operator} '{value}'\"\n                conditions.append(condition)\n            sql_query += \" AND \".join(conditions)\n\n        return sql.SQL(sql_query)\n\n    def execute_query(self, index_name: str, filters: List[Dict]):\n        with self._con.cursor() as cur:\n            # Building and executing the query\n            sql_query = self.build_query(filters)\n            parameters = (index_name,)\n            cur.execute(sql_query, parameters)\n            return cur.fetchall()", "\n"]}
{"filename": "citrusdb/db/postgres/db.py", "chunked_list": ["from psycopg_pool import ConnectionPool\nfrom psycopg import sql\nfrom typing import Any, Dict, List, Optional, Tuple\nfrom citrusdb.db import BaseDB\nimport citrusdb.db.postgres.queries as queries\nfrom citrusdb.db.postgres.query_builder import QueryBuilder\nfrom citrusdb.utils.types import IDs\nfrom citrusdb.utils.utils import convert_row_to_dict\n\n\nclass PostgresDB(BaseDB):\n    _pool: ConnectionPool\n\n    def __init__(\n        self,\n        **kwargs: Dict[str, Any]\n    ):\n        # Setup connection pool\n        self._pool = ConnectionPool(kwargs=kwargs)\n\n        # Create index_manager and index_data table if they don't exist already\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.CREATE_INDEX_MANAGER_TABLE)\n                cur.execute(queries.CREATE_INDEX_DATA_TABLE)\n                conn.commit()\n\n    def create_index(\n        self,\n        name: str,\n        max_elements: int,\n        M: int,\n        ef_construction: int,\n        allow_replace_deleted: bool,\n        dimensions: Optional[int] = 1536,\n    ):\n        ef = ef_construction\n        parameters = (name, dimensions, max_elements, M, ef, ef_construction, allow_replace_deleted)\n        # Create new index entry to postgres db\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.INSERT_INDEX_TO_MANAGER, parameters)\n                conn.commit()\n\n    def delete_vectors_from_index(\n        self,\n        index_id: int,\n        ids: IDs\n    ):\n        \"\"\"\n        Delete vectors with given list of IDs from specific index\n\n        index_id: ID of index where the elements belong\n        ids: List of IDs to be deleted\n        \"\"\"\n\n        vector_ids = []\n        parameters = [ids, index_id]\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                for vector_id in cur.execute(queries.DELETE_VECTORS_FROM_INDEX, parameters):\n                    vector_ids.append(vector_id[0])\n                conn.commit()\n\n        return vector_ids\n\n    def filter_vectors(self, index_name: str, filters: List[Dict]):\n        \"\"\"\n        Get list of IDs of vectors that match filters.\n\n        index_name: Name of index where the elements belong\n        filters: List of filters to be applied\n        \"\"\"\n\n        with self._pool.connection() as conn:\n            query_builder = QueryBuilder(conn)\n            res = query_builder.execute_query(index_name, filters)\n            allowed_ids = []\n            for row in res:\n                allowed_ids.append(row[0])\n            return allowed_ids\n\n    def get_indices(self):\n        \"\"\"\n        Get all index details\n        \"\"\"\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.GET_ALL_INDEX_DETAILS)\n                return cur.fetchall()\n\n    def get_index_details(\n        self,\n        name: str\n    ) -> Optional[Tuple[int, str, int, int, int, int, int, bool]]:\n        \"\"\"\n        Get specific index details\n\n        name: Name of index to fetch\n        \"\"\"\n        parameters = (name,)\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.GET_INDEX_DETAILS_BY_NAME, parameters)\n                return cur.fetchone()\n\n    def get_vector_ids_of_results(\n        self,\n        name: str,\n        results: List[List[int]],\n        include: Dict\n    ):\n        \"\"\"\n        Get user facing IDs of results\n\n        name: Name of index\n        results: List of list of integer HNSW labels\n        \"\"\"\n        index_details = self.get_index_details(name)\n        if not(index_details):\n            return\n\n        cols = [sql.Identifier(\"id\")]\n        if include[\"document\"]:\n            cols.append(sql.Identifier(\"text\"))\n            if include[\"metadata\"]:\n                cols.append(sql.Identifier(\"metadata\"))\n        elif include[\"metadata\"]:\n            cols.append(sql.Identifier(\"metadata\"))\n\n        returning_list = []\n        unordered_rows_list = []\n        index_id = index_details[0]\n\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                data = []\n                for ids in results:\n                    ids_list = []\n                    for id in ids:\n                        ids_list.append(int(id))\n                    data.append([ids_list, index_id])\n\n                query = sql.SQL(queries.GET_VECTOR_IDS_OF_RESULTS).format(\n                    sql.SQL(\", \").join(cols)\n                )\n                cur.executemany(\n                    query,\n                    data,\n                    returning=True\n                )\n                while True:\n                    rows = cur.fetchall()\n                    unordered_rows_list.append(rows)\n                    if not cur.nextset():\n                        break;\n\n                conn.commit()\n\n        # Order rows according to order of id in ids list\n        for i, ids in enumerate(results):\n            unordered_rows = unordered_rows_list[i]\n            ordered_rows = []\n            for id in ids:\n                low = 0; high = len(unordered_rows) - 1\n                while (low <= high):\n                    mid = low + (high - low)//2\n                    curr_vector_id = unordered_rows[mid][0]\n                    if curr_vector_id == id:\n                        ordered_rows.append(\n                            convert_row_to_dict(\n                                row=unordered_rows[mid],\n                                include=include\n                            )\n                        )\n                        break\n                    elif curr_vector_id < id:\n                        low = mid + 1\n                    else:\n                        high = mid - 1\n\n            returning_list.append(ordered_rows)\n        return returning_list\n\n    def insert_to_index(\n        self,\n        data\n    ):\n        \"\"\"\n        Insert vectors to index\n\n        data: Tuple of tuples corresponding to each row\n        \"\"\"\n        vector_ids = []\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.executemany(queries.INSERT_DATA_TO_INDEX, data, returning=True)\n                while True:\n                    vector_ids.append(cur.fetchone()[0])        # type: ignore\n                    if not cur.nextset():\n                        break;\n\n                conn.commit()\n\n        return vector_ids\n\n    def update_ef(\n        self,\n        name: str,\n        ef: int\n    ):\n        \"\"\"\n        Update ef for an index\n\n        name: Name of index to be updated\n        ef: New ef value\n        \"\"\"\n        parameters = (ef, name)\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.UPDATE_EF, parameters)\n                conn.commit()", "\n\nclass PostgresDB(BaseDB):\n    _pool: ConnectionPool\n\n    def __init__(\n        self,\n        **kwargs: Dict[str, Any]\n    ):\n        # Setup connection pool\n        self._pool = ConnectionPool(kwargs=kwargs)\n\n        # Create index_manager and index_data table if they don't exist already\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.CREATE_INDEX_MANAGER_TABLE)\n                cur.execute(queries.CREATE_INDEX_DATA_TABLE)\n                conn.commit()\n\n    def create_index(\n        self,\n        name: str,\n        max_elements: int,\n        M: int,\n        ef_construction: int,\n        allow_replace_deleted: bool,\n        dimensions: Optional[int] = 1536,\n    ):\n        ef = ef_construction\n        parameters = (name, dimensions, max_elements, M, ef, ef_construction, allow_replace_deleted)\n        # Create new index entry to postgres db\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.INSERT_INDEX_TO_MANAGER, parameters)\n                conn.commit()\n\n    def delete_vectors_from_index(\n        self,\n        index_id: int,\n        ids: IDs\n    ):\n        \"\"\"\n        Delete vectors with given list of IDs from specific index\n\n        index_id: ID of index where the elements belong\n        ids: List of IDs to be deleted\n        \"\"\"\n\n        vector_ids = []\n        parameters = [ids, index_id]\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                for vector_id in cur.execute(queries.DELETE_VECTORS_FROM_INDEX, parameters):\n                    vector_ids.append(vector_id[0])\n                conn.commit()\n\n        return vector_ids\n\n    def filter_vectors(self, index_name: str, filters: List[Dict]):\n        \"\"\"\n        Get list of IDs of vectors that match filters.\n\n        index_name: Name of index where the elements belong\n        filters: List of filters to be applied\n        \"\"\"\n\n        with self._pool.connection() as conn:\n            query_builder = QueryBuilder(conn)\n            res = query_builder.execute_query(index_name, filters)\n            allowed_ids = []\n            for row in res:\n                allowed_ids.append(row[0])\n            return allowed_ids\n\n    def get_indices(self):\n        \"\"\"\n        Get all index details\n        \"\"\"\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.GET_ALL_INDEX_DETAILS)\n                return cur.fetchall()\n\n    def get_index_details(\n        self,\n        name: str\n    ) -> Optional[Tuple[int, str, int, int, int, int, int, bool]]:\n        \"\"\"\n        Get specific index details\n\n        name: Name of index to fetch\n        \"\"\"\n        parameters = (name,)\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.GET_INDEX_DETAILS_BY_NAME, parameters)\n                return cur.fetchone()\n\n    def get_vector_ids_of_results(\n        self,\n        name: str,\n        results: List[List[int]],\n        include: Dict\n    ):\n        \"\"\"\n        Get user facing IDs of results\n\n        name: Name of index\n        results: List of list of integer HNSW labels\n        \"\"\"\n        index_details = self.get_index_details(name)\n        if not(index_details):\n            return\n\n        cols = [sql.Identifier(\"id\")]\n        if include[\"document\"]:\n            cols.append(sql.Identifier(\"text\"))\n            if include[\"metadata\"]:\n                cols.append(sql.Identifier(\"metadata\"))\n        elif include[\"metadata\"]:\n            cols.append(sql.Identifier(\"metadata\"))\n\n        returning_list = []\n        unordered_rows_list = []\n        index_id = index_details[0]\n\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                data = []\n                for ids in results:\n                    ids_list = []\n                    for id in ids:\n                        ids_list.append(int(id))\n                    data.append([ids_list, index_id])\n\n                query = sql.SQL(queries.GET_VECTOR_IDS_OF_RESULTS).format(\n                    sql.SQL(\", \").join(cols)\n                )\n                cur.executemany(\n                    query,\n                    data,\n                    returning=True\n                )\n                while True:\n                    rows = cur.fetchall()\n                    unordered_rows_list.append(rows)\n                    if not cur.nextset():\n                        break;\n\n                conn.commit()\n\n        # Order rows according to order of id in ids list\n        for i, ids in enumerate(results):\n            unordered_rows = unordered_rows_list[i]\n            ordered_rows = []\n            for id in ids:\n                low = 0; high = len(unordered_rows) - 1\n                while (low <= high):\n                    mid = low + (high - low)//2\n                    curr_vector_id = unordered_rows[mid][0]\n                    if curr_vector_id == id:\n                        ordered_rows.append(\n                            convert_row_to_dict(\n                                row=unordered_rows[mid],\n                                include=include\n                            )\n                        )\n                        break\n                    elif curr_vector_id < id:\n                        low = mid + 1\n                    else:\n                        high = mid - 1\n\n            returning_list.append(ordered_rows)\n        return returning_list\n\n    def insert_to_index(\n        self,\n        data\n    ):\n        \"\"\"\n        Insert vectors to index\n\n        data: Tuple of tuples corresponding to each row\n        \"\"\"\n        vector_ids = []\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.executemany(queries.INSERT_DATA_TO_INDEX, data, returning=True)\n                while True:\n                    vector_ids.append(cur.fetchone()[0])        # type: ignore\n                    if not cur.nextset():\n                        break;\n\n                conn.commit()\n\n        return vector_ids\n\n    def update_ef(\n        self,\n        name: str,\n        ef: int\n    ):\n        \"\"\"\n        Update ef for an index\n\n        name: Name of index to be updated\n        ef: New ef value\n        \"\"\"\n        parameters = (ef, name)\n        with self._pool.connection() as conn:\n            with conn.cursor() as cur:\n                cur.execute(queries.UPDATE_EF, parameters)\n                conn.commit()", ""]}
{"filename": "citrusdb/db/postgres/queries.py", "chunked_list": ["CREATE_INDEX_MANAGER_TABLE = '''\nCREATE TABLE IF NOT EXISTS index_manager (\n    index_id BIGSERIAL PRIMARY KEY,\n    name TEXT NOT NULL UNIQUE,\n    dimensions INTEGER NOT NULL,\n    max_elements INTEGER NOT NULL,\n    m INTEGER NOT NULL,\n    ef INTEGER NOT NULL,\n    ef_construction INTEGER NOT NULL,\n    allow_replace_deleted BOOLEAN NOT NULL", "    ef_construction INTEGER NOT NULL,\n    allow_replace_deleted BOOLEAN NOT NULL\n);\n'''\n\nCREATE_INDEX_DATA_TABLE = '''\nCREATE TABLE IF NOT EXISTS index_data (\n    vector_id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,\n    id text NOT NULL,\n    index_id BIGINT,", "    id text NOT NULL,\n    index_id BIGINT,\n    text TEXT,\n    embedding JSONB NOT NULL,\n    metadata JSONB,\n    UNIQUE(id, index_id),\n    FOREIGN KEY(index_id) REFERENCES index_manager(index_id) ON DELETE CASCADE\n);\n'''\n", "'''\n\nDELETE_VECTORS_FROM_INDEX = '''\nDELETE FROM index_data\nWHERE id = ANY(%s) AND index_id = %s\nRETURNING vector_id\n'''\n\nGET_ALL_INDEX_DETAILS = '''\nSELECT index_id, name, dimensions, max_elements, m, ef, ef_construction, allow_replace_deleted", "GET_ALL_INDEX_DETAILS = '''\nSELECT index_id, name, dimensions, max_elements, m, ef, ef_construction, allow_replace_deleted\nFROM index_manager\n'''\n\nGET_INDEX_DETAILS_BY_NAME = '''\nSELECT index_id, name, dimensions, max_elements, m, ef, ef_construction, allow_replace_deleted\nFROM index_manager\nWHERE name = %s\n'''", "WHERE name = %s\n'''\n\nGET_VECTOR_IDS_OF_RESULTS = '''\nSELECT vector_id, {}\nFROM index_data\nWHERE vector_id = ANY(%s) AND index_id = %s\nORDER BY vector_id ASC\n'''\n", "'''\n\nINSERT_DATA_TO_INDEX = '''\nINSERT INTO index_data\n(id, index_id, text, embedding, metadata)\nVALUES(%s, %s, %s, %s, %s)\nON CONFLICT(id, index_id)\nDO UPDATE SET id = %s, index_id = %s, text = %s, embedding = %s, metadata = %s\nRETURNING vector_id\n'''", "RETURNING vector_id\n'''\n\nINSERT_INDEX_TO_MANAGER = '''\nINSERT INTO index_manager\n(name, dimensions, max_elements, m, ef, ef_construction, allow_replace_deleted)\nVALUES (%s, %s, %s, %s, %s, %s, %s);\n'''\n\nUPDATE_EF = '''", "\nUPDATE_EF = '''\nUPDATE index_manager\nSET ef = %s\nWHERE name = %s\n'''\n"]}
{"filename": "citrusdb/db/sqlite/query_builder.py", "chunked_list": ["import sqlite3\nfrom typing import Dict, List\n\nclass QueryBuilder:\n    _con: sqlite3.Connection\n\n    def __init__(self, connection):\n        self._con = connection\n\n    def build_query(self, index_name, filters):\n        # Building the base SQL query\n        sql_query = f\"SELECT d.vector_id, d.id, d.index_id, d.text FROM index_data d JOIN index_manager m ON m.index_id = d.index_id WHERE m.name = '{index_name}'\"\n\n        # Adding the filter criteria to the SQL query\n        if filters:\n            sql_query += \" AND \"\n            conditions = []\n            for filter in filters:\n                field = filter[\"field\"]\n                operator = filter[\"operator\"]\n                value = filter[\"value\"]\n                if isinstance(value, int) or isinstance(value, float):\n                    condition = f\"metadata ->> '{field}' {operator} {value}\"\n                else:\n                    condition = f\"metadata ->> '{field}' {operator} '{value}'\"\n                conditions.append(condition)\n            sql_query += \" AND \".join(conditions)\n\n        return sql_query\n\n    def execute_query(self, index_name: str, filters: List[Dict]):\n        cursor = self._con.cursor()\n\n        # Building and executing the query\n        sql_query = self.build_query(index_name, filters)\n        cursor.execute(sql_query)\n        results = cursor.fetchall()\n\n        return results", "\n"]}
{"filename": "citrusdb/db/sqlite/db.py", "chunked_list": ["import os\nimport sqlite3\nfrom typing import Dict, List, Optional, Tuple\n\nfrom citrusdb.db import BaseDB\nfrom citrusdb.utils.types import IDs\nfrom citrusdb.utils.utils import convert_row_to_dict, ensure_valid_path\nimport citrusdb.db.sqlite.queries as queries\nfrom citrusdb.db.sqlite.query_builder import QueryBuilder\n", "from citrusdb.db.sqlite.query_builder import QueryBuilder\n\n\nclass SQLiteDB(BaseDB):\n    _con: sqlite3.Connection\n\n    def __init__(\n        self,\n        persist_directory: str,\n    ):\n        ensure_valid_path(persist_directory)\n\n        self._con = sqlite3.connect(\n            os.path.join(\n                persist_directory, \"citrus.db\"\n            )\n        )\n\n        cur = self._con.cursor()\n        cur.execute(\"PRAGMA foreign_keys = ON\")    # Enable foreign keys\n        cur.executescript(f'''\n        BEGIN;\n        {queries.CREATE_INDEX_MANAGER_TABLE}\n        {queries.CREATE_INDEX_DATA_TABLE}\n        END;\n        ''')\n        cur.close()\n\n    def create_index(\n        self,\n        name: str,\n        max_elements: int,\n        M: int,\n        ef_construction: int,\n        allow_replace_deleted: bool,\n        dimensions: Optional[int] = 1536,\n    ):\n        cur = self._con.cursor()\n        ef = ef_construction\n        parameters = (name, dimensions, max_elements, M, ef, ef_construction, allow_replace_deleted)\n        cur.execute(queries.INSERT_INDEX_TO_MANAGER, parameters)\n        self._con.commit()\n        cur.close()\n\n    def delete_vectors_from_index(\n        self,\n        index_id: int,\n        ids: IDs\n    ):\n        cur = self._con.cursor()\n        query = queries.DELETE_VECTORS_FROM_INDEX.format(\", \".join(\"?\" * len(ids)))\n        parameters = tuple(ids) + (index_id,)\n        cur.execute(query, parameters)\n\n        rows = cur.fetchall()\n        self._con.commit()\n        cur.close()\n\n        vector_ids = [row[0] for row in rows]\n        return vector_ids\n\n    def filter_vectors(self, index_name: str, filters: List[Dict]):\n        query_builder = QueryBuilder(self._con)\n        res = query_builder.execute_query(index_name, filters)\n        allowed_ids = []\n        for row in res:\n            allowed_ids.append(row[0])\n        return allowed_ids\n\n    def get_indices(self):\n        \"\"\"\n        Fetch all index details from index_manager table.\n        Returns a list of tuples where each one corresponds to an index.\n        \"\"\"\n\n        cur = self._con.cursor()\n        res = cur.execute(queries.GET_ALL_INDEX_DETAILS)\n        rows = res.fetchall()\n        cur.close()\n        return rows\n\n    def get_index_details(\n        self,\n        name: str\n    ) -> Optional[Tuple[int, str, int, int, int, int, int, bool]]:\n        cur = self._con.cursor()\n        parameters = (name,)\n        res = cur.execute(queries.GET_INDEX_DETAILS_BY_NAME, parameters)\n        row = res.fetchone()\n        cur.close()\n        return row\n\n    def get_vector_ids_of_results(\n        self,\n        name: str,\n        results: List[List[int]],\n        include: Dict\n    ) -> List[List[Dict]]:\n        cols = \"id\"\n        if include[\"document\"]:\n            cols += \", text\"\n            if include[\"metadata\"]:\n                cols += \", metadata\"\n        elif include[\"metadata\"]:\n            cols += \", metadata\"\n\n        returning_list = []\n        index_details = self.get_index_details(name)\n        index_id = index_details[0]                 # type: ignore\n\n        cur = self._con.cursor()\n        for ids in results:\n            query = queries.GET_VECTOR_IDS_OF_RESULTS.format(cols, \", \".join(\"?\" * len(ids)))\n            parameters = ()\n            for id in ids:\n                parameters += (int(id),)\n            parameters += (index_id,)\n            res = cur.execute(query, parameters)\n            unordered_rows = res.fetchall()         # Rows not ordered according to similarity score\n\n            # Order rows according to order of id in ids list\n            ordered_rows = []\n            for id in ids:\n                low = 0; high = len(unordered_rows) - 1\n                while (low <= high):\n                    mid = low + (high - low)//2\n                    curr_vector_id = unordered_rows[mid][0]\n                    if curr_vector_id == id:\n                        ordered_rows.append(\n                            convert_row_to_dict(\n                                row=unordered_rows[mid],\n                                include=include\n                            )\n                        )\n                        break\n                    elif curr_vector_id < id:\n                        low = mid + 1\n                    else:\n                        high = mid - 1\n\n            returning_list.append(ordered_rows)\n        cur.close()\n\n        return returning_list\n\n    def insert_to_index(\n        self,\n        data\n    ):\n        cur = self._con.cursor()\n        vector_ids = []\n        for row in data:\n            res = cur.execute(queries.INSERT_DATA_TO_INDEX, row)\n            vector_ids.append(res.fetchone()[0])\n\n        self._con.commit()\n        cur.close()\n\n        return vector_ids\n\n    def update_ef(\n        self,\n        name: str,\n        ef: int\n    ):\n        cur = self._con.cursor()\n        parameters = (ef, name)\n        cur.execute(queries.UPDATE_EF, parameters)\n        self._con.commit()\n        cur.close()", ""]}
{"filename": "citrusdb/db/sqlite/__init__.py", "chunked_list": [""]}
{"filename": "citrusdb/db/sqlite/queries.py", "chunked_list": ["CREATE_INDEX_MANAGER_TABLE = '''\nCREATE TABLE IF NOT EXISTS index_manager (\n    index_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    name TEXT NOT NULL UNIQUE,\n    dimensions INTEGER NOT NULL,\n    max_elements INTEGER NOT NULL,\n    m INTEGER NOT NULL,\n    ef INTEGER NOT NULL,\n    ef_construction INTEGER NOT NULL,\n    allow_replace_deleted INTEGER NOT NULL", "    ef_construction INTEGER NOT NULL,\n    allow_replace_deleted INTEGER NOT NULL\n);\n'''\n\nCREATE_INDEX_DATA_TABLE = '''\nCREATE TABLE IF NOT EXISTS index_data (\n    vector_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    id TEXT NOT NULL,\n    index_id INTEGER,", "    id TEXT NOT NULL,\n    index_id INTEGER,\n    text TEXT,\n    embedding BLOB NOT NULL,\n    metadata TEXT,\n    UNIQUE(id, index_id),\n    FOREIGN KEY(index_id) REFERENCES index_manager(index_id) ON DELETE CASCADE\n);\n'''\n", "'''\n\nDELETE_VECTORS_FROM_INDEX = '''\nDELETE FROM index_data\nWHERE id IN ({}) AND index_id = ?\nRETURNING vector_id\n'''\n\nGET_ALL_INDEX_DETAILS = '''\nSELECT index_id, name, dimensions, max_elements, m, ef, ef_construction, allow_replace_deleted", "GET_ALL_INDEX_DETAILS = '''\nSELECT index_id, name, dimensions, max_elements, m, ef, ef_construction, allow_replace_deleted\nFROM index_manager\n'''\n\nGET_INDEX_DETAILS_BY_NAME = '''\nSELECT index_id, name, dimensions, max_elements, m, ef, ef_construction, allow_replace_deleted\nFROM index_manager\nWHERE name = ?\n'''", "WHERE name = ?\n'''\n\nGET_VECTOR_IDS_OF_RESULTS = '''\nSELECT vector_id, {}\nFROM index_data\nWHERE vector_id IN ({}) AND index_id = ?\nORDER BY vector_id ASC\n'''\n", "'''\n\nINSERT_DATA_TO_INDEX = '''\nINSERT INTO index_data\n(id, index_id, text, embedding, metadata)\nVALUES(?, ?, ?, ?, ?)\nON CONFLICT(id, index_id)\nDO UPDATE SET id = ?, index_id = ?, text = ?, embedding = ?, metadata = ?\nRETURNING vector_id\n'''", "RETURNING vector_id\n'''\n\nINSERT_INDEX_TO_MANAGER = '''\nINSERT INTO index_manager\n(name, dimensions, max_elements, m, ef, ef_construction, allow_replace_deleted)\nVALUES (?, ?, ?, ?, ?, ?, ?);\n'''\n\nUPDATE_EF = '''", "\nUPDATE_EF = '''\nUPDATE index_manager\nSET ef = ?\nWHERE name = ?\n'''\n"]}
{"filename": "citrusdb/api/local.py", "chunked_list": ["import enum\nimport os\nimport json\nfrom typing import Any, Dict, List, Optional\nfrom numpy import float32\nfrom numpy._typing import NDArray\nimport shutil\n\nfrom citrusdb.api.index import Index\nfrom citrusdb.db import BaseDB", "from citrusdb.api.index import Index\nfrom citrusdb.db import BaseDB\nfrom citrusdb.db.postgres.db import PostgresDB\nfrom citrusdb.db.sqlite.db import SQLiteDB\nfrom citrusdb.utils.types import IDs\n\n\nclass LocalAPI:\n    _db: Dict[str, Index] \n    _SQLClient: BaseDB\n    persist_directory: Optional[str]\n    _TEMP_DIRECTORY = \"citrus_temp\"\n\n    def __init__(\n        self,\n        persist_directory: Optional[str] = None,\n        database_type: Optional[str] = \"sqlite\",\n        **kwargs: Optional[Dict[str, Any]]\n    ):\n        self._db = {}\n        self.persist_directory = persist_directory\n\n        if not(persist_directory) and os.path.isdir(self._TEMP_DIRECTORY):\n            # Cleanup previous sqlite data\n            shutil.rmtree(self._TEMP_DIRECTORY)\n\n        if persist_directory and (database_type == \"pg\" or database_type == \"postgres\"):\n            self._SQLClient = PostgresDB(**kwargs)\n        else:\n            self._SQLClient = SQLiteDB(persist_directory if persist_directory else self._TEMP_DIRECTORY)\n\n    def create_index(\n        self,\n        name: str,\n        max_elements: int = 1000,\n        M: int = 64,\n        ef_construction: int = 200,\n        allow_replace_deleted: bool = False,\n    ):\n        if not(self._SQLClient.get_index_details(name)):\n            self._SQLClient.create_index(\n                name,\n                max_elements,\n                M,\n                ef_construction,\n                allow_replace_deleted\n            )\n\n        self._db[name] = Index(\n            name=name,\n            max_elements=max_elements,\n            persist_directory=self.persist_directory,\n            M=M,\n            ef_construction=ef_construction,\n            allow_replace_deleted=allow_replace_deleted\n        )\n\n    def add(\n        self,\n        index: str,\n        ids: IDs,\n        documents: Optional[List[str]] = None,\n        embeddings: Optional[NDArray[float32]] = None,\n        metadatas: Optional[List[Dict]] = None\n    ):\n        \"\"\"\n        Insert embeddings/text documents\n\n        index: Name of index\n        ids: Unique ID for each element\n        documents: List of strings to index\n        embeddings: List of embeddings to index\n        metadatas: Additional metadata for each vector\n        \"\"\"\n\n        if embeddings is None and documents is None:\n            raise ValueError(\"Please provide either embeddings or documents.\")\n\n        index_details = self._SQLClient.get_index_details(index)\n        if index_details is None:\n            raise ValueError(f\"Index with name '{index}' does not exist.\")\n\n        if (documents is not None) and (embeddings is None):\n            from citrusdb.embedding.openai import get_embeddings\n\n            embeddings = get_embeddings(documents)\n\n        if embeddings is not None:\n            embedding_dim = len(embeddings[0])\n            index_id = index_details[0]\n            index_dim = index_details[2]\n            replace_deleted = True if index_details[7] else False\n\n            # Check whether the dimensions are equal\n            if embedding_dim != index_dim:\n                raise ValueError(\n                        f\"Embedding dimenstion ({embedding_dim}) and index \"\n                        + f\"dimension ({index_dim}) do not match.\"\n                        )\n\n            # Ensure no of ids = no of embeddings\n            if len(ids) != len(embeddings):\n                raise ValueError(f\"Number of embeddings\" + \" and ids are different.\")\n\n            data = []\n            for i in range(len(ids)):\n                row = (\n                    ids[i],\n                    index_id,\n                    None if documents is None else documents[i],\n                    json.dumps(embeddings[i].tolist()),\n                    None if metadatas is None else json.dumps(metadatas[i])\n                )\n                data.append(row + row)\n\n            # Insert data into DB\n            hnsw_labels = self._SQLClient.insert_to_index(data)\n\n            # Index vectors\n            self._db[index].add(\n                ids=hnsw_labels,\n                embeddings=embeddings,\n                replace_deleted=replace_deleted\n            )\n\n    def delete_vectors(\n        self,\n        index: str,\n        ids: IDs\n    ):\n        index_details = self._SQLClient.get_index_details(index)\n        if index_details is None:\n            raise ValueError(f\"Could not find index: {index}\")\n\n        index_id = index_details[0]\n        hnsw_labels = self._SQLClient.delete_vectors_from_index(\n            index_id=index_id,\n            ids=ids\n        )\n\n        self._db[index].delete_vectors(hnsw_labels)\n\n    def reload_indices(self):\n        \"\"\"\n        Load all indices from disk to memory\n        \"\"\"\n\n        indices = self._SQLClient.get_indices()\n        for index in indices:\n            index_name = index[1]\n            # Load index\n            self.create_index(\n                name=index_name,\n                max_elements=index[3],\n                M=index[4],\n                ef_construction=index[6],\n                allow_replace_deleted=index[7]\n            )\n            # Set ef value\n            self._db[index_name].set_ef(index[5])\n\n    def set_ef(self, index: str, ef: int):\n        index_details = self._SQLClient.get_index_details(index)\n        if index_details is None:\n            raise ValueError(f\"Could not find index: {index}\")\n\n        self._SQLClient.update_ef(index, ef)\n        self._db[index].set_ef(ef)\n\n    def query(\n        self,\n        index: str,\n        documents: Optional[List[str]] = None,\n        query_embeddings: Optional[NDArray[float32]] = None,\n        k=1,\n        filters: Optional[List[Dict]] = None,\n        include: List[str] = []\n    ):\n        allowed_ids = []\n        if filters is not None:\n            allowed_ids = self._SQLClient.filter_vectors(index, filters)\n\n        filter_function = lambda label: label in allowed_ids\n\n        included_columns = {\"id\": True, \"document\": False, \"metadata\": False}\n        if \"document\" in include:\n            included_columns[\"document\"] = True\n        if \"metadata\" in include:\n            included_columns[\"metadata\"] = True\n\n        flag = 1\n        for key in self._db.keys():\n            if key == index:\n                flag = 0\n                results, distances = self._db[key].query(\n                    documents=documents,\n                    query_embeddings=query_embeddings,\n                    k=k,\n                    filter_function=None if filters is None else filter_function\n                )\n                elements = self._SQLClient.get_vector_ids_of_results(\n                    name=index,\n                    results=results,\n                    include=included_columns\n                )\n                for i, rows in enumerate(elements):\n                    for j, row in enumerate(rows):\n                        row[\"distance\"] = distances[i][j]\n                return elements\n\n        if flag:\n            raise ValueError(f\"Could not find index: {index}\")\n\n\n    def get_status(self, index: str):\n        flag = 1\n        for key in self._db.keys():\n            if key == index:\n                flag = 0\n                self._db[key].get_status()\n\n        if flag:\n            raise ValueError(f\"Could not find index: {index}\")", ""]}
{"filename": "citrusdb/api/__init__.py", "chunked_list": [""]}
{"filename": "citrusdb/api/index.py", "chunked_list": ["import os\nimport pickle\nfrom typing import Any, List, Optional\nfrom numpy import float32\nfrom numpy._typing import NDArray\nfrom citrusdb.db.index.hnswlib import HnswIndex\nfrom citrusdb.utils.types import IDs\nfrom citrusdb.utils.utils import ensure_valid_path\n\n\nclass Index:\n    _db: HnswIndex\n    _parameters: dict\n\n    def __init__(\n        self,\n        name: str,\n        max_elements: int = 1000,\n        persist_directory: Optional[str] = None,\n        M: int = 64,\n        ef_construction: int = 200,\n        allow_replace_deleted: bool = False,\n    ):\n        self._db = HnswIndex(id=name)\n\n        self._parameters = {\n            \"index_name\": name,\n            \"max_elements\": max_elements,\n            \"persist_directory\": persist_directory,\n            \"M\": M,\n            \"ef_construction\": ef_construction,\n            \"allow_replace_deleted\": allow_replace_deleted,\n        }\n\n        if persist_directory:\n            self._load_params()\n\n            if ensure_valid_path(persist_directory, str(self._parameters[\"index_name\"])):\n                self._db.load_index(\n                    os.path.join(\n                        persist_directory, str(self._parameters[\"index_name\"])\n                    ),\n                    allow_replace_deleted=bool(\n                        self._parameters[\"allow_replace_deleted\"]\n                    ),\n                )\n            else:\n                self._db.init_index(\n                    max_elements=max_elements,\n                    M=M,\n                    ef_construction=ef_construction,\n                    allow_replace_deleted=allow_replace_deleted,\n                )\n                self._save()\n        else:\n            self._db.init_index(\n                max_elements=max_elements,\n                M=M,\n                ef_construction=ef_construction,\n                allow_replace_deleted=allow_replace_deleted,\n            )\n\n    def add(\n        self,\n        ids: List[int],\n        embeddings: Optional[NDArray[float32]],\n        replace_deleted: bool,\n    ):\n        self._db.add_items(embeddings, ids, replace_deleted)\n        if self._parameters[\"persist_directory\"]:\n            self._save()\n\n    def _load_params(self):\n        if ensure_valid_path(self._parameters[\"persist_directory\"], \".citrus_params\"):\n            filename = os.path.join(\n                self._parameters[\"persist_directory\"], \".citrus_params\"\n            )\n            with open(filename, \"rb\") as f:\n                self._parameters = pickle.load(f)\n\n    def delete_vectors(self, ids: List[int]):\n        for id in ids:\n            self._db.mark_deleted(id)\n        if self._parameters[\"persist_directory\"]:\n            self._save()\n\n    def _save(self):\n        self._db.save_index(\n            os.path.join(\n                self._parameters[\"persist_directory\"], self._parameters[\"index_name\"]\n            )\n        )\n        self._save_params()\n\n    def _save_params(self):\n        output_file = os.path.join(\n            self._parameters[\"persist_directory\"], \".citrus_params\"\n        )\n        with open(output_file, \"wb\") as f:\n            pickle.dump(self._parameters, f)\n\n    def set_ef(self, ef: int):\n        self._db.set_ef(ef)\n\n    def query(\n        self,\n        documents: Optional[List[str]] = None,\n        query_embeddings: Optional[NDArray[float32]] = None,\n        k=1,\n        filter_function=None\n    ):\n        if query_embeddings is None and documents is None:\n            raise ValueError(\"Please provide either an embedding\" + \" or a document.\")\n\n        if documents is not None:\n            from citrusdb.embedding.openai import get_embeddings\n\n            embeddings = get_embeddings(documents)\n            query_embeddings = embeddings\n\n        return self._db.knn_query(query_embeddings, k, filter_function)\n\n    def get_status(self):\n        self._db.get_status()\n\n    def get_dimension(self):\n        return self._db.get_dimension()\n\n    def get_replace_deleted(self):\n        return self._parameters[\"allow_replace_deleted\"]", "\n\nclass Index:\n    _db: HnswIndex\n    _parameters: dict\n\n    def __init__(\n        self,\n        name: str,\n        max_elements: int = 1000,\n        persist_directory: Optional[str] = None,\n        M: int = 64,\n        ef_construction: int = 200,\n        allow_replace_deleted: bool = False,\n    ):\n        self._db = HnswIndex(id=name)\n\n        self._parameters = {\n            \"index_name\": name,\n            \"max_elements\": max_elements,\n            \"persist_directory\": persist_directory,\n            \"M\": M,\n            \"ef_construction\": ef_construction,\n            \"allow_replace_deleted\": allow_replace_deleted,\n        }\n\n        if persist_directory:\n            self._load_params()\n\n            if ensure_valid_path(persist_directory, str(self._parameters[\"index_name\"])):\n                self._db.load_index(\n                    os.path.join(\n                        persist_directory, str(self._parameters[\"index_name\"])\n                    ),\n                    allow_replace_deleted=bool(\n                        self._parameters[\"allow_replace_deleted\"]\n                    ),\n                )\n            else:\n                self._db.init_index(\n                    max_elements=max_elements,\n                    M=M,\n                    ef_construction=ef_construction,\n                    allow_replace_deleted=allow_replace_deleted,\n                )\n                self._save()\n        else:\n            self._db.init_index(\n                max_elements=max_elements,\n                M=M,\n                ef_construction=ef_construction,\n                allow_replace_deleted=allow_replace_deleted,\n            )\n\n    def add(\n        self,\n        ids: List[int],\n        embeddings: Optional[NDArray[float32]],\n        replace_deleted: bool,\n    ):\n        self._db.add_items(embeddings, ids, replace_deleted)\n        if self._parameters[\"persist_directory\"]:\n            self._save()\n\n    def _load_params(self):\n        if ensure_valid_path(self._parameters[\"persist_directory\"], \".citrus_params\"):\n            filename = os.path.join(\n                self._parameters[\"persist_directory\"], \".citrus_params\"\n            )\n            with open(filename, \"rb\") as f:\n                self._parameters = pickle.load(f)\n\n    def delete_vectors(self, ids: List[int]):\n        for id in ids:\n            self._db.mark_deleted(id)\n        if self._parameters[\"persist_directory\"]:\n            self._save()\n\n    def _save(self):\n        self._db.save_index(\n            os.path.join(\n                self._parameters[\"persist_directory\"], self._parameters[\"index_name\"]\n            )\n        )\n        self._save_params()\n\n    def _save_params(self):\n        output_file = os.path.join(\n            self._parameters[\"persist_directory\"], \".citrus_params\"\n        )\n        with open(output_file, \"wb\") as f:\n            pickle.dump(self._parameters, f)\n\n    def set_ef(self, ef: int):\n        self._db.set_ef(ef)\n\n    def query(\n        self,\n        documents: Optional[List[str]] = None,\n        query_embeddings: Optional[NDArray[float32]] = None,\n        k=1,\n        filter_function=None\n    ):\n        if query_embeddings is None and documents is None:\n            raise ValueError(\"Please provide either an embedding\" + \" or a document.\")\n\n        if documents is not None:\n            from citrusdb.embedding.openai import get_embeddings\n\n            embeddings = get_embeddings(documents)\n            query_embeddings = embeddings\n\n        return self._db.knn_query(query_embeddings, k, filter_function)\n\n    def get_status(self):\n        self._db.get_status()\n\n    def get_dimension(self):\n        return self._db.get_dimension()\n\n    def get_replace_deleted(self):\n        return self._parameters[\"allow_replace_deleted\"]", "\n"]}
{"filename": "citrusdb/embedding/openai.py", "chunked_list": ["import os\nimport numpy as np\nimport openai\nfrom typing import List\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n\ndef get_embeddings(data: List[str], model=\"text-embedding-ada-002\"):\n    strings = [text.replace(\"\\n\", \" \") for text in data]\n\n    response = openai.Embedding.create(model=model, input=strings)\n\n    return np.array([result[\"embedding\"] for result in response[\"data\"]], dtype=np.float32)", "def get_embeddings(data: List[str], model=\"text-embedding-ada-002\"):\n    strings = [text.replace(\"\\n\", \" \") for text in data]\n\n    response = openai.Embedding.create(model=model, input=strings)\n\n    return np.array([result[\"embedding\"] for result in response[\"data\"]], dtype=np.float32)\n"]}
{"filename": "citrusdb/embedding/__init__.py", "chunked_list": [""]}
{"filename": "demo/demo.py", "chunked_list": ["import citrusdb\nimport json\n\n# Instantiate citrusdb\ncitrus = citrusdb.Client()\n\n# Create index\ncitrus.create_index(\n    name=\"pokemon\",\n    max_elements=50,", "    name=\"pokemon\",\n    max_elements=50,\n)\n\npokemons = []\ndocuments = []\nids = []\nwith open(\"demo/pokemon.jsonl\", \"r\") as f:\n    for line in f:\n        pokemon = json.loads(line)\n        pokemons.append(pokemon)\n        documents.append(pokemon[\"info\"][\"description\"])\n        ids.append(pokemon[\"info\"][\"id\"])", "\n# Insert documents to index\ncitrus.add(\"pokemon\", ids, documents=documents)\ncitrus.get_status(\"pokemon\")\n\ncitrus.delete_vectors(\"pokemon\", [\"143\"])\n\n# Query with a text input\nres = citrus.query(\n    \"pokemon\",", "res = citrus.query(\n    \"pokemon\",\n    documents=[\"Likes to sleep\"],\n    k=5\n)\n\ndef find_pokemon(id):\n    for pokemon in pokemons:\n        if (pokemon[\"info\"][\"id\"] == int(id)):\n            print(format(pokemon))\n            break", "def format(pokemon):\n    return f\"\"\"Name: {pokemon[\"name\"]}\nPokedex ID: {pokemon[\"info\"][\"id\"]}\nType: {pokemon[\"info\"][\"type\"]}\nDescription: {pokemon[\"info\"][\"description\"]}\n\"\"\"\n\nif res:\n    ids_list, distances = res\n\n    # Print results\n    for ids in ids_list:\n        for id in ids:\n            find_pokemon(id)", ""]}
