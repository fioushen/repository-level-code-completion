{"filename": "setup.py", "chunked_list": ["# -*- coding: utf-8 -*-\nfrom setuptools import setup, find_packages\n\nwith open('README.md', encoding='utf-8') as f:\n    long_description = f.read()\n\nwith open('requirements.txt', encoding='utf-8') as f:\n    requirements = f.read().strip().split('\\n')\n\npkgs = find_packages(where='src')", "\npkgs = find_packages(where='src')\nprint(pkgs)\n\nsetup(\n    name='ask-api',\n    version='0.1.0',\n    url='https://github.com/yanqingmen/ask-api',\n    license=\"Apache License 2.0\",\n    long_description=long_description,", "    license=\"Apache License 2.0\",\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    author='yanqingmen',\n    python_requires='>=3.7',\n    install_requires=requirements,\n    package_dir={\"\": \"src\"},\n    packages=pkgs,\n)\n", ")\n"]}
{"filename": "tests/llm/__init__.py", "chunked_list": [""]}
{"filename": "tests/llm/llm_util_test.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nllm util test\n\"\"\"\nfrom ask_api.llm.base import LLMBase\nfrom ask_api.config import askapi_config\nfrom ask_api.llm.llm_util import build_default_llm\n\n\ndef split_text(text: str, sep: str = \" \") -> list:\n    \"\"\"\n    demo function\n    \"\"\"\n    return text.split(sep)", "\ndef split_text(text: str, sep: str = \" \") -> list:\n    \"\"\"\n    demo function\n    \"\"\"\n    return text.split(sep)\n\n\ndef test_build_default_llm():\n    llm = build_default_llm()\n    assert issubclass(llm.__class__, LLMBase)", "def test_build_default_llm():\n    llm = build_default_llm()\n    assert issubclass(llm.__class__, LLMBase)\n\n\ndef test_lang():\n    askapi_config.LANG = \"zh\"\n    zh_llm = build_default_llm()\n    print(\"zh_llm desc: \", zh_llm.desc(split_text))\n\n    askapi_config.LANG = \"en\"\n    en_llm = build_default_llm()\n    print(\"en_llm desc: \", en_llm.desc(split_text))", "\n\n"]}
{"filename": "tests/util/askapi_asyn_test.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\n\u6d4b\u8bd5\u5f02\u6b65\u8c03\u7528\u51fd\u6570\u76f8\u5173\u5de5\u5177\n\"\"\"\n\nfrom ask_api.util.askapi_asyn import run_async_task, wait_task\n\n\ndef test_run_async_task():\n    async def func():\n        return 1\n\n    task = run_async_task(func())\n    assert wait_task(task) == 1", "def test_run_async_task():\n    async def func():\n        return 1\n\n    task = run_async_task(func())\n    assert wait_task(task) == 1\n"]}
{"filename": "tests/util/__init__.py", "chunked_list": [""]}
{"filename": "src/ask_api/ask_api.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nask api, talk with your python code\n\"\"\"\nfrom ask_api.base.session import Session, Message\nfrom ask_api.llm.llm_util import build_default_llm\nfrom ask_api.base.role import FunctionRole, UserRole, Role\nfrom ask_api.util.askapi_log import logging\n\nGLOBAL_SESSIONS = {}", "\nGLOBAL_SESSIONS = {}\nFUNCTION_ROLES = {}\n\n# \u7528\u6237\u89d2\u8272\uff0c\u76ee\u524d\u53ea\u7528\u4e8e\u5360\u4f4d\uff0c\u540e\u7eed\u6dfb\u52a0\u4ea4\u4e92\u529f\u80fd\nDEFAULT_USER_ROLE = UserRole(\"user\")\n\n\ndef create_func_role(func, name: str = None) -> Role:\n    \"\"\"\n    create function role\n    \"\"\"\n    if func in FUNCTION_ROLES:\n        return FUNCTION_ROLES[func]\n\n    logging.info(\"create function role for: {}\".format(func.__name__))\n    llm = build_default_llm()\n    role = FunctionRole(llm, func, name)\n    FUNCTION_ROLES[func] = role\n    return role", "def create_func_role(func, name: str = None) -> Role:\n    \"\"\"\n    create function role\n    \"\"\"\n    if func in FUNCTION_ROLES:\n        return FUNCTION_ROLES[func]\n\n    logging.info(\"create function role for: {}\".format(func.__name__))\n    llm = build_default_llm()\n    role = FunctionRole(llm, func, name)\n    FUNCTION_ROLES[func] = role\n    return role", "\n\ndef ask_func(func,\n             message: str,\n             mode: str = \"free\",\n             user_role: Role = None,\n             func_name: str = None,\n             session: Session = None) -> Session:\n    \"\"\"\n    ask function\n    \"\"\"\n    if session is None:\n        session_id = str(id(func))\n        if session_id not in GLOBAL_SESSIONS:\n            GLOBAL_SESSIONS[session_id] = Session()\n        session = GLOBAL_SESSIONS[session_id]\n\n    if user_role is None:\n        user_role = DEFAULT_USER_ROLE\n\n    if not mode == \"desc\":\n        # \u4ec5\u5728\u975e\u63cf\u8ff0\u6a21\u5f0f\u4e0b\uff0c\u624d\u5c06\u7528\u6237\u8f93\u5165\u52a0\u5165\u4f1a\u8bdd\n        question = Message(user_role, message)\n        session.add_message(question)\n\n    func_role = create_func_role(func, func_name)\n    # session \u4f5c\u4e3a\u53c2\u6570\u4f20\u5165\uff0c\u65b9\u4fbf\u5f02\u6b65\u51fd\u6570\u8c03\u7528\u65f6\u4f7f\u7528\n    answer = func_role.answer(message, mode, session)\n    session.add_message(answer)\n    return session", "\n\ndef get_session(func):\n    \"\"\"\n    get session\n    \"\"\"\n    session_id = str(id(func))\n    if session_id not in GLOBAL_SESSIONS:\n        GLOBAL_SESSIONS[session_id] = Session()\n    return GLOBAL_SESSIONS[session_id]", ""]}
{"filename": "src/ask_api/__init__.py", "chunked_list": ["\n\n"]}
{"filename": "src/ask_api/config/__init__.py", "chunked_list": [""]}
{"filename": "src/ask_api/config/askapi_config.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nask api \u76f8\u5173\u57fa\u7840\u914d\u7f6e\n\"\"\"\nimport os\n\n# \u8bed\u8a00\u914d\u7f6e\uff0czh \u4e3a\u4e2d\u6587\uff0cen \u4e3a\u82f1\u6587\nLANG = \"zh\"\n\n# llm\u6a21\u578b\u9605\u8bfb\u51fd\u6570\u7684\u6700\u5927\u957f\u5ea6", "\n# llm\u6a21\u578b\u9605\u8bfb\u51fd\u6570\u7684\u6700\u5927\u957f\u5ea6\nMAX_FUNC_LEN = 1024\n\n# \u662f\u5426\u4e3adebug\u6a21\u578b\nASK_API_DEBUG = False\n\n# openai api key path\nOPENAI_KEY_PATH = \"config/open-ai.key\"\nOPENAI_KEY = None", "OPENAI_KEY_PATH = \"config/open-ai.key\"\nOPENAI_KEY = None\n\n# DEFAULT_LLM_MODEL\nDEFAULT_LLM_MODEL = \"openai_chat\"\nDEFAULT_OPENAI_CHAT_MODEL = \"gpt-3.5-turbo\"\n"]}
{"filename": "src/ask_api/prompt/__init__.py", "chunked_list": [""]}
{"filename": "src/ask_api/prompt/basic.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\n\u57fa\u7840prompt\uff0c\u5305\u542b \u4e2d\u6587 \u4ee5\u53ca \u82f1\u6587\n\"\"\"\n\nZH_BASIC_PROMPT = {\n    \"system_prompt\": \"\u4e0b\u9762\u662f\u4e00\u6bb5\u51fd\u6570\u4ee3\u7801\uff0c\u73b0\u5728\u7531\u4f60\u626e\u6f14\u8fd9\u4e2a\u51fd\u6570\uff0c\u4f7f\u7528\u7b2c\u4e00\u4eba\u79f0\u56de\u7b54\u7528\u6237\u5bf9\u4e8e\u8fd9\u4e2a\u51fd\u6570\u7684\u76f8\u5173\u95ee\u9898\u3002\\n\u4ee5\u4e0b\u662f\u51fd\u6570\u4ee3\u7801\uff1a {code_source}\",\n    # \u7528\u4e8e\u7ed9llm\u8fdb\u884c\u793a\u4f8b\u7684prompt\uff0c\u53ef\u4ee5\u4e0d\u63d0\u4f9b\uff0c\u4ee5\u51cf\u5c11token\u6570\u91cf\uff0c\u53ef\u4ee5\u5bf9\u6bd4\u4e0d\u63d0\u4f9b\u793a\u4f8b\u65f6\u7684\u6548\u679c\n    \"system_example_prompt\": [\n        {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"\u4f60\u597d\uff0c\u8bf7\u95ee\u4f60\u80fd\u5e2e\u6211\u505a\u4ec0\u4e48\uff1f\"},", "    \"system_example_prompt\": [\n        {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"\u4f60\u597d\uff0c\u8bf7\u95ee\u4f60\u80fd\u5e2e\u6211\u505a\u4ec0\u4e48\uff1f\"},\n        {\"role\": \"system\", \"name\": \"example_assistant\",\n         \"content\": \"\u4f60\u597d\uff0c\u6211\u662f{\u51fd\u6570\u540d}\uff0c\u6211\u80fd\u591f\u5e2e\u52a9\u4f60{\u51fd\u6570\u529f\u80fd\u63cf\u8ff0}\uff0c\u5982\u679c\u9700\u8981\u6211\u7684\u5e2e\u52a9\uff0c\u8bf7\u5bf9\u6211\u8bf4{\u6307\u4ee4\u8bf4\u660e}\"},\n    ],\n    \"desc_prompt\": \"\u4f60\u597d\uff0c\u8bf7\u95ee\u4f60\u80fd\u5e2e\u6211\u505a\u4ec0\u4e48\uff1f\",\n    \"execute_prompt\": \"\u8bf7\u5c06\u4e0b\u9762\u7684\u7528\u6237\u8bf7\u6c42\u8f6c\u6362\u4e3a\u4f60\u53ef\u63a5\u6536\u7684\u53c2\u6570\uff0c\u8868\u793a\u4e3ajson\u683c\u5f0f\uff0c\u82e5\u65e0\u6cd5\u8f6c\u6362\u65f6\uff0c\u8bf7\u56de\u7b54\u7f3a\u5c11\u7684\u53c2\u6570\u4fe1\u606f\u3002\\n\u7528\u6237\u8bf7\u6c42\uff1a{message}\",\n    \"exception_prompt\": \"\u5047\u8bbe\u4e0b\u9762\u662f\u4f60\u5728\u6267\u884c\u65f6\u629b\u51fa\u7684\u5f02\u5e38\u4fe1\u606f\uff0c\u8bf7\u8bf4\u660e\u5176\u5185\u5bb9.\\n\u5f02\u5e38\u4fe1\u606f\uff1a{message}\",\n    \"return_prompt\": \"\u5047\u8bbe\u4e0b\u9762\u662f\u4f60\u7684\u8fd4\u56de\u7ed3\u679c\uff0c\u8bf7\u7528\u8bf4\u660e\u4e00\u4e0b\u8fd4\u56de\u7684\u4fe1\u606f\u3002\\n\u8fd4\u56de\u503c\uff1a{message}\",\n    \"execute_message\": \"\u6211\u5df2\u7ecf\u5f00\u59cb\u5904\u7406\u4efb\u52a1\u4e86\uff0c\u8bf7\u7a0d\u7b49\u3002\",", "    \"return_prompt\": \"\u5047\u8bbe\u4e0b\u9762\u662f\u4f60\u7684\u8fd4\u56de\u7ed3\u679c\uff0c\u8bf7\u7528\u8bf4\u660e\u4e00\u4e0b\u8fd4\u56de\u7684\u4fe1\u606f\u3002\\n\u8fd4\u56de\u503c\uff1a{message}\",\n    \"execute_message\": \"\u6211\u5df2\u7ecf\u5f00\u59cb\u5904\u7406\u4efb\u52a1\u4e86\uff0c\u8bf7\u7a0d\u7b49\u3002\",\n    \"exception_message\": \"\u6211\u5f88\u62b1\u6b49\uff0c\u6211\u65e0\u6cd5\u5b8c\u6210\u8fd9\u4e2a\u4efb\u52a1\uff0c\u5f02\u5e38\u4fe1\u606f\u5982\u4e0b\uff1a\\n{message}\",\n    \"return_message\": \"\u6211\u5df2\u7ecf\u5b8c\u6210\u4e86\u4efb\u52a1\uff0c\u8fd4\u56de\u7ed3\u679c\u5982\u4e0b\uff1a\\n{message}\"\n\n}\n\nEN_BASIC_PROMPT = {\n    \"system_prompt\": \"The following is a piece of function code. Now you play this function,\"\n                     \" answer the user's questions about this function in the first person.\"", "    \"system_prompt\": \"The following is a piece of function code. Now you play this function,\"\n                     \" answer the user's questions about this function in the first person.\"\n                     \"\\nHere is the function code: {code_source}\",\n    # \u7528\u4e8e\u7ed9llm\u8fdb\u884c\u793a\u4f8b\u7684prompt\uff0c\u53ef\u4ee5\u4e0d\u63d0\u4f9b\uff0c\u4ee5\u51cf\u5c11token\u6570\u91cf\uff0c\u53ef\u4ee5\u5bf9\u6bd4\u4e0d\u63d0\u4f9b\u793a\u4f8b\u65f6\u7684\u6548\u679c\n    \"system_example_prompt\": [\n        {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"Hello, what can you do for me?\"},\n        {\"role\": \"system\", \"name\": \"example_assistant\",\n         \"content\": \"Hello, I am {function name}, I can help you {function description}, \"\n                    \"if you need my help, please tell me {instruction description}\"},\n    ],", "                    \"if you need my help, please tell me {instruction description}\"},\n    ],\n    \"desc_prompt\": \"Hello, what can you do for me?\",\n    \"execute_prompt\": \"Please convert the following user request to the parameters you can accept, \"\n                      \"represented as json format. If you cannot convert it,\"\n                      \"please answer the missing parameter information.\\n\"\n                      \"User request: {message}\",\n    \"exception_prompt\": \"Assume the following is the exception information you throw when executing, \"\n                        \"please explain its content.\\n\"\n                        \"Exception information: {message}\",", "                        \"please explain its content.\\n\"\n                        \"Exception information: {message}\",\n    \"return_prompt\": \"Assume the following is your return result, please explain the returned information.\\n\"\n                     \"Return value: {message}\",\n    \"execute_message\": \"I'm processing the task, please wait a moment.\",\n    \"exception_message\": \"I'm sorry, I can't do this task, the exception information is as follows:\\n {message}\",\n    \"return_message\": \"The task is completed, the result is as follows:\\n {message}\"\n}\n\n", "\n\nALL_BASIC_PROMPTS = {\n    \"zh\": ZH_BASIC_PROMPT,\n    \"en\": EN_BASIC_PROMPT\n}\n"]}
{"filename": "src/ask_api/llm/base.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nllm \u4e3b\u8981\u7528\u4e8e\u751f\u6210\u5982\u4e0b\u4fe1\u606f\uff1a\n1. \u51fd\u6570\u7684\u529f\u80fd\u63cf\u8ff0\n2. \u7528\u6237\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u4e0e\u51fd\u6570\u53c2\u6570\u7684\u6620\u5c04\n3. \u51fd\u6570\u7684\u8fd4\u56de\u503c\u63cf\u8ff0\n4. \u51fd\u6570\u7684\u5f02\u5e38\u4fe1\u606f\u63cf\u8ff0\n5. \u4e0e\u51fd\u6570\u8fdb\u884c\u81ea\u7531\u56de\u7b54\n\"\"\"\nfrom abc import ABC, abstractmethod", "\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\n\n\nclass AskApiPrompt(ABC):\n    def __init__(self, prompt_config) -> None:\n        self.prompt = prompt_config\n\n    def __str__(self) -> str:\n        return self.prompt\n\n    @abstractmethod\n    def desc_prompt(self, func):\n        raise NotImplementedError(\"desc_prompt() is not implemented\")\n\n    @abstractmethod\n    def execute_prompt(self, func, message):\n        raise NotImplementedError(\"execute_prompt() is not implemented\")\n\n    @abstractmethod\n    def return_prompt(self, func, message):\n        raise NotImplementedError(\"return_prompt() is not implemented\")\n\n    @abstractmethod\n    def exception_prompt(self, func, message):\n        raise NotImplementedError(\"exception_prompt() is not implemented\")\n\n    @abstractmethod\n    def free_prompt(self, func, message):\n        raise NotImplementedError(\"free_prompt() is not implemented\")\n\n    @abstractmethod\n    def execute_message(self):\n        raise NotImplementedError(\"execute_message() is not implemented\")\n\n    @abstractmethod\n    def exception_message(self):\n        raise NotImplementedError(\"exception_message() is not implemented\")", "\n\nclass LLMBase(ABC):\n    def __init__(self, prompt: AskApiPrompt) -> None:\n        self.prompt = prompt\n\n    @abstractmethod\n    def desc(self, func) -> str:\n        raise NotImplementedError(\"desc() is not implemented\")\n\n    @abstractmethod\n    def execute_param(self, func, message) -> str:\n        raise NotImplementedError(\"execute() is not implemented\")\n\n    @abstractmethod\n    def return_value(self, func, message) -> str:\n        raise NotImplementedError(\"return_value() is not implemented\")\n\n    @abstractmethod\n    def exception(self, func, message) -> str:\n        raise NotImplementedError(\"exception() is not implemented\")\n\n    @abstractmethod\n    def free_answer(self, func, message) -> str:\n        raise NotImplementedError(\"free_answer() is not implemented\")\n\n    def execute_message(self):\n        \"\"\"\n        \u51fd\u6570\u5f00\u59cb\u6267\u884c\u65f6\u7684\u63d0\u793a\u4fe1\u606f\n        :return:\n        \"\"\"\n        return self.prompt.execute_message()\n\n    def exception_message(self):\n        \"\"\"\n        \u51fd\u6570\u6267\u884c\u5f02\u5e38\u65f6\u7684\u63d0\u793a\u4fe1\u606f\n        :return:\n        \"\"\"\n        return self.prompt.exception_message()", "\n\nclass LLMBuilder(ABC):\n    @staticmethod\n    def builder_name():\n        return \"llm_base\"\n\n    def __init__(self, name: str) -> None:\n        self._name = name\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @abstractmethod\n    def __call__(self, prompt_config: Dict) -> LLMBase:\n        raise NotImplementedError(\"__call__() is not implemented\")\n\n    @name.setter\n    def name(self, value):\n        self._name = value", "\n\n\n"]}
{"filename": "src/ask_api/llm/openai.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nopenai based llm\n\"\"\"\nfrom typing import Dict\n\nimport openai\nimport os\n\nfrom ask_api.config.askapi_config import ASK_API_DEBUG, DEFAULT_OPENAI_CHAT_MODEL, OPENAI_KEY, OPENAI_KEY_PATH", "\nfrom ask_api.config.askapi_config import ASK_API_DEBUG, DEFAULT_OPENAI_CHAT_MODEL, OPENAI_KEY, OPENAI_KEY_PATH\nfrom ask_api.util.askapi_log import logging\nfrom ask_api.llm.base import LLMBase, AskApiPrompt, LLMBuilder\nfrom ask_api.util.askapi_inspect import get_func_source\n\n# openai api key\nif OPENAI_KEY is None:\n    if \"OPENAI_KEY\" in os.environ:\n        OPENAI_KEY = os.environ[\"OPENAI_KEY\"]\n    elif os.path.exists(OPENAI_KEY_PATH):\n        with open(OPENAI_KEY_PATH, \"r\") as f:\n            OPENAI_KEY = f.read().strip()\n    else:\n        logging.warning(\n            \"openai key not founded in both os.environ, OPENAI_KEY property and OPENAI_KEY_PATH;  OPENAI_KEY: {}, \"\n            \"OPENAI_KEY_PATH: {}\".format(\n                OPENAI_KEY, OPENAI_KEY_PATH))\n        raise ValueError(\"openai api key is not available\")", "\nopenai.api_key = OPENAI_KEY\n\n\nclass OpenAIChatPrompt(AskApiPrompt):\n    \"\"\"\n    openai chat prompt\n    \"\"\"\n    def __init__(self, prompt_config) -> None:\n        \"\"\"\n        Args:\n            prompt_config (_type_): _description_\n        \"\"\"\n        super().__init__(prompt_config)\n        self._system_prompt = self.prompt[\"system_prompt\"]\n        self._system_example_prompt = self.prompt[\"system_example_prompt\"]\n        self._desc_prompt = self.prompt[\"desc_prompt\"]\n        self._execute_prompt = self.prompt[\"execute_prompt\"]\n        self._exception_prompt = self.prompt[\"exception_prompt\"]\n        self._return_prompt = self.prompt[\"return_prompt\"]\n\n    def _build_system_prompt(self, func, add_example: bool = True):\n        \"\"\"\n        build system prompt\n        \"\"\"\n        source = get_func_source(func)\n\n        system_prompt = self._system_prompt.format(code_source=source)\n        system_prompts = [{\"role\": \"system\", \"content\": system_prompt}]\n        if self._system_example_prompt and add_example:\n            system_prompts.extend(self._system_example_prompt)\n\n        if ASK_API_DEBUG:\n            logging.info(\"system_prompt: {}\".format(system_prompts))\n\n        return system_prompts\n\n    def desc_prompt(self, func):\n        desc_prompt = self._desc_prompt\n        system_prompts = self._build_system_prompt(func)\n        messages = system_prompts + [{\"role\": \"user\", \"content\": desc_prompt}]\n\n        if ASK_API_DEBUG:\n            logging.info(\"desc_prompt: {}\".format(messages))\n\n        return messages\n\n    def execute_prompt(self, func, message):\n        \"\"\"\n        \u89e3\u6790\u53c2\u6570\u7684\u65f6\u5019\u4e0d\u9700\u8981\u62df\u4eba\u5316\n        Args:\n            func (_type_): _description_\n            message (_type_): _description_\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        execute_prompt = self._execute_prompt.format(message=message)\n        system_prompts = self._build_system_prompt(func, add_example=False)\n        messages = system_prompts + [{\"role\": \"user\", \"content\": execute_prompt}]\n\n        if ASK_API_DEBUG:\n            logging.info(\"execute_prompt: {}\".format(messages))\n\n        return messages\n\n    def return_prompt(self, func, message):\n        return_prompt = self._return_prompt.format(message=message)\n        system_prompts = self._build_system_prompt(func)\n        messages = system_prompts + [{\"role\": \"user\", \"content\": return_prompt}]\n\n        if ASK_API_DEBUG:\n            logging.info(\"return_prompt: {}\".format(messages))\n\n        return messages\n\n    def exception_prompt(self, func, message):\n        exception_prompt = self._exception_prompt.format(message=message)\n        system_prompts = self._build_system_prompt(func)\n        messages = system_prompts + [{\"role\": \"user\", \"content\": exception_prompt}]\n\n        if ASK_API_DEBUG:\n            logging.info(\"exception_prompt: {}\".format(messages))\n\n        return messages\n\n    def free_prompt(self, func, message):\n        free_prompt = [{\"role\": \"user\", \"content\": message}]\n        system_prompts = self._build_system_prompt(func)\n        messages = system_prompts + free_prompt\n\n        if ASK_API_DEBUG:\n            logging.info(\"free_prompt: {}\".format(messages))\n\n        return messages\n\n    def execute_message(self):\n        return self.prompt[\"execute_message\"]\n\n    def exception_message(self):\n        return self.prompt[\"exception_message\"]", "\n\nclass OpenAIChat(LLMBase):\n    \"\"\"\n    Args:\n        LLMBase (_type_): _description_\n    \"\"\"\n\n    def __init__(self, prompt: AskApiPrompt, model_name=\"gpt-3.5-turbo\") -> None:\n        super().__init__(prompt)\n        self.model_name = model_name\n\n    def desc(self, func) -> str:\n        desc_prompt_info = self.prompt.desc_prompt(func)\n        completion = openai.ChatCompletion.create(model=self.model_name, messages=desc_prompt_info)\n        desc_info = completion.choices[0].message.content\n\n        if ASK_API_DEBUG:\n            logging.info(\"desc: {}\".format(desc_info))\n\n        return desc_info\n\n    def execute_param(self, func, message) -> str:\n        execute_prompt_info = self.prompt.execute_prompt(func, message)\n        completion = openai.ChatCompletion.create(model=self.model_name, messages=execute_prompt_info)\n        param_info = completion.choices[0].message.content\n\n        if ASK_API_DEBUG:\n            logging.info(\"execute_param: {}\".format(param_info))\n\n        return param_info\n\n    def return_value(self, func, message) -> str:\n        return_prompt_info = self.prompt.return_prompt(func, message)\n        completion = openai.ChatCompletion.create(model=self.model_name, messages=return_prompt_info)\n        return_info = completion.choices[0].message.content\n\n        if ASK_API_DEBUG:\n            logging.info(\"return_value: {}\".format(return_info))\n\n        return return_info\n\n    def exception(self, func, message) -> str:\n        exception_prompt_info = self.prompt.exception_prompt(func, message)\n        completion = openai.ChatCompletion.create(model=self.model_name, messages=exception_prompt_info)\n        exception_info = completion.choices[0].message.content\n\n        if ASK_API_DEBUG:\n            logging.info(\"exception: {}\".format(exception_info))\n\n        return exception_info\n\n    def free_answer(self, func, message) -> str:\n        free_prompt_info = self.prompt.free_prompt(func, message)\n        completion = openai.ChatCompletion.create(model=self.model_name, messages=free_prompt_info)\n        free_answer = completion.choices[0].message.content\n\n        if ASK_API_DEBUG:\n            logging.info(\"free_answer: {}\".format(free_answer))\n\n        return free_answer", "\n\nclass OpenAIChatBuilder(LLMBuilder):\n    @staticmethod\n    def builder_name():\n        return \"openai_chat\"\n\n    \"\"\"\n    OpenAI Chat Builder\n    \"\"\"\n\n    def __init__(self, name: str = \"openai_chat\", model_name=DEFAULT_OPENAI_CHAT_MODEL) -> None:\n        super().__init__(name)\n        self.model_name = model_name\n\n    def __call__(self, prompt_config: Dict) -> LLMBase:\n        \"\"\"\n        :param prompt_config:\n        :return:\n        \"\"\"\n        prompt = OpenAIChatPrompt(prompt_config)\n        return OpenAIChat(prompt, model_name=self.model_name)", ""]}
{"filename": "src/ask_api/llm/__init__.py", "chunked_list": [""]}
{"filename": "src/ask_api/llm/llm_util.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nllm \u5de5\u5177\u51fd\u6570\n\"\"\"\nfrom typing import Dict\n\nfrom ask_api.util.askapi_log import logging\nfrom ask_api.config.askapi_config import DEFAULT_LLM_MODEL, LANG\nfrom ask_api.prompt.basic import ALL_BASIC_PROMPTS\nfrom .base import LLMBase, LLMBuilder", "from ask_api.prompt.basic import ALL_BASIC_PROMPTS\nfrom .base import LLMBase, LLMBuilder\n\nLLM_BUILDERS = {}\n\n\ndef register_llm_builder(name: str):\n    \"\"\"\n    \u6ce8\u518c LLM builder\n    :param name:\n    :return:\n    \"\"\"\n    def _register_llm_builder(cls: LLMBuilder) -> LLMBuilder:\n        if name in LLM_BUILDERS:\n            raise ValueError(f\"Cannot register duplicate LLM builder ({name})\")\n        if not issubclass(cls.__class__, LLMBuilder):\n            raise ValueError(f\"LLM builder ({name}) must extend LLMBuilder\")\n        LLM_BUILDERS[name] = cls\n        return cls\n\n    return _register_llm_builder", "\n\ndef build_llm(name: str, prompt_config: Dict) -> LLMBase:\n    \"\"\"\n    \u6784\u5efa LLM\n    :param name:\n    :param prompt_config:\n    :return:\n    \"\"\"\n    if name not in LLM_BUILDERS:\n        raise ValueError(f\"Unregistered LLM builder ({name})\")\n    return LLM_BUILDERS[name](prompt_config)", "\n\ndef list_llm() -> list:\n    \"\"\"\n    \u83b7\u53d6\u6240\u6709\u7684 LLM\n    :return:\n    \"\"\"\n    return list(LLM_BUILDERS.keys())\n\n", "\n\n# \u6ce8\u518c\u5404\u4e2a LLM Builder\n# \u6ce8\u518c OpenAIChatBuilder\ntry:\n    from .openai import OpenAIChatBuilder\n    register_llm_builder(OpenAIChatBuilder.builder_name())(OpenAIChatBuilder())\nexcept ImportError:\n    logging.warning(\"OpenAIChatBuilder is not available, please install openai package\")\n    pass\nexcept Exception as e:\n    logging.warning(\"OpenAIChatBuilder is not available, error: {}\".format(e))\n    pass", "\n\n# \u6784\u9020 Default LLM\ndef build_default_llm() -> LLMBase:\n    \"\"\"\n    \u6784\u9020 Default LLM\n    :return:\n    \"\"\"\n    try:\n        prompt_config = ALL_BASIC_PROMPTS[LANG]\n    except KeyError:\n        raise ValueError(f\"Unsupported language ({LANG})\")\n\n    default_llm_name = DEFAULT_LLM_MODEL\n    return build_llm(default_llm_name, prompt_config)", "\n"]}
{"filename": "src/ask_api/util/askapi_util.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nutil functions for askapi\n\"\"\"\n\n\ndef get_json_from_text(text: str):\n    \"\"\"\n    get json from text\n    \"\"\"\n    import json\n\n    json_start = text.find(\"{\")\n    json_end = text.rfind(\"}\")\n    if json_start == -1 or json_end == -1:\n        raise ValueError(\"json not found\")\n    else:\n        text = text[json_start:json_end + 1]\n        return json.loads(text)", ""]}
{"filename": "src/ask_api/util/askapi_log.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nlog setting\n\"\"\"\n\nimport logging\n\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n", "                    format='%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n"]}
{"filename": "src/ask_api/util/__init__.py", "chunked_list": [""]}
{"filename": "src/ask_api/util/askapi_inspect.py", "chunked_list": ["# -*- coding\uff1autf-8 -*-\n\"\"\"\naskapi inspect\n\"\"\"\nimport inspect\nfrom ask_api.config.askapi_config import MAX_FUNC_LEN\n\n\ndef get_func_name(func):\n    \"\"\"\n    get function name\n    \"\"\"\n    return func.__name__", "def get_func_name(func):\n    \"\"\"\n    get function name\n    \"\"\"\n    return func.__name__\n\n\ndef get_func_desc(func):\n    \"\"\"\n    get function desc\n    \"\"\"\n    return inspect.getdoc(func)", "\n\ndef get_func_source(func):\n    \"\"\"\n    get function source\n    \"\"\"\n    source = inspect.getsource(func)\n    # \u8d85\u8fc7 MAX_FUNC_LEN \u4e2a\u5b57\u7b26\u65f6\uff0c\u9700\u8981\u8fdb\u884c\u622a\u65ad\uff0c\u4fdd\u7559\u524d\u540e\u5404 MAX_FUNC_LEN/2 \u4e2a\u5b57\u7b26\n    if len(source) > MAX_FUNC_LEN:\n        source = source[:int(MAX_FUNC_LEN/2)] + \"\\n...\\n\" + source[-int(MAX_FUNC_LEN/2):]\n    return source", ""]}
{"filename": "src/ask_api/util/askapi_asyn.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\n\u5f02\u6b65\u8c03\u7528\u51fd\u6570\u76f8\u5173\u5de5\u5177\n\"\"\"\nimport nest_asyncio\nnest_asyncio.apply()\n\nimport asyncio\n\nloop = asyncio.get_event_loop()", "\nloop = asyncio.get_event_loop()\nasyncio.set_event_loop(loop)\n\n\ndef run_async_task(func):\n    \"\"\"\n    \u5f02\u6b65\u8c03\u7528\u51fd\u6570\n    \"\"\"\n    task = loop.create_task(func)\n    return task", "\n\ndef close_loop():\n    \"\"\"\n    \u5173\u95edloop\n    \"\"\"\n    loop.close()\n\n\ndef wait_task(task):\n    \"\"\"\n    \u7b49\u5f85task\u6267\u884c\u5b8c\u6210\n    \"\"\"\n    loop.run_until_complete(task)\n    return task.result()", "\ndef wait_task(task):\n    \"\"\"\n    \u7b49\u5f85task\u6267\u884c\u5b8c\u6210\n    \"\"\"\n    loop.run_until_complete(task)\n    return task.result()\n"]}
{"filename": "src/ask_api/base/role.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\naskapi role\n\"\"\"\nfrom ask_api.llm.base import LLMBase\nfrom ask_api.util.askapi_log import logging\nfrom ask_api.util.askapi_asyn import run_async_task, wait_task\nfrom ask_api.util.askapi_util import get_json_from_text\nfrom .session import Message, Session\nimport json", "from .session import Message, Session\nimport json\n\n\nclass Role(object):\n    def __init__(self, name) -> None:\n        self.name = name\n\n    def __str__(self) -> str:\n        return self.name\n\n    def __repr__(self) -> str:\n        return self.name\n\n    def answer(self, message: str, mode: str = 'free', session: Session = None) -> Message:\n        raise NotImplementedError(\"answer() is not implemented\")\n\n    def ask(self) -> str:\n        raise NotImplementedError(\"ask() is not implemented\")", "\n\nclass FunctionRole(Role):\n    \"\"\"\n    \u51fd\u6570\u89d2\u8272\n    Args:\n        Role (_type_): _description_\n    \"\"\"\n\n    def __init__(self, llm: LLMBase, func, name: str = None) -> None:\n        if name:\n            super().__init__(name)\n        else:\n            super().__init__(func.__name__)\n        self.func = func\n        self.llm = llm\n        self.desc = None\n\n    def answer(self, message: Message, mode: str = 'free', session: Session = None) -> Message:\n        \"\"\"\n        Args:\n            message (Message): message info\n            mode (str, optional): _description_. Defaults to 'free'.\n            session (Session, optional): _description_. Defaults to None.\n        Raises:\n            ValueError: _description_\n\n        Returns:\n            _type_: _description_\n\n        \"\"\"\n        if mode == \"desc\":\n            return self.ask()\n        elif mode == \"execute\":\n            return self.execute(message, session)\n        elif mode == \"free\":\n            answer = self.llm.free_answer(self.func, message)\n            return Message(role=self, text=answer)\n        else:\n            raise ValueError(\"mode must be one of desc, execute, free\")\n\n    def execute(self, message: Message, session: Session = None) -> Message:\n        \"\"\"\n        \u6267\u884c\u4efb\u52a1\n        Args:\n            message (str): a str message\n            session (Session, optional): _description_. Defaults to None.\n        Raises:\n            ValueError: _description_\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        param_json = self.llm.execute_param(self.func, message)\n        try:\n            param_dic = get_json_from_text(param_json)\n        except Exception as e:\n            return Message(role=self, text=param_json)\n\n        # \u5f02\u6b65\u6267\u884c\u51fd\u6570\n        async def execute():\n            try:\n                ret = self.func(**param_dic)\n                answer = self.llm.return_value(self.func, ret)\n                async_message = Message(role=self, text=answer)\n            except Exception as ex:\n                ex_desc = self.llm.exception(self.func, str(ex))\n                ex_message = self.llm.exception_message().format(message=ex_desc)\n                async_message = Message(role=self, text=ex_message)\n            if session:\n                session.add_message(async_message)\n            return async_message\n\n        task = run_async_task(execute())\n        execute_message = self.llm.execute_message()\n        return Message(role=self, text=execute_message, task=task)\n\n    def ask(self) -> Message:\n        \"\"\"\n        Returns:\n            str: _description_\n        \"\"\"\n        if not self.desc:\n            self.desc = self.llm.desc(self.func)\n        text = self.desc\n        return Message(role=self, text=text)", "\n\nclass UserRole(Role):\n    \"\"\"\n    \u7528\u6237\u89d2\u8272\uff08\u865a\u62df\u89d2\u8272\uff0c\u53ea\u662f\u7528\u4e8e\u5360\u4f4d\uff0c\u4e0d\u8fdb\u884c\u4efb\u4f55\u8c03\u7528\uff09\n    Args:\n        Role (_type_): _description_\n    \"\"\"\n\n    def __init__(self, name) -> None:\n        super().__init__(name)\n\n    def answer(self, message: str, mode: str = 'free', session: Session = None) -> Message:\n        \"\"\"\n        Args:\n            message (str): _description_\n            mode (str, optional): _description_. Defaults to 'free'.\n            session (Session, optional): _description_. Defaults to None.\n        Raises:\n            ValueError: _description_\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        raise ValueError(\"user role can not answer\")\n\n    def ask(self) -> str:\n        \"\"\"\n        Returns:\n            str: _description_\n        \"\"\"\n        raise ValueError(\"user role can not ask\")", "\n\nclass CLIUserRole(UserRole):\n    \"\"\"\n    \u547d\u4ee4\u884c\u7528\u6237\u89d2\u8272(\u7528\u4e8e\u547d\u4ee4\u884c\u4ea4\u4e92\u5f0f\u63d0\u95ee)\n    Args:\n        UserRole (_type_): _description_\n    \"\"\"\n\n    def __init__(self, name) -> None:\n        super().__init__(name)\n\n    def answer(self, message: str, mode: str = 'free', session: Session = None):\n        \"\"\"\n        Args:\n            message (str): _description_\n            mode (str, optional): _description_. Defaults to 'free'\n            session (Session, optional): _description_. Defaults to None.\n        Raises:\n            ValueError: _description_\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        # \u4ece\u547d\u4ee4\u884c\u83b7\u53d6\u8f93\u5165\n        answer = input(self.name + \":\")\n        return answer\n\n    def ask(self) -> str:\n        \"\"\"\n        Returns:\n            str: _description_\n        \"\"\"\n        message = input(self.name + \":\")\n        return message", ""]}
{"filename": "src/ask_api/base/__init__.py", "chunked_list": [""]}
{"filename": "src/ask_api/base/session.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\n\u4f1a\u8bdd\u7ba1\u7406\uff0c\u8bb0\u5f55\u5386\u53f2\u4f1a\u8bdd\u4fe1\u606f\n\"\"\"\nfrom typing import List\n\n\nclass Message(object):\n    def __init__(self, role, text, task=None) -> None:\n        self.role = role\n        self.text = text\n        # \u5f02\u6b65\u4efb\u52a1\n        self.task = task\n\n    def __str__(self) -> str:\n        return str(self.role) + \": \" + self.text\n\n    def __repr__(self) -> str:\n        return str(self.role) + \": \" + self.text\n\n    def get_role(self):\n        return self.role\n\n    def get_text(self):\n        return self.text\n\n    def get(self):\n        return self.role, self.text\n\n    def set_role(self, role):\n        self.role = role\n\n    def set_text(self, text):\n        self.text = text\n\n    def set(self, role, text):\n        self.role = role\n        self.text = text\n\n    def set_task(self, task):\n        self.task = task\n\n    def get_task(self):\n        return self.task", "\n\nclass Session(object):\n    def __init__(self) -> None:\n        self.messages = []\n\n    def add_message(self, message: Message):\n        self.messages.append(message)\n\n    def get_messages(self) -> List[Message]:\n        return self.messages\n\n    def print_messages(self):\n        print(\"*\" * 40 + \"Session\" + \"*\" * 40)\n        for message in self.messages:\n            print(message)\n        print(\"*\" * 40 + \"Session\" + \"*\" * 40)\n\n    def get_current(self) -> Message:\n        return self.messages[-1]", ""]}
