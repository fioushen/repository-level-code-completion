{"filename": "main.py", "chunked_list": ["from src.common.constants import *\nfrom src.common.input_parser import *\nfrom src.common.loads_functions import *\nfrom src.datasets.dataset_factory import DatasetFactory\nfrom src.trainers.standard_problem_to_opt import StandardProblemToOpt\n\n\ndef main():\n    parser = get_parser_general_test_without_optimization()\n    args = parser.parse_args()\n    data_json_path = args.dataset_config\n    brain_trainer_json_path = args.model_config\n    dataset_params, brain_params = load_config_json([data_json_path, brain_trainer_json_path])\n    dataset_data = DatasetFactory(dataset_params=dataset_params)()\n    to_opt = StandardProblemToOpt(dataset_data=dataset_data,\n                                  brain_params=brain_params,\n                                  problem_type=dataset_params[PROBLEM_TYPE],\n                                  problem_size=dataset_params[PROBLEM_SIZE],\n                                  target_embedding=dataset_params[USE_TARGET_EMBEDDING])\n    to_opt()\n    print('============== END SCRIPT ==============')", "\n\nif __name__ == \"__main__\":\n    main()\n"]}
{"filename": "src/common/input_parser.py", "chunked_list": ["import argparse\n\n\ndef get_parser_general_test_without_optimization():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-d', '--dataset_config', type=str, required=True, help='Data set configuration file')\n    parser.add_argument('-m', '--model_config', type=str, required=True, help='Model parameters file')\n    return parser\n\n\ndef get_parser_general_cross_val_test_without_optimization():\n    parser = get_parser_general_test_without_optimization()\n    parser.add_argument('-o', '--optimization_config', type=str, required=True, help='Optimization configuration file')\n    return parser", "\n\ndef get_parser_general_cross_val_test_without_optimization():\n    parser = get_parser_general_test_without_optimization()\n    parser.add_argument('-o', '--optimization_config', type=str, required=True, help='Optimization configuration file')\n    return parser\n\n\ndef get_parser_general_cross_val_test_with_optimization():\n    parser = get_parser_general_cross_val_test_without_optimization()\n    parser.add_argument('-r', '--ray_config', type=str, required=True, help='Model parameters file to optimize by Ray')\n    return parser", "def get_parser_general_cross_val_test_with_optimization():\n    parser = get_parser_general_cross_val_test_without_optimization()\n    parser.add_argument('-r', '--ray_config', type=str, required=True, help='Model parameters file to optimize by Ray')\n    return parser\n"]}
{"filename": "src/common/constants.py", "chunked_list": ["# Datasets\nDATASET_NAME = 'dataset_name'\nPROBLEM_TYPE = 'problem_type'\nPROBLEM_SIZE = 'problem_size'\nUSE_TARGET_EMBEDDING = 'use_target_embedding'\nREGRESSION = 'regression'\nCLASSIFICATION = 'classification'\nEXPLAINABILITY = 'explainability'\n\n# Discretizaci\u00f3n de variables continuas", "\n# Discretizaci\u00f3n de variables continuas\nN_QUANTILE = 'n_quantile'\nOUTPUT_DISTRIBUTION = 'output_distribution'\n\n# Split train/test\nPERCENTAGE_TEST = 'percentage_test'\n\n# Brain struct\nBRAIN_PARAMS = 'brain_params'", "# Brain struct\nBRAIN_PARAMS = 'brain_params'\nCOMMON = 'common'\nINPUT_EMBEDDING = 'input_embedding'\nINPUT_GRAPH_EMBEDDING = 'input_graph_embedding'\nINPUT_MLP_EMBEDDING = 'input_mlp_embedding'\nGRAPH_EMBEDDING = 'graph_embedding'\nTRANSFORMER_EMBEDDING = 'transformer_embedding'\nDECODER = 'decoder'\nTRAINER_PARAMS = 'trainer_params'", "DECODER = 'decoder'\nTRAINER_PARAMS = 'trainer_params'\nENABLE = 'enable'\nINPUT_EMBEDDING_CON = 'input_embedding_con'\n\n# Brain\nLATENT_SPACE_SIZE = 'latent_space_size'\nCLS_NUM = 'cls_num'\nDROPOUT = 'dropout'\nGNN_TYPE = 'gnn_type'", "DROPOUT = 'dropout'\nGNN_TYPE = 'gnn_type'\nGNN_NUM = 'gnn_num'\nIN_GNN = 'in_gnn'\nIN_MULTI_CHANNEL_GNN = 'in_multichannel_gnn'\nIN_MLP_DEEP = 'in_mlp_deep'\nIN_CHANNELS = 'in_channels'\nIN_CHANNEL_AGG = 'in_channel_agg'\nIN_CHANNEL_AGG_CONCAT = 'concat'\nIN_CHANNEL_AGG_MLP = 'mlp'", "IN_CHANNEL_AGG_CONCAT = 'concat'\nIN_CHANNEL_AGG_MLP = 'mlp'\nIN_CHANNEL_AGG_SUM = 'sum'\nIN_TRANSFORMER = 'in_transformer'\nGAT_GNN = 'gat_gnn'\nGAT_HEADS = 'gat_heads'\nTRANSFORMER_TYPE = 'transformer_type'\nTRANSFORMER_NUM = 'transformer_num'\nTRANSFORMER_HEADS = 'transformer_heads'\nDECODER_DEEP = 'decoder_deep'", "TRANSFORMER_HEADS = 'transformer_heads'\nDECODER_DEEP = 'decoder_deep'\nDECODER_TYPE = 'decoder_type'\nTRAINABLE_PARAMS_NUM = 'trainable_params_num'\n\n# Trainer\nEPOCHS = 'epochs'\nBATCH_SIZE = 'batch_size'\nTRAIN_LEARNING_RATE = 'training_learning_rate'\nDEVICE = 'device'", "TRAIN_LEARNING_RATE = 'training_learning_rate'\nDEVICE = 'device'\nMETRIC = 'metric'\nMETRIC_LIST = 'metric_list'\nEPOCH = 'epoch'\nTRAINING_TITLE = 'TRAINING'\nTRAIN_TITLE = 'TRAIN'\nTRAIN_TIME = 'train_time'\nTEST_TIME = 'test_time'\nTEST_TITLE = 'TEST'", "TEST_TIME = 'test_time'\nTEST_TITLE = 'TEST'\nMEAN = 'mean'\nSTD = 'sdt'\nPATH = 'path'\n"]}
{"filename": "src/common/loads_functions.py", "chunked_list": ["from typing import Dict, List\nimport json\n\n\ndef load_config_json(jsons: List[str]) -> List[Dict]:\n    \"\"\"Load json files\n\n    :param jsons: List[str], list of json paths to load\n    :return: List[Dict] with the info contained in the jsons\n    \"\"\"\n    to_return = []\n    for path in jsons:\n        with open(path) as f:\n            to_return.append(json.load(f))\n    return to_return", ""]}
{"filename": "src/models/brain.py", "chunked_list": ["import torch\nimport torch.nn as nn\n\nfrom src.models.brain_struct import *\nfrom src.models.building_blocks.decoder_mlp import DecoderMLP\nfrom src.models.building_blocks.input_graph_embedding import InputGraphEmbedding\nfrom src.models.building_blocks.in_encoder import INEncoder\n\n\nclass Brain(nn.Module):\n\n    def __init__(self,\n                 general_info: GeneralInfo,\n                 common_info: CommonInfo,\n                 input_graph_embedding: InputGraphEmbeddingInfo,\n                 encoder_gnn_info: GNNEmbeddingInfo,\n                 decoder_info: DecoderInfo,\n                 device: str):\n        super(Brain, self).__init__()\n        assert general_info.cat_num == len(general_info.cat_degrees), \\\n            \"cat_num has to be compatible with the len of cat_degrees\"\n\n        self.continuous_num = general_info.con_num\n        self.categorical_num = general_info.cat_num\n\n        # ===========================================\n        # ENCODER\n        # ===========================================\n        self.encoder = nn.ModuleList()\n\n        # COLUMNAR EMBEDDING\n        columnar_embedding = InputGraphEmbedding(con_features_num=general_info.con_num,\n                                                 cat_features_num=general_info.cat_num,\n                                                 cat_features_degrees=general_info.cat_degrees,\n                                                 latent_space_size=common_info.latent_space_size,\n                                                 cls_num=input_graph_embedding.cls_num)\n        self.cls_num = input_graph_embedding.cls_num\n        self.mlp_emb = False\n\n        print(\"\\tColumnar Embedding - Number of trainable parameters: {}\"\n              .format(sum(p.numel() for p in columnar_embedding.parameters() if p.requires_grad)))\n        self.encoder.append(columnar_embedding)\n\n        # CONTEXTUAL EMBEDDING - IN Graph ENCODER\n        self.in_multichannel = False\n        self.encoder.append(INEncoder(general_info=general_info,\n                                      common_info=common_info,\n                                      input_graph_embedding=input_graph_embedding,\n                                      gnn_info=encoder_gnn_info,\n                                      device=device))\n\n        print(\"\\tGNN Contextual Encoder - Number of trainable parameters: {}\"\n              .format(sum(p.numel() for p in self.encoder[-1].parameters() if p.requires_grad)))\n\n        channels_multiplier = (1 if encoder_gnn_info.in_channel_agg != IN_CHANNEL_AGG_CONCAT else\n                               encoder_gnn_info.in_channels)\n        decoder_input_size = common_info.latent_space_size * self.cls_num * channels_multiplier\n        decoder_sequence_length = 0\n\n        # ===========================================\n        # DECODER\n        # ===========================================\n        self.decoder = DecoderMLP(input_size=decoder_input_size,\n                                  latent_space_size=common_info.latent_space_size,\n                                  output_size=decoder_info.class_num,\n                                  layer_num=decoder_info.decoder_deep,\n                                  sequence_length=decoder_sequence_length)\n        print(\"\\tDecoder - Number of trainable parameters: {}\"\n              .format(sum(p.numel() for p in self.decoder.parameters() if p.requires_grad)))\n\n    def forward(self, features: torch.tensor) -> torch.tensor:\n        \"\"\"\n        Forward function\n\n        :param features: torch.tensor of shape = [batch_size, con_features_num + cat_features_num]\n\n        :return torch.tensor of shape = [batch_size, num_targets]\n        \"\"\"\n        # Encoder\n        for i, layer in enumerate(self.encoder):\n            if i == 0:\n                con = features[:, :self.continuous_num] if self.continuous_num > 0 else None\n                cat = features[:, self.continuous_num:].to(dtype=torch.long) if self.categorical_num > 0 else None\n                features = layer(con, cat)\n            else:\n                features = layer(features)\n\n        if not self.in_multichannel:\n            batch_size = features.shape[0]\n            x = (features[:, :self.cls_num, :].reshape(batch_size, -1)\n                 if ((not self.mlp_emb) and self.cls_num > 0) else features)\n        else:\n            x = features\n\n        # Decoder\n        return self.decoder(x)  # shape = [batch_size, num_targets]", "\nclass Brain(nn.Module):\n\n    def __init__(self,\n                 general_info: GeneralInfo,\n                 common_info: CommonInfo,\n                 input_graph_embedding: InputGraphEmbeddingInfo,\n                 encoder_gnn_info: GNNEmbeddingInfo,\n                 decoder_info: DecoderInfo,\n                 device: str):\n        super(Brain, self).__init__()\n        assert general_info.cat_num == len(general_info.cat_degrees), \\\n            \"cat_num has to be compatible with the len of cat_degrees\"\n\n        self.continuous_num = general_info.con_num\n        self.categorical_num = general_info.cat_num\n\n        # ===========================================\n        # ENCODER\n        # ===========================================\n        self.encoder = nn.ModuleList()\n\n        # COLUMNAR EMBEDDING\n        columnar_embedding = InputGraphEmbedding(con_features_num=general_info.con_num,\n                                                 cat_features_num=general_info.cat_num,\n                                                 cat_features_degrees=general_info.cat_degrees,\n                                                 latent_space_size=common_info.latent_space_size,\n                                                 cls_num=input_graph_embedding.cls_num)\n        self.cls_num = input_graph_embedding.cls_num\n        self.mlp_emb = False\n\n        print(\"\\tColumnar Embedding - Number of trainable parameters: {}\"\n              .format(sum(p.numel() for p in columnar_embedding.parameters() if p.requires_grad)))\n        self.encoder.append(columnar_embedding)\n\n        # CONTEXTUAL EMBEDDING - IN Graph ENCODER\n        self.in_multichannel = False\n        self.encoder.append(INEncoder(general_info=general_info,\n                                      common_info=common_info,\n                                      input_graph_embedding=input_graph_embedding,\n                                      gnn_info=encoder_gnn_info,\n                                      device=device))\n\n        print(\"\\tGNN Contextual Encoder - Number of trainable parameters: {}\"\n              .format(sum(p.numel() for p in self.encoder[-1].parameters() if p.requires_grad)))\n\n        channels_multiplier = (1 if encoder_gnn_info.in_channel_agg != IN_CHANNEL_AGG_CONCAT else\n                               encoder_gnn_info.in_channels)\n        decoder_input_size = common_info.latent_space_size * self.cls_num * channels_multiplier\n        decoder_sequence_length = 0\n\n        # ===========================================\n        # DECODER\n        # ===========================================\n        self.decoder = DecoderMLP(input_size=decoder_input_size,\n                                  latent_space_size=common_info.latent_space_size,\n                                  output_size=decoder_info.class_num,\n                                  layer_num=decoder_info.decoder_deep,\n                                  sequence_length=decoder_sequence_length)\n        print(\"\\tDecoder - Number of trainable parameters: {}\"\n              .format(sum(p.numel() for p in self.decoder.parameters() if p.requires_grad)))\n\n    def forward(self, features: torch.tensor) -> torch.tensor:\n        \"\"\"\n        Forward function\n\n        :param features: torch.tensor of shape = [batch_size, con_features_num + cat_features_num]\n\n        :return torch.tensor of shape = [batch_size, num_targets]\n        \"\"\"\n        # Encoder\n        for i, layer in enumerate(self.encoder):\n            if i == 0:\n                con = features[:, :self.continuous_num] if self.continuous_num > 0 else None\n                cat = features[:, self.continuous_num:].to(dtype=torch.long) if self.categorical_num > 0 else None\n                features = layer(con, cat)\n            else:\n                features = layer(features)\n\n        if not self.in_multichannel:\n            batch_size = features.shape[0]\n            x = (features[:, :self.cls_num, :].reshape(batch_size, -1)\n                 if ((not self.mlp_emb) and self.cls_num > 0) else features)\n        else:\n            x = features\n\n        # Decoder\n        return self.decoder(x)  # shape = [batch_size, num_targets]", ""]}
{"filename": "src/models/brain_struct.py", "chunked_list": ["from collections import namedtuple\n\nfrom src.common.constants import *\n\nGeneralInfo = namedtuple('GeneralInfo',\n                         'con_num, cat_num, cat_degrees')\n\nCommonInfo = namedtuple('CommonInfo',\n                        'latent_space_size, dropout')\n", "                        'latent_space_size, dropout')\n\nInputGraphEmbeddingInfo = namedtuple('InputGraphEmbeddingInfo',\n                                     'cls_num')\n\nInputMLPEmbeddingInfo = namedtuple('InputMLPEmbeddingInfo',\n                                   'input_embedding_con')\n\nGNNEmbeddingInfo = namedtuple('GNNEmbeddingInfo',\n                              'gnn_type, gnn_num, in_mlp_deep, in_channels, in_channel_agg, gat_heads')", "GNNEmbeddingInfo = namedtuple('GNNEmbeddingInfo',\n                              'gnn_type, gnn_num, in_mlp_deep, in_channels, in_channel_agg, gat_heads')\n\nTransformerEmbeddingInfo = namedtuple('EncoderTransformerInfo',\n                                      'transformer_type, layer_num, heads_num')\n\nDecoderInfo = namedtuple('DecoderInfo',\n                         'class_num, decoder_deep')\n\n\ndef build_brain_structs(dataset_data, brain_params):\n    # Sanity check\n    graph_and_mlp_emb = (brain_params[INPUT_GRAPH_EMBEDDING][ENABLE] and\n                         brain_params[INPUT_MLP_EMBEDDING][ENABLE])\n    assert not graph_and_mlp_emb,\\\n        \"Input Graph Embedding and Input MLP Embedding cannot be simultaneously enabled\"\n\n    # Wrapper to Python struct\n    general_info = GeneralInfo(con_num=dataset_data.con_num,\n                               cat_num=dataset_data.cat_num,\n                               cat_degrees=dataset_data.cat_degrees)\n\n    common_info = CommonInfo(latent_space_size=brain_params[COMMON][LATENT_SPACE_SIZE],\n                             dropout=brain_params[COMMON][DROPOUT])\n\n    input_graph_embedding = None\n    if brain_params[INPUT_GRAPH_EMBEDDING][ENABLE]:\n        input_graph_embedding = InputGraphEmbeddingInfo(\n            cls_num=brain_params[INPUT_GRAPH_EMBEDDING][CLS_NUM])\n\n    input_mlp_embedding = None\n    if brain_params[INPUT_MLP_EMBEDDING][ENABLE]:\n        input_mlp_embedding = InputMLPEmbeddingInfo(\n            input_embedding_con=brain_params[INPUT_MLP_EMBEDDING][INPUT_EMBEDDING_CON])\n\n    encoder_gnn_info = None\n    if brain_params[GRAPH_EMBEDDING][ENABLE]:\n        encoder_gnn_info = GNNEmbeddingInfo(gnn_type=brain_params[GRAPH_EMBEDDING][GNN_TYPE],\n                                            gnn_num=brain_params[GRAPH_EMBEDDING][GNN_NUM],\n                                            in_mlp_deep=brain_params[GRAPH_EMBEDDING][IN_MLP_DEEP],\n                                            in_channels=brain_params[GRAPH_EMBEDDING][IN_CHANNELS],\n                                            in_channel_agg=brain_params[GRAPH_EMBEDDING][IN_CHANNEL_AGG],\n                                            gat_heads=brain_params[GRAPH_EMBEDDING][GAT_HEADS])\n    encoder_transformer_info = None\n    if brain_params[TRANSFORMER_EMBEDDING][ENABLE]:\n        encoder_transformer_info = TransformerEmbeddingInfo(\n            transformer_type=brain_params[TRANSFORMER_EMBEDDING][TRANSFORMER_TYPE],\n            layer_num=brain_params[TRANSFORMER_EMBEDDING][TRANSFORMER_NUM],\n            heads_num=brain_params[TRANSFORMER_EMBEDDING][TRANSFORMER_HEADS]\n        )\n\n    decoder_info = DecoderInfo(class_num=dataset_data.problem_size,\n                               decoder_deep=brain_params[DECODER][DECODER_DEEP])\n\n    return (general_info, common_info, input_graph_embedding, input_mlp_embedding,\n            encoder_gnn_info, encoder_transformer_info, decoder_info)", "\n\ndef build_brain_structs(dataset_data, brain_params):\n    # Sanity check\n    graph_and_mlp_emb = (brain_params[INPUT_GRAPH_EMBEDDING][ENABLE] and\n                         brain_params[INPUT_MLP_EMBEDDING][ENABLE])\n    assert not graph_and_mlp_emb,\\\n        \"Input Graph Embedding and Input MLP Embedding cannot be simultaneously enabled\"\n\n    # Wrapper to Python struct\n    general_info = GeneralInfo(con_num=dataset_data.con_num,\n                               cat_num=dataset_data.cat_num,\n                               cat_degrees=dataset_data.cat_degrees)\n\n    common_info = CommonInfo(latent_space_size=brain_params[COMMON][LATENT_SPACE_SIZE],\n                             dropout=brain_params[COMMON][DROPOUT])\n\n    input_graph_embedding = None\n    if brain_params[INPUT_GRAPH_EMBEDDING][ENABLE]:\n        input_graph_embedding = InputGraphEmbeddingInfo(\n            cls_num=brain_params[INPUT_GRAPH_EMBEDDING][CLS_NUM])\n\n    input_mlp_embedding = None\n    if brain_params[INPUT_MLP_EMBEDDING][ENABLE]:\n        input_mlp_embedding = InputMLPEmbeddingInfo(\n            input_embedding_con=brain_params[INPUT_MLP_EMBEDDING][INPUT_EMBEDDING_CON])\n\n    encoder_gnn_info = None\n    if brain_params[GRAPH_EMBEDDING][ENABLE]:\n        encoder_gnn_info = GNNEmbeddingInfo(gnn_type=brain_params[GRAPH_EMBEDDING][GNN_TYPE],\n                                            gnn_num=brain_params[GRAPH_EMBEDDING][GNN_NUM],\n                                            in_mlp_deep=brain_params[GRAPH_EMBEDDING][IN_MLP_DEEP],\n                                            in_channels=brain_params[GRAPH_EMBEDDING][IN_CHANNELS],\n                                            in_channel_agg=brain_params[GRAPH_EMBEDDING][IN_CHANNEL_AGG],\n                                            gat_heads=brain_params[GRAPH_EMBEDDING][GAT_HEADS])\n    encoder_transformer_info = None\n    if brain_params[TRANSFORMER_EMBEDDING][ENABLE]:\n        encoder_transformer_info = TransformerEmbeddingInfo(\n            transformer_type=brain_params[TRANSFORMER_EMBEDDING][TRANSFORMER_TYPE],\n            layer_num=brain_params[TRANSFORMER_EMBEDDING][TRANSFORMER_NUM],\n            heads_num=brain_params[TRANSFORMER_EMBEDDING][TRANSFORMER_HEADS]\n        )\n\n    decoder_info = DecoderInfo(class_num=dataset_data.problem_size,\n                               decoder_deep=brain_params[DECODER][DECODER_DEEP])\n\n    return (general_info, common_info, input_graph_embedding, input_mlp_embedding,\n            encoder_gnn_info, encoder_transformer_info, decoder_info)", ""]}
{"filename": "src/models/building_blocks/mlp.py", "chunked_list": ["import math\nimport torch\n\n\nclass MLP(torch.nn.Module):\n    def __init__(self, input_size: int, hidden_size: int, output_size: int, layers: int, layernorm: bool =True):\n        \"\"\" Multi-Layer perceptron\n\n        Initial Code: https://colab.research.google.com/drive/1hirUfPgLU35QCSQSZ7T2lZMyFMOaK_OF?usp=sharing\n\n        :param input_size: int,\n        :param hidden_size: int\n        :param output_size: int\n        :param layers: int\n        :param layernorm: bool\n        \"\"\"\n        super().__init__()\n        self.layers = torch.nn.ModuleList()\n        for i in range(layers):\n            self.layers.append(torch.nn.Linear(\n                input_size if i == 0 else hidden_size,\n                output_size if i == layers - 1 else hidden_size,\n            ))\n            if i != layers - 1:\n                self.layers.append(torch.nn.ReLU())\n        if layernorm:\n            self.layers.append(torch.nn.LayerNorm(output_size))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        for layer in self.layers:\n            if isinstance(layer, torch.nn.Linear):\n                layer.weight.data.normal_(0, 1 / math.sqrt(layer.in_features))\n                layer.bias.data.fill_(0)\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x", ""]}
{"filename": "src/models/building_blocks/decoder_mlp.py", "chunked_list": ["import torch\nimport torch.nn as nn\n\n\nclass DecoderMLP(nn.Module):\n\n    def __init__(self,\n                 input_size: int,\n                 latent_space_size: int,\n                 output_size: int,\n                 layer_num: int,\n                 sequence_length: int):\n        super(DecoderMLP, self).__init__()\n\n        self.output_size = output_size\n        self.hiddens = nn.ModuleList()\n        for i in range(layer_num):\n            self.hiddens.append(nn.Linear(latent_space_size if i > 0 else input_size, latent_space_size))\n        self.output = (nn.Linear(latent_space_size, output_size) if sequence_length <= 1 else\n                       MultiNodeOutputLayer(output_size, latent_space_size, sequence_length))\n\n    def forward(self, x: torch.tensor) -> torch.tensor:\n        \"\"\"\n\n        :param x: shape = [batch_size, features_num=input_size]\n        :return: shape = [batch_size, output_size]\n        \"\"\"\n        for h in self.hiddens:\n            x = torch.nn.functional.relu(h(x))\n        return self.output(x)\n\n    def predict_cls(self, x: torch.tensor) -> torch.tensor:\n        \"\"\"\n\n        :param x: shape = [batch_size, features_num=input_size]\n        :return: shape = [batch_size, output_size]\n        \"\"\"\n        for h in self.hiddens:\n            x = torch.nn.functional.relu(h(x))\n        return x", "\n\nclass MultiNodeOutputLayer(nn.Module):\n\n    def __init__(self, output_size: int, latent_space_size: int, sequence_length: int):\n        super(MultiNodeOutputLayer, self).__init__()\n        self.outputs = nn.ModuleList()\n        for _ in range(sequence_length):\n            self.outputs.append(nn.Linear(latent_space_size, output_size))\n\n    def forward(self, x: torch.tensor) -> torch.tensor:\n        out = torch.stack([o(x[:, i, :]) for i, o in enumerate(self.outputs)], dim=0)  # [node_num, batch_size, num_targets]\n        return torch.permute(out, (1, 0, 2)).sum(dim=1)", ""]}
{"filename": "src/models/building_blocks/input_graph_embedding.py", "chunked_list": ["from typing import List\n\nimport torch\nimport torch.nn as nn\n\n\nclass InputGraphEmbedding(nn.Module):\n\n    def __init__(self,\n                 con_features_num: int,\n                 cat_features_num: int,\n                 cat_features_degrees: List[int],\n                 latent_space_size: int,\n                 cls_num: int):\n        super(InputGraphEmbedding, self).__init__()\n        self.con_features_num = con_features_num\n        self.cat_features_num = cat_features_num\n        self.cls_num = cls_num\n\n        # cls embedding as in the Transformer case\n        if self.cls_num > 0:\n            cls = torch.Tensor(self.cls_num, latent_space_size)\n            self.cls = nn.Parameter(nn.init.xavier_uniform_(cls))\n\n        # Continuous Features embedding\n        if self.con_features_num > 0:\n            self.con_emb = nn.ModuleList()\n            for _ in range(self.con_features_num):\n                self.con_emb.append(nn.Linear(1, latent_space_size))\n\n        # Categorical Features embedding\n        if self.cat_features_num > 0:\n            self.cat_emb = nn.ModuleList()\n            for size in cat_features_degrees:\n                self.cat_emb.append(nn.Embedding(size, latent_space_size))\n\n    def forward(self, x_con: torch.tensor, x_cat: torch.tensor) -> torch.tensor:\n        \"\"\"\n\n        :param x_con: shape = [batch_size, con_features_num]\n        :param x_cat: shape = [batch_size, cat_features_num]\n        :return: shape = [batch_size, features_num=con_features_num+cat_features_num, latent_space_size]\n        \"\"\"\n        batch_size = x_cat.shape[0] if x_cat is not None else x_con.shape[0]\n        final_list = []\n        if self.cls_num > 0:\n            final_list.append(self.cls.repeat(batch_size, 1, 1))\n\n        if self.con_features_num > 0:\n            con_feature_nodes = torch.permute(\n                torch.stack([torch.nn.functional.relu(con_emb(x_con[:, i].unsqueeze(dim=1)))\n                             for i, con_emb in enumerate(self.con_emb)], dim=0), (1, 0, 2))\n            final_list.append(con_feature_nodes)\n\n        if self.cat_features_num > 0:\n            cat_feature_nodes = torch.permute(\n                torch.stack([cat_emb(x_cat[:, i]) for i, cat_emb in enumerate(self.cat_emb)], dim=0), (1, 0, 2))\n            final_list.append(cat_feature_nodes)\n\n        return torch.cat(final_list, dim=1)", ""]}
{"filename": "src/models/building_blocks/in_encoder.py", "chunked_list": ["from typing import Optional\n\nimport torch\nimport torch.nn as nn\n\nfrom src.models.brain_struct import *\nfrom src.models.building_blocks.interaction_network import InteractionNetwork\n\n\nclass INEncoder(nn.Module):\n\n    def __init__(self,\n                 general_info: GeneralInfo,\n                 common_info: CommonInfo,\n                 input_graph_embedding: InputGraphEmbeddingInfo,\n                 gnn_info: GNNEmbeddingInfo,\n                 device: str):\n        super(INEncoder, self).__init__()\n        # Sanity checks\n        assert_msg = \"IN_CHANNEL_AGG={} is not allowed, only the following values are currently available: [{}, {}, {}]\"\n        assert gnn_info.in_channel_agg in [IN_CHANNEL_AGG_CONCAT, IN_CHANNEL_AGG_MLP, IN_CHANNEL_AGG_SUM], \\\n            assert_msg.format(gnn_info.in_channel_agg, IN_CHANNEL_AGG_CONCAT, IN_CHANNEL_AGG_MLP, IN_CHANNEL_AGG_SUM)\n\n        # General info\n        self.channels = gnn_info.in_channels\n        self.channel_agg = gnn_info.in_channel_agg\n        nodes_num = general_info.con_num + general_info.cat_num\n        if input_graph_embedding.cls_num > 0:\n            nodes_num += input_graph_embedding.cls_num\n        a, b = zip(*[[i, j] for i in range(nodes_num) for j in range(nodes_num) if i != j])\n        self.indexes = torch.tensor([list(a), list(b)]).to(device)\n\n        # Parameters\n        self.node_dropouts = nn.ModuleList()\n        self.edge_dropouts = nn.ModuleList()\n        self.gnns = nn.ModuleList()\n        self.node_norms = nn.ModuleList()\n        self.edge_norms = nn.ModuleList()\n        for i in range(gnn_info.gnn_num):\n            self.node_dropouts.append(nn.Dropout(p=common_info.dropout))\n            if i > 0:\n                self.edge_dropouts.append(nn.Dropout(p=common_info.dropout))\n            # channels, mlp_output_size, mlp_hidden_size, mlp_layer_num, with_input_channels, with_edge_features\n            self.gnns.append(InteractionNetwork(self.channels,\n                                                common_info.latent_space_size,\n                                                common_info.latent_space_size,\n                                                gnn_info.in_mlp_deep,\n                                                with_input_channels=(i > 0),\n                                                with_edge_features=(i > 0)))\n            self.node_norms.append(nn.LayerNorm([self.channels, nodes_num, common_info.latent_space_size]))\n            if i < (gnn_info.gnn_num - 1):\n                self.edge_norms.append(nn.LayerNorm([self.channels,\n                                                     nodes_num * (nodes_num - 1),\n                                                     common_info.latent_space_size]))\n        if self.channels > 1 and self.channel_agg == IN_CHANNEL_AGG_MLP:\n            self.channel_mlp = nn.Linear(self.channels * common_info.latent_space_size, common_info.latent_space_size)\n\n    def forward_xai(self, nodes: torch.tensor, edges: Optional[torch.tensor] = None) -> torch.tensor:\n        \"\"\"\n\n        :param nodes: shape = [batch_size, node_num, features_size]\n        :param edges: shape = [batch_size, edge num, features_size]\n        :return: shape = [batch_size, node_num, features_size]\n        \"\"\"\n        batch_size = nodes.shape[0]\n        node_num = nodes.shape[1]\n\n        # Encoder GNN\n        for i, gnn in enumerate(self.gnns):\n            nodes = self.node_dropouts[i](nodes)\n            if i > 0:\n                self.edge_dropouts[i - 1](edges)\n            nodes, edges = gnn(x=nodes, edge_index=self.indexes, edge_attr=edges)\n            nodes = self.node_norms[i](nodes.permute(1, 0, 2, 3)).permute(1, 0, 2, 3)\n            if i < (len(self.gnns) - 1):\n                edges = self.edge_norms[i](edges.permute(1, 0, 2, 3)).permute(1, 0, 2, 3)\n        if self.channels > 1:\n            if self.channel_agg == IN_CHANNEL_AGG_MLP:\n                nodes = nn.functional.relu(self.channel_mlp(nodes.permute(1, 2, 3, 0).reshape(batch_size,\n                                                                                              node_num,\n                                                                                              -1)))\n            elif self.channel_agg == IN_CHANNEL_AGG_CONCAT:\n                nodes = nodes.permute(1, 2, 3, 0).reshape(batch_size, node_num, -1)\n            else:\n                nodes = nodes.sum(dim=0)\n        else:\n            nodes = nodes.squeeze()\n        return nodes, edges\n\n    def forward(self, nodes: torch.tensor, edges: Optional[torch.tensor] = None) -> torch.tensor:\n        \"\"\"\n\n        :param nodes: shape = [batch_size, node_num, features_size]\n        :param edges: shape = [batch_size, edge num, features_size]\n        :return: shape = [batch_size, node_num, features_size]\n        \"\"\"\n        nodes, _ = self.forward_xai(nodes, edges)\n        return nodes", "\nclass INEncoder(nn.Module):\n\n    def __init__(self,\n                 general_info: GeneralInfo,\n                 common_info: CommonInfo,\n                 input_graph_embedding: InputGraphEmbeddingInfo,\n                 gnn_info: GNNEmbeddingInfo,\n                 device: str):\n        super(INEncoder, self).__init__()\n        # Sanity checks\n        assert_msg = \"IN_CHANNEL_AGG={} is not allowed, only the following values are currently available: [{}, {}, {}]\"\n        assert gnn_info.in_channel_agg in [IN_CHANNEL_AGG_CONCAT, IN_CHANNEL_AGG_MLP, IN_CHANNEL_AGG_SUM], \\\n            assert_msg.format(gnn_info.in_channel_agg, IN_CHANNEL_AGG_CONCAT, IN_CHANNEL_AGG_MLP, IN_CHANNEL_AGG_SUM)\n\n        # General info\n        self.channels = gnn_info.in_channels\n        self.channel_agg = gnn_info.in_channel_agg\n        nodes_num = general_info.con_num + general_info.cat_num\n        if input_graph_embedding.cls_num > 0:\n            nodes_num += input_graph_embedding.cls_num\n        a, b = zip(*[[i, j] for i in range(nodes_num) for j in range(nodes_num) if i != j])\n        self.indexes = torch.tensor([list(a), list(b)]).to(device)\n\n        # Parameters\n        self.node_dropouts = nn.ModuleList()\n        self.edge_dropouts = nn.ModuleList()\n        self.gnns = nn.ModuleList()\n        self.node_norms = nn.ModuleList()\n        self.edge_norms = nn.ModuleList()\n        for i in range(gnn_info.gnn_num):\n            self.node_dropouts.append(nn.Dropout(p=common_info.dropout))\n            if i > 0:\n                self.edge_dropouts.append(nn.Dropout(p=common_info.dropout))\n            # channels, mlp_output_size, mlp_hidden_size, mlp_layer_num, with_input_channels, with_edge_features\n            self.gnns.append(InteractionNetwork(self.channels,\n                                                common_info.latent_space_size,\n                                                common_info.latent_space_size,\n                                                gnn_info.in_mlp_deep,\n                                                with_input_channels=(i > 0),\n                                                with_edge_features=(i > 0)))\n            self.node_norms.append(nn.LayerNorm([self.channels, nodes_num, common_info.latent_space_size]))\n            if i < (gnn_info.gnn_num - 1):\n                self.edge_norms.append(nn.LayerNorm([self.channels,\n                                                     nodes_num * (nodes_num - 1),\n                                                     common_info.latent_space_size]))\n        if self.channels > 1 and self.channel_agg == IN_CHANNEL_AGG_MLP:\n            self.channel_mlp = nn.Linear(self.channels * common_info.latent_space_size, common_info.latent_space_size)\n\n    def forward_xai(self, nodes: torch.tensor, edges: Optional[torch.tensor] = None) -> torch.tensor:\n        \"\"\"\n\n        :param nodes: shape = [batch_size, node_num, features_size]\n        :param edges: shape = [batch_size, edge num, features_size]\n        :return: shape = [batch_size, node_num, features_size]\n        \"\"\"\n        batch_size = nodes.shape[0]\n        node_num = nodes.shape[1]\n\n        # Encoder GNN\n        for i, gnn in enumerate(self.gnns):\n            nodes = self.node_dropouts[i](nodes)\n            if i > 0:\n                self.edge_dropouts[i - 1](edges)\n            nodes, edges = gnn(x=nodes, edge_index=self.indexes, edge_attr=edges)\n            nodes = self.node_norms[i](nodes.permute(1, 0, 2, 3)).permute(1, 0, 2, 3)\n            if i < (len(self.gnns) - 1):\n                edges = self.edge_norms[i](edges.permute(1, 0, 2, 3)).permute(1, 0, 2, 3)\n        if self.channels > 1:\n            if self.channel_agg == IN_CHANNEL_AGG_MLP:\n                nodes = nn.functional.relu(self.channel_mlp(nodes.permute(1, 2, 3, 0).reshape(batch_size,\n                                                                                              node_num,\n                                                                                              -1)))\n            elif self.channel_agg == IN_CHANNEL_AGG_CONCAT:\n                nodes = nodes.permute(1, 2, 3, 0).reshape(batch_size, node_num, -1)\n            else:\n                nodes = nodes.sum(dim=0)\n        else:\n            nodes = nodes.squeeze()\n        return nodes, edges\n\n    def forward(self, nodes: torch.tensor, edges: Optional[torch.tensor] = None) -> torch.tensor:\n        \"\"\"\n\n        :param nodes: shape = [batch_size, node_num, features_size]\n        :param edges: shape = [batch_size, edge num, features_size]\n        :return: shape = [batch_size, node_num, features_size]\n        \"\"\"\n        nodes, _ = self.forward_xai(nodes, edges)\n        return nodes", ""]}
{"filename": "src/models/building_blocks/interaction_network.py", "chunked_list": ["from typing import Optional\n\nimport torch\nfrom torch_geometric import nn as pyg_nn\n\nfrom src.models.building_blocks.mlp import MLP\n\n\ndef broadcast(src: torch.Tensor, other: torch.Tensor, dim: int):\n    if dim < 0:\n        dim = other.dim() + dim\n    if src.dim() == 1:\n        for _ in range(0, dim):\n            src = src.unsqueeze(0)\n    for _ in range(src.dim(), other.dim()):\n        src = src.unsqueeze(-1)\n    src = src.expand(other.size())\n    return src", "def broadcast(src: torch.Tensor, other: torch.Tensor, dim: int):\n    if dim < 0:\n        dim = other.dim() + dim\n    if src.dim() == 1:\n        for _ in range(0, dim):\n            src = src.unsqueeze(0)\n    for _ in range(src.dim(), other.dim()):\n        src = src.unsqueeze(-1)\n    src = src.expand(other.size())\n    return src", "\n\ndef scatter_sum(src: torch.Tensor, index: torch.Tensor, dim: int = -1,\n                out: Optional[torch.Tensor] = None,\n                dim_size: Optional[int] = None) -> torch.Tensor:\n    index = broadcast(index, src, dim)\n    if out is None:\n        size = list(src.size())\n        if dim_size is not None:\n            size[dim] = dim_size\n        elif index.numel() == 0:\n            size[dim] = 0\n        else:\n            size[dim] = int(index.max()) + 1\n        out = torch.zeros(size, dtype=src.dtype, device=src.device)\n        return out.scatter_add_(dim, index, src)\n    else:\n        return out.scatter_add_(dim, index, src)", "\n\nclass InteractionNetwork(pyg_nn.MessagePassing):\n    \"\"\"\n    Interaction Network as proposed in this paper:\n    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\n\n    Initial Code: https://colab.research.google.com/drive/1hirUfPgLU35QCSQSZ7T2lZMyFMOaK_OF?usp=sharing\n    \"\"\"\n    def __init__(self,\n                 channels: int,\n                 mlp_output_size: int,\n                 mlp_hidden_size: int,\n                 mlp_layer_num: int,\n                 with_input_channels: bool,\n                 with_edge_features: bool):\n        super().__init__()\n        self.channels = channels\n        self.with_input_channels = with_input_channels\n        self.with_edge_features = with_edge_features\n\n        self.lin_edge = torch.nn.ModuleList()\n        self.lin_node = torch.nn.ModuleList()\n        multiplier = 3 if with_edge_features else 2\n        for ch in range(self.channels):\n            self.lin_edge.append(MLP(mlp_hidden_size * multiplier, mlp_hidden_size, mlp_output_size, mlp_layer_num))\n            self.lin_node.append(MLP(mlp_hidden_size * 2, mlp_hidden_size, mlp_output_size, mlp_layer_num))\n\n    def forward(self, x, edge_index, edge_attr):\n        if self.with_input_channels:\n            assert len(x.shape) == 4\n            assert x.shape[0] == self.channels\n            if edge_attr is not None:\n                assert edge_attr.shape[0] == self.channels\n        else:\n            x = x.repeat(self.channels, 1, 1, 1)\n            if edge_attr is not None:\n                edge_attr = edge_attr.repeat(self.channels, 1, 1, 1)\n        edge_out, aggr = self.propagate(edge_index, x=(x, x), edge_feature=edge_attr)\n        node_out = torch.cat((x, aggr), dim=-1)\n        node_out = torch.stack([l(node_out[ch, :, :, :])\n                                for ch, l in enumerate(self.lin_node)], dim=0)\n        if self.with_edge_features:\n            edge_out = edge_attr + edge_out\n        node_out = x + node_out\n        return node_out, edge_out\n\n    def message(self, x_i, x_j, edge_feature):\n        if self.with_edge_features:\n            x = torch.cat((x_i, x_j, edge_feature), dim=-1)\n        else:\n            x = torch.cat((x_i, x_j), dim=-1)\n        x = torch.stack([l(x[ch, :, :, :])\n                        for ch, l in enumerate(self.lin_edge)], dim=0)\n        return x\n\n    def aggregate(self, inputs, index, dim_size=None):\n        # out = torch_scatter.scatter(inputs, index, dim=self.node_dim, dim_size=dim_size, reduce=\"sum\")\n        out = scatter_sum(inputs, index, dim=self.node_dim, dim_size=dim_size)\n        return (inputs, out)", ""]}
{"filename": "src/trainers/standard_problem_to_opt.py", "chunked_list": ["import torch.optim as optim\n\nfrom src.models.brain import Brain\nfrom src.models.brain_struct import *\nfrom src.trainers.trainer_factory import TrainerFactory\n\n\nclass StandardProblemToOpt(object):\n\n    def __init__(self, dataset_data, brain_params, problem_type: str, problem_size: int,\n                 target_embedding: bool):\n        self.dataset_data = dataset_data\n        self.brain_params = brain_params\n        self.problem_type = problem_type\n        self.problem_size = problem_size\n        self.target_embedding = target_embedding\n        self.weights = None\n        if problem_type == CLASSIFICATION:\n            self.weights = dataset_data.weights\n\n    def __call__(self, *args, **kwargs):\n        # Model\n        print('Building brain...')\n        (general_info, common_info, input_graph_embedding, _,\n         encoder_gnn_info, _, decoder_info) = build_brain_structs(self.dataset_data, self.brain_params)\n        # Brain\n        brain = Brain(general_info=general_info,\n                      common_info=common_info,\n                      input_graph_embedding=input_graph_embedding,\n                      encoder_gnn_info=encoder_gnn_info,\n                      decoder_info=decoder_info,\n                      device=self.brain_params[TRAINER_PARAMS][DEVICE]).to(self.brain_params[TRAINER_PARAMS][DEVICE])\n        print(brain)\n        print(\"Number of trainable parameters: {}\"\n              .format(sum(p.numel() for p in brain.parameters() if p.requires_grad)))\n        optimizer = optim.Adam(brain.parameters(), self.brain_params[TRAINER_PARAMS][TRAIN_LEARNING_RATE])\n        \n        # Trainer\n        print('Building trainer...')\n        trainer_type = (TrainerFactory.TRAINER_WITH_TARGET_EMBEDDING if self.target_embedding else\n                        TrainerFactory.TRAINER_WITHOUT_TARGET_EMBEDDING)\n        weights = self.weights if self.weights is None else self.weights.to(self.brain_params[TRAINER_PARAMS][DEVICE])\n        checkpoint_path = self.brain_params[TRAINER_PARAMS][PATH]\n        trainer = TrainerFactory.get_trainer(trainer_type=trainer_type,\n                                             problem_type=self.problem_type,\n                                             weights=weights,\n                                             checkpoint_path=checkpoint_path)\n        # Train-Test\n        print('Start training...')\n        return trainer.train_model(brain=brain,\n                                   optimizer=optimizer,\n                                   train_data=[self.dataset_data.x_train, self.dataset_data.y_train],\n                                   test_data=[self.dataset_data.x_test, self.dataset_data.y_test],\n                                   epochs=self.brain_params[TRAINER_PARAMS][EPOCHS],\n                                   batch_size=self.brain_params[TRAINER_PARAMS][BATCH_SIZE],\n                                   device=self.brain_params[TRAINER_PARAMS][DEVICE])", ""]}
{"filename": "src/trainers/trainer_te.py", "chunked_list": ["from typing import Optional\nimport torch\n\nfrom src.trainers.trainer import Trainer\n\n\nclass TrainerTE(Trainer):\n    def __init__(self,\n                 problem_type: str,\n                 weights: Optional[torch.tensor] = None,\n                 checkpoint_path: Optional[str] = None):\n        \"\"\" rainer class with Target Embedding.\n\n        NOTE: using Target Embedding means that edge features are used\n\n        :param brain: nn.Module, the brain to train/test\n        :param optimizer: the optimizer to use\n        :param problem_type: str, the problem to solve (REGRESSION or CLASSIFICATION)\n        :param weights: torch.tensor, in the CLASSIFICATION case, the weight of each class. Optional\n        \"\"\"\n        super(TrainerTE, self).__init__(problem_type, weights, checkpoint_path)\n\n    def get_train_batch(self, data, epoch_shuffle_idx, ini, fin, device):\n        if self.problem_type == Trainer.REGRESSION:\n            return ([data[0][epoch_shuffle_idx[ini:fin], :].to(device),   # shape: [batch_size, features_num]\n                     data[1][epoch_shuffle_idx[ini:fin], :].to(device),   # shape: [batch_size, node_num, node_feature_size]\n                     data[1][epoch_shuffle_idx[ini:fin], :].to(device)],  # shape: [batch_size, edge_num, edge_feature_size]\n                    data[1][epoch_shuffle_idx[ini:fin], :].squeeze().to(device))    # shape: [batch_size, target_num]\n        else:\n            return ([data[0][epoch_shuffle_idx[ini:fin], :].to(device),   # shape: [batch_size, features_num]\n                     data[1][epoch_shuffle_idx[ini:fin], :].to(device),   # shape: [batch_size, node_num, node_feature_size]\n                     data[1][epoch_shuffle_idx[ini:fin], :].to(device)],  # shape: [batch_size, edge_num, edge_feature_size]\n                    data[1][epoch_shuffle_idx[ini:fin], :].to(device))    # shape: [batch_size, target_num]\n\n    def get_test_batch(self, data, ini, fin, device):\n        if self.problem_type == Trainer.REGRESSION:\n            return ([data[0][ini:fin, :].to(device),   # shape: [batch_size, features_num]\n                     data[1][ini:fin, :].to(device),   # shape: [batch_size, node_num, node_feature_size]\n                     data[1][ini:fin, :].to(device)],  # shape: [batch_size, edge_num, edge_feature_size]\n                    data[1][ini:fin, :].squeeze().to(device))    # shape: [batch_size, target_num]\n        else:\n            return ([data[0][ini:fin, :].to(device),  # shape: [batch_size, features_num]\n                     data[1][ini:fin, :].to(device),  # shape: [batch_size, node_num, node_feature_size]\n                     data[1][ini:fin, :].to(device)],  # shape: [batch_size, edge_num, edge_feature_size]\n                    data[1][ini:fin, :].to(device))  # shape: [batch_size, target_num]", ""]}
{"filename": "src/trainers/trainer_factory.py", "chunked_list": ["from typing import Optional\n\nimport torch\n\nfrom src.trainers.trainer import Trainer\nfrom src.trainers.trainer_te import TrainerTE\nfrom src.trainers.trainer_wo_te import TrainerWOTE\n\n\nclass TrainerFactory(object):\n    TRAINER_WITH_TARGET_EMBEDDING = 'trainer_with_target_embedding'\n    TRAINER_WITHOUT_TARGET_EMBEDDING = 'trainer_without_target_embedding'\n\n    @staticmethod\n    def get_trainer(trainer_type: str,\n                    problem_type: str,\n                    weights: Optional[torch.tensor] = None,\n                    checkpoint_path: Optional[str] = None) -> Trainer:\n        if trainer_type == TrainerFactory.TRAINER_WITH_TARGET_EMBEDDING:\n            trainer = TrainerTE(problem_type, weights, checkpoint_path)\n        elif trainer_type == TrainerFactory.TRAINER_WITHOUT_TARGET_EMBEDDING:\n            trainer = TrainerWOTE(problem_type, weights, checkpoint_path)\n        else:\n            print('{} trainer is not implemented!'.format(trainer_type))\n            trainer = None\n        return trainer", "\nclass TrainerFactory(object):\n    TRAINER_WITH_TARGET_EMBEDDING = 'trainer_with_target_embedding'\n    TRAINER_WITHOUT_TARGET_EMBEDDING = 'trainer_without_target_embedding'\n\n    @staticmethod\n    def get_trainer(trainer_type: str,\n                    problem_type: str,\n                    weights: Optional[torch.tensor] = None,\n                    checkpoint_path: Optional[str] = None) -> Trainer:\n        if trainer_type == TrainerFactory.TRAINER_WITH_TARGET_EMBEDDING:\n            trainer = TrainerTE(problem_type, weights, checkpoint_path)\n        elif trainer_type == TrainerFactory.TRAINER_WITHOUT_TARGET_EMBEDDING:\n            trainer = TrainerWOTE(problem_type, weights, checkpoint_path)\n        else:\n            print('{} trainer is not implemented!'.format(trainer_type))\n            trainer = None\n        return trainer", ""]}
{"filename": "src/trainers/trainer.py", "chunked_list": ["import random\nimport time\nfrom typing import Callable, List, Optional, Tuple\n\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\n\nfrom src.common.constants import *", "\nfrom src.common.constants import *\n\n\nclass Trainer(nn.Module):\n\n    def __init__(self,\n                 problem_type: str,\n                 weights: Optional[torch.tensor] = None,\n                 checkpoint_path: str = None,\n                 logger_func: Optional[Callable] = print,\n                 test_on_train_dataset: bool = False):\n        \"\"\" Trainer class\n\n        :param problem_type: str, the problem to solve (REGRESSION or CLASSIFICATION)\n        :param weights: torch.tensor, in the CLASSIFICATION case, the weight of each class. Optional\n        \"\"\"\n        super(Trainer, self).__init__()\n        self.problem_type = problem_type\n        if problem_type == REGRESSION:\n            self.criterion = self.custom_mse\n            self.test_criterion = self.custom_mse\n            self.str_test = 'MSE'\n        elif problem_type == CLASSIFICATION:\n            self.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n            self.test_criterion = self.custom_accuracy\n            self.str_test = 'Accuracy'\n        self.logger_func = logger_func\n        self.test_on_train_dataset = test_on_train_dataset\n        self.checkpoint_path = checkpoint_path\n\n    def train_model(self,\n                    brain: nn.Module,\n                    optimizer,\n                    train_data: List[torch.tensor],\n                    test_data: List[torch.tensor],\n                    epochs: int,\n                    batch_size: int,\n                    device: str,\n                    extra_text: Optional[str]=None):\n        \"\"\" Main flux of train/test\n\n        :param brain: Model to train\n        :param optimizer: Optimizer to use\n        :param train_data: List of tensors to use for training\n        :param test_data: List of tensors to use for testing\n        :param epochs: int, number of epochs\n        :param batch_size: int, batch size\n        :param device: str, device to use\n        :param extra_text: str\n        :return:\n        \"\"\"\n        start_train = time.time()\n\n        # Preparamos el array de indices sobre el que nos apoyaremos para hacer shuffle en cada \u00e9poca\n        tot = train_data[0].shape[0]\n        tot_test = test_data[0].shape[0]\n        epoch_shuffle_idx = [i for i in range(tot)]\n\n        # For sobre las epocas\n        best_res = float('inf') if self.problem_type == REGRESSION else -float('inf')\n        best_res_str = ''\n        epoch_metrics = []\n        epoch_train_time = []\n        epoch_test_time = []\n        for epoch in range(epochs):\n            new_extra_text = (extra_text + \"EPOCH: {}/{} - \".format(epoch + 1, epochs) if extra_text is not None else\n                              \"EPOCH: {}/{} - \".format(epoch + 1, epochs))\n            start_train_epoch_time = time.time()\n            train_str = self.epoch_train(brain, optimizer, train_data, tot, epoch_shuffle_idx, batch_size, device, new_extra_text)\n            epoch_train_time.append(time.time() - start_train_epoch_time)\n            if self.test_on_train_dataset:\n                _, new_extra_text = self.epoch_test(brain, train_data, tot, batch_size, device, TRAIN_TITLE, new_extra_text)\n            start_test_epoch_time = time.time()\n            epoch_res, test_str = self.epoch_test(brain, test_data, tot_test, batch_size, device, TEST_TITLE, new_extra_text)\n            epoch_test_time.append(time.time() - start_test_epoch_time)\n            epoch_metrics.append(epoch_res)\n            if (((self.problem_type == REGRESSION) and (epoch_res.item() < best_res)) or\n                ((self.problem_type == CLASSIFICATION) and (epoch_res.item() > best_res))):\n                best_res = epoch_res.item()\n                best_res_str = ' - BEST: {:.4f}'.format(best_res)\n                if self.checkpoint_path is not None:\n                    torch.save({\n                        'epoch': epoch,\n                        'model_state_dict': brain.state_dict(),\n                        'optimizer_state_dict': optimizer.state_dict(),\n                        'loss': best_res\n                    }, self.checkpoint_path)\n            print(new_extra_text + train_str + test_str + best_res_str)\n\n        if self.problem_type == REGRESSION:\n            best_res, best_epoch = torch.tensor(epoch_metrics).min().item(), torch.argmin(torch.tensor(epoch_metrics)).item()\n        else:\n            best_res, best_epoch = torch.tensor(epoch_metrics).max().item(), torch.argmax(torch.tensor(epoch_metrics)).item()\n        self.logger_func('Best result: {} - epoch: {} - time: {:.1f}'.format(best_res, best_epoch + 1, time.time() - start_train))\n        return {METRIC: best_res,\n                EPOCH: best_epoch + 1,\n                TRAIN_TIME: torch.tensor(epoch_train_time).mean().item(),\n                TEST_TIME: torch.tensor(epoch_test_time).mean().item()}\n\n    def epoch_train(self,\n                    brain: nn.Module,\n                    optimizer,\n                    data: List[torch.tensor],\n                    dataset_size: int,\n                    epoch_shuffle_idx: List[int],\n                    batch_size: int,\n                    device: str,\n                    extra_text: Optional[str]=None) -> str:\n        \"\"\" Epoch train\n\n        :param brain: Model to train\n        :param optimizer: Optimizer to use\n        :param data: List of torch.tensor to use for training\n        :param dataset_size: int, size of the training dataset\n        :param epoch_shuffle_idx: list of indexes (used to shuffle the dataset in each epoch)\n        :param batch_size: int\n        :param device: str\n        :param extra_text: str\n        :return: str, the trace of training\n        \"\"\"\n        start_epoch = time.time()\n\n        # brain -> train mode\n        brain.train()\n\n        # Epoch shuffle\n        random.shuffle(epoch_shuffle_idx)\n\n        # For over the batches of the current epoch\n        ini = 0\n        fin = ini + batch_size\n        train_loss_list = []\n        title = TRAINING_TITLE if extra_text is None else extra_text + TRAINING_TITLE\n        progress_bool = True # TODO: a par\u00e1metro!\n        pbar = None\n        if progress_bool:\n            pbar = tqdm(total=int(dataset_size / batch_size) + 1, desc=title)\n\n        while True:\n            # Batch data preprocessing\n            forward_input, targets = self.get_train_batch(data=data,\n                                                          epoch_shuffle_idx=epoch_shuffle_idx,\n                                                          ini=ini,\n                                                          fin=fin,\n                                                          device=device)\n            # Optimization\n            optimizer.zero_grad()\n            predictions: torch.tensor = brain.forward(*forward_input)  # Shape: [batch_size, class_num]\n            total_loss_function = self.criterion(predictions, targets.squeeze().detach())\n            total_loss_function.backward()\n            torch.nn.utils.clip_grad_value_(self.parameters(), 1.0)\n            optimizer.step()\n\n            # Trace\n            train_loss_list.append(total_loss_function.detach().item())\n\n            if progress_bool:\n                pbar.update(1)\n            ini = fin\n            fin = ini + batch_size\n            if fin > dataset_size:\n                break\n\n            del total_loss_function\n            del predictions\n            del targets\n            del forward_input\n            if device == 'cuda':\n                torch.cuda.empty_cache()\n        trace_txt = 'Train Loss: {:.10f} - Time: {:.4f} - '.format(torch.tensor(train_loss_list).mean(),\n                                                                time.time() - start_epoch)\n        del train_loss_list\n        return trace_txt\n\n    def epoch_test(self,\n                   brain: nn.Module,\n                   epoch_data_test: List[torch.tensor],\n                   dataset_size: int,\n                   batch_size: int,\n                   device: str,\n                   test_type: str,\n                   extra_text: Optional[str]=None) -> Tuple[float, str]:\n        \"\"\" Epoch test\n\n        :param brain: nn.Module to test\n        :param epoch_data_test: List of torch.tensor to use for testing\n        :param dataset_size: int, size of the testing dataset\n        :param batch_size: int\n        :param device: str\n        :param test_type: str to use in the logging\n        :param extra_text: str\n        :return: Tuple[float->metric, str->trace of test results]\n        \"\"\"\n        start_test = time.time()\n\n        # brain -> eval mode\n        brain.eval()\n\n        # For over the batches of the current epoch\n        pre_list = []\n        true_list = []\n        title = test_type if extra_text is None else extra_text + test_type\n        progress_bool = False  # TODO: a par\u00e1metro!\n        pbar =None\n        if progress_bool:\n            pbar = tqdm(total=int(dataset_size / batch_size) + 1, desc=title)\n\n        with torch.no_grad():\n            ini = 0\n            fin = ini + batch_size\n            while True:\n                # Batch data preprocessing\n                forward_input, targets = self.get_test_batch(data=epoch_data_test,\n                                                             ini=ini,\n                                                             fin=fin,\n                                                             device=device)\n\n                # Test\n                predictions: torch.tensor = brain.forward(*forward_input)\n                pre_list = pre_list + predictions.detach().to('cpu').numpy().tolist()\n                true_list = true_list + targets.detach().to('cpu').numpy().tolist()\n\n                if progress_bool:\n                    pbar.update(1)\n                ini = fin\n                fin = min(ini + batch_size, dataset_size)\n                if ini == dataset_size:\n                    break\n                del predictions\n                del targets\n                del forward_input\n                if device == 'cuda':\n                    torch.cuda.empty_cache()\n        test_metric = self.test_criterion(torch.tensor(pre_list), torch.tensor(true_list))\n        trace_txt = '{} {}: {:.10f} - Time: {:.4f}'.format(test_type, self.str_test, test_metric,\n                                                           time.time() - start_test)\n\n        del pre_list, true_list\n        return test_metric, trace_txt\n\n    def get_train_batch(self, data, epoch_shuffle_idx, ini, fin, device):\n        raise NotImplementedError\n\n    def get_test_batch(self, data, ini, fin, device):\n        raise NotImplementedError\n\n    @staticmethod\n    def custom_accuracy(predictions: torch.tensor, targets: torch.tensor) -> torch.tensor:\n        \"\"\" Accuracy score\n\n        :param predictions: torch.tensor, shape = [batch_size, class_num]\n        :param targets: torch.tensor, shape = [batch_size, class_num]\n        :return: float\n        \"\"\"\n        preds = torch.argmax(predictions, dim=1).cpu()\n        trues = targets.squeeze().cpu()\n        return torch.tensor(accuracy_score(trues, preds))\n\n    @staticmethod\n    def custom_mse(predictions: torch.tensor, targets: torch.tensor) -> torch.tensor:\n        loss = torch.nn.MSELoss()\n        return loss(predictions.squeeze(), targets.squeeze())          ", ""]}
{"filename": "src/trainers/trainer_wo_te.py", "chunked_list": ["from typing import Optional\nimport torch\n\nfrom src.trainers.trainer import Trainer\n\n\nclass TrainerWOTE(Trainer):\n    def __init__(self,\n                 problem_type: str,\n                 weights: Optional[torch.tensor] = None,\n                 checkpoint_path: Optional[str] = None\n                 ):\n        \"\"\" Trainer class without Target Embedding.\n\n        NOTE: without Target Embedding, there is no edge features\n\n        :param problem_type: str, the problem to solve (REGRESSION or CLASSIFICATION)\n        :param weights: torch.tensor, in the CLASSIFICATION case, the weight of each class. Optional\n        \"\"\"\n        super(TrainerWOTE, self).__init__(problem_type, weights, checkpoint_path)\n\n    def get_train_batch(self, data, epoch_shuffle_idx, ini, fin, device):\n        return ([data[0][epoch_shuffle_idx[ini:fin], :].to(device)],  # shape: [batch_size, features_num]\n                data[1][epoch_shuffle_idx[ini:fin], :].to(device))    # shape: [batch_size, target_num]\n\n    def get_test_batch(self, data, ini, fin, device):\n        return ([data[0][ini:fin, :].to(device)],  # shape: [batch_size, features_num]\n                data[1][ini:fin, :].to(device))    # shape: [batch_size, target_num]", ""]}
{"filename": "src/datasets/experiment_dataset.py", "chunked_list": ["from collections import namedtuple\n\n\nExperimentData = namedtuple('ExperimentData',\n                            'x_train, y_train, x_test, y_test, con_num, cat_num, cat_degrees, problem_type, problem_size, weights, aux')\n\n\nclass ExperimentDataset(object):\n\n    def get_data_without_target_embedding(self, params) -> ExperimentData:\n        raise NotImplementedError\n\n    def get_data_with_target_embedding(self, params) -> ExperimentData:\n        raise NotImplementedError", ""]}
{"filename": "src/datasets/dataset_factory.py", "chunked_list": ["from typing import Dict\n\nfrom src.common.constants import *\nfrom src.datasets.etl_datasets.california_housing import CaliforniaHousing\n\n\nclass DatasetFactory(object):\n\n    def __init__(self, dataset_params: Dict):\n        self.dataset_params = dataset_params\n\n    def __call__(self, *args, **kwargs):\n        if self.dataset_params[DATASET_NAME] == 'California_Housing':\n            return CaliforniaHousing().get_data_without_target_embedding(self.dataset_params)", ""]}
{"filename": "src/datasets/etl_utils.py", "chunked_list": ["from typing import Dict, List, Optional, Tuple\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import QuantileTransformer, StandardScaler\n\n\ndef preprocess_continous_features(cont_feature_names: List[str],\n                                  cat_features_name: List[str],\n                                  n_quantiles: int,\n                                  output_distribution: str,\n                                  df_train: pd.DataFrame,\n                                  df_test: Optional[pd.DataFrame]=None,\n                                  discretize: Optional[bool]=True) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:\n    \"\"\" Continuous features preprocessing\n\n    :param cont_feature_names: List of str, the names of the continuous features\n    :param cat_features_name: List of str, the names of the categorical features\n    :param n_quantiles: int\n    :param output_distribution: str, 'normal' or 'uniform' -> output distribution of  QuantileTransformer\n    :param df_train: pd.DataFrame to discretize\n    :param df_test: pd.DataFrame to discretize\n    :param discretize: bool, if True the continuous fatures are discretized\n    :return: Tuple[pd.DataFrame, pd.DataFrame], the new version of df_train and df_test\n    \"\"\"\n    # Change in the distribution\n    if n_quantiles > 0:\n        tr = QuantileTransformer(n_quantiles=n_quantiles, random_state=0, output_distribution=output_distribution)\n    else:\n        tr = StandardScaler()\n    tr.fit(df_train[cont_feature_names])\n    cont_train = tr.transform(df_train[cont_feature_names])\n    if df_test is not None:\n        cont_test = tr.transform(df_test[cont_feature_names])\n\n    if len(cat_features_name) > 0:\n        new_train = np.concatenate((cont_train, df_train[cat_features_name].values), axis=1).tolist()\n        if df_test is not None:\n            new_test = np.concatenate((cont_test, df_test[cat_features_name].values), axis=1).tolist()\n        features_names = cont_feature_names + cat_features_name\n    else:\n        new_train = cont_train.tolist()\n        if df_test is not None:\n            new_test = cont_test.tolist()\n        features_names = cont_feature_names\n\n    x_train = pd.DataFrame(new_train, columns=features_names)\n    if df_test is not None:\n        x_test = pd.DataFrame(new_test, columns=features_names)\n\n    # One value for each quantile\n    if discretize:\n        for c in cont_feature_names:\n            c_min = x_train[c].values.min()\n            c_max = x_train[c].values.max()\n            cuant = (c_max - c_min) / n_quantiles\n            for i in range(n_quantiles):\n                for df in ([x_train, x_test] if df_test is not None else [x_train]):\n                    df[c][(df[c] >= c_min + i * cuant) & (df[c] <= c_min + (i + 1) * cuant)] = round(c_min + i * cuant, 2)\n    if df_test is not None:\n        return x_train, x_test\n    else:\n        return x_train, None", ""]}
{"filename": "src/datasets/etl_datasets/california_housing.py", "chunked_list": ["from sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nimport torch\n\nfrom src.common.constants import *\nfrom src.datasets.experiment_dataset import ExperimentData, ExperimentDataset\nfrom src.datasets.etl_utils import *\n\n\nclass CaliforniaHousing(ExperimentDataset):\n\n    def get_data_without_target_embedding(self, params: Dict) -> ExperimentData:\n        # Load data\n        print('Loading CALIFORNIA HOUSING data...')\n        data = fetch_california_housing(as_frame=True)\n        df = data['frame']\n        target_cols = ['MedHouseVal']\n        cont_cols = [c for c in df.columns if c not in target_cols]\n        cat_cols = []\n        print(df.columns)\n\n        print('Preprocessing continuous features...')\n        targets_df = df[target_cols]\n        df, _ = preprocess_continous_features(cont_feature_names=cont_cols,\n                                              cat_features_name=cat_cols,\n                                              n_quantiles=params[N_QUANTILE],\n                                              output_distribution=params[OUTPUT_DISTRIBUTION],\n                                              df_train=df.drop(target_cols, axis=1),\n                                              df_test=None,\n                                              discretize=False)\n        df = pd.DataFrame(data=np.concatenate([df.values, targets_df.values], axis=1),\n                          columns=list(df.columns) + target_cols)\n\n        # Split train-test\n        print('Splitting train/test data...')\n        data_train, data_test = train_test_split(df, test_size=params[PERCENTAGE_TEST], random_state=0)\n\n        # Features-target split\n        X_train, y_train = data_train.drop(target_cols, axis=1), data_train[target_cols]\n        X_test, y_test = data_test.drop(target_cols, axis=1), data_test[target_cols]\n\n        # Data-->Torch\n        print('Summary data:')\n        torch_x_train = torch.tensor(X_train[list(X_train.columns)].values, dtype=torch.float)\n        torch_y_train = torch.tensor(y_train[target_cols].values, dtype=torch.float)\n        print('\\tTrain Features: {}'.format(torch_x_train.shape))\n        print('\\tTrain Targets: {}'.format(torch_y_train.shape))\n        torch_x_test = torch.tensor(X_test[list(X_train.columns)].values, dtype=torch.float)\n        torch_y_test = torch.tensor(y_test[target_cols].values, dtype=torch.float)\n        print('\\tTest Features: {}'.format(torch_x_test.shape))\n        print('\\tTest Targets: {}'.format(torch_y_test.shape))\n\n        data = ExperimentData(x_train=torch_x_train,\n                              y_train=torch_y_train,\n                              x_test=torch_x_test,\n                              y_test=torch_y_test,\n                              con_num=len(cont_cols),\n                              cat_num=len(cat_cols),\n                              cat_degrees=[],\n                              problem_type=params[PROBLEM_TYPE],\n                              problem_size=params[PROBLEM_SIZE],\n                              weights=None,\n                              aux=None)\n\n        return data\n\n    def get_data_with_target_embedding(self, params: Dict) -> ExperimentData:\n        return None, None, None, None", "\nclass CaliforniaHousing(ExperimentDataset):\n\n    def get_data_without_target_embedding(self, params: Dict) -> ExperimentData:\n        # Load data\n        print('Loading CALIFORNIA HOUSING data...')\n        data = fetch_california_housing(as_frame=True)\n        df = data['frame']\n        target_cols = ['MedHouseVal']\n        cont_cols = [c for c in df.columns if c not in target_cols]\n        cat_cols = []\n        print(df.columns)\n\n        print('Preprocessing continuous features...')\n        targets_df = df[target_cols]\n        df, _ = preprocess_continous_features(cont_feature_names=cont_cols,\n                                              cat_features_name=cat_cols,\n                                              n_quantiles=params[N_QUANTILE],\n                                              output_distribution=params[OUTPUT_DISTRIBUTION],\n                                              df_train=df.drop(target_cols, axis=1),\n                                              df_test=None,\n                                              discretize=False)\n        df = pd.DataFrame(data=np.concatenate([df.values, targets_df.values], axis=1),\n                          columns=list(df.columns) + target_cols)\n\n        # Split train-test\n        print('Splitting train/test data...')\n        data_train, data_test = train_test_split(df, test_size=params[PERCENTAGE_TEST], random_state=0)\n\n        # Features-target split\n        X_train, y_train = data_train.drop(target_cols, axis=1), data_train[target_cols]\n        X_test, y_test = data_test.drop(target_cols, axis=1), data_test[target_cols]\n\n        # Data-->Torch\n        print('Summary data:')\n        torch_x_train = torch.tensor(X_train[list(X_train.columns)].values, dtype=torch.float)\n        torch_y_train = torch.tensor(y_train[target_cols].values, dtype=torch.float)\n        print('\\tTrain Features: {}'.format(torch_x_train.shape))\n        print('\\tTrain Targets: {}'.format(torch_y_train.shape))\n        torch_x_test = torch.tensor(X_test[list(X_train.columns)].values, dtype=torch.float)\n        torch_y_test = torch.tensor(y_test[target_cols].values, dtype=torch.float)\n        print('\\tTest Features: {}'.format(torch_x_test.shape))\n        print('\\tTest Targets: {}'.format(torch_y_test.shape))\n\n        data = ExperimentData(x_train=torch_x_train,\n                              y_train=torch_y_train,\n                              x_test=torch_x_test,\n                              y_test=torch_y_test,\n                              con_num=len(cont_cols),\n                              cat_num=len(cat_cols),\n                              cat_degrees=[],\n                              problem_type=params[PROBLEM_TYPE],\n                              problem_size=params[PROBLEM_SIZE],\n                              weights=None,\n                              aux=None)\n\n        return data\n\n    def get_data_with_target_embedding(self, params: Dict) -> ExperimentData:\n        return None, None, None, None", ""]}
