{"filename": "run.py", "chunked_list": ["import clrs\nimport os\nimport torch\nimport typer\n\nfrom config.hyperparameters import HP_SPACE\nfrom functools import partial\nfrom nn.models import EncodeProcessDecode, MF_Net, MF_NetPipeline\nfrom pathlib import Path\nfrom statistics import mean, stdev", "from pathlib import Path\nfrom statistics import mean, stdev\nfrom utils.data import load_dataset\nfrom utils.experiments import evaluate\nfrom utils.types import Algorithm\nfrom norm import set_seed\nfrom norm.experiments import Experiment, init_runs, run_exp\nfrom norm.io import dump, load\n\napp = typer.Typer(add_completion=False)", "\napp = typer.Typer(add_completion=False)\n\n\ndef choose_default_type(name: str):\n    assert name in ['float16', 'float32']\n\n    if name == 'float16':\n        return torch.HalfTensor\n\n    return torch.FloatTensor", "\n\ndef choose_model(name: str):\n    assert name in [\"epd\", \"mf_net\", \"mf_net_pipe\", \"mf_net_res\"]\n\n    if name == \"epd\":\n        model_class = EncodeProcessDecode\n    elif name == \"mf_net\":\n        model_class = MF_Net\n    else:\n        model_class = MF_NetPipeline\n\n    return model_class", "\n\ndef choose_hint_mode(mode: str):\n\n    assert mode in [\"io\", \"o\", \"none\"]\n\n    if mode == \"io\":\n        encode_hints, decode_hints = True, True\n    elif mode == \"o\":\n        encode_hints, decode_hints = False, True\n    elif mode == \"none\":\n        encode_hints, decode_hints = False, False\n\n    return encode_hints, decode_hints", "\n\ndef split_probes(feedback):\n    _, source, tail, weights, adj = feedback.features.inputs\n    return (\n        source.data.squeeze().numpy().argmax(-1),\n        tail.data.squeeze().numpy().argmax(-1),\n        weights.data.squeeze().numpy(),\n        adj.data.squeeze().numpy()\n    )", "\n\ndef _preprocess_yaml(config):\n    assert 'algorithm' in config.keys()\n    assert 'runs' in config.keys()\n    assert 'experiment' in config.keys()\n\n    for key in config['runs'].keys():\n        if key == 'hp_space':\n            config['runs'][key] = HP_SPACE[config['runs'][key]]\n            continue\n\n    return config", "\n\n@app.command()\ndef valid(exp_path: Path,\n          data_path: Path,\n          model: str = \"epd\",\n          hint_mode: str = \"io\",\n          max_steps: int = None,\n          num_cpus: int = None,\n          num_gpus: int = 1,\n          nw: int = 5,\n          no_feats: str = 'adj',\n          noise: bool = False,\n          processor: str = 'pgn',\n          aggregator: str = 'max',\n          save_path: Path = './runs',\n          dtype: str = 'float32',\n          num_test_trials: int = 5,\n          seed: int = None,):\n\n    torch.set_default_tensor_type(choose_default_type(dtype))\n\n    assert aggregator in ['max', 'sum', 'mean']\n    assert processor in ['mpnn', 'pgn']\n\n    if seed is None:\n        seed = int.from_bytes(os.urandom(2), byteorder=\"big\")\n\n    encode_hints, decode_hints = choose_hint_mode(hint_mode)\n    model_class = choose_model(model)\n\n    configs = _preprocess_yaml(load(exp_path))\n\n    alg = configs['algorithm']\n    set_seed(seed)\n\n    print(\"loading val...\")\n    vl_sampler, _ = load_dataset('val', alg, folder=data_path)\n    print(\"loading test...\")\n    ts_sampler, _ = load_dataset('test', alg, folder=data_path)\n    print(\"loading tr...\")\n    tr_sampler, spec = load_dataset('train', alg, folder=data_path)\n\n    print(\"loading done\")\n\n    model_fn = partial(model_class,\n                       spec=spec,\n                       dummy_trajectory=tr_sampler.next(1),\n                       decode_hints=decode_hints,\n                       encode_hints=encode_hints,\n                       add_noise=noise,\n                       no_feats=no_feats.split(','),\n                       max_steps=max_steps,\n                       processor=processor,\n                       aggregator=aggregator)\n\n    runs = init_runs(seed=seed,\n                     model_fn=model_fn,\n                     optim_fn=torch.optim.SGD,\n                     **configs['runs'])\n\n    experiment = Experiment(runs=runs,\n                            evaluate_fn=evaluate,\n                            save_path=save_path,\n                            num_cpus=num_cpus if num_cpus else num_gpus * nw,\n                            num_gpus=num_gpus,\n                            nw=nw,\n                            num_test_trials=num_test_trials,\n                            **configs['experiment'])\n\n    dump(dict(\n        alg=alg,\n        data_path=str(data_path),\n        hint_mode=hint_mode,\n        model=model,\n        aggregator=aggregator,\n        processor=processor,\n        no_feats=no_feats.split(','),\n        seed=seed,\n    ), save_path / experiment.name / 'config.json')\n\n    print(f\"Experiment name: {experiment.name}\")\n\n    run_exp(experiment=experiment,\n            tr_set=tr_sampler,\n            vl_set=vl_sampler,\n            ts_set=ts_sampler,\n            save_path=save_path)", "\n\n@app.command()\ndef test(alg: Algorithm,\n         test_path: Path,\n         data_path: Path,\n         max_steps: int = None,\n         test_set: str = 'test',):\n\n    from utils.metrics import eval_categorical, masked_mae\n    ts_sampler, spec = load_dataset(test_set, alg.value, folder=data_path)\n    best_run = load(test_path / 'best_run.json')['config']\n    config = load(test_path / 'config.json')\n\n    hint_mode = config['hint_mode']\n\n    encode_hints, decode_hints = choose_hint_mode(hint_mode)\n    model_class = choose_model(config['model'])\n\n    feedback = ts_sampler.next()\n    runs = []\n\n    adj = feedback.features.inputs[-2].data.numpy()\n\n    def predict(features, outputs, i):\n\n        model = model_class(spec=spec,\n                            dummy_trajectory=ts_sampler.next(1),\n                            num_hidden=best_run['num_hidden'],\n                            alpha=best_run['alpha'],\n                            aggregator=config['aggregator'],\n                            processor=config['processor'],\n                            max_steps=max_steps,\n                            no_feats=config['no_feats'],\n                            decode_hints=decode_hints,\n                            encode_hints=encode_hints,\n                            optim_fn=torch.optim.Adam)\n        model.restore_model(test_path / f'trial_{i}' / 'model_0.pth', 'cuda')\n\n        preds, aux = model.predict(features)\n        for key in preds:\n            preds[key].data = preds[key].data.cpu()\n\n        metrics = {}\n        for truth in feedback.outputs:\n            type_ = preds[truth.name].type_\n            y_pred = preds[truth.name].data.numpy()\n            y_true = truth.data.numpy()\n\n            if type_ == clrs.Type.SCALAR:\n                metrics[truth.name] = masked_mae(y_pred, y_true * adj).item()\n\n            elif type_ == clrs.Type.CATEGORICAL:\n                metrics[truth.name] = eval_categorical(y_pred, y_true).item()\n\n        dump(preds, test_path / f'trial_{i}' / f'preds_{i}.{test_set}.pkl')\n        dump(model.net_.flow_net.h_t.cpu(), test_path / f'trial_{i}' / f'H{i}.{test_set}.pth')\n        dump(model.net_.flow_net.edge_attr.cpu(), test_path / f'trial_{i}' / f'E{i}.{test_set}.pth')\n        return metrics\n\n    for i in range(5):\n        if not (test_path / f'trial_{i}' / 'model_0.pth').exists():\n            continue\n\n        runs.append(predict(feedback.features, feedback.outputs, i))\n        torch.cuda.empty_cache()\n    dump(runs, test_path / f'scores.{test_set}.json')\n\n    for key in runs[0]:\n        out = [evals[key] for evals in runs]\n        print(key, mean(out), \"pm\", stdev(out) if len(out) > 1 else 0)", "\n\nif __name__ == '__main__':\n    app()\n"]}
{"filename": "build_data.py", "chunked_list": ["import numpy as np\nimport typer\nimport os\n\nfrom config.data import DATA_SETTINGS\nfrom functools import partial\nfrom math import log\nfrom norm.io import dump\nfrom numpy.random import default_rng\nfrom numpy.typing import NDArray", "from numpy.random import default_rng\nfrom numpy.typing import NDArray\nfrom pathlib import Path\nfrom utils.data import algorithms\nfrom utils.data.graphs import erdos_renyi_full, two_community, bipartite\nfrom utils.types import Algorithm\n\n\ndef bfs_init(adj, rng, **kwargs):\n    num_nodes = adj.shape[0]\n    source = rng.choice(num_nodes)\n\n    return adj, source", "def bfs_init(adj, rng, **kwargs):\n    num_nodes = adj.shape[0]\n    source = rng.choice(num_nodes)\n\n    return adj, source\n\n\ndef ford_fulkerson_init(adj, rng, **kwargs):\n    num_nodes = adj.shape[0]\n\n    if kwargs['random_st']:\n        source = rng.choice(num_nodes // 2)\n        target = rng.choice(range(num_nodes // 2 + 1, num_nodes))\n\n        if source == target:\n            target = (source + 1) % num_nodes\n    else:\n        source, target = 0, num_nodes - 1\n\n    if kwargs['capacity']:\n        high = 10\n        capacity: NDArray = rng.integers(low=1, high=high, size=(num_nodes, num_nodes)) / high\n    else:\n        capacity: NDArray = np.ones((num_nodes, num_nodes))\n\n    capacity = np.maximum(capacity, capacity.T) * adj\n    capacity = capacity * np.abs((np.eye(num_nodes) - 1))\n\n    return capacity, source, target", "\n\n_INITS = {\n    Algorithm.ff: ford_fulkerson_init,\n    Algorithm.ffmc: ford_fulkerson_init\n}\n\n_GRAPH_DISTRIB = {\n    'two_community': two_community,\n    'erdos_renyi': erdos_renyi_full,", "    'two_community': two_community,\n    'erdos_renyi': erdos_renyi_full,\n    'bipartite': bipartite\n}\n\n\ndef accum_samples(alg, params, data):\n    algorithm_fn = getattr(algorithms, alg)\n    if alg == Algorithm.ek_bfs:\n        for _, probes in algorithm_fn(*params):\n            data.append(probes)\n\n    else:\n        _, probes = algorithm_fn(*params)\n        data.append(probes)\n\n    return data", "\n\ndef main(alg: Algorithm,\n         dataset_name: str = 'default',\n         graph_density: float = 0.35,\n         outer_prob: float = 0.05,\n         save_path: Path = './data/clrs',\n         graph_distrib: str = 'two_community',\n         weighted: bool = False,\n         directed: bool = False,\n         seed: int = None):\n\n    if seed is None:\n        seed = int.from_bytes(os.urandom(2), byteorder=\"big\")\n\n    assert graph_distrib in ['two_community', 'erdos_renyi', 'bipartite']\n\n    distrib = _GRAPH_DISTRIB[graph_distrib]\n\n    rng = default_rng(seed)\n    init_fn = _INITS[alg]\n\n    save_path = save_path / alg.value / dataset_name\n\n    probs = {}\n    graphs = {}\n    extras = {}\n\n    # First sample graphs (aids reproducibility).\n    for split in DATA_SETTINGS.keys():\n        num_nodes = DATA_SETTINGS[split]['length']\n        probs[split] = max(graph_density, 1.25*log(num_nodes)/num_nodes)\n\n        distrib = partial(distrib, outer_prob=outer_prob)\n        graphs[split] = []\n        for _ in range(DATA_SETTINGS[split]['num_samples']):\n            adj = distrib(num_nodes=num_nodes,\n                          prob=probs[split] if graph_distrib != 'bipartite' else rng.uniform(low=graph_density, high=1),\n                          directed=directed,\n                          weighted=weighted,\n                          rng=rng)\n            graphs[split].append(adj)\n\n    # Then run the algorithm for each of them.\n    for split in DATA_SETTINGS.keys():\n        extras[split] = dict()\n        data = []\n        num_nodes = DATA_SETTINGS[split]['length']\n        with typer.progressbar(range(DATA_SETTINGS[split]['num_samples']), label=split) as progress:\n            for i in progress:\n                params = init_fn(graphs[split][i],\n                                 rng,\n                                 random_st=graph_distrib != 'bipartite',\n                                 capacity=graph_distrib != 'bipartite')\n                data = accum_samples(alg, params, data)\n\n        key = list(data[0]['hint']['node'].keys())[0]\n        avg_length = []\n        for d in data:\n            avg_length.append(d['hint']['node'][key]['data'].shape[0])\n        # print statistics\n\n        extras[split]['max'] = max(avg_length)\n        extras[split]['avg'] = sum(avg_length) / len(avg_length)\n        print(\"[avg] traj len:\", extras[split]['avg'])\n        print(\"[max] traj len:\", extras[split]['max'])\n\n        dump(data, save_path / f'{split}_{alg}.pkl')\n\n    dump(dict(seed=seed,\n              graph_density=probs,\n              **extras),\n         save_path / 'config.json')", "\n\nif __name__ == '__main__':\n    typer.run(main)\n"]}
{"filename": "test/test_mpnn.py", "chunked_list": ["import os, sys; sys.path.insert(0, os.getcwd())  # noqa: E401, E702\n\nfrom nn.layers import MpnnConv\n\nimport os.path as osp\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T", "from torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.utils import to_dense_adj\nfrom torch.nn import Sequential, Linear\n\n\ndef set_seed(seed):\n    import torch\n    import random\n    import numpy as np\n\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)", "\n\nset_seed(0)\n\ndataset = 'Cora'\ntransform = T.Compose([\n    T.RandomNodeSplit(num_val=500, num_test=500),\n    T.TargetIndegree(),\n])\npath = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)", "])\npath = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)\ndataset = Planetoid(path, dataset, transform=transform)\ndata = dataset[0]\nnum_nodes, num_node_features = data.x.shape\n\ndata.edge_attr = to_dense_adj(data.edge_index, edge_attr=data.edge_attr, max_num_nodes=num_nodes)\ndata.edge_index = to_dense_adj(data.edge_index, max_num_nodes=num_nodes)\ndata.x = data.x.unsqueeze(0)\n", "data.x = data.x.unsqueeze(0)\n\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = MpnnConv(in_channels=dataset.num_features,\n                              edge_channels=data.num_edge_features,\n                              mid_channels=16,\n                              out_channels=16,\n                              net=Sequential(Linear(16, 16)),\n                              mid_activation=F.relu,\n                              aggregator='max',\n                              activation=F.elu)\n        self.conv2 = MpnnConv(in_channels=16,\n                              edge_channels=data.num_edge_features,\n                              mid_channels=16,\n                              out_channels=dataset.num_classes,\n                              net=Sequential(Linear(16, 16)),\n                              mid_activation=F.relu,\n                              aggregator='max',\n                              activation=None)\n\n    def forward(self):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n        x = F.dropout(x, training=self.training)\n        x = F.elu(self.conv1(x, edge_index, edge_attr))\n        x = F.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index, edge_attr)\n        x = x.squeeze()\n        return F.log_softmax(x, dim=1)", "\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel, data = Net().to(device), data.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-3)\n\n\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n    optimizer.step()", "\n\n@torch.no_grad()\ndef test():\n    model.eval()\n    log_probs, accs = model(), []\n    for _, mask in data('train_mask', 'test_mask'):\n        pred = log_probs[mask].max(1)[1]\n        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n        accs.append(acc)\n    return accs", "\n\nfor epoch in range(200):\n    train()\n    train_acc, test_acc = test()\n    print(f'Epoch: {epoch+1:03d}, Train: {train_acc:.4f}, Test: {test_acc:.4f}')\n"]}
{"filename": "utils/types.py", "chunked_list": ["from enum import Enum\n\n\nclass Algorithm(str, Enum):\n    bfs = 'bfs'\n    ek_bfs = 'ek_bfs'\n    dijkstra = 'dijkstra'\n    astar = 'a_star'\n    ff = 'ford_fulkerson'\n    ffmc = 'ford_fulkerson_mincut'", "\n\nclass SearchType(str, Enum):\n    large = 'large'\n    small = 'small'\n    one = 'one'\n\n\nclass ModelType(str, Enum):\n    dual_edp = 'dual_edp'\n    uniform = 'uniform'\n    normal = 'normal'", "class ModelType(str, Enum):\n    dual_edp = 'dual_edp'\n    uniform = 'uniform'\n    normal = 'normal'\n"]}
{"filename": "utils/__init__.py", "chunked_list": ["def set_seed(seed):\n    import numpy as np\n    import torch\n    import random\n\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n", "\n\ndef get_date():\n    from datetime import datetime\n    return datetime.utcnow().isoformat()[:-7]\n\n\ndef is_not_done_broadcast(lengths, i, tensor):\n    import torch\n    is_not_done = torch.as_tensor((lengths > i + 1) * 1.0, dtype=torch.float32).to(tensor.device)\n    while len(is_not_done.shape) < len(tensor.shape):\n        is_not_done = is_not_done.unsqueeze(-1)\n    return is_not_done", ""]}
{"filename": "utils/metrics/__init__.py", "chunked_list": ["import numpy as np\n\nfrom ._heuristic import constraints_accuracy, objective_node_accuracy, overall_accuracy  # noqa: F401\nfrom config.vars import CLASSIFICATION_ERROR_DECIMALS, REGRESSION_ERROR_DECIMALS\n\n\ndef accuracy(y_pred, y_true):\n    error = (y_pred == y_true) * 1.0\n    error = np.mean(error)\n    return round(error, CLASSIFICATION_ERROR_DECIMALS)", "\n\ndef eval_categorical(y_pred, y_true):\n    return accuracy(y_pred.argmax(-1), y_true.argmax(-1))\n\n\ndef mse(y_pred, y_true):\n    error = (y_pred - y_true)**2\n    error = np.mean(error)\n    return round(error, REGRESSION_ERROR_DECIMALS)", "\n\ndef mae(y_pred, y_true):\n    error = np.abs((y_pred - y_true)).mean()\n    return round(error, REGRESSION_ERROR_DECIMALS)\n\n\ndef masked_mae(y_pred, y_true):\n    mask = y_true != 0\n    error = np.abs(y_pred - y_true)[mask].mean()\n    return round(error, REGRESSION_ERROR_DECIMALS)", "\n\ndef masked_mse(y_pred, y_true):\n    mask = y_true != 0\n    error = (y_pred - y_true)**2\n    error = error[mask].mean()\n    return round(error, REGRESSION_ERROR_DECIMALS)\n\n\ndef dual_objective(y_pred, inputs):\n    for inp in inputs:\n        if inp.name == 'adj':\n            adj = inp.data.numpy()\n        elif inp.name == 'A':\n            weights = inp.data.numpy()\n\n    return round(constraints_accuracy(y_pred, weights, adj), CLASSIFICATION_ERROR_DECIMALS)", "\ndef dual_objective(y_pred, inputs):\n    for inp in inputs:\n        if inp.name == 'adj':\n            adj = inp.data.numpy()\n        elif inp.name == 'A':\n            weights = inp.data.numpy()\n\n    return round(constraints_accuracy(y_pred, weights, adj), CLASSIFICATION_ERROR_DECIMALS)\n", "\n\ndef mask_fn(pred, truth):\n    tp = ((pred > 0.5) * (truth > 0.5)) * 1.0\n    fp = ((pred > 0.5) * (truth < 0.5)) * 1.0\n    fn = ((pred < 0.5) * (truth > 0.5)) * 1.0\n\n    tp = np.sum(tp)\n    fp = np.sum(fp)\n    fn = np.sum(fn)\n\n    if tp + fp + fn == 0:\n        return 1.\n\n    if tp == 0:\n        return 0.\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    f_1 = 2.0 * precision * recall / (precision + recall)\n\n    return round(f_1, CLASSIFICATION_ERROR_DECIMALS)", "\n\ndef eval_one(pred, truth):\n    error = np.argmax(pred, -1) == np.argmax(truth, -1)\n    error = np.mean(error)\n    return round(error, CLASSIFICATION_ERROR_DECIMALS)\n"]}
{"filename": "utils/metrics/_heuristic.py", "chunked_list": ["def constraints_accuracy(y, w, adj):\n    from numpy import expand_dims, transpose\n\n    y = expand_dims(y, axis=-1)\n    cons_value = transpose(y, (0, 2, 1)) - y\n    cons = ((cons_value * adj <= w))\n\n    return (cons * adj).sum() / adj.sum()\n\n\ndef objective_node_accuracy(path_preds, truth):\n    accuracy = 0.0\n    for path_a, path_b in zip(path_preds, truth):\n        if path_a[-1] == path_b[-1]:\n            accuracy += 1\n\n    return accuracy / len(truth)", "\n\ndef objective_node_accuracy(path_preds, truth):\n    accuracy = 0.0\n    for path_a, path_b in zip(path_preds, truth):\n        if path_a[-1] == path_b[-1]:\n            accuracy += 1\n\n    return accuracy / len(truth)\n", "\n\ndef overall_accuracy(path_preds, truth):\n    accuracy = 0.0\n    for path_a, path_b in zip(path_preds, truth):\n        if len(path_a) == len(path_b) and path_a == path_b:\n            accuracy += 1\n\n    return accuracy / len(truth)\n", ""]}
{"filename": "utils/data/_helpers.py", "chunked_list": ["import clrs\nimport numpy as np\nfrom typing import List, Tuple\nfrom norm.performance import Timer\n\n\n_DataPoint = clrs.DataPoint\n_Trajectory = clrs.Trajectory\n_Trajectories = List[_Trajectory]\n", "_Trajectories = List[_Trajectory]\n\n\ndef _maybe_show_progress(length):\n    import os\n\n    if 'SHOW_LOADER_PROGRESS' in os.environ:\n        import typer\n        return typer.progressbar(length)\n\n    return None", "\n\ndef _update(progress):\n    if progress is None:\n        return\n\n    progress.update(1)\n\n\ndef batch_hints_helper(traj_hints: _Trajectories) -> Tuple[_Trajectory, List[int]]:\n    \"\"\"Batches a trajectory of hints samples along the time axis per probe.\n\n    Unlike i/o, hints have a variable-length time dimension. Before batching, each\n    trajectory is padded to the maximum trajectory length.\n\n    Args:\n    traj_hints: A hint trajectory of `DataPoints`s indexed by time then probe\n\n    Returns:\n    A |num probes| list of `DataPoint`s with the time axis stacked into `data`,\n    and a |sample| list containing the length of each trajectory.\n    \"\"\"\n\n    max_steps = 0\n    assert traj_hints  # non-empty\n    for sample_hint in traj_hints:\n        for dp in sample_hint:\n            assert dp.data.shape[1] == 1  # batching axis\n            if dp.data.shape[0] > max_steps:\n                max_steps = dp.data.shape[0]\n\n    n_samples = len(traj_hints)\n    batched_traj = traj_hints[0]  # construct batched trajectory in-place\n    hint_lengths = np.zeros(len(traj_hints))\n\n    for i in range(len(traj_hints[0])):\n        hint_i = traj_hints[0][i]\n        assert batched_traj[i].name == hint_i.name\n        batched_traj[i] = _DataPoint(\n            name=batched_traj[i].name,\n            location=batched_traj[i].location,\n            type_=batched_traj[i].type_,\n            data=np.zeros((max_steps, n_samples) + hint_i.data.shape[2:]))\n        batched_traj[i].data[:hint_i.data.shape[0], :1] = hint_i.data\n        if i > 0:\n            assert hint_lengths[0] == hint_i.data.shape[0]\n        else:\n            hint_lengths[0] = hint_i.data.shape[0]\n\n    progress = _maybe_show_progress(traj_hints[1:])\n\n    for hint_ind, cur_hint in enumerate(traj_hints[1:], start=1):\n        for i in range(len(cur_hint)):\n            assert batched_traj[i].name == cur_hint[i].name\n\n            batched_traj[i].data[:cur_hint[i].data.shape[0], hint_ind:hint_ind+1] = cur_hint[i].data\n\n            if i > 0:\n                assert hint_lengths[hint_ind] == cur_hint[i].data.shape[0]\n            else:\n                hint_lengths[hint_ind] = cur_hint[i].data.shape[0]\n\n        _update(progress)\n    return batched_traj, hint_lengths", "\ndef batch_hints_helper(traj_hints: _Trajectories) -> Tuple[_Trajectory, List[int]]:\n    \"\"\"Batches a trajectory of hints samples along the time axis per probe.\n\n    Unlike i/o, hints have a variable-length time dimension. Before batching, each\n    trajectory is padded to the maximum trajectory length.\n\n    Args:\n    traj_hints: A hint trajectory of `DataPoints`s indexed by time then probe\n\n    Returns:\n    A |num probes| list of `DataPoint`s with the time axis stacked into `data`,\n    and a |sample| list containing the length of each trajectory.\n    \"\"\"\n\n    max_steps = 0\n    assert traj_hints  # non-empty\n    for sample_hint in traj_hints:\n        for dp in sample_hint:\n            assert dp.data.shape[1] == 1  # batching axis\n            if dp.data.shape[0] > max_steps:\n                max_steps = dp.data.shape[0]\n\n    n_samples = len(traj_hints)\n    batched_traj = traj_hints[0]  # construct batched trajectory in-place\n    hint_lengths = np.zeros(len(traj_hints))\n\n    for i in range(len(traj_hints[0])):\n        hint_i = traj_hints[0][i]\n        assert batched_traj[i].name == hint_i.name\n        batched_traj[i] = _DataPoint(\n            name=batched_traj[i].name,\n            location=batched_traj[i].location,\n            type_=batched_traj[i].type_,\n            data=np.zeros((max_steps, n_samples) + hint_i.data.shape[2:]))\n        batched_traj[i].data[:hint_i.data.shape[0], :1] = hint_i.data\n        if i > 0:\n            assert hint_lengths[0] == hint_i.data.shape[0]\n        else:\n            hint_lengths[0] = hint_i.data.shape[0]\n\n    progress = _maybe_show_progress(traj_hints[1:])\n\n    for hint_ind, cur_hint in enumerate(traj_hints[1:], start=1):\n        for i in range(len(cur_hint)):\n            assert batched_traj[i].name == cur_hint[i].name\n\n            batched_traj[i].data[:cur_hint[i].data.shape[0], hint_ind:hint_ind+1] = cur_hint[i].data\n\n            if i > 0:\n                assert hint_lengths[hint_ind] == cur_hint[i].data.shape[0]\n            else:\n                hint_lengths[hint_ind] = cur_hint[i].data.shape[0]\n\n        _update(progress)\n    return batched_traj, hint_lengths", ""]}
{"filename": "utils/data/graphs.py", "chunked_list": ["import numpy as np\nimport networkx as nx\nfrom itertools import product\nfrom numpy.typing import NDArray\nfrom numpy.random import Generator, default_rng\nfrom typing import Optional\n\n\ndef _make_weights_undirected(w):\n    w = np.triu(w)\n    return np.triu(w) + np.triu(w, 1).T", "def _make_weights_undirected(w):\n    w = np.triu(w)\n    return np.triu(w) + np.triu(w, 1).T\n\n\ndef _erdos_renyi(num_nodes: int,\n                 prob: float,\n                 directed: bool = False,\n                 weighted: bool = False,\n                 rng: Optional[Generator] = None) -> NDArray:\n\n    assert num_nodes >= 0 and 0 < prob <= 1\n\n    if rng is None:\n        rng = default_rng()\n\n    adj_matrix = rng.random((num_nodes, num_nodes)) <= prob\n\n    if not directed:\n        adj_matrix = adj_matrix + adj_matrix.T\n\n    weights = None\n    if weighted:\n        weights = rng.uniform(low=0.0, high=1.0, size=(num_nodes, num_nodes))\n        if not directed:\n            weights = _make_weights_undirected(weights)\n\n    return adj_matrix, weights", "\n\ndef erdos_renyi_full(num_nodes: int,\n                     prob: float,\n                     directed: bool = False,\n                     weighted: bool = False,\n                     rng: Optional[Generator] = None) -> NDArray:\n\n    adj_matrix, weights = _erdos_renyi(num_nodes=num_nodes,\n                                       prob=prob,\n                                       directed=directed,\n                                       weighted=weighted,\n                                       rng=rng)\n\n    adj_matrix = adj_matrix.astype(dtype=np.float32)\n\n    return adj_matrix * weights if weighted else adj_matrix", "\n\ndef two_community(num_nodes: int,\n                  prob: float,\n                  outer_prob: float,\n                  directed: bool = False,\n                  weighted: bool = False,\n                  rng: Optional[Generator] = None) -> NDArray:\n\n    assert num_nodes % 2 == 0\n    adj_matrix_1, _ = _erdos_renyi(num_nodes=num_nodes // 2,\n                                   prob=prob,\n                                   directed=directed,\n                                   weighted=weighted,\n                                   rng=rng)\n    adj_matrix_2, _ = _erdos_renyi(num_nodes=num_nodes // 2,\n                                   prob=prob,\n                                   directed=directed,\n                                   weighted=weighted,\n                                   rng=rng)\n\n    adj_matrix = np.zeros((num_nodes, num_nodes))\n\n    N = num_nodes // 2\n    adj_matrix[:N, :N] = adj_matrix_1\n    adj_matrix[N:, N:] = adj_matrix_2\n\n    cart = list(product(range(N), range(N, num_nodes)))\n    mask = rng.binomial(n=1, p=outer_prob, size=len(cart))\n\n    n = 0\n    while mask.sum() == 0:  # prevent disconnected graph\n        mask = rng.binomial(n=1, p=outer_prob + (0.01 * n), size=len(cart))\n        n += 1\n\n    for i, e in enumerate(cart):\n        if mask[i]:\n            u, v = e\n            adj_matrix[u, v] = 1.\n\n    if not directed:\n        adj_matrix = np.maximum(adj_matrix, adj_matrix.T)\n\n    return adj_matrix", "\n\ndef bipartite(num_nodes: int,\n              prob: float,\n              outer_prob: float = None,  # unused param\n              directed: bool = True,\n              weighted: bool = False,\n              rng: Optional[Generator] = None) -> NDArray:\n\n    if rng is None:\n        rng = default_rng()\n\n    N = (num_nodes-2) // 2\n\n    adj_matrix = np.zeros((num_nodes, num_nodes))\n\n    set_a = list(range(1, N+1))\n    set_b = list(range(N+1, num_nodes-1))\n\n    cart = list(product(set_a, set_b))\n    mask = rng.binomial(n=1, p=prob, size=len(cart))\n\n    connected_nodes_b = np.unique(\n        [y for x, y in np.array(cart)[np.argwhere(mask)].squeeze()]\n    )\n\n    n = 0\n    while len(set_b) != len(connected_nodes_b):  # prevent disconnected graph\n        mask = rng.binomial(n=1, p=prob + (0.01 * n), size=len(cart))\n        connected_nodes_b = np.unique(\n            [y for x, y in np.array(cart)[np.argwhere(mask)].squeeze()]\n        )\n        n += 1\n\n    for i, e in enumerate(cart):\n        if mask[i]:\n            u, v = e\n            adj_matrix[u, v] = 1.\n\n    adj_matrix[0, :max(set_a)+1] = 1.\n    adj_matrix[min(set_b):, -1] = 1.\n\n    if not directed:\n        adj_matrix = np.maximum(adj_matrix, adj_matrix.T)\n\n    assert nx.is_connected(nx.from_numpy_matrix(adj_matrix))\n\n    return adj_matrix", ""]}
{"filename": "utils/data/_loader.py", "chunked_list": ["import clrs\nimport numpy as np\nimport torch\n\nfrom ._helpers import batch_hints_helper\nfrom .algorithms import SPECS\nfrom clrs._src.probing import split_stages\nfrom norm.io import load\nfrom pathlib import Path\nfrom torch import as_tensor, index_select", "from pathlib import Path\nfrom torch import as_tensor, index_select\nfrom typing import List, Optional, Tuple, Union\nfrom utils.types import Algorithm\n\n_DataPoint = clrs.DataPoint\n_Spec = clrs.Spec\n_Type = clrs.Type\n_Trajectory = clrs.Trajectory\n_Trajectories = List[_Trajectory]", "_Trajectory = clrs.Trajectory\n_Trajectories = List[_Trajectory]\n_Features = clrs.Features\n_Feedback = clrs.Feedback\n\n\ndef _batch_io(traj_io):\n    from clrs._src.samplers import _batch_io as _batch_io_helper\n\n    batched_traj = _batch_io_helper(traj_io)\n    for traj in batched_traj:\n        traj.data = as_tensor(traj.data, dtype=torch.float32)\n    return batched_traj", "\n\ndef _batch_hints(traj_hints):\n    batched_traj, hint_lengths = batch_hints_helper(traj_hints)\n    for traj in batched_traj:\n        traj.data = as_tensor(traj.data, dtype=torch.float32)\n    return batched_traj, hint_lengths\n\n\ndef _subsample_data(trajectory, indices, axis=0):\n    sampled_traj = []\n    for dp in trajectory:\n        sampled_data = index_select(dp.data, dim=axis, index=indices)\n        sampled_traj.append(_DataPoint(dp.name, dp.location, dp.type_, sampled_data))\n\n    return sampled_traj", "\ndef _subsample_data(trajectory, indices, axis=0):\n    sampled_traj = []\n    for dp in trajectory:\n        sampled_data = index_select(dp.data, dim=axis, index=indices)\n        sampled_traj.append(_DataPoint(dp.name, dp.location, dp.type_, sampled_data))\n\n    return sampled_traj\n\n\ndef _load_probes(file_name: Path, spec: _Spec):\n    inputs = []\n    outputs = []\n    hints = []\n\n    file_probes = load(file_name)\n\n    for probes in file_probes:\n        inp, outp, hint = split_stages(probes, spec)\n        inputs.append(inp)\n        outputs.append(outp)\n        hints.append(hint)\n\n    return inputs, outputs, hints", "\n\ndef _load_probes(file_name: Path, spec: _Spec):\n    inputs = []\n    outputs = []\n    hints = []\n\n    file_probes = load(file_name)\n\n    for probes in file_probes:\n        inp, outp, hint = split_stages(probes, spec)\n        inputs.append(inp)\n        outputs.append(outp)\n        hints.append(hint)\n\n    return inputs, outputs, hints", "\n\nclass Loader:\n    def __init__(self, file_name: Union[Path, List[Path]], spec: _Spec):\n\n        if isinstance(file_name, list):\n            inputs, outputs, hints = [], [], []\n            for name in file_name:\n                inp, out, hin = _load_probes(name, spec)\n                inputs.extend(inp)\n                outputs.extend(out)\n                hints.extend(hin)\n        else:\n            inputs, outputs, hints = _load_probes(file_name, spec)\n\n        # Batch and pad trajectories to max(T).\n        self._inputs = _batch_io(inputs)\n        self._outputs = _batch_io(outputs)\n        self._hints, self._lengths = _batch_hints(hints)\n        self._num_samples = len(inputs)\n        self._file_name = file_name\n        self._spec = spec\n\n    def __add__(self, other):\n        return Loader([self._file_name, other._file_name], self._spec)\n\n    def next(self, batch_size: Optional[int] = None) -> _Feedback:\n        \"\"\"Subsamples trajectories from the pre-generated dataset.\n\n        Args:\n          batch_size: Optional batch size. If `None`, returns entire dataset.\n\n        Returns:\n          Subsampled trajectories.\n        \"\"\"\n\n        if batch_size:\n            if batch_size > self._num_samples:\n                raise ValueError(\n                    f'Batch size {batch_size} > dataset size {self._num_samples}.')\n\n            # Returns a fixed-size random batch.\n            raw_indices = np.random.choice(self._num_samples, (batch_size,), replace=True)\n            indices = as_tensor(raw_indices, dtype=torch.long)\n\n            inputs = _subsample_data(self._inputs, indices, axis=0)\n            outputs = _subsample_data(self._outputs, indices, axis=0)\n            hints = _subsample_data(self._hints, indices, axis=1)\n            lengths = self._lengths[raw_indices]\n\n        else:\n            # Returns the full dataset.\n            inputs = self._inputs\n            hints = self._hints\n            lengths = self._lengths\n            outputs = self._outputs\n\n        return _Feedback(_Features(inputs, hints, lengths), outputs)\n\n    def get(self, index: int) -> _Feedback:\n        index = torch.LongTensor([index])\n        inputs = _subsample_data(self._inputs, index, axis=0)\n        outputs = _subsample_data(self._outputs, index, axis=0)\n        hints = _subsample_data(self._hints, index, axis=1)\n        lengths = self._lengths[index]\n\n        for hint in hints:\n            hint.data = hint.data[:int(lengths)]\n\n        return _Feedback(_Features(inputs, hints, lengths), outputs)", "\n\ndef load_dataset(split: str,\n                 algorithm: Algorithm,\n                 folder: Path) -> Tuple[Loader, _Spec]:\n\n    if algorithm not in SPECS:\n        raise NotImplementedError(f\"No implementation of algorithm {algorithm}\")\n\n    spec = SPECS[algorithm]\n    loader = Loader(file_name=folder / f'{split}_{algorithm}.pkl', spec=spec)\n\n    return loader, spec", ""]}
{"filename": "utils/data/__init__.py", "chunked_list": ["from ._loader import load_dataset, Loader  # noqa: F401\n\n\ndef adj_mat(features):\n    for inp in features.inputs:\n        if inp.name == \"adj\":\n            return inp.data\n\n\ndef edge_attr_mat(features):\n    for inp in features.inputs:\n        if inp.name == \"A\":\n            return inp.data", "\ndef edge_attr_mat(features):\n    for inp in features.inputs:\n        if inp.name == \"A\":\n            return inp.data\n"]}
{"filename": "utils/data/algorithms/__init__.py", "chunked_list": ["from ._graphs import a_star, dijkstra, ford_fulkerson, ford_fulkerson_mincut, max_flow_min_cut_lp, max_flow_lp, min_cut_lp, ek_bfs  # noqa: F401\nfrom ._specs import SPECS, ALGS  # noqa: F401\n\nfrom clrs._src.algorithms import bfs  # noqa: F401\n"]}
{"filename": "utils/data/algorithms/_specs.py", "chunked_list": ["import clrs\nimport types\n\n_Stage = clrs.Stage\n_Location = clrs.Location\n_Type = clrs.Type\n\nSPECS = types.MappingProxyType({\n    **clrs._src.specs.SPECS,\n    'dijkstra': {", "    **clrs._src.specs.SPECS,\n    'dijkstra': {\n        'pos': (_Stage.INPUT, _Location.NODE, _Type.SCALAR),\n        's': (_Stage.INPUT, _Location.NODE, _Type.MASK_ONE),\n        't': (_Stage.INPUT, _Location.NODE, _Type.MASK_ONE),\n        'A': (_Stage.INPUT, _Location.EDGE, _Type.SCALAR),\n        'adj': (_Stage.INPUT, _Location.EDGE, _Type.MASK),\n        'pi': (_Stage.OUTPUT, _Location.NODE, _Type.POINTER),\n        'pi_h': (_Stage.HINT, _Location.NODE, _Type.POINTER),\n        'd': (_Stage.HINT, _Location.NODE, _Type.SCALAR),", "        'pi_h': (_Stage.HINT, _Location.NODE, _Type.POINTER),\n        'd': (_Stage.HINT, _Location.NODE, _Type.SCALAR),\n        'mark': (_Stage.HINT, _Location.NODE, _Type.MASK),\n        'in_queue': (_Stage.HINT, _Location.NODE, _Type.MASK),\n        'u': (_Stage.HINT, _Location.NODE, _Type.MASK_ONE)\n    },\n    'ford_fulkerson': {\n        'pos': (_Stage.INPUT, _Location.NODE, _Type.SCALAR),\n        's': (_Stage.INPUT, _Location.NODE, _Type.MASK_ONE),\n        't': (_Stage.INPUT, _Location.NODE, _Type.MASK_ONE),", "        's': (_Stage.INPUT, _Location.NODE, _Type.MASK_ONE),\n        't': (_Stage.INPUT, _Location.NODE, _Type.MASK_ONE),\n        'A': (_Stage.INPUT, _Location.EDGE, _Type.SCALAR),\n        'adj': (_Stage.INPUT, _Location.EDGE, _Type.MASK),\n        'w': (_Stage.INPUT, _Location.EDGE, _Type.SCALAR),\n        'mask': (_Stage.HINT, _Location.NODE, _Type.MASK),\n        'pi_h': (_Stage.HINT, _Location.NODE, _Type.POINTER),\n        '__is_bfs_op': (_Stage.HINT, _Location.GRAPH, _Type.MASK),\n        'f_h': (_Stage.HINT, _Location.EDGE, _Type.SCALAR),\n        'f': (_Stage.OUTPUT, _Location.EDGE, _Type.SCALAR)", "        'f_h': (_Stage.HINT, _Location.EDGE, _Type.SCALAR),\n        'f': (_Stage.OUTPUT, _Location.EDGE, _Type.SCALAR)\n    },\n    'ford_fulkerson_mincut': {\n        'pos': (_Stage.INPUT, _Location.NODE, _Type.SCALAR),\n        's': (_Stage.INPUT, _Location.NODE, _Type.MASK_ONE),\n        't': (_Stage.INPUT, _Location.NODE, _Type.MASK_ONE),\n        'A': (_Stage.INPUT, _Location.EDGE, _Type.SCALAR),\n        'adj': (_Stage.INPUT, _Location.EDGE, _Type.MASK),\n        'w': (_Stage.INPUT, _Location.EDGE, _Type.SCALAR),", "        'adj': (_Stage.INPUT, _Location.EDGE, _Type.MASK),\n        'w': (_Stage.INPUT, _Location.EDGE, _Type.SCALAR),\n        'mask': (_Stage.HINT, _Location.NODE, _Type.MASK),\n        'pi_h': (_Stage.HINT, _Location.NODE, _Type.POINTER),\n        'f_h': (_Stage.HINT, _Location.EDGE, _Type.SCALAR),\n        'c_h': (_Stage.HINT, _Location.NODE, _Type.CATEGORICAL),\n        '__is_bfs_op': (_Stage.HINT, _Location.GRAPH, _Type.MASK),\n        'f': (_Stage.OUTPUT, _Location.EDGE, _Type.SCALAR),\n        'c': (_Stage.OUTPUT, _Location.NODE, _Type.CATEGORICAL),\n    },", "        'c': (_Stage.OUTPUT, _Location.NODE, _Type.CATEGORICAL),\n    },\n})\n\nALGS = [*clrs._src.specs.CLRS_30_ALGS,\n        'ford_fulkerson',\n        'ford_fulkerson_min_cut']\n"]}
{"filename": "utils/data/algorithms/_graphs.py", "chunked_list": ["import clrs\nimport numpy as np\nimport chex\nimport networkx as nx\n\nfrom ._specs import SPECS\nfrom clrs._src import probing\nfrom clrs._src.probing import ProbesDict\nfrom typing import Tuple\n", "from typing import Tuple\n\n\n_Stage = clrs.Stage\n_Location = clrs.Location\n_Type = clrs.Type\n_Array = np.ndarray\n_Out = Tuple[_Array, ProbesDict]\n_OutputClass = clrs.OutputClass\n", "_OutputClass = clrs.OutputClass\n\n\ndef a_star(A: _Array, h: _Array, s: int, t: int, max_iter=5000) -> _Out:\n    \"\"\"A* search algorithm (Hart et al., 1968)\"\"\"\n\n    chex.assert_rank(A, 2)\n    probes = probing.initialize(SPECS['a_star'])\n\n    A_pos = np.arange(A.shape[0])\n\n    probing.push(\n        probes,\n        _Stage.INPUT,\n        next_probe={\n            'pos': np.copy(A_pos) * 1.0 / A.shape[0],\n            's': probing.mask_one(s, A.shape[0]),\n            't': probing.mask_one(t, A.shape[0]),\n            'A': np.copy(A),\n            'adj': probing.graph(np.copy(A))\n        })\n\n    d = np.zeros(A.shape[0])\n    mark = np.zeros(A.shape[0])\n    in_queue = np.zeros(A.shape[0])\n    f = np.zeros(A.shape[0])\n    pi = np.arange(A.shape[0])\n    d[s] = 0\n    f[s] = h[s]\n    in_queue[s] = 1\n\n    probing.push(\n        probes,\n        _Stage.HINT,\n        next_probe={\n            'pi_h': np.copy(pi),\n            'd': np.copy(d),\n            'f': np.copy(f),\n            'mark': np.copy(mark),\n            'in_queue': np.copy(in_queue),\n            'u': probing.mask_one(s, A.shape[0])\n        })\n\n    while in_queue.any():\n\n        u = np.argsort(f + (1.0 - in_queue) * 1e9)[0]  # drop-in for extract-min\n\n        if in_queue[u] == 0 or u == t:\n            break\n\n        in_queue[u] = 0\n        mark[u] = 1\n\n        for v in range(A.shape[0]):\n            if A[u, v] != 0:\n                if mark[v] == 0 or d[u] + A[u, v] < d[v]:\n                    pi[v] = u\n                    d[v] = d[u] + A[u, v]\n                    f[v] = d[v] - h[v]\n                    mark[v] = 1\n                    in_queue[v] = 1\n\n        probing.push(\n            probes,\n            _Stage.HINT,\n            next_probe={\n                'pi_h': np.copy(pi),\n                'd': np.copy(d),\n                'f': np.copy(f),\n                'mark': np.copy(mark),\n                'in_queue': np.copy(in_queue),\n                'u': probing.mask_one(u, A.shape[0])\n            })\n\n    probing.push(probes, _Stage.OUTPUT, next_probe={'pi': np.copy(pi)})\n    probing.finalize(probes)\n\n    return pi, probes", "\n\ndef dijkstra(A: _Array, s: int, t: int, early_stop: bool = False) -> _Out:\n    \"\"\"Dijkstra's single-source shortest path (Dijkstra, 1959).\"\"\"\n\n    chex.assert_rank(A, 2)\n    probes = probing.initialize(SPECS['dijkstra'])\n    A_pos = np.arange(A.shape[0])\n    probing.push(\n        probes,\n        _Stage.INPUT,\n        next_probe={\n            'pos': np.copy(A_pos) * 1.0 / A.shape[0],\n            's': probing.mask_one(s, A.shape[0]),\n            't': probing.mask_one(t, A.shape[0]),\n            'A': np.copy(A),\n            'adj': probing.graph(np.copy(A))\n        })\n\n    d = np.zeros(A.shape[0])\n    mark = np.zeros(A.shape[0])\n    in_queue = np.zeros(A.shape[0])\n    pi = np.arange(A.shape[0])\n    d[s] = 0\n    in_queue[s] = 1\n\n    probing.push(\n        probes,\n        _Stage.HINT,\n        next_probe={\n            'pi_h': np.copy(pi),\n            'd': np.copy(d),\n            'mark': np.copy(mark),\n            'in_queue': np.copy(in_queue),\n            'u': probing.mask_one(s, A.shape[0])\n        })\n\n    for _ in range(A.shape[0]):\n        u = np.argsort(d + (1.0 - in_queue) * 1e9)[0]  # drop-in for extract-min\n\n        if in_queue[u] == 0 or (early_stop and u == t):\n            break\n\n        mark[u] = 1\n        in_queue[u] = 0\n        for v in range(A.shape[0]):\n            if A[u, v] != 0:\n                if mark[v] == 0 and (in_queue[v] == 0 or d[u] + A[u, v] < d[v]):\n                    pi[v] = u\n                    d[v] = d[u] + A[u, v]\n                    in_queue[v] = 1\n\n        probing.push(\n            probes,\n            _Stage.HINT,\n            next_probe={\n                'pi_h': np.copy(pi),\n                'd': np.copy(d),\n                'mark': np.copy(mark),\n                'in_queue': np.copy(in_queue),\n                'u': probing.mask_one(u, A.shape[0])\n            })\n\n    probing.push(probes, _Stage.OUTPUT, next_probe={'pi': np.copy(pi)})\n    probing.finalize(probes)\n\n    return pi, probes", "\n\ndef max_flow_lp(adj: _Array, capacity: _Array, s: int, t: int):\n    \"\"\"Max flow LP formulation.\"\"\"\n\n    chex.assert_rank(adj, 2)\n    probes = probing.initialize(SPECS['max_flow_lp'])\n    A_pos = np.arange(adj.shape[0])\n    probing.push(\n        probes,\n        _Stage.INPUT,\n        next_probe={\n            'pos': np.copy(A_pos) * 1.0 / adj.shape[0],\n            's': probing.mask_one(s, adj.shape[0]),\n            't': probing.mask_one(t, adj.shape[0]),\n            'A': np.copy(capacity),\n            'adj': probing.graph(np.copy(adj))\n        })\n\n    probing.push(\n        probes,\n        _Stage.OUTPUT,\n        next_probe={\n            'unsup_lp_flow': np.empty(1)\n        }\n    )\n\n    probing.finalize(probes)\n\n    return None, probes", "\n\ndef min_cut_lp(adj: _Array, capacity: _Array, s: int, t: int):\n    \"\"\"Min-Cut LP formulation.\"\"\"\n\n    chex.assert_rank(adj, 2)\n    probes = probing.initialize(SPECS['min_cut_lp'])\n    A_pos = np.arange(adj.shape[0])\n    probing.push(\n        probes,\n        _Stage.INPUT,\n        next_probe={\n            'pos': np.copy(A_pos) * 1.0 / adj.shape[0],\n            's': probing.mask_one(s, adj.shape[0]),\n            't': probing.mask_one(t, adj.shape[0]),\n            'A': np.copy(capacity),\n            'adj': probing.graph(np.copy(adj))\n        })\n\n    probing.push(\n        probes,\n        _Stage.OUTPUT,\n        next_probe={\n            's': np.array([[1, 0]]).repeat(adj.shape[0], axis=0),\n        }\n    )\n\n    probing.finalize(probes)\n\n    return None, probes", "\n\ndef max_flow_min_cut_lp(adj: _Array, capacity: _Array, s: int, t: int):\n\n    chex.assert_rank(adj, 2)\n    probes = probing.initialize(SPECS['max_flow_min_cut_lp'])\n    A_pos = np.arange(adj.shape[0])\n    probing.push(\n        probes,\n        _Stage.INPUT,\n        next_probe={\n            'pos': np.copy(A_pos) * 1.0 / adj.shape[0],\n            's': probing.mask_one(s, adj.shape[0]),\n            't': probing.mask_one(t, adj.shape[0]),\n            'A': np.copy(capacity),\n            'adj': probing.graph(np.copy(adj))\n        })\n\n    probing.push(\n        probes,\n        _Stage.OUTPUT,\n        next_probe={\n            'unsup_lp_flow': np.empty(1),\n            's': np.array([[1, 0]]).repeat(adj.shape[0], axis=0),\n        }\n    )\n\n    probing.finalize(probes)\n\n    return None, probes", "\n\ndef _ff_impl(A: _Array, s: int, t: int, probes, w):\n    f = np.zeros((A.shape[0], A.shape[0]))\n    df = np.array(0)\n\n    C = _minimum_cut(A, s, t)\n\n    def reverse(pi):\n        u, v = pi[t], t\n        while u != v:\n            yield u, v\n            v = u\n            u = pi[u]\n\n    d = np.zeros(A.shape[0])\n    msk = np.zeros(A.shape[0])\n    pi = np.arange(A.shape[0])\n    d[s] = 0\n    msk[s] = 1\n\n    probing.push(\n        probes,\n        _Stage.HINT,\n        next_probe={\n            'mask': np.copy(msk),\n            'd': np.copy(d),\n            'pi_h': np.copy(pi),\n            'f_h': np.copy(f),\n            'df': np.copy(df),\n            'c_h': np.copy(C),\n            '__is_bfs_op': np.copy([1])\n        })\n\n    while True:\n        for _ in range(A.shape[0]):\n            prev_d = np.copy(d)\n            prev_msk = np.copy(msk)\n            for u in range(A.shape[0]):\n                for v in range(A.shape[0]):\n                    if prev_msk[u] == 1 and A[u, v] - abs(f[u, v]) > 0:\n                        if msk[v] == 0 or prev_d[u] + w[u, v] < d[v]:\n                            d[v] = prev_d[u] + w[u, v]\n                            pi[v] = u\n                        msk[v] = 1\n\n            probing.push(\n                probes,\n                _Stage.HINT,\n                next_probe={\n                    'pi_h': np.copy(pi),\n                    'd': np.copy(prev_d),\n                    'mask': np.copy(msk),\n                    'f_h': np.copy(f),\n                    'df': np.copy(df),\n                    'c_h': np.copy(C),\n                    '__is_bfs_op': np.copy([1])\n                })\n\n            if np.all(d == prev_d):\n                break\n\n        if pi[t] == t:\n            break\n\n        df = min([\n            A[u, v] - f[u, v]\n            for u, v in reverse(pi)\n        ])\n\n        for u, v in reverse(pi):\n            f[u, v] += df\n            f[v, u] -= df\n\n        d = np.zeros(A.shape[0])\n        msk = np.zeros(A.shape[0])\n        pi = np.arange(A.shape[0])\n        d[s] = 0\n        msk[s] = 1\n        probing.push(\n            probes,\n            _Stage.HINT,\n            next_probe={\n                'pi_h': np.copy(pi),\n                'd': np.copy(d),\n                'mask': np.copy(msk),\n                'f_h': np.copy(f),\n                'df': np.copy(df),\n                'c_h': np.copy(C),\n                '__is_bfs_op': np.array([0])\n            })\n\n    return f, probes", "\n\ndef ford_fulkerson(A: _Array, s: int, t: int):\n\n    chex.assert_rank(A, 2)\n    probes = probing.initialize(SPECS['ford_fulkerson'])\n    A_pos = np.arange(A.shape[0])\n\n    rng = np.random.default_rng(0)\n\n    w = rng.random(size=A.shape)\n    w = np.maximum(w, w.T) * probing.graph(np.copy(A))\n\n    probing.push(\n        probes,\n        _Stage.INPUT,\n        next_probe={\n            'pos': np.copy(A_pos) * 1.0 / A.shape[0],\n            's': probing.mask_one(s, A.shape[0]),\n            't': probing.mask_one(t, A.shape[0]),\n            'A': np.copy(A),\n            'adj': probing.graph(np.copy(A)),\n            'w': np.copy(w),\n        })\n\n    f, probes = _ff_impl(A, s, t, probes, w)\n\n    probing.push(\n        probes,\n        _Stage.OUTPUT,\n        next_probe={\n            'f': np.copy(f)\n        }\n    )\n    probing.finalize(probes)\n\n    return f, probes", "\n\ndef ford_fulkerson_mincut(A: _Array, s: int, t: int):\n    chex.assert_rank(A, 2)\n    probes = probing.initialize(SPECS['ford_fulkerson_mincut'])\n    A_pos = np.arange(A.shape[0])\n\n    rng = np.random.default_rng(0)\n\n    w = rng.random(size=A.shape)\n    w = np.maximum(w, w.T) * probing.graph(np.copy(A))\n\n    probing.push(\n        probes,\n        _Stage.INPUT,\n        next_probe={\n            'pos': np.copy(A_pos) * 1.0 / A.shape[0],\n            's': probing.mask_one(s, A.shape[0]),\n            't': probing.mask_one(t, A.shape[0]),\n            'A': np.copy(A),\n            'adj': probing.graph(np.copy(A)),\n            'w': np.copy(w)\n        })\n\n    f, probes = _ff_impl(A, s, t, probes, w)\n\n    probing.push(\n        probes,\n        _Stage.OUTPUT,\n        next_probe={\n            'f': np.copy(f),\n            'c': _minimum_cut(A, s, t)\n        }\n    )\n\n    probing.finalize(probes)\n\n    return f, probes", "\n\ndef _minimum_cut(A, s, t):\n    C = np.zeros((A.shape[0], 2))\n\n    graph = nx.from_numpy_matrix(A)\n    nx.set_edge_attributes(graph, {(i, j): A[i, j] for i, j in zip(*A.nonzero())},\n                           name='capacity')\n\n    _, cuts = nx.minimum_cut(graph, s, t)\n\n    for v in cuts[0]:\n        C[v][0] = 1\n\n    for v in cuts[1]:\n        C[v][1] = 1\n\n    return C", "\n\ndef _masked_array(a):\n    a = np.empty_like(a)\n    a.fill(_OutputClass.MASKED)\n    return a\n\n\n# TEST PURPOSE\n\ndef ek_bfs(A: _Array, s: int, t: int):\n    chex.assert_rank(A, 2)\n    A_pos = np.arange(A.shape[0])\n    f = np.zeros((A.shape[0], A.shape[0]))\n    df = np.array(0)\n\n    def reverse(pi):\n        u, v = pi[t], t\n        while u != v:\n            yield u, v\n            v = u\n            u = pi[u]\n\n    while True:\n        probes = probing.initialize(SPECS['ek_bfs'])\n        probing.push(\n            probes,\n            _Stage.INPUT,\n            next_probe={\n                'pos': np.copy(A_pos) * 1.0 / A.shape[0],\n                's': probing.mask_one(s, A.shape[0]),\n                't': probing.mask_one(t, A.shape[0]),\n                'A': np.copy(A),\n                'adj': probing.graph(np.copy(A)),\n                'f_h': np.copy(f)\n            })\n\n        pi, probes = _bfs_ek_impl(A, s, f, probes)\n\n        probing.push(\n            probes,\n            _Stage.OUTPUT,\n            next_probe={\n                'pi': np.copy(pi)\n            }\n        )\n\n        if pi[t] == t:\n            break\n\n        df = min([\n            A[u, v] - f[u, v]\n            for u, v in reverse(pi)\n        ])\n\n        for u, v in reverse(pi):\n            f[u, v] += df\n            f[v, u] -= df\n\n        probing.finalize(probes)\n        yield pi, probes\n\n    probing.finalize(probes)\n\n    yield pi, probes\n    return", "# TEST PURPOSE\n\ndef ek_bfs(A: _Array, s: int, t: int):\n    chex.assert_rank(A, 2)\n    A_pos = np.arange(A.shape[0])\n    f = np.zeros((A.shape[0], A.shape[0]))\n    df = np.array(0)\n\n    def reverse(pi):\n        u, v = pi[t], t\n        while u != v:\n            yield u, v\n            v = u\n            u = pi[u]\n\n    while True:\n        probes = probing.initialize(SPECS['ek_bfs'])\n        probing.push(\n            probes,\n            _Stage.INPUT,\n            next_probe={\n                'pos': np.copy(A_pos) * 1.0 / A.shape[0],\n                's': probing.mask_one(s, A.shape[0]),\n                't': probing.mask_one(t, A.shape[0]),\n                'A': np.copy(A),\n                'adj': probing.graph(np.copy(A)),\n                'f_h': np.copy(f)\n            })\n\n        pi, probes = _bfs_ek_impl(A, s, f, probes)\n\n        probing.push(\n            probes,\n            _Stage.OUTPUT,\n            next_probe={\n                'pi': np.copy(pi)\n            }\n        )\n\n        if pi[t] == t:\n            break\n\n        df = min([\n            A[u, v] - f[u, v]\n            for u, v in reverse(pi)\n        ])\n\n        for u, v in reverse(pi):\n            f[u, v] += df\n            f[v, u] -= df\n\n        probing.finalize(probes)\n        yield pi, probes\n\n    probing.finalize(probes)\n\n    yield pi, probes\n    return", "\n\ndef _bfs_ek_impl(A: _Array, s: int, f: int, probes):\n\n    reach = np.zeros(A.shape[0])\n    reach[s] = 1\n    pi = np.arange(A.shape[0])\n\n    probing.push(\n        probes,\n        _Stage.HINT,\n        next_probe={\n            'reach_h': np.copy(reach),\n            'pi_h': np.copy(pi),\n        })\n\n    while True:\n        prev_reach = np.copy(reach)\n\n        for i in range(A.shape[0]):\n            for j in range(A.shape[0]):\n                if A[i, j] - f[i, j] > 0 and prev_reach[i] == 1:\n                    if pi[j] == j and j != s:\n                        pi[j] = i\n                    reach[j] = 1\n\n        probing.push(\n            probes,\n            _Stage.HINT,\n            next_probe={\n                'reach_h': np.copy(reach),\n                'pi_h': np.copy(pi),\n            })\n\n        if np.all(reach == prev_reach):\n            break\n\n    return pi, probes", ""]}
{"filename": "utils/experiments/__init__.py", "chunked_list": ["from ._evaluation import evaluate, EVAL_FN  # noqa: F401\n"]}
{"filename": "utils/experiments/_evaluation.py", "chunked_list": ["import clrs\nfrom utils.metrics import accuracy, eval_one, mse, mask_fn, eval_categorical, masked_mae, masked_mse\n\n_Type = clrs.Type\n\n\ndef evaluate(model, feedback, extras=None, verbose=False):\n    out = {}\n    predictions, (raw_preds, aux) = model.predict(feedback.features)\n\n    if extras:\n        out.update(extras)\n\n    if verbose and aux:\n        losses, total_loss = model.verbose_loss(feedback, raw_preds, aux)\n        out.update(losses)\n        out.update({'val_loss': total_loss})\n\n    out.update(_eval_preds(predictions, feedback, verbose))\n\n    return out", "\n\ndef _eval_preds(preds, feedback, verbose=False):\n    evals = {}\n    extras = {}\n\n    for truth in feedback.outputs:\n        assert truth.name in preds\n        pred = preds[truth.name]\n        assert pred.name == truth.name\n        assert pred.location == truth.location\n        assert pred.type_ == truth.type_\n\n        y_hat = pred.data.cpu().numpy()\n        y = truth.data.numpy()\n\n        if truth.type_ == clrs.Type.SCALAR:\n            evals[truth.name + \"_mae\"] = masked_mae(y_hat, y).item()\n            evals[truth.name + \"_mse\"] = masked_mse(y_hat, y).item()\n        else:\n            evals[truth.name] = EVAL_FN[truth.type_](y_hat, y).item()\n\n    evals['score'] = evals['f_mse']  # sum([v for v in evals.values()]) / len(evals)\n\n    if verbose:\n        evals = {\n            **evals,\n            **extras,\n        }\n\n    return evals", "\n\nEVAL_FN = {\n    clrs.Type.SCALAR: mse,\n    clrs.Type.MASK: mask_fn,\n    clrs.Type.MASK_ONE: eval_one,\n    clrs.Type.CATEGORICAL: eval_categorical,\n    clrs.Type.POINTER: accuracy\n}\n", "}\n"]}
{"filename": "config/vars.py", "chunked_list": ["REGRESSION_ERROR_DECIMALS = 5\nCLASSIFICATION_ERROR_DECIMALS = 3\n"]}
{"filename": "config/data.py", "chunked_list": ["DATA_SETTINGS = {\n    'train': {\n        'num_samples': 1000,\n        'length': 16\n    },\n    'val': {\n        'num_samples': 128,\n        'length': 16\n    },\n    'test': {", "    },\n    'test': {\n        'num_samples': 128,\n        'length': 16\n    },\n    'test_2x': {\n        'num_samples': 128,\n        'length': 32\n    },\n    'test_4x': {", "    },\n    'test_4x': {\n        'num_samples': 128,\n        'length': 64\n    },\n    # 'test_6x': {\n    #     'num_samples': 128,\n    #     'length': 96\n    # },\n    # 'test_8x': {", "    # },\n    # 'test_8x': {\n    #     'num_samples': 128,\n    #     'length': 128\n    # },\n    # 'test_10x': {\n    #     'num_samples': 128,\n    #     'length': 160\n    # },\n    # 'test_12x': {", "    # },\n    # 'test_12x': {\n    #     'num_samples': 128,\n    #     'length': 192\n    # },\n    # 'test_14x': {\n    #     'num_samples': 128,\n    #     'length': 224\n    # },\n    # 'test_16x': {", "    # },\n    # 'test_16x': {\n    #     'num_samples': 128,\n    #     'length': 256\n    # }\n\n}\n"]}
{"filename": "config/hyperparameters.py", "chunked_list": ["from functools import partial\nfrom norm.experiments.samplers import integer, uniform\n\n\n_LARGE = {\n    'model': dict(num_hidden=partial(integer, a=16, b=512),\n                  alpha=partial(uniform, a=0, b=0)),\n    'optim': dict(\n        lr=partial(uniform, a=1e-5, b=1e-1),\n        weight_decay=partial(uniform, a=1e-5, b=1e-1)", "        lr=partial(uniform, a=1e-5, b=1e-1),\n        weight_decay=partial(uniform, a=1e-5, b=1e-1)\n    )\n}\n\n_SMALL_FF = {\n    'model': dict(num_hidden=partial(integer, a=64, b=72),  # 114-138\n                  alpha=partial(uniform, a=0, b=1)),\n    'optim': dict(\n        lr=partial(uniform, 1e-3, b=1e-2),", "    'optim': dict(\n        lr=partial(uniform, 1e-3, b=1e-2),\n        weight_decay=partial(uniform, a=1e-3, b=4e-3)\n    )\n}\n\n_ONE_FF = {\n    'model': dict(num_hidden=lambda: 68,  # 114-138\n                  alpha=partial(uniform, a=0, b=0)),\n    'optim': dict(", "                  alpha=partial(uniform, a=0, b=0)),\n    'optim': dict(\n        lr=lambda: 0.009341493994646139,\n        weight_decay=lambda: 0.003420373065077989,\n    )\n}\n\n_ONE_FF_MC = {\n    'model': dict(num_hidden=lambda: 65,\n                  alpha=partial(uniform, a=0, b=0)),", "    'model': dict(num_hidden=lambda: 65,\n                  alpha=partial(uniform, a=0, b=0)),\n    'optim': dict(\n        lr=lambda: 0.009868199084919982,\n        weight_decay=lambda: 0.0017345516681916279\n    )\n}\n\nHP_SPACE = {\n    'dual_sp_large': _LARGE,", "HP_SPACE = {\n    'dual_sp_large': _LARGE,\n    'ff_large': _LARGE,\n    'ff_mc_large': _LARGE,\n    'ff_small': _SMALL_FF,\n    'ff_mc_small': _SMALL_FF,\n    'ff_one': _ONE_FF,\n    'ff_mc_one': _ONE_FF_MC\n}\n", "}\n"]}
{"filename": "nn/__init__.py", "chunked_list": ["from .models import EncodeProcessDecode  # noqa: 401\n"]}
{"filename": "nn/losses/__init__.py", "chunked_list": ["import clrs\nimport torch\nfrom utils.data import adj_mat\nfrom nn.models.impl import _expand_to\n\n_Feedback = clrs.Feedback\n_Location = clrs.Location\n_OutputClass = clrs.OutputClass\n_Spec = clrs.Spec\n_Stage = clrs.Stage", "_Spec = clrs.Spec\n_Stage = clrs.Stage\n_Type = clrs.Type\n_DataPoint = clrs.DataPoint\n\nEPS = 1e-12\n\n\ndef cross_entropy(y_pred, y_true, num_classes):\n    from torch import mean, sum\n    from torch.nn.functional import one_hot, log_softmax\n    return mean(-sum(\n        one_hot(y_true, num_classes) * log_softmax(y_pred, dim=-1),\n        dim=-1\n    ), dim=-1)", "def cross_entropy(y_pred, y_true, num_classes):\n    from torch import mean, sum\n    from torch.nn.functional import one_hot, log_softmax\n    return mean(-sum(\n        one_hot(y_true, num_classes) * log_softmax(y_pred, dim=-1),\n        dim=-1\n    ), dim=-1)\n\n\ndef mse_loss(y_pred, y_true):\n    from torch import mean\n    return mean((y_pred - y_true)**2, dim=-1)", "\ndef mse_loss(y_pred, y_true):\n    from torch import mean\n    return mean((y_pred - y_true)**2, dim=-1)\n\n\ndef mask_loss(y_pred, y_true):\n    from torch import abs, exp, log1p, maximum, zeros_like\n    return maximum(y_pred, zeros_like(y_pred)) - y_pred * y_true + log1p(exp(-abs(y_pred)))\n", "\n\ndef dual_loss(dual_y, inputs, alpha, device='cpu'):\n    from torch import mean, sum, take_along_dim\n    from torch.linalg import vector_norm\n\n    for inp in inputs:\n        if inp.name == 'adj':\n            adj = inp.data.to(device)\n        elif inp.name == 'A':\n            weights = inp.data.to(device)\n        elif inp.name == 's':\n            source = inp.data.to(device)\n        elif inp.name == 't':\n            target = inp.data.to(device)\n\n    source_idxs = source.argmax(dim=-1, keepdims=True)\n    target_idxs = target.argmax(dim=-1, keepdims=True)\n\n    y_s = take_along_dim(dual_y, source_idxs, dim=1)\n    y_t = take_along_dim(dual_y, target_idxs, dim=1)\n\n    dual_y = dual_y.unsqueeze(-1)\n\n    # main objective: max y(t) - y(s)\n    e1 = (y_t - y_s).unsqueeze(-1)\n\n    # penalty term constraint: \\forall u,v : y(v) - y(u) <= w_uv\n    e2 = dual_y.permute((0, 2, 1)) - dual_y\n    e2 = e2 * adj\n    e2 = (e2 - weights) * (e2 > weights).float()\n\n    # penalty term constraint: \\forall u: y(u) >= 0\n    e3 = -dual_y * ((dual_y < 0) * 1.0)\n\n    return -e1.mean() + mean(sum(e2, dim=-1)) + mean(sum(e3, dim=-1)) + alpha * vector_norm(e1, ord=2)**2", "\n\ndef max_flow(x, inputs, device='cpu'):\n\n    from torch import bmm, mean, sum\n\n    batch_len, num_nodes, _ = x.shape\n\n    for inp in inputs:\n        if inp.name == 's':\n            source = inp.data.to(device)\n        elif inp.name == 't':\n            target = inp.data.to(device)\n\n    # main objective: max sum_{(s,v) \\in E} x_sv\n\n    e1 = bmm(source.unsqueeze(1), x).squeeze()\n    e2 = bmm(target.unsqueeze(1), x).squeeze()\n\n    e1 = -mean(sum(e1, dim=-1))\n    e2 = mean(sum(e2, dim=-1))\n\n    return e1 + e2", "\n\ndef min_cut(S, inputs, device='cpu', reducer=torch.mean):\n    import torch\n\n    for inp in inputs:\n        if inp.name == 'A':\n            capacity = inp.data.to(device)\n        elif inp.name == 's':\n            source = inp.data.to(device)\n        elif inp.name == 't':\n            target = inp.data.to(device)\n\n    num_cuts = S.shape[-1]\n\n    S = S.softmax(-1)\n    S_t = S.transpose(1, 2)\n\n    l_cut = _3d_trace(S_t @ capacity @ S) / _3d_trace(S_t @ _3d_diag(capacity.sum(-1)) @ S)\n    l_ort = torch.linalg.matrix_norm(S_t @ S / torch.linalg.matrix_norm(S_t @ S, keepdims=True) -\n                                     torch.eye(num_cuts, device=device) / torch.tensor(num_cuts, device=device).sqrt()\n                                     )\n\n    source = torch.bmm(source.unsqueeze(1), S).squeeze()\n    target = torch.bmm(target.unsqueeze(1), S).squeeze()\n    l_dot = (source * target).sum(-1)  # dot-product\n\n    loss = -l_cut + l_ort + l_dot\n    return reducer(loss) if reducer else loss, {\n        \"l_cut\": reducer(-l_cut).detach() if reducer else (-l_cut).detach(),\n        \"l_ort\": reducer(l_ort).detach() if reducer else l_ort.detach(),\n        \"l_dot\": reducer(l_dot).detach() if reducer else l_dot.detach()\n    }", "\n\ndef hint_loss(preds, truth, feedback, alpha, device):\n    import torch\n    import numpy as np\n\n    losses = []\n    hint_mask = []\n    adj = adj_mat(feedback.features).to(device)\n\n    for i in range(truth.data.shape[0] - 1):\n        y = truth.data[i + 1].to(device)\n\n        y_pred = preds[i][truth.name]\n        h_mask = (y_pred != clrs.OutputClass.MASKED) * 1.0\n\n        if truth.type_ == _Type.SCALAR:\n\n            loss = (y_pred - (y * adj))**2\n            # if truth.name == \"f_h\":\n            #    loss = alpha * loss + (1-alpha) * max_flow(y_pred, feedback.features.inputs, device=device\n            if truth.name == \"f_h\":\n                hint_mask.append(h_mask.all(-1).all(-1))\n                loss = (loss * h_mask).sum(-1).sum(-1) / adj.sum(-1).sum(-1).to(device)\n            else:\n                hint_mask.append(h_mask.all(-1))\n\n        elif truth.type_ == _Type.MASK:\n            hint_mask.append(h_mask.all(-1))\n            loss = mask_loss(y_pred, y)\n            mask = (truth.data[i + 1] != _OutputClass.MASKED).float().to(device)\n            mask *= h_mask\n            loss = torch.sum(loss * mask, dim=-1) / (torch.sum(mask, dim=-1) + EPS)\n        elif truth.type_ == _Type.MASK_ONE:\n            loss = -torch.sum(y * torch.nn.functional.log_softmax(y_pred, dim=-1) * h_mask, dim=-1)\n        elif truth.type_ == _Type.POINTER:\n            from torch.nn.functional import log_softmax, one_hot\n            hint_mask.append(h_mask.all(-1).all(-1))\n            # cross entropy\n            loss = one_hot(y.long(), y_pred.shape[-1]) * log_softmax(y_pred, dim=-1)\n            loss = -torch.sum(loss * h_mask, dim=-1).mean(-1)\n\n        elif truth.type_ == _Type.CATEGORICAL:\n            from torch.nn.functional import log_softmax, one_hot\n            # cross entropy\n            hint_mask.append(h_mask.all(-1).all(-1))\n            loss = one_hot(y.argmax(-1).long(), y_pred.shape[-1]) * log_softmax(y_pred, dim=-1)\n            loss = -torch.sum(loss * h_mask, dim=-1).mean(-1)\n\n        losses.append(loss)\n\n    losses = torch.stack(losses)\n    hint_mask = torch.stack(hint_mask) * 1.0\n    is_not_done = _is_not_done_broadcast(feedback.features.lengths, np.arange(truth.data.shape[0] - 1)[:, None], losses)\n    mask = is_not_done * _expand_to(hint_mask, len(is_not_done.shape))\n\n    return (losses * mask).sum() / mask.sum()", "\n\ndef output_loss(preds, truth, feedback, alpha, device):\n    import torch\n    y_pred = preds[truth.name]\n    y = truth.data.to(device)\n    adj = adj_mat(feedback.features).to(device)\n\n    if truth.name == \"unsup_lp_flow\":\n        return max_flow(y_pred, feedback.features.inputs, alpha=alpha, device=device)\n    elif truth.type_ == _Type.POINTER:\n        y = y.long()\n        return torch.mean(cross_entropy(y_pred, y, num_classes=y_pred.shape[-1]))\n    elif truth.type_ == _Type.CATEGORICAL:\n        return torch.mean(cross_entropy(y_pred, y.argmax(-1).long(), num_classes=y_pred.shape[-1]))\n    elif truth.location == _Location.EDGE and truth.type_ == _Type.SCALAR:\n        loss = ((y_pred - (y * adj))**2).sum() / adj_mat(feedback.features).sum()\n        # if truth.name == \"f\":\n        #    loss = alpha * loss + (1-alpha) * max_flow(y_pred, feedback.features.inputs, device=device)\n\n        return loss\n\n    assert False", "\n\ndef _capacity_constraint(pred, inputs, device):\n    for inp in inputs:\n        if inp.name == 'A':\n            capacity = inp.data.to(device)\n\n    return pred * (pred > capacity) * 1.0\n\n\ndef _3d_trace(A):\n    return A.diagonal(offset=0, dim1=-1, dim2=-2).sum(-1)", "\n\ndef _3d_trace(A):\n    return A.diagonal(offset=0, dim1=-1, dim2=-2).sum(-1)\n\n\ndef _3d_diag(A):\n    return A.diag_embed(offset=0, dim1=-2, dim2=-1)\n\n\ndef _is_not_done_broadcast(lengths, i, tensor):\n    import torch\n    is_not_done = torch.as_tensor((lengths > i + 1) * 1.0, dtype=torch.float32).to(tensor.device)\n    while len(is_not_done.shape) < len(tensor.shape):\n        is_not_done = is_not_done.unsqueeze(-1)\n    return is_not_done", "\n\ndef _is_not_done_broadcast(lengths, i, tensor):\n    import torch\n    is_not_done = torch.as_tensor((lengths > i + 1) * 1.0, dtype=torch.float32).to(tensor.device)\n    while len(is_not_done.shape) < len(tensor.shape):\n        is_not_done = is_not_done.unsqueeze(-1)\n    return is_not_done\n\n\ndef _bfs_op_mask(hints):\n    for dp in hints:\n        if dp.name == '__is_bfs_op':\n            return dp.data", "\n\ndef _bfs_op_mask(hints):\n    for dp in hints:\n        if dp.name == '__is_bfs_op':\n            return dp.data\n"]}
{"filename": "nn/layers/mpnn.py", "chunked_list": ["import torch\nfrom typing import Callable, List\nfrom torch.nn import Linear, Module, Sequential\nfrom torch.nn import functional as F\n\nInf = 1e6\n\n\nclass MpnnConv(Module):\n    def __init__(self,\n                 in_channels: int,\n                 edge_channels: int,\n                 mid_channels: int,\n                 out_channels: int,\n                 net: Sequential,\n                 aggregator: str,\n                 mid_activation: Callable = None,\n                 activation: Callable = None,\n                 bias: bool = True):\n\n        super(MpnnConv, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n        self.m_1 = Linear(in_features=in_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n        self.m_2 = Linear(in_features=in_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n        self.m_e = Linear(in_features=edge_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n\n        self.o1 = Linear(in_features=in_channels,\n                         out_features=out_channels,\n                         bias=bias)\n        self.o2 = Linear(in_features=mid_channels,\n                         out_features=out_channels,\n                         bias=bias)\n\n        self.net = net\n        self.mid_activation = mid_activation\n        self.activation = activation\n\n        self.aggregator = aggregator\n\n        if aggregator == 'max':\n            self.reduce = torch.amax\n        elif aggregator == 'sum':\n            self.reduce = torch.sum\n        elif aggregator == 'mean':\n            self.reduce = torch.mean\n        else:\n            raise NotImplementedError(\"Invalid type of aggregator function.\")\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        self.m_1.reset_parameters()\n        self.m_2.reset_parameters()\n        self.m_e.reset_parameters()\n        self.o1.reset_parameters()\n        self.o2.reset_parameters()\n\n    def forward(self, x, adj, edge_attr):\n        \"\"\"\n        x : Tensor\n            node feature matrix (batch_size x num_nodes x num_nodes_features)\n        adj : Tensor\n            adjacency matrix (batch_size x num_nodes x num_nodes)\n        edge_attr : Tensor\n            edge attributes (batch_size x num_nodes x num_nodes x num_edge_features)\n        \"\"\"\n\n        batch_size, num_nodes, num_features = x.shape\n        _, _, _, num_edge_features = edge_attr.shape\n\n        msg_1 = self.m_1(x)\n        msg_2 = self.m_2(x)\n        msg_e = self.m_e(edge_attr)\n\n        msg = (\n            msg_1.unsqueeze(1) +\n            msg_2.unsqueeze(2) +\n            msg_e\n        )\n        if self.net is not None:\n            msg = self.net(F.relu(msg))\n\n        if self.mid_activation is not None:\n            msg = self.mid_activation(msg)\n\n        if self.aggregator == \"mean\":\n            msg = (msg * adj.unsqueeze(-1)).sum(1)\n            msg = msg / torch.sum(adj, dim=-1, keepdims=True)\n        elif self.aggregator == \"max\":\n            max_arg = torch.where(adj.unsqueeze(-1).bool(),\n                                  msg,\n                                  torch.tensor(-Inf).to(msg.device))\n            msg = self.reduce(max_arg, dim=1)\n        else:\n            msg = self.reduce(msg * adj.unsqueeze(-1), dim=1)\n\n        h_1 = self.o1(x)\n        h_2 = self.o2(msg)\n\n        out = h_1 + h_2\n\n        if self.activation is not None:\n            out = self.activation(out)\n\n        return out", "class MpnnConv(Module):\n    def __init__(self,\n                 in_channels: int,\n                 edge_channels: int,\n                 mid_channels: int,\n                 out_channels: int,\n                 net: Sequential,\n                 aggregator: str,\n                 mid_activation: Callable = None,\n                 activation: Callable = None,\n                 bias: bool = True):\n\n        super(MpnnConv, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n        self.m_1 = Linear(in_features=in_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n        self.m_2 = Linear(in_features=in_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n        self.m_e = Linear(in_features=edge_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n\n        self.o1 = Linear(in_features=in_channels,\n                         out_features=out_channels,\n                         bias=bias)\n        self.o2 = Linear(in_features=mid_channels,\n                         out_features=out_channels,\n                         bias=bias)\n\n        self.net = net\n        self.mid_activation = mid_activation\n        self.activation = activation\n\n        self.aggregator = aggregator\n\n        if aggregator == 'max':\n            self.reduce = torch.amax\n        elif aggregator == 'sum':\n            self.reduce = torch.sum\n        elif aggregator == 'mean':\n            self.reduce = torch.mean\n        else:\n            raise NotImplementedError(\"Invalid type of aggregator function.\")\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        self.m_1.reset_parameters()\n        self.m_2.reset_parameters()\n        self.m_e.reset_parameters()\n        self.o1.reset_parameters()\n        self.o2.reset_parameters()\n\n    def forward(self, x, adj, edge_attr):\n        \"\"\"\n        x : Tensor\n            node feature matrix (batch_size x num_nodes x num_nodes_features)\n        adj : Tensor\n            adjacency matrix (batch_size x num_nodes x num_nodes)\n        edge_attr : Tensor\n            edge attributes (batch_size x num_nodes x num_nodes x num_edge_features)\n        \"\"\"\n\n        batch_size, num_nodes, num_features = x.shape\n        _, _, _, num_edge_features = edge_attr.shape\n\n        msg_1 = self.m_1(x)\n        msg_2 = self.m_2(x)\n        msg_e = self.m_e(edge_attr)\n\n        msg = (\n            msg_1.unsqueeze(1) +\n            msg_2.unsqueeze(2) +\n            msg_e\n        )\n        if self.net is not None:\n            msg = self.net(F.relu(msg))\n\n        if self.mid_activation is not None:\n            msg = self.mid_activation(msg)\n\n        if self.aggregator == \"mean\":\n            msg = (msg * adj.unsqueeze(-1)).sum(1)\n            msg = msg / torch.sum(adj, dim=-1, keepdims=True)\n        elif self.aggregator == \"max\":\n            max_arg = torch.where(adj.unsqueeze(-1).bool(),\n                                  msg,\n                                  torch.tensor(-Inf).to(msg.device))\n            msg = self.reduce(max_arg, dim=1)\n        else:\n            msg = self.reduce(msg * adj.unsqueeze(-1), dim=1)\n\n        h_1 = self.o1(x)\n        h_2 = self.o2(msg)\n\n        out = h_1 + h_2\n\n        if self.activation is not None:\n            out = self.activation(out)\n\n        return out", "\n\nclass SparseMpnnConv(torch.nn.Module):\n    def __init__(self,\n                 in_channels: int,\n                 edge_channels: int,\n                 mid_channels: int,\n                 out_channels: int,\n                 net: Sequential,\n                 aggregator: str,\n                 devices: List[str] = ['cpu', 'cpu'],\n                 mid_activation: Callable = None,\n                 activation: Callable = None,\n                 bias: bool = True):\n\n        super().__init__()\n\n        from torch_geometric.nn.aggr import MaxAggregation\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n        self.m_1 = Linear(in_features=in_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n        self.m_2 = Linear(in_features=in_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n        self.m_e = Linear(in_features=edge_channels,\n                          out_features=mid_channels,\n                          bias=bias)\n\n        self.o1 = Linear(in_features=in_channels,\n                         out_features=out_channels,\n                         bias=bias)\n        self.o2 = Linear(in_features=mid_channels,\n                         out_features=out_channels,\n                         bias=bias)\n\n        self.net = net\n        self.mid_activation = mid_activation\n        self.activation = activation\n        self.devices = devices\n        self.aggregator = aggregator\n\n        assert aggregator == 'max', \"Invalid type of aggregator function.\"\n        self.reduce = MaxAggregation()\n\n    def reset_parameters(self):\n        self.m_1.reset_parameters()\n        self.m_2.reset_parameters()\n        self.m_e.reset_parameters()\n        self.o1.reset_parameters()\n        self.o2.reset_parameters()\n\n    def forward(self, x, adj_t, edge_attr, reporter=None):\n        \"\"\"\n        x : Tensor\n            node feature matrix (num_nodes x num_nodes_features)\n        adj_t : SparseTensor | Tensor\n            sparse adjacency matrix (num_nodes x num_nodes)\n        edge_attr : Tensor\n            edge attributes (num_edges x num_edge_features)\n        \"\"\"\n\n        x = x.to(self.devices[0])\n        edge_attr = edge_attr.to(self.devices[0])\n        adj_t = adj_t.to(self.devices[1])\n\n        msg_1 = self.m_1.to(self.devices[0])(x)\n        msg_2 = self.m_2.to(self.devices[0])(x)\n        msg_e = self.m_e.to(self.devices[0])(edge_attr)\n\n        # for each (u, v) : m1(u) + m2(v) + m_e(uv)\n\n        msg = torch.relu(\n            msg_1[adj_t.storage.row()] +\n            msg_2[adj_t.storage.col()] +\n            msg_e\n        )\n\n        msg = self.net.to(self.devices[1])(\n            msg.to(self.devices[1])\n        ).to(self.devices[1])\n\n        msg = self.reduce(msg,\n                          adj_t.storage.row(),\n                          ptr=adj_t.storage.rowptr(),\n                          dim_size=adj_t.storage.row().max().item() + 1,\n                          dim=-2)\n\n        h_1 = self.o1.to(self.devices[1])(x.to(self.devices[1]))\n        h_2 = self.o2.to(self.devices[1])(msg)\n\n        out = h_1 + h_2\n\n        if self.activation is not None:\n            out = self.activation(out)\n\n        return out", "\n\n# class SparseMpnnConv(MessagePassing):\n#     def __init__(self,\n#                  in_channels: int,\n#                  edge_channels: int,\n#                  mid_channels: int,\n#                  out_channels: int,\n#                  net: Sequential,\n#                  aggregator: str,", "#                  net: Sequential,\n#                  aggregator: str,\n#                  mid_activation: Callable = None,\n#                  activation: Callable = None,\n#                  bias: bool = True):\n\n#         super().__init__(aggr=aggregator)\n\n#         self.in_channels = in_channels\n#         self.out_channels = out_channels", "#         self.in_channels = in_channels\n#         self.out_channels = out_channels\n\n#         self.m_1 = Linear(in_features=in_channels,\n#                           out_features=mid_channels,\n#                           bias=bias)\n#         self.m_2 = Linear(in_features=in_channels,\n#                           out_features=mid_channels,\n#                           bias=bias)\n#         self.m_e = Linear(in_features=edge_channels,", "#                           bias=bias)\n#         self.m_e = Linear(in_features=edge_channels,\n#                           out_features=mid_channels,\n#                           bias=bias)\n\n#         self.o1 = Linear(in_features=in_channels,\n#                          out_features=out_channels,\n#                          bias=bias)\n#         self.o2 = Linear(in_features=mid_channels,\n#                          out_features=out_channels,", "#         self.o2 = Linear(in_features=mid_channels,\n#                          out_features=out_channels,\n#                          bias=bias)\n\n#         self.net = net\n#         self.mid_activation = mid_activation\n#         self.activation = activation\n\n#         self.aggregator = aggregator\n", "#         self.aggregator = aggregator\n\n#         if aggregator == 'max':\n#             self.reduce = torch.amax\n#         elif aggregator == 'sum':\n#             self.reduce = torch.sum\n#         elif aggregator == 'mean':\n#             self.reduce = torch.mean\n#         else:\n#             raise NotImplementedError(\"Invalid type of aggregator function.\")", "#         else:\n#             raise NotImplementedError(\"Invalid type of aggregator function.\")\n\n#     def reset_parameters(self):\n#         self.m_1.reset_parameters()\n#         self.m_2.reset_parameters()\n#         self.m_e.reset_parameters()\n#         self.o1.reset_parameters()\n#         self.o2.reset_parameters()\n", "#         self.o2.reset_parameters()\n\n#     def message(self, x_i, x_j, e_ij):\n#         msg = self.m_1(x_i) + self.m_2(x_j) + self.m_e(e_ij)\n#         msg = self.net(F.relu(msg))\n#         return msg\n\n#     def forward(self, x, adj_t, edge_attr):\n#         \"\"\"\n#         x : Tensor", "#         \"\"\"\n#         x : Tensor\n#             node feature matrix (num_nodes x num_nodes_features)\n#         adj_t : SparseTensor | Tensor\n#             sparse adjacency matrix (num_nodes x num_nodes) |\n#             coo coordinates tensor (2 x num_edges)\n#         edge_attr : Tensor\n#             edge attributes (num_edges x num_edge_features)\n#         \"\"\"\n", "#         \"\"\"\n\n#         msg = self.propagate(edge_index=adj_t,\n#                              x=x,\n#                              e_ij=edge_attr)\n\n#         h_1 = self.o1(x)\n#         h_2 = self.o2(msg)\n\n#         out = h_1 + h_2", "\n#         out = h_1 + h_2\n\n#         if self.activation is not None:\n#             out = self.activation(out)\n\n#         return out\n"]}
{"filename": "nn/layers/__init__.py", "chunked_list": ["from .mpnn import MpnnConv, SparseMpnnConv  # noqa\n"]}
{"filename": "nn/models/epd.py", "chunked_list": ["import clrs\nimport torch\n\nfrom nn import losses as loss\nfrom nn.models.impl import _dimensions, _expand, _hints_i, _own_hints_i\nfrom nn.models.impl import decoders\nfrom nn.models.impl import encoders\nfrom nn.models.impl import processors\nfrom utils import is_not_done_broadcast\nfrom utils.data import adj_mat, edge_attr_mat", "from utils import is_not_done_broadcast\nfrom utils.data import adj_mat, edge_attr_mat\nfrom typing import Callable, Dict, List\nfrom torch.nn import Module, ModuleDict\nfrom torch.nn.functional import relu\n\nResult = Dict[str, clrs.DataPoint]\n\n_Feedback = clrs.Feedback\n_Location = clrs.Location", "_Feedback = clrs.Feedback\n_Location = clrs.Location\n_OutputClass = clrs.OutputClass\n_Spec = clrs.Spec\n_Stage = clrs.Stage\n_Type = clrs.Type\n_Type = clrs.Type\n_DataPoint = clrs.DataPoint\n\n\nclass EncodeProcessDecode(clrs.Model):\n    def __init__(self,\n                 spec: _Spec,\n                 num_hidden: int,\n                 optim_fn: Callable,\n                 dummy_trajectory: _Feedback,\n                 alpha: float,\n                 processor: str,\n                 aggregator: str,\n                 no_feats: List = ['adj'],\n                 add_noise: bool = False,\n                 decode_hints: bool = True,\n                 encode_hints: bool = True,\n                 max_steps: int = None):\n        super().__init__(spec=spec)\n\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.net_ = EncodeProcessDecode_Impl(spec=spec,\n                                             dummy_trajectory=dummy_trajectory,\n                                             num_hidden=num_hidden,\n                                             encode_hints=encode_hints,\n                                             decode_hints=decode_hints,\n                                             processor=processor,\n                                             aggregator=aggregator,\n                                             max_steps=max_steps,\n                                             no_feats=no_feats,\n                                             add_noise=add_noise,\n                                             device=self.device)\n\n        self.optimizer = optim_fn(self.net_.parameters())\n        self.alpha = alpha\n        self.no_feats = lambda x: x in no_feats or x.startswith('__')\n        self.encode_hints = encode_hints\n        self.decode_hints = decode_hints\n\n    def dump_model(self, path):\n        torch.save(self.net_.state_dict(), path)\n\n    def restore_model(self, path, device):\n        self.net_.load_state_dict(torch.load(path, map_location=device))\n\n    def _train_step(self, feedback: _Feedback):\n        self.net_.train()\n        self.optimizer.zero_grad()\n\n        preds, hint_preds = self.net_(feedback.features)\n        total_loss = 0.0\n\n        n_hints = 0\n        if self.decode_hints:\n            hint_loss = 0.0\n            for truth in feedback.features.hints:\n                if self.no_feats(truth.name):\n                    continue\n                n_hints += 1\n                hint_loss += loss.hint_loss(hint_preds, truth, feedback, self.alpha, self.device)\n\n            total_loss += hint_loss / n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        total_loss.backward()\n\n        self.optimizer.step()\n        return total_loss.item()\n\n    def feedback(self, feedback: _Feedback) -> float:\n        loss = self._train_step(feedback)\n        return loss\n\n    @torch.no_grad()\n    def predict(self, features: clrs.Features) -> Result:\n        self.net_.eval()\n        raw_preds, aux = self.net_(features)\n        preds = decoders.postprocess(raw_preds, self._spec)\n\n        return preds, (raw_preds, aux)\n\n    @torch.no_grad()\n    def verbose_loss(self, feedback: _Feedback, preds, aux_preds):\n        losses = {}\n        total_loss = 0\n        n_hints = 0\n        for truth in feedback.features.hints:\n            if self.no_feats(truth.name):\n                continue\n            n_hints += 1\n            losses[\"aux_\" + truth.name] = loss.hint_loss(aux_preds, truth, feedback, self.alpha, self.device).cpu().item()\n            total_loss += losses[\"aux_\" + truth.name]\n\n        total_loss /= n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        return losses, total_loss.item()", "\n\nclass EncodeProcessDecode(clrs.Model):\n    def __init__(self,\n                 spec: _Spec,\n                 num_hidden: int,\n                 optim_fn: Callable,\n                 dummy_trajectory: _Feedback,\n                 alpha: float,\n                 processor: str,\n                 aggregator: str,\n                 no_feats: List = ['adj'],\n                 add_noise: bool = False,\n                 decode_hints: bool = True,\n                 encode_hints: bool = True,\n                 max_steps: int = None):\n        super().__init__(spec=spec)\n\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.net_ = EncodeProcessDecode_Impl(spec=spec,\n                                             dummy_trajectory=dummy_trajectory,\n                                             num_hidden=num_hidden,\n                                             encode_hints=encode_hints,\n                                             decode_hints=decode_hints,\n                                             processor=processor,\n                                             aggregator=aggregator,\n                                             max_steps=max_steps,\n                                             no_feats=no_feats,\n                                             add_noise=add_noise,\n                                             device=self.device)\n\n        self.optimizer = optim_fn(self.net_.parameters())\n        self.alpha = alpha\n        self.no_feats = lambda x: x in no_feats or x.startswith('__')\n        self.encode_hints = encode_hints\n        self.decode_hints = decode_hints\n\n    def dump_model(self, path):\n        torch.save(self.net_.state_dict(), path)\n\n    def restore_model(self, path, device):\n        self.net_.load_state_dict(torch.load(path, map_location=device))\n\n    def _train_step(self, feedback: _Feedback):\n        self.net_.train()\n        self.optimizer.zero_grad()\n\n        preds, hint_preds = self.net_(feedback.features)\n        total_loss = 0.0\n\n        n_hints = 0\n        if self.decode_hints:\n            hint_loss = 0.0\n            for truth in feedback.features.hints:\n                if self.no_feats(truth.name):\n                    continue\n                n_hints += 1\n                hint_loss += loss.hint_loss(hint_preds, truth, feedback, self.alpha, self.device)\n\n            total_loss += hint_loss / n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        total_loss.backward()\n\n        self.optimizer.step()\n        return total_loss.item()\n\n    def feedback(self, feedback: _Feedback) -> float:\n        loss = self._train_step(feedback)\n        return loss\n\n    @torch.no_grad()\n    def predict(self, features: clrs.Features) -> Result:\n        self.net_.eval()\n        raw_preds, aux = self.net_(features)\n        preds = decoders.postprocess(raw_preds, self._spec)\n\n        return preds, (raw_preds, aux)\n\n    @torch.no_grad()\n    def verbose_loss(self, feedback: _Feedback, preds, aux_preds):\n        losses = {}\n        total_loss = 0\n        n_hints = 0\n        for truth in feedback.features.hints:\n            if self.no_feats(truth.name):\n                continue\n            n_hints += 1\n            losses[\"aux_\" + truth.name] = loss.hint_loss(aux_preds, truth, feedback, self.alpha, self.device).cpu().item()\n            total_loss += losses[\"aux_\" + truth.name]\n\n        total_loss /= n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        return losses, total_loss.item()", "\n\nclass EncodeProcessDecode_Impl(Module):\n    def __init__(self,\n                 spec: _Spec,\n                 dummy_trajectory: _Feedback,\n                 num_hidden: int,\n                 encode_hints: bool,\n                 decode_hints: bool,\n                 processor: str,\n                 aggregator: str,\n                 no_feats: List,\n                 add_noise: bool = False,\n                 bias: bool = True,\n                 max_steps: int = None,\n                 device: str = 'cpu'):\n        super().__init__()\n\n        self.num_hidden = num_hidden\n        self.decode_hints = decode_hints\n\n        self.encoders = ModuleDict({})\n        self.decoders = ModuleDict({})\n        self.hint_decoders = ModuleDict({})\n\n        self.max_steps = max_steps\n\n        self.no_feats = lambda x: x in no_feats or x.startswith('__') # noqa\n\n        for inp in dummy_trajectory.features.inputs:\n            if self.no_feats(inp.name):\n                continue\n\n            self.encoders[inp.name] = encoders.Encoder(\n                in_features=_expand(inp.data, inp.location).shape[-1],\n                out_features=self.num_hidden,\n                bias=False)\n\n        if encode_hints:\n            for hint in dummy_trajectory.features.hints:\n                if self.no_feats(hint.name):\n                    continue\n                self.encoders[hint.name] = encoders.Encoder(\n                    in_features=_expand(hint.data[0], hint.location).shape[-1],\n                    out_features=self.num_hidden,\n                    bias=False)\n\n        self.process = processors.PROCESSORS[processor](num_hidden=num_hidden,\n                                                        aggregator=aggregator,\n                                                        activation=relu)\n\n        if decode_hints:\n            for hint in dummy_trajectory.features.hints:\n                if self.no_feats(hint.name):\n                    continue\n                self.hint_decoders[hint.name] = decoders.new_decoder(spec[hint.name],\n                                                                     num_hidden,\n                                                                     num_classes=hint.data.shape[-1])\n\n        for out in dummy_trajectory.outputs:\n            self.decoders[out.name] = decoders.new_decoder(spec[out.name],\n                                                           num_hidden,\n                                                           num_classes=out.data.shape[-1])\n\n        self.device = device\n        self.spec = spec\n        self.encode_hints = encode_hints\n        self.to(device)\n\n    def step(self, trajectories, h, adj):\n        # ~~~ init ~~~\n        batch_size, num_nodes = _dimensions(trajectories[0])\n        x = torch.zeros((batch_size, num_nodes, self.num_hidden)).to(self.device)\n        edge_attr = torch.zeros((batch_size, num_nodes, num_nodes, self.num_hidden)).to(self.device)\n\n        # ~~~ encode ~~~\n        for trajectory in trajectories:\n            for dp in trajectory:\n                if self.no_feats(dp.name) or dp.name not in self.encoders:\n                    continue\n                data = encoders.preprocess(dp, num_nodes).to(self.device)\n                encoder = self.encoders[dp.name]\n                x = encoders.accum_node_fts(encoder, dp, data, x)\n                edge_attr = encoders.accum_edge_fts(encoder, dp, data, edge_attr, adj)\n                # graph_fts = encoders.accum_graph_fts(encoder, dp, data, graph_fts)\n\n        # ~~~ process ~~~\n        z = torch.cat([x, h], dim=-1)\n        hiddens = self.process(z, adj, edge_attr)\n        h_t = torch.cat([z, hiddens], dim=-1)\n        self.h_t = h_t\n        self.edge_attr = edge_attr\n\n        # ~~~ decode ~~~\n        if not self.decode_hints:\n            hint_preds = {}\n        else:\n            hint_preds = {\n                name: decoders.decode_from_latents(\n                    name,\n                    self.spec[name],\n                    self.hint_decoders[name],\n                    h_t,\n                    adj,\n                    edge_attr)\n                for name in self.hint_decoders.keys()\n            }\n\n        output_preds = {\n            name: decoders.decode_from_latents(\n                name,\n                self.spec[name],\n                self.decoders[name],\n                h_t,\n                adj,\n                edge_attr)\n            for name in self.decoders.keys()\n        }\n\n        return output_preds, hiddens, hint_preds\n\n    def forward(self, features):\n        output_preds = {}\n        hint_preds = []\n\n        num_steps = self.max_steps if self.max_steps else features.hints[0].data.shape[0] - 1\n        batch_size, num_nodes = _dimensions(features.inputs)\n\n        h = torch.zeros((batch_size, num_nodes, self.num_hidden)).to(self.device)\n\n        adj = adj_mat(features).to(self.device)\n        A = edge_attr_mat(features).to(self.device)\n\n        for i in range(num_steps):\n            cur_hint = _hints_i(features.hints, i) if self.training or i == 0 else _own_hints_i(hint_preds[-1], self.spec, features, i)\n\n            trajectories = [features.inputs]\n            if self.encode_hints:\n                trajectories.append(cur_hint)\n\n            cand, h, h_preds = self.step(trajectories, h, adj)\n\n            if \"f\" in cand:\n                cand[\"f\"] = A * cand[\"f\"]\n\n            if \"f_h\" in h_preds:\n                h_preds[\"f_h\"] = A * h_preds[\"f_h\"]\n\n            hint_preds.append(h_preds)\n\n            for name in cand:\n                if i == 0 or features.lengths.sum() == 0:\n                    # if the algorithm has no hints, bypass the following check\n                    output_preds[name] = cand[name]\n                else:\n                    is_not_done = is_not_done_broadcast(features.lengths, i, cand[name])\n                    output_preds[name] = is_not_done * cand[name] + \\\n                        (1.0 - is_not_done) * output_preds[name]\n\n        return output_preds, hint_preds", ""]}
{"filename": "nn/models/mf_net_pipeline.py", "chunked_list": ["import clrs\nimport torch\n\nfrom nn import losses as loss\nfrom nn.models.impl import _dimensions, _bfs_op_mask, _expand_to, \\\n    _get_fts, _hints_i, _own_hints_i, _reset_hints\nfrom nn.models.impl import decoders\nfrom nn.models.epd import EncodeProcessDecode_Impl as Net\n\nfrom random import random", "\nfrom random import random\nfrom typing import Callable, Dict, List\nfrom utils import is_not_done_broadcast\nfrom utils.data import adj_mat, edge_attr_mat\n\nResult = Dict[str, clrs.DataPoint]\n\n_INFINITY = 1e5\n", "_INFINITY = 1e5\n\n_Feedback = clrs.Feedback\n_Spec = clrs.Spec\n_Stage = clrs.Stage\n_Location = clrs.Location\n_Type = clrs.Type\n_DataPoint = clrs.DataPoint\n\n\nclass MF_Net(clrs.Model):\n    def __init__(self,\n                 spec: _Spec,\n                 num_hidden: int,\n                 optim_fn: Callable,\n                 dummy_trajectory: _Feedback,\n                 alpha: float,\n                 processor: str,\n                 aggregator: str,\n                 no_feats: List = ['adj'],\n                 add_noise: bool = False,\n                 decode_hints: bool = True,\n                 encode_hints: bool = True,\n                 max_steps: int = None):\n        super().__init__(spec=spec)\n\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.net_ = MFNet_Impl(spec=spec,\n                               dummy_trajectory=dummy_trajectory,\n                               processor=processor,\n                               aggregator=aggregator,\n                               num_hidden=num_hidden,\n                               encode_hints=encode_hints,\n                               decode_hints=decode_hints,\n                               max_steps=max_steps,\n                               no_feats=no_feats,\n                               add_noise=add_noise,\n                               device=self.device)\n\n        self.optimizer = optim_fn(self.net_.parameters())\n        self.alpha = alpha\n        self.no_feats = lambda x: x in no_feats or x.startswith('__')\n        self.encode_hints = encode_hints\n        self.decode_hints = decode_hints\n\n    def dump_model(self, path):\n        torch.save(self.net_.state_dict(), path)\n\n    def restore_model(self, path, device):\n        self.net_.load_state_dict(torch.load(path, map_location=device))\n\n    def _train_step(self, feedback: _Feedback):\n        self.net_.train()\n        self.optimizer.zero_grad()\n\n        preds, hint_preds = self.net_(feedback.features)\n        total_loss = 0.0\n        n_hints = 0\n        if self.decode_hints:\n            hint_loss = 0.0\n            for truth in feedback.features.hints:\n                if self.no_feats(truth.name):\n                    continue\n\n                n_hints += 1\n                hint_loss += loss.hint_loss(hint_preds, truth, feedback, self.alpha, self.device)\n\n            total_loss += hint_loss / n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        total_loss.backward()\n\n        self.optimizer.step()\n\n        return total_loss.item()\n\n    def feedback(self, feedback: _Feedback) -> float:\n        loss = self._train_step(feedback)\n        return loss\n\n    @torch.no_grad()\n    def predict(self, features: clrs.Features) -> Result:\n        self.net_.eval()\n        raw_preds, aux = self.net_(features)\n        preds = decoders.postprocess(raw_preds, self._spec)\n\n        return preds, (raw_preds, aux)\n\n    @torch.no_grad()\n    def verbose_loss(self, feedback: _Feedback, preds, aux_preds):\n        losses = {}\n        total_loss = 0\n        n_hints = 0\n        for truth in feedback.features.hints:\n            if self.no_feats(truth.name):\n                continue\n            n_hints += 1\n            losses[\"aux_\" + truth.name] = loss.hint_loss(aux_preds, truth, feedback, self.alpha, self.device).cpu().item()\n            total_loss += losses[\"aux_\" + truth.name]\n\n        total_loss /= n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        return losses, total_loss.item()", "\n\nclass MF_Net(clrs.Model):\n    def __init__(self,\n                 spec: _Spec,\n                 num_hidden: int,\n                 optim_fn: Callable,\n                 dummy_trajectory: _Feedback,\n                 alpha: float,\n                 processor: str,\n                 aggregator: str,\n                 no_feats: List = ['adj'],\n                 add_noise: bool = False,\n                 decode_hints: bool = True,\n                 encode_hints: bool = True,\n                 max_steps: int = None):\n        super().__init__(spec=spec)\n\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.net_ = MFNet_Impl(spec=spec,\n                               dummy_trajectory=dummy_trajectory,\n                               processor=processor,\n                               aggregator=aggregator,\n                               num_hidden=num_hidden,\n                               encode_hints=encode_hints,\n                               decode_hints=decode_hints,\n                               max_steps=max_steps,\n                               no_feats=no_feats,\n                               add_noise=add_noise,\n                               device=self.device)\n\n        self.optimizer = optim_fn(self.net_.parameters())\n        self.alpha = alpha\n        self.no_feats = lambda x: x in no_feats or x.startswith('__')\n        self.encode_hints = encode_hints\n        self.decode_hints = decode_hints\n\n    def dump_model(self, path):\n        torch.save(self.net_.state_dict(), path)\n\n    def restore_model(self, path, device):\n        self.net_.load_state_dict(torch.load(path, map_location=device))\n\n    def _train_step(self, feedback: _Feedback):\n        self.net_.train()\n        self.optimizer.zero_grad()\n\n        preds, hint_preds = self.net_(feedback.features)\n        total_loss = 0.0\n        n_hints = 0\n        if self.decode_hints:\n            hint_loss = 0.0\n            for truth in feedback.features.hints:\n                if self.no_feats(truth.name):\n                    continue\n\n                n_hints += 1\n                hint_loss += loss.hint_loss(hint_preds, truth, feedback, self.alpha, self.device)\n\n            total_loss += hint_loss / n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        total_loss.backward()\n\n        self.optimizer.step()\n\n        return total_loss.item()\n\n    def feedback(self, feedback: _Feedback) -> float:\n        loss = self._train_step(feedback)\n        return loss\n\n    @torch.no_grad()\n    def predict(self, features: clrs.Features) -> Result:\n        self.net_.eval()\n        raw_preds, aux = self.net_(features)\n        preds = decoders.postprocess(raw_preds, self._spec)\n\n        return preds, (raw_preds, aux)\n\n    @torch.no_grad()\n    def verbose_loss(self, feedback: _Feedback, preds, aux_preds):\n        losses = {}\n        total_loss = 0\n        n_hints = 0\n        for truth in feedback.features.hints:\n            if self.no_feats(truth.name):\n                continue\n            n_hints += 1\n            losses[\"aux_\" + truth.name] = loss.hint_loss(aux_preds, truth, feedback, self.alpha, self.device).cpu().item()\n            total_loss += losses[\"aux_\" + truth.name]\n\n        total_loss /= n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        return losses, total_loss.item()", "\n\nclass MFNet_Impl(torch.nn.Module):\n    def __init__(self,\n                 spec: _Spec,\n                 dummy_trajectory: _Feedback,\n                 num_hidden: int,\n                 encode_hints: bool,\n                 decode_hints: bool,\n                 processor: str,\n                 aggregator: str,\n                 no_feats: List,\n                 add_noise: bool = False,\n                 bias: bool = True,\n                 max_steps: int = None,\n                 load_path: str = None,\n                 annealing: bool = True,\n                 device: str = 'cpu'):\n        super().__init__()\n\n        self.num_hidden = num_hidden\n        self.decode_hints = decode_hints\n\n        self.max_steps = max_steps\n\n        self.no_feats = lambda x: x in no_feats or x.startswith('__')  # noqa\n        self.bfs_net = Net(spec,\n                           dummy_trajectory,\n                           num_hidden,\n                           encode_hints,\n                           decode_hints,\n                           processor,\n                           aggregator,\n                           no_feats,\n                           add_noise=add_noise,\n                           device=device)\n\n        self.flow_net = Net(spec,\n                            dummy_trajectory,\n                            num_hidden,\n                            encode_hints,\n                            decode_hints,\n                            processor,\n                            aggregator,\n                            no_feats,\n                            add_noise=add_noise,\n                            device=device)\n\n        c = _get_fts(dummy_trajectory.features.hints, name='c_h')\n        if c is not None:\n            print(c.data.shape[2])\n            self.mincut_net = Net(\n                spec,\n                dummy_trajectory,\n                num_hidden,\n                encode_hints=False,\n                decode_hints=False,\n                processor=processor,\n                aggregator=aggregator,\n                max_steps=c.data.shape[2] + 1,\n                no_feats=no_feats,\n                device=device\n            )\n            del self.flow_net.decoders['c']\n            del self.flow_net.hint_decoders['c_h']\n            del self.bfs_net.hint_decoders['c_h']\n            del self.mincut_net.decoders['f']\n\n        self.is_annealing_enabled = annealing\n        self.annealing_state = 0\n        self.device = device\n        self.spec = spec\n        self.encode_hints = encode_hints\n        self.to(device)\n\n    def op(self, trajectories, h_bfs, adj, is_bfs_op):\n\n        _, h_bfs, h_preds_bfs = self.bfs_net.step(trajectories, h_bfs, adj)\n\n        cand, _, h_preds_fnet = self.flow_net.step(trajectories, h_bfs.detach(), adj)\n\n        for ignored_key in ['f_h', 'c_h']:\n            if ignored_key in self.bfs_net.hint_decoders.keys():\n                h_preds_bfs[ignored_key] = h_preds_bfs[ignored_key].new_full(h_preds_bfs[ignored_key].shape, clrs.OutputClass.MASKED)\n\n        for ignored_key in ['reach_h', 'pi_h']:\n            if ignored_key in self.flow_net.hint_decoders.keys():\n                h_preds_fnet[ignored_key] = h_preds_fnet[ignored_key].new_full(h_preds_fnet[ignored_key].shape, clrs.OutputClass.MASKED)\n\n        if self.decode_hints:\n            hint_preds = {}\n            idx_bfs = is_bfs_op.flatten().nonzero()\n            idx_f = (1 - is_bfs_op).flatten().nonzero()\n            for name in h_preds_bfs.keys():\n                n_dims = len(h_preds_bfs[name].shape)\n                hint_preds[name] = torch.empty_like(h_preds_bfs[name]).to(self.device)\n                hint_preds[name].fill_(clrs.OutputClass.MASKED)\n\n                hint_preds[name][idx_bfs] = h_preds_bfs[name][idx_bfs]\n                hint_preds[name][idx_f] = h_preds_fnet[name][idx_f]\n\n        # attempt to reset h_bfs\n        reset = torch.zeros_like(h_bfs)\n        h_bfs = h_bfs.masked_scatter(_expand_to(is_bfs_op.bool(), n_dims), reset)\n\n        assert h_bfs[is_bfs_op.flatten().nonzero()].sum().item() == 0\n\n        for name in cand.keys():\n            n_dims = len(cand[name].shape)\n            mask = torch.zeros_like(cand[name])\n            mask.fill_(clrs.OutputClass.MASKED)\n            cand[name] = cand[name].masked_scatter(_expand_to(is_bfs_op.bool(), n_dims), mask)\n\n        return cand, h_bfs, hint_preds\n\n    def forward(self, features):\n        output_preds = {}\n        hint_preds = []\n\n        num_steps = self.max_steps if self.max_steps else features.hints[0].data.shape[0] - 1\n        batch_size, num_nodes = _dimensions(features.inputs)\n\n        h_bfs = torch.zeros((batch_size, num_nodes, self.num_hidden)).to(self.device)\n\n        adj = adj_mat(features).to(self.device)\n        A = edge_attr_mat(features).to(self.device)\n\n        def next_hint(i):\n            use_teacher_forcing = self.training\n            first_step = i == 0\n\n            if self.is_annealing_enabled:\n                self.annealing_state += 1\n                use_teacher_forcing = use_teacher_forcing and not(random() > (0.999 ** self.annealing_state))\n\n            if use_teacher_forcing or first_step:\n                return _hints_i(features.hints, i)\n            else:\n                return _own_hints_i(last_valid_hints, self.spec, features, i)\n\n        prev_is_flow_op = None\n        # if not self.training:\n        last_valid_hints = {hint.name: hint.data.to(self.device) for hint in next_hint(0)}\n        last_valid_hints['pi_h'] = torch.nn.functional.one_hot(last_valid_hints['pi_h'].long(),\n                                                               num_nodes).float()\n        del last_valid_hints['__is_bfs_op']\n\n        if self.mincut_net is not None:\n            mc_out, _ = self.mincut_net(features)\n            output_preds['c'] = mc_out['c']\n            last_valid_hints['c_h'] = mc_out['c']\n\n        for i in range(num_steps):\n            # ~~~ init ~~~\n            trajectories = [features.inputs]\n            if self.encode_hints:\n                cur_hint = next_hint(i)\n                if i > 0 and not self.training:\n                    assert prev_is_flow_op is not None\n                    first_bfs_step = prev_is_flow_op\n                    reach_h, pi_h = _reset_hints(cur_hint, _get_fts(features.inputs, \"s\").data)\n                    for hint in cur_hint:\n                        if hint.name == 'reach_h':\n                            hint.data[first_bfs_step.flatten().nonzero()] = reach_h.data.to(self.device)[first_bfs_step.flatten().nonzero()]\n                        elif hint.name == 'pi_h':\n                            hint.data[first_bfs_step.flatten().nonzero()] = pi_h.data.to(self.device)[first_bfs_step.flatten().nonzero()]\n\n                trajectories.append(cur_hint)\n\n            if self.decode_hints:\n                is_bfs_op = _bfs_op_mask(next_hint(i)).data.to(self.device)\n                is_flow_op = (1 - is_bfs_op)\n            else:\n                is_bfs_op = None\n\n            cand, h_bfs, h_preds = self.op(trajectories, h_bfs, adj, is_bfs_op)\n\n            if self.mincut_net is not None:\n                h_preds['c_h'] = mc_out['c']\n            if \"f\" in cand:\n                idx = is_flow_op.flatten().nonzero()\n                cand[\"f\"][idx] = (A * cand['f'])[idx]\n\n            if \"f_h\" in h_preds:\n                idx = is_flow_op.flatten().nonzero()\n                h_preds[\"f_h\"][idx] = (A * h_preds['f_h'])[idx]\n\n            # if not self.training:\n            for name in last_valid_hints.keys():\n                is_masked = (h_preds[name] == clrs.OutputClass.MASKED) * 1.0\n\n                last_valid_hints[name] = is_masked * last_valid_hints[name] + (1.0 - is_masked) * h_preds[name]\n\n            hint_preds.append(h_preds)\n\n            for name in cand:\n                if name not in output_preds or features.lengths.sum() == 0:\n                    output_preds[name] = cand[name]\n                else:\n                    is_not_done = is_not_done_broadcast(features.lengths, i, cand[name])\n\n                    mask = is_not_done * _expand_to(is_flow_op, len(is_not_done.shape))\n                    output_preds[name] = mask * cand[name] + \\\n                        (1.0 - mask) * output_preds[name]\n\n            prev_is_flow_op = is_flow_op\n\n        return output_preds, hint_preds", ""]}
{"filename": "nn/models/baselines.py", "chunked_list": ["import clrs\n\n_Features = clrs.Features\n\n\nclass UniformRandom:\n    def predict(self, features: _Features):\n        from numpy.random import rand\n\n        for inp in features.inputs:\n            if inp.location in [clrs.Location.NODE, clrs.Location.EDGE]:\n                batch_size, num_nodes = inp.data.shape[0], inp.data.shape[1]\n                break\n\n        return rand(batch_size, num_nodes)", "\n\nclass NormalRandom:\n    def predict(self, features: _Features):\n        from numpy.random import randn\n\n        for inp in features.inputs:\n            if inp.location in [clrs.Location.NODE, clrs.Location.EDGE]:\n                batch_size, num_nodes = inp.data.shape[0], inp.data.shape[1]\n                break\n\n        return randn(batch_size, num_nodes)", ""]}
{"filename": "nn/models/__init__.py", "chunked_list": ["from .epd import EncodeProcessDecode  # noqa: F401\nfrom .mf_net import MF_Net  # noqa: F401\nfrom .mf_net_pipeline import MF_Net as MF_NetPipeline  # noqa: F401\nfrom .baselines import NormalRandom, UniformRandom  # noqa: F401\n"]}
{"filename": "nn/models/mf_net.py", "chunked_list": ["\nimport clrs\nimport torch\n\nfrom nn import losses as loss\nfrom nn.models.impl import _dimensions, _bfs_op_mask, _expand_to, \\\n    _get_fts, _hints_i, _own_hints_i, _reset_hints\nfrom nn.models.impl import decoders\nfrom nn.models.epd import EncodeProcessDecode_Impl as Net\nfrom random import random", "from nn.models.epd import EncodeProcessDecode_Impl as Net\nfrom random import random\nfrom typing import Callable, Dict, List\nfrom utils import is_not_done_broadcast\nfrom utils.data import adj_mat, edge_attr_mat\n\nResult = Dict[str, clrs.DataPoint]\n\n_INFINITY = 1e5\n", "_INFINITY = 1e5\n\n_Feedback = clrs.Feedback\n_Spec = clrs.Spec\n_Stage = clrs.Stage\n_Location = clrs.Location\n_Type = clrs.Type\n_DataPoint = clrs.DataPoint\n_ANNEALING_STATE = 0\n", "_ANNEALING_STATE = 0\n\n\nclass MF_Net(clrs.Model):\n    def __init__(self,\n                 spec: _Spec,\n                 num_hidden: int,\n                 optim_fn: Callable,\n                 dummy_trajectory: _Feedback,\n                 alpha: float,\n                 processor: str,\n                 aggregator: str,\n                 no_feats: List = ['adj'],\n                 add_noise: bool = False,\n                 decode_hints: bool = True,\n                 encode_hints: bool = True,\n                 max_steps: int = None,):\n        super().__init__(spec=spec)\n\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.net_ = MFNet_Impl(spec=spec,\n                               dummy_trajectory=dummy_trajectory,\n                               processor=processor,\n                               aggregator=aggregator,\n                               num_hidden=num_hidden,\n                               encode_hints=encode_hints,\n                               decode_hints=decode_hints,\n                               max_steps=max_steps,\n                               no_feats=no_feats,\n                               add_noise=add_noise,\n                               device=self.device)\n\n        self.optimizer = optim_fn(self.net_.parameters())\n        self.alpha = alpha\n        self.no_feats = lambda x: x in no_feats or x.startswith('__')\n        self.encode_hints = encode_hints\n        self.decode_hints = decode_hints\n        self.spec = spec\n\n    def dump_model(self, path):\n        torch.save(self.net_.state_dict(), path)\n\n    def restore_model(self, path, device):\n        self.net_.load_state_dict(torch.load(path, map_location=device))\n\n    def _train_step(self, feedback: _Feedback):\n        self.net_.train()\n        self.optimizer.zero_grad()\n\n        preds, hint_preds = self.net_(feedback.features)\n\n        total_loss = 0.0\n        n_hints = 0\n        if self.decode_hints:\n            hint_loss = 0.0\n            for truth in feedback.features.hints:\n                if self.no_feats(truth.name):\n                    continue\n\n                n_hints += 1\n                hint_loss += loss.hint_loss(hint_preds, truth, feedback, self.alpha, self.device)\n\n            total_loss += hint_loss / n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        total_loss.backward()\n\n        self.optimizer.step()\n\n        return total_loss.item()\n\n    def feedback(self, feedback: _Feedback) -> float:\n        loss = self._train_step(feedback)\n        return loss\n\n    @torch.no_grad()\n    def predict(self, features: clrs.Features):\n        self.net_.eval()\n        raw_preds, aux = self.net_(features)\n        preds = decoders.postprocess(raw_preds, self.spec)\n\n        return preds, (raw_preds, aux)\n\n    @torch.no_grad()\n    def verbose_loss(self, feedback: _Feedback, preds, aux_preds):\n        losses = {}\n        total_loss = 0\n        n_hints = 0\n        for truth in feedback.features.hints:\n            if self.no_feats(truth.name):\n                continue\n            n_hints += 1\n            losses[\"aux_\" + truth.name] = loss.hint_loss(aux_preds, truth, feedback, self.alpha, self.device).cpu().item()\n            total_loss += losses[\"aux_\" + truth.name]\n\n        total_loss /= n_hints\n\n        for truth in feedback.outputs:\n            total_loss += loss.output_loss(preds, truth, feedback, self.alpha, self.device)\n\n        return losses, total_loss.item()", "\n\nclass MFNet_Impl(torch.nn.Module):\n    def __init__(self,\n                 spec: _Spec,\n                 dummy_trajectory: _Feedback,\n                 num_hidden: int,\n                 encode_hints: bool,\n                 decode_hints: bool,\n                 processor: str,\n                 aggregator: str,\n                 no_feats: List,\n                 add_noise: bool = False,\n                 bias: bool = True,\n                 max_steps: int = None,\n                 load_path: str = None,\n                 annealing: bool = True,\n                 device: str = 'cpu'):\n        super().__init__()\n\n        self.num_hidden = num_hidden\n        self.decode_hints = decode_hints\n\n        self.max_steps = max_steps\n\n        self.no_feats = lambda x: x in no_feats or x.startswith('__')  # noqa\n\n        self.bfs_net = Net(spec, dummy_trajectory, num_hidden,\n                           encode_hints, decode_hints,\n                           processor, aggregator, no_feats,\n                           add_noise=add_noise,\n                           device=device)\n\n        self.flow_net = Net(spec, dummy_trajectory, num_hidden,\n                            encode_hints, decode_hints,\n                            processor, aggregator, no_feats,\n                            add_noise=add_noise,\n                            device=device)\n\n        del self.bfs_net.encoders['c_h']\n\n        self.is_annealing_enabled = annealing\n        self.annealing_state = 0\n        self.device = device\n        self.spec = spec\n        self.encode_hints = encode_hints\n        self.to(device)\n        self.hiddens = None\n\n    def op(self, trajectories, h_bfs, adj, is_bfs_op):\n\n        _, h_bfs, h_preds_bfs = self.bfs_net.step(trajectories, h_bfs, adj)\n\n        cand, hiddens, h_preds_fnet = self.flow_net.step(trajectories, h_bfs.detach(), adj)\n\n        for ignored_key in ['f_h', 'c_h']:\n            if ignored_key in self.bfs_net.hint_decoders.keys():\n                h_preds_bfs[ignored_key] = h_preds_bfs[ignored_key].new_full(h_preds_bfs[ignored_key].shape, clrs.OutputClass.MASKED)\n\n        for ignored_key in ['reach_h', 'pi_h']:\n            if ignored_key in self.flow_net.hint_decoders.keys():\n                h_preds_fnet[ignored_key] = h_preds_fnet[ignored_key].new_full(h_preds_fnet[ignored_key].shape, clrs.OutputClass.MASKED)\n\n        if self.decode_hints:\n            hint_preds = {}\n            idx_bfs = is_bfs_op.flatten().nonzero()\n            idx_f = (1 - is_bfs_op).flatten().nonzero()\n            for name in h_preds_bfs.keys():\n                n_dims = len(h_preds_bfs[name].shape)\n                hint_preds[name] = torch.empty_like(h_preds_bfs[name]).to(self.device)\n                hint_preds[name].fill_(clrs.OutputClass.MASKED)\n\n                hint_preds[name][idx_bfs] = h_preds_bfs[name][idx_bfs]\n                hint_preds[name][idx_f] = h_preds_fnet[name][idx_f]\n\n        # attempt to reset h_bfs\n        reset = torch.zeros_like(h_bfs)\n        h_bfs = h_bfs.masked_scatter(_expand_to(is_bfs_op.bool(), len(h_bfs.shape)), reset)\n\n        assert h_bfs[is_bfs_op.flatten().nonzero()].sum().item() == 0\n\n        for name in cand.keys():\n            n_dims = len(cand[name].shape)\n            mask = torch.zeros_like(cand[name])\n            mask.fill_(clrs.OutputClass.MASKED)\n            cand[name] = cand[name].masked_scatter(_expand_to(is_bfs_op.bool(), n_dims), mask)\n\n        return cand, h_bfs, hint_preds, hiddens\n\n    def forward(self, features):\n        output_preds = {}\n        hint_preds = []\n\n        num_steps = self.max_steps if self.max_steps else features.hints[0].data.shape[0] - 1\n        batch_size, num_nodes = _dimensions(features.inputs)\n\n        h_bfs = torch.zeros((batch_size, num_nodes, self.num_hidden)).to(self.device)\n\n        adj = adj_mat(features).to(self.device)\n        A = edge_attr_mat(features).to(self.device)\n\n        def next_hint(i):\n            use_teacher_forcing = self.training\n            first_step = i == 0\n\n            if self.is_annealing_enabled:\n                self.annealing_state += 1\n                use_teacher_forcing = use_teacher_forcing and not(random() > (0.999 ** self.annealing_state))\n\n            if use_teacher_forcing or first_step:\n                return _hints_i(features.hints, i)\n            else:\n                return _own_hints_i(last_valid_hints, self.spec, features, i)\n\n        prev_is_flow_op = None\n        last_valid_hints = {hint.name: hint.data.to(self.device) for hint in next_hint(0)}\n        last_valid_hints['pi_h'] = torch.nn.functional.one_hot(last_valid_hints['pi_h'].long(),\n                                                               num_nodes).float()\n        del last_valid_hints['__is_bfs_op']\n\n        for i in range(num_steps):\n            # ~~~ init ~~~\n            trajectories = [features.inputs]\n            if self.encode_hints:\n                cur_hint = next_hint(i)\n                if i > 0 and not self.training:\n                    assert prev_is_flow_op is not None\n                    first_bfs_step = prev_is_flow_op\n                    reach_h, pi_h = _reset_hints(cur_hint, _get_fts(features.inputs, \"s\").data)\n                    for hint in cur_hint:\n                        if hint.name == 'reach_h':\n                            hint.data[first_bfs_step.flatten().nonzero()] = reach_h.data.to(self.device)[first_bfs_step.flatten().nonzero()]\n                        elif hint.name == 'pi_h':\n                            hint.data[first_bfs_step.flatten().nonzero()] = pi_h.data.to(self.device)[first_bfs_step.flatten().nonzero()]\n\n                trajectories.append(cur_hint)\n\n            if self.decode_hints:\n                is_bfs_op = _bfs_op_mask(next_hint(i)).data.to(self.device)\n                is_flow_op = (1 - is_bfs_op)\n            else:\n                is_bfs_op = None\n\n            cand, h_bfs, h_preds, _ = self.op(trajectories, h_bfs, adj, is_bfs_op)\n\n            if \"f\" in cand:\n                idx = is_flow_op.flatten().nonzero()\n                cand[\"f\"][idx] = (A * cand['f'])[idx]\n\n            if \"f_h\" in h_preds:\n                idx = is_flow_op.flatten().nonzero()\n                h_preds[\"f_h\"][idx] = (A * h_preds['f_h'])[idx]\n\n            for name in last_valid_hints.keys():\n                if self.no_feats(name):\n                    continue\n\n                is_masked = (h_preds[name] == clrs.OutputClass.MASKED) * 1.0\n\n                last_valid_hints[name] = is_masked * last_valid_hints[name] + (1.0 - is_masked) * h_preds[name]\n\n            hint_preds.append(h_preds)\n\n            for name in cand:\n                if name not in output_preds or features.lengths.sum() == 0:\n                    output_preds[name] = cand[name]\n                else:\n                    is_not_done = is_not_done_broadcast(features.lengths, i, cand[name])\n\n                    mask = is_not_done * _expand_to(is_flow_op, len(is_not_done.shape))\n                    output_preds[name] = mask * cand[name] + \\\n                        (1.0 - mask) * output_preds[name]\n\n            prev_is_flow_op = is_flow_op\n\n        return output_preds, hint_preds", ""]}
{"filename": "nn/models/impl/encoders.py", "chunked_list": ["import clrs\nimport torch\nfrom torch.nn import Module, Sequential, Linear\n\n_DataPoint = clrs.DataPoint\n_Spec = clrs.Spec\n_Stage = clrs.Stage\n_Location = clrs.Location\n_Type = clrs.Type\n_Tensor = torch.FloatTensor", "_Type = clrs.Type\n_Tensor = torch.FloatTensor\n\n\nclass Encoder(Module):\n    def __init__(self,\n                 in_features,\n                 out_features,\n                 bias=True):\n\n        super(Encoder, self).__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.net = Sequential(\n            Linear(in_features=in_features, out_features=out_features, bias=bias)\n        )\n\n    def forward(self, x):\n        return self.net(x)", "\n\ndef preprocess(dp: _DataPoint, nb_nodes: int) -> _Tensor:\n    from torch.nn.functional import one_hot\n\n    if dp.type_ == _Type.POINTER:\n        return one_hot(dp.data.long(), nb_nodes).float()\n\n    return dp.data\n", "\n\ndef accum_edge_fts(encoder, dp: _DataPoint, data: _Tensor,\n                   edge_fts: _Tensor, adj: _Tensor) -> _Tensor:\n\n    encoding = _encode_inputs(encoder, dp, data)\n\n    if dp.location == _Location.NODE and dp.type_ == _Type.POINTER:\n        edge_fts += encoding\n\n    elif dp.location == _Location.EDGE:\n        assert dp.type_ != _Type.POINTER\n        edge_fts += encoding\n\n    return edge_fts", "\n\ndef accum_node_fts(encoder, dp: _DataPoint, data: _Tensor,\n                   node_fts: _Tensor) -> _Tensor:\n\n    encoding = _encode_inputs(encoder, dp, data)\n\n    if dp.location == _Location.NODE and dp.type_ != _Type.POINTER:\n        node_fts += encoding\n\n    return node_fts", "\n\ndef accum_graph_fts(encoders, dp: _DataPoint, data: _Tensor,\n                    graph_fts: _Tensor) -> _Tensor:\n    encoding = _encode_inputs(encoders, dp, data)\n\n    if dp.location == _Location.GRAPH and dp.type_ != _Type.POINTER:\n        graph_fts += encoding\n\n    return graph_fts", "\n\ndef _encode_inputs(encoder, dp: _DataPoint, data: _Tensor) -> _Tensor:\n    if dp.type_ in [_Type.CATEGORICAL]:\n        encoding = encoder(data)\n    else:\n        encoding = encoder(data.unsqueeze(-1))\n    return encoding\n", ""]}
{"filename": "nn/models/impl/__init__.py", "chunked_list": ["import clrs\nimport torch\n\nfrom . import decoders\n\n\n_Feedback = clrs.Feedback\n_Spec = clrs.Spec\n_Stage = clrs.Stage\n_Location = clrs.Location", "_Stage = clrs.Stage\n_Location = clrs.Location\n_Type = clrs.Type\n_DataPoint = clrs.DataPoint\n\n\ndef _dimensions(inputs):\n    for input_ in inputs:\n        if input_.location in [clrs.Location.NODE, clrs.Location.EDGE]:\n            return input_.data.shape[0], input_.data.shape[1]\n\n    assert False", "\n\ndef _bfs_op_mask(hints):\n    for dp in hints:\n        if dp.name == '__is_bfs_op':\n            return dp\n\n\ndef _hints_i(hints, i):\n    hints_i = [_DataPoint(dp.name, dp.location, dp.type_, dp.data[i]) for dp in hints]\n\n    for h in hints_i:\n        if h.name == 'f_h':\n            zero_c_h = 1 - (h.data == 0).all(-1).all(-1) * 1.0\n            break\n\n    for h in hints_i:\n        if h.name == 'c_h':\n            h.data = h.data * (1 - zero_c_h.unsqueeze(-1).unsqueeze(-1))\n            break\n\n    return hints_i", "def _hints_i(hints, i):\n    hints_i = [_DataPoint(dp.name, dp.location, dp.type_, dp.data[i]) for dp in hints]\n\n    for h in hints_i:\n        if h.name == 'f_h':\n            zero_c_h = 1 - (h.data == 0).all(-1).all(-1) * 1.0\n            break\n\n    for h in hints_i:\n        if h.name == 'c_h':\n            h.data = h.data * (1 - zero_c_h.unsqueeze(-1).unsqueeze(-1))\n            break\n\n    return hints_i", "\n\ndef _own_hints_i(preds, spec, features, i):\n    hints = list(decoders.postprocess(preds, spec).values())\n    hints.append(_bfs_op_mask(_hints_i(features.hints, i)))\n    return hints\n\n\ndef _expand(tensor, loc):\n    if loc == _Location.NODE:\n        n_dims = 3\n    elif loc == _Location.EDGE:\n        n_dims = 4\n    elif loc == _Location.GRAPH:\n        n_dims = 2\n    else:\n        assert False\n\n    return _expand_to(tensor, n_dims)", "def _expand(tensor, loc):\n    if loc == _Location.NODE:\n        n_dims = 3\n    elif loc == _Location.EDGE:\n        n_dims = 4\n    elif loc == _Location.GRAPH:\n        n_dims = 2\n    else:\n        assert False\n\n    return _expand_to(tensor, n_dims)", "\n\ndef _expand_to(tensor, num_dims):\n    while len(tensor.shape) < num_dims:\n        tensor = tensor.unsqueeze(-1)\n\n    return tensor\n\n\ndef _get_fts(trajectory, name):\n    for dp in trajectory:\n        if dp.name == name:\n            return dp\n\n    return None", "\ndef _get_fts(trajectory, name):\n    for dp in trajectory:\n        if dp.name == name:\n            return dp\n\n    return None\n\n\ndef _reset_hints(hints, source):\n    b, n = _dimensions(hints)\n    reach_h = torch.zeros((b, n))\n    for i, s in enumerate(source):\n        reach_h[i][s.argmax().item()] = 1\n\n    pi = torch.stack([torch.arange(n)] * b)\n    return [_DataPoint('reach_h', _Location.NODE, _Type.MASK, reach_h),\n            _DataPoint('pi_h', _Location.NODE, _Type.POINTER, pi)]", "\ndef _reset_hints(hints, source):\n    b, n = _dimensions(hints)\n    reach_h = torch.zeros((b, n))\n    for i, s in enumerate(source):\n        reach_h[i][s.argmax().item()] = 1\n\n    pi = torch.stack([torch.arange(n)] * b)\n    return [_DataPoint('reach_h', _Location.NODE, _Type.MASK, reach_h),\n            _DataPoint('pi_h', _Location.NODE, _Type.POINTER, pi)]", ""]}
{"filename": "nn/models/impl/processors.py", "chunked_list": ["import torch\nfrom nn.layers import MpnnConv\nfrom torch.nn import Linear, Module, ReLU, Sequential\n\n\nclass MPNN(Module):\n    def __init__(self,\n                 num_hidden: int,\n                 aggregator: str,\n                 activation: callable = None,\n                 bias: bool = True):\n\n        super(MPNN, self).__init__()\n\n        self.conv = MpnnConv(\n            in_channels=num_hidden * 2,\n            edge_channels=num_hidden,\n            mid_channels=num_hidden,\n            out_channels=num_hidden,\n            net=Sequential(\n                Linear(in_features=num_hidden, out_features=num_hidden),\n                ReLU(),\n                Linear(in_features=num_hidden, out_features=num_hidden),\n            ),\n            aggregator=aggregator,\n            mid_activation=activation,\n            activation=activation,\n            bias=bias\n        )\n\n    def forward(self, x, adj, edge_attr):\n        adj = torch.ones_like(adj).to(adj.device)\n        x = self.conv(x, adj, edge_attr)\n        return x", "\n\nclass PGN(Module):\n    def __init__(self,\n                 num_hidden: int,\n                 aggregator: str,\n                 activation: callable = None,\n                 bias: bool = True):\n        super(PGN, self).__init__()\n\n        self.conv = MpnnConv(\n            in_channels=num_hidden * 2,\n            edge_channels=num_hidden,\n            mid_channels=num_hidden,\n            out_channels=num_hidden,\n            net=Sequential(\n                Linear(in_features=num_hidden, out_features=num_hidden),\n                ReLU(),\n                Linear(in_features=num_hidden, out_features=num_hidden),\n            ),\n            aggregator=aggregator,\n            mid_activation=activation,\n            activation=activation,\n            bias=bias\n        )\n\n    def forward(self, x, adj, edge_attr):\n        x = self.conv(x, adj, edge_attr)\n        return x", "\n\nPROCESSORS = {\n    'pgn': PGN,\n    'mpnn': MPNN\n}\n"]}
{"filename": "nn/models/impl/decoders.py", "chunked_list": ["\nimport clrs\nimport torch\nfrom torch.nn import Module, Sequential, Linear\nfrom typing import Dict\n\n_INFINITY = 1e5\n\n_DataPoint = clrs.DataPoint\n_Spec = clrs.Spec", "_DataPoint = clrs.DataPoint\n_Spec = clrs.Spec\n_Stage = clrs.Stage\n_Location = clrs.Location\n_Type = clrs.Type\n_Tensor = torch.Tensor\n\n\nclass Decoder(Module):\n    def __init__(self,\n                 in_features,\n                 out_features):\n\n        super().__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.net = Sequential(\n            Linear(in_features=in_features, out_features=out_features)\n        )\n\n    def forward(self, x):\n        return self.net(x)", "class Decoder(Module):\n    def __init__(self,\n                 in_features,\n                 out_features):\n\n        super().__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.net = Sequential(\n            Linear(in_features=in_features, out_features=out_features)\n        )\n\n    def forward(self, x):\n        return self.net(x)", "\n\nclass DecoderPair(Module):\n    def __init__(self,\n                 in_features,\n                 out_features):\n\n        super().__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.first = Sequential(\n            Linear(in_features=in_features, out_features=out_features)\n        )\n\n        self.second = Sequential(\n            Linear(in_features=in_features, out_features=out_features)\n        )\n\n    def forward(self, x):\n        return self.first(x), self.second(x)", "\n\nclass DecoderEdge(Module):\n    def __init__(self,\n                 in_features,\n                 e_features,\n                 out_features):\n\n        super().__init__()\n\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.first = Sequential(\n            Linear(in_features=in_features, out_features=out_features)\n        )\n\n        self.second = Sequential(\n            Linear(in_features=in_features, out_features=out_features)\n        )\n\n        self.third = Sequential(\n            Linear(in_features=e_features, out_features=out_features)\n        )\n\n    def forward(self, x, edge_feats):\n        return self.first(x), self.second(x), self.third(edge_feats)", "\n\ndef new_decoder(spec, num_hidden, num_classes=None):\n    stage, location, type_ = spec\n\n    if location == _Location.NODE:\n        if type_ in [_Type.SCALAR, _Type.MASK, _Type.MASK_ONE]:\n            return Decoder(in_features=num_hidden*3, out_features=1)\n        if type_ == _Type.POINTER:\n            return DecoderPair(in_features=num_hidden*3, out_features=num_hidden)\n        if type_ == _Type.CATEGORICAL:\n            assert num_classes is not None\n            return Decoder(in_features=num_hidden*3, out_features=num_classes)\n\n    if location == _Location.EDGE:\n        if type_ == _Type.SCALAR:\n            return DecoderEdge(in_features=num_hidden*3,\n                               e_features=num_hidden,\n                               out_features=1)\n        if type_ == _Type.CATEGORICAL:\n            assert num_classes is not None\n            return DecoderEdge(in_features=num_hidden*3, e_features=num_hidden,\n                               out_features=num_classes)\n\n    if location == _Location.GRAPH:\n        if type_ in [_Type.SCALAR, _Type.MASK, _Type.MASK_ONE]:\n            return Decoder(in_features=num_hidden*3, out_features=1)\n\n    raise ValueError(\"Unrecognized specs during decoder creation.\")", "\n\ndef decode_from_latents(name, spec, decoder, h_t, adj, edge_attr):\n\n    stage, location, type_ = spec\n    if location == _Location.NODE:\n        if type_ in [_Type.SCALAR, _Type.MASK, _Type.MASK_ONE]:\n            return decoder(h_t).squeeze(-1)\n        if type_ == _Type.POINTER:\n            p_1, p_2 = decoder(h_t)\n            p = torch.matmul(p_1, torch.permute(p_2, (0, 2, 1)))\n            # p = p.masked_fill(~adj.bool(), -_INFINITY)\n            return p\n        if type_ == _Type.CATEGORICAL:\n            return decoder(h_t)\n\n    if location == _Location.EDGE:\n        assert edge_attr is not None\n        if type_ == _Type.SCALAR:\n            p_1, p_2, p_e = decoder(h_t, edge_attr)\n            p = (p_1.unsqueeze(-2) + p_2.unsqueeze(-3) + p_e).squeeze() * adj\n\n            if name in [\"f\", \"f_h\"]:\n                p = p - p.transpose(1, 2)  # TODO: remove and generalise\n                p = torch.tanh(p)\n            return p\n\n        if type_ == _Type.CATEGORICAL:\n            p_1, p_2, p_e = decoder(h_t, edge_attr)\n            return p_1.unsqueeze(-2) + p_2.unsqueeze(-3) + p_e\n\n    if location == _Location.GRAPH:\n        if type_ in [_Type.SCALAR, _Type.MASK, _Type.MASK_ONE]:\n            g_h = torch.amax(h_t, dim=-2)\n            return decoder(g_h).squeeze(-1)\n\n    raise ValueError(\"Unrecognized specs during decoding from latents.\")", "\n\ndef postprocess(preds: Dict[str, _Tensor], spec: _Spec) -> Dict[str, _DataPoint]:\n    result = {}\n    for name in preds.keys():\n        _, location, type_ = spec[name]\n        data = preds[name]\n\n        if type_ == _Type.SCALAR:\n            data = data\n        elif type_ == _Type.MASK:\n            data = ((data > 0.0) * 1.0)\n        elif type_ in [_Type.MASK_ONE, _Type.CATEGORICAL]:\n            data = torch.nn.functional.one_hot(data.argmax(-1), data.shape[-1]).float()\n        elif type_ == _Type.POINTER:\n            data = data.argmax(dim=-1)\n\n        result[name] = _DataPoint(name, location, type_, data)\n    return result", ""]}
