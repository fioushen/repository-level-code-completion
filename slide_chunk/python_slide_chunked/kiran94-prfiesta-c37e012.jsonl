{"filename": "prfiesta/spinner.py", "chunked_list": ["from logging import Logger\n\nfrom rich.spinner import Spinner\n\nfrom prfiesta import SPINNER_STYLE\n\n\ndef update_spinner(message: str, spinner: Spinner, logger: Logger) -> None:\n    logger.debug(message)\n    if spinner:\n        spinner.update(text=message, style=SPINNER_STYLE)", ""]}
{"filename": "prfiesta/environment.py", "chunked_list": ["import os\n\nfrom github.Consts import DEFAULT_BASE_URL as GITHUB_DEFAULT_BASE_URL\n\n\nclass GitHubEnvironment:\n\n    def get_token(self) -> str:\n        \"\"\"Gets the authentication token for this environment.\"\"\"\n        token = os.environ.get('GITHUB_ENTERPRISE_TOKEN', os.environ.get('GITHUB_TOKEN'))\n        if not token:\n            raise ValueError('GITHUB_ENTERPRISE_TOKEN or GITHUB_TOKEN must be set')\n\n        return token\n\n    def get_url(self) -> str:\n        \"\"\"Gets the URL for the git provider.\"\"\"\n        return os.environ.get('GH_HOST', GITHUB_DEFAULT_BASE_URL)", ""]}
{"filename": "prfiesta/__main__.py", "chunked_list": ["import logging\nfrom datetime import datetime\n\nimport click\nimport cloup\nfrom rich.live import Live\nfrom rich.spinner import Spinner\nfrom rich.text import Text\n\nfrom prfiesta import SPINNER_STYLE, __version__", "\nfrom prfiesta import SPINNER_STYLE, __version__\nfrom prfiesta.collectors.github import GitHubCollector\nfrom prfiesta.environment import GitHubEnvironment\nfrom prfiesta.output import output_frame\n\nlogger = logging.getLogger(__name__)\n\ngithub_environment = GitHubEnvironment()\n", "github_environment = GitHubEnvironment()\n\n@cloup.command()\n@cloup.option_group(\n    'general options',\n    cloup.option('-u', '--users', required=True, multiple=True, help='The GitHub Users to search for. Can be multiple'),\n)\n@cloup.option_group(\n    'date filter options',\n    cloup.option('-a', '--after', type=click.DateTime(formats=['%Y-%m-%d']), help='Only search for pull requests after this date e.g 2023-01-01'),", "    'date filter options',\n    cloup.option('-a', '--after', type=click.DateTime(formats=['%Y-%m-%d']), help='Only search for pull requests after this date e.g 2023-01-01'),\n    cloup.option('-b', '--before', type=click.DateTime(formats=['%Y-%m-%d']), help='Only search for pull requests before this date e.g 2023-04-30'),\n    cloup.option('-d', '--use-updated', is_flag=True, default=False, help='filter on when the pr was last updated rather then created'),\n)\n@cloup.option_group(\n    'user filter options',\n    cloup.option('-i', '--use-involves', is_flag=True, default=False, help='collect prs where the users are the author or assignee or mentioned or commented'),\n    cloup.option('-r', '--use-reviewed-by', is_flag=True, default=False, help='collect prs where the users reviewed them'),\n    cloup.option('-rr', '--use-review-requested', is_flag=True, default=False, help='collect prs where the users were requested a review'),", "    cloup.option('-r', '--use-reviewed-by', is_flag=True, default=False, help='collect prs where the users reviewed them'),\n    cloup.option('-rr', '--use-review-requested', is_flag=True, default=False, help='collect prs where the users were requested a review'),\n    constraint=cloup.constraints.mutually_exclusive,\n    help='Collect alternative details for the users. If omitted then just collect the prs that a user has authored.',\n)\n@cloup.option_group(\n    'output options',\n    cloup.option('-o', '--output', default=None, help='The output location'),\n    cloup.option(\n        '-ot', '--output-type', type=click.Choice(['csv', 'parquet', 'duckdb']), default='csv', show_default=True, show_choices=True, help='The output format'),", "    cloup.option(\n        '-ot', '--output-type', type=click.Choice(['csv', 'parquet', 'duckdb']), default='csv', show_default=True, show_choices=True, help='The output format'),\n    cloup.option('-dc', '--drop-columns', multiple=True, help='Drop columns from the output dataframe'),\n)\n@cloup.option_group(\n    'authentication options',\n    cloup.option('-x', '--url', help='The URL of the Git provider to use'),\n    cloup.option('-t', '--token', help='The Authentication token to use'),\n)\n@cloup.version_option(__version__)\ndef main(**kwargs) -> None:\n\n    users: tuple[str] = kwargs.get('users')\n    token: str = kwargs.get('token') or github_environment.get_token()\n    url: str = kwargs.get('url') or github_environment.get_url()\n    output: str = kwargs.get('output')\n    output_type: str = kwargs.get('output_type')\n    before: datetime = kwargs.get('before')\n    after: datetime = kwargs.get('after')\n    drop_columns: list[str] = list(kwargs.get('drop_columns'))\n    use_updated: bool = kwargs.get('use_updated')\n    use_involves: bool = kwargs.get('use_involves')\n    use_reviewed_by: bool = kwargs.get('use_reviewed_by')\n    use_review_requested: bool = kwargs.get('use_review_requested')\n\n    logger.info('[bold green]PR Fiesta \ud83e\udd9c\ud83e\udd73')\n\n    spinner = Spinner('dots', text=Text('Loading', style=SPINNER_STYLE))\n\n    with Live(spinner, refresh_per_second=20, transient=True):\n\n        collector = GitHubCollector(token=token, url=url, spinner=spinner, drop_columns=drop_columns)\n        pr_frame = collector.collect(\n            *users,\n            after=after,\n            before=before,\n            use_updated=use_updated,\n            use_involves=use_involves,\n            use_reviewed_by=use_reviewed_by,\n            use_review_requested=use_review_requested)\n\n        if not pr_frame.empty:\n            logger.info('Found [bold green]%s[/bold green] pull requests!', pr_frame.shape[0])\n\n            output_frame(pr_frame, output_type, spinner=spinner, output_name=output)\n            logger.info('Time to analyze \ud83d\udd0e See https://github.com/kiran94/prfiesta/blob/main/docs/analysis.md for some inspiration!')", ")\n@cloup.version_option(__version__)\ndef main(**kwargs) -> None:\n\n    users: tuple[str] = kwargs.get('users')\n    token: str = kwargs.get('token') or github_environment.get_token()\n    url: str = kwargs.get('url') or github_environment.get_url()\n    output: str = kwargs.get('output')\n    output_type: str = kwargs.get('output_type')\n    before: datetime = kwargs.get('before')\n    after: datetime = kwargs.get('after')\n    drop_columns: list[str] = list(kwargs.get('drop_columns'))\n    use_updated: bool = kwargs.get('use_updated')\n    use_involves: bool = kwargs.get('use_involves')\n    use_reviewed_by: bool = kwargs.get('use_reviewed_by')\n    use_review_requested: bool = kwargs.get('use_review_requested')\n\n    logger.info('[bold green]PR Fiesta \ud83e\udd9c\ud83e\udd73')\n\n    spinner = Spinner('dots', text=Text('Loading', style=SPINNER_STYLE))\n\n    with Live(spinner, refresh_per_second=20, transient=True):\n\n        collector = GitHubCollector(token=token, url=url, spinner=spinner, drop_columns=drop_columns)\n        pr_frame = collector.collect(\n            *users,\n            after=after,\n            before=before,\n            use_updated=use_updated,\n            use_involves=use_involves,\n            use_reviewed_by=use_reviewed_by,\n            use_review_requested=use_review_requested)\n\n        if not pr_frame.empty:\n            logger.info('Found [bold green]%s[/bold green] pull requests!', pr_frame.shape[0])\n\n            output_frame(pr_frame, output_type, spinner=spinner, output_name=output)\n            logger.info('Time to analyze \ud83d\udd0e See https://github.com/kiran94/prfiesta/blob/main/docs/analysis.md for some inspiration!')", "\nif __name__ == '__main__':  # pragma: nocover\n    main()\n"]}
{"filename": "prfiesta/__init__.py", "chunked_list": ["import importlib.metadata\nimport logging\nimport os\n\nfrom rich.logging import RichHandler\n\n__version__ = importlib.metadata.version(__name__)\n\nLOGGING_LEVEL=os.environ.get('LOGGING_LEVEL', logging.INFO)\nLOGGING_FORMAT=os.environ.get('LOGGING_FORMAT', '%(message)s')", "LOGGING_LEVEL=os.environ.get('LOGGING_LEVEL', logging.INFO)\nLOGGING_FORMAT=os.environ.get('LOGGING_FORMAT', '%(message)s')\nSPINNER_STYLE=os.environ.get('SPINNER_STYLE', 'blue')\n\nlogging.basicConfig(\n    level=LOGGING_LEVEL,\n    format=LOGGING_FORMAT,\n    handlers=[RichHandler(markup=True, show_path=False, show_time=False, show_level=True)],\n)\n", ")\n"]}
{"filename": "prfiesta/output.py", "chunked_list": ["import logging\nimport os\nimport re\nfrom datetime import datetime\nfrom typing import Literal\n\nimport duckdb\nimport pandas as pd\nfrom rich.spinner import Spinner\n", "from rich.spinner import Spinner\n\nfrom prfiesta.spinner import update_spinner\n\nlogger = logging.getLogger(__name__)\n\nOUTPUT_TYPE = Literal['csv', 'parquet', 'duckdb']\nWIN_ILLEGAL_FILENAME = r'[:\\/\\\\\\*\\?\\\"\\<\\>\\|]'\n\ndef output_frame(\n        frame: pd.DataFrame,\n        output_type: OUTPUT_TYPE,\n        spinner: Spinner,\n        output_name: str = None,\n        timestamp: datetime = None) -> None:\n\n    if not timestamp:\n        timestamp = datetime.now()\n\n    if not output_name:\n        output_name = f\"export.{timestamp.strftime('%Y%m%d%H%M%S')}.{output_type}\"\n\n    if os.name == 'nt' and re.search(WIN_ILLEGAL_FILENAME, output_name):\n        msg = f'{output_name} is an invalid filename on windows'\n        raise ValueError(msg)\n\n    update_spinner(f'Writing export to {output_name}', spinner, logger)\n\n    if output_type == 'csv':\n        frame.to_csv(output_name, index=False)\n\n    elif output_type == 'parquet':\n        frame.to_parquet(output_name, index=False)\n\n    elif output_type == 'duckdb':\n        duckdb_table = f\"prfiesta_{timestamp.strftime('%Y%m%d_%H%M%S')}\"\n\n        update_spinner(f'connecting to duckdb {output_name}', spinner, logger)\n        conn = duckdb.connect(output_name)\n\n        update_spinner(f'exporting to duckdb table {duckdb_table}', spinner, logger)\n        conn.execute(f'CREATE TABLE {duckdb_table} AS SELECT * FROM frame') # noqa: duckdb_table is always constructed internally\n\n        conn.close()\n    else:\n        raise ValueError('unknown output_type %s', output_type)\n\n    logger.info('Exported to %s!', output_name)", "\ndef output_frame(\n        frame: pd.DataFrame,\n        output_type: OUTPUT_TYPE,\n        spinner: Spinner,\n        output_name: str = None,\n        timestamp: datetime = None) -> None:\n\n    if not timestamp:\n        timestamp = datetime.now()\n\n    if not output_name:\n        output_name = f\"export.{timestamp.strftime('%Y%m%d%H%M%S')}.{output_type}\"\n\n    if os.name == 'nt' and re.search(WIN_ILLEGAL_FILENAME, output_name):\n        msg = f'{output_name} is an invalid filename on windows'\n        raise ValueError(msg)\n\n    update_spinner(f'Writing export to {output_name}', spinner, logger)\n\n    if output_type == 'csv':\n        frame.to_csv(output_name, index=False)\n\n    elif output_type == 'parquet':\n        frame.to_parquet(output_name, index=False)\n\n    elif output_type == 'duckdb':\n        duckdb_table = f\"prfiesta_{timestamp.strftime('%Y%m%d_%H%M%S')}\"\n\n        update_spinner(f'connecting to duckdb {output_name}', spinner, logger)\n        conn = duckdb.connect(output_name)\n\n        update_spinner(f'exporting to duckdb table {duckdb_table}', spinner, logger)\n        conn.execute(f'CREATE TABLE {duckdb_table} AS SELECT * FROM frame') # noqa: duckdb_table is always constructed internally\n\n        conn.close()\n    else:\n        raise ValueError('unknown output_type %s', output_type)\n\n    logger.info('Exported to %s!', output_name)", ""]}
{"filename": "prfiesta/collectors/__init__.py", "chunked_list": [""]}
{"filename": "prfiesta/collectors/github.py", "chunked_list": ["import logging\nfrom datetime import datetime\nfrom typing import List, Optional, Tuple\n\nimport pandas as pd\nfrom github import Github\nfrom github.GithubException import RateLimitExceededException\nfrom rich.spinner import Spinner\n\nfrom prfiesta.environment import GitHubEnvironment", "\nfrom prfiesta.environment import GitHubEnvironment\nfrom prfiesta.spinner import update_spinner\n\nlogger = logging.getLogger(__name__)\n\n\nclass GitHubCollector:\n\n    def __init__(self, **kwargs) -> None:\n\n        environment = GitHubEnvironment()\n        token = kwargs.get('token') or environment.get_token()\n        self._url = kwargs.get('url') or environment.get_url()\n\n        self._github = Github(token, base_url=self._url)\n        self._spinner: Spinner = kwargs.get('spinner')\n\n        self._sort_column = ['updated_at']\n        self._drop_columns = kwargs.get('drop_columns') or ['node_id', 'performed_via_github_app']\n\n        self._move_to_end_columns = [\n            'url',\n            'repository_url',\n            'html_url',\n            'timeline_url',\n            'labels_url',\n            'comments_url',\n            'events_url',\n        ]\n        self._datetime_columns = [\n            'created_at',\n            'updated_at',\n            'closed_at',\n        ]\n\n\n    def collect(\n            self,\n            *users: Tuple[str],\n            after: Optional[datetime] = None,\n            before: Optional[datetime] = None,\n            use_updated: Optional[bool] = False,\n            use_involves: Optional[bool] = False,\n            use_reviewed_by: Optional[bool] = False,\n            use_review_requested: Optional[bool] = False,\n        ) -> pd.DataFrame:\n\n        query = self._construct_query(users, after, before, use_updated, use_involves, use_reviewed_by, use_review_requested)\n\n        update_spinner(f'Searching {self._url} with[bold blue] {query}', self._spinner,  logger)\n\n        pull_request_data = None\n        try:\n            pulls = self._github.search_issues(query=query)\n\n            pull_request_data: list[dict] = []\n            for pr in pulls:\n                pull_request_data.append(pr.__dict__['_rawData'])\n\n        except RateLimitExceededException as e:\n            logger.warning('\ud83d\ude47 You were rate limited by the GitHub API, try requesting less data.')\n            logger.debug(e)\n            return pd.DataFrame()\n\n        if not pull_request_data:\n            logger.warning('Did not find any results for this search criteria!')\n            return pd.DataFrame()\n\n        update_spinner('Post Processing', self._spinner, logger)\n        pr_frame = pd.json_normalize(pull_request_data)\n\n        pr_frame = pr_frame.drop(columns=self._drop_columns, errors='ignore')\n        pr_frame = pr_frame.sort_values(by=self._sort_column, ascending=False)\n        pr_frame = self._parse_datetime_columns(pr_frame)\n        pr_frame['repository_name'] = pr_frame['repository_url'].str.extract(r'(.*)\\/repos\\/(?P<repository_name>(.*))')['repository_name']\n        pr_frame = self._move_column_to_end(pr_frame)\n\n        return pr_frame\n\n\n    @staticmethod\n    def _construct_query(\n            users: List[str],\n            after: Optional[datetime] = None,\n            before: Optional[datetime] = None,\n            use_updated: Optional[bool] = False,\n            use_involves: Optional[bool] = False,\n            use_reviewed_by: Optional[bool] = False,\n            use_review_requested: Optional[bool] = False,\n        ) -> str:\n        \"\"\"\n        Constructs a GitHub Search Query\n        that returns pull requests made by the passed users and options.\n\n        Examples\n        --------\n            type:pr author:user1\n            type:pr author:user2 created:<=2021-01-01\n            type:pr author:user1 author:user2 created:2021-01-01..2021-03-01\n            type:pr author:user2 updated:>=2021-01-01\n            type:pr involves:user2\n            type:pr reviewed-by:user1\n            type:pr review-requested:user1\n\n        All dates are inclusive.\n        See GitHub Docs for full options https://docs.github.com/en/search-github/searching-on-github/searching-issues-and-pull-requests\n        \"\"\"\n        query: List[str] = []\n        query.append('type:pr')\n\n        author_filter = 'author'\n        if use_involves:\n            author_filter = 'involves'\n        elif use_reviewed_by:\n            author_filter = 'reviewed-by'\n        elif use_review_requested:\n            author_filter = 'review-requested'\n\n        logger.debug('using author filter %s', author_filter)\n\n        for u in users:\n            query.append(f'{author_filter}:{u}')\n\n        time_filter = 'created'\n        if use_updated:\n            time_filter = 'updated'\n\n        logger.debug('using time filter %s', time_filter)\n\n        if before and after:\n            query.append(f\"{time_filter}:{after.strftime('%Y-%m-%d')}..{before.strftime('%Y-%m-%d')}\")\n        elif before:\n            query.append(f\"{time_filter}:<={before.strftime('%Y-%m-%d')}\")\n        elif after:\n            query.append(f\"{time_filter}:>={after.strftime('%Y-%m-%d')}\")\n\n        return ' '.join(query)\n\n    def _move_column_to_end(self, df: pd.DataFrame) -> pd.DataFrame:\n        for col in self._move_to_end_columns:\n            try:\n                df.insert(len(df.columns)-1, col, df.pop(col))\n                df.drop(columns=col)\n            except KeyError:\n                # This can happen if the user provides a custom _drop_columns which\n                # removes the column before we can move it to the end\n                logger.debug('Attempted to move column %s but it did not exist', col)\n\n        return df\n\n    def _parse_datetime_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n        for col in self._datetime_columns:\n            df[col] = pd.to_datetime(df[col], errors='ignore')\n        return df", "\n\n\nif __name__ == '__main__':  # pragma: nocover\n    g = GitHubCollector()\n    logger.info(g._construct_query(['kiran94', 'hello'], datetime(2021, 1, 1), datetime(2021, 3, 1)))\n"]}
{"filename": "prfiesta/analysis/plot.py", "chunked_list": ["import calendar\nimport logging\nfrom typing import Optional, Union\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib.axes import Axes\n\nlogger = logging.getLogger(__name__)", "\nlogger = logging.getLogger(__name__)\n\n_months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\ndef plot_state_distribution(data: pd.DataFrame, **kwargs) -> Union[plt.Figure, plt.Axes, pd.DataFrame]:\n\n    ax: Optional[Axes] = kwargs.get('ax')\n    palette: Optional[str] = kwargs.get('palette')\n    title: Optional[str] = kwargs.get('title', 'State Distribution')\n    hue: Optional[str] = kwargs.get('hue', 'repository_name')\n\n    if ax:\n        ax.set_title(title)\n\n    return sns.histplot(data, x='state', hue=hue, ax=ax, palette=palette)", "\ndef plot_overall_timeline(data: pd.DataFrame, **kwargs) -> Union[plt.Figure, plt.Axes, pd.DataFrame]:\n\n    ax: Optional[Axes] = kwargs.get('ax')\n    palette: Optional[str] = kwargs.get('palette')\n    title: Optional[str] = kwargs.get('title', 'Overall Contributions')\n    hue: Optional[str] = kwargs.get('hue', 'month')\n\n    temp = data.copy()\n\n    temp['month'] = temp['created_at'].dt.month_name()\n    temp['year'] = temp['created_at'].dt.year.astype(str)\n\n    temp = temp.groupby(['month', 'year'])['id'].count()\n    temp = temp.reset_index()\n\n    # X Axis Ordering (Year)\n    x_order = temp['year'].unique().tolist()\n    x_order = [int(x) for x in x_order]\n    x_order.sort()\n    x_order = [str(x) for x in x_order]\n\n    # Hue Ordering (Months)\n    sorted_months = sorted(_months, key=lambda x: list(calendar.month_name).index(x))\n\n    p = sns.barplot(temp, x='year', y='id', hue=hue, ax=ax, order=x_order, hue_order=sorted_months, palette=palette)\n\n    if ax:\n        ax.set_title(title)\n        ax.legend(loc='upper left')\n\n    return p", "\ndef plot_author_associations(data: pd.DataFrame, **kwargs) -> Union[plt.Figure, plt.Axes, pd.DataFrame]:\n\n    ax: Optional[Axes] = kwargs.get('ax')\n    palette: Optional[str] = kwargs.get('palette')\n    title: Optional[str] = kwargs.get('title', 'Author Associations')\n\n    temp = data.groupby('author_association')['id'].count()\n    temp.name = 'count'\n\n    return temp.plot.pie(ax=ax, title=title, legend=True, colormap=palette)", "\ndef plot_conventional_commit_breakdown(data: pd.DataFrame, **kwargs) -> Union[plt.Figure, plt.Axes, pd.DataFrame]:\n\n    ax: Optional[Axes] = kwargs.get('ax')\n    palette: Optional[str] = kwargs.get('palette')\n    title: Optional[str] = kwargs.get('title', 'Conventional Commit Breakdown')\n    hue: Optional[str] = kwargs.get('hue', 'type')\n\n    conventional_commit_frame = data['title'] \\\n        .str \\\n        .extract(r'^(?P<type>feat|fix|docs|style|refactor|test|chore|build|ci|perf)(\\((?P<scope>[A-Za-z-]+)\\))?: (?P<subject>[^\\n]+)$').copy()\n\n    conventional_commit_frame = conventional_commit_frame.drop(columns=[1, 'subject'])\n    conventional_commit_frame = pd.concat([conventional_commit_frame, data['repository_name']], axis=1)\n    conventional_commit_frame = conventional_commit_frame.dropna(subset=['type'])\n\n    if conventional_commit_frame.empty:\n        logger.warning('passed data did not seem to have any conventional commits')\n        return None\n\n    type_count = conventional_commit_frame.groupby(['type', 'repository_name']).count().reset_index()\n    type_count = type_count[type_count['scope'] != 0]\n    type_count = type_count.sort_values(by='scope', ascending=False)\n    type_count = type_count.rename(columns={'scope': 'count'})\n\n    p = sns.barplot(type_count, y='repository_name', x='count', hue=hue, ax=ax, palette=palette)\n\n    if ax:\n        ax.set_title(title)\n        ax.legend(loc='upper right')\n\n    return p", "\ndef plot_reactions(data: pd.DataFrame, **kwargs) -> Union[plt.Figure, plt.Axes, pd.DataFrame]:\n\n    ax: Optional[Axes] = kwargs.get('ax')\n    palette: Optional[str] = kwargs.get('palette')\n    title: Optional[str] = kwargs.get('title', 'Reactions')\n    hue: Optional[str] = kwargs.get('hue')\n    threshold: Optional[int] = kwargs.get('threshold')\n\n    reaction_columns = [x for x in data.columns.tolist() if x.startswith('reactions.') and x not in ['reactions.url']]\n\n    reaction_df = data[reaction_columns]\n    reaction_df = reaction_df[reaction_df['reactions.total_count'] > 0]\n    reaction_df = reaction_df.drop(columns=['reactions.total_count'])\n\n    if reaction_df.empty:\n        logger.warning('passed data did not seem to have any reactions \ud83d\ude41')\n        return None\n\n    if threshold:\n        reaction_df = reaction_df[reaction_df < threshold]\n\n    p = sns.scatterplot(reaction_df, ax=ax, palette=palette, hue=hue)\n\n    if ax:\n        ax.set_title(title)\n        ax.legend(loc='upper right')\n\n    return p", ""]}
{"filename": "prfiesta/analysis/view.py", "chunked_list": ["from datetime import datetime, timezone\n\nimport pandas as pd\nfrom IPython.display import HTML, DisplayObject\nfrom natural.date import duration\n\n\ndef _enrich_pr_link(data: pd.DataFrame) -> pd.DataFrame:\n    def make_link(row: pd.Series) -> str:\n        return f'<a href=\"{row[\"html_url\"]}\">{row[\"title\"]}</a>'\n\n    data['title'] = data.apply(make_link, axis=1)\n    return data.drop(columns='html_url')", "\n\ndef view_pull_requests(data: pd.DataFrame, **kwargs) -> DisplayObject:\n\n    as_frame: bool = kwargs.get('as_frame', False)\n    relative_dates: bool = kwargs.get('relative_dates', True)\n    head: int = kwargs.get('head')\n\n    temp = data[['number', 'title', 'repository_name', 'updated_at', 'html_url']].copy()\n    temp = _enrich_pr_link(temp)\n\n    if relative_dates:\n        temp['updated_at'] = pd.to_datetime(temp['updated_at'])\n        temp['updated_at'] = temp['updated_at'].apply(duration, now=datetime.now(timezone.utc))\n\n    if head:\n        temp = temp.head(head)\n\n    if as_frame:\n        return temp\n\n    return HTML(temp.to_html(escape=False, index=False))", ""]}
{"filename": "prfiesta/analysis/__init__.py", "chunked_list": [""]}
{"filename": "tests/test_main.py", "chunked_list": ["import os\nfrom datetime import datetime\nfrom typing import List\nfrom unittest.mock import ANY, Mock, call, patch\n\nimport pandas as pd\nimport pytest\nfrom click.testing import CliRunner\n\nfrom prfiesta.__main__ import main", "\nfrom prfiesta.__main__ import main\n\nFAILURE_CODE = 2\n\n\ndef test_main_missing_users() -> None:\n    runner = CliRunner()\n    result = runner.invoke(main, [''])\n\n    assert \"Missing option '-u' / '--users'\" in result.output\n    assert result.exit_code == FAILURE_CODE", "\n\n@pytest.mark.parametrize('arguments', [\n    pytest.param(['--users', 'user', '--use-involves', '--use-reviewed-by', '--use-review-requested']),\n    pytest.param(['--users', 'user', '--use-involves', '--use-reviewed-by']),\n    pytest.param(['--users', 'user', '--use-reviewed-by', '--use-review-requested']),\n    pytest.param(['--users', 'user', '--use-involves', '--use-review-requested']),\n])\ndef test_main_author_filters_mutually_exclusive(arguments: List[str]) -> None:\n    runner = CliRunner()\n    result = runner.invoke(main, arguments)\n\n    assert 'the following parameters are mutually exclusive' in result.output\n    assert result.exit_code == FAILURE_CODE", "def test_main_author_filters_mutually_exclusive(arguments: List[str]) -> None:\n    runner = CliRunner()\n    result = runner.invoke(main, arguments)\n\n    assert 'the following parameters are mutually exclusive' in result.output\n    assert result.exit_code == FAILURE_CODE\n\n@pytest.mark.parametrize(('params', 'expected_collect_params', 'collect_response', 'expected_output_type', 'expected_output'), [\n\n    pytest.param", "\n    pytest.param\n    (\n        ['--users', 'test_user'],\n        [call('test_user', after=None, before=None, use_updated=False, use_involves=False, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(),\n        'csv',\n        None,\n        id='user_provided',\n    ),", "        id='user_provided',\n    ),\n    pytest.param\n    (\n        ['--users', 'test_user', '--after', '2020-01-01'],\n        [call('test_user', after=datetime(2020, 1, 1), before=None, use_updated=False, use_involves=False, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(),\n        'csv',\n        None,\n        id='with_after',", "        None,\n        id='with_after',\n    ),\n    pytest.param\n    (\n        ['--users', 'test_user', '--before', '2020-01-01'],\n        [call('test_user', before=datetime(2020, 1, 1), after=None, use_updated=False, use_involves=False, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(),\n        'csv',\n        None,", "        'csv',\n        None,\n        id='with_before',\n    ),\n    pytest.param\n    (\n        ['--users', 'test_user', '--before', '2020-01-01', '--after', '2009-01-01'],\n        [call(\n            'test_user',\n            before=datetime(2020, 1, 1),", "            'test_user',\n            before=datetime(2020, 1, 1),\n            after=datetime(2009, 1, 1),\n            use_updated=False,\n            use_involves=False,\n            use_reviewed_by=False,\n            use_review_requested=False)],\n        pd.DataFrame(),\n        'csv',\n        None,", "        'csv',\n        None,\n        id='with_before_and_after',\n    ),\n    pytest.param\n    (\n        ['--users', 'test_user'],\n        [call('test_user', after=None, before=None, use_updated=False, use_involves=False, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(\n                data=[(1, 2, 3)],", "        pd.DataFrame(\n                data=[(1, 2, 3)],\n                columns=['col1', 'col2', 'col3'],\n        ),\n        'csv',\n        None,\n        id='with_collected_responses',\n    ),\n    pytest.param\n    (", "    pytest.param\n    (\n        ['--users', 'test_user', '--output-type', 'parquet'],\n        [call('test_user', after=None, before=None, use_updated=False, use_involves=False, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(\n                data=[(1, 2, 3)],\n                columns=['col1', 'col2', 'col3'],\n        ),\n        'parquet',\n        None,", "        'parquet',\n        None,\n        id='with_parquet',\n    ),\n    pytest.param\n    (\n        ['--users', 'test_user', '--before', '2020-01-01', '--use-updated'],\n        [call('test_user', before=datetime(2020, 1, 1), after=None, use_updated=True, use_involves=False, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(),\n        'csv',", "        pd.DataFrame(),\n        'csv',\n        None,\n        id='with_use_updated',\n    ),\n    pytest.param\n    (\n        ['--users', 'test_user', '--before', '2020-01-01', '--use-involves'],\n        [call('test_user', before=datetime(2020, 1, 1), after=None, use_updated=False, use_involves=True, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(),", "        [call('test_user', before=datetime(2020, 1, 1), after=None, use_updated=False, use_involves=True, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(),\n        'csv',\n        None,\n        id='with_use_involves',\n    ),\n    pytest.param\n    (\n        ['--users', 'test_user', '--use-reviewed-by'],\n        [call('test_user', after=None, before=None, use_updated=False, use_involves=False, use_reviewed_by=True, use_review_requested=False)],", "        ['--users', 'test_user', '--use-reviewed-by'],\n        [call('test_user', after=None, before=None, use_updated=False, use_involves=False, use_reviewed_by=True, use_review_requested=False)],\n        pd.DataFrame(),\n        'csv',\n        None,\n        id='user_reviewed_by',\n    ),\n    pytest.param\n    (\n        ['--users', 'test_user', '--use-review-requested'],", "    (\n        ['--users', 'test_user', '--use-review-requested'],\n        [call('test_user', after=None, before=None, use_updated=False, use_involves=False, use_reviewed_by=False, use_review_requested=True)],\n        pd.DataFrame(),\n        'csv',\n        None,\n        id='user_review_requested',\n    ),\n    pytest.param\n    (", "    pytest.param\n    (\n        ['--users', 'test_user', '--output-type', 'duckdb', '--output', 'my.duckdb'],\n        [call('test_user', after=None, before=None, use_updated=False, use_involves=False, use_reviewed_by=False, use_review_requested=False)],\n        pd.DataFrame(data={'a': [1, 2, 3]}),\n        'duckdb',\n        'my.duckdb',\n        id='with_duckdb',\n    ),\n])", "    ),\n])\n@patch('prfiesta.__main__.Spinner')\n@patch('prfiesta.__main__.Live')\n@patch('prfiesta.__main__.GitHubCollector')\n@patch('prfiesta.__main__.output_frame')\n@patch.dict(os.environ, {'GITHUB_TOKEN': 'token'}, clear=True)\ndef test_main(\n        mock_output_frame: Mock,\n        mock_collector: Mock,\n        mock_live: Mock,\n        mock_spinner: Mock,\n        params: List[str],\n        expected_collect_params: List,\n        collect_response: pd.DataFrame,\n        expected_output_type: str,\n        expected_output: str,\n    ) -> None:\n\n    mock_collector.return_value.collect.return_value = collect_response\n    runner = CliRunner()\n    result = runner.invoke(main, params)\n\n    assert mock_live.called\n    assert mock_spinner.called\n\n    assert mock_collector.call_args_list == [call(token=ANY, url='https://api.github.com', spinner=mock_spinner.return_value, drop_columns=[])]\n    assert mock_collector.return_value.collect.call_args_list == expected_collect_params\n\n    if not collect_response.empty:\n        assert mock_output_frame.call_args_list \\\n            == [call(collect_response, expected_output_type, spinner=mock_spinner.return_value, output_name=expected_output)]\n\n    assert result.exit_code == 0", ""]}
{"filename": "tests/test_spinners.py", "chunked_list": ["from unittest.mock import Mock, call\n\nimport pytest\n\nfrom prfiesta import SPINNER_STYLE\nfrom prfiesta.spinner import update_spinner\n\n\n@pytest.mark.parametrize(('message', 'spinner', 'logger'), [\n    pytest.param('my_message', Mock(), Mock(), id='all_parameters_supplied'),", "@pytest.mark.parametrize(('message', 'spinner', 'logger'), [\n    pytest.param('my_message', Mock(), Mock(), id='all_parameters_supplied'),\n    pytest.param('my_message', None, Mock(), id='spinner_none'),\n])\ndef test_update_spinner(message: str, spinner: Mock, logger: Mock) -> None:\n\n    update_spinner(message, spinner, logger)\n\n    assert logger.debug.call_args_list == [call(message)]\n\n    if spinner:\n        assert spinner.update.call_args_list == [call(text=message, style=SPINNER_STYLE)]", ""]}
{"filename": "tests/__init__.py", "chunked_list": [""]}
{"filename": "tests/test_environment.py", "chunked_list": ["import os\nfrom unittest.mock import patch\n\nimport pytest\nfrom github.Consts import DEFAULT_BASE_URL\n\nfrom prfiesta.environment import GitHubEnvironment\n\n\n@patch.dict(os.environ, {'GITHUB_ENTERPRISE_TOKEN': 'enterprise_token'}, clear=True)\ndef test_environment_get_token_enterprise() -> None:\n    gh = GitHubEnvironment()\n    assert gh.get_token() == 'enterprise_token'", "\n@patch.dict(os.environ, {'GITHUB_ENTERPRISE_TOKEN': 'enterprise_token'}, clear=True)\ndef test_environment_get_token_enterprise() -> None:\n    gh = GitHubEnvironment()\n    assert gh.get_token() == 'enterprise_token'\n\n\n@patch.dict(os.environ, {'GITHUB_TOKEN': 'token'}, clear=True)\ndef test_environment_get_token() -> None:\n    gh = GitHubEnvironment()\n    assert gh.get_token() == 'token'", "def test_environment_get_token() -> None:\n    gh = GitHubEnvironment()\n    assert gh.get_token() == 'token'\n\n@patch.dict(os.environ, {}, clear=True)\ndef test_environment_get_token_none_set() -> None:\n    gh = GitHubEnvironment()\n    with pytest.raises(ValueError, match='GITHUB_ENTERPRISE_TOKEN or GITHUB_TOKEN must be set'):\n        gh.get_token()\n", "\n@patch.dict(os.environ, {'GITHUB_TOKEN': 'token', 'GITHUB_ENTERPRISE_TOKEN': 'enterprise_token'}, clear=True)\ndef test_environment_both_environment_set() -> None:\n    gh = GitHubEnvironment()\n    assert gh.get_token() == 'enterprise_token'\n\n\n@patch.dict(os.environ, {'GH_HOST': 'host'}, clear=True)\ndef test_environemnt_get_url_host_set() -> None:\n    gh = GitHubEnvironment()\n    assert gh.get_url() == 'host'", "def test_environemnt_get_url_host_set() -> None:\n    gh = GitHubEnvironment()\n    assert gh.get_url() == 'host'\n\ndef test_environment_get_url_host_not_set() -> None:\n    gh = GitHubEnvironment()\n    assert gh.get_url() == DEFAULT_BASE_URL\n"]}
{"filename": "tests/test_output.py", "chunked_list": ["from datetime import datetime\nfrom unittest.mock import ANY, Mock, call, patch\n\nimport pytest\n\nfrom prfiesta.output import output_frame\n\n\n@pytest.mark.parametrize(('output_type', 'timestamp'), [\n    pytest.param('csv', datetime(2021, 1, 1), id='csv_with_timestamp'),", "@pytest.mark.parametrize(('output_type', 'timestamp'), [\n    pytest.param('csv', datetime(2021, 1, 1), id='csv_with_timestamp'),\n    pytest.param('parquet', datetime(2021, 1, 1), id='parquet_with_timestamp'),\n    pytest.param('csv', None, id='csv_without_timestamp'),\n    pytest.param('parquet', None, id='parquet_without_timestamp'),\n])\ndef test_output_frame(output_type: str, timestamp: datetime) -> None:\n\n    mock_frame: Mock = Mock()\n    mock_spinner: Mock = Mock()\n\n    output_frame(mock_frame, output_type, mock_spinner, timestamp=timestamp)\n\n    assert mock_spinner.update.called\n\n    if timestamp and output_type == 'csv':\n        assert [call('export.20210101000000.csv', index=False)] == mock_frame.to_csv.call_args_list\n\n    elif timestamp and output_type == 'parquet':\n        assert [call('export.20210101000000.parquet', index=False)] == mock_frame.to_parquet.call_args_list\n\n    elif not timestamp and output_type == 'csv':\n        assert [call(ANY, index=False)] == mock_frame.to_csv.call_args_list\n\n    elif not timestamp and output_type == 'parquet':\n        assert [call(ANY, index=False)] == mock_frame.to_parquet.call_args_list", "\ndef test_output_frame_unknown_type() -> None:\n\n    mock_frame: Mock = Mock()\n    mock_spinner: Mock = Mock()\n\n    with pytest.raises(ValueError, match='unknown output_type'):\n        output_frame(mock_frame, 'unknown_type', mock_spinner, timestamp=datetime(2021, 1, 1))\n\n@patch('prfiesta.output.duckdb')\ndef test_output_duckdb(mock_duckdb: Mock) -> None:\n\n    mock_frame: Mock = Mock()\n    mock_spinner: Mock = Mock()\n\n    mock_duckdb_connection = Mock()\n    mock_duckdb.connect.return_value = mock_duckdb_connection\n\n    timestamp = datetime(2021, 1, 1)\n    output_frame(mock_frame, 'duckdb', mock_spinner, timestamp=timestamp)\n\n    assert mock_duckdb.connect.called\n    assert mock_duckdb_connection.execute.call_args_list == [call('CREATE TABLE prfiesta_20210101_000000 AS SELECT * FROM frame')]\n    assert mock_duckdb_connection.close.called", "\n@patch('prfiesta.output.duckdb')\ndef test_output_duckdb(mock_duckdb: Mock) -> None:\n\n    mock_frame: Mock = Mock()\n    mock_spinner: Mock = Mock()\n\n    mock_duckdb_connection = Mock()\n    mock_duckdb.connect.return_value = mock_duckdb_connection\n\n    timestamp = datetime(2021, 1, 1)\n    output_frame(mock_frame, 'duckdb', mock_spinner, timestamp=timestamp)\n\n    assert mock_duckdb.connect.called\n    assert mock_duckdb_connection.execute.call_args_list == [call('CREATE TABLE prfiesta_20210101_000000 AS SELECT * FROM frame')]\n    assert mock_duckdb_connection.close.called", "\n@pytest.mark.parametrize('filename',[\n    'illegal:filename.csv',\n    '<illegalfilename.csv',\n    'illegalfilename.csv>',\n    'illegal\\\"filename.csv',\n    '/illegalfilename.csv',\n    'illegalfilename.\\\\csv',\n    'illegalfilename|.csv',\n    '*illegalfilename.csv',", "    'illegalfilename|.csv',\n    '*illegalfilename.csv',\n    'illegalfilename.csv?',\n])\n@patch('os.name', 'nt')\ndef test_output_illegal_filename_windows(filename: str) -> None:\n    with pytest.raises(ValueError, match='is an invalid filename on windows'):\n        output_frame(frame=Mock(), output_type='csv', spinner=Mock(), output_name=filename, timestamp=datetime(2021, 1, 1))\n", ""]}
{"filename": "tests/collectors/__init__.py", "chunked_list": [""]}
{"filename": "tests/collectors/test_github.py", "chunked_list": ["from datetime import datetime\nfrom typing import List, Tuple\nfrom unittest.mock import Mock, call, patch\n\nimport pytest\nfrom github.GithubException import RateLimitExceededException\n\nfrom prfiesta.collectors.github import GitHubCollector\n\n_mock_issue1 = Mock()", "\n_mock_issue1 = Mock()\n_mock_issue1.__dict__ = {\n        '_rawData': {\n            'url': 'my_url',\n            'repository_url': 'https://api.github.com/repos/user/repo',\n            'html_url': '',\n            'timeline_url': '',\n            'labels_url': '',\n            'comments_url': '',", "            'labels_url': '',\n            'comments_url': '',\n            'events_url': '',\n            'node_id': '',\n            'performed_via_github_app': '',\n            'active_lock_reason': '',\n            'created_at': '2021-01-01',\n            'updated_at': datetime(2021, 1, 1),\n            'closed_at': datetime(2021, 1, 1),\n            'milestone.created_at': '2020-03-04',", "            'closed_at': datetime(2021, 1, 1),\n            'milestone.created_at': '2020-03-04',\n            'milestone.updated_at': datetime(2021, 1, 1),\n            'milestone.due_on': datetime(2021, 1, 1),\n            'milestone.closed_at': datetime(2021, 1, 1),\n        },\n}\n\n_mock_issue2 = Mock()\n_mock_issue2.__dict__ = {", "_mock_issue2 = Mock()\n_mock_issue2.__dict__ = {\n        '_rawData': {\n            'url': 'my_url',\n            'repository_url': 'https://api.github.com/repos/user1/repo',\n            'html_url': '',\n            'timeline_url': '',\n            'labels_url': '',\n            'comments_url': '',\n            'events_url': '',", "            'comments_url': '',\n            'events_url': '',\n            'node_id': '',\n            'performed_via_github_app': '',\n            'active_lock_reason': '',\n            'created_at': datetime(2021, 1, 1),\n            'updated_at': datetime(2021, 1, 2),\n            'closed_at': datetime(2021, 1, 1),\n            'milestone.created_at': datetime(2021, 1, 1),\n            'milestone.updated_at': datetime(2021, 1, 1),", "            'milestone.created_at': datetime(2021, 1, 1),\n            'milestone.updated_at': datetime(2021, 1, 1),\n            'milestone.due_on': datetime(2021, 1, 1),\n            'milestone.closed_at': datetime(2021, 1, 1),\n        },\n}\n\n\n@pytest.mark.parametrize(('collect_users', 'collect_params', 'github_issues', 'expected_github_query'), [\n    pytest.param", "@pytest.mark.parametrize(('collect_users', 'collect_params', 'github_issues', 'expected_github_query'), [\n    pytest.param\n    (\n        ('user1', 'user2'),\n        {},\n        [],\n        None,\n        id='no_results',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1',),\n        {},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr author:user1',\n        id='user_returned_results',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1', 'user2'),\n        {},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr author:user1 author:user2',\n        id='users_returned_results',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1', 'user2'),\n        {'after': datetime(2009, 1, 1)},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr author:user1 author:user2 created:>=2009-01-01',\n        id='after_returned_results',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1', 'user2'),\n        {'before': datetime(2009, 1, 1)},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr author:user1 author:user2 created:<=2009-01-01',\n        id='before_returned_resutls',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1', 'user2'),\n        {'after': datetime(2009, 1, 1),  'before': datetime(2010, 1, 1)},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr author:user1 author:user2 created:2009-01-01..2010-01-01',\n        id='before_and_after_returned_results',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1',),\n        {'after': datetime(2009, 1, 1), 'use_updated': True},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr author:user1 updated:>=2009-01-01',\n        id='updated_after_returned_results',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1',),\n        {'before': datetime(2009, 1, 1), 'use_updated': True},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr author:user1 updated:<=2009-01-01',\n        id='updated_before_returned_resutls',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1',),\n        {'after': datetime(2009, 1, 1),  'before': datetime(2010, 1, 1), 'use_updated': True},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr author:user1 updated:2009-01-01..2010-01-01',\n        id='updated_before_and_after_returned_results',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1', 'user2'),\n        { 'use_involves': True },\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr involves:user1 involves:user2',\n        id='involves_user',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1',),\n        {'after': datetime(2009, 1, 1),  'before': datetime(2010, 1, 1), 'use_updated': True, 'use_involves': True},\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr involves:user1 updated:2009-01-01..2010-01-01',\n        id='involves_updated_before_and_after_returned_results',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1', 'user2'),\n        { 'use_reviewed_by': True },\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr reviewed-by:user1 reviewed-by:user2',\n        id='reviewed_by_user',\n    ),\n    pytest.param", "    ),\n    pytest.param\n    (\n        ('user1', 'user2'),\n        { 'use_review_requested': True },\n        [ _mock_issue1, _mock_issue2 ],\n        'type:pr review-requested:user1 review-requested:user2',\n        id='review_requested_user',\n    ),\n])", "    ),\n])\n@patch('prfiesta.collectors.github.Github')\ndef test_collect(\n        mock_github: Mock,\n        collect_users: Tuple[str],\n        collect_params: dict,\n        github_issues: List[Mock],\n        expected_github_query: str,\n    ) -> None:\n\n    spinner_mock = Mock()\n    collector_params = {\n        'token': 'dummy_token',\n        'url': 'dummy_url',\n        'spinner': spinner_mock,\n    }\n\n    mock_github.return_value.search_issues.return_value = github_issues\n\n    gc = GitHubCollector(**collector_params)\n    returned = gc.collect(*collect_users, **collect_params)\n\n    assert mock_github.call_args_list == [call('dummy_token', base_url='dummy_url')]\n    assert gc._spinner == collector_params['spinner']\n    assert spinner_mock.update.called\n\n    if not github_issues:\n        assert returned.empty\n        return\n\n    assert mock_github.return_value.search_issues.call_args_list == [call(query=expected_github_query)]\n\n    # Ensure the rows and columns came as expected\n    assert returned.shape == (2, 16)\n\n    # Ensure none of the drop columns came through\n    assert not set(gc._drop_columns).intersection(set(returned.columns.tolist()))\n\n    # Ensure that updated at is orderered in decreasing order\n    assert returned['updated_at'].is_monotonic_decreasing\n\n    # Ensure the all the input repos came through\n    assert set(returned['repository_name'].unique().tolist()) == {'user/repo', 'user1/repo'}\n\n    # Ensure all the datetime columns were converted\n    for col in returned[gc._datetime_columns].columns.tolist():\n        assert str(returned[col].dtype) == 'datetime64[ns]', f'{col} was not a datetime column'", "\n\n@patch('prfiesta.collectors.github.Github')\ndef test_collect_rate_limit(mock_github: Mock) -> None:\n    mock_github.return_value.search_issues.side_effect = RateLimitExceededException(429, {}, {})\n\n    spinner_mock = Mock()\n    collector_params = {\n        'token': 'dummy_token',\n        'url': 'dummy_url',\n        'spinner': spinner_mock,\n    }\n\n    gc = GitHubCollector(**collector_params)\n    result = gc.collect('user')\n\n    assert result.empty", "\n\n@patch('prfiesta.collectors.github.Github')\ndef test_collect_custom_drop_columns(mock_github: Mock) -> None:\n\n    mock_github.return_value.search_issues.return_value = [_mock_issue1]\n\n    collector_params = {\n        'token': 'dummy_token',\n        'url': 'dummy_url',\n        'drop_columns': ['comments_url'],\n    }\n\n    gc = GitHubCollector(**collector_params)\n    result = gc.collect('user1')\n\n    columns = result.columns.tolist()\n    assert 'comments_url' not in columns\n\n    # These are default drop columns\n    # Since we are overriding it in this scenario, they should still exist in the output column\n    assert 'node_id' in columns\n    assert 'performed_via_github_app' in columns", ""]}
{"filename": "tests/analysis/test_view.py", "chunked_list": ["from datetime import datetime, timezone\nfrom typing import Dict\nfrom unittest.mock import Mock, patch\n\nimport pandas as pd\nimport pytest\n\nfrom prfiesta.analysis.view import view_pull_requests\n\n_now = datetime.now(timezone.utc)", "\n_now = datetime.now(timezone.utc)\n\n\n@pytest.mark.parametrize(('data', 'options', 'expected'), [\n    pytest.param(\n        pd.DataFrame(data =\n        {\n            'number': [1, 2],\n            'title': ['title', 'title2'],", "            'number': [1, 2],\n            'title': ['title', 'title2'],\n            'repository_name': ['repository', 'repository'],\n            'updated_at': [datetime.now(timezone.utc), datetime.now(timezone.utc)],\n            'html_url': ['url1', 'url2'],\n         }),\n        {'as_frame': True},\n        pd.DataFrame(data={\n            'number': [1, 2],\n            'title': ['<a href=\"url1\">title</a>', '<a href=\"url2\">title2</a>'],", "            'number': [1, 2],\n            'title': ['<a href=\"url1\">title</a>', '<a href=\"url2\">title2</a>'],\n            'repository_name': ['repository']*2,\n            'updated_at': ['just now']*2,\n        }),\n        id='as_frame_with_defaults',\n    ),\n    pytest.param(\n        pd.DataFrame(data =\n        {", "        pd.DataFrame(data =\n        {\n            'number': [1, 2],\n            'title': ['title', 'title2'],\n            'repository_name': ['repository', 'repository'],\n            'updated_at': [_now, _now],\n            'html_url': ['url1', 'url2'],\n         }),\n        {'as_frame': True, 'relative_dates': False},\n        pd.DataFrame(data={", "        {'as_frame': True, 'relative_dates': False},\n        pd.DataFrame(data={\n            'number': [1, 2],\n            'title': ['<a href=\"url1\">title</a>', '<a href=\"url2\">title2</a>'],\n            'repository_name': ['repository']*2,\n            'updated_at': [_now, _now],\n        }),\n        id='as_frame_with_no_relative_dates',\n    ),\n    pytest.param(", "    ),\n    pytest.param(\n        pd.DataFrame(data =\n        {\n            'number': [1, 2],\n            'title': ['title', 'title2'],\n            'repository_name': ['repository', 'repository'],\n            'updated_at': [datetime.now(timezone.utc), datetime.now(timezone.utc)],\n            'html_url': ['url1', 'url2'],\n         }),", "            'html_url': ['url1', 'url2'],\n         }),\n        {'as_frame': True, 'head': 1},\n        pd.DataFrame(data={\n            'number': [1],\n            'title': ['<a href=\"url1\">title</a>'],\n            'repository_name': ['repository'],\n            'updated_at': ['just now'],\n        }),\n        id='as_frame_with_head',", "        }),\n        id='as_frame_with_head',\n    ),\n    pytest.param(\n        pd.DataFrame(data =\n        {\n            'number': [1, 2],\n            'title': ['title', 'title2'],\n            'repository_name': ['repository', 'repository'],\n            'updated_at': [datetime.now(timezone.utc), datetime.now(timezone.utc)],", "            'repository_name': ['repository', 'repository'],\n            'updated_at': [datetime.now(timezone.utc), datetime.now(timezone.utc)],\n            'html_url': ['url1', 'url2'],\n         }),\n        {},\n        pd.DataFrame(data={\n            'number': [1, 2],\n            'title': ['<a href=\"url1\">title</a>', '<a href=\"url2\">title2</a>'],\n            'repository_name': ['repository']*2,\n            'updated_at': ['just now']*2,", "            'repository_name': ['repository']*2,\n            'updated_at': ['just now']*2,\n        }),\n        id='html_default',\n    ),\n    pytest.param(\n        pd.DataFrame(data =\n        {\n            'number': [1, 2],\n            'title': ['title', 'title2'],", "            'number': [1, 2],\n            'title': ['title', 'title2'],\n            'repository_name': ['repository', 'repository'],\n            'updated_at': [datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S%z'), datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S%z')],\n            'html_url': ['url1', 'url2'],\n         }),\n        {'as_frame': True},\n        pd.DataFrame(data={\n            'number': [1, 2],\n            'title': ['<a href=\"url1\">title</a>', '<a href=\"url2\">title2</a>'],", "            'number': [1, 2],\n            'title': ['<a href=\"url1\">title</a>', '<a href=\"url2\">title2</a>'],\n            'repository_name': ['repository']*2,\n            'updated_at': ['just now']*2,\n        }),\n        id='string_datetime',\n    ),\n])\n@patch('prfiesta.analysis.view.HTML')\ndef test_view_pull_request(\n        mock_html: Mock,\n        data: pd.DataFrame,\n        options: Dict,\n        expected: pd.DataFrame) -> None:\n\n    mock_html.return_value = 'DUMMY'\n\n    result = view_pull_requests(data, **options)\n\n    if 'as_frame' in options and options['as_frame']:\n        pd.testing.assert_frame_equal(expected, result)\n    else:\n        assert mock_html.called\n        assert result == mock_html.return_value", "@patch('prfiesta.analysis.view.HTML')\ndef test_view_pull_request(\n        mock_html: Mock,\n        data: pd.DataFrame,\n        options: Dict,\n        expected: pd.DataFrame) -> None:\n\n    mock_html.return_value = 'DUMMY'\n\n    result = view_pull_requests(data, **options)\n\n    if 'as_frame' in options and options['as_frame']:\n        pd.testing.assert_frame_equal(expected, result)\n    else:\n        assert mock_html.called\n        assert result == mock_html.return_value", ""]}
{"filename": "tests/analysis/__init__.py", "chunked_list": [""]}
{"filename": "tests/analysis/test_plot.py", "chunked_list": ["from datetime import datetime\nfrom typing import Dict\nfrom unittest.mock import ANY, Mock, call, patch\n\nimport pandas as pd\nimport pytest\n\nfrom prfiesta.analysis.plot import (\n    _months,\n    plot_author_associations,", "    _months,\n    plot_author_associations,\n    plot_conventional_commit_breakdown,\n    plot_overall_timeline,\n    plot_reactions,\n    plot_state_distribution,\n)\n\n_mock_state_distribution_axis = Mock()\n_mock_overall_timeline_axis = Mock()", "_mock_state_distribution_axis = Mock()\n_mock_overall_timeline_axis = Mock()\n_mock_author_association_axis = Mock()\n_mock_conventional_commit_axis = Mock()\n_mock_reaction_commit_axis = Mock()\n\n\n@pytest.mark.parametrize(('options', 'expected_options'), [\n    pytest.param(\n        {},", "    pytest.param(\n        {},\n        { 'x': 'state', 'hue': 'repository_name', 'ax': None, 'palette': None },\n        id='default'),\n    pytest.param(\n        {'ax': _mock_state_distribution_axis},\n        { 'x': 'state', 'hue': 'repository_name', 'ax': _mock_state_distribution_axis, 'palette': None },\n        id='with_custom_axis'),\n    pytest.param(\n        {'hue': 'user.login'},", "    pytest.param(\n        {'hue': 'user.login'},\n        { 'x': 'state', 'hue': 'user.login', 'ax': None, 'palette': None },\n        id='with_custom_hue'),\n    pytest.param(\n        {'palette': 'tab10'},\n        { 'x': 'state', 'hue': 'repository_name', 'ax': None, 'palette': 'tab10' },\n        id='with_custom_hue'),\n    pytest.param(\n        {'ax': _mock_state_distribution_axis, 'title': 'my_title'},", "    pytest.param(\n        {'ax': _mock_state_distribution_axis, 'title': 'my_title'},\n        { 'x': 'state', 'hue': 'repository_name', 'ax': _mock_state_distribution_axis, 'palette': None },\n        id='with_custom_title'),\n])\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_state_distribution(mock_seaborn: Mock, options: Dict, expected_options: Dict) -> None:\n\n    data = pd.DataFrame(data={\n        'state': ['opened', 'closed'],\n        'repository_name': ['repo', 'repo2'],\n        'user.login': ['user', 'user2'],\n    })\n\n    mock_histplot = Mock()\n    mock_seaborn.histplot.return_value = mock_histplot\n\n    result = plot_state_distribution(data, **options)\n\n    if ('title' in options) and (options['title']):\n        assert _mock_state_distribution_axis.set_title.call_args_list == [call(options['title'])]\n\n    assert mock_histplot == result\n    assert mock_seaborn.histplot.call_args_list == [call(data, **expected_options)]\n\n    _mock_state_distribution_axis.reset_mock()", "\n\n@pytest.mark.parametrize(('options', 'expected_options'), [\n   pytest.param(\n        {},\n        {'x':'year', 'y':'id', 'hue':'month', 'ax': None, 'order':['2021', '2022'], 'hue_order':_months, 'palette':None},\n        id='default',\n    ),\n   pytest.param(\n        {'ax': _mock_overall_timeline_axis },", "   pytest.param(\n        {'ax': _mock_overall_timeline_axis },\n        {'x':'year', 'y':'id', 'hue':'month', 'ax': _mock_overall_timeline_axis, 'order':['2021', '2022'], 'hue_order':_months, 'palette':None},\n        id='with_custom_axis',\n    ),\n   pytest.param(\n        {'palette': 'tab10'},\n        {'x':'year', 'y':'id', 'hue':'month', 'ax': None, 'order':['2021', '2022'], 'hue_order':_months, 'palette':'tab10'},\n        id='with_custom_pallete',\n    ),", "        id='with_custom_pallete',\n    ),\n   pytest.param(\n        { 'ax': _mock_overall_timeline_axis, 'title': 'my_title'},\n        {'x':'year', 'y':'id', 'hue':'month', 'ax': _mock_overall_timeline_axis, 'order':['2021', '2022'], 'hue_order':_months, 'palette':None},\n        id='with_custom_title',\n    ),\n   pytest.param(\n        {'hue': 'custom_field'},\n        {'x':'year', 'y':'id', 'hue':'custom_field', 'ax': None, 'order':['2021', '2022'], 'hue_order':_months, 'palette':None},", "        {'hue': 'custom_field'},\n        {'x':'year', 'y':'id', 'hue':'custom_field', 'ax': None, 'order':['2021', '2022'], 'hue_order':_months, 'palette':None},\n        id='with_custom_hue',\n    ),\n])\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_overall_timeline(mock_seaborn: Mock, options: Dict, expected_options: Dict) -> None:\n\n    mock_barplot = Mock()\n    mock_seaborn.barplot.return_value = mock_barplot\n\n    data = pd.DataFrame(data={\n        'created_at': [datetime(2021, 1, 1), datetime(2021, 2, 1), datetime(2022, 4, 14)],\n        'id': ['id1', 'id2', 'id3'],\n    })\n\n    result = plot_overall_timeline(data, **options)\n\n    assert mock_barplot == result\n    assert mock_seaborn.barplot.call_args_list == [call(ANY, **expected_options)]\n\n    if ('title' in options) and (options['title']):\n        assert _mock_overall_timeline_axis.set_title.call_args_list == [call(options['title'])]\n\n    _mock_overall_timeline_axis.reset_mock()", "\n\n@pytest.mark.parametrize(('options', 'expected_options'), [\n   pytest.param(\n        {},\n        {'ax': None, 'title': 'Author Associations', 'legend': True, 'colormap': None},\n        id='default',\n    ),\n   pytest.param(\n        {'ax': _mock_author_association_axis},", "   pytest.param(\n        {'ax': _mock_author_association_axis},\n        {'ax': _mock_author_association_axis, 'title': 'Author Associations', 'legend': True, 'colormap': None},\n        id='with_custom_axis',\n    ),\n   pytest.param(\n        {'title': 'my_custom_title'},\n        {'ax': None, 'title': 'my_custom_title', 'legend': True, 'colormap': None},\n        id='with_custom_title',\n    ),", "        id='with_custom_title',\n    ),\n   pytest.param(\n        {'palette': 'my_colors'},\n        {'ax': None, 'title': 'Author Associations', 'legend': True, 'colormap': 'my_colors'},\n        id='with_custom_pallete',\n    ),\n])\ndef test_plot_author_associations(options: Dict, expected_options: Dict) -> None:\n\n    agg_mock = Mock()\n\n    data = Mock()\n    data.groupby = Mock(return_value = {'id': Mock()})\n    data.groupby.return_value['id'] = agg_mock\n\n    plot_author_associations(data, **options)\n\n    assert data.groupby.called\n    assert agg_mock.count.called\n    assert agg_mock.count.return_value.plot.pie.call_args_list == [call(**expected_options)]", "def test_plot_author_associations(options: Dict, expected_options: Dict) -> None:\n\n    agg_mock = Mock()\n\n    data = Mock()\n    data.groupby = Mock(return_value = {'id': Mock()})\n    data.groupby.return_value['id'] = agg_mock\n\n    plot_author_associations(data, **options)\n\n    assert data.groupby.called\n    assert agg_mock.count.called\n    assert agg_mock.count.return_value.plot.pie.call_args_list == [call(**expected_options)]", "\n\n@pytest.mark.parametrize(('data', 'options', 'expected_options'),[\n   pytest.param(\n        pd.DataFrame({\n            'title': ['feat(hello): my change', 'fix: my other change'],\n            'repository_name': ['repo1', 'repo2'],\n        }),\n        {},\n        {'y': 'repository_name', 'x': 'count', 'hue': 'type', 'ax': None, 'palette': None},", "        {},\n        {'y': 'repository_name', 'x': 'count', 'hue': 'type', 'ax': None, 'palette': None},\n        id='default',\n    ),\n   pytest.param(\n        pd.DataFrame({\n            'title': ['refactor(hello): my change', 'chore: my other change'],\n            'repository_name': ['repo1', 'repo2'],\n        }),\n        {'ax': _mock_conventional_commit_axis},", "        }),\n        {'ax': _mock_conventional_commit_axis},\n        {'y': 'repository_name', 'x': 'count', 'hue': 'type', 'ax': _mock_conventional_commit_axis, 'palette': None},\n        id='with_custom_axis',\n    ),\n   pytest.param(\n        pd.DataFrame({\n            'title': ['docs(hello): my change', 'style: my other change'],\n            'repository_name': ['repo1', 'repo2'],\n        }),", "            'repository_name': ['repo1', 'repo2'],\n        }),\n        {'palette': 'my_colors'},\n        {'y': 'repository_name', 'x': 'count', 'hue': 'type', 'ax': None, 'palette': 'my_colors'},\n        id='with_custom_pallete',\n    ),\n   pytest.param(\n        pd.DataFrame({\n            'title': ['feat(hello): my change', 'fix: my other change'],\n            'repository_name': ['repo1', 'repo2'],", "            'title': ['feat(hello): my change', 'fix: my other change'],\n            'repository_name': ['repo1', 'repo2'],\n        }),\n        {'ax': _mock_conventional_commit_axis, 'title': 'my_title'},\n        {'y': 'repository_name', 'x': 'count', 'hue': 'type', 'ax': _mock_conventional_commit_axis, 'palette': None},\n        id='with_custom_title',\n    ),\n   pytest.param(\n        pd.DataFrame({\n            'title': ['feat(hello): my change', 'fix: my other change'],", "        pd.DataFrame({\n            'title': ['feat(hello): my change', 'fix: my other change'],\n            'repository_name': ['repo1', 'repo2'],\n        }),\n        {'hue': 'my_field'},\n        {'y': 'repository_name', 'x': 'count', 'hue': 'my_field', 'ax': None, 'palette': None},\n        id='with_custom_hue',\n    ),\n])\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_conventional_commit_breakdown(mock_seaborn: Mock, data: pd.DataFrame, options: Dict, expected_options: Dict) -> None:\n\n    mock_barplot = Mock()\n    mock_seaborn.barplot.return_value = mock_barplot\n\n    result = plot_conventional_commit_breakdown(data, **options)\n\n    assert mock_barplot == result\n    assert mock_seaborn.barplot.call_args_list == [call(ANY, **expected_options)]\n\n    if ('title' in options) and (options['title']):\n        assert _mock_conventional_commit_axis.set_title.call_args_list == [call(options['title'])]\n\n    _mock_conventional_commit_axis.reset_mock()", "])\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_conventional_commit_breakdown(mock_seaborn: Mock, data: pd.DataFrame, options: Dict, expected_options: Dict) -> None:\n\n    mock_barplot = Mock()\n    mock_seaborn.barplot.return_value = mock_barplot\n\n    result = plot_conventional_commit_breakdown(data, **options)\n\n    assert mock_barplot == result\n    assert mock_seaborn.barplot.call_args_list == [call(ANY, **expected_options)]\n\n    if ('title' in options) and (options['title']):\n        assert _mock_conventional_commit_axis.set_title.call_args_list == [call(options['title'])]\n\n    _mock_conventional_commit_axis.reset_mock()", "\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_conventional_commit_breakdown_no_valid_commits(mock_seaborn: Mock) -> None:\n\n    mock_seaborn.barplot.return_value = Mock()\n\n    data = pd.DataFrame({\n            'title': ['my change', 'fixed a thing'],\n            'repository_name': ['repo1', 'repo2'],\n    })\n\n    options = {}\n\n    assert not plot_conventional_commit_breakdown(data, **options)\n    assert not mock_seaborn.called\n    assert not mock_seaborn.barplot.called", "\n\n@pytest.mark.parametrize(('data', 'options', 'expected_options'), [\n    pytest.param(\n        pd.DataFrame(data={\n            'reactions.total_count': [1, 0, 1],\n            'reactions.+1': [1, 0, 1],\n            'reactions.-1': [0, 0, 1],\n            'reactions.laugh': [1, 1, 1],\n            'reactions.hooray': [1, 0, 0],", "            'reactions.laugh': [1, 1, 1],\n            'reactions.hooray': [1, 0, 0],\n            'reactions.confused': [0, 0, 1],\n        }),\n        {},\n        {'ax': None, 'palette': None, 'hue': None },\n        id='default',\n    ),\n    pytest.param(\n        pd.DataFrame(data={", "    pytest.param(\n        pd.DataFrame(data={\n            'reactions.total_count': [1, 0, 1],\n            'reactions.+1': [1, 0, 1],\n            'reactions.-1': [0, 0, 1],\n            'reactions.laugh': [1, 1, 1],\n            'reactions.hooray': [1, 0, 0],\n            'reactions.confused': [0, 0, 1],\n        }),\n        {'ax': _mock_reaction_commit_axis},", "        }),\n        {'ax': _mock_reaction_commit_axis},\n        {'ax': _mock_reaction_commit_axis, 'palette': None, 'hue': None },\n        id='with_custom_axis',\n    ),\n    pytest.param(\n        pd.DataFrame(data={\n            'reactions.total_count': [1, 0, 1],\n            'reactions.+1': [1, 0, 1],\n            'reactions.-1': [0, 0, 1],", "            'reactions.+1': [1, 0, 1],\n            'reactions.-1': [0, 0, 1],\n            'reactions.laugh': [1, 1, 1],\n            'reactions.hooray': [1, 0, 0],\n            'reactions.confused': [0, 0, 1],\n        }),\n        {'palette': 'tab10'},\n        {'ax': None, 'palette': 'tab10', 'hue': None },\n        id='with_custom_pallete',\n    ),", "        id='with_custom_pallete',\n    ),\n    pytest.param(\n        pd.DataFrame(data={\n            'reactions.total_count': [1, 0, 1],\n            'reactions.+1': [1, 0, 1],\n            'reactions.-1': [0, 0, 1],\n            'reactions.laugh': [1, 1, 1],\n            'reactions.hooray': [1, 0, 0],\n            'reactions.confused': [0, 0, 1],", "            'reactions.hooray': [1, 0, 0],\n            'reactions.confused': [0, 0, 1],\n        }),\n        {'hue': 'custom'},\n        {'ax': None, 'palette': None, 'hue': 'custom' },\n        id='with_custom_hue',\n    ),\n\n])\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_reactions(mock_seaborn: Mock, data: pd.DataFrame, options: Dict, expected_options: Dict) -> None:\n\n    mock_scatter = Mock()\n    mock_seaborn.scatterplot.return_value = mock_scatter\n\n    result = plot_reactions(data, **options)\n\n    expected_df = data[data['reactions.total_count'] > 0].copy()\n    expected_df = expected_df.drop(columns='reactions.total_count')\n\n    assert mock_scatter == result\n    assert mock_seaborn.scatterplot.call_args_list == [call(ANY, **expected_options)]\n\n    pd.testing.assert_frame_equal(expected_df, mock_seaborn.scatterplot.call_args_list[0][0][0])", "])\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_reactions(mock_seaborn: Mock, data: pd.DataFrame, options: Dict, expected_options: Dict) -> None:\n\n    mock_scatter = Mock()\n    mock_seaborn.scatterplot.return_value = mock_scatter\n\n    result = plot_reactions(data, **options)\n\n    expected_df = data[data['reactions.total_count'] > 0].copy()\n    expected_df = expected_df.drop(columns='reactions.total_count')\n\n    assert mock_scatter == result\n    assert mock_seaborn.scatterplot.call_args_list == [call(ANY, **expected_options)]\n\n    pd.testing.assert_frame_equal(expected_df, mock_seaborn.scatterplot.call_args_list[0][0][0])", "\n\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_reaction_no_reactions(mock_seaborn: Mock) -> None:\n\n    data = pd.DataFrame(data={\n        'reactions.total_count': [0, 0, 0],\n        'reactions.+1': [0, 0, 0],\n        'reactions.-1': [0, 0, 0],\n        'reactions.laugh': [0, 0, 0],\n        'reactions.hooray': [0, 0, 0],\n        'reactions.confused': [0, 0, 0],\n    })\n\n    assert not plot_reactions(data)\n    assert not mock_seaborn.scatterplot.called", "\n\n@patch('prfiesta.analysis.plot.sns')\ndef test_plot_reaction_threshold(mock_seaborn: Mock) -> None:\n\n    threshold = 15\n\n    data = pd.DataFrame(data={\n        'reactions.total_count': [1, 1, 1],\n        'reactions.+1': [threshold*3, 2, 2],\n        'reactions.-1': [1, 1, 1],\n        'reactions.laugh': [0, 0, threshold*2],\n        'reactions.hooray': [0, 0, 0],\n        'reactions.confused': [0, 0, 0],\n    })\n\n    plot_reactions(data, threshold=threshold)\n\n    expected_df = data.copy()\n    expected_df = expected_df[expected_df < threshold]\n    expected_df = expected_df.drop(columns=['reactions.total_count'])\n\n    pd.testing.assert_frame_equal(expected_df, mock_seaborn.scatterplot.call_args_list[0][0][0])", ""]}
