{"filename": "classes/__init__.py", "chunked_list": ["import urllib.parse\nimport json\n\nclass Response:\n    '''A response object'''\n    \n    def __init__(self, body, statuscode=200, contenttype='application/json'):\n        self.body = body\n        self.statuscode = statuscode\n        self.contenttype = contenttype", "\nclass STATError(Exception):\n    '''A handled STAT exception'''\n\n    def __init__(self, error:str, source_error:dict={}, status_code:int=400):\n        self.error = error\n        self.source_error = source_error\n        self.status_code = status_code\n\nclass STATNotFound(STATError):\n    '''A handled STAT exception where the API call returned a 404 error'''\n    pass", "\nclass STATNotFound(STATError):\n    '''A handled STAT exception where the API call returned a 404 error'''\n    pass\n\nclass BaseModule:\n    '''A base module object'''\n    \n    def __init__(self):\n        self.Accounts = []\n        self.AccountsCount = 0\n        self.Alerts = []\n        self.Domains = []\n        self.DomainsCount = 0\n        self.EntitiesCount = 0\n        self.FileHashes = []\n        self.FileHashesCount = 0\n        self.Files = []\n        self.FilesCount = 0\n        self.Hosts = []\n        self.HostsCount = 0\n        self.IPs = []\n        self.IPsCount = 0\n        self.IncidentARMId = \"\"\n        self.IncidentTriggered = False\n        self.IncidentAvailable = False\n        self.ModuleVersions = {}\n        self.MultiTenantConfig = {}\n        self.OtherEntities = []\n        self.OtherEntitiesCount = 0\n        self.RelatedAnalyticRuleIds = []\n        self.SentinelRGARMId = \"\"\n        self.TenantDisplayName = \"\"\n        self.TenantId = \"\"\n        self.URLs = []\n        self.URLsCount = 0\n        self.WorkspaceARMId = \"\"\n        self.WorkspaceId = \"\"\n\n    def load_incident_trigger(self, req_body):\n        \n        self.IncidentARMId = req_body['object']['id']\n        self.IncidentTriggered = True\n        self.IncidentAvailable = True\n        self.SentinelRGARMId = \"/subscriptions/\" + req_body['workspaceInfo']['SubscriptionId'] + \"/resourceGroups/\" + req_body['workspaceInfo']['ResourceGroupName']\n        self.WorkspaceARMId = self.SentinelRGARMId + \"/providers/Microsoft.OperationalInsights/workspaces/\" + req_body['workspaceInfo']['WorkspaceName']\n        self.WorkspaceId = req_body['workspaceId']\n        self.RelatedAnalyticRuleIds = req_body['object']['properties'].get('relatedAnalyticRuleIds', [])\n        self.Alerts = req_body['object']['properties'].get('alerts', [])\n\n    def load_alert_trigger(self, req_body):\n        self.IncidentTriggered = False\n        self.SentinelRGARMId = \"/subscriptions/\" + req_body['WorkspaceSubscriptionId'] + \"/resourceGroups/\" + req_body['WorkspaceResourceGroup']\n        self.WorkspaceId = req_body['WorkspaceId']\n\n    def load_from_input(self, basebody):\n        self.Accounts = basebody['Accounts']\n        self.AccountsCount = basebody['AccountsCount']\n        self.Alerts = basebody.get('Alerts', [])\n        self.Domains = basebody['Domains']\n        self.DomainsCount = basebody['DomainsCount']\n        self.EntitiesCount = basebody['EntitiesCount']\n        self.FileHashes = basebody['FileHashes']\n        self.FileHashesCount = basebody['FileHashesCount']\n        self.Files = basebody['Files']\n        self.FilesCount = basebody['FilesCount']\n        self.Hosts = basebody['Hosts']\n        self.HostsCount = basebody['HostsCount']\n        self.IPs = basebody['IPs']\n        self.IPsCount = basebody['IPsCount']\n        self.IncidentTriggered = basebody['IncidentTriggered']\n        self.IncidentAvailable = basebody['IncidentAvailable']\n        self.IncidentARMId = basebody['IncidentARMId']\n        self.ModuleVersions = basebody['ModuleVersions']\n        self.MultiTenantConfig = basebody.get('MultiTenantConfig', {})\n        self.OtherEntities = basebody['OtherEntities']\n        self.OtherEntitiesCount = basebody['OtherEntitiesCount']\n        self.RelatedAnalyticRuleIds = basebody.get('RelatedAnalyticRuleIds', [])\n        self.SentinelRGARMId = basebody['SentinelRGARMId']\n        self.TenantDisplayName = basebody['TenantDisplayName']\n        self.TenantId = basebody['TenantId']\n        self.URLs = basebody['URLs']\n        self.URLsCount = basebody['URLsCount']\n        self.WorkspaceARMId = basebody['WorkspaceARMId']\n        self.WorkspaceId = basebody['WorkspaceId']\n\n    def add_ip_entity(self, address, geo_data, rawentity):\n        self.IPs.append({'Address': address, 'GeoData': geo_data, 'RawEntity': rawentity })\n\n    def add_host_entity(self, fqdn, hostname, dnsdomain, mdedeviceid, rawentity):\n        if mdedeviceid:\n            self.Hosts.append({'DnsDomain': dnsdomain, 'FQDN': fqdn, 'Hostname': hostname, 'MdatpDeviceId': mdedeviceid, 'RawEntity': rawentity })\n        else:\n            self.Hosts.append({'DnsDomain': dnsdomain, 'FQDN': fqdn, 'Hostname': hostname, 'RawEntity': rawentity })\n\n    def add_account_entity(self, data):\n        self.Accounts.append(data)\n\n    def get_ip_list(self):\n        ip_list = []\n        for ip in self.IPs:\n            ip_list.append(ip['Address'])\n\n        return ip_list\n    \n    def get_domain_list(self):\n        domain_list = []\n        for domain in self.Domains:\n            domain_list.append(domain['Domain'])\n        \n        return domain_list\n    \n    def get_url_list(self):\n        url_list = []\n        for url in self.URLs:\n            url_list.append(url['Url'])\n        \n        return url_list\n    \n    def get_filehash_list(self):\n        hash_list = []\n        for hash in self.FileHashes:\n            hash_list.append(hash['FileHash'])\n        \n        return hash_list\n    \n    def get_ip_kql_table(self):\n\n        ip_data = []\n\n        for ip in self.IPs:\n            ip_data.append({'Address': ip.get('Address'), 'Latitude': ip.get('GeoData').get('latitude'), 'Longitude': ip.get('GeoData').get('longitude'), \\\n                            'Country': ip.get('GeoData').get('country'), 'State': ip.get('GeoData').get('state')})\n\n        encoded = urllib.parse.quote(json.dumps(ip_data))\n\n        kql = f'''let ipEntities = print t = todynamic(url_decode('{encoded}'))\n| mv-expand t\n| project IPAddress=tostring(t.Address), Latitude=toreal(t.Latitude), Longitude=toreal(t.Longitude), Country=tostring(t.Country), State=tostring(t.State);\n'''\n        return kql\n    \n    def get_account_kql_table(self):\n\n        account_data = []\n\n        for account in self.Accounts:\n            account_data.append({'userPrincipalName': account.get('userPrincipalName'), 'SamAccountName': account.get('onPremisesSamAccountName'), \\\n                                 'SID': account.get('onPremisesSecurityIdentifier'), 'id': account.get('id'), 'ManagerUPN': account.get('manager', {}).get('userPrincipalName')})\n\n        encoded = urllib.parse.quote(json.dumps(account_data))\n\n        kql = f'''let accountEntities = print t = todynamic(url_decode('{encoded}'))\n| mv-expand t\n| project UserPrincipalName=tostring(t.userPrincipalName), SamAccountName=tostring(t.SamAccountName), ObjectSID=tostring(t.SID), AADUserId=tostring(t.id), ManagerUPN=tostring(t.ManagerUPN);\n'''\n        return kql\n    \n    def get_host_kql_table(self):\n\n        host_data = []\n\n        for host in self.Hosts:\n            host_data.append({'FQDN': host.get('FQDN'), 'Hostname': host.get('Hostname')})\n\n        encoded = urllib.parse.quote(json.dumps(host_data))\n\n        kql = f'''let hostEntities = print t = todynamic(url_decode('{encoded}'))\n| mv-expand t\n| project FQDN=tostring(t.FQDN), Hostname=tostring(t.Hostname);\n'''\n        return kql\n    \n    def get_url_kql_table(self):\n        url_data = []\n\n        for url in self.URLs:\n            url_data.append({'Url': url.get('Url')})\n\n        encoded = urllib.parse.quote(json.dumps(url_data))\n\n        kql = f'''let urlEntities = print t = todynamic(url_decode('{encoded}'))\n| mv-expand t\n| project Url=tostring(t.Url);\n'''\n        return kql\n\n    def get_filehash_kql_table(self):\n        hash_data = []\n\n        for hash in self.FileHashes:\n            hash_data.append({'FileHash': hash.get('FileHash'), 'Algorithm': hash.get('Algorithm')})\n\n        encoded = urllib.parse.quote(json.dumps(hash_data))\n\n        kql = f'''let hashEntities = print t = todynamic(url_decode('{encoded}'))\n| mv-expand t\n| project FileHash=tostring(t.FileHash), Algorithm=tostring(t.Algorithm);\n'''\n        return kql\n\n    def get_domain_kql_table(self):\n        \n        domain_data = []\n\n        for domain in self.Domains:\n            domain_data.append({'Domain': domain.get('Domain')})\n\n        encoded = urllib.parse.quote(json.dumps(domain_data))\n\n        kql = f'''let domainEntities = print t = todynamic(url_decode('{encoded}'))\n| mv-expand t\n| project Domain=tostring(t.Domain);\n'''\n        return kql\n        \n    def get_account_id_list(self):\n        account_list = []\n        for account in self.Accounts:\n            account_list.append(account['id'])\n        \n        return account_list\n\n    def get_account_upn_list(self):\n        account_list = []\n        for account in self.Accounts:\n            account_list.append(account['userPrincipalName'])\n        \n        return account_list\n    \n    def get_account_sam_list(self):\n        account_list = []\n        for account in self.Accounts:\n            account_list.append(account['onPremisesSamAccountName'])\n\n        return account_list\n    \n    def get_alert_ids(self):\n        alert_list = []\n        for alert in self.Alerts:\n            alert_id = alert.get('properties', {}).get('systemAlertId')\n            if alert_id:\n                alert_list.append(alert_id)\n        \n        return alert_list\n    \n    def get_alert_tactics(self):\n        tactics_list = []\n        for alert in self.Alerts:\n            tactics_list = tactics_list + alert['properties']['tactics']\n\n        return list(set(tactics_list))", "\nclass KQLModule:\n    '''A KQL module object'''\n    \n    def __init__(self):\n        self.DetailedResults = []\n        self.ModuleName = 'KQLModule'\n        self.ResultsCount = 0\n        self.ResultsFound = False\n\n    def load_from_input(self, body):\n        self.DetailedResults = body['DetailedResults']\n        self.ResultsCount = body['ResultsCount']\n        self.ResultsFound = body['ResultsFound']", "\nclass WatchlistModule:\n    '''A Watchlist module object'''\n    \n    def __init__(self):\n        self.DetailedResults = []\n        self.EntitiesAnalyzedCount = 0\n        self.EntitiesOnWatchlist = False\n        self.EntitiesOnWatchlistCount = 0\n        self.WatchlistName = \"\"\n        self.ModuleName = 'WatchlistModule'\n\n    def load_from_input(self, body):\n        self.DetailedResults = body['DetailedResults']\n        self.EntitiesAnalyzedCount = body['EntitiesAnalyzedCount']\n        self.EntitiesOnWatchlist = body['EntitiesOnWatchlist']\n        self.EntitiesOnWatchlistCount = body['EntitiesOnWatchlistCount']\n        self.WatchlistName = body['WatchlistName']", "\nclass TIModule:\n    '''A Threat Intelligence module object'''\n\n    def __init__(self):\n        self.AnyTIFound = False\n        self.DetailedResults = []\n        self.DomainEntitiesCount = 0\n        self.DomainEntitiesWithTI = 0\n        self.DomainTIFound = False\n        self.FileHashEntitiesCount = 0\n        self.FileHashEntitiesWithTI = 0\n        self.FileHashTIFound = False\n        self.IPEntitiesCount = 0\n        self.IPEntitiesWithTI = 0\n        self.IPTIFound = False\n        self.ModuleName = 'TIModule'\n        self.TotalTIMatchCount = 0\n        self.URLEntitiesCount = 0\n        self.URLEntitiesWithTI = 0\n        self.URLTIFound = False\n\n    def load_from_input(self, body):\n        self.AnyTIFound = body['AnyTIFound']\n        self.DetailedResults = body['DetailedResults']\n        self.DomainEntitiesCount = body['DomainEntitiesCount']\n        self.DomainEntitiesWithTI = body['DomainEntitiesWithTI']\n        self.DomainTIFound = body['DomainTIFound']\n        self.FileHashEntitiesCount = body['FileHashEntitiesCount']\n        self.FileHashEntitiesWithTI = body['FileHashEntitiesWithTI']\n        self.FileHashTIFound = body['FileHashTIFound']\n        self.IPEntitiesCount = body['IPEntitiesCount']\n        self.IPEntitiesWithTI = body['IPEntitiesWithTI']\n        self.IPTIFound = body['IPTIFound']\n        self.TotalTIMatchCount = body['TotalTIMatchCount']\n        self.URLEntitiesCount = body['URLEntitiesCount']\n        self.URLEntitiesWithTI = body['URLEntitiesWithTI']\n        self.URLTIFound = body['URLTIFound']       ", "\nclass RelatedAlertsModule:\n    '''A Related Alerts module object'''\n\n    def __init__(self):\n        self.AllTactics =  []\n        self.AllTacticsCount = 0\n        self.DetailedResults = []\n        self.FusionIncident = False\n        self.HighestSeverityAlert = ''\n        self.ModuleName = 'RelatedAlerts'\n        self.RelatedAccountAlertsCount = 0\n        self.RelatedAccountAlertsFound = False\n        self.RelatedAlertsCount = 0\n        self.RelatedAlertsFound = False\n        self.RelatedHostAlertsCount = 0\n        self.RelatedHostAlertsFound = False\n        self.RelatedIPAlertsCount = 0\n        self.RelatedIPAlertsFound = False\n\n    def load_from_input(self, body):\n        self.AllTactics =  body['AllTactics']\n        self.AllTacticsCount = body['AllTacticsCount']\n        self.DetailedResults = body['DetailedResults']\n        self.FusionIncident = body['FusionIncident']\n        self.HighestSeverityAlert = body['HighestSeverityAlert']\n        self.RelatedAccountAlertsCount = body['RelatedAccountAlertsCount']\n        self.RelatedAccountAlertsFound = body['RelatedAccountAlertsFound']\n        self.RelatedAlertsCount = body['RelatedAlertsCount']\n        self.RelatedAlertsFound = body['RelatedAlertsFound']\n        self.RelatedHostAlertsCount = body['RelatedHostAlertsCount']\n        self.RelatedHostAlertsFound = body['RelatedHostAlertsFound']\n        self.RelatedIPAlertsCount = body['RelatedIPAlertsCount']\n        self.RelatedIPAlertsFound = body['RelatedIPAlertsFound']", "\nclass UEBAModule:\n    '''A UEBA module object'''\n    \n    def __init__(self):\n        self.AllEntityEventCount = 0\n        self.AllEntityInvestigationPriorityAverage = float(0)\n        self.AllEntityInvestigationPriorityMax = 0\n        self.AllEntityInvestigationPrioritySum = 0\n        self.AnomaliesFound = False\n        self.AnomalyCount = 0\n        self.AnomalyTactics = []\n        self.AnomalyTacticsCount = 0\n        self.DetailedResults = []\n        self.InvestigationPrioritiesFound = False\n        self.ModuleName = 'UEBAModule'\n        self.ThreatIntelFound = False\n        self.ThreatIntelMatchCount = 0\n\n    def load_from_input(self, body):\n        self.AllEntityEventCount = body['AllEntityEventCount']\n        self.AllEntityInvestigationPriorityAverage = body['AllEntityInvestigationPriorityAverage']\n        self.AllEntityInvestigationPriorityMax = body['AllEntityInvestigationPriorityMax']\n        self.AllEntityInvestigationPrioritySum = body['AllEntityInvestigationPrioritySum']\n        self.AnomaliesFound = body['AnomaliesFound']\n        self.AnomalyCount = body['AnomalyCount']\n        self.AnomalyTactics = body['AnomalyTactics']\n        self.AnomalyTacticsCount = body['AnomalyTacticsCount']\n        self.DetailedResults = body['DetailedResults']\n        self.InvestigationPrioritiesFound = body['InvestigationPrioritiesFound']\n        self.ThreatIntelFound = body['ThreatIntelFound']\n        self.ThreatIntelMatchCount = body['ThreatIntelMatchCount']       ", "\nclass ScoringModule:\n    '''A Scoring Module object'''\n    \n    def __init__(self):\n        self.DetailedResults = []\n        self.TotalScore = 0\n\n    def append_score(self, score, label):\n        '''Adds to the TotalScore and DetailedResults list'''\n        self.TotalScore += score\n        self.DetailedResults.append({'Score': score, 'ScoreSource': label})", "\nclass AADModule:\n    '''An AAD Module object'''\n\n    def __init__(self):\n        self.AnalyzedEntities = 0\n        self.FailedMFATotalCount = None\n        self.HighestRiskLevel = ''\n        self.MFAFraudTotalCount = None\n        self.SuspiciousActivityReportTotalCount = None\n        self.ModuleName = 'AADRisksModule'\n        self.DetailedResults = []\n\n    def load_from_input(self, body):\n        self.AnalyzedEntities = body['AnalyzedEntities']\n        self.FailedMFATotalCount = body['FailedMFATotalCount']\n        self.HighestRiskLevel = body['HighestRiskLevel']\n        self.MFAFraudTotalCount = body['MFAFraudTotalCount']\n        self.SuspiciousActivityReportTotalCount = body['SuspiciousActivityReportTotalCount']\n        self.DetailedResults = body['DetailedResults']", "\nclass FileModule:\n    '''A File Module object'''\n    \n    def __init__(self):\n        self.AnalyzedEntities = 0\n        self.DeviceUniqueDeviceTotalCount = 0\n        self.DeviceUniqueFileNameTotalCount = 0\n        self.DeviceFileActionTotalCount = 0\n        self.EntitiesAttachmentCount = 0\n        self.HashesLinkedToThreatCount = 0\n        self.HashesNotMicrosoftSignedCount = 0\n        self.HashesThreatList = []\n        self.MaximumGlobalPrevalence = 0\n        self.MinimumGlobalPrevalence = 0\n        self.ModuleName = 'FileModule'\n        self.DetailedResults = []\n\n    def load_from_input(self, body):\n        self.AnalyzedEntities = body['AnalyzedEntities']\n        self.DeviceUniqueDeviceTotalCount = body['DeviceUniqueDeviceTotalCount']\n        self.DeviceUniqueFileNameTotalCount = body['DeviceUniqueFileNameTotalCount']\n        self.DeviceFileActionTotalCount = body['DeviceFileActionTotalCount']\n        self.EntitiesAttachmentCount = body['EntitiesAttachmentCount']\n        self.HashesLinkedToThreatCount = body['HashesLinkedToThreatCount']\n        self.HashesNotMicrosoftSignedCount = body['HashesNotMicrosoftSignedCount']\n        self.HashesThreatList = body['HashesThreatList']\n        self.MaximumGlobalPrevalence = body['MaximumGlobalPrevalence']\n        self.MinimumGlobalPrevalence = body['MinimumGlobalPrevalence']\n        self.DetailedResults = body['DetailedResults']", "\nclass MDCAModule:\n    '''A Microsoft Defender for Cloud Apps Module object'''\n    \n    def __init__(self):\n        self.AboveThresholdCount = 0\n        self.AnalyzedEntities = 0\n        self.DetailedResults = []\n        self.MaximumScore = 0\n        self.ModuleName = 'MDCAModule'\n\n    def load_from_input(self, body):\n        self.AboveThresholdCount = body['AboveThresholdCount']\n        self.AnalyzedEntities = body['AnalyzedEntities']\n        self.DetailedResults = body['DetailedResults']\n        self.MaximumScore = body['MaximumScore']", "\nclass RunPlaybook:\n    '''A RunPlaybook module object'''\n\n    def __init__(self):\n        self.LogicAppArmId = ''\n        self.TenantId = ''\n        self.PlaybookName = ''\n        self.IncidentArmId = ''\n        \nclass OOFModule:\n    '''An Out of Office module object'''\n    def __init__(self):\n        self.AllUsersInOffice = True\n        self.AllUsersOutOfOffice = False\n        self.DetailedResults = []\n        self.UsersInOffice = 0\n        self.UsersOutOfOffice = 0\n        self.UsersUnknown = 0", "        \nclass OOFModule:\n    '''An Out of Office module object'''\n    def __init__(self):\n        self.AllUsersInOffice = True\n        self.AllUsersOutOfOffice = False\n        self.DetailedResults = []\n        self.UsersInOffice = 0\n        self.UsersOutOfOffice = 0\n        self.UsersUnknown = 0", "\nclass MDEModule:\n    '''An MDE module object'''\n    def __init__(self):\n        self.AnalyzedEntities = 0\n        self.IPsHighestExposureLevel = ''\n        self.IPsHighestRiskScore = ''\n        self.UsersHighestExposureLevel = ''\n        self.UsersHighestRiskScore = ''\n        self.HostsHighestExposureLevel = ''\n        self.HostsHighestRiskScore = ''\n        self.ModuleName = 'MDEModule'\n        self.DetailedResults = {}\n\n    def load_from_input(self, body):\n        self.AnalyzedEntities = body['AnalyzedEntities']\n        self.IPsHighestExposureLevel = body['IPsHighestExposureLevel']\n        self.IPsHighestRiskScore = body['IPsHighestRiskScore']\n        self.UsersHighestExposureLevel = body['UsersHighestExposureLevel']\n        self.UsersHighestRiskScore = body['UsersHighestRiskScore']\n        self.HostsHighestExposureLevel = body['HostsHighestExposureLevel']\n        self.HostsHighestRiskScore = body['HostsHighestRiskScore']\n        self.DetailedResults = body['DetailedResults']", "\nclass CreateIncident:\n    '''A CreateIncident object'''\n    def __init__(self):\n        self.IncidentARMId = ''\n        self.AlertARMId = ''\n        self.Title = ''\n        self.Description = ''\n        self.Severity = ''\n        self.IncidentNumber = 0\n        self.IncidentUrl = ''", ""]}
{"filename": "tests/test_rest.py", "chunked_list": ["from shared import rest\nfrom classes import BaseModule\nimport json, os\nimport requests\n\ndef test_get_endpoint():\n\n    mdca_endpoint = str(rest.get_endpoint('mdca'))\n    if mdca_endpoint.startswith('https://') and mdca_endpoint.endswith('portal.cloudappsecurity.com'):\n        mdca_valid = True\n    else:\n        mdca_valid = False\n\n    assert rest.get_endpoint('msgraph') == 'https://graph.microsoft.com'\n    assert rest.get_endpoint('la') == 'https://api.loganalytics.io'\n    assert rest.get_endpoint('arm') == 'https://management.azure.com'\n    assert rest.get_endpoint('m365') == 'https://api.security.microsoft.com'\n    assert rest.get_endpoint('mde') == 'https://api.securitycenter.microsoft.com'\n    assert mdca_valid == True", "\ndef test_rest_get():\n    result = rest.rest_call_get(get_base_module_object(), 'msgraph', '/v1.0/organization')\n    assert result.status_code == 200\n\ndef test_execute_la_query():\n    result = rest.execute_la_query(get_base_module_object(), 'SigninLogs | take 5', 7)\n    assert len(result) == 5\n\ndef test_execute_m365d_query():\n    result = rest.execute_m365d_query(get_base_module_object(), 'DeviceInfo | take 5')\n    assert len(result) == 5", "\ndef test_execute_m365d_query():\n    result = rest.execute_m365d_query(get_base_module_object(), 'DeviceInfo | take 5')\n    assert len(result) == 5\n\ndef test_execute_mde_query():\n    result = rest.execute_mde_query(get_base_module_object(), 'DeviceInfo | take 5')\n    assert len(result) == 5\n\ndef get_base_module_object():\n    base_module_body = json.loads(requests.get(url=os.getenv('BASEDATA')).content)\n    base_object = BaseModule()\n    base_object.load_from_input(base_module_body)\n    return base_object", "\ndef get_base_module_object():\n    base_module_body = json.loads(requests.get(url=os.getenv('BASEDATA')).content)\n    base_object = BaseModule()\n    base_object.load_from_input(base_module_body)\n    return base_object\n"]}
{"filename": "tests/test_data.py", "chunked_list": ["from shared import data\n\ndef test_return_highest_value():\n\n    highest = data.return_highest_value(list_data(), 'Severity')\n    custom_highest = data.return_highest_value(list_data(), 'Severity', ['Low', 'Unknown'])\n    unknown = data.return_highest_value(list_data(), 'Description')\n\n    assert highest == 'Medium'\n    assert custom_highest == 'Low'\n    assert unknown == 'Unknown'", "\ndef test_sort_list_by_key():\n\n    sort_data_desc = data.sort_list_by_key(list_data(), 'Value', False)\n    sort_data_asc = data.sort_list_by_key(list_data(), 'Value', True)\n\n    assert sort_data_asc[0]['Description'] == 'Lowest'\n    assert sort_data_desc[0]['Description'] == 'Highest'\n\ndef test_max_column_by_key():\n\n    max_data = data.max_column_by_key(list_data(), 'Value')\n\n    assert max_data == 10", "\ndef test_max_column_by_key():\n\n    max_data = data.max_column_by_key(list_data(), 'Value')\n\n    assert max_data == 10\n\ndef test_sum_column_by_key():\n\n    max_data = data.sum_column_by_key(list_data(), 'Value')\n\n    assert max_data == 20", "\ndef test_update_column_values_in_list():\n\n    updated_list = data.update_column_value_in_list(list_data(), 'Description', 'New [col_value] data')\n\n    assert updated_list[0]['Description'] == 'New Value 4 data'\n\ndef test_join_lists():\n\n    merged_data = data.join_lists(list_data(), list_data2(), 'left', 'Description', 'Description', fill_nan=0)\n\n    assert merged_data[0]['MergedData'] == 'merge1'\n    assert merged_data[3].get('MergedData') == 0", "\ndef test_coalesce():\n\n    test_value = data.coalesce(None, None, 'test', 'test2')\n    test_value_none = data.coalesce(None, None, None)\n\n    assert test_value == 'test'\n    assert test_value_none is None\n\ndef test_version_check():\n    assert data.version_check('1.0.0', '1.0.0', 'Major') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.0.0', 'Minor') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.0.0', 'Build') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n\n    assert data.version_check('1.0.0', '1.0.1', 'Major') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.0.1', 'Minor') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.0.1', 'Build') == {'UpdateAvailable': True, 'UpdateType': 'Build'}\n\n    assert data.version_check('1.0.0', '1.1.1', 'Major') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.1.1', 'Minor') == {'UpdateAvailable': True, 'UpdateType': 'Minor'}\n    assert data.version_check('1.0.0', '1.1.1', 'Build') == {'UpdateAvailable': True, 'UpdateType': 'Minor'}\n\n    assert data.version_check('1.0.0', '2.1.1', 'Major') == {'UpdateAvailable': True, 'UpdateType': 'Major'}\n    assert data.version_check('1.0.0', '2.1.1', 'Minor') == {'UpdateAvailable': True, 'UpdateType': 'Major'}\n    assert data.version_check('1.0.0', '2.1.1', 'Build') == {'UpdateAvailable': True, 'UpdateType': 'Major'}\n\n    assert data.version_check('2.0.0', '1.1.1', 'Build') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.2.0', '1.1.1', 'Build') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.1.5', '1.1.1', 'Build') == {'UpdateAvailable': False, 'UpdateType': 'None'}", "\ndef test_version_check():\n    assert data.version_check('1.0.0', '1.0.0', 'Major') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.0.0', 'Minor') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.0.0', 'Build') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n\n    assert data.version_check('1.0.0', '1.0.1', 'Major') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.0.1', 'Minor') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.0.1', 'Build') == {'UpdateAvailable': True, 'UpdateType': 'Build'}\n\n    assert data.version_check('1.0.0', '1.1.1', 'Major') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.0.0', '1.1.1', 'Minor') == {'UpdateAvailable': True, 'UpdateType': 'Minor'}\n    assert data.version_check('1.0.0', '1.1.1', 'Build') == {'UpdateAvailable': True, 'UpdateType': 'Minor'}\n\n    assert data.version_check('1.0.0', '2.1.1', 'Major') == {'UpdateAvailable': True, 'UpdateType': 'Major'}\n    assert data.version_check('1.0.0', '2.1.1', 'Minor') == {'UpdateAvailable': True, 'UpdateType': 'Major'}\n    assert data.version_check('1.0.0', '2.1.1', 'Build') == {'UpdateAvailable': True, 'UpdateType': 'Major'}\n\n    assert data.version_check('2.0.0', '1.1.1', 'Build') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.2.0', '1.1.1', 'Build') == {'UpdateAvailable': False, 'UpdateType': 'None'}\n    assert data.version_check('1.1.5', '1.1.1', 'Build') == {'UpdateAvailable': False, 'UpdateType': 'None'}", "    \n\ndef list_data():\n    test_data = [\n        {\n            'Description': 'Value 4',\n            'Severity': 'low',\n            'Value': 4\n        },\n        {\n            'Description': 'Highest',\n            'Severity': 'MEDIUM',\n            'Value': 10\n        },\n        {\n            'Description': 'Value 5',\n            'Severity': 'informational',\n            'Value': 5\n        },\n        {\n            'Description': 'Lowest',\n            'Severity': 'low',\n            'Value': 1\n        }\n    ]\n    return test_data", "\ndef list_data2():\n    test_data = [\n        {\n            'Description': 'Value 4',\n            'MergedData': 'merge1',\n        },\n        {\n            'Description': 'Highest',\n            'MergedData': 'merge2',\n        }\n    ]\n    return test_data"]}
{"filename": "tests/test_stat.py", "chunked_list": ["from modules import base, relatedalerts, watchlist, kql, ti, ueba, oof, scoring, aadrisks, mdca, mde, file\nfrom classes import Response\nimport json, os, requests\n\n\ndef test_base_module_incident():\n    base_response:Response = base.execute_base_module(get_incident_trigger_data())\n\n    assert base_response.statuscode == 200\n    assert base_response.body.AccountsCount == 2\n    assert len(base_response.body.Accounts) == base_response.body.AccountsCount\n    assert len(base_response.body.Domains) == base_response.body.DomainsCount\n    assert len(base_response.body.FileHashes) == base_response.body.FileHashesCount\n    assert len(base_response.body.Files) == base_response.body.FilesCount\n    assert len(base_response.body.Hosts) == base_response.body.HostsCount\n    assert len(base_response.body.IPs) == base_response.body.IPsCount\n    assert len(base_response.body.URLs) == base_response.body.URLsCount\n    assert len(base_response.body.OtherEntities) == base_response.body.OtherEntitiesCount", "\n\ndef test_base_module_alert():\n    base_response:Response = base.execute_base_module(get_alert_trigger_data())\n\n    assert base_response.statuscode == 200\n    assert len(base_response.body.Accounts) == base_response.body.AccountsCount\n    assert len(base_response.body.Domains) == base_response.body.DomainsCount\n    assert len(base_response.body.FileHashes) == base_response.body.FileHashesCount\n    assert len(base_response.body.Files) == base_response.body.FilesCount\n    assert len(base_response.body.Hosts) == base_response.body.HostsCount\n    assert len(base_response.body.IPs) == base_response.body.IPsCount\n    assert len(base_response.body.URLs) == base_response.body.URLsCount\n    assert len(base_response.body.OtherEntities) == base_response.body.OtherEntitiesCount", "\ndef test_related_alerts():\n    alerts_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'CheckAccountEntityMatches': True,\n        'CheckHostEntityMatches': True,\n        'CheckIPEntityMatches': True,\n        'AlertKQLFilter': None,\n        'IncidentTaskInstructions': \"\",\n        'LookbackInDays': 20,\n        'BaseModuleBody': get_base_module_body(),\n    }\n    alerts_response:Response = relatedalerts.execute_relatedalerts_module(alerts_input)\n\n    assert alerts_response.statuscode == 200\n    assert alerts_response.body.RelatedAlertsFound == True\n    assert alerts_response.body.RelatedAccountAlertsFound == True", "\ndef test_threat_intel():\n    ti_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'IncidentTaskInstructions': '',\n        'BaseModuleBody': get_base_module_body(),\n    }\n    ti_response:Response = ti.execute_ti_module(ti_input)\n\n    assert ti_response.statuscode == 200\n    assert ti_response.body.AnyTIFound == True\n    assert ti_response.body.IPTIFound == True", "\ndef test_watchlist_upn():\n    watchlist_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'WatchlistName': 'VIPUsers',\n        'WatchlistKey': 'SearchKey',\n        'WatchlistKeyDataType': 'UPN',\n        'BaseModuleBody': get_base_module_body()\n    }\n    watchlist_response:Response = watchlist.execute_watchlist_module(watchlist_input)\n\n    assert watchlist_response.statuscode == 200\n    assert watchlist_response.body.EntitiesOnWatchlist == True\n    assert watchlist_response.body.EntitiesOnWatchlistCount == 1", "\ndef test_watchlist_ip():\n    watchlist_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'WatchlistName': 'IPWatchlist',\n        'WatchlistKey': 'SearchKey',\n        'WatchlistKeyDataType': 'IP',\n        'BaseModuleBody': get_base_module_body()\n    }\n    watchlist_response:Response = watchlist.execute_watchlist_module(watchlist_input)\n\n    assert watchlist_response.statuscode == 200\n    assert watchlist_response.body.EntitiesOnWatchlist == True\n    assert watchlist_response.body.EntitiesOnWatchlistCount == 1", "\ndef test_watchlist_cidr():\n    watchlist_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'WatchlistName': 'NetworkAddresses',\n        'WatchlistKey': 'SearchKey',\n        'WatchlistKeyDataType': 'CIDR',\n        'BaseModuleBody': get_base_module_body()\n    }\n    watchlist_response:Response = watchlist.execute_watchlist_module(watchlist_input)\n\n    assert watchlist_response.statuscode == 200\n    assert watchlist_response.body.EntitiesOnWatchlist == True\n    assert watchlist_response.body.EntitiesOnWatchlistCount == 1", "\ndef test_watchlist_fqdn():\n    watchlist_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'WatchlistName': 'HighValueAssets',\n        'WatchlistKey': 'SearchKey',\n        'WatchlistKeyDataType': 'FQDN',\n        'BaseModuleBody': get_base_module_body()\n    }\n    watchlist_response:Response = watchlist.execute_watchlist_module(watchlist_input)\n\n    assert watchlist_response.statuscode == 200\n    assert watchlist_response.body.EntitiesOnWatchlist == True\n    assert watchlist_response.body.EntitiesOnWatchlistCount == 1", "\ndef test_kql_sentinel():\n    kql_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'KQLQuery': 'SigninLogs | take 5 | project UserPrincipalName',\n        'RunQueryAgainst': 'Sentinel',\n        'QueryDescription': 'Test Query',\n        'LookbackInDays': 30,\n        'BaseModuleBody': get_base_module_body()\n    }\n    kql_response:Response = kql.execute_kql_module(kql_input)\n\n    assert kql_response.statuscode == 200\n    assert kql_response.body.ResultsCount == 5", "\ndef test_kql_m365():\n    kql_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'KQLQuery': 'DeviceInfo | take 5 | project DeviceId',\n        'RunQueryAgainst': 'M365',\n        'QueryDescription': 'Test Query',\n        'LookbackInDays': 30,\n        'BaseModuleBody': get_base_module_body()\n    }\n    kql_response:Response = kql.execute_kql_module(kql_input)\n\n    assert kql_response.statuscode == 200\n    assert kql_response.body.ResultsCount == 5", "\ndef test_ueba():\n    ueba_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'MinimumInvestigationPriority': 2,\n        'LookbackInDays': 60,\n        'BaseModuleBody': get_base_module_body()\n    }\n    ueba_response:Response = ueba.execute_ueba_module(ueba_input)\n\n    assert ueba_response.statuscode == 200\n    assert ueba_response.body.InvestigationPrioritiesFound == True", "\ndef test_oof():\n    oof_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'BaseModuleBody': get_base_module_body()\n    }\n    oof_response:Response = oof.execute_oof_module(oof_input)\n\n    assert oof_response.statuscode == 200", "\ndef test_aad_risks():\n    aad_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'LookbackInDays': 14,\n        'BaseModuleBody': get_base_module_body()\n    }\n    aad_response:Response = aadrisks.execute_aadrisks_module(aad_input)\n\n    assert aad_response.statuscode == 200", "\ndef test_mde_module():\n    aad_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'LookbackInDays': 14,\n        'BaseModuleBody': get_base_module_body()\n    }\n    mde_response:Response = mde.execute_mde_module(aad_input)\n\n    assert mde_response.statuscode == 200", "\ndef test_mdca_module():\n    mdca_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'ScoreThreshold': 1,\n        'BaseModuleBody': get_base_module_body()\n    }\n    mdca_response:Response = mdca.execute_mdca_module(mdca_input)\n\n    assert mdca_response.statuscode == 200", "\ndef test_file_module():\n    file_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'BaseModuleBody': get_base_module_body()\n    }\n    file_response:Response = file.execute_file_module(file_input)\n\n    assert file_response.statuscode == 200\n    assert file_response.body.HashesLinkedToThreatCount > 0", "\ndef test_scoring():\n    scoring_input = {\n        'AddIncidentComments': False,\n        'AddIncidentTask': False,\n        'ScoringData': get_scoring_data(),\n        'BaseModuleBody': get_base_module_body()\n    }\n    scoring_response:Response = scoring.execute_scoring_module(scoring_input)\n\n    assert scoring_response.statuscode == 200\n    assert scoring_response.body.TotalScore == 532", "\ndef get_base_module_body():\n    base_module_body = json.loads(requests.get(url=os.getenv('BASEDATA')).content)\n    return base_module_body\n\ndef get_incident_trigger_data():\n    trigger_data = json.loads(requests.get(url=os.getenv('INCIDENTDATA')).content)\n    return trigger_data\n\ndef get_alert_trigger_data():\n    trigger_data = json.loads(requests.get(url=os.getenv('ALERTDATA')).content)\n    return trigger_data", "\ndef get_alert_trigger_data():\n    trigger_data = json.loads(requests.get(url=os.getenv('ALERTDATA')).content)\n    return trigger_data\n\ndef get_scoring_data():\n    scoring_data = json.loads(requests.get(url=os.getenv('SCORINGDATA')).content)\n    return scoring_data\n", ""]}
{"filename": "tests/__init__.py", "chunked_list": ["#Needed for test modules to execute\n\"\"\"Init for test package.\"\"\""]}
{"filename": "shared/data.py", "chunked_list": ["import pandas as pd\n\ndef list_to_html_table(input_list:list, max_rows=20, max_cols=10, nan_str='N/A', escape_html=True):\n    '''Convert a list of dictionaries into an HTML table'''\n    df = pd.DataFrame(input_list)\n    df.index = df.index + 1\n    html_table = df.to_html(max_rows=max_rows, max_cols=max_cols, na_rep=nan_str, escape=escape_html).replace('\\n', '')\n\n    return html_table\n\ndef update_column_value_in_list(input_list:list, col_name:str, update_str:str):\n    '''Updates the value of a column in each dict in the list, to include the column value in your replacement use [col_value]'''\n    updated_list = []\n    for row in input_list:\n        row[col_name] = update_str.replace('[col_value]', row[col_name])\n        updated_list.append(row)\n\n    return updated_list", "\ndef update_column_value_in_list(input_list:list, col_name:str, update_str:str):\n    '''Updates the value of a column in each dict in the list, to include the column value in your replacement use [col_value]'''\n    updated_list = []\n    for row in input_list:\n        row[col_name] = update_str.replace('[col_value]', row[col_name])\n        updated_list.append(row)\n\n    return updated_list\n\ndef return_highest_value(input_list:list, key:str, order:list=['High','Medium','Low','Informational','None','Unknown']):\n    '''Locate the highest value in a list of dictionaries by key'''\n    \n    unsorted_list = []\n    for item in input_list:\n        unsorted_list.append(item[key].lower())\n\n    for item in order:\n        if item.lower() in unsorted_list:\n            return item\n    \n    return 'Unknown'", "\ndef return_highest_value(input_list:list, key:str, order:list=['High','Medium','Low','Informational','None','Unknown']):\n    '''Locate the highest value in a list of dictionaries by key'''\n    \n    unsorted_list = []\n    for item in input_list:\n        unsorted_list.append(item[key].lower())\n\n    for item in order:\n        if item.lower() in unsorted_list:\n            return item\n    \n    return 'Unknown'", "\ndef join_lists(left_list, right_list, kind, left_key, right_key, fill_nan=None):\n    '''Join 2 lists of objects using a key.  Supported join kinds left, right, outer, inner, cross'''\n    left_df = pd.DataFrame(left_list)\n    right_df = pd.DataFrame(right_list)\n    join_data = left_df.merge(right=right_df, how=kind, left_on=left_key, right_on=right_key)\n    if fill_nan is None:\n        join_data = join_data.where(join_data.notna(), None)\n    else:\n        join_data = join_data.fillna(fill_nan)\n\n    return join_data.to_dict('records')", "\ndef sum_column_by_key(input_list, key):\n    df = pd.DataFrame(input_list)\n    try:\n        val = int(df[key].sum())\n    except KeyError:\n        val = int(0)\n    return val\n\ndef max_column_by_key(input_list, key):\n    df = pd.DataFrame(input_list)\n    try:\n        val = int(df[key].max())\n    except KeyError:\n        val = int(0)\n    return val", "\ndef max_column_by_key(input_list, key):\n    df = pd.DataFrame(input_list)\n    try:\n        val = int(df[key].max())\n    except KeyError:\n        val = int(0)\n    return val\n\ndef min_column_by_key(input_list, key):\n    df = pd.DataFrame(input_list)\n    try:\n        val = int(df[key].min())\n    except KeyError:\n        val = int(0)\n    return val", "\ndef min_column_by_key(input_list, key):\n    df = pd.DataFrame(input_list)\n    try:\n        val = int(df[key].min())\n    except KeyError:\n        val = int(0)\n    return val\n\ndef sort_list_by_key(input_list, key, ascending=False):\n    df = pd.DataFrame(input_list)\n    df = df.sort_values(by=[key], ascending=ascending)\n    return df.to_dict('records')", "\ndef sort_list_by_key(input_list, key, ascending=False):\n    df = pd.DataFrame(input_list)\n    df = df.sort_values(by=[key], ascending=ascending)\n    return df.to_dict('records')\n\ndef coalesce(*args):\n    for arg in args:\n        if arg is not None:\n            return arg", "        \ndef version_check(current_version:str, avaialble_version:str, update_check_type:str):\n    current = current_version.split('.')\n    available = avaialble_version.split('.')\n\n    update_dict = {\n        'Major': 1,\n        'Minor': 2,\n        'Build': 3\n    }\n\n    if available[0] > current[0]:\n        return {'UpdateAvailable': True, 'UpdateType': 'Major'}\n    elif available[1] > current[1] and available[0] == current[0] and update_dict[update_check_type] > 1:\n        return {'UpdateAvailable': True, 'UpdateType': 'Minor'}\n    elif available[2] > current[2] and available[0] == current[0] and available[1] == current[1] and update_dict[update_check_type] == 3:\n        return {'UpdateAvailable': True, 'UpdateType': 'Build'}\n    else:\n        return {'UpdateAvailable': False, 'UpdateType': 'None'}", "\ndef return_property_as_list(input_list:list, property_name:str):\n    return_list = []\n    for item in input_list:\n        return_list.append(item[property_name])\n    return return_list\n"]}
{"filename": "shared/coordinator.py", "chunked_list": ["from modules import base, kql, watchlist, ti, relatedalerts, scoring, ueba, playbook, oof, aadrisks, file, createincident, mdca, mde\nfrom classes import STATError\n\ndef initiate_module(module_name, req_body):\n    '''Call the appropriate STAT Module.'''\n\n    match module_name:\n        case 'base':\n            return_data = base.execute_base_module(req_body)\n        case 'kql':", "            return_data = base.execute_base_module(req_body)\n        case 'kql':\n            return_data = kql.execute_kql_module(req_body)\n        case 'scoring':\n            return_data = scoring.execute_scoring_module(req_body)\n        case 'watchlist':\n            return_data = watchlist.execute_watchlist_module(req_body)\n        case 'relatedalerts':\n            return_data = relatedalerts.execute_relatedalerts_module(req_body)\n        case 'threatintel':", "            return_data = relatedalerts.execute_relatedalerts_module(req_body)\n        case 'threatintel':\n            return_data = ti.execute_ti_module(req_body)\n        case 'mdca': \n            return_data = mdca.execute_mdca_module(req_body)\n        case 'mde':\n            return_data = mde.execute_mde_module(req_body)\n        case 'file':\n            return_data = file.execute_file_module(req_body)\n        case 'aadrisks':", "            return_data = file.execute_file_module(req_body)\n        case 'aadrisks':\n            return_data = aadrisks.execute_aadrisks_module(req_body)\n        case 'ueba':\n            return_data = ueba.execute_ueba_module(req_body)\n        case 'oofmodule':\n            return_data = oof.execute_oof_module(req_body)\n        case 'runplaybook':\n            return_data = playbook.execute_playbook_module(req_body)\n        case 'createincident':", "            return_data = playbook.execute_playbook_module(req_body)\n        case 'createincident':\n            return_data = createincident.execute_create_incident(req_body)\n        case _:\n            raise STATError(error=f'Invalid module name: {module_name}.', status_code=400)\n\n    return return_data\n"]}
{"filename": "shared/rest.py", "chunked_list": ["from azure.identity import DefaultAzureCredential, ClientSecretCredential\nfrom azure.keyvault.secrets import SecretClient\nimport requests\nimport datetime as dt\nimport json\nimport os\nimport uuid\nfrom classes import STATError, STATNotFound, BaseModule\n\nstat_token = {}", "\nstat_token = {}\ngraph_endpoint = os.getenv('GRAPH_ENDPOINT')\narm_endpoint = os.getenv('ARM_ENDPOINT')\nla_endpoint = os.getenv('LOGANALYTICS_ENDPOINT')\nm365_endpoint = os.getenv('M365_ENDPOINT')\nmde_endpoint = os.getenv('MDE_ENDPOINT')\ndefault_tenant_id = os.getenv('AZURE_TENANT_ID')\nmdca_endpoint = os.getenv('MDCA_ENDPOINT')\nkv_endpoint = os.getenv('KEYVAULT_ENDPOINT')", "mdca_endpoint = os.getenv('MDCA_ENDPOINT')\nkv_endpoint = os.getenv('KEYVAULT_ENDPOINT')\nkv_secret_name = os.getenv('KEYVAULT_SECRET_NAME')\nkv_client_id = os.getenv('KEYVAULT_CLIENT_ID')\nkv_secret = None\n\ndef token_cache(base_module:BaseModule, api:str):\n    global stat_token\n\n    default_tenant = os.getenv('AZURE_TENANT_ID')", "\n    default_tenant = os.getenv('AZURE_TENANT_ID')\n\n    match api:\n        case 'arm':\n            tenant = base_module.MultiTenantConfig.get('ARMTenantId', base_module.MultiTenantConfig.get('TenantId', default_tenant))\n            token_expiration_check(api, stat_token.get(tenant,{}).get('armtoken'), tenant)\n            return stat_token[tenant]['armtoken']\n        case 'msgraph':\n            tenant = base_module.MultiTenantConfig.get('MSGraphTenantId', base_module.MultiTenantConfig.get('TenantId', default_tenant))", "        case 'msgraph':\n            tenant = base_module.MultiTenantConfig.get('MSGraphTenantId', base_module.MultiTenantConfig.get('TenantId', default_tenant))\n            token_expiration_check(api, stat_token.get(tenant,{}).get('msgraphtoken'), tenant) \n            return stat_token[tenant]['msgraphtoken']\n        case 'la':\n            tenant = base_module.MultiTenantConfig.get('LogAnalyticsTenantId', base_module.MultiTenantConfig.get('TenantId', default_tenant))\n            token_expiration_check(api, stat_token.get(tenant,{}).get('latoken'), tenant)\n            return stat_token[tenant]['latoken']\n        case 'm365':\n            tenant = base_module.MultiTenantConfig.get('M365DTenantId', base_module.MultiTenantConfig.get('TenantId', default_tenant))", "        case 'm365':\n            tenant = base_module.MultiTenantConfig.get('M365DTenantId', base_module.MultiTenantConfig.get('TenantId', default_tenant))\n            token_expiration_check(api, stat_token.get(tenant,{}).get('m365token'), tenant)\n            return stat_token[tenant]['m365token']\n        case 'mde':\n            tenant = base_module.MultiTenantConfig.get('MDETenantId', base_module.MultiTenantConfig.get('TenantId', default_tenant))\n            token_expiration_check(api, stat_token.get(tenant,{}).get('mdetoken'), tenant)\n            return stat_token[tenant]['mdetoken']\n        case 'mdca':\n            tenant = base_module.MultiTenantConfig.get('MDCAUrl', base_module.MultiTenantConfig.get('TenantId', default_tenant))", "        case 'mdca':\n            tenant = base_module.MultiTenantConfig.get('MDCAUrl', base_module.MultiTenantConfig.get('TenantId', default_tenant))\n            token_expiration_check(api, stat_token.get(tenant,{}).get('mdcatoken'), tenant)\n            return stat_token[tenant]['mdcatoken']\n\ndef token_expiration_check(api:str, token, tenant:str):\n    \n    if token is None:\n        acquire_token(api, tenant)\n    else:", "        acquire_token(api, tenant)\n    else:\n        expiration_time = dt.datetime.fromtimestamp(token.expires_on) - dt.timedelta(minutes=5)\n        current_time = dt.datetime.now()\n\n        if current_time > expiration_time:\n            acquire_token(api, tenant) \n\ndef acquire_token(api:str, tenant:str):\n    global stat_token", "def acquire_token(api:str, tenant:str):\n    global stat_token\n    global kv_secret\n\n    if kv_endpoint and kv_secret_name and kv_client_id:\n        if not kv_secret:\n            kv_secret = get_kv_secret()\n        cred = ClientSecretCredential(tenant_id=tenant, client_id=kv_client_id, client_secret=kv_secret, additionally_allowed_tenants='*')\n    else:\n        cred = DefaultAzureCredential(additionally_allowed_tenants='*')", "    else:\n        cred = DefaultAzureCredential(additionally_allowed_tenants='*')\n\n    if not stat_token.get(tenant):\n        stat_token[tenant] = {}\n\n    match api:\n        case 'arm':\n            stat_token[tenant]['armtoken'] = cred.get_token(get_endpoint('arm') + \"/.default\", tenant_id=tenant)\n        case 'msgraph':", "            stat_token[tenant]['armtoken'] = cred.get_token(get_endpoint('arm') + \"/.default\", tenant_id=tenant)\n        case 'msgraph':\n            stat_token[tenant]['msgraphtoken'] = cred.get_token(get_endpoint('msgraph') + \"/.default\", tenant_id=tenant)\n        case 'la':\n            stat_token[tenant]['latoken'] = cred.get_token(get_endpoint('la') + \"/.default\", tenant_id=tenant)\n        case 'm365':\n            stat_token[tenant]['m365token'] = cred.get_token(get_endpoint('m365') + \"/.default\", tenant_id=tenant)\n        case 'mde':\n            stat_token[tenant]['mdetoken'] = cred.get_token(get_endpoint('mde') + \"/.default\", tenant_id=tenant)\n        case 'mdca':", "            stat_token[tenant]['mdetoken'] = cred.get_token(get_endpoint('mde') + \"/.default\", tenant_id=tenant)\n        case 'mdca':\n            stat_token[tenant]['mdcatoken'] = cred.get_token(\"05a65629-4c1b-48c1-a78b-804c4abdd4af/.default\", tenant_id=tenant)\n\ndef get_kv_secret():\n    cred = DefaultAzureCredential()\n    client = SecretClient(f'https://{kv_endpoint}/', cred)\n    kv_return = client.get_secret(kv_secret_name)\n    return kv_return.value\n", "    return kv_return.value\n\ndef rest_call_get(base_module:BaseModule, api:str, path:str, headers:dict={}):\n    '''Perform a GET HTTP call to a REST API.  Accepted API values are arm, msgraph, la, m365 and mde'''\n    token = token_cache(base_module, api)\n    url = get_endpoint(api) + path\n    headers['Authorization'] = 'Bearer ' + token.token\n    response = requests.get(url=url, headers=headers)\n\n    if response.status_code == 404:", "\n    if response.status_code == 404:\n        raise STATNotFound(f'The API call to {api} with path {path} failed with status {response.status_code}', source_error={'status_code': int(response.status_code), 'reason': str(response.reason)})\n    elif response.status_code >= 300:\n        raise STATError(f'The API call to {api} with path {path} failed with status {response.status_code}', source_error={'status_code': int(response.status_code), 'reason': str(response.reason)})\n    \n    return response\n\ndef rest_call_post(base_module:BaseModule, api:str, path:str, body, headers:dict={}):\n    '''Perform a POST HTTP call to a REST API.  Accepted API values are arm, msgraph, la, m365 and mde'''", "def rest_call_post(base_module:BaseModule, api:str, path:str, body, headers:dict={}):\n    '''Perform a POST HTTP call to a REST API.  Accepted API values are arm, msgraph, la, m365 and mde'''\n    token = token_cache(base_module, api)\n    url = get_endpoint(api) + path\n    headers['Authorization'] = 'Bearer ' + token.token\n    response = requests.post(url=url, json=body, headers=headers)\n\n    if response.status_code == 404:\n        raise STATNotFound(f'The API call to {api} with path {path} failed with status {response.status_code}', source_error={'status_code': int(response.status_code), 'reason': str(response.reason)})\n    elif response.status_code >= 300:", "        raise STATNotFound(f'The API call to {api} with path {path} failed with status {response.status_code}', source_error={'status_code': int(response.status_code), 'reason': str(response.reason)})\n    elif response.status_code >= 300:\n        raise STATError(f'The API call to {api} with path {path} failed with status {response.status_code}', source_error={'status_code': int(response.status_code), 'reason': str(response.reason)})\n    \n    return response\n\ndef rest_call_put(base_module:BaseModule, api:str, path:str, body, headers:dict={}):\n    '''Perform a PUT HTTP call to a REST API.  Accepted API values are arm, msgraph, la, m365 and mde'''\n    token = token_cache(base_module, api)\n    url = get_endpoint(api) + path", "    token = token_cache(base_module, api)\n    url = get_endpoint(api) + path\n    headers['Authorization'] = 'Bearer ' + token.token\n    response = requests.put(url=url, json=body, headers=headers)\n\n    if response.status_code == 404:\n        raise STATNotFound(f'The API call to {api} with path {path} failed with status {response.status_code}', source_error={'status_code': int(response.status_code), 'reason': str(response.reason)})\n    elif response.status_code >= 300:\n        raise STATError(f'The API call to {api} with path {path} failed with status {response.status_code}', source_error={'status_code': int(response.status_code), 'reason': str(response.reason)})\n    ", "        raise STATError(f'The API call to {api} with path {path} failed with status {response.status_code}', source_error={'status_code': int(response.status_code), 'reason': str(response.reason)})\n    \n    return response\n\ndef execute_la_query(base_module:BaseModule, query:str, lookbackindays:int):\n    token = token_cache(base_module, 'la')\n    url = get_endpoint('la') + '/v1/workspaces/' + base_module.WorkspaceId + '/query'\n    duration = 'P' + str(lookbackindays) + 'D'\n    body = {'query': query, 'timespan': duration}\n    response = requests.post(url=url, json=body, headers={\"Authorization\": \"Bearer \" + token.token})", "    body = {'query': query, 'timespan': duration}\n    response = requests.post(url=url, json=body, headers={\"Authorization\": \"Bearer \" + token.token})\n    data = json.loads(response.content)\n\n    if response.status_code >= 300:\n        raise STATError('Microsoft Sentinel KQL Query failed to execute', data)\n \n    columns = data['tables'][0]['columns']\n    rows = data['tables'][0]['rows']\n    columnlist = []", "    rows = data['tables'][0]['rows']\n    columnlist = []\n    query_results = []\n\n    for column in columns:\n        columnlist.append(column['name'])\n\n    for row in rows:\n        query_results.append(dict(zip(columnlist,row)))\n", "        query_results.append(dict(zip(columnlist,row)))\n\n    return query_results\n\ndef execute_m365d_query(base_module:BaseModule, query:str):\n    token = token_cache(base_module, 'm365')\n    url = get_endpoint('m365') + '/api/advancedhunting/run'\n    body = {'Query': query}\n    response = requests.post(url=url, json=body, headers={\"Authorization\": \"Bearer \" + token.token})\n    data = json.loads(response.content)", "    response = requests.post(url=url, json=body, headers={\"Authorization\": \"Bearer \" + token.token})\n    data = json.loads(response.content)\n\n    if response.status_code >= 300:\n        raise STATError('Microsoft 365 Advanced Hunting Query failed to execute', data)\n    \n    return data['Results']\n\ndef execute_mde_query(base_module:BaseModule, query:str):\n    token = token_cache(base_module, 'mde')", "def execute_mde_query(base_module:BaseModule, query:str):\n    token = token_cache(base_module, 'mde')\n    url = get_endpoint('mde') + '/api/advancedqueries/run'\n    body = {'Query': query}\n    response = requests.post(url=url, json=body, headers={\"Authorization\": \"Bearer \" + token.token})\n    data = json.loads(response.content)\n\n    if response.status_code >= 300:\n        raise STATError('Microsoft 365 Advanced Hunting Query failed to execute', data)\n    ", "        raise STATError('Microsoft 365 Advanced Hunting Query failed to execute', data)\n    \n    return data['Results']\n\ndef get_endpoint(api:str):\n    try:\n        match api:\n            case 'arm':\n                return 'https://' + arm_endpoint\n            case 'msgraph':", "                return 'https://' + arm_endpoint\n            case 'msgraph':\n                return 'https://' + graph_endpoint\n            case 'la':\n                return 'https://' + la_endpoint\n            case 'm365':\n                return 'https://' + m365_endpoint\n            case 'mde':\n                return 'https://' + mde_endpoint\n            case 'mdca':", "                return 'https://' + mde_endpoint\n            case 'mdca':\n                return 'https://' + mdca_endpoint\n    except TypeError:\n        raise STATError(f'The STAT Function Application Setting was not configured for the {api} API. '\n                        'Ensure that all API endpoint enrivonrment variables are correctly set in the STAT Function App '\n                        '(ARM_ENDPOINT, GRAPH_ENDPOINT, LOGANALYTICS_ENDPOINT, M365_ENDPOINT, MDE_ENDPOINT, and MDCA_ENDPOINT).')\n    \ndef add_incident_comment(base_module:BaseModule, comment:str):\n    token = token_cache(base_module, 'arm')", "def add_incident_comment(base_module:BaseModule, comment:str):\n    token = token_cache(base_module, 'arm')\n    endpoint = get_endpoint('arm')\n    url = endpoint + base_module.IncidentARMId + '/comments/' + str(uuid.uuid4()) + '?api-version=2023-02-01'\n    return requests.put(url=url, json={'properties': {'message': comment[:30000]}}, headers={\"Authorization\": \"Bearer \" + token.token})\n\ndef add_incident_task(base_module:BaseModule, title:str, description:str, status:str='New'):\n    token = token_cache(base_module, 'arm')\n    endpoint = get_endpoint('arm')\n    url = endpoint + base_module.IncidentARMId + '/tasks/' + str(uuid.uuid4()) + '?api-version=2023-04-01-preview'", "    endpoint = get_endpoint('arm')\n    url = endpoint + base_module.IncidentARMId + '/tasks/' + str(uuid.uuid4()) + '?api-version=2023-04-01-preview'\n\n    if description is None or description == '':\n        return requests.put(url=url, json={'properties': {'title': title, 'status': status}}, headers={\"Authorization\": \"Bearer \" + token.token})\n    else:\n        return requests.put(url=url, json={'properties': {'title': title, 'description': description[:3000], 'status': status}}, headers={\"Authorization\": \"Bearer \" + token.token})\n    "]}
{"filename": "modules/base.py", "chunked_list": ["from classes import BaseModule, Response, STATError, STATNotFound\nfrom shared import rest, data\nimport json\nimport time\nimport logging\nimport requests\nimport pathlib\n\nstat_version = None\n\ndef execute_base_module (req_body):\n    global base_object\n    \n    base_object = BaseModule()\n\n    trigger_type = req_body['Body'].get('objectSchemaType', 'alert')\n\n    base_object.MultiTenantConfig = req_body.get('MultiTenantConfig', {})\n\n    if trigger_type.lower() == 'incident':\n        entities = process_incident_trigger(req_body)\n    else:\n        entities = process_alert_trigger(req_body)\n\n    if not entities:\n        if base_object.IncidentAvailable:\n            rest.add_incident_comment(base_object, 'The Microsoft Sentinel Triage AssistanT failed to analyze this incident. This error was due to no incident entities being available at the time the incident was processed.')\n        raise STATError('No entities found in the trigger data. The Microsoft Sentinel Triage AssistanT requires at least 1 entity be linked to the alert.')\n\n    enrich_ips(entities, req_body.get('EnrichIPsWithGeoData', True))\n    enrich_accounts(entities)\n    enrich_hosts(entities)\n    enrich_domains(entities)\n    enrich_files(entities)\n    enrich_filehashes(entities)\n    enrich_urls(entities)\n    append_other_entities(entities)\n\n    base_object.EntitiesCount = base_object.AccountsCount + base_object.DomainsCount + base_object.FileHashesCount + base_object.FilesCount + base_object.HostsCount + base_object.OtherEntitiesCount + base_object.URLsCount\n\n    org_info = json.loads(rest.rest_call_get(base_object, api='msgraph', path='/v1.0/organization').content)\n    base_object.TenantDisplayName = org_info['value'][0]['displayName']\n    base_object.TenantId = org_info['value'][0]['id']\n\n    req_header = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.58'\n    }\n\n    base_object.ModuleVersions = json.loads(requests.get('https://aka.ms/mstatversion', headers=req_header, allow_redirects=True).content)\n    version_check_type = req_body.get('VersionCheckType', 'Build')\n    \n    if version_check_type != 'None':\n        try:\n            get_stat_version(version_check_type)\n        except:\n            pass\n\n    account_comment = ''\n    ip_comment = ''\n\n    if req_body.get('AddAccountComment', True) and base_object.AccountsCount > 0:\n        account_comment = 'Account Info:<br>' + get_account_comment()\n\n    if req_body.get('AddIPComment', True) and base_object.IPsCount > 0:\n        ip_comment = 'IP Info:<br>' + get_ip_comment()\n\n    if (req_body.get('AddAccountComment', True) and base_object.AccountsCount > 0) or (req_body.get('AddIPComment', True) and base_object.IPsCount > 0):\n        comment = account_comment + '<br><p>' + ip_comment\n        rest.add_incident_comment(base_object, comment)\n\n    return Response(base_object)", "stat_version = None\n\ndef execute_base_module (req_body):\n    global base_object\n    \n    base_object = BaseModule()\n\n    trigger_type = req_body['Body'].get('objectSchemaType', 'alert')\n\n    base_object.MultiTenantConfig = req_body.get('MultiTenantConfig', {})\n\n    if trigger_type.lower() == 'incident':\n        entities = process_incident_trigger(req_body)\n    else:\n        entities = process_alert_trigger(req_body)\n\n    if not entities:\n        if base_object.IncidentAvailable:\n            rest.add_incident_comment(base_object, 'The Microsoft Sentinel Triage AssistanT failed to analyze this incident. This error was due to no incident entities being available at the time the incident was processed.')\n        raise STATError('No entities found in the trigger data. The Microsoft Sentinel Triage AssistanT requires at least 1 entity be linked to the alert.')\n\n    enrich_ips(entities, req_body.get('EnrichIPsWithGeoData', True))\n    enrich_accounts(entities)\n    enrich_hosts(entities)\n    enrich_domains(entities)\n    enrich_files(entities)\n    enrich_filehashes(entities)\n    enrich_urls(entities)\n    append_other_entities(entities)\n\n    base_object.EntitiesCount = base_object.AccountsCount + base_object.DomainsCount + base_object.FileHashesCount + base_object.FilesCount + base_object.HostsCount + base_object.OtherEntitiesCount + base_object.URLsCount\n\n    org_info = json.loads(rest.rest_call_get(base_object, api='msgraph', path='/v1.0/organization').content)\n    base_object.TenantDisplayName = org_info['value'][0]['displayName']\n    base_object.TenantId = org_info['value'][0]['id']\n\n    req_header = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.58'\n    }\n\n    base_object.ModuleVersions = json.loads(requests.get('https://aka.ms/mstatversion', headers=req_header, allow_redirects=True).content)\n    version_check_type = req_body.get('VersionCheckType', 'Build')\n    \n    if version_check_type != 'None':\n        try:\n            get_stat_version(version_check_type)\n        except:\n            pass\n\n    account_comment = ''\n    ip_comment = ''\n\n    if req_body.get('AddAccountComment', True) and base_object.AccountsCount > 0:\n        account_comment = 'Account Info:<br>' + get_account_comment()\n\n    if req_body.get('AddIPComment', True) and base_object.IPsCount > 0:\n        ip_comment = 'IP Info:<br>' + get_ip_comment()\n\n    if (req_body.get('AddAccountComment', True) and base_object.AccountsCount > 0) or (req_body.get('AddIPComment', True) and base_object.IPsCount > 0):\n        comment = account_comment + '<br><p>' + ip_comment\n        rest.add_incident_comment(base_object, comment)\n\n    return Response(base_object)", "\ndef process_incident_trigger (req_body):\n    base_object.load_incident_trigger(req_body['Body'])\n    return req_body['Body']['object']['properties']['relatedEntities']\n\ndef process_alert_trigger (req_body):\n    base_object.load_alert_trigger(req_body['Body'])\n    entities = req_body['Body']['Entities']\n    for entity in entities:\n        entity['kind'] = entity.pop('Type')\n             \n    #Get Workspace ARM Id\n    subscription_id = req_body['Body']['WorkspaceSubscriptionId']\n    workspace_query = json.loads(rest.rest_call_get(base_object, 'arm', f'/subscriptions/{subscription_id}/providers/Microsoft.OperationalInsights/workspaces?api-version=2021-12-01-preview').content)\n    filter_workspace = list(filter(lambda x: x['properties']['customerId'] == req_body['Body']['WorkspaceId'], workspace_query['value']))\n    base_object.WorkspaceARMId = filter_workspace[0]['id']\n\n    alert_rule_id = base_object.WorkspaceARMId + '/providers/Microsoft.SecurityInsights/alertRules/' + req_body['Body']['AlertType'].split('_')[-1]\n    base_object.RelatedAnalyticRuleIds.append(alert_rule_id)\n\n    #Get Security Alert Entity\n    alert_found = False\n    x = 0\n    alert_id = base_object.WorkspaceARMId + '/providers/Microsoft.SecurityInsights/entities/' + req_body['Body']['SystemAlertId']\n    alert_path = alert_id + '?api-version=2023-05-01-preview'\n    \n    while not alert_found:\n        x += 1\n        try:\n            alert_result = json.loads(rest.rest_call_get(base_object, 'arm', alert_path).content)\n        except STATNotFound:\n            if x > 5:\n                raise STATError('Alert metadata is not currently available, consider adding a delay in the logic app before calling the base module using an alert.', status_code=503)\n            time.sleep(20)\n        else:\n            logging.info('Alert found, processing')\n            base_object.Alerts.append(alert_result)\n            alert_found = True\n\n        \n    #Check if alert is already linked to an incident and retrieve Incident ARM Id\n    alert_relation_path = alert_id + '/relations?api-version=2023-05-01-preview'\n    alert_relation_result = json.loads(rest.rest_call_get(base_object, 'arm', alert_relation_path).content)\n    filter_relations = list(filter(lambda x: x['properties']['relatedResourceType'] == 'Microsoft.SecurityInsights/Incidents', alert_relation_result['value']))\n    \n    if filter_relations:\n        base_object.IncidentARMId = filter_relations[0]['properties']['relatedResourceId']\n        base_object.IncidentAvailable = True\n\n    return entities", "\ndef enrich_ips (entities, get_geo):\n    ip_entities = list(filter(lambda x: x['kind'].lower() == 'ip', entities))\n    base_object.IPsCount = len(ip_entities)\n\n    for ip in ip_entities:\n        current_ip = data.coalesce(ip.get('properties', {}).get('address'), ip.get('Address'))\n        raw_entity = data.coalesce(ip.get('properties'), ip)\n        if get_geo:\n            path = base_object.SentinelRGARMId + \"/providers/Microsoft.SecurityInsights/enrichment/ip/geodata/?api-version=2023-04-01-preview&ipAddress=\" + current_ip\n            try:\n                response = rest.rest_call_get(base_object, api='arm', path=path)\n            except STATError:\n                base_object.add_ip_entity(address=current_ip, geo_data={}, rawentity=raw_entity)\n            else:\n                base_object.add_ip_entity(address=current_ip, geo_data=json.loads(response.content), rawentity=raw_entity)\n        else:\n            base_object.add_ip_entity(address=current_ip, geo_data={}, rawentity=raw_entity)", "\ndef enrich_accounts(entities):\n    account_entities = list(filter(lambda x: x['kind'].lower() == 'account', entities))\n    base_object.AccountsCount = len(account_entities)\n\n    attributes = 'userPrincipalName,id,onPremisesSecurityIdentifier,onPremisesDistinguishedName,onPremisesDomainName,onPremisesSamAccountName,onPremisesSyncEnabled,mail,city,state,country,department,jobTitle,officeLocation,accountEnabled&$expand=manager($select=userPrincipalName,mail,id)'\n\n    for account in account_entities:\n        aad_id = data.coalesce(account.get('properties',{}).get('aadUserId'), account.get('AadUserId'))\n        upn_suffix = data.coalesce(account.get('properties',{}).get('upnSuffix'), account.get('UPNSuffix'))\n        account_name = data.coalesce(account.get('properties',{}).get('accountName'), account.get('Name'))\n        friendly_name = data.coalesce(account.get('properties',{}).get('friendlyName'), account.get('DisplayName'), account.get('Name'))\n        sid = data.coalesce(account.get('properties',{}).get('sid'), account.get('Sid'))\n        nt_domain = data.coalesce(account.get('properties',{}).get('ntDomain'), account.get('NTDomain'))\n        properties = data.coalesce(account.get('properties'), account)\n\n        if aad_id:\n            get_account_by_upn_or_id(aad_id, attributes, properties)\n        elif upn_suffix:\n            get_account_by_upn_or_id(account_name + '@' + upn_suffix, attributes, properties)\n        elif sid:\n            get_account_by_sid(sid, attributes, properties)\n        elif nt_domain and account_name:\n            get_account_by_samaccountname(account_name, attributes, properties)\n        else:\n            if friendly_name.__contains__('@'):\n                get_account_by_upn_or_id(friendly_name, attributes, properties)\n            elif friendly_name.__contains__('S-1-'):\n                get_account_by_sid(friendly_name, attributes, properties)\n            elif friendly_name.__contains__('CN='):\n                get_account_by_dn(friendly_name, attributes, properties)\n            else:\n                get_account_by_samaccountname(friendly_name, attributes, properties)", "\n\ndef enrich_domains(entities):\n    domain_entities = list(filter(lambda x: x['kind'].lower() in ('dnsresolution', 'dns'), entities))\n    base_object.DomainsCount = len(domain_entities)\n    \n    for domain in domain_entities:\n        domain_name = data.coalesce(domain.get('properties',{}).get('domainName'), domain.get('DomainName'))\n        raw_entity = data.coalesce(domain.get('properties'), domain)\n        base_object.Domains.append({'Domain': domain_name, 'RawEntity': raw_entity})", "\ndef enrich_files(entities):\n    file_entities = list(filter(lambda x: x['kind'].lower() == 'file', entities))\n    base_object.FilesCount = len(file_entities)\n\n    for file in file_entities:\n        raw_entity = data.coalesce(file.get('properties'), file)\n        base_object.Files.append({'FileName': data.coalesce(file.get('properties',{}).get('friendlyName'), file.get('Name')),'RawEntity': raw_entity})\n\ndef enrich_filehashes(entities):\n    filehash_entities = list(filter(lambda x: x['kind'].lower() == 'filehash', entities))\n    base_object.FileHashesCount = len(filehash_entities)\n\n    for hash in filehash_entities:\n        file_hash = data.coalesce(hash.get('properties',{}).get('hashValue'), hash.get('Value'))\n        hash_alg = data.coalesce(hash.get('properties',{}).get('algorithm'), hash.get('Algorithm'))\n        raw_entity = data.coalesce(hash.get('properties'), hash)\n        base_object.FileHashes.append({'FileHash': file_hash, 'Algorithm': hash_alg, 'RawEntity': raw_entity})", "\ndef enrich_filehashes(entities):\n    filehash_entities = list(filter(lambda x: x['kind'].lower() == 'filehash', entities))\n    base_object.FileHashesCount = len(filehash_entities)\n\n    for hash in filehash_entities:\n        file_hash = data.coalesce(hash.get('properties',{}).get('hashValue'), hash.get('Value'))\n        hash_alg = data.coalesce(hash.get('properties',{}).get('algorithm'), hash.get('Algorithm'))\n        raw_entity = data.coalesce(hash.get('properties'), hash)\n        base_object.FileHashes.append({'FileHash': file_hash, 'Algorithm': hash_alg, 'RawEntity': raw_entity})", "\ndef enrich_urls(entities):\n    url_entities = list(filter(lambda x: x['kind'].lower() == 'url', entities))\n    base_object.URLsCount = len(url_entities)\n\n    for url in url_entities:\n        url_data = data.coalesce(url.get('properties',{}).get('url'), url.get('Url'))\n        raw_entity = data.coalesce(url.get('properties'), url)\n        base_object.URLs.append({'Url': url_data, 'RawEntity': raw_entity})\n\ndef append_other_entities(entities):\n    other_entities = list(filter(lambda x: x['kind'].lower() not in ('ip','account','dnsresolution','dns','file','filehash','host','url'), entities))\n    base_object.OtherEntitiesCount = len(other_entities)\n\n    for entity in other_entities:\n        raw_entity = data.coalesce(entity.get('properties'), entity)\n        base_object.OtherEntities.append({'RawEntity': raw_entity})", "\ndef append_other_entities(entities):\n    other_entities = list(filter(lambda x: x['kind'].lower() not in ('ip','account','dnsresolution','dns','file','filehash','host','url'), entities))\n    base_object.OtherEntitiesCount = len(other_entities)\n\n    for entity in other_entities:\n        raw_entity = data.coalesce(entity.get('properties'), entity)\n        base_object.OtherEntities.append({'RawEntity': raw_entity})\n\ndef get_account_by_upn_or_id(account, attributes, properties):\n    try:\n        user_info = json.loads(rest.rest_call_get(base_object, api='msgraph', path='/v1.0/users/' + account + '?$select=' + attributes).content)\n    except STATError:\n        if account.__contains__('@'):\n            get_account_by_mail(account, attributes, properties)\n        else:\n            base_object.add_account_entity({'RawEntity': properties})\n    else:\n        append_account_details(account, user_info, properties)", "\ndef get_account_by_upn_or_id(account, attributes, properties):\n    try:\n        user_info = json.loads(rest.rest_call_get(base_object, api='msgraph', path='/v1.0/users/' + account + '?$select=' + attributes).content)\n    except STATError:\n        if account.__contains__('@'):\n            get_account_by_mail(account, attributes, properties)\n        else:\n            base_object.add_account_entity({'RawEntity': properties})\n    else:\n        append_account_details(account, user_info, properties)", "\ndef get_account_by_mail(account, attributes, properties):\n    try:\n        user_info = json.loads(rest.rest_call_get(base_object, api='msgraph', path=f'''/v1.0/users?$filter=(mail%20eq%20'{account}')&$select={attributes}''').content)\n    except STATError:\n        base_object.add_account_entity({'RawEntity': properties})\n    else:\n        if user_info['value']:\n            append_account_details(account, user_info['value'][0], properties)\n        else:\n            base_object.add_account_entity({'RawEntity': properties})", "\ndef get_account_by_dn(account, attributes, properties):\n\n    query = f'''IdentityInfo\n| where OnPremisesDistinguishedName =~ '{account}'\n| summarize arg_max(TimeGenerated, *) by OnPremisesDistinguishedName\n| project AccountUPN'''\n\n    results = rest.execute_la_query(base_object, query, 14)\n    if results:\n        get_account_by_upn_or_id(results[0]['AccountUPN'], attributes, properties)\n    else:\n        base_object.add_account_entity({'RawEntity': properties})", "\ndef get_account_by_sid(account, attributes, properties):\n    try:\n        user_info = json.loads(rest.rest_call_get(base_object, api='msgraph', path=f'''/v1.0/users?$filter=(onPremisesSecurityIdentifier%20eq%20'{account}')&$select={attributes}''').content)\n    except STATError:\n        base_object.add_account_entity({'RawEntity': properties})\n    else:\n        if user_info['value']:\n            append_account_details(account, user_info['value'][0], properties)\n        else:\n            base_object.add_account_entity({'RawEntity': properties})", "\ndef get_account_by_samaccountname(account, attributes, properties):\n    query = f'''IdentityInfo\n| where AccountName =~ '{account}'\n| summarize arg_max(TimeGenerated, *) by AccountName\n| project AccountUPN'''\n\n    results = rest.execute_la_query(base_object, query, 14)\n    if results:\n        get_account_by_upn_or_id(results[0]['AccountUPN'], attributes, properties)\n    else:\n        base_object.add_account_entity({'RawEntity': properties})", "\ndef append_account_details(account, user_info, raw_entity):\n\n    assigned_roles = ['Unavailable']\n    security_info = {}\n    \n    try: \n        assigned_roles = get_account_roles(user_info['id'])\n    except:\n        pass\n    \n    try:\n        security_info = get_security_info(user_info['userPrincipalName'])\n    except:\n        pass\n\n    user_info['AssignedRoles'] = assigned_roles\n    user_info['isAADPrivileged'] = bool(list(filter(lambda x: x != 'Unknown', assigned_roles)))\n    user_info['isMfaRegistered'] = security_info.get('isMfaRegistered', 'Unknown')\n    user_info['isSSPREnabled'] = security_info.get('isEnabled', 'Unknown')\n    user_info['isSSPRRegistered'] = security_info.get('isRegistered', 'Unknown')\n    user_info['RawEntity'] = raw_entity\n    \n    base_object.add_account_entity(user_info)", "\ndef get_account_roles(id):\n    role_info = json.loads(rest.rest_call_get(base_object, api='msgraph', path=\"/v1.0/roleManagement/directory/roleAssignments?$filter=principalId%20eq%20'\" + id + \"'&$expand=roleDefinition\").content)\n    roles = []\n    \n    for role in role_info['value']:\n        roles.append(role['roleDefinition']['displayName'])\n    return roles\n\ndef get_security_info(upn):\n    response = json.loads(rest.rest_call_get(base_object, api='msgraph', path=\"/beta/reports/credentialUserRegistrationDetails?$filter=userPrincipalName%20eq%20'\" + upn + \"'\").content)\n    security_info = response['value'][0]\n    return security_info", "\ndef get_security_info(upn):\n    response = json.loads(rest.rest_call_get(base_object, api='msgraph', path=\"/beta/reports/credentialUserRegistrationDetails?$filter=userPrincipalName%20eq%20'\" + upn + \"'\").content)\n    security_info = response['value'][0]\n    return security_info\n\n\ndef enrich_hosts(entities):\n    host_entities = list(filter(lambda x: x['kind'].lower() == 'host', entities))\n    base_object.HostsCount = len(host_entities)\n\n    for host in host_entities:\n        host_name = data.coalesce(host.get('properties',{}).get('hostName'), host.get('HostName'))\n        domain_name = data.coalesce(host.get('properties',{}).get('dnsDomain'), host.get('DnsDomain'), '')\n        mde_device_id = data.coalesce(host.get('properties',{}).get('additionalData', {}).get('MdatpDeviceId'), host.get('MdatpDeviceId'))\n        raw_entity = data.coalesce(host.get('properties'), host)\n        base_object.add_host_entity(fqdn=host_name + '.' + domain_name, hostname=host_name, dnsdomain=domain_name, mdedeviceid=mde_device_id, rawentity=raw_entity)", "\ndef get_account_comment():\n    \n    account_list = []\n    for account in base_object.Accounts:\n        account_id = account.get('id')\n        account_upn = account.get('userPrincipalName')\n        account_mail = account.get('mail')\n        if account_id:    \n            upn_data = f'<a href=\"https://portal.azure.com/#view/Microsoft_AAD_UsersAndTenants/UserProfileMenuBlade/~/overview/userId/{account_id}\" target=\"_blank\">{account_upn}</a><br>(<a href=\"mailto:{account_mail}\">Contact User</a>)'\n        else:\n            upn_data = account_upn\n            \n        account_list.append({'UserPrincipalName': upn_data, 'City': account.get('city'), 'Country': account.get('country'), \\\n                             'Department': account.get('department'), 'JobTitle': account.get('jobTitle'), 'Office': account.get('officeLocation'), \\\n                             'AADRoles': account.get('AssignedRoles'), 'ManagerUPN': account.get('manager', {}).get('userPrincipalName'), \\\n                             'MfaRegistered': account.get('isMfaRegistered'), 'SSPREnabled': account.get('isSSPREnabled'), \\\n                             'SSPRRegistered': account.get('isSSPRRegistered')})\n        \n    link_template = f'https://portal.azure.com/#view/Microsoft_AAD_UsersAndTenants/UserProfileMenuBlade/~/overview/userId/ed2a76d8-c545-4ada-9f45-8c86667394f4'\n        \n    return data.list_to_html_table(account_list, 20, 20, escape_html=False)", "\ndef get_ip_comment():\n    \n    ip_list = []\n    for ip in base_object.IPs:\n        geo = ip.get('GeoData')\n        ip_list.append({'IP': ip.get('Address'), 'City': geo.get('city'), 'State': geo.get('state'), 'Country': geo.get('country'), \\\n                        'Organization': geo.get('organization'), 'OrganizationType': geo.get('organizationType'), 'ASN': geo.get('asn') })\n        \n    return data.list_to_html_table(ip_list)", "\ndef get_stat_version(version_check_type):\n    global stat_version\n\n    if stat_version is None:\n        with open(pathlib.Path(__file__).parent / 'version.json') as f:\n            stat_version = json.loads(f.read())['FunctionVersion']\n    \n    available_version = base_object.ModuleVersions.get('STATFunction', '1.4.9')\n    logging.info(f'STAT Version check info. Current Version: {stat_version}, Available Version: {available_version}')\n    version_check_result = data.version_check(stat_version, available_version, version_check_type)\n    if version_check_result['UpdateAvailable'] and base_object.IncidentAvailable:\n        rest.add_incident_comment(base_object, f'<h4>A Microsoft Sentinel Triage AssistanT update is available</h4>The currently installed version is {stat_version}, the available version is {available_version}.')", ""]}
{"filename": "modules/oof.py", "chunked_list": ["from classes import BaseModule, Response, OOFModule, STATError\nfrom shared import rest, data\nimport json\nimport re\nimport datetime\n\ndef execute_oof_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, Entities, IncidentTaskInstructions, KQLQuery, LookbackInDays, QueryDescription, RunQueryAgainst\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    oof = OOFModule()\n\n    for account in base_object.Accounts:\n        upn = account.get('userPrincipalName')\n        if upn:\n            path = f'/v1.0/users/{upn}/mailboxSettings/automaticRepliesSetting'\n            try:\n                results = json.loads(rest.rest_call_get(base_object, api='msgraph', path=path).content)\n            except STATError as e:\n                if e.source_error['status_code'] == 403:\n                    raise STATError(e.error, e.source_error, e.status_code)\n                oof.UsersUnknown += 1\n                append_unknown(oof, upn)\n\n            else:\n                current_time = datetime.datetime.utcnow()\n                if results['status'].lower() == 'disabled':\n                    oof.UsersInOffice += 1\n                    append_disabled(oof, upn)\n                elif results['status'].lower() == 'enabled' or results['status'].lower() == 'alwaysenabled':\n                    oof.UsersOutOfOffice += 1\n                    append_enabled(oof, upn, results['internalReplyMessage'], results['externalReplyMessage'])\n                elif results['status'].lower() == 'scheduled' and current_time >= results['scheduledStartDateTime']['dateTime'] \\\n                        and current_time <= results['scheduledEndDateTime']['dateTime']:\n                    oof.UsersOutOfOffice += 1\n                    append_enabled(oof, upn, results['internalReplyMessage'], results['externalReplyMessage'])\n                else:\n                    oof.UsersInOffice += 1\n                    append_disabled(oof, upn)\n\n        else:\n            oof.UsersUnknown += 1\n\n    if oof.UsersOutOfOffice == 0 and oof.UsersUnknown == 0:\n        oof.AllUsersInOffice = True\n        oof.AllUsersOutOfOffice = False\n    elif oof.UsersOutOfOffice > 0 and oof.UsersInOffice == 0 and oof.UsersUnknown == 0:\n        oof.AllUsersInOffice = False\n        oof.AllUsersOutOfOffice = True \n    else:\n        oof.AllUsersInOffice = False\n        oof.AllUsersOutOfOffice = False\n\n    if req_body.get('AddIncidentComments', True) and base_object.IncidentAvailable:\n        \n        html_table = data.list_to_html_table(oof.DetailedResults)\n\n        comment = f'''A total of {oof.UsersOutOfOffice} users have out of office messages set.<br>{html_table}'''\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and oof.UsersOutOfOffice > 0 and base_object.IncidentAvailable:\n        task_result = rest.add_incident_task(base_object, req_body.get('QueryDescription', 'Review User Out of Office messages'), req_body.get('IncidentTaskInstructions'))\n\n    return Response(oof)", "\ndef append_disabled(oof, upn):\n    oof.DetailedResults.append({'ExternalMessage': '', 'InternalMessage': '', 'OOFStatus': 'disabled', 'UPN': upn})\n\ndef append_unknown(oof, upn):\n    oof.DetailedResults.append({'ExternalMessage': '', 'InternalMessage': '', 'OOFStatus': 'unknown', 'UPN': upn})\n\ndef append_enabled(oof, upn, internal, external):\n    clean_html = re.compile('<.*?>')\n    replace_nbsp = re.compile('&nbsp;|\\\\n')\n    int_msg = re.sub(replace_nbsp, ' ', re.sub(clean_html, '', internal))\n    ext_msg = re.sub(replace_nbsp, ' ', re.sub(clean_html, '', external))\n    oof.DetailedResults.append({'ExternalMessage': ext_msg, 'InternalMessage': int_msg, 'OOFStatus': 'enabled', 'UPN': upn})", ""]}
{"filename": "modules/ueba.py", "chunked_list": ["from classes import BaseModule, Response, UEBAModule\nfrom shared import rest, data\nimport ast\n\ndef execute_ueba_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, BaseModuleBody, IncidentTaskInstructions\n    #LookbackInDays, MinimumInvestigationPriority\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    ueba_object = UEBAModule()\n\n    lookback = req_body.get('LookbackInDays', 14)\n    min_priority = req_body.get('MinimumInvestigationPriority', 3)\n\n    query = f'''let minPriority = {min_priority};\nlet lookback = {lookback}d;\n{base_object.get_account_kql_table()}let accountIds = accountEntities\n| summarize UserNames=make_set(SamAccountName), UPNs=make_set(UserPrincipalName)\n| extend ids = array_concat(UserNames, UPNs);\nlet userDetails = BehaviorAnalytics\n| where TimeGenerated > ago(lookback)\n| join kind=inner (accountEntities) on UserPrincipalName\n| where InvestigationPriority >= minPriority or isnotnull(DevicesInsights.ThreatIntelIndicatorType) \n| summarize InvestigationPrioritySum=sum(InvestigationPriority), InvestigationPriorityAverage=avg(InvestigationPriority), InvestigationPriorityMax=max(InvestigationPriority), ThreatIntelMatches=countif(isnotnull(DevicesInsights.ThreatIntelIndicatorType)), EventCount=count() by UserPrincipalName;\nlet userAnomalies = Anomalies\n| where TimeGenerated > ago(lookback)\n| where UserPrincipalName in~ (accountIds) or UserName in~ (accountIds)\n| mv-expand todynamic(Tactics)\n| summarize AnomalyTactics=make_set(Tactics), AnomalyCount=dcount(Id, 4)\n| extend UserPrincipalName=\"Total\";\nuserDetails\n| summarize InvestigationPrioritySum=sum(InvestigationPrioritySum), InvestigationPriorityAverage=avg(InvestigationPriorityAverage), InvestigationPriorityMax=coalesce(max(InvestigationPriorityMax),int(0)), ThreatIntelMatches=sum(ThreatIntelMatches), EventCount=sum(EventCount)\n| extend UserPrincipalName=\"Total\"\n| join kind=leftouter userAnomalies on UserPrincipalName\n| extend AnomalyTacticsCount = toint(array_length(AnomalyTactics))\n| union userDetails\n| project-away UserPrincipalName1\n| extend InvestigationPriorityAverage=iff(isnan(InvestigationPriorityAverage), toreal(0), round(toreal(InvestigationPriorityAverage),2))'''\n\n    results = rest.execute_la_query(base_object, query, lookback)\n\n    details = list(filter(lambda x: x['UserPrincipalName'] != 'Total', results))\n\n    for detail in details:\n        detail.pop('AnomalyTactics')\n        detail.pop('AnomalyCount')\n        detail.pop('AnomalyTacticsCount')\n\n    total = list(filter(lambda x: x['UserPrincipalName'] == 'Total', results))[0]\n\n    ueba_object.AllEntityEventCount = total['EventCount']\n    ueba_object.AllEntityInvestigationPriorityAverage = total['InvestigationPriorityAverage']\n    ueba_object.AllEntityInvestigationPriorityMax = total['InvestigationPriorityMax']\n    ueba_object.AllEntityInvestigationPrioritySum = total['InvestigationPrioritySum']\n    ueba_object.AnomaliesFound = bool(total['AnomalyCount'])\n    ueba_object.AnomalyCount = total['AnomalyCount']\n    ueba_object.AnomalyTactics = ast.literal_eval(total['AnomalyTactics'])\n    ueba_object.AnomalyTacticsCount = len(ueba_object.AnomalyTactics)\n    ueba_object.DetailedResults = details\n    ueba_object.InvestigationPrioritiesFound = bool(total['EventCount'])\n    ueba_object.ThreatIntelFound = bool(total['ThreatIntelMatches'])\n    ueba_object.ThreatIntelMatchCount = total['ThreatIntelMatches']\n\n    if req_body.get('AddIncidentComments', True) and base_object.IncidentAvailable:\n        \n        html_table = data.list_to_html_table(results)\n\n        comment = f'A total of {ueba_object.AllEntityEventCount} matching UEBA events, {ueba_object.ThreatIntelMatchCount} \\\n            UEBA Threat Intellgience matches and {ueba_object.AnomalyCount} anomalies were found.<br>{html_table}'\n        \n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and (ueba_object.InvestigationPrioritiesFound or ueba_object.ThreatIntelFound or ueba_object.AnomaliesFound) and base_object.IncidentAvailable:\n        task_result = rest.add_incident_task(base_object, 'Review UEBA Matches', req_body.get('IncidentTaskInstructions'))\n\n    return Response(ueba_object)", ""]}
{"filename": "modules/relatedalerts.py", "chunked_list": ["from classes import BaseModule, Response, RelatedAlertsModule, STATError\nfrom shared import rest, data\nimport datetime as dt\nimport json, copy\n\ndef execute_relatedalerts_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, BaseModuleBody, IncidentTaskInstructions\n    #LookbackInDays, CheckAccountEntityMatches, CheckHostEntityMatches, CheckIPEntityMatches, AlertKQLFilter\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    related_alerts = RelatedAlertsModule()\n\n    check_accounts = req_body.get('CheckAccountEntityMatches', True)\n    check_ips = req_body.get('CheckIPEntityMatches', True)\n    check_hosts = req_body.get('CheckHostEntityMatches', True)\n    alert_filter = req_body.get('AlertKQLFilter')\n    lookback = req_body.get('LookbackInDays', 14)\n\n    if alert_filter is None:\n        alert_filter = '// No Custom Alert Filter Provided'\n\n    for rule in base_object.RelatedAnalyticRuleIds:\n        path = rule + '?api-version=2023-02-01'\n        try:\n            rule_data = json.loads(rest.rest_call_get(base_object, 'arm', path).content)\n        except STATError:\n            pass\n        else:\n            if rule_data.get('kind', '').lower() == 'fusion':\n                related_alerts.FusionIncident = True\n                break         \n\n    query = f'''let lookback = {str(lookback)}d;\nlet currentIncidentAlerts = dynamic({str(base_object.get_alert_ids())});\nlet isFusionIncident = {related_alerts.FusionIncident};\nlet severityOrder = datatable (AlertSeverity:string, Order:int)['Informational', 1, 'Low', 2, 'Medium', 3, 'High', 4];\n{base_object.get_account_kql_table()}let accounts = toscalar(accountEntities\n| where {check_accounts}\n| extend UPNName = split(UserPrincipalName,'@')[0]\n| extend EntityData = pack_array(UserPrincipalName, SamAccountName, ObjectSID, AADUserId, UPNName)\n| mv-apply EntityData on (where isnotempty(EntityData))\n| summarize EntityData=make_set(EntityData));\n{base_object.get_ip_kql_table()}let ips = toscalar(ipEntities\n| where {check_ips}\n| project IPAddress\n| summarize EntityData=make_set(IPAddress));\n{base_object.get_host_kql_table()}let hosts = toscalar(hostEntities\n| where {check_hosts}\n| project FQDN, Hostname\n| extend EntityData = pack_array(FQDN, Hostname)\n| mv-apply EntityData on (where isnotempty(EntityData))\n| summarize EntityData=make_set(EntityData));\nSecurityAlert \n| where TimeGenerated > ago(lookback) \n| summarize arg_max(TimeGenerated, *) by SystemAlertId \n| where SystemAlertId !in (currentIncidentAlerts) or isFusionIncident\n| mv-expand todynamic(Entities) \n{alert_filter}\n| where Entities has_any (accounts) or ( Entities has_any (ips) and Entities.Type == \"ip\") or Entities has_any (hosts) or (SystemAlertId in (currentIncidentAlerts) and isFusionIncident)\n| extend AccountEntityMatch = iff(Entities has_any (accounts), true, false), HostEntityMatch = iff(Entities has_any (hosts), true, false), IPEntityMatch = iff(Entities has_any (ips) , true, false) \n| summarize AccountEntityMatch = max(AccountEntityMatch), IPEntityMatch=max(IPEntityMatch),HostEntityMatch=max(HostEntityMatch) by StartTime, DisplayName, AlertSeverity, SystemAlertId, ProviderName, Tactics\n| join kind=leftouter severityOrder on AlertSeverity\n| sort by Order desc\n| project-away Order, AlertSeverity1'''\n\n    results = rest.execute_la_query(base_object, query, lookback)\n\n    account_matches = filter_alerts(results, 'AccountEntityMatch')\n    ip_matches = filter_alerts(results, 'IPEntityMatch')\n    host_matches = filter_alerts(results, 'HostEntityMatch')\n\n    tactics_list = []\n    for alert in results:\n        tactics = alert.get('Tactics').split(',')\n        for tactic in tactics:\n            tactics_list.append(tactic.strip().replace(' ', ''))\n\n    tactics_list = list(set(tactics_list))\n\n    related_alerts.AllTactics =  tactics_list\n    related_alerts.AllTacticsCount = len(tactics_list)\n    related_alerts.DetailedResults = copy.deepcopy(results)\n    related_alerts.HighestSeverityAlert = data.return_highest_value(results, 'AlertSeverity')\n    related_alerts.RelatedAccountAlertsCount = len(account_matches)\n    related_alerts.RelatedAccountAlertsFound = bool(account_matches)\n    related_alerts.RelatedAlertsCount = len(results)\n    related_alerts.RelatedAlertsFound = bool(results)\n    related_alerts.RelatedHostAlertsCount = len(host_matches)\n    related_alerts.RelatedHostAlertsFound = bool(host_matches)\n    related_alerts.RelatedIPAlertsCount = len(ip_matches)\n    related_alerts.RelatedIPAlertsFound = bool(ip_matches)\n\n    if req_body.get('AddIncidentComments', True) and base_object.IncidentAvailable:\n        \n        ### Alert Linking\n\n        arm_id = base_object.IncidentARMId.split('/')\n        utc_now = dt.datetime.utcnow()\n        utc_start = utc_now - dt.timedelta(days=lookback)\n\n        link_template = f'<a href=\"https://portal.azure.com/#blade/Microsoft_Azure_Monitoring_Logs/LogsBlade/scope/%7B%22resources%22%3A%5B%7B%22resourceId%22%3A%22%2Fsubscriptions%2F{arm_id[2]}%2FresourceGroups%2F{arm_id[4]}%2Fproviders%2FMicrosoft.OperationalInsights%2Fworkspaces%2F{arm_id[8]}%22%7D%5D%7D/initiator/ASI_Hunting/query/SecurityAlert%0A%7C%20where%20SystemAlertId%20%3D%3D%20%22[col_value]%22%0A%7C%20summarize%20arg_max%28TimeGenerated%2C%20%2A%29%20by%20SystemAlertId%0A/timespanInIsoFormat/{utc_start.isoformat()}%2F{utc_now.isoformat()}\">[col_value]</a>'\n        linked_alerts = data.update_column_value_in_list(results, 'SystemAlertId', link_template)\n        html_table = data.list_to_html_table(linked_alerts, escape_html=False)\n\n        #html_table = data.list_to_html_table(results)\n        \n        comment = f'''A total of {related_alerts.RelatedAlertsCount} related alerts were found.<br>{html_table}'''\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and related_alerts.RelatedAlertsFound and base_object.IncidentAvailable:\n        task_result = rest.add_incident_task(base_object, 'Review Related Alerts', req_body.get('IncidentTaskInstructions'))\n\n    return Response(related_alerts)", "\ndef filter_alerts(results, match_key):\n    return list(filter(lambda x: x[match_key], results))\n"]}
{"filename": "modules/aadrisks.py", "chunked_list": ["from classes import BaseModule, Response, AADModule, STATError, STATNotFound\nfrom shared import rest, data\nimport json\n\ndef execute_aadrisks_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, Entities, IncidentTaskInstructions, LookbackInDays, MFAFailureLookup, MFAFraudLookup, SuspiciousActivityReportLookup\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    aadrisks_object = AADModule()\n\n    for account in base_object.Accounts:\n        userid = account.get('id')\n        if userid:\n            upn = account.get('userPrincipalName')\n            current_account = {\n                'UserFailedMFACount': None,\n                'UserMFAFraudCount': None,\n                'SuspiciousActivityReportCount' : None,\n                'UserId': f'{userid}',\n                'UserPrincipalName': f'{upn}',\n                'UserRiskLevel': 'unknown'\n            }\n            path = f'/v1.0/identityProtection/riskyUsers/{userid}'\n            try:\n                user_risk_level = json.loads(rest.rest_call_get(base_object, api='msgraph', path=path).content)['riskLevel']\n            except STATNotFound:\n                pass\n            else:\n                current_account['UserRiskLevel'] = user_risk_level\n\n            if req_body.get('MFAFailureLookup', True):\n                MFAFailureLookup_query = f'SigninLogs\\n| where ResultType == \\\"500121\\\"\\n| where UserId== \\\"{userid}\\\"\\n| summarize Count=count() by UserPrincipalName'\n                MFAFailureLookup_results = rest.execute_la_query(base_object, MFAFailureLookup_query, req_body.get('LookbackInDays'))\n                if MFAFailureLookup_results:\n                    current_account['UserFailedMFACount'] = MFAFailureLookup_results[0]['Count']\n                else:\n                    current_account['UserFailedMFACount'] = 0\n            if req_body.get('MFAFraudLookup', True):\n                MFAFraudLookup_query = f'AuditLogs \\n| where OperationName in (\\\"Fraud reported - user is blocked for MFA\\\",\\\"Fraud reported - no action taken\\\")\\n| where ResultDescription == \\\"Successfully reported fraud\\\"\\n| extend Id= tostring(parse_json(tostring(InitiatedBy.user)).id)\\n| where Id == \\\"{userid}\\\"\\n| summarize Count=count() by Id'\n                MFAFraudLookup_results = rest.execute_la_query(base_object, MFAFraudLookup_query, req_body.get('LookbackInDays'))\n                if MFAFraudLookup_results:\n                    current_account['UserMFAFraudCount'] = MFAFraudLookup_results[0]['Count']\n                else:\n                    current_account['UserMFAFraudCount'] = 0\n            if req_body.get('SuspiciousActivityReportLookup', True):\n                SuspiciousActivityReportLookup_query = f'AuditLogs \\n| where OperationName == \\\"Suspicious activity reported\\\"\\n| where ResultDescription == \\\"Successfully reported suspicious activity\\\"\\n| extend Id= tostring(parse_json(tostring(InitiatedBy.user)).id)\\n| where Id == \\\"{userid}\\\"\\n| summarize Count=count() by Id'\n                SuspiciousActivityReportLookup_results = rest.execute_la_query(base_object, SuspiciousActivityReportLookup_query, req_body.get('LookbackInDays'))\n                if SuspiciousActivityReportLookup_results:\n                    current_account['SuspiciousActivityReportCount'] = SuspiciousActivityReportLookup_results[0]['Count']\n                else:\n                    current_account['SuspiciousActivityReportCount'] = 0\n            aadrisks_object.DetailedResults.append(current_account)\n\n    entities_nb = len(aadrisks_object.DetailedResults)\n    if entities_nb != 0:\n        aadrisks_object.AnalyzedEntities = entities_nb\n        aadrisks_object.FailedMFATotalCount = sum(total['UserFailedMFACount'] for total in aadrisks_object.DetailedResults)\n        aadrisks_object.MFAFraudTotalCount = sum(total['UserMFAFraudCount'] for total in aadrisks_object.DetailedResults)\n        aadrisks_object.SuspiciousActivityReportTotalCount = sum(total['SuspiciousActivityReportCount'] for total in aadrisks_object.DetailedResults)\n        aadrisks_object.HighestRiskLevel = data.return_highest_value(aadrisks_object.DetailedResults,'UserRiskLevel')\n\n    if req_body.get('AddIncidentComments', True):\n        html_table = data.list_to_html_table(aadrisks_object.DetailedResults)\n        comment = f'<h3>Azure AD Risks Module</h3>'\n        comment += f'A total of {aadrisks_object.AnalyzedEntities} entities were analyzed.<br />'\n        comment += f'<ul><li>Highest risk detected: {aadrisks_object.HighestRiskLevel}</li>'\n        comment += f'<li>Total MFA failures: {aadrisks_object.FailedMFATotalCount} </li>'\n        comment += f'<li>Total MFA frauds: {aadrisks_object.MFAFraudTotalCount} </li></ul><br />'\n        comment += f'<li>Total Suspicious Activity reports: {aadrisks_object.SuspiciousActivityReportTotalCount} </li></ul><br />'\n        comment += f'{html_table}'\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and data.coalesce(aadrisks_object.FailedMFATotalCount,0) > 0 or data.coalesce(aadrisks_object.MFAFraudTotalCount,0) > 0 or data.coalesce(aadrisks_object.SuspiciousActivityReportTotalCount,0) > 0 or ( aadrisks_object.HighestRiskLevel != 'None' and aadrisks_object.HighestRiskLevel != 'Unknown'):\n        task_result = rest.add_incident_task(base_object, req_body.get('QueryDescription', 'Review users Azure AD risks level, MFA failures and fraud reports.'), req_body.get('IncidentTaskInstructions'))\n\n    return Response(aadrisks_object)"]}
{"filename": "modules/mde.py", "chunked_list": ["from classes import BaseModule, Response, MDEModule\nfrom shared import rest, data\nimport json\n\ndef execute_mde_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, Entities, IncidentTaskInstructions\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n    lookback = req_body.get('LookbackInDays', 7)\n    mde_object = MDEModule()\n\n    detailed_accounts = []\n    for account in base_object.Accounts:\n        usersid = account.get('onPremisesSecurityIdentifier')\n        if usersid:\n            userid = account.get('id')\n            userupn = account.get('userPrincipalName')\n            current_account = {\n                'UserDevices': [],\n                'UserHighestExposureLevel': 'Unknown',\n                'UserHighestRiskScore': 'Unknown',\n                'UserId': f'{userid}',\n                'UserPrincipalName': f'{userupn}',\n                'UserSid': f'{usersid}'\n            }\n            get_devices = ('DeviceLogonEvents'\n                        f'| where Timestamp > ago({lookback}d)'\n                        f'| where AccountSid =~ \"{usersid}\"'\n                        '| where LogonType in (\"Interactive\",\"RemoteInteractive\")'\n                        '| distinct DeviceName, DeviceId')\n            results = rest.execute_m365d_query(base_object, get_devices)\n            if results:\n                current_account['UserDevices'] = []\n                #Split the results into chuncks of 30 in case there are many devices associated with that user\n                max_device_per_query = 30\n                splited_results = [results[i:i+max_device_per_query] for i in range(0, len(results), max_device_per_query)]\n                for result_chunck in splited_results:\n                    idlist = ','.join(['\"'+item['DeviceId']+'\"' for item in result_chunck])\n                    pathwithfilter = f'/api/machines?$filter=id+in+({idlist})&$select=id,computerDnsName,riskScore,exposureLevel'\n                    devicedata = json.loads(rest.rest_call_get(base_object, 'mde', f'{pathwithfilter}').content)\n                    if len(devicedata['value']) > 0:\n                        current_account['UserDevices'] += devicedata['value']\n            current_account['UserHighestExposureLevel'] = data.return_highest_value(current_account['UserDevices'],'exposureLevel')\n            current_account['UserHighestRiskScore'] = data.return_highest_value(current_account['UserDevices'],'riskScore') \n            detailed_accounts.append( current_account) \n    mde_object.DetailedResults['Accounts'] = detailed_accounts\n    mde_object.UsersHighestExposureLevel = data.return_highest_value(mde_object.DetailedResults['Accounts'],'UserHighestExposureLevel') \n    mde_object.UsersHighestRiskScore = data.return_highest_value(mde_object.DetailedResults['Accounts'],'UserHighestRiskScore')\n    \n    detailed_hosts = []\n    for host in base_object.Hosts:\n        hostmdeid = host.get('MdatpDeviceId')\n        hostfqdn = host.get('FQDN')\n        if hostmdeid or hostfqdn:\n            if hostmdeid:\n                queryfilter = f\"id+eq+'{hostmdeid}'\"\n            else:\n                queryfilter = f\"computerDnsName+eq+'{hostfqdn}'\"\n            pathwithfilter = f\"/api/machines?$filter={queryfilter}&$select=id,computerDnsName,riskScore,exposureLevel\"\n            devicedata = json.loads(rest.rest_call_get(base_object, 'mde', f'{pathwithfilter}').content)\n            if len(devicedata['value']) > 0:\n                detailed_hosts += devicedata['value']\n    mde_object.DetailedResults['Hosts'] = detailed_hosts\n    mde_object.HostsHighestExposureLevel = data.return_highest_value(mde_object.DetailedResults['Hosts'],'exposureLevel') \n    mde_object.HostsHighestRiskScore = data.return_highest_value(mde_object.DetailedResults['Hosts'],'riskScore')\n    \n    detailed_ips = []\n    for ip in base_object.IPs:\n        ipaddress = ip.get('Address')\n        get_devices = ('DeviceNetworkInfo'\n                    f'| where Timestamp > ago({lookback}d)'\n                    '| summarize arg_max(Timestamp,*) by DeviceId'\n                    '| extend IPs = todynamic(IPAddresses)'\n                    '| mv-expand IPs'\n                    '| evaluate bag_unpack(IPs)'\n                    '| extend IPAddress = column_ifexists(\"IPAddress\",\"\")'\n                    f'| where IPAddress == \"{ipaddress}\"'\n                    '| distinct IPAddress, DeviceId'\n                    '| top 30 by DeviceId') #Only returns 30 devices\n        results = rest.execute_m365d_query(base_object, get_devices)\n        if results:\n            idlist = ','.join(['\"'+item['DeviceId']+'\"' for item in results])\n            pathwithfilter = f'/api/machines?$filter=id+in+({idlist})&$select=id,computerDnsName,riskScore,exposureLevel'\n            devicedata = json.loads(rest.rest_call_get(base_object, 'mde', f'{pathwithfilter}').content)\n            if len(devicedata['value']) > 0:\n                detailed_ips += devicedata['value']\n    mde_object.DetailedResults['IPs'] = detailed_ips\n    mde_object.IPsHighestExposureLevel = data.return_highest_value(mde_object.DetailedResults['IPs'],'exposureLevel') \n    mde_object.IPsHighestRiskScore = data.return_highest_value(mde_object.DetailedResults['IPs'],'riskScore')\n\n    nb_accounts = len(mde_object.DetailedResults['Accounts'])\n    nb_hosts = len(mde_object.DetailedResults['Hosts'])\n    nb_ips = len(mde_object.DetailedResults['IPs'])\n    entities_nb = nb_accounts + nb_hosts + nb_ips\n    if entities_nb != 0:\n        mde_object.AnalyzedEntities = entities_nb\n\n    if req_body.get('AddIncidentComments', True):\n        comment = f'<h3>Microsoft Defender for Endpoint Module</h3>'\n        comment += f'A total of {mde_object.AnalyzedEntities} entities were analyzed (Accounts: {nb_accounts} - Hosts: {nb_hosts} - IPs: {nb_ips}).<br />'\n        account_link = f'<a href=\"https://security.microsoft.com/user/?aad=[col_value]&tid={base_object.TenantId}\" target=\"_blank\">[col_value]</a>'\n        host_link = f'<a href=\"https://security.microsoft.com/machines/[col_value]?tid={base_object.TenantId}\" target=\"_blank\">[col_value]</a>'\n\n        if nb_accounts > 0:\n            linked_accounts_list = data.update_column_value_in_list([{k: v for k, v in DetailedResults.items() if k != 'UserDevices'} for DetailedResults in mde_object.DetailedResults['Accounts']], 'UserId', account_link)\n            html_table_accounts = data.list_to_html_table(linked_accounts_list, escape_html=False)\n            comment += f'<ul><li>Maximum Risk Score of devices used by the user entities: {mde_object.UsersHighestRiskScore}</li>'\n            comment += f'<li>Maximum Exposure Level of devices used by the user entities: {mde_object.UsersHighestExposureLevel}</li></ul>'\n            comment += f'{html_table_accounts}'\n        if nb_hosts > 0:\n            linked_host_list = data.update_column_value_in_list(mde_object.DetailedResults['Hosts'], 'id', host_link)\n            html_table_hosts = data.list_to_html_table(linked_host_list, escape_html=False)\n            comment += f'<ul><li>Maximum Risk Score of devices present in the incident: {mde_object.HostsHighestRiskScore}</li>'\n            comment += f'<li>Maximum Exposure Level of devices present in the incident: {mde_object.HostsHighestExposureLevel}</li></ul>'\n            comment += f'{html_table_hosts}'\n        if nb_ips > 0:\n            linked_ip_list = data.update_column_value_in_list(mde_object.DetailedResults['IPs'], 'id', host_link)\n            html_table_ips = data.list_to_html_table(linked_ip_list, escape_html=False)\n            comment += f'<ul><li>Maximum Risk Score of IPs present in the incident: {mde_object.IPsHighestRiskScore}</li>'\n            comment += f'<li>Maximum Exposure Level of IPs present in the incident: {mde_object.IPsHighestExposureLevel}</li></ul>'\n            comment += f'{html_table_ips}'\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    return Response(mde_object)", ""]}
{"filename": "modules/kql.py", "chunked_list": ["from classes import BaseModule, Response, KQLModule\nfrom shared import rest, data\n\ndef execute_kql_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, Entities, IncidentTaskInstructions, KQLQuery, LookbackInDays, QueryDescription, RunQueryAgainst\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    kql_object = KQLModule()\n\n    arm_id = f'let incidentArmId = \"{base_object.IncidentARMId}\";\\n'\n    ip_entities = base_object.get_ip_kql_table()\n    account_entities = base_object.get_account_kql_table()\n    host_entities = base_object.get_host_kql_table()\n\n    query = arm_id + ip_entities + account_entities + host_entities + req_body['KQLQuery']\n\n    if req_body.get('RunQueryAgainst') == 'M365':\n        results = rest.execute_m365d_query(base_object, query)\n    else:\n        results = rest.execute_la_query(base_object, query, req_body['LookbackInDays'])\n\n    kql_object.DetailedResults = results\n    kql_object.ResultsCount = len(results)\n    kql_object.ResultsFound = bool(results)\n\n    if req_body.get('AddIncidentComments', True) and base_object.IncidentAvailable:\n        \n        html_table = data.list_to_html_table(results)\n        if req_body.get('QueryDescription'):\n            query_description = req_body.get('QueryDescription') + '<p>'\n        else:\n            query_description = ''\n\n        comment = f'''{query_description}A total of {kql_object.ResultsCount} records were found in the {req_body.get('RunQueryAgainst')} search.<br>{html_table}'''\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and kql_object.ResultsFound and base_object.IncidentAvailable:\n        task_result = rest.add_incident_task(base_object, req_body.get('QueryDescription', 'Review KQL Query Results'), req_body.get('IncidentTaskInstructions'))\n\n    return Response(kql_object)"]}
{"filename": "modules/createincident.py", "chunked_list": ["from classes import BaseModule, Response, STATError, CreateIncident\nfrom shared import rest, data\nimport json\nimport uuid\n\ndef execute_create_incident (req_body):\n    \n    #Inputs: Severity, Title, Description\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    if base_object.IncidentTriggered:\n        raise STATError('Incident creation is only supported when starting from an alert triggered Playbook.')\n    \n    create = CreateIncident()\n\n    create.Title = req_body.get('Title', base_object.Alerts[0]['properties'].get('alertDisplayName', 'STAT Genearted Incident'))\n    create.Description = req_body.get('Description', base_object.Alerts[0]['properties'].get('description', ''))\n    create.Severity = req_body.get('Severity', base_object.Alerts[0]['properties'].get('severity', 'Medium'))\n\n    \n    create.AlertARMId = base_object.Alerts[0]['id']\n    create.IncidentARMId = base_object.WorkspaceARMId + '/providers/Microsoft.SecurityInsights/incidents/' + str(uuid.uuid4())\n\n    incident_data = {\n        'properties': {\n            'description': create.Description,\n            'title': create.Title,\n            'severity': create.Severity,\n            'status': 'New'\n        }\n    }\n\n    incident = json.loads(rest.rest_call_put(base_object, 'arm', create.IncidentARMId + '?api-version=2023-02-01', incident_data).content)\n    create.IncidentNumber = incident['properties']['incidentNumber']\n    create.IncidentUrl = incident['properties']['incidentUrl']\n\n    link_path = create.IncidentARMId + '/relations/' + str(uuid.uuid4()) + '?api-version=2023-02-01'\n    link_data = {\n        'properties': {\n            'relatedResourceId': create.AlertARMId\n        }\n    }\n    alert_link = rest.rest_call_put(base_object, 'arm', link_path, link_data)\n\n    return Response(create)"]}
{"filename": "modules/__init__.py", "chunked_list": ["import logging\nimport traceback as tb\nimport json\nimport azure.functions as func\nfrom classes import STATError\nfrom shared import coordinator\n\ndef main(req: func.HttpRequest, context: func.Context) -> func.HttpResponse:\n    logging.debug('STAT Function started processing a request.')\n    module_name = req.route_params.get('modulename')\n\n    try:\n        req_body = req.get_json()\n    except ValueError:\n        logging.error(msg={'Error': 'Invalid Request Body', 'InvocationId': context.invocation_id})\n        return func.HttpResponse(json.dumps({'Error': 'Invalid Request Body', 'InvocationId': context.invocation_id}), status_code=400, mimetype='application/json')\n\n    try:\n        return_data = coordinator.initiate_module(module_name=module_name, req_body=req_body)\n    except STATError as e:\n        trace = tb.format_exception(None, e, e.__traceback__)\n        logging.error(msg={'Error': e.error, 'SourceError': e.source_error, 'InvocationId': context.invocation_id}, exc_info=True)\n        return func.HttpResponse(json.dumps({'Error': e.error, 'InvocationId': context.invocation_id, 'SourceError': e.source_error, 'Traceback': trace}), status_code=e.status_code, mimetype='application/json')\n    except Exception as e:\n        trace = tb.format_exception(None, e, e.__traceback__)\n        logging.error(e, exc_info=True)\n        return func.HttpResponse(json.dumps({'Error': 'Module processing failed, an unknown exception has occurred.', 'InvocationId': context.invocation_id, 'Traceback': trace}), status_code=400, mimetype='application/json')\n    except:\n        logging.error(msg={'Error': 'Module processing failed, an unknown exception has occurred.', 'InvocationId': context.invocation_id}, exc_info=True)\n        return func.HttpResponse(json.dumps({'Error': 'Module processing failed, an unknown exception has occurred.', 'InvocationId': context.invocation_id}), status_code=400, mimetype='application/json')\n    \n    return func.HttpResponse(body=json.dumps(return_data.body.__dict__), status_code=return_data.statuscode, mimetype=return_data.contenttype)", ""]}
{"filename": "modules/playbook.py", "chunked_list": ["from classes import BaseModule, Response, STATError, RunPlaybook\nfrom shared import rest\n\ndef execute_playbook_module (req_body):\n\n    #Inputs AddIncidentComments, LogicAppResourceId, PlaybookName, TenantId\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    playbook = RunPlaybook()\n\n    playbook.LogicAppArmId = req_body.get('LogicAppResourceId')\n    playbook.TenantId = req_body.get('TenantId')\n    playbook.PlaybookName = req_body.get('PlaybookName', base_object.IncidentARMId)\n    playbook.IncidentArmId = base_object.IncidentARMId\n\n    if not playbook.TenantId or not playbook.LogicAppArmId:\n        raise STATError(f'Missing logic app id {playbook.LogicAppArmId} or tenant id {playbook.TenantId}.')\n    \n    if not base_object.IncidentAvailable:\n        raise STATError(f'There is no incident associated with this STAT triage.  Unable to execute Incident playbook.')\n\n    path = f'{base_object.IncidentARMId}/runPlaybook?api-version=2023-06-01-preview'\n    body = {\n        'logicAppsResourceId': playbook.LogicAppArmId,\n        'tenantId': playbook.TenantId\n    }\n\n    try:\n        response = rest.rest_call_post(base_object, api='arm', path=path, body=body)\n    except STATError as e:\n        if req_body.get('AddIncidentComments', True):\n            comment = f'The Sentinel Triage AssistanT failed to start the playbook {playbook.PlaybookName} on this incident.<br>Playbook resource id: {playbook.LogicAppArmId}'\n            rest.add_incident_comment(base_object, comment)\n        if e.source_error['status_code'] == 400:\n            raise STATError(f'{e.error}. This is usually due to missing permissions on the Playbook you are attempting to run. '\n                            'The identity used by the STAT function must have the Microsoft Sentinel Playbook Operator RBAC role and Azure Security Insights must have '\n                            'the Microsoft Sentinel Automation Contributor role on the resource group containing the playbook.', e.source_error, e.status_code)\n        else:\n            raise STATError(e.error, e.source_error, e.status_code)\n\n    if req_body.get('AddIncidentComments', True):\n        \n        comment = f'The Playbook {playbook.PlaybookName} was successfully started on this incident by the Microsoft Sentinel Triage AssistanT (STAT)<br>Playbook resource id: {playbook.LogicAppArmId}'\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    return Response(playbook)"]}
{"filename": "modules/watchlist.py", "chunked_list": ["from classes import BaseModule, Response, WatchlistModule, STATError\nfrom shared import rest, data\n\ndef execute_watchlist_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, BaseModuleBody, IncidentTaskInstructions, WatchlistKey, WatchlistKeyDataType, WatchlistName\n    # WatchlistKeyDataType: UPN, IP, CIDR, FQDN\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    watchlist_object = WatchlistModule()\n\n    watchlist_datatype = req_body.get('WatchlistKeyDataType')\n    watchlist_key = req_body.get('WatchlistKey')\n    watchlist_object.WatchlistName = req_body.get('WatchlistName')\n\n    #Check if the WatchlistName is valid, otherwise the query will succeed and never find anything on the watchlist\n    watchlist_check = f'_GetWatchlistAlias\\n| where WatchlistAlias == \"{watchlist_object.WatchlistName}\"'\n    check_watchlist = rest.execute_la_query(base_object, watchlist_check, 7)\n\n    if not check_watchlist:\n        raise STATError(f'The watchlist name {watchlist_object.WatchlistName} is invalid.', {})\n    \n    if watchlist_datatype == 'UPN':\n        account_entities = base_object.get_account_kql_table()\n        query = account_entities +  f'''accountEntities\n| project UserPrincipalName\n| extend UserPrincipalName = tolower(UserPrincipalName)\n| join kind=leftouter (_GetWatchlist(\"{watchlist_object.WatchlistName}\")\n| extend {watchlist_key} = tolower({watchlist_key})) on $left.UserPrincipalName == $right.{watchlist_key}\n| extend OnWatchlist = iff(isempty(_DTItemId), false, true)\n| project OnWatchlist, UserPrincipalName'''\n        results = rest.execute_la_query(base_object, query, 7)\n        \n    elif watchlist_datatype == 'IP':\n        ip_entities = base_object.get_ip_kql_table()\n        query = ip_entities + f'''ipEntities\n| project IPAddress\n| join kind=leftouter (_GetWatchlist('{watchlist_object.WatchlistName}')) on $left.IPAddress == $right.{watchlist_key}\n| extend OnWatchlist = iff(isempty(_DTItemId), false, true)\n| project OnWatchlist, IPAddress'''\n        results = rest.execute_la_query(base_object, query, 7)\n\n    elif watchlist_datatype == 'CIDR':\n        ip_entities = base_object.get_ip_kql_table()\n        query = ip_entities + f'''ipEntities\n| project IPAddress\n| evaluate ipv4_lookup(_GetWatchlist('{watchlist_object.WatchlistName}'), IPAddress, {watchlist_key}, true)\n| extend OnWatchlist = iff(isempty(_DTItemId), false, true)\n| project OnWatchlist, IPAddress'''\n        results = rest.execute_la_query(base_object, query, 7)\n        \n    elif watchlist_datatype == 'FQDN':\n        host_entities = base_object.get_host_kql_table()\n        query = host_entities + f'''let watchListItems = materialize (_GetWatchlist('{watchlist_object.WatchlistName}')\n| project SearchKey = tolower({watchlist_key}), _DTItemId\n| extend Hostname=tolower(tostring(split(SearchKey, '.')[0])));\nhostEntities\n| extend FQDNKey = tolower(FQDN), HostKey = tolower(Hostname)\n| join kind=leftouter (watchListItems) on $left.FQDNKey == $right.SearchKey\n| join kind=leftouter (watchListItems) on $left.HostKey == $right.Hostname\n| extend OnWatchlist = iff(isempty(_DTItemId) and isempty(_DTItemId1), false, true)\n| project OnWatchlist, FQDN'''\n        results = rest.execute_la_query(base_object, query, 7)\n\n    else:\n        raise STATError(f'Invalid WatchlistKeyDataType: {watchlist_datatype}')\n\n    watchlist_entities = list(filter(lambda x: x['OnWatchlist'], results))\n    watchlist_object.EntitiesOnWatchlist = bool(watchlist_entities)\n    watchlist_object.EntitiesOnWatchlistCount = len(watchlist_entities)\n    watchlist_object.DetailedResults = results\n    watchlist_object.EntitiesAnalyzedCount = len(results)\n\n    if req_body.get('AddIncidentComments', True) and base_object.IncidentAvailable:\n        \n        html_table = data.list_to_html_table(results)\n\n        comment = f'''A total of {watchlist_object.EntitiesOnWatchlistCount} records were found on the {watchlist_object.WatchlistName} watchlist.<br>{html_table}'''\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and watchlist_object.EntitiesOnWatchlist and base_object.IncidentAvailable:\n        task_result = rest.add_incident_task(base_object, 'Review Watchlist Matches', req_body.get('IncidentTaskInstructions'))\n\n\n    return Response(watchlist_object)"]}
{"filename": "modules/scoring.py", "chunked_list": ["from classes import *\nfrom shared import data, rest\n\ndef execute_scoring_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, BaseModuleBody, IncidentTaskInstructions, ScoringData\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n", "    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    score = ScoringModule()\n\n    for input_module in req_body['ScoringData']:\n        module_body = input_module['ModuleBody']\n        module = module_body.get('ModuleName')\n        label = input_module.get('ScoreLabel', module)\n        multiplier = input_module.get('ScoreMultiplier', 1)\n        per_item = input_module.get('ScorePerItem', True)", "        multiplier = input_module.get('ScoreMultiplier', 1)\n        per_item = input_module.get('ScorePerItem', True)\n\n        try:\n            score_module(score, module, module_body, per_item, multiplier, label)\n        except BaseException as e:\n            raise STATError(f'Failed to score the module {module} with label {label}', {'Error': str(e)})\n\n    score.DetailedResults = data.sort_list_by_key(score.DetailedResults, 'Score')\n", "    score.DetailedResults = data.sort_list_by_key(score.DetailedResults, 'Score')\n\n    if req_body.get('AddIncidentComments', True) and base_object.IncidentAvailable:\n        \n        html_table = data.list_to_html_table(score.DetailedResults)\n\n        comment = f'''The total calculated risk score is {score.TotalScore}.<br>{html_table}'''\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and score.TotalScore > 0 and base_object.IncidentAvailable:", "\n    if req_body.get('AddIncidentTask', False) and score.TotalScore > 0 and base_object.IncidentAvailable:\n        task_result = rest.add_incident_task(base_object, 'Review Incident Risk Score', req_body.get('IncidentTaskInstructions')) \n\n    return Response(score)\n\ndef score_module(score:ScoringModule, module:str, module_body:dict, per_item:bool, multiplier:int, label:str):\n\n    mitre_list = [\n        {'Tactic': 'Reconnaissance', 'Score': 2},", "    mitre_list = [\n        {'Tactic': 'Reconnaissance', 'Score': 2},\n        {'Tactic': 'ResourceDevelopment', 'Score': 3},\n        {'Tactic': 'InitialAccess', 'Score': 5},\n        {'Tactic': 'Execution', 'Score': 5},\n        {'Tactic': 'Persistence', 'Score': 6},\n        {'Tactic': 'PrivilegeEscalation', 'Score': 8},\n        {'Tactic': 'DefenseEvasion', 'Score': 8},\n        {'Tactic': 'CredentialAccess', 'Score': 8},\n        {'Tactic': 'Discovery', 'Score': 8},", "        {'Tactic': 'CredentialAccess', 'Score': 8},\n        {'Tactic': 'Discovery', 'Score': 8},\n        {'Tactic': 'LateralMovement', 'Score': 9},\n        {'Tactic': 'Collection', 'Score': 9},\n        {'Tactic': 'CommandAndControl', 'Score': 10},\n        {'Tactic': 'Exfiltration', 'Score': 12},\n        {'Tactic': 'Impact', 'Score': 12},\n        {'Tactic': 'InhibitResponseFunction', 'Score': 12},\n        {'Tactic': 'ImpairProcessControl', 'Score': 12}\n    ]", "        {'Tactic': 'ImpairProcessControl', 'Score': 12}\n    ]\n\n    match module:\n        case 'WatchlistModule':\n            score_watchlist(score, module_body, per_item, multiplier, label)\n        case 'AADRisksModule':\n            score_aad(score, module_body, per_item, multiplier, label)\n        case 'FileModule':\n            score_file(score, module_body, multiplier, label)", "        case 'FileModule':\n            score_file(score, module_body, multiplier, label)\n        case 'KQLModule':\n            score_kql(score, module_body, per_item, multiplier, label)\n        case 'MDCAModule' | 'MCASModule':\n            score_mdca(score, module_body, per_item, multiplier, label)\n        case 'MDEModule':\n            score_mde(score, module_body, per_item, multiplier, label)\n        case 'RelatedAlerts':\n            score_alerts(score, module_body, per_item, multiplier, label, mitre_list)", "        case 'RelatedAlerts':\n            score_alerts(score, module_body, per_item, multiplier, label, mitre_list)\n        case 'TIModule':\n            score_ti(score, module_body, per_item, multiplier, label)\n        case 'UEBAModule':\n            score_ueba(score, module_body, per_item, multiplier, label, mitre_list)\n        case 'Custom':\n            score_custom(score, module_body, multiplier)\n        case _:\n            raise STATError(f'Incorrectly formatted data or data from an unsupported module was passed to the Scoring Module, module name: {module}')", "        case _:\n            raise STATError(f'Incorrectly formatted data or data from an unsupported module was passed to the Scoring Module, module name: {module}')\n\ndef score_kql(score:ScoringModule, module_body, per_item, multiplier, label):\n    kql = KQLModule()\n    kql.load_from_input(module_body)\n         \n    if per_item and kql.ResultsCount > 0:\n        module_score = 5 * kql.ResultsCount * multiplier\n    elif kql.ResultsCount > 0:", "        module_score = 5 * kql.ResultsCount * multiplier\n    elif kql.ResultsCount > 0:\n        module_score = 5 * multiplier\n    else:\n        module_score = 0\n\n    score.append_score(score=module_score, label=label)\n\ndef score_watchlist(score:ScoringModule, module_body, per_item, multiplier, label):\n    watchlist = WatchlistModule()", "def score_watchlist(score:ScoringModule, module_body, per_item, multiplier, label):\n    watchlist = WatchlistModule()\n    watchlist.load_from_input(module_body)\n         \n    if per_item and watchlist.EntitiesOnWatchlist:\n        module_score = 10 * watchlist.EntitiesOnWatchlistCount * multiplier\n    elif watchlist.EntitiesOnWatchlist:\n        module_score = 10 * multiplier\n    else:\n        module_score = 0", "    else:\n        module_score = 0\n\n    score.append_score(score=module_score, label=label)\n\ndef score_ti(score:ScoringModule, module_body, per_item, multiplier, label):\n    ti = TIModule()\n    ti.load_from_input(module_body)\n         \n    if per_item and ti.AnyTIFound:", "         \n    if per_item and ti.AnyTIFound:\n        module_score = 10 * ti.TotalTIMatchCount * multiplier\n    elif ti.AnyTIFound:\n        module_score = 10 * multiplier\n    else:\n        module_score = 0\n\n    score.append_score(score=module_score, label=label)\n", "    score.append_score(score=module_score, label=label)\n\ndef score_alerts(score:ScoringModule, module_body, per_item, multiplier, label, mitre_list):\n    alerts = RelatedAlertsModule()\n    alerts.load_from_input(module_body)\n\n    alert_list = [\n        {'AlertSeverity': 'High', 'Score': 10},\n        {'AlertSeverity': 'Medium', 'Score': 5},\n        {'AlertSeverity': 'Low', 'Score': 3},", "        {'AlertSeverity': 'Medium', 'Score': 5},\n        {'AlertSeverity': 'Low', 'Score': 3},\n        {'AlertSeverity': 'Informational', 'Score': 1}\n    ]\n         \n    if per_item and alerts.RelatedAlertsFound:\n        scored_alerts = data.join_lists(left_list=alerts.DetailedResults, right_list=alert_list, left_key='AlertSeverity', right_key='AlertSeverity', kind='left', fill_nan=5)\n        module_score = data.sum_column_by_key(scored_alerts, 'Score') * multiplier\n    elif alerts.RelatedAlertsFound:\n        scored_alerts = data.join_lists(left_list=alerts.DetailedResults, right_list=alert_list, left_key='AlertSeverity', right_key='AlertSeverity', kind='left', fill_nan=1)", "    elif alerts.RelatedAlertsFound:\n        scored_alerts = data.join_lists(left_list=alerts.DetailedResults, right_list=alert_list, left_key='AlertSeverity', right_key='AlertSeverity', kind='left', fill_nan=1)\n        module_score = data.max_column_by_key(scored_alerts, 'Score') * multiplier\n    else:\n        module_score = 0\n\n    score.append_score(score=module_score, label=label)\n\n    if alerts.AllTacticsCount > 0:\n        scored_tactics = data.join_lists(left_list={'Tactic': alerts.AllTactics}, right_list=mitre_list, left_key='Tactic', right_key='Tactic', kind='left', fill_nan=8)", "    if alerts.AllTacticsCount > 0:\n        scored_tactics = data.join_lists(left_list={'Tactic': alerts.AllTactics}, right_list=mitre_list, left_key='Tactic', right_key='Tactic', kind='left', fill_nan=8)\n        mitre_score = data.sum_column_by_key(scored_tactics, 'Score') * multiplier\n        mitre_join = ', '\n        score.append_score(score=mitre_score, label=f'{label} - {alerts.AllTacticsCount} MITRE Tactics ({mitre_join.join(alerts.AllTactics)})')\n    \ndef score_ueba(score:ScoringModule, module_body, per_item, multiplier, label, mitre_list):\n    ueba = UEBAModule()\n    ueba.load_from_input(module_body)\n", "    ueba.load_from_input(module_body)\n\n    module_score = 0\n         \n    if per_item and ueba.DetailedResults:\n        module_score = data.sum_column_by_key(ueba.DetailedResults, 'InvestigationPriorityMax') * multiplier\n    else:\n        module_score = ueba.AllEntityInvestigationPriorityMax * multiplier\n\n    module_score += 10 * ueba.ThreatIntelMatchCount * multiplier", "\n    module_score += 10 * ueba.ThreatIntelMatchCount * multiplier\n\n    score.append_score(score=module_score, label=label)    \n\n    if ueba.AnomalyTactics:\n        ueba_mitre = data.join_lists(left_list={'Tactic': ueba.AnomalyTactics}, right_list=mitre_list, left_key='Tactic', right_key='Tactic', kind='left', fill_nan=8)\n        ueba_mitre_score = int((data.sum_column_by_key(ueba_mitre, 'Score') / 2) * multiplier)\n        mitre_join = ', '\n        score.append_score(score=ueba_mitre_score, label=f'{label} - {ueba.AnomalyTacticsCount} Anomaly MITRE Tactics ({mitre_join.join(ueba.AnomalyTactics)})')", "        mitre_join = ', '\n        score.append_score(score=ueba_mitre_score, label=f'{label} - {ueba.AnomalyTacticsCount} Anomaly MITRE Tactics ({mitre_join.join(ueba.AnomalyTactics)})')\n\ndef score_aad(score:ScoringModule, module_body, per_item, multiplier, label):\n    aad = AADModule()\n    aad.load_from_input(module_body)\n\n    score_key = {\n        'high': 10,\n        'medium': 5,", "        'high': 10,\n        'medium': 5,\n        'low': 3\n    }\n         \n    if per_item and aad.DetailedResults:\n        for user in aad.DetailedResults:\n            module_score = score_key.get(user['UserRiskLevel'].lower(), 0) * multiplier\n            upn = user['UserPrincipalName']\n            score.append_score(score=module_score, label=f'{label} - {upn}')", "            upn = user['UserPrincipalName']\n            score.append_score(score=module_score, label=f'{label} - {upn}')\n    elif aad.DetailedResults:\n        module_score = score_key.get(aad.HighestRiskLevel.lower(), 0) * multiplier\n        score.append_score(score=module_score, label=label)\n    else:\n        score.append_score(score=0, label=f'{label} - No User Entities')\n\ndef score_file(score:ScoringModule, module_body, multiplier, label):\n    file = FileModule()", "def score_file(score:ScoringModule, module_body, multiplier, label):\n    file = FileModule()\n    file.load_from_input(module_body)\n\n    if file.HashesLinkedToThreatCount > 0:\n        score.append_score((file.HashesLinkedToThreatCount * 10 * multiplier), f'{label} - Hash linked to threat')\n\n    if file.HashesLinkedToThreatCount == 0:\n        score.append_score(0, f'{label} - No File threats found')\n", "        score.append_score(0, f'{label} - No File threats found')\n\ndef score_mdca(score:ScoringModule, module_body, per_item, multiplier, label):\n    mdca = MDCAModule()\n    mdca.load_from_input(module_body)\n    \n    if per_item:\n        score.append_score((mdca.AboveThresholdCount * 10 * multiplier), label)\n    elif mdca.AboveThresholdCount > 0:\n        score.append_score((10 * multiplier), label)", "    elif mdca.AboveThresholdCount > 0:\n        score.append_score((10 * multiplier), label)\n    else:\n        score.append_score(0, label)\n\ndef score_mde(score:ScoringModule, module_body, per_item, multiplier, label):\n    mde = MDEModule()\n    mde.load_from_input(module_body)\n\n    score_key = {", "\n    score_key = {\n        'high': 10,\n        'medium': 5,\n        'low': 3,\n        'informational': 1,\n    }\n\n    user_score = score_key.get(mde.UsersHighestRiskScore.lower(), 0)\n    host_score = score_key.get(mde.HostsHighestRiskScore.lower(), 0)", "    user_score = score_key.get(mde.UsersHighestRiskScore.lower(), 0)\n    host_score = score_key.get(mde.HostsHighestRiskScore.lower(), 0)\n    ip_score = score_key.get(mde.IPsHighestRiskScore.lower(), 0)\n\n    if per_item:\n        total_score = (user_score + host_score + ip_score) * multiplier\n    else:\n        total_score = max(user_score, host_score, ip_score) * multiplier\n\n    score.append_score(total_score, label)", "\n    score.append_score(total_score, label)\n\ndef score_custom(score:ScoringModule, module_body, multiplier):\n\n    for score_item in module_body['ScoringData']:\n        item_score = score_item['Score'] * multiplier\n        score.append_score(score=item_score, label=score_item['ScoreLabel'])\n", ""]}
{"filename": "modules/mdca.py", "chunked_list": ["from classes import BaseModule, Response, MDCAModule, STATError, STATNotFound\nfrom shared import rest, data\nimport json,os,base64\n\ndef execute_mdca_module (req_body):\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    mdca_endpoint_url = base_object.MultiTenantConfig.get('MDCAUrl',os.getenv('MDCA_ENDPOINT'))\n    if mdca_endpoint_url is None or mdca_endpoint_url == \"\":\n        raise STATError('There are no configured endpoint for MDCA.')\n\n    mdac_object = MDCAModule()\n    ScoreThreshold =  req_body.get('ScoreThreshold', -1)\n\n    for account in base_object.Accounts:\n        userid = account.get('id')\n        if userid:\n            upn = account.get('userPrincipalName')\n            current_account = {\n                'ThreatScore': 0,\n                'UserId': f'{userid}',\n                'UserPrincipalName': f'{upn}',\n                'ThreatScoreHistory': []\n            }\n            pkuser = f'{{\"id\":\"{userid}\",\"inst\":0,\"saas\":11161}}'\n            pkuser64 = base64.b64encode(pkuser.encode('ascii')).decode('ascii')\n            path = f'/api/v1/entities/{pkuser64}'\n            try:\n                mdcaresults = json.loads(rest.rest_call_get(base_object, api='mdca', path=path).content)\n            except STATNotFound:\n                pass\n            else:\n                current_account['ThreatScore'] = 0 if mdcaresults['threatScore'] is None else mdcaresults['threatScore']\n                current_account['ThreatScoreHistory'] = mdcaresults['threatScoreHistory']\n            mdac_object.DetailedResults.append(current_account)\n\n    entities_nb = len(mdac_object.DetailedResults)\n    if entities_nb != 0:\n        mdac_object.AnalyzedEntities = entities_nb\n        mdac_object.AboveThresholdCount = sum(1 for score in mdac_object.DetailedResults if score['ThreatScore'] > ScoreThreshold)\n        mdac_object.MaximumScore = max(maximum['ThreatScore'] for maximum in mdac_object.DetailedResults)\n\n    if req_body.get('AddIncidentComments', True):\n        link_template = f'<a href=\"https://security.microsoft.com/user/?aad=[col_value]&tid={base_object.TenantId}\" target=\"_blank\">[col_value]</a>'\n        linked_table = data.update_column_value_in_list([{k: v for k, v in DetailedResults.items() if k != 'ThreatScoreHistory'} for DetailedResults in mdac_object.DetailedResults], 'UserId', link_template)\n        html_table = data.list_to_html_table(linked_table, escape_html=False)\n        comment = f'<h3>Microsoft Defender for Cloud Apps Module</h3>'\n        comment += f'A total of {mdac_object.AnalyzedEntities} entities were analyzed.<br />'\n        comment += f'<ul><li>Maximum investigation score: {mdac_object.MaximumScore}</li>'\n        comment += f'<li>Users above the score threshold of {ScoreThreshold}: {mdac_object.AboveThresholdCount} </li></ul><br />'\n        comment += f'{html_table}'\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', True) and mdac_object.AboveThresholdCount > 0 :\n        task_result = rest.add_incident_task(base_object, req_body.get(f'QueryDescription', 'Review users with an investigation score higher than {ScoreThreshold}'), req_body.get('IncidentTaskInstructions'))\n\n    return Response(mdac_object)"]}
{"filename": "modules/ti.py", "chunked_list": ["from classes import BaseModule, Response, TIModule\nfrom shared import rest, data\n\ndef execute_ti_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, BaseModuleBody, IncidentTaskInstructions, CheckDomains, CheckFileHashes, CheckIPs, CheckURLs\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    ti_object = TIModule()\n\n    check_domains = req_body.get('CheckDomains', True)\n    check_filehashes = req_body.get('CheckFileHashes', True)\n    check_ips = req_body.get('CheckIPs', True)\n    check_urls = req_body.get('CheckURLs', True)\n\n    if check_domains and base_object.Domains:\n        query = base_object.get_domain_kql_table() + '''domainEntities\n| extend DomainName = tolower(Domain)\n| join kind=inner (ThreatIntelligenceIndicator\n| extend DomainName = coalesce(DomainName, EmailSourceDomain)\n| where isnotempty(DomainName)\n| summarize arg_max(TimeGenerated, *) by IndicatorId\n| where Active\n| extend DomainName = tolower(DomainName)) on DomainName\n| project TIType=\"Domain\", TIData=Domain, SourceSystem, Description, ThreatType, ConfidenceScore, IndicatorId'''\n        results = rest.execute_la_query(base_object, query, 14)\n        ti_object.DetailedResults = ti_object.DetailedResults + results\n        ti_object.DomainEntitiesCount = len(base_object.get_domain_list())\n        ti_object.DomainEntitiesWithTI = len(results)\n        ti_object.DomainTIFound = bool(results)\n    \n    if check_filehashes and base_object.FileHashes:\n        query = base_object.get_filehash_kql_table() + '''hashEntities\n| extend FileHash = tolower(FileHash)\n| join kind=inner (ThreatIntelligenceIndicator\n| where isnotempty(FileHashValue)\n| summarize arg_max(TimeGenerated, *) by IndicatorId\n| where Active\n| extend FileHash = tolower(FileHashValue)) on FileHash\n| project TIType=\"FileHash\", TIData=FileHash, SourceSystem, Description, ThreatType, ConfidenceScore, IndicatorId'''\n        results = rest.execute_la_query(base_object, query, 14)\n        ti_object.DetailedResults = ti_object.DetailedResults + results\n        ti_object.FileHashEntitiesCount = len(base_object.get_filehash_list())\n        ti_object.FileHashEntitiesWithTI = len(results)\n        ti_object.FileHashTIFound = bool(results)\n\n    if check_ips and base_object.IPs:\n        query = base_object.get_ip_kql_table() + '''ipEntities\n| join kind=inner (ThreatIntelligenceIndicator\n| extend tiIP = coalesce(NetworkIP, NetworkSourceIP, NetworkDestinationIP, EmailSourceIpAddress)\n| where isnotempty(tiIP)\n| summarize arg_max(TimeGenerated, *) by IndicatorId\n| where Active) on $left.IPAddress == $right.tiIP\n| project TIType=\"IP\", TIData=IPAddress, SourceSystem, Description, ThreatType, ConfidenceScore, IndicatorId'''\n        results = rest.execute_la_query(base_object, query, 14)\n        ti_object.DetailedResults = ti_object.DetailedResults + results\n        ti_object.IPEntitiesCount = len(base_object.get_ip_list())\n        ti_object.IPEntitiesWithTI = len(results)\n        ti_object.IPTIFound = bool(results)\n\n    if check_urls and base_object.URLs:\n        query = base_object.get_url_kql_table() + '''urlEntities\n| extend Url = tolower(Url)\n| join kind=inner (ThreatIntelligenceIndicator\n| where isnotempty(Url)\n| summarize arg_max(TimeGenerated, *) by IndicatorId\n| where Active\n| extend Url = tolower(Url)) on Url\n| extend Url = strcat('[', tostring(split(Url, '//')[0]), ']//', tostring(split(Url, '//')[1]))\n| project TIType=\"URL\", TIData=Url, SourceSystem, Description, ThreatType, ConfidenceScore, IndicatorId'''\n        results = rest.execute_la_query(base_object, query, 14)\n        ti_object.DetailedResults = ti_object.DetailedResults + results\n        ti_object.URLEntitiesCount = len(base_object.get_url_list())\n        ti_object.URLEntitiesWithTI = len(results)\n        ti_object.URLTIFound = bool(results)\n\n    ti_object.AnyTIFound = bool(ti_object.DetailedResults)\n    ti_object.TotalTIMatchCount = len(ti_object.DetailedResults)\n\n    if req_body.get('AddIncidentComments', True) and base_object.IncidentAvailable:\n        \n        html_table = data.list_to_html_table(ti_object.DetailedResults)\n\n        comment = f'''A total of {ti_object.TotalTIMatchCount} records were found with matching Threat Intelligence data.<br>{html_table}'''\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and ti_object.AnyTIFound and base_object.IncidentAvailable:\n        task_result = rest.add_incident_task(base_object, 'Review Threat Intelligence Matches', req_body.get('IncidentTaskInstructions'))\n\n    return Response(ti_object)"]}
{"filename": "modules/file.py", "chunked_list": ["from classes import BaseModule, Response, FileModule, STATError, STATNotFound\nfrom shared import rest, data\nimport json\n\ndef execute_file_module (req_body):\n\n    #Inputs AddIncidentComments, AddIncidentTask, BaseModuleBody, IncidentTaskInstructions\n\n    base_object = BaseModule()\n    base_object.load_from_input(req_body['BaseModuleBody'])\n\n    file_object = FileModule()\n\n    file_names = data.return_property_as_list(base_object.Files, 'FileName')\n    sha1_hashes = data.return_property_as_list(list(filter(lambda x: x['Algorithm'].lower() == 'sha1', base_object.FileHashes)), 'FileHash')\n    sha256_hashes = data.return_property_as_list(list(filter(lambda x: x['Algorithm'].lower() == 'sha256', base_object.FileHashes)), 'FileHash')\n\n    file_object.AnalyzedEntities = len(sha1_hashes) + len(sha256_hashes) + len(base_object.Files)\n\n    results_data = {}\n\n    if file_names:\n        email_file_query = f'''EmailAttachmentInfo\n| where Timestamp > ago(30d)\n| where FileName in~ ({convert_list_to_string(file_names)})\n| summarize FirstSeen=min(Timestamp), LastSeen=max(Timestamp), AttachmentCount=count() by FileName,SHA256, FileSize'''\n        file_results = rest.execute_m365d_query(base_object, email_file_query)\n\n        for file in file_results:\n            if not results_data.get(file['SHA256']):\n                results_data[file['SHA256']] = {\n                    'SHA256': file['SHA256']\n                }\n            results_data[file['SHA256']]['EmailAttachmentCount'] = file['AttachmentCount']\n            results_data[file['SHA256']]['EmailAttachmentFileSize'] = file['FileSize']\n            results_data[file['SHA256']]['EmailAttachmentFirstSeen'] = file['FirstSeen']\n            results_data[file['SHA256']]['EmailAttachmentLastSeen'] = file['LastSeen']\n            results_data[file['SHA256']]['FileName'] = file['FileName']\n            file_object.EntitiesAttachmentCount += file['AttachmentCount']\n\n    device_file_query = f'''let sha1Hashes = datatable(SHA1:string)[{convert_list_to_string(sha1_hashes)}];\nlet sha256Hashes = datatable(SHA256:string)[{convert_list_to_string(sha256_hashes)}];\nunion\n(DeviceFileEvents\n| where Timestamp > ago(30d)\n| where SHA1 in~ (sha1Hashes) or SHA256 in~ (sha256Hashes)\n| project FileName, SHA1, SHA256, DeviceId),\n(DeviceProcessEvents\n| where Timestamp > ago(30d)\n| where SHA1 in~ (sha1Hashes) or SHA256 in~ (sha256Hashes)\n| project FileName, SHA1, SHA256, DeviceId)\n| summarize DeviceUniqueDeviceCount=dcount(DeviceId), Files=make_set(FileName), FileName=min(FileName), Count=count() by SHA1, SHA256\n| extend DeviceUniqueFileNameCount = array_length(Files)'''\n    \n    device_file_results = rest.execute_m365d_query(base_object, device_file_query)\n\n    for file in device_file_results:\n        if file['SHA256'] not in sha256_hashes:\n            sha256_hashes.append(file['SHA256'])\n        try:\n            sha1_hashes.remove(file['SHA1'])\n        except:\n            pass\n        results_data[file['SHA256']] = {\n            'DeviceUniqueDeviceCount': file['DeviceUniqueDeviceCount'],\n            'DeviceUniqueFileNameCount': file['DeviceUniqueFileNameCount'],\n            'DeviceFileActionCount': file['Count'],\n            'FileName': file['FileName'],\n            'SHA1': file['SHA1'],\n            'SHA256': file['SHA256']\n        }\n\n    for hash in sha256_hashes:\n        result = call_file_api(base_object, hash)\n        if result:\n            add_file_api_result(result, results_data, file_object)\n\n            try:\n                sha1_hashes.remove(result['sha1'])\n            except:\n                pass\n\n    for hash in sha1_hashes:\n        result = call_file_api(base_object, hash)\n        if result:\n            add_file_api_result(result, results_data, file_object)\n            sha256_hashes.append(result['sha256'])\n            \n            try:\n                sha1_hashes.remove(result['sha1'])\n            except:\n                pass\n       \n    if sha256_hashes:\n        email_hash_query = f'''datatable(SHA256:string)[{convert_list_to_string(sha256_hashes)}]\n| join (EmailAttachmentInfo | where Timestamp > ago(30d)) on SHA256\n| summarize AttachmentCount=countif(isnotempty(NetworkMessageId)), FirstSeen=min(Timestamp), LastSeen=max(Timestamp), FileName=min(FileName), FileSize=max(FileSize) by SHA256'''\n    \n        email_attachments_by_hash = rest.execute_m365d_query(base_object, email_hash_query)\n\n        for attachment in email_attachments_by_hash:\n            if not results_data.get(attachment['SHA256']):\n                results_data[attachment['SHA256']] = {\n                    'SHA256': attachment['SHA256']\n                }\n            results_data[attachment['SHA256']]['EmailAttachmentCount'] = attachment['AttachmentCount']\n            results_data[attachment['SHA256']]['EmailAttachmentFileSize'] = attachment['FileSize']\n            results_data[attachment['SHA256']]['EmailAttachmentFirstSeen'] = attachment['FirstSeen']\n            results_data[attachment['SHA256']]['EmailAttachmentLastSeen'] = attachment['LastSeen']\n            file_object.EntitiesAttachmentCount += attachment['AttachmentCount']\n            if not results_data[attachment['SHA256']].get('FileName'):\n                results_data[attachment['SHA256']]['FileName'] = attachment['FileName']\n\n    for key in results_data:\n        file_object.DetailedResults.append(results_data[key])\n\n    file_object.EntitiesAttachmentCount = data.sum_column_by_key(file_object.DetailedResults, 'EmailAttachmentCount')\n    file_object.DeviceFileActionTotalCount = data.sum_column_by_key(file_object.DetailedResults, 'DeviceFileActionCount')\n    file_object.DeviceUniqueDeviceTotalCount = data.sum_column_by_key(file_object.DetailedResults, 'DeviceUniqueDeviceCount')\n    file_object.DeviceUniqueFileNameTotalCount = data.sum_column_by_key(file_object.DetailedResults, 'DeviceUniqueFileNameCount')\n    file_object.HashesLinkedToThreatCount = len(file_object.HashesThreatList)\n    file_object.MaximumGlobalPrevalence = data.max_column_by_key(file_object.DetailedResults, 'GlobalPrevalence')\n    file_object.MinimumGlobalPrevalence = data.min_column_by_key(file_object.DetailedResults, 'GlobalPrevalence')\n\n\n    if req_body.get('AddIncidentComments', True) and base_object.IncidentAvailable:\n        \n        html_table = data.list_to_html_table(file_object.DetailedResults)\n\n        comment = f'''<h3>File Module</h3>A total of {file_object.AnalyzedEntities} entities were analyzed.<br>{html_table}'''\n        comment_result = rest.add_incident_comment(base_object, comment)\n\n    if req_body.get('AddIncidentTask', False) and file_object.AnalyzedEntities > 0 and base_object.IncidentAvailable:\n        task_result = rest.add_incident_task(base_object, 'Review File Module Results', req_body.get('IncidentTaskInstructions'))\n\n    return Response(file_object)", "\ndef convert_list_to_string(hash_list:list):\n    if hash_list:\n        return \"'\" + \"','\".join(list(set(hash_list))).lower() + \"'\"\n    else:\n        return ''\n\ndef call_file_api(base_object, hash):\n    path = f'/api/files/{hash}'\n    try:\n        file_data = json.loads(rest.rest_call_get(base_object, 'mde', path).content)   \n    except STATNotFound:\n        return None\n        \n    return file_data", "\ndef add_file_api_result(result, results_data, file_object:FileModule):\n    if not results_data.get(result['sha256']):\n        results_data[result['sha256']] = {\n            'SHA1': result['sha1'],\n            'SHA256': result['sha256']\n        }\n    results_data[result['sha256']]['GlobalFirstSeen'] = result['globalFirstObserved']\n    results_data[result['sha256']]['GlobalLastSeen'] = result['globalLastObserved']\n    results_data[result['sha256']]['GlobalPrevalence'] = result['globalPrevalence']\n    results_data[result['sha256']]['Publisher'] = result['filePublisher']\n    results_data[result['sha256']]['Signer'] = result['signer']\n    results_data[result['sha256']]['IsCertificateValid'] = result['isValidCertificate']\n    results_data[result['sha256']]['FileSize'] = result['size']\n    results_data[result['sha256']]['ThreatName'] = result['determinationValue']\n\n    if results_data[result['sha256']]['Publisher'] != 'Microsoft Corporation':\n        file_object.HashesNotMicrosoftSignedCount += 1\n\n    if results_data[result['sha256']]['ThreatName'] != '' and results_data[result['sha256']]['ThreatName'] is not None:\n        file_object.HashesThreatList.append(results_data[result['sha256']]['ThreatName'])\n        file_object.HashesLinkedToThreatCount += 1"]}
