{"filename": "setup.py", "chunked_list": ["import setuptools\n\n\nwith open('README.md', encoding='utf-8') as f:\n    long_description = f.read()\n\nsetuptools.setup(\n    name='extr',\n    version='0.0.44',\n    keywords=['Named Entity Recognition', 'Relation Extraction', 'Entity Linking', 'NER', 'RE', 'NLP'],", "    version='0.0.44',\n    keywords=['Named Entity Recognition', 'Relation Extraction', 'Entity Linking', 'NER', 'RE', 'NLP'],\n    description='Named Entity Recognition (NER) and Relation Extraction (RE) library using Regular Expressions',\n    packages=setuptools.find_packages('src'),\n    package_dir={'': 'src'},\n    install_requires=[],\n    url='https://github.com/dpasse/extr',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n)", "    long_description_content_type='text/markdown',\n)\n"]}
{"filename": "tests/test_relations_viewers.py", "chunked_list": ["import os\nimport sys\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr import Location, Entity\nfrom extr.relations import RelationExtractor, RegExRelationLabelBuilder\nfrom extr.relations.viewers import HtmlViewer\n\n\ndef test_html_viewer():\n    text = 'Ted is a Pitcher.'\n    annotated_text = '##ENTITY_PERSON_2## is a ##ENTITY_POSITION_1##.'\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    ## define relationship between PERSON and POSITION    \n    relationship = RegExRelationLabelBuilder('is_a') \\\n        .add_e1_to_e2(\n            'PERSON', ## e1\n            [\n                ## define how the relationship exists in nature\n                r'\\s+is\\s+a\\s+',\n            ],\n            'POSITION' ## e2\n        ) \\\n        .build()\n        \n    relations_to_extract = [relationship]\n\n    relations = RelationExtractor(relations_to_extract).extract(annotated_text, entities)\n\n    viewer = HtmlViewer()\n    viewer.append_header('r(\"PERSON\", \"POSITION\")')\n    viewer.append_relation(text, relation=relations[0])\n\n    html = viewer.create_view()\n\n    assert html == \"\"\"<html>\n    <head>\n        <style>\ntable { width: 100%; }\nspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\nspan.label { font-weight: bold; padding: 3px; color: black; }\nspan.e1 { background-color: aqua; }\nspan.e2 { background-color: coral; }\ntr.delete { background-color: black !important; }\ntr.delete span { background-color: black !important; }\ntd { line-height: 30px; border: 1px solid black; padding: 5px; }\ntd.header { font-weight: bold; }\ntd.label { font-weight: bold; text-align: center; }\n        </style>\n    </head>\n    <body>\n        <table>\n<tr><td class=\"header\" colspan=\"3\">r(\"PERSON\", \"POSITION\")</td></tr>\n<tr id=\"0\"><td>0</td><td class=\"label\">is_a</td><td><span class=\"entity lb-PERSON e1\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION e2\"><span class=\"label\">POSITION</span>Pitcher</span>.</td></tr>\n        </table>\n    </body>\n</html>\"\"\"", "\n\ndef test_html_viewer():\n    text = 'Ted is a Pitcher.'\n    annotated_text = '##ENTITY_PERSON_2## is a ##ENTITY_POSITION_1##.'\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    ## define relationship between PERSON and POSITION    \n    relationship = RegExRelationLabelBuilder('is_a') \\\n        .add_e1_to_e2(\n            'PERSON', ## e1\n            [\n                ## define how the relationship exists in nature\n                r'\\s+is\\s+a\\s+',\n            ],\n            'POSITION' ## e2\n        ) \\\n        .build()\n        \n    relations_to_extract = [relationship]\n\n    relations = RelationExtractor(relations_to_extract).extract(annotated_text, entities)\n\n    viewer = HtmlViewer()\n    viewer.append_header('r(\"PERSON\", \"POSITION\")')\n    viewer.append_relation(text, relation=relations[0])\n\n    html = viewer.create_view()\n\n    assert html == \"\"\"<html>\n    <head>\n        <style>\ntable { width: 100%; }\nspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\nspan.label { font-weight: bold; padding: 3px; color: black; }\nspan.e1 { background-color: aqua; }\nspan.e2 { background-color: coral; }\ntr.delete { background-color: black !important; }\ntr.delete span { background-color: black !important; }\ntd { line-height: 30px; border: 1px solid black; padding: 5px; }\ntd.header { font-weight: bold; }\ntd.label { font-weight: bold; text-align: center; }\n        </style>\n    </head>\n    <body>\n        <table>\n<tr><td class=\"header\" colspan=\"3\">r(\"PERSON\", \"POSITION\")</td></tr>\n<tr id=\"0\"><td>0</td><td class=\"label\">is_a</td><td><span class=\"entity lb-PERSON e1\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION e2\"><span class=\"label\">POSITION</span>Pitcher</span>.</td></tr>\n        </table>\n    </body>\n</html>\"\"\"", "    "]}
{"filename": "tests/test_entities.py", "chunked_list": ["import os\nimport sys\nimport re\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr import RegEx, RegExLabel, Entity, Location\nfrom extr.entities import create_entity_extractor, \\\n                          EntityAnnotator, \\\n                          HtmlEntityAnnotator, \\", "                          EntityAnnotator, \\\n                          HtmlEntityAnnotator, \\\n                          KnowledgeBaseEntityLinker\n\ndef test_get_entities():\n    regex_labels = [\n        RegExLabel('PERSON', [\n            RegEx([r'ted'], re.IGNORECASE)\n        ]),\n        RegExLabel('POSITION', [\n            RegEx([r'pitcher'], re.IGNORECASE)\n        ]),\n    ]\n\n    extractor = create_entity_extractor(regex_labels)\n    entities = extractor.get_entities('Ted is a Pitcher.')\n\n    assert len(entities) == 2", "\ndef test_get_entities_with_overlap():\n    regex_labels = [\n        RegExLabel('PERSON', [\n            RegEx([r'ted'], re.IGNORECASE)\n        ]),\n        RegExLabel('POSITION', [\n            RegEx([r'pitch'], re.IGNORECASE),\n            RegEx([r'pitcher'], re.IGNORECASE)\n        ]),\n    ]\n\n    extractor = create_entity_extractor(regex_labels)\n    entities = extractor.get_entities('Ted is a Pitcher.')\n\n    assert len(entities) == 2\n    assert entities[0].text == 'Pitcher'\n    assert entities[1].text == 'Ted'", "\ndef test_get_entities_with_knowledge():\n    extractor = create_entity_extractor(\n        regex_labels=[\n            RegExLabel('POSITION', [\n                RegEx([r'pitcher'], re.IGNORECASE)\n            ]),\n        ],\n        kb={\n            'PERSON': [\n                'Ted'\n            ]\n        }\n    )\n\n    entities = extractor.get_entities('Ted is a Pitcher.')\n\n    assert len(entities) == 2", "\ndef test_annotate():\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    annotated_text = EntityAnnotator().annotate('Ted is a Pitcher.', entities)\n\n    assert annotated_text == '##ENTITY_PERSON_2## is a ##ENTITY_POSITION_1##.'", "\ndef test_html_annotate():\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    annotated_text = HtmlEntityAnnotator().annotate('Ted is a Pitcher.', entities)\n\n    assert annotated_text == '<span class=\"entity lb-PERSON\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION\"><span class=\"label\">POSITION</span>Pitcher</span>.'", "\ndef test_kb_linker():\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'POSITION', 'Short Stop', Location(34, 44)),\n    ]\n\n    linker = KnowledgeBaseEntityLinker(\n        attribute_label='eid',\n        kb={\n            'Pitcher': 'BB-1',\n            'Catcher': 'BB-2',\n            'First Base': 'BB-3',\n            'Short Stop': 'BB-6',\n        }\n    )\n\n    entities = linker.link(entities)\n    \n    assert entities[0].attributes['eid'].pop() == 'BB-1'\n    assert entities[1].attributes['eid'].pop() == 'BB-6'", ""]}
{"filename": "tests/test_models.py", "chunked_list": ["import os\nimport sys\nimport re\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr import Location\n\n\ndef test_location_bigger_location_contains_smaller():\n    big = Location(0, 10)\n    small = Location(3, 7)\n\n    assert big.contains(small)", "\ndef test_location_bigger_location_contains_smaller():\n    big = Location(0, 10)\n    small = Location(3, 7)\n\n    assert big.contains(small)\n\ndef test_location_contains_returns_false_on_partial_fit_1():\n    big = Location(0, 10)\n    small = Location(7, 12)\n\n    assert not big.contains(small)", "\ndef test_location_contains_returns_false_on_partial_fit_2():\n    big = Location(5, 10)\n    small = Location(3, 8)\n\n    assert not big.contains(small)\n\ndef test_location_contains_return_false_when_given_larger():\n    big = Location(5, 10)\n    small = Location(3, 12)\n\n    assert not big.contains(small)", "\ndef test_location_is_in_returns_true_when_completely_in_other():\n    location1 = Location(3, 12)\n    location2 = Location(5, 10)\n\n    assert location2.is_in(location1)\n\ndef test_location_is_in_returns_true_when_start_is_in_other():\n    location1 = Location(3, 12)\n    location2 = Location(5, 15)\n\n    assert location2.is_in(location1)", "\ndef test_location_is_in_returns_true_when_end_is_in_other():\n    location1 = Location(3, 12)\n    location2 = Location(1, 5)\n\n    assert location2.is_in(location1)\n\ndef test_location_is_in_returns_false_when_neither_is_in_other():\n    location1 = Location(3, 12)\n    location2 = Location(1, 3)\n\n    assert not location2.is_in(location1)", ""]}
{"filename": "tests/test_end_to_end.py", "chunked_list": ["import os\nimport sys\nimport re\nimport pytest\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr import RegEx, RegExLabel\nfrom extr.entities import EntityExtractor, EntityAnnotator\nfrom extr.relations import RelationExtractor, RegExRelationLabelBuilder", "from extr.entities import EntityExtractor, EntityAnnotator\nfrom extr.relations import RelationExtractor, RegExRelationLabelBuilder\n\n\n@pytest.mark.skip\ndef test_end_to_end():\n    text = 'Walk; Mountcastle to 3B; Odor to 2B'\n\n    entity_extractor = EntityExtractor([\n        RegExLabel('PLAYER', [\n            RegEx([\n                r'\\b([A-Z]\\w+)(?=\\s+to\\b)'\n            ])\n        ]),\n        RegExLabel('BASE', [\n            RegEx([\n                r'([123]B)\\b'\n            ])\n        ]),\n        RegExLabel('EVENT', [\n            RegEx(\n                [\n                    r'\\b(Walk|Single)\\b'\n                ],\n                re.IGNORECASE\n            )\n        ]),\n    ])\n\n    entities = entity_extractor.get_entities(text)\n    print(entities)\n    assert len(entities) == 5\n\n    player_to_base_relationship = RegExRelationLabelBuilder('is_on') \\\n        .add_e1_to_e2(\n            'PLAYER', ## e1\n            [\n                ## define how the relationship exists in nature\n                r'\\s+to\\s+',\n            ],\n            'BASE' ## e2\n        ) \\\n        .build()\n\n    relations_to_extract = [\n        player_to_base_relationship\n    ]\n\n    annotated_text = EntityAnnotator().annotate(text, entities)\n    relations = RelationExtractor(relations_to_extract).extract(annotated_text, entities)\n\n    print(relations)\n    assert len(relations) == 2", ""]}
{"filename": "tests/test_context.py", "chunked_list": ["import os\nimport sys\nimport re\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr import RegEx, RegExLabel\nfrom extr.entities import create_entity_extractor\nfrom extr.entities.context import ConText, ConTextRule, ConTextRuleGroup, DirectionType\n", "from extr.entities.context import ConText, ConTextRule, ConTextRuleGroup, DirectionType\n\n\nregex_labels=[\n    RegExLabel(\n        'LEFT_NEGATIVE',\n        regexes=[\n            RegEx([r'is ruled out'], flags=re.IGNORECASE)\n        ]\n    ),", "        ]\n    ),\n    RegExLabel(\n        'HISTORY_RIGHT',\n        regexes=[\n            RegEx([r'history of'], flags=re.IGNORECASE)\n        ]\n    ),\n    RegExLabel(\n        'INFECTION',", "    RegExLabel(\n        'INFECTION',\n        regexes=[\n            RegEx([r'pneumonia'], flags=re.IGNORECASE)\n        ]\n    ),\n]\n\nrules = [\n    ConTextRule(", "rules = [\n    ConTextRule(\n        'NEGATED',\n        ['RIGHT_NEGATIVE'],\n        direction=DirectionType.RIGHT\n    ),\n    ConTextRule(\n        'NEGATED',\n        ['LEFT_NEGATIVE'],\n        direction=DirectionType.LEFT", "        ['LEFT_NEGATIVE'],\n        direction=DirectionType.LEFT\n    ),\n    ConTextRule(\n        'HISTORICAL',\n        ['HISTORY_RIGHT'],\n        direction=DirectionType.RIGHT\n    ),\n    ConTextRule(\n        'HISTORICAL',", "    ConTextRule(\n        'HISTORICAL',\n        ['HISTORY_LEFT'],\n        direction=DirectionType.LEFT\n    ),\n    ConTextRule(\n        'HYPOTHETICAL',\n        ['HYPOTHETICAL_RIGHT'],\n        direction=DirectionType.RIGHT\n    ),", "        direction=DirectionType.RIGHT\n    ),\n    ConTextRule(\n        'HYPOTHETICAL',\n        ['HYPOTHETICAL_LEFT'],\n        direction=DirectionType.LEFT\n    )\n]\n\ndef test_contextor_historical_right_1():\n    text = 'Past history of pneumonia.'\n    entity_extractor = create_entity_extractor(regex_labels=regex_labels)\n\n    contextor = ConText(\n        rule_grouping=ConTextRuleGroup(\n            rules=rules\n        ),\n        word_tokenizer=lambda _: ['Past', 'history', 'of', 'pneumonia', '.']\n    )\n\n    entities = contextor.apply(\n        text,\n        entity_extractor.get_entities(text)\n    )\n\n    assert len(entities) == 1\n    assert list(entities[0].get_attributes_by_label('ctypes'))[0] == 'HISTORICAL'\n\n    print(\n        [\n            (entity, entity.get_attributes_by_label('ctypes'))\n            for entity in entities\n        ]\n    )", "\ndef test_contextor_historical_right_1():\n    text = 'Past history of pneumonia.'\n    entity_extractor = create_entity_extractor(regex_labels=regex_labels)\n\n    contextor = ConText(\n        rule_grouping=ConTextRuleGroup(\n            rules=rules\n        ),\n        word_tokenizer=lambda _: ['Past', 'history', 'of', 'pneumonia', '.']\n    )\n\n    entities = contextor.apply(\n        text,\n        entity_extractor.get_entities(text)\n    )\n\n    assert len(entities) == 1\n    assert list(entities[0].get_attributes_by_label('ctypes'))[0] == 'HISTORICAL'\n\n    print(\n        [\n            (entity, entity.get_attributes_by_label('ctypes'))\n            for entity in entities\n        ]\n    )", "    \ndef test_contextor_negative_left_1():\n    text = 'Pneumonia is ruled out.'\n    entity_extractor = create_entity_extractor(regex_labels=regex_labels)\n\n    contextor = ConText(\n        rule_grouping=ConTextRuleGroup(\n            rules=rules\n        ),\n        word_tokenizer=lambda _: ['Pneumonia', 'is', 'ruled', 'out', '.']\n    )\n\n    entities = contextor.apply(\n        text,\n        entity_extractor.get_entities(text)\n    )\n\n    assert len(entities) == 1\n    assert list(entities[0].get_attributes_by_label('ctypes'))[0] == 'NEGATED'\n\n\n    print(\n        [\n            (entity, entity.get_attributes_by_label('ctypes'))\n            for entity in entities\n        ]\n    )", ""]}
{"filename": "tests/test_entities_viewers.py", "chunked_list": ["import os\nimport sys\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr import Entity, Location\nfrom extr.entities.viewers import HtmlViewer\n\n\ndef test_html_viewer():\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    viewer = HtmlViewer()\n    viewer.append('Ted is a Pitcher.', entities)\n\n    html_doc = viewer.create_view()\n\n    assert html_doc == \"\"\"<html>\n    <head>\n        <style>\np { margin: 5px; line-height: 45px; }\nspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\nspan.label { font-weight: bold; padding: 3px; color: black; }\n        </style>\n    </head>\n    <body>\n<p><span class=\"entity lb-PERSON\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION\"><span class=\"label\">POSITION</span>Pitcher</span>.</p>\n    </body>\n</html>\"\"\"", "\ndef test_html_viewer():\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    viewer = HtmlViewer()\n    viewer.append('Ted is a Pitcher.', entities)\n\n    html_doc = viewer.create_view()\n\n    assert html_doc == \"\"\"<html>\n    <head>\n        <style>\np { margin: 5px; line-height: 45px; }\nspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\nspan.label { font-weight: bold; padding: 3px; color: black; }\n        </style>\n    </head>\n    <body>\n<p><span class=\"entity lb-PERSON\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION\"><span class=\"label\">POSITION</span>Pitcher</span>.</p>\n    </body>\n</html>\"\"\"", "\ndef test_html_viewer_with_custom_styles():\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    viewer = HtmlViewer()\n    viewer.append('Ted is a Pitcher.', entities)\n\n    html_doc = viewer.create_view(\"\"\"\n.lb-PERSON { background-color: orange; }\n.lb-POSITION { background-color: yellow; }\n\"\"\")\n    \n    assert html_doc == \"\"\"<html>\n    <head>\n        <style>\np { margin: 5px; line-height: 45px; }\nspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\nspan.label { font-weight: bold; padding: 3px; color: black; }\n.lb-PERSON { background-color: orange; }\n.lb-POSITION { background-color: yellow; }\n        </style>\n    </head>\n    <body>\n<p><span class=\"entity lb-PERSON\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION\"><span class=\"label\">POSITION</span>Pitcher</span>.</p>\n    </body>\n</html>\"\"\"", ""]}
{"filename": "tests/test_tokenizer.py", "chunked_list": ["import os\nimport sys\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr.tokenizers import word_tokenizer\n\n\ndef test_word_tokenizer():\n    token_group = word_tokenizer(\n        'Ted is a pitcher.',\n        ['Ted', 'is', 'a', 'pitcher', '.']\n    )\n\n    assert token_group.location.start == 0\n    assert token_group.location.end == 17\n    assert len(token_group.tokens) == 5", "def test_word_tokenizer():\n    token_group = word_tokenizer(\n        'Ted is a pitcher.',\n        ['Ted', 'is', 'a', 'pitcher', '.']\n    )\n\n    assert token_group.location.start == 0\n    assert token_group.location.end == 17\n    assert len(token_group.tokens) == 5\n", ""]}
{"filename": "tests/test_relations.py", "chunked_list": ["import os\nimport sys\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr import Location, Entity\nfrom extr.relations import RelationExtractor, RegExRelationLabelBuilder\n\n\ndef test_get_relations():\n    annotated_text = '##ENTITY_PERSON_2## is a ##ENTITY_POSITION_1##.'\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    ## define relationship between PERSON and POSITION    \n    relationship = RegExRelationLabelBuilder('is_a') \\\n        .add_e1_to_e2(\n            'PERSON', ## e1\n            [\n                ## define how the relationship exists in nature\n                r'\\s+is\\s+a\\s+',\n            ],\n            'POSITION' ## e2\n        ) \\\n        .build()\n        \n    relations_to_extract = [relationship]\n\n    relations = RelationExtractor(relations_to_extract).extract(annotated_text, entities)\n    \n    assert len(relations) == 1\n    assert relations[0].e1.text == 'Ted'\n    assert relations[0].e2.text == 'Pitcher'\n    assert relations[0].label == 'is_a'", "\ndef test_get_relations():\n    annotated_text = '##ENTITY_PERSON_2## is a ##ENTITY_POSITION_1##.'\n    entities = [\n        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n    ]\n\n    ## define relationship between PERSON and POSITION    \n    relationship = RegExRelationLabelBuilder('is_a') \\\n        .add_e1_to_e2(\n            'PERSON', ## e1\n            [\n                ## define how the relationship exists in nature\n                r'\\s+is\\s+a\\s+',\n            ],\n            'POSITION' ## e2\n        ) \\\n        .build()\n        \n    relations_to_extract = [relationship]\n\n    relations = RelationExtractor(relations_to_extract).extract(annotated_text, entities)\n    \n    assert len(relations) == 1\n    assert relations[0].e1.text == 'Ted'\n    assert relations[0].e2.text == 'Pitcher'\n    assert relations[0].label == 'is_a'", "    "]}
{"filename": "tests/test_regex.py", "chunked_list": ["import os\nimport sys\nimport re\n\nsys.path.insert(0, os.path.join('../src'))\n\nfrom extr.regexes import RegEx, SlimRegEx\n\n\ndef test_findall():\n    regex = RegEx(\n        expressions=[\n            r'.+',\n        ]\n    )\n\n    text = 'Ted is a pitcher.'\n\n    matches = regex.findall(text)\n    assert len(matches) == 1\n    assert matches[0].group() == text", "\ndef test_findall():\n    regex = RegEx(\n        expressions=[\n            r'.+',\n        ]\n    )\n\n    text = 'Ted is a pitcher.'\n\n    matches = regex.findall(text)\n    assert len(matches) == 1\n    assert matches[0].group() == text", "\n\ndef test_findall_with_skip_ifs():\n    regex = RegEx(\n        expressions=[\n            r'.+',\n        ],\n        skip_if=[\n            SlimRegEx([r'is\\s+a'])\n        ],\n    )\n\n    matches = regex.findall('Ted is a pitcher.')\n    assert len(matches) == 0", ""]}
{"filename": "src/extr/models.py", "chunked_list": ["from typing import Set, Dict, List, TypeVar, Generator, cast\n\nfrom dataclasses import dataclass, field\n\n\nNOT_DEFINED_FLAG: int = -1\n\n# pylint: disable=C0103\nTLocation = TypeVar('TLocation', bound='Location')\n# pylint: enable=C0103", "TLocation = TypeVar('TLocation', bound='Location')\n# pylint: enable=C0103\n\n@dataclass(frozen=True)\nclass Location:\n    start: int\n    end: int\n\n    @property\n    def actual_end(self) -> int:\n        return self.end - 1\n\n    def is_in(self: TLocation, other: TLocation) -> bool:\n        return self.start >= other.start and self.start <= other.actual_end \\\n            or self.actual_end >= other.start and self.actual_end <= other.actual_end\n\n    def contains(self: TLocation, other: TLocation) -> bool:\n        return other.start >= self.start and other.actual_end <= self.actual_end\n\n    def extract(self, text: str) -> str:\n        return text[self.start:self.end]\n\n    def __str__(self) -> str:\n        return f'({self.start}, {self.end})'\n\n    def __repr__(self) -> str:\n        return f'({self.start}, {self.end})'", "\n# pylint: disable=C0103\nTILocation = TypeVar('TILocation', bound='ILocation')\n# pylint: enable=C0103\n\nclass ILocation:\n    location: Location\n\n    def is_in(self: TILocation, other: TILocation) -> bool:\n        return self.location.is_in(other.location)\n\n    def contains(self: TILocation, other: TILocation) -> bool:\n        return self.location.contains(other.location)", "\nclass IMeta():\n    attributes: Dict[str, Set[str]]\n\n    def add_attribute(self, label: str, attribute: str) -> None:\n        if not label in self.attributes:\n            self.attributes[label] = set()\n\n        self.attributes[label].add(attribute)\n\n    def get_attributes_by_label(self, label: str) -> Set[str]:\n        if not label in self.attributes:\n            return set()\n\n        return self.attributes[label]\n\n    def is_a(self, label: str, attribute: str) -> bool:\n        if label in self.attributes:\n            return attribute in self.get_attributes_by_label(label)\n\n        return False", "\n@dataclass()\nclass Entity(ILocation, IMeta):\n    identifier: int\n    label: str\n    text: str\n    location: Location\n    attributes: Dict[str, Set[str]] = field(default_factory=dict)\n\n    @property\n    def start(self) -> int:\n        return self.location.start\n\n    @property\n    def end(self) -> int:\n        return self.location.end\n\n    def __str__(self) -> str:\n        return f'##ENTITY_{self.label}_{self.identifier}##'\n\n    def __repr__(self) -> str:\n        return f'<Entity label=\"{self.label}\" text=\"{self.text}\" span={repr(self.location)}>'", "\n@dataclass(frozen=True)\nclass Relation:\n    label: str\n    e1: Entity\n    e2: Entity\n\n    @property\n    def key(self) -> str:\n        return self.create_key(self.e1, self.e2)\n\n    @property\n    def definition(self) -> str:\n        return f'r(\"{self.e1.label}\", \"{self.e2.label}\")'\n\n    def __str__(self) -> str:\n        return f'r(\"{self.e1.text}\", \"{self.e2.text}\") == \"{self.label}\"'\n\n    def __repr__(self) -> str:\n        return f'<Relation e1=\"{self.e1.text}\" r=\"{self.label}\" e2=\"{self.e2.text}\">'\n\n    @staticmethod\n    def create_key(e1: Entity, e2: Entity) -> str:\n        return f'{e1.identifier}_{e2.identifier}'", "\n@dataclass(frozen=True)\nclass Token(ILocation):\n    text: str\n    location: Location\n    order: int\n    entities: List[Entity] = field(default_factory=lambda: [])\n\n    def add_entity(self, entity: Entity) -> None:\n        self.entities.append(entity)\n\n    def apply_attribute(self, label: str, attribute: str) -> None:\n        for entity in self.entities:\n            entity.add_attribute(label, attribute)\n\n    def __len__(self) -> int:\n        return len(self.entities)\n\n    def __str__(self) -> str:\n        return self.text\n\n    def __repr__(self) -> str:\n        return f'<Token text=\"{self.text}\", location={repr(self.location)}, order={self.order}>'", "\n@dataclass(frozen=True)\nclass TokenGroup(ILocation):\n    location: Location\n    sentence: str\n    tokens: List[Token]\n\n    def find_entities(self: ILocation, entities: List[Entity]) -> Generator[Entity, None, None]:\n        for entity in entities:\n            if self.contains(entity):\n                yield entity\n\n    def find_relations(self: ILocation, relations: List[Relation]) -> Generator[Relation, None, None]:\n        for relation in relations:\n            if self.contains(relation.e1) and self.contains(relation.e2):\n                yield relation\n\n    def apply_entities(self, entities: List[Entity]) -> None:\n        for entity in self.find_entities(entities):\n            for token in self.tokens:\n                if not cast(ILocation, entity).is_in(token) and not cast(ILocation, entity).contains(token):\n                    continue\n\n                token.add_entity(entity)", ""]}
{"filename": "src/extr/__init__.py", "chunked_list": ["from .regexes import RegExLabel, RegEx\nfrom .models import Entity, Relation, ILocation, Location, Token, TokenGroup\nfrom .entities import EntityExtractor, EntityAnnotator\nfrom .relations import RelationExtractor, RelationAnnotator, RegExRelationLabelBuilder\n"]}
{"filename": "src/extr/regexes/regex.py", "chunked_list": ["from typing import List, Tuple, Optional\nimport re\n\nfrom ..utils.iterutils import flatten\n\n\nclass SlimRegEx:\n    def __init__(self, expressions: List[str], flags: int = 0) -> None:\n        self._expressions = expressions\n        self._flags = flags\n\n    def findall(self, text: str) -> List[re.Match]:\n        def handler(expression: str) -> list:\n            return list(re.finditer(expression, text, self._flags))\n\n        return flatten(map(handler, self._expressions))\n\n    def search(self, text: str) -> Optional[re.Match]:\n        for expression in self._expressions:\n            match = re.search(expression, text)\n            if match:\n                return match\n\n        return None", "\nclass RegEx(SlimRegEx):\n    def __init__(self, expressions: List[str], flags: int = 0, skip_if: Optional[List[SlimRegEx]] = None) -> None:\n        super().__init__(expressions, flags)\n\n        self._skip_if = set([] if skip_if is None else skip_if)\n\n    def findall(self, text: str) -> List[re.Match]:\n        def handler(expression: str) -> list:\n            observations = []\n            for match in re.finditer(expression, text, self._flags):\n\n                should_skip_match = False\n                for skip_if in self._skip_if:\n                    if skip_if.search(match.group()):\n                        should_skip_match = True\n                        break\n\n                if not should_skip_match:\n                    observations.append(match)\n\n            return observations\n\n        return flatten(map(handler, self._expressions))", "\nclass RegExLabel:\n    def __init__(self, label: str, regexes: List[RegEx]) -> None:\n        self._label = label\n        self._regexes = regexes\n\n    def findall(self, text: str) -> List[Tuple[str, re.Match]]:\n        def handler(regex) -> list:\n            observations = regex.findall(text)\n            return list(zip([self._label] * len(observations), observations))\n\n        return flatten(map(handler, self._regexes))", "\ndef transform_knowledge(label: str, knowledge: List[str]) -> RegExLabel:\n    expressions = [\n        r'(?<!\\w)' + term + r'(?!\\w)'\n        for term in knowledge\n    ]\n\n    return RegExLabel(\n        label,\n        [\n            RegEx(expressions)\n        ]\n    )", ""]}
{"filename": "src/extr/regexes/__init__.py", "chunked_list": ["from .regex import SlimRegEx, RegEx, RegExLabel, transform_knowledge\n"]}
{"filename": "src/extr/pipelines/pipes.py", "chunked_list": ["from typing import Optional, List, Tuple\nfrom ..models import Entity, Relation\nfrom ..entities.extractor import AbstractEntityExtractor\nfrom ..entities.annotator import EntityAnnotator\nfrom ..entities.linkers import AbstractEntityLinker\nfrom ..entities.context import ConText\nfrom ..relations.extractor import RelationExtractor\n\n\nclass EntityPipeline:\n    def __init__(self, \\\n                 entity_extractor: AbstractEntityExtractor, \\\n                 entity_linker: Optional[AbstractEntityLinker], \\\n                 context: Optional[ConText]):\n        self._entity_extractor = entity_extractor\n        self._entity_linker = entity_linker\n        self._context = context\n\n    def extract(self, text: str) -> List[Entity]:\n        entities = self._entity_extractor.get_entities(text)\n        if self._entity_linker:\n            entities = self._entity_linker.link(entities)\n\n        if self._context:\n            entities = self._context.apply(\n                text,\n                entities,\n                filter_out_rule_labels=True\n            )\n\n        return entities", "\nclass EntityPipeline:\n    def __init__(self, \\\n                 entity_extractor: AbstractEntityExtractor, \\\n                 entity_linker: Optional[AbstractEntityLinker], \\\n                 context: Optional[ConText]):\n        self._entity_extractor = entity_extractor\n        self._entity_linker = entity_linker\n        self._context = context\n\n    def extract(self, text: str) -> List[Entity]:\n        entities = self._entity_extractor.get_entities(text)\n        if self._entity_linker:\n            entities = self._entity_linker.link(entities)\n\n        if self._context:\n            entities = self._context.apply(\n                text,\n                entities,\n                filter_out_rule_labels=True\n            )\n\n        return entities", "\nclass RelationPipeline:\n    def __init__(self, \\\n                 entity_pipeline: EntityPipeline,\n                 entity_annotator: EntityAnnotator,\n                 relation_extractor: RelationExtractor):\n        self._entity_pipeline = entity_pipeline\n        self._entity_annotator = entity_annotator\n        self._relation_extractor = relation_extractor\n\n    def extract(self, text: str) -> Tuple[List[Entity], List[Relation]]:\n        entities = self._entity_pipeline.extract(text)\n        relations = self._relation_extractor.extract(\n            self._entity_annotator.annotate(text, entities),\n            entities\n        )\n\n        return entities, relations", ""]}
{"filename": "src/extr/pipelines/__init__.py", "chunked_list": ["from .pipes import EntityPipeline, RelationPipeline\n"]}
{"filename": "src/extr/utils/iterutils.py", "chunked_list": ["def flatten(items) -> list:\n    flat_list = []\n    for sublist in items:\n        for item in sublist:\n            flat_list.append(item)\n\n    return flat_list\n"]}
{"filename": "src/extr/utils/query.py", "chunked_list": ["from typing import Dict, List, TypeVar, Generic, Callable, Optional\nfrom copy import deepcopy\n\nT = TypeVar('T')\n\n# pylint: disable=C0103\nTQuery = TypeVar('TQuery', bound='Query')\n# pylint: enable=C0103\n\nclass Query(Generic[T]):\n    def __init__(self: TQuery, sequence: List[T]):\n        self._sequence = deepcopy(sequence)\n\n    def __filter(self: TQuery, filter_method: Callable[[T], bool]) -> List[T]:\n        return list(filter(filter_method, self._sequence))\n\n    def filter(self: TQuery, filter_method: Callable[[T], bool]) -> TQuery:\n        self._sequence = self.__filter(filter_method)\n        return self\n\n    def find(self: TQuery, find_method: Callable[[T], bool]) -> Optional[T]:\n        observations = self.__filter(find_method)\n\n        size = len(observations)\n        if size > 1:\n            raise Exception('Search was not unique.')\n\n        if size == 1:\n            return observations[0]\n\n        return None\n\n    def tolist(self: TQuery) -> List[T]:\n        return self._sequence\n\n    def todict(self: TQuery, key_method: Callable[[T], str]) -> Dict[str, T]:\n        mapping: Dict[str, T] = {}\n        for item in self._sequence:\n            mapping[key_method(item)] = item\n\n        return mapping", "\nclass Query(Generic[T]):\n    def __init__(self: TQuery, sequence: List[T]):\n        self._sequence = deepcopy(sequence)\n\n    def __filter(self: TQuery, filter_method: Callable[[T], bool]) -> List[T]:\n        return list(filter(filter_method, self._sequence))\n\n    def filter(self: TQuery, filter_method: Callable[[T], bool]) -> TQuery:\n        self._sequence = self.__filter(filter_method)\n        return self\n\n    def find(self: TQuery, find_method: Callable[[T], bool]) -> Optional[T]:\n        observations = self.__filter(find_method)\n\n        size = len(observations)\n        if size > 1:\n            raise Exception('Search was not unique.')\n\n        if size == 1:\n            return observations[0]\n\n        return None\n\n    def tolist(self: TQuery) -> List[T]:\n        return self._sequence\n\n    def todict(self: TQuery, key_method: Callable[[T], str]) -> Dict[str, T]:\n        mapping: Dict[str, T] = {}\n        for item in self._sequence:\n            mapping[key_method(item)] = item\n\n        return mapping", ""]}
{"filename": "src/extr/utils/__init__.py", "chunked_list": ["from .iterutils import flatten\nfrom .query import Query\n"]}
{"filename": "src/extr/tokenizers/tokenizer.py", "chunked_list": ["from typing import List\nfrom extr import Location\nfrom ..models import Token, TokenGroup\n\n\ndef word_tokenizer(text: str, tokens: List[str]) -> TokenGroup:\n    cache = text[:]\n\n    offset = 0\n    tokens_in_sentence: List[Token] = []\n    for term in tokens:\n        start = cache.find(term)\n        end = start + len(term)\n\n        actual_term = cache[start:end]\n        assert actual_term == term, f'mismatch(\"{actual_term}\", \"{term}\")'\n\n        tokens_in_sentence.append(\n            Token(term, Location(offset + start, offset + end), len(tokens_in_sentence) + 1)\n        )\n\n        cache = cache[end:]\n        offset += end\n\n    sentence_start = tokens_in_sentence[0].location.start\n    sentence_end = tokens_in_sentence[-1].location.end\n\n    token_group = TokenGroup(\n        Location(sentence_start, sentence_end),\n        text[sentence_start:sentence_end],\n        tokens_in_sentence\n    )\n\n    return token_group", ""]}
{"filename": "src/extr/tokenizers/__init__.py", "chunked_list": ["from .tokenizer import word_tokenizer\n"]}
{"filename": "src/extr/relations/__init__.py", "chunked_list": ["from .extractor import AbstractRelationExtractor, RelationExtractor\nfrom .annotator import RelationAnnotator, RelationAnnotatorWithEntityType, HtmlRelationAnnotator\nfrom .label_builder import RegExRelationLabelBuilder, RelationLabelBuilderConfig\n"]}
{"filename": "src/extr/relations/label_builder.py", "chunked_list": ["from typing import List, TypeVar\nfrom dataclasses import dataclass, field\n\nfrom ..regexes import RegEx, RegExLabel\n\n\n# pylint: disable=C0103\nTRegExRelationLabelBuilder = TypeVar('TRegExRelationLabelBuilder', bound='RegExRelationLabelBuilder')\n# pylint: enable=C0103\n", "# pylint: enable=C0103\n\n@dataclass\nclass RelationLabelBuilderConfig:\n    flags: int = 0\n    skip_if: List[str] = field(default_factory=lambda: [])\n\nclass RegExRelationLabelBuilder:\n    def __init__(self: TRegExRelationLabelBuilder, label: str) -> None:\n        self._label = label\n        self._expressions: List[RegEx] = []\n\n    @property\n    def label(self: TRegExRelationLabelBuilder) -> str:\n        return self._label\n\n    def add_e1_to_e2(self: TRegExRelationLabelBuilder, \\\n                     e1: str, relation_expressions: List[str], \\\n                     e2: str, config = RelationLabelBuilderConfig() \\\n    ) -> TRegExRelationLabelBuilder:\n        self._expressions.append(\n            RegEx(\n                expressions=list(\n                    map(\n                        lambda expression: r'(?P<e1>##ENTITY_' + e1 + r'_\\d+##)' + expression + r'(?P<e2>##ENTITY_' + e2 + r'_\\d+##)',\n                        relation_expressions\n                    )\n                ),\n                flags=config.flags,\n                skip_if=config.skip_if\n            )\n        )\n\n        return self\n\n    def add_e2_to_e1(self: TRegExRelationLabelBuilder, e2: str, \\\n                     relation_expressions: List[str], \\\n                     e1: str, config = RelationLabelBuilderConfig() \\\n    ) -> TRegExRelationLabelBuilder:\n        self._expressions.append(\n            RegEx(\n                expressions=list(\n                    map(\n                        lambda expression: r'(?P<e2>##ENTITY_' + e2 + r'_\\d+##)' + expression + r'(?P<e1>##ENTITY_' + e1 + r'_\\d+##)',\n                        relation_expressions\n                    )\n                ),\n                flags=config.flags,\n                skip_if=config.skip_if\n            )\n        )\n\n        return self\n\n    def build(self: TRegExRelationLabelBuilder) -> RegExLabel:\n        return RegExLabel(self.label, self._expressions)", ""]}
{"filename": "src/extr/relations/annotator.py", "chunked_list": ["import re\nfrom ..models import Relation, Entity\n\n\nclass RelationAnnotator:\n    def display_entity(self, entity: Entity, position: int) -> str:\n        return f'<e{str(position)}>{entity.text}</e{str(position)}>'\n\n    def annotate(self, text: str, relation: Relation) -> str:\n        annotated_text = text[:]\n\n        e1 = relation.e1\n        e1_start = e1.location.start\n        e1_end = e1.location.end\n\n        e2 = relation.e2\n        e2_start = e2.location.start\n        e2_end = e2.location.end\n\n        if e1_end < e2_start:\n            return annotated_text[:e1_start] + \\\n                self.display_entity(e1, 1) + \\\n                annotated_text[e1_end:e2_start] + \\\n                self.display_entity(e2, 2) + \\\n                annotated_text[e2_end:]\n\n        return annotated_text[:e2_start] + \\\n            self.display_entity(e2, 2) + \\\n            annotated_text[e2_end:e1_start] + \\\n            self.display_entity(e1, 1) + \\\n            annotated_text[e1_end:]", "\nclass RelationAnnotatorWithEntityType(RelationAnnotator):\n    def display_entity(self, entity: Entity, position: int) -> str:\n        return f'<e{str(position)}:{entity.label}>{entity.text}</e{str(position)}:{entity.label}>'\n\nclass HtmlRelationAnnotator(RelationAnnotator):\n    def display_entity(self, entity: Entity, position: int) -> str:\n        key = re.sub(r' ', '-', entity.label)\n        return f'<span class=\"entity lb-{key} e{position}\">' + \\\n            f'<span class=\"label\">{entity.label}</span>' + \\\n            f'{entity.text}' + \\\n            '</span>'", ""]}
{"filename": "src/extr/relations/extractor.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import List, Generator, cast\n\nimport re\nfrom ..regexes import RegExLabel\nfrom ..models import Relation, Entity\nfrom ..utils import flatten\n\n\nclass AbstractRelationExtractor(ABC):\n    @abstractmethod\n    def extract(self, text: str, entities: List[Entity]) -> List[Relation]:\n        pass", "\nclass AbstractRelationExtractor(ABC):\n    @abstractmethod\n    def extract(self, text: str, entities: List[Entity]) -> List[Relation]:\n        pass\n\nclass RelationExtractor(AbstractRelationExtractor):\n    def __init__(self, relation_labels: List[RegExLabel]) -> None:\n        self._relation_labels = relation_labels\n\n    def extract(self, text: str, entities: List[Entity]) -> List[Relation]:\n        entity_lookup = { str(entity): entity for entity in entities }\n\n        def create_relation(label, match: re.Match) -> Relation:\n            group = match.groupdict()\n            e1_key = group['e1']\n            e2_key = group['e2']\n\n            return Relation(\n                label,\n                entity_lookup[e1_key],\n                entity_lookup[e2_key]\n            )\n\n        def handler(relationship_label: RegExLabel) -> Generator[Relation, None, None]:\n            return (\n                create_relation(label, match)\n                for label, match in relationship_label.findall(text)\n            )\n\n        return cast(List[Relation], flatten(map(handler, self._relation_labels)))", ""]}
{"filename": "src/extr/relations/viewers/__init__.py", "chunked_list": ["from .html import HtmlViewer\n"]}
{"filename": "src/extr/relations/viewers/html.py", "chunked_list": ["from typing import List, Optional\n\nfrom ...models import Relation\nfrom ...entities.viewers.html import __TEMPLATE__\nfrom ..annotator import HtmlRelationAnnotator\n\nclass HtmlViewer:\n    __TEMPLATE = __TEMPLATE__ \\\n        .replace(\n            '{{body}}',\n            \"\"\"        <table>\n{{body}}\n        </table>\"\"\"\n        )\n\n    __DEFAULT_STYLES = \"\"\"\ntable { width: 100%; }\nspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\nspan.label { font-weight: bold; padding: 3px; color: black; }\nspan.e1 { background-color: aqua; }\nspan.e2 { background-color: coral; }\ntr.delete { background-color: black !important; }\ntr.delete span { background-color: black !important; }\ntd { line-height: 30px; border: 1px solid black; padding: 5px; }\ntd.header { font-weight: bold; }\ntd.label { font-weight: bold; text-align: center; }\n\"\"\"\n\n    def __init__(self, show_index=True) -> None:\n        self._relation_index = 0\n        self._show_index = show_index\n        self._rows: List[str] = []\n        self._annotator = HtmlRelationAnnotator()\n\n    def append_header(self, header: str) -> None:\n        colspan = 3 if self._show_index else 2\n        self._rows.append(\n            '<tr>' + \\\n                f'<td class=\"header\" colspan=\"{colspan}\">{header}</td>' + \\\n            '</tr>'\n        )\n\n    def append_relation(self, text: str, relation: Relation) -> None:\n        index = self._relation_index\n        annotation = self._annotator.annotate(text, relation)\n        self._rows.append(\n            f'<tr id=\"{index}\">' + \\\n                (f'<td>{index}</td>' if self._show_index else '') + \\\n                f'<td class=\"label\">{relation.label}</td>' + \\\n                f'<td>{annotation}</td>' + \\\n            '</tr>'\n        )\n\n        self._relation_index += 1\n\n    def create_view(self, custom_styles: Optional[str] = None) -> str:\n        styles = self.__DEFAULT_STYLES.strip()\n        if custom_styles:\n            styles += f'\\n{custom_styles.strip()}'\n\n        body = '\\n'.join(self._rows)\n\n        return self.__TEMPLATE \\\n            .replace('{{styles}}', styles) \\\n            .replace('{{body}}', body) \\\n            .strip()", ""]}
{"filename": "src/extr/entities/context.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import Callable, Generator, List, Optional, Set\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom ..models import Entity, Token\nfrom ..tokenizers import word_tokenizer as tokenizer\n\n\nclass DirectionType(Enum):\n    LEFT=0\n    RIGHT=1\n    BOTH=2", "class DirectionType(Enum):\n    LEFT=0\n    RIGHT=1\n    BOTH=2\n\nclass ConTextRule:\n    def __init__(self,\n                 attribute: str,\n                 labels: List[str],\n                 window_size: int = 5,\n                 direction: DirectionType = DirectionType.RIGHT,\n                 exit_labels: Optional[List[str]] = None) -> None:\n        self._attribute = attribute\n        self._labels = labels\n        self._window_size = window_size\n        self._direction = direction\n        self._exit_labels = labels[:] + ([] if exit_labels is None else exit_labels)\n\n    @property\n    def attribute(self) -> str:\n        return self._attribute\n\n    @property\n    def labels(self) -> List[str]:\n        return self._labels\n\n    @property\n    def window_size(self) -> int:\n        return self._window_size\n\n    @property\n    def direction(self) -> DirectionType:\n        return self._direction\n\n    @property\n    def exit_labels(self) -> List[str]:\n        return self._exit_labels", "\n@dataclass\nclass ConTextRuleGroup:\n    rules: List[ConTextRule]\n\n    def get_rules(self, token: Token) -> Generator[ConTextRule, None, None]:\n        entity_labels: Set[str] = set(entity.label for entity in token.entities)\n        for rule in self.rules:\n            if any(\n                label\n                for label in rule.labels\n                if label in entity_labels\n            ):\n                yield rule", "\nclass AbstractConText(ABC):\n    @abstractmethod\n    def apply(self, text: str, entities: List[Entity], filter_out_rule_labels: bool = True) -> List[Entity]:\n        pass\n\nclass ConText(AbstractConText):\n    def __init__(self, \\\n                 rule_grouping: ConTextRuleGroup, \\\n                 word_tokenizer: Callable[[str], List[str]], \\\n                 attribute_label: str = 'ctypes') -> None:\n        self._rule_grouping = rule_grouping\n        self._word_tokenizer = word_tokenizer\n        self._attribute_label = attribute_label\n\n    @staticmethod\n    def get_tokens_by_direction(current_index: int, window_size: int, direction: DirectionType, tokens: List[Token]) -> List[Token]:\n        if direction == DirectionType.RIGHT:\n            start = current_index + 1\n            end = min([start + window_size, len(tokens)])\n            return tokens[start:end]\n\n        if direction == DirectionType.LEFT:\n            start = max([current_index - 1 - window_size, 0])\n            end = current_index\n            return tokens[start:end][::-1]\n\n        return []\n\n    def apply(self, text: str, entities: List[Entity], filter_out_rule_labels: bool = True) -> List[Entity]:\n        token_group = tokenizer(text, self._word_tokenizer(text))\n        token_group.apply_entities(entities)\n\n        tokens = token_group.tokens\n        for current_index, token in enumerate(tokens):\n            for rule in self._rule_grouping.get_rules(token):\n                for tokens_by_direction in self._get_tokens_for_rule(\n                    current_index,\n                    rule,\n                    tokens\n                ):\n                    self._process_direction_for_rule(rule, tokens_by_direction)\n\n        if filter_out_rule_labels:\n            all_labels: List[str] = []\n            for rule in self._rule_grouping.rules:\n                all_labels.extend(rule.labels)\n                all_labels.extend(rule.exit_labels)\n\n            labels = set(all_labels)\n\n            return [\n                entity\n                for entity in entities\n                if not entity.label in labels\n            ]\n\n        return entities\n\n    def _get_tokens_for_rule(self, current_index: int, rule: ConTextRule, tokens: List[Token]) -> Generator[List[Token], None, None]:\n        directions = [DirectionType.RIGHT, DirectionType.LEFT] \\\n            if rule.direction == DirectionType.BOTH \\\n            else [rule.direction]\n\n        for direction in directions:\n            yield ConText.get_tokens_by_direction(current_index, rule.window_size, direction, tokens)\n\n    def _process_direction_for_rule(self, rule: ConTextRule, tokens: List[Token]) -> None:\n        for token in tokens:\n            exit_condition_met = any(\n                entity\n                for entity in token.entities\n                if entity.label in rule.exit_labels\n            )\n\n            if exit_condition_met:\n                break\n\n            token.apply_attribute(self._attribute_label, rule.attribute)", ""]}
{"filename": "src/extr/entities/factories.py", "chunked_list": ["from typing import List, Dict, Optional\n\nfrom .extractor import EntityExtractor\nfrom ..regexes import RegExLabel, transform_knowledge\n\n\ndef create_entity_extractor(regex_labels: List[RegExLabel], kb: Optional[Dict[str, List[str]]] = None):\n    all_regex_labels = []\n\n    if len(regex_labels) > 0:\n        all_regex_labels.extend(regex_labels)\n\n    if kb:\n        all_regex_labels.extend(\n            [transform_knowledge(label, expressions) for label, expressions in kb.items()]\n        )\n\n    return EntityExtractor(all_regex_labels)", ""]}
{"filename": "src/extr/entities/__init__.py", "chunked_list": ["from .extractor import AbstractEntityExtractor, EntityExtractor\nfrom .annotator import EntityAnnotator, \\\n                       HtmlEntityAnnotator, \\\n                       LabelOnlyEntityAnnotator\nfrom .linkers import AbstractEntityLinker, \\\n                     KnowledgeBaseEntityLinker\nfrom .factories import create_entity_extractor\n"]}
{"filename": "src/extr/entities/annotator.py", "chunked_list": ["from typing import List\nimport re\n\nfrom ..models import Entity\n\n\nclass EntityAnnotator:\n    def display_entity(self, entity: Entity) -> str:\n        return str(entity)\n\n    def annotate(self, text: str, entities: List[Entity]) -> str:\n        def insert_entity(text: str, entity: Entity) -> str:\n            start = entity.start\n            end = entity.end\n            return text[:start] + self.display_entity(entity) + text[end:]\n\n        annotated_text = text[:]\n        for entity in entities:\n            annotated_text = insert_entity(annotated_text, entity)\n\n        return annotated_text", "\nclass LabelOnlyEntityAnnotator(EntityAnnotator):\n    def display_entity(self, entity: Entity) -> str:\n        return f'<{entity.label}>{entity.text}</{entity.label}>'\n\nclass HtmlEntityAnnotator(EntityAnnotator):\n    def display_entity(self, entity: Entity) -> str:\n        key = re.sub(r' ', '-', entity.label)\n        return f'<span class=\"entity lb-{key}\">' + \\\n            f'<span class=\"label\">{entity.label}</span>' + \\\n            f'{entity.text}' + \\\n            '</span>'", "    "]}
{"filename": "src/extr/entities/extractor.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import List\n\nfrom ..regexes import RegExLabel\nfrom ..models import Location, Entity\n\n\nclass AbstractEntityExtractor(ABC):\n    @abstractmethod\n    def get_entities(self, text: str) -> List[Entity]:\n        pass", "\nclass EntityExtractor(AbstractEntityExtractor):\n    def __init__(self, regex_labels: List[RegExLabel]) -> None:\n        self._regex_labels = regex_labels\n\n    def get_entities(self, text: str) -> List[Entity]:\n        entities: List[Entity] = []\n        for regex_label in self._regex_labels:\n            for label, match in regex_label.findall(text):\n                entities.append(\n                    Entity(\n                        len(entities) + 1,\n                        label,\n                        match.group(),\n                        Location(*match.span())\n                    )\n                )\n\n        if len(entities) == 0:\n            return []\n\n        ## sort descending\n        all_found_entities = sorted(\n            entities,\n            key=lambda entity: (entity.end, -entity.start),\n            reverse=True\n        )\n\n        slim_entities = [\n            all_found_entities[0]\n        ]\n\n        for curr_entity in all_found_entities[1:]:\n            if curr_entity.is_in(slim_entities[-1]):\n                continue\n\n            slim_entities.append(curr_entity)\n\n        return slim_entities", ""]}
{"filename": "src/extr/entities/linkers.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import Dict, List\nfrom ..models import Entity\n\n\nclass AbstractEntityLinker(ABC):\n    def __init__(self, attribute_label: str) -> None:\n        self._attribute_label = attribute_label\n\n    @property\n    def attribute_label(self) -> str:\n        return self._attribute_label\n\n    @abstractmethod\n    def link(self, entities: List[Entity]) -> List[Entity]:\n        pass", "\nclass KnowledgeBaseEntityLinker(AbstractEntityLinker):\n    def __init__(self, attribute_label: str, kb: Dict[str, str]) -> None:\n        super().__init__(attribute_label)\n        self._kb = kb\n\n    def link(self, entities: List[Entity]) -> List[Entity]:\n        for entity in entities:\n            key = entity.text\n\n            if key in self._kb:\n                entity.add_attribute(self._attribute_label, self._kb[key])\n\n        return entities", ""]}
{"filename": "src/extr/entities/viewers/__init__.py", "chunked_list": ["from .html import HtmlViewer\n"]}
{"filename": "src/extr/entities/viewers/html.py", "chunked_list": ["from typing import List, Optional\n\nfrom ...models import Entity\nfrom ..annotator import HtmlEntityAnnotator\n\n\n__TEMPLATE__ = \"\"\"\n<html>\n    <head>\n        <style>", "    <head>\n        <style>\n{{styles}}\n        </style>\n    </head>\n    <body>\n{{body}}\n    </body>\n</html>\n    \"\"\"", "</html>\n    \"\"\"\n\n\nclass HtmlViewer:\n    __TEMPLATE = __TEMPLATE__\n\n    __DEFAULT_STYLES = \"\"\"\np { margin: 5px; line-height: 45px; }\nspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\nspan.label { font-weight: bold; padding: 3px; color: black; }\n\"\"\"\n\n    def __init__(self, annotations: Optional[List[str]] = None) -> None:\n        self._rows: List[str] = annotations if annotations is not None else []\n        self._annotator = HtmlEntityAnnotator()\n\n    def append(self, text: str, entities: List[Entity]) -> None:\n        self._rows.append(\n            self._annotator.annotate(text, entities)\n        )\n\n    def create_view(self, custom_styles: Optional[str] = None, spacer='<hr />') -> str:\n        styles = self.__DEFAULT_STYLES.strip()\n        if custom_styles:\n            styles += f'\\n{custom_styles.strip()}'\n\n        format_annoations = (f'<p>{annotation}</p>' for annotation in self._rows)\n        body = f'{spacer}\\n'.join(format_annoations)\n\n        return self.__TEMPLATE \\\n            .replace('{{styles}}', styles) \\\n            .replace('{{body}}', body) \\\n            .strip()", ""]}
