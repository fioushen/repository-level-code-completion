{"filename": "ardilla/ordering.py", "chunked_list": ["from typing import Container\n\ndef validate_ordering(columns: Container[str], order_by: dict[str, str]) -> dict[str, str]:\n    \"\"\"validates an ordering dictionary\n    The ordering should have this structure:\n        {\n            'column_name': 'ASC' OR 'DESC'\n        }\n    Case in values is insensitive\n    \n    Args:\n        columns (Container[str]): a collection of columns to check the keys against\n        order_by (dict[str, str]): \n\n    Raises:\n        KeyError: if the key is not listed in the columns of the table\n        ValueError: if the value is not either ASC or DESC\n\n    Returns:\n        dict[str, str]: a copy of the ordering dict with values in uppercase\n    \"\"\"\n    out = order_by.copy()\n    for k, v in order_by.items():\n        if k not in columns:\n            raise KeyError(f'\"{k}\" is not a valid column name')\n        elif v.lower() not in {'desc', 'asc'}:\n            raise ValueError(f'\"{k}\" value \"{v}\" is invalid, must be either \"asc\" or \"desc\" (case insensitive)')\n        else:\n            out[k] = v.upper()\n    return out"]}
{"filename": "ardilla/abc.py", "chunked_list": ["from __future__ import annotations\nimport sqlite3\nfrom typing import Any, Literal, TypeVar, Optional, Union\nfrom abc import abstractmethod, ABC\nfrom sqlite3 import Row\n\nfrom .models import M, Model as BaseModel\n\nE = TypeVar(\"E\")  # Engine Type\n", "E = TypeVar(\"E\")  # Engine Type\n\nConnection = TypeVar(\"Connection\")\nCrudType = TypeVar('CrudType', bound='BaseCrud')\n\n\nclass BaseEngine(ABC):\n    \"\"\"This just provides autocompletition across the library\"\"\"\n\n    __slots__ = (\n        \"path\",  # the path to the database\n        \"schemas\",  # the registered tables\n        \"tables_created\",  # a list of tables that were setup\n        \"enable_foreing_keys\",  # a bool to specify if the pragma should be enforced\n        \"con\", # sync connection\n        \"_cruds\", # crud cache\n    )\n    \n    def check_connection(self) -> bool:\n        \"\"\"Checks if the engine's connection is alive\n        works for both the sync and async classes\n\n        Returns:\n            bool: if the connection is fine\n        \"\"\"\n        con: Union[Connection, None] = getattr(self, 'con', None)\n        try:\n            if isinstance(con, sqlite3.Connection):\n                con.cursor()\n                return True\n            elif con is not None:\n                # should be aiosqlite\n                # we don't import it here to prevent import errors \n                # in case there's missing dependency of aiosqlite\n                return con._running and con._connection\n            else:\n                return None\n        except:\n            return False\n\n    def __init__(\n        self,\n        path: str,\n        enable_foreing_keys: bool = False,\n    ):\n        self.path = path\n        self.schemas: set[str] = set()\n        self.tables_created: set[str] = set()\n        self._cruds: dict[type[M], CrudType] = {}\n        self.enable_foreing_keys = enable_foreing_keys\n    \n    @abstractmethod\n    def get_connection(self) -> Connection:\n        ...\n        \n    @abstractmethod\n    def connect(self) -> Connection:\n        ...\n        \n    @abstractmethod\n    def close(self) -> None:\n        ...\n\n    @abstractmethod\n    def crud(self, Model: type[M]) -> CrudType:\n        ...", "\n\nclass BaseCrud(ABC):\n    __slots__ = (\n        \"connection\",\n        \"tablename\",\n        \"Model\",\n        \"columns\",\n    )\n\n    def __init__(self, Model: type[M], connection: Connection) -> None:\n        self.Model = Model\n        self.connection = connection\n\n        self.tablename = Model.__tablename__\n        self.columns = tuple(Model.__fields__)\n\n    def __new__(cls, Model: type[M], connection: Connection):\n        if not issubclass(Model, BaseModel):\n            raise TypeError(\"Model param has to be a subclass of model\")\n\n        return super().__new__(cls)\n\n    def verify_kws(self, kws: dict[str, Any]) -> Literal[True]:\n        \"\"\"Verifies that the passed kws keys in dictionary\n        are all contained within the model's fields\n\n        Args:\n            kws (dict[str, Any]): the keyword arguments for queries\n\n        Returns:\n            Literal[True]: If the kws are verified\n        \"\"\"\n        for key in kws:\n            if key not in self.Model.__fields__:\n                raise KeyError(\n                    f'\"{key}\" is not a field of the \"{self.Model.__name__}\" and cannot be used in queries'\n                )\n        return True\n\n    def _row2obj(self, row: Row, rowid: Optional[int] = None) -> BaseModel:\n        \"\"\"\n        Args:\n            row: the sqlite row\n            rowid: the rowid of the row.\n                If passed it means it comes from an insert function\n\n        \"\"\"\n        keys = list(self.Model.__fields__)\n        if rowid is None:\n            rowid, *vals = row\n        else:\n            vals = list(row)\n        data = {k: v for k, v in zip(keys, vals)}\n\n        obj = self.Model(**data)\n        obj.__rowid__ = rowid\n        return obj\n\n    # Create\n    @abstractmethod\n    def _do_insert(self, ignore: bool = False, returning: bool = True, /, **kws):\n        ...\n\n    @abstractmethod\n    def insert(self, **kws):\n        ...\n\n    @abstractmethod\n    def insert_or_ignore(self):\n        ...\n\n    # Read\n    @abstractmethod\n    def get_all(self) -> list[M]:\n        ...\n\n    @abstractmethod\n    def get_many(\n        self,\n        order_by: Optional[dict[str, str]] = None,\n        limit: Optional[int] = None,\n        **kws,\n    ) -> list[M]:\n        ...\n\n    @abstractmethod\n    def get_or_create(self, **kws) -> tuple[M, bool]:\n        ...\n\n    @abstractmethod\n    def get_or_none(self, **kws) -> Optional[M]:\n        ...\n\n    # Update\n    @abstractmethod\n    def save_one(self, obj: M) -> Literal[True]:\n        ...\n\n    @abstractmethod\n    def save_many(self, *objs: M) -> Literal[True]:\n        ...\n\n    # Delete\n    @abstractmethod\n    def delete_one(self, obj: M) -> Literal[True]:\n        ...\n\n    @abstractmethod\n    def delete_many(self, *objs: M) -> Literal[True]:\n        ...\n\n    @abstractmethod\n    def count(self, column: str = '*', /, **kws) -> int:\n        ..."]}
{"filename": "ardilla/errors.py", "chunked_list": ["\"\"\"\nContains the module's errors\n\"\"\"\n\n\nclass ArdillaException(Exception):\n    pass\n\n\nclass ModelIntegrityError(ArdillaException):\n    pass", "\nclass ModelIntegrityError(ArdillaException):\n    pass\n\n\nclass MissingEngine(ArdillaException):\n    pass\n\n\nclass QueryExecutionError(ArdillaException):\n    pass", "\nclass QueryExecutionError(ArdillaException):\n    pass\n\n\nclass BadQueryError(ArdillaException):\n    pass\n\n\nclass DisconnectedEngine(ArdillaException):\n    pass", "\nclass DisconnectedEngine(ArdillaException):\n    pass\n\n\ndisconnected_engine_error = DisconnectedEngine(\n    \"The engine has been disconnected and cannot operate on the database\"\n)\n\n\nclass MigrationError(ArdillaException):\n    pass", "\n\nclass MigrationError(ArdillaException):\n    pass"]}
{"filename": "ardilla/migration.py", "chunked_list": ["from typing import Optional\n\n\nfrom .models import Model\nfrom .errors import MigrationError\nfrom .schemas import make_field_schema, make_table_schema\n\n\n\ndef generate_migration_script(\n    old: type[Model],\n    new: type[Model],\n    *,\n    original_tablename: str,\n    new_tablename: Optional[str] = None\n) -> str:\n    \"\"\"_summary_\n\n    Args:\n        old (type[Model]): the old model\n        new (type[Model]): the new model\n        original_tablename (str): the tablename as it is in the database before migrating\n        new_tablename (Optional[str], optional): If the table should change its name this is the new one. Defaults to None.\n\n    Raises:\n        MigrationError: Migration includes a new field with unique constraint\n        MigrationError: Migration includes a new field with primary key constraint\n        MigrationError: Migration includes a not null field without a default value\n\n    Returns:\n        str: The migration script. Execute it with an sqlite3 connection\n    \"\"\"      \n    scripts = []\n\n    if new_tablename is not None:\n        scripts.append(\n            f\"ALTER TABLE {original_tablename} RENAME TO {new_tablename};\"\n        )\n    \n    tablename = tablename if not new_tablename else new_tablename\n\n    old_fields = set(old.__fields__)\n    new_fields = set(new.__fields__)\n\n    dropped = old_fields - new_fields\n    for field_name in dropped:\n        scripts.append(f\"ALTER TABLE {tablename} DROP COLUMN {field_name};\")\n\n    added = new_fields - old_fields\n    for field_name in added:\n        field = new.__fields__[field_name]\n        schema = make_field_schema(field)\n        if schema[\"unique\"]:\n            raise MigrationError(\n                f\"cannot process '{field_name}' because it's marked as unique\"\n            )\n            continue\n        if schema[\"pk\"]:\n            raise MigrationError(\n                f\"cannot process '{field_name}' because it's marked as primary key\"\n            )\n        field_schema = schema[\"schema\"]\n        if \"NOT NULL\" in field_schema and not \"DEFAULT\" in field_schema:\n            raise MigrationError(\n                f'Cannot script a \"not null\" field without default value in field \"{field_name}\"'\n            )\n\n        scripts.append(f\"ALTER TABLE {tablename} ADD COLUMN {field_schema};\")\n\n    conserved = old_fields & new_fields\n    alter_fields = False\n    for f in conserved:\n        old_schema = make_field_schema(old.__fields__[f])\n        new_schema = make_field_schema(new.__fields__[f])\n        if old_schema != new_schema:\n            alter_fields = True\n            \n            # if old.__fields__[f].type_ != new.__fields__[f].type_:\n            #     print(\n            #         f\"Ardilla can't handle type changes for now. \"\n            #         f\"You'll have to migrate this on your own.\"\n            #     )\n            #     alter_fields = False\n            #     break\n\n    if alter_fields is True:\n        new_table_schema = make_table_schema(new)\n        cols = ', '.join(name for name in new.__fields__)\n\n        script = f'''\n        \\rALTER TABLE {tablename} RENAME TO _{tablename};\n        \\r\n        \\r{new_table_schema}\n        \\r\n        \\rINSERT INTO {tablename} ({cols})\n        \\r  SELECT {cols}\n        \\r  FROM _{tablename};\n        \\r\n        \\rDROP TABLE _{tablename};\n        \\r'''\n\n        scripts.append(script)\n        \n\n    return \"\\n\\n\".join(scripts)", "\ndef generate_migration_script(\n    old: type[Model],\n    new: type[Model],\n    *,\n    original_tablename: str,\n    new_tablename: Optional[str] = None\n) -> str:\n    \"\"\"_summary_\n\n    Args:\n        old (type[Model]): the old model\n        new (type[Model]): the new model\n        original_tablename (str): the tablename as it is in the database before migrating\n        new_tablename (Optional[str], optional): If the table should change its name this is the new one. Defaults to None.\n\n    Raises:\n        MigrationError: Migration includes a new field with unique constraint\n        MigrationError: Migration includes a new field with primary key constraint\n        MigrationError: Migration includes a not null field without a default value\n\n    Returns:\n        str: The migration script. Execute it with an sqlite3 connection\n    \"\"\"      \n    scripts = []\n\n    if new_tablename is not None:\n        scripts.append(\n            f\"ALTER TABLE {original_tablename} RENAME TO {new_tablename};\"\n        )\n    \n    tablename = tablename if not new_tablename else new_tablename\n\n    old_fields = set(old.__fields__)\n    new_fields = set(new.__fields__)\n\n    dropped = old_fields - new_fields\n    for field_name in dropped:\n        scripts.append(f\"ALTER TABLE {tablename} DROP COLUMN {field_name};\")\n\n    added = new_fields - old_fields\n    for field_name in added:\n        field = new.__fields__[field_name]\n        schema = make_field_schema(field)\n        if schema[\"unique\"]:\n            raise MigrationError(\n                f\"cannot process '{field_name}' because it's marked as unique\"\n            )\n            continue\n        if schema[\"pk\"]:\n            raise MigrationError(\n                f\"cannot process '{field_name}' because it's marked as primary key\"\n            )\n        field_schema = schema[\"schema\"]\n        if \"NOT NULL\" in field_schema and not \"DEFAULT\" in field_schema:\n            raise MigrationError(\n                f'Cannot script a \"not null\" field without default value in field \"{field_name}\"'\n            )\n\n        scripts.append(f\"ALTER TABLE {tablename} ADD COLUMN {field_schema};\")\n\n    conserved = old_fields & new_fields\n    alter_fields = False\n    for f in conserved:\n        old_schema = make_field_schema(old.__fields__[f])\n        new_schema = make_field_schema(new.__fields__[f])\n        if old_schema != new_schema:\n            alter_fields = True\n            \n            # if old.__fields__[f].type_ != new.__fields__[f].type_:\n            #     print(\n            #         f\"Ardilla can't handle type changes for now. \"\n            #         f\"You'll have to migrate this on your own.\"\n            #     )\n            #     alter_fields = False\n            #     break\n\n    if alter_fields is True:\n        new_table_schema = make_table_schema(new)\n        cols = ', '.join(name for name in new.__fields__)\n\n        script = f'''\n        \\rALTER TABLE {tablename} RENAME TO _{tablename};\n        \\r\n        \\r{new_table_schema}\n        \\r\n        \\rINSERT INTO {tablename} ({cols})\n        \\r  SELECT {cols}\n        \\r  FROM _{tablename};\n        \\r\n        \\rDROP TABLE _{tablename};\n        \\r'''\n\n        scripts.append(script)\n        \n\n    return \"\\n\\n\".join(scripts)", "\n"]}
{"filename": "ardilla/schemas.py", "chunked_list": ["\"\"\"\nvariables and functions here are used to generate and work with the Model's schemas\n\"\"\"\nimport re\nfrom typing import Optional, Union\nfrom datetime import datetime, date, time\nfrom pydantic import BaseModel, Json\nfrom pydantic.fields import ModelField\n\nfrom .errors import ModelIntegrityError", "\nfrom .errors import ModelIntegrityError\n\n\nSCHEMA_TEMPLATE: str = \"CREATE TABLE IF NOT EXISTS {tablename} (\\n{fields}\\n);\"\n\nSQLFieldType = Union[int, float, str, bool, datetime, bytes, date, time]\n\nFIELD_MAPPING: dict[type, str] = {\n    int: \"INTEGER\",", "FIELD_MAPPING: dict[type, str] = {\n    int: \"INTEGER\",\n    float: \"REAL\",\n    str: \"TEXT\",\n    bool: \"INTEGER\",\n    datetime: \"DATETIME\",\n    bytes: \"BLOB\",\n    date: \"DATE\",\n    time: \"TIME\",\n}", "    time: \"TIME\",\n}\n\nAUTOFIELDS = {\n    int: \" AUTOINCREMENT\",\n    datetime: \" DEFAULT CURRENT_TIMESTAMP\",\n    date: \" DEFAULT CURRENT_DATE\",\n    time: \" DEFAULT CURRENT_TIME\",\n}\n", "}\n\n\ndef get_tablename(model: type[BaseModel]) -> str:\n    \"\"\"returns the tablename of a model either from the attribute __tablenam__\n    or from the lowercase model's name\n\n    Args:\n        model (type[BaseModel]): the model\n\n    Returns:\n        str: the name of the table\n    \"\"\"\n    return getattr(model, \"__tablename__\", model.__name__.lower())", "\n\ndef make_field_schema(field: ModelField) -> dict:\n    output = {}\n    name = field.name\n    T = field.type_\n    default = field.default\n    extra = field.field_info.extra\n    auto = output[\"auto\"] = extra.get(\"auto\")\n    unique = output[\"unique\"] = extra.get(\"unique\")\n    is_pk = False\n    constraint = None\n\n    if default and unique:\n        raise ModelIntegrityError(\n            \"field {name} has both unique and default constrains which are incompatible\"\n        )\n\n    autoerror = ModelIntegrityError(\n        f'field {name} has a type of \"{T}\" which does not support \"auto\"'\n    )\n    schema = f\"{name} {FIELD_MAPPING[T]}\"\n\n    primary_field_keys = {\"pk\", \"primary\", \"primary_key\"}\n    if len(extra.keys() & primary_field_keys) > 1:\n        raise ModelIntegrityError(f'Multiple keywords for a primary field in \"{name}\"')\n\n    for k in primary_field_keys:\n        if k in extra and extra[k]:\n            is_pk = True\n\n            schema += \" PRIMARY KEY\"\n\n            if auto and T in AUTOFIELDS:\n                schema += AUTOFIELDS[T]\n                field.required = (\n                    False  # to allow users to create the objs without this field\n                )\n\n            elif auto:\n                raise autoerror\n\n            break\n    else:\n        if auto and T in AUTOFIELDS.keys() - {int}:\n            schema += AUTOFIELDS[T]\n        elif auto:\n            raise autoerror\n        elif default is not None:\n            if T in {int, str, float, bool}:\n                schema += f\" DEFAULT {default!r}\"\n            elif T in {datetime, date, time}:\n                schema += f\" DEFAULT {default}\"\n            elif T is bytes:\n                schema += f\" DEFAULT (X'{default.hex()}')\"\n        elif field.required:\n            schema += \" NOT NULL\"\n        if unique:\n            schema += \" UNIQUE\"\n\n    if extra.get(\"references\"):\n        references, fk, on_delete, on_update = (\n            extra.get(f) for f in [\"references\", \"fk\", \"on_delete\", \"on_update\"]\n        )\n        constraint = (\n            f\"FOREIGN KEY ({name}) \"\n            f\"REFERENCES {references}({fk}) \"\n            f\"ON UPDATE {on_update} \"\n            f\"ON DELETE {on_delete}\"\n        )\n\n    output.update({\"pk\": is_pk, \"schema\": schema, \"constraint\": constraint})\n\n    return output", "\n\ndef make_table_schema(Model: type[BaseModel]) -> str:\n    tablename = get_tablename(Model)\n    fields = []\n    constrains = []\n    pk = None\n    for field in Model.__fields__.values():\n        name = field\n        field_schema = make_field_schema(field)\n        if field_schema[\"pk\"] is True:\n            if pk is not None:\n                raise ModelIntegrityError(\n                    f'field \"{name}\" is marked as primary but there is already a primary key field \"{pk}\"'\n                )\n            pk = field.name\n        fields.append(field_schema[\"schema\"])\n\n        constrains.append(field_schema[\"constraint\"]) if field_schema[\n            \"constraint\"\n        ] else None\n\n    schema = (\n        f\"CREATE TABLE IF NOT EXISTS {tablename}(\\n\"\n        + \",\\n\".join(f\"\\r    {f}\" for f in (fields + constrains))\n        + \"\\n);\"\n    )\n    return schema", "\n\ndef get_pk(schema: str) -> Optional[str]:\n    \"\"\"Gets the primary key field name from the passed schema\n\n    Args:\n        schema (str): table schema\n\n    Returns:\n        Optional[str]: the name of the primary key if any\n    \"\"\"\n    # Check if the schema contains a primary key definition\n    if \"PRIMARY KEY\" in schema:\n        # Use a regular expression to extract the primary key column name\n        match = re.search(r\"(?i)\\b(\\w+)\\b\\s+(?:\\w+\\s+)*PRIMARY\\s+KEY\", schema)\n        if match:\n            return match.group(1)\n    return None", ""]}
{"filename": "ardilla/models.py", "chunked_list": ["\"\"\"\nContains the Model object and typing alias to work with the engines and Cruds\n\"\"\"\n\nfrom typing import Optional, TypeVar\nfrom pydantic import BaseModel, PrivateAttr\n\nfrom .schemas import make_table_schema, FIELD_MAPPING, get_tablename, get_pk\nfrom .errors import ModelIntegrityError\n", "from .errors import ModelIntegrityError\n\n\nclass Model(BaseModel):\n    \"\"\"\n    The base model representing SQLite tables\n    Inherits directly from pydantic.BaseModel\n    \n    Attributes:\n        __rowid__ (int | None): (class attribute) when an object is returned by a query it will \n            contain the rowid field that can be used for update and deletion.\n        __pk__ (str | None): (class attribute) Holds the primary key column name of the table\n        __tablename__ (str): (class attribute) the name of the table in the database\n        __schema__(str): the (class attribute) schema for the table.\n        \n    Example:\n        ```py\n        from ardilla import Model, Field\n        # Field is actually pydantic.Field but it's imported here for the convenience of the developer\n        \n        class User(Model):\n            __tablename__ = 'users' # by default the tablename is just the model's name in lowercase\n            id: int = Field(primary=True) # sets this field as the primary key\n            name: str\n        ```\n    \"\"\"\n    __rowid__: Optional[int] = PrivateAttr(default=None)\n    __pk__: Optional[str]  # tells the model which key to idenfity as primary\n    __tablename__: str  # will default to the lowercase name of the subclass\n    __schema__: str  # best effort will be made if it's missing\n    # there's no support for constrains or foreign fields yet but you can\n    # define your own schema to support them\n\n    def __init_subclass__(cls, **kws) -> None:\n\n        for field in cls.__fields__.values():\n            if field.type_ not in FIELD_MAPPING:\n                raise ModelIntegrityError(\n                    f'Field \"{field.name}\" of model \"{cls.__name__}\" is of unsupported type \"{field.type_}\"'\n                )\n\n            if field.field_info.extra.keys() & {'primary', 'primary_key', 'pk'}:\n                if getattr(cls, '__pk__', None) not in {None, field.name}:\n                    raise ModelIntegrityError('More than one fields defined as primary')\n                \n                cls.__pk__ = field.name \n\n        if not hasattr(cls, \"__schema__\"):\n            cls.__schema__ = make_table_schema(cls)\n        \n        if not hasattr(cls, '__pk__'):\n            cls.__pk__ = get_pk(cls.__schema__)\n\n        if not hasattr(cls, \"__tablename__\"):\n            tablename = get_tablename(cls)\n            setattr(cls, \"__tablename__\", tablename)\n\n        super().__init_subclass__(**kws)\n\n    def __str__(self) -> str:\n        return f\"{self!r}\"", "\n\nM = TypeVar(\"M\", bound=Model)\n"]}
{"filename": "ardilla/__init__.py", "chunked_list": ["from .engine import Engine as Engine\nfrom .models import Model as Model\nfrom .crud import Crud as Crud\nfrom .fields import Field, ForeignField"]}
{"filename": "ardilla/engine.py", "chunked_list": ["from __future__ import annotations\nimport sqlite3\nfrom typing import Union\n\nfrom .models import M\nfrom .crud import Crud\nfrom .abc import BaseEngine\nfrom .errors import DisconnectedEngine\n\nclass Engine(BaseEngine):\n    \"\"\"The sync engine that uses `sqlite3.Connection` and `sqlite3.Cursor`\n    \n    Args:\n        path (str): a pathlike object that points to the sqlite database\n        enable_foreing_keys (bool, optional): specifies if the pragma should be enforced. Defaults to False.\n    \n    Attributes:\n        path (str): the path to the db\n        schemas (set[str]): a set of table schemas\n        tables_created (set[str]): the tables that have been setup by the engine\n        enable_foreing_keys (bool): if True, the engine enables the pragma on all connections\n    \"\"\"\n    con: sqlite3.Connection\n    \n    def __init__(self, path: str, enable_foreing_keys: bool = False):\n        super().__init__(path, enable_foreing_keys)\n    \n    def get_connection(self) -> sqlite3.Connection:\n        \"\"\"Gets the connections or makes a new one but it doesn't set it as an attrib\n\n        Returns:\n            sqlite3.Connection: the connection\n        \"\"\"\n        con: Union[sqlite3.Connection, None] = getattr(self, 'con', None)\n        if not self.check_connection():\n            con = sqlite3.connect(self.path)\n            con.row_factory = sqlite3.Row\n            \n            if self.enable_foreing_keys:\n                con.execute(\"PRAGMA foreign_keys = on;\")\n            \n            return con\n        else:\n            return self.con\n        \n    def __enter__(self):\n        self.connect()\n        return self\n    \n    def __exit__(self, *_):\n        self.close()\n        \n    def connect(self) -> sqlite3.Connection:\n        self.close()\n        self.con = self.get_connection()\n        return self.con\n\n    def close(self) -> None:\n        if self.check_connection():\n            self.con.close()\n        self._cruds.clear()\n    \n    def crud(self, Model: type[M]) -> Crud[M]:\n        \"\"\"returns a Crud instances for the given model type\n\n        Args:\n            Model (type[M]): the model type for the crud object\n\n        Returns:\n            Crud[M]: the crud for the model type\n        \"\"\"\n        if not self.check_connection():\n            raise DisconnectedEngine(\"Can't create crud objects with a disconnected engine\")\n        \n        if Model.__schema__ not in self.tables_created:\n            self.con.execute(Model.__schema__)\n            self.con.commit()\n            self.tables_created.add(Model.__schema__)\n        \n        crud = self._cruds.setdefault(Model, Crud(Model, self.con))\n        \n        return crud", "\nclass Engine(BaseEngine):\n    \"\"\"The sync engine that uses `sqlite3.Connection` and `sqlite3.Cursor`\n    \n    Args:\n        path (str): a pathlike object that points to the sqlite database\n        enable_foreing_keys (bool, optional): specifies if the pragma should be enforced. Defaults to False.\n    \n    Attributes:\n        path (str): the path to the db\n        schemas (set[str]): a set of table schemas\n        tables_created (set[str]): the tables that have been setup by the engine\n        enable_foreing_keys (bool): if True, the engine enables the pragma on all connections\n    \"\"\"\n    con: sqlite3.Connection\n    \n    def __init__(self, path: str, enable_foreing_keys: bool = False):\n        super().__init__(path, enable_foreing_keys)\n    \n    def get_connection(self) -> sqlite3.Connection:\n        \"\"\"Gets the connections or makes a new one but it doesn't set it as an attrib\n\n        Returns:\n            sqlite3.Connection: the connection\n        \"\"\"\n        con: Union[sqlite3.Connection, None] = getattr(self, 'con', None)\n        if not self.check_connection():\n            con = sqlite3.connect(self.path)\n            con.row_factory = sqlite3.Row\n            \n            if self.enable_foreing_keys:\n                con.execute(\"PRAGMA foreign_keys = on;\")\n            \n            return con\n        else:\n            return self.con\n        \n    def __enter__(self):\n        self.connect()\n        return self\n    \n    def __exit__(self, *_):\n        self.close()\n        \n    def connect(self) -> sqlite3.Connection:\n        self.close()\n        self.con = self.get_connection()\n        return self.con\n\n    def close(self) -> None:\n        if self.check_connection():\n            self.con.close()\n        self._cruds.clear()\n    \n    def crud(self, Model: type[M]) -> Crud[M]:\n        \"\"\"returns a Crud instances for the given model type\n\n        Args:\n            Model (type[M]): the model type for the crud object\n\n        Returns:\n            Crud[M]: the crud for the model type\n        \"\"\"\n        if not self.check_connection():\n            raise DisconnectedEngine(\"Can't create crud objects with a disconnected engine\")\n        \n        if Model.__schema__ not in self.tables_created:\n            self.con.execute(Model.__schema__)\n            self.con.commit()\n            self.tables_created.add(Model.__schema__)\n        \n        crud = self._cruds.setdefault(Model, Crud(Model, self.con))\n        \n        return crud", "\n"]}
{"filename": "ardilla/fields.py", "chunked_list": ["from typing import Any\nfrom pydantic import Field\nfrom ardilla import Model\n\nclass _ForeignFieldMaker():\n    \"\"\"\n    Helper class to generate foreing key field constrains.\n    \n    Intead of instantiating this class the developer should use \n    the already instantiated `ardilla.fields.ForeignKey`\n    instead of directly instantiating this class.\n    \n    Attributes:\n        NO_ACTION (str): (class attribute) The database won't take action. This most likely will result in errors\n        RESTRICT (str): (class attribute) The app will not be able to delete the foreing row unless there's no related child elements left\n        SET_NULL (str): (class attribute) The app will set the child to Null if the parent is deleted\n        SET_DEFAULT (str): (class attribute) Returns the value of this field to the default of the child when the parent is deleted or updated\n        CASCADE (str): (class attribute) If the parent gets deleted or updated the child follows  \n        \n    \"\"\"\n    NO_ACTION = 'NO ACTION'\n    RESTRICT = 'RESTRICT'\n    SET_NULL = 'SET NULL'\n    SET_DEFAULT = 'SET DEFAULT'\n    CASCADE = 'CASCADE'\n    \n    def __call__(\n        self,\n        *,\n        references: type[Model],\n        on_delete: str = NO_ACTION, \n        on_update: str = NO_ACTION,\n        **kws,\n    ) -> Any:\n        \"\"\"\n        Args:\n            references (type[Model]):\n                The model this foreign key points to\n            on_delete (str): defaults to 'NO ACTION'\n                what happens when the referenced row gets deleted\n            on_update (str): defaults to 'NO ACTION'\n                what happens when the referenced row gets updated\n        Returns:\n            A `pydantic.Field` with extra metadata for the schema creation\n        Raises:\n            KeyError: if the referenced value is not a type of model\n            ValueError: if the referenced model does not have a primary key or has not yet been instantiated\n        \"\"\"\n        if not issubclass(references, Model):\n            raise TypeError('The referenced type must be a subclass of ardilla.Model')\n        fk = getattr(references, '__pk__', None)\n        tablename = getattr(references, '__tablename__')\n        \n        if not fk:\n            raise ValueError('The referenced model requires to have a primary key')\n        \n        return Field(\n            references=tablename, \n            fk=fk,\n            on_delete=on_delete,\n            on_update=on_update,\n            **kws\n        )", "\nForeignField = _ForeignFieldMaker()"]}
{"filename": "ardilla/logging.py", "chunked_list": ["from logging import getLogger\nfrom typing import Optional\n\nlog = getLogger('ardilla')\n\ndef log_query(q: str, vals:  Optional[tuple] = None):\n    vals = vals or ()\n    log.debug(f'Querying: {q} - values: {vals}')\n\n", "\n"]}
{"filename": "ardilla/queries.py", "chunked_list": ["\"\"\"\nMethods here are used by Crud classes to obtain the query \nstrings and variable tuples to pass to the connections and cursors\n\"\"\"\nfrom typing import Any, Optional, Union\nfrom .errors import BadQueryError\nfrom .models import M\nfrom .ordering import validate_ordering\nfrom .logging import log_query\n", "from .logging import log_query\n\n\ndef for_get_or_none(tablename: str, kws: dict) -> tuple[str, tuple[Any, ...]]:\n    \"\"\"called by _get_or_none_one method\n    Args:\n        tablename (str): name of the table\n        kws (dict): the keywords to identify the rows with\n    Returns:\n        tuple[str, tuple[Any, ...]]: the query and values.\n    \"\"\"\n    keys, vals = zip(*kws.items())\n    to_match = f\" AND \".join(f\"{k} = ?\" for k in keys)\n    q = f\"SELECT rowid, * FROM {tablename} WHERE ({to_match}) LIMIT 1;\"\n    log_query(q, vals)\n    return q, vals", "\n\ndef for_get_many(\n    Model: M,\n    *,\n    order_by: Optional[dict[str, str]] = None,\n    limit: Optional[int] = None,\n    kws: dict,\n) -> tuple[str, tuple[Any, ...]]:\n    \"\"\"called by _get_many method\n    Args:\n     Args:\n        Model (Model): the model of the table\n        order_by (dict[str, str] | None ):\n            if passed Defines the sorting methods for the query\n            defaults to no sorting\n        limit (int | None) an integer to determine the number of items to grab\n        kws (dict): the keywords to identify the rows with\n    \"\"\"\n    tablename = Model.__tablename__\n    columns = tuple(Model.__fields__)\n\n    if kws:\n        keys, vals = zip(*kws.items())\n        to_match = f\" AND \".join(f\"{k} = ?\" for k in keys)\n        filter_ = f\" WHERE ({to_match})\"\n    else:\n        filter_ = \"\"\n        vals = ()\n\n    if order_by is not None:\n        ord = validate_ordering(columns, order_by)\n        order_by_q = f\" ORDER BY \" + \", \".join(f\"{k} {v}\" for k, v in ord.items())\n    else:\n        order_by_q = \"\"\n\n    if limit is not None:\n        if not isinstance(limit, int) or limit < 1:\n            raise ValueError(\"Limit, when passed, must be an integer larger than zero\")\n        limit_q = \" LIMIT ?\"\n        vals += (limit,)\n    else:\n        limit_q = \"\"\n\n    q = f\"SELECT rowid, * FROM {tablename}{filter_}{order_by_q}{limit_q};\"\n    return q, vals", "\n\ndef for_do_insert(\n    tablename: str,\n    ignore: bool,\n    returning: bool,\n    kws: dict,\n) -> tuple[str, tuple[Any, ...]]:\n    \"\"\"called by _do_insert methods\n\n    Args:\n        tablename (str): name of the table\n        ignore (bool): whether or not to use `INSERT OR IGNORE` vs just `INSERT`\n        returning (bool): if the inserted values should be returned by the query\n        kws (dict): the keywords representing column name and values\n\n    Returns:\n        tuple[str, tuple[Any, ...]]: the queries and values\n    \"\"\"\n    keys, vals = zip(*kws.items())\n    placeholders = \", \".join(\"?\" * len(keys))\n    cols = \", \".join(keys)\n\n    q = \"INSERT OR IGNORE \" if ignore else \"INSERT \"\n    q += f\"INTO {tablename} ({cols}) VALUES ({placeholders})\"\n    q += \" RETURNING *;\" if returning else \";\"\n    log_query(q, vals)\n    return q, vals", "\n\ndef for_save_one(obj: M) -> tuple[str, tuple[Any, ...]]:\n    \"\"\"called by save_one methods\n\n    Args:\n        obj (M): the Model instance to save\n\n    Returns:\n        tuple[str, tuple[Any, ...]]: the query and values\n    \"\"\"\n    cols, vals = zip(*obj.dict().items())\n\n    if obj.__rowid__ is not None:\n        q = f\"\"\"\n        UPDATE {obj.__tablename__} SET {', '.join(f'{k} = ?' for k in cols)} WHERE rowid = ?;\n        \"\"\"\n        vals += (obj.__rowid__,)\n\n    else:\n        placeholders = \", \".join(\"?\" * len(cols))\n        q = f\"\"\"\n        INSERT OR REPLACE INTO {obj.__tablename__} ({', '.join(cols)}) VALUES ({placeholders});\n        \"\"\"\n    log_query(q, vals)\n    return q, vals", "\n\ndef for_save_many(objs: tuple[M]) -> tuple[str, tuple[Any, ...]]:\n    \"\"\"called by save_many methods\n\n    Args:\n        objs (tuple[M]): the objects to save\n\n    Raises:\n        BadQueryError: if the objs tuple is empty\n\n    Returns:\n        tuple[str, tuple[Any, ...]]: the query and values\n    \"\"\"\n    if not objs:\n        raise BadQueryError(\"To save many, you have to at least past one object\")\n    cols = tuple(objs[0].__fields__)\n    tablename = objs[0].__tablename__\n    placeholders = \", \".join(\"?\" * len(cols))\n    q = f'INSERT OR REPLACE INTO {tablename} ({\", \".join(cols)}) VALUES ({placeholders});'\n    vals = tuple(tuple(obj.dict().values()) for obj in objs)\n    log_query(q, vals)\n    return q, vals", "\n\ndef for_delete_one(obj: M) -> tuple[str, tuple[Any, ...]]:\n    \"\"\"called by delete_one methods\n\n    Args:\n        obj (M): the object to delete\n\n    Returns:\n        tuple[str, tuple[Any, ...]]: the query and values\n    \"\"\"\n    tablename = obj.__tablename__\n    if obj.__pk__:\n        q = f\"DELETE FROM {tablename} WHERE {obj.__pk__} = ?\"\n        vals = (getattr(obj, obj.__pk__),)\n    elif obj.__rowid__:\n        q = f\"DELETE FROM {tablename} WHERE rowid = ?\"\n        vals = (obj.__rowid__,)\n    else:\n        obj_dict = obj.dict()\n        placeholders = \" AND \".join(f\"{k} = ?\" for k in obj_dict)\n        vals = tuple(obj_dict[k] for k in obj_dict)\n        q = f\"\"\"\n        DELETE FROM {tablename} WHERE ({placeholders});\n        \"\"\"\n    log_query(q, vals)\n    return q, vals", "\n\ndef for_delete_many(objs: tuple[M]) -> tuple[str, tuple[Any, ...]]:\n    \"\"\"called by delete_many methods\n\n    Args:\n        objs (tuple[M]): objects to delete\n\n    Raises:\n        IndexError: if the the obj tuple is empty\n        BadQueryError: if the objects don't have either rowid or pks\n\n    Returns:\n        tuple[str, tuple[Any, ...]]\n    \"\"\"\n    if not objs:\n        raise IndexError('param \"objs\" is empty, pass at least one object')\n\n    tablename = objs[0].__tablename__\n    placeholders = \", \".join(\"?\" * len(objs))\n    if all(obj.__rowid__ for obj in objs):\n        vals = tuple(obj.__rowid__ for obj in objs)\n        q = f\"DELETE FROM {tablename} WHERE rowid IN ({placeholders})\"\n\n    elif (pk := objs[0].__pk__) and all(getattr(o, pk, None) is not None for o in objs):\n        vals = tuple(getattr(obj, pk) for obj in objs)\n        q = f\"DELETE FROM {tablename} WHERE id IN ({placeholders})\"\n\n    else:\n        raise BadQueryError(\n            \"Objects requiere either a primary key or the rowid set for mass deletion\"\n        )\n\n    log_query(q, vals)\n    return q, vals", "\n\ndef for_count(tablename: str, column: str = '*', kws: Optional[dict] = None) -> tuple[str, tuple]:\n    \"\"\"Returns a query for counting the number of non null values in a column\n\n    Args:\n        tablename (str): The name of the table.\n        column (str, optional): The column to count. . Defaults to '*' which then counts all the rows\n        kws (dict, optional): The key/value pair for the \"WHERE\" clausule\n            If not specified the complete table will be used.\n\n    Returns:\n        tuple: the query and vals\n    \"\"\"\n    q = f'SELECT COUNT({column}) AS total_count FROM {tablename}'\n    \n    vals = ()\n    if kws:\n        keys, vals = zip(*kws.items())\n        placeholders = ', '.join(f'{k} = ?' for k in keys)\n        q += f' WHERE {placeholders};'\n        \n    return q, vals", "\n"]}
{"filename": "ardilla/crud.py", "chunked_list": ["from __future__ import annotations\nimport sqlite3\nfrom sqlite3 import Row\nfrom contextlib import contextmanager\nfrom typing import Literal, Generic, Optional, Union, Generator\n\nfrom . import queries\nfrom .abc import BaseCrud\nfrom .models import M\nfrom .errors import BadQueryError, QueryExecutionError, disconnected_engine_error, DisconnectedEngine", "from .models import M\nfrom .errors import BadQueryError, QueryExecutionError, disconnected_engine_error, DisconnectedEngine\nfrom .schemas import SQLFieldType\n\n\n@contextmanager\ndef contextcursor(con: sqlite3.Connection) -> Generator[sqlite3.Cursor, None, None]:\n    \"\"\"a context manager wrapper for sqlite3.Cursor\n\n    Args:\n        con (sqlite3.Connection): the connection\n\n    Raises:\n        disconnected_engine_error: if the connection is non functioning\n\n    Yields:\n        Generator[sqlite3.Cursor, None, None]: the cursor\n    \"\"\"\n    cur = None\n    try:\n        cur = con.cursor()\n        yield cur\n    except Exception as e:\n        if (\n            isinstance(e, sqlite3.ProgrammingError)\n            and str(e) == \"Cannot operate on a closed database.\"\n        ):\n            raise DisconnectedEngine(str(e))\n        else:\n            raise e\n    finally:\n        if cur is not None:\n            cur.close()", "\n\nclass Crud(BaseCrud, Generic[M]):\n    \"\"\"Abstracts CRUD actions for model associated tables\"\"\"\n\n    connection: sqlite3.Connection\n\n    def _do_insert(\n        self,\n        ignore: bool = False,\n        returning: bool = True,\n        /,\n        **kws: SQLFieldType,\n    ) -> Optional[M]:\n        \"\"\"private helper method for insertion methods\n\n        Args:\n            ignore (bool, optional): Ignores conflicts silently. Defaults to False.\n            returning (bool, optional): Determines if the query should return the inserted row. Defaults to True.\n            kws (SQLFieldType): the column name and values for the insert query\n\n        Raises:\n            QueryExecutionError: when sqlite3.IntegrityError happens because of a conflic\n\n        Returns:\n            An instance of model if any row is returned\n        \"\"\"\n        q, vals = queries.for_do_insert(self.tablename, ignore, returning, kws)\n\n        with contextcursor(self.connection) as cur:\n            try:\n                cur.execute(q, vals)\n            except sqlite3.IntegrityError as e:\n                raise QueryExecutionError(str(e))\n\n            row = cur.fetchone()\n            self.connection.commit()\n            if returning and row:\n                return self._row2obj(row, cur.lastrowid)\n\n        return None\n\n    def insert(self, **kws: SQLFieldType) -> M:\n        \"\"\"Inserts a record into the database.\n\n        Args:\n            kws (SQLFieldType): The keyword arguments are passed as the column names and values\n                to the insert query\n\n        Returns:\n            Creates a new entry in the database and returns the object\n\n        Rises:\n            `ardilla.error.QueryExecutionError`: if there's a conflict when inserting the record\n        \"\"\"\n        self.verify_kws(kws)\n        return self._do_insert(False, True, **kws)\n\n    def insert_or_ignore(self, **kws: SQLFieldType) -> Optional[M]:\n        \"\"\"Inserts a record to the database with the keywords passed. It ignores conflicts.\n\n        Args:\n            kws (SQLFieldType): The keyword arguments are passed as the column names and values\n                to the insert query\n\n        Returns:\n            The newly created row as an instance of the model if there was no conflicts\n        \"\"\"\n        self.verify_kws(kws)\n        return self._do_insert(True, True, **kws)\n    \n    def get_or_none(self, **kws: SQLFieldType) -> Optional[M]:\n        \"\"\"Returns a row as an instance of the model if one is found or none\n\n        Args:\n            kws (SQLFieldType): The keyword arguments are passed as column names and values to\n                a select query\n\n        Example:\n            ```py\n            crud.get_or_none(id=42)\n\n            # returns an object with id of 42 or None if there isn't one in the database\n            ```\n\n        Returns:\n            The object found with the criteria if any\n        \"\"\"\n        self.verify_kws(kws)\n        q, vals = queries.for_get_or_none(self.tablename, kws)\n        with contextcursor(self.connection) as cur:\n            cur.execute(q, vals)\n            row: Union[Row, None] = cur.fetchone()\n            if row:\n                return self._row2obj(row)\n        return None\n\n    def get_or_create(self, **kws: SQLFieldType) -> tuple[M, bool]:\n        \"\"\"Returns an object from the database with the spefied matching data\n        Args:\n            kws (SQLFieldType): the key value pairs will be used to query for an existing row\n                if no record is found then a new row will be inserted\n        Returns:\n            A tuple with two values, the object and a boolean indicating if the\n                object was newly created or not\n        \"\"\"\n        self.verify_kws(kws)\n        created = False\n        result = self.get_or_none(**kws)\n        if not result:\n            result = self.insert_or_ignore(**kws)\n            created = True\n        return result, created\n\n    def get_all(self) -> list[M]:\n        \"\"\"Gets all objects from the database\n        Returns:\n            A list with all the rows in table as instances of the model\n        \"\"\"\n        return self.get_many()\n\n    def get_many(\n        self,\n        order_by: Optional[dict[str, str]] = None,\n        limit: Optional[int] = None,\n        **kws: SQLFieldType,\n    ) -> list[M]:\n        \"\"\"Queries the database and returns objects that meet the criteris\n\n        Args:\n            order_by (Optional[dict[str, str]], optional): An ordering dict. Defaults to None.\n                The ordering should have the structure: `{'column_name': 'ASC' OR 'DESC'}`\n                Case in values is insensitive\n\n            limit (Optional[int], optional): The number of items to return. Defaults to None.\n            kws (SQLFieldType): The column names and values for the select query\n\n        Returns:\n            a list of rows matching the criteria as intences of the model\n        \"\"\"\n        self.verify_kws(kws)\n        q, vals = queries.for_get_many(\n            self.Model, \n            order_by=order_by,\n            limit=limit, \n            kws=kws,\n        )\n        with contextcursor(self.connection) as cur:\n            cur.execute(q, vals)\n            rows: list[Row] = cur.fetchall()\n            return [self._row2obj(row) for row in rows]\n\n    def save_one(self, obj: M) -> Literal[True]:\n        \"\"\"Saves one object to the database\n\n        Args:\n            obj (M): the object to persist\n\n        Returns:\n            The literal `True` if the method ran successfuly\n        \"\"\"\n        q, vals = queries.for_save_one(obj)\n        try:\n            self.connection.execute(q, vals)\n            self.connection.commit()\n        except:\n            raise disconnected_engine_error\n        return True\n\n    def save_many(self, *objs: tuple[M]) -> Literal[True]:\n        \"\"\"Saves all the passed objects to the database\n\n        Args:\n            objs (M): the objects to persist\n\n        Returns:\n            The literal `True` if the method ran successfuly\n        \"\"\"\n        q, vals = queries.for_save_many(objs)\n        try:\n            self.connection.executemany(q, vals)\n            self.connection.commit()\n        except:\n            raise disconnected_engine_error\n\n        return True\n\n    def delete_one(self, obj: M) -> Literal[True]:\n        \"\"\"\n        Deletes the object from the database (won't delete the actual object)\n        If the object has a PK field or the rowid setup, those will be\n        used to locate the obj and delete it.\n        If not, this function will delete any row that meets the values of the object\n\n\n        Args:\n            obj (M): the object to delete\n\n        Returns:\n            The literal `True` if the method ran successfuly\n\n        \"\"\"\n\n        q, vals = queries.for_delete_one(obj)\n        try:\n            self.connection.execute(q, vals)\n            self.connection.commit()\n        except:\n            raise disconnected_engine_error\n        return True\n\n    def delete_many(self, *objs: M) -> Literal[True]:\n        \"\"\"\n        Deletes all the objects passed\n\n        Args:\n            objs (M): the object to delete\n\n        Returns:\n            The literal `True` if the method ran successfuly\n\n        \"\"\"\n        q, vals = queries.for_delete_many(objs)\n        try:\n            self.connection.execute(q, vals)\n            self.connection.commit()\n        except:\n            raise disconnected_engine_error\n        return True\n\n    def count(self, column: str = '*',/, **kws) -> int:\n        \"\"\"Returns an integer of the number of non null values in a column\n        Or the total number of rows if '*' is passed\n\n        Args:\n            column (str, optional): The column name to count rows on. \n                Defaults to '*' which counts all the rows in the table\n\n        Returns:\n            int: the number of rows with non null values in a column or the number of rows in a table\n        \"\"\"\n        self.verify_kws(kws)\n        \n        tablename = self.Model.__tablename__\n        if column not in self.Model.__fields__ and column != '*':\n            raise BadQueryError(f'\"{column}\" is not a field of the \"{tablename}\" table')\n        \n        \n        q, vals = queries.for_count(tablename, column, kws)\n        with contextcursor(self.connection) as cur:\n            cur.execute(q, vals)\n            row = cur.fetchone()\n    \n            count = row['total_count']\n                \n        return count"]}
{"filename": "ardilla/asyncio/__init__.py", "chunked_list": ["from .engine import AsyncEngine as Engine\nfrom .crud import AsyncCrud as Crud"]}
{"filename": "ardilla/asyncio/engine.py", "chunked_list": ["from __future__ import annotations\nfrom ctypes import Union\n\nimport aiosqlite\n\nfrom ..abc import BaseEngine\nfrom ..models import M\nfrom ..errors import DisconnectedEngine\n\nfrom .crud import AsyncCrud", "\nfrom .crud import AsyncCrud\n\nclass AsyncEngine(BaseEngine):\n    \"\"\"Async Engine that uses `aiosqlite.Connection` and `aiosqlite.Cursor`\n    \"\"\"\n    con: aiosqlite.Connection\n\n    async def get_connection(self) -> aiosqlite.Connection:\n        \"\"\"Gets the connections or makes a new one but it doesn't set it as an attrib\n\n        Returns:\n            sqlite3.Connection: the connection\n        \"\"\"\n        con: Union[aiosqlite.Connection, None] = getattr(self, 'con', None)\n        if not self.check_connection():\n            con: aiosqlite.Connection = await aiosqlite.connect(self.path)\n            con.row_factory = aiosqlite.Row\n            \n            if self.enable_foreing_keys:\n                await con.execute(\"PRAGMA foreign_keys = on;\")\n            \n            return con\n        else:\n            return self.con\n    \n    async def connect(self) -> aiosqlite.Connection:\n        \"\"\"\n        Stablishes a connection to the database\n        Returns:\n            The connection\n        \"\"\"\n        await self.close()\n        \n        self.con = await self.get_connection()\n        return self.con\n\n    async def close(self) -> None:\n        if self.check_connection():\n            await self.con.close()\n        self._cruds.clear()\n\n    async def __aenter__(self) -> AsyncEngine:\n        \"\"\"Stablishes the connection and if specified enables foreign keys pragma\n\n        Returns:\n            The connection\n        \"\"\"\n        await self.connect()\n        return self\n\n    async def __aexit__(self, *_):\n        \"\"\"Closes the connection\"\"\"\n        await self.close()\n    \n    async def crud(self, Model: type[M]) -> AsyncCrud[M]:\n        \"\"\"\n        This function works exactly like `Engine.crud` but\n        returns an instance of `ardilla.asyncio.crud.AsyncCrud` instead of `ardilla.crud.Crud`\n        and is asynchronous\n        \n        Returns:\n            The async Crud for the given model\n        \"\"\"\n        if not self.check_connection():\n            raise DisconnectedEngine(\"Can't create crud objects with a disconnected engine\")\n            \n        if Model.__schema__ not in self.tables_created:\n            await self.con.execute(Model.__schema__)\n            await self.con.commit()\n            self.tables_created.add(Model.__schema__)\n        \n        crud = self._cruds.setdefault(Model, AsyncCrud(Model, self.con))\n        return crud", ""]}
{"filename": "ardilla/asyncio/crud.py", "chunked_list": ["from __future__ import annotations\nfrom typing import Literal, Generic, Optional, Union\n\nfrom typing import Any\nimport aiosqlite\nfrom aiosqlite import Row\n\nfrom ..errors import BadQueryError, QueryExecutionError, disconnected_engine_error\nfrom ..models import M\nfrom ..abc import BaseCrud", "from ..models import M\nfrom ..abc import BaseCrud\nfrom ..schemas import SQLFieldType\nfrom ..errors import DisconnectedEngine\nfrom .. import queries\n\n\nclass ConnectionProxy:\n    \"\"\"A proxy class for aiosqlite.Connection that\n    checks if the connections is alive before returning any of its attributes\n    \n    Args:\n        connection (aiosqlite.Connection)\n    \"\"\"\n    def __init__(self, connection: aiosqlite.Connection):\n        self._connection = connection\n    \n    def __getattr__(self, __name: str) -> Any:\n        if __name in {'execute', 'commit'}:\n            if not self._connection._running or not self._connection._connection:\n                raise DisconnectedEngine('The engine is disconnected')\n        return getattr(self._connection, __name)", "\n\nclass AsyncCrud(BaseCrud, Generic[M]):\n    \"\"\"Abstracts CRUD actions for model associated tables\"\"\"\n    connection: aiosqlite.Connection\n    \n    def __init__(self, Model: type[M], connection: aiosqlite.Connection) -> None:\n        connection = ConnectionProxy(connection)\n        super().__init__(Model, connection)\n\n\n    async def _do_insert(\n        self,\n        ignore: bool = False,\n        returning: bool = True,\n        /,\n        **kws: SQLFieldType,\n    ):\n        \"\"\"private helper method for insertion methods\n\n        Args:\n            ignore (bool, optional): Ignores conflicts silently. Defaults to False.\n            returning (bool, optional): Determines if the query should return the inserted row. Defaults to True.\n            kws (SQLFieldType): the column names and values for the insertion query\n\n        Raises:\n            QueryExecutionError: when sqlite3.IntegrityError happens because of a conflic\n\n        Returns:\n            An instance of model if any row is returned\n        \"\"\"\n        q, vals = queries.for_do_insert(self.tablename, ignore, returning, kws)\n\n        cur = None\n        try:\n            cur = await self.connection.execute(q, vals)\n        except aiosqlite.IntegrityError as e:\n            raise QueryExecutionError(str(e))\n        except aiosqlite.ProgrammingError as e:\n            raise disconnected_engine_error\n        else:\n            row = await cur.fetchone()\n            await self.connection.commit()\n            if returning and row:\n                return self._row2obj(row, cur.lastrowid)\n        finally:\n            if cur is not None:\n                await cur.close()\n\n    async def get_or_none(self, **kws: SQLFieldType) -> Optional[M]:\n        \"\"\"Returns a row as an instance of the model if one is found or none\n\n        Args:\n            kws (SQLFieldType): The keyword arguments are passed as column names and values to\n                a select query\n\n        Example:\n            ```py\n            await crud.get_or_none(id=42)\n\n            # returns an object with id of 42 or None if there isn't one in the database\n            ```\n        Returns:\n            The object found with the criteria if any\n        \"\"\"\n        self.verify_kws(kws)\n        q, vals = queries.for_get_or_none(self.tablename, kws)\n\n        async with self.connection.execute(q, vals) as cur:\n            row: Union[Row, None] = await cur.fetchone()\n            if row:\n                return self._row2obj(row)\n        return None\n\n    async def insert(self, **kws: SQLFieldType) -> M:\n        \"\"\"\n        Inserts a record into the database.\n\n        Args:\n            kws (SQLFieldType): the column names and values for the insertion query\n\n        Returns:\n            Returns the inserted row as an instance of the model\n        Rises:\n            ardilla.error.QueryExecutionError: if there's a conflict when inserting the record\n        \"\"\"\n        self.verify_kws(kws)\n        return await self._do_insert(False, True, **kws)\n\n    async def insert_or_ignore(self, **kws: SQLFieldType) -> Optional[M]:\n        \"\"\"Inserts a record to the database with the keywords passed. It ignores conflicts.\n\n        Args:\n            kws (SQLFieldType): The keyword arguments are passed as the column names and values\n                to the insert query\n\n        Returns:\n            The newly created row as an instance of the model if there was no conflicts\n        \"\"\"\n        self.verify_kws(kws)\n        return await self._do_insert(True, True, **kws)\n\n    async def get_or_create(self, **kws: SQLFieldType) -> tuple[M, bool]:\n        \"\"\"Returns an object from the database with the spefied matching data\n        Args:\n            kws (SQLFieldType): the key value pairs will be used to query for an existing row\n                if no record is found then a new row will be inserted\n        Returns:\n            A tuple with two values, the object and a boolean indicating if the\n                object was newly created or not\n        \"\"\"\n        created = False\n        result = await self.get_or_none(**kws)\n        if not result:\n            result = await self.insert_or_ignore(**kws)\n            created = True\n        return result, created\n\n    async def get_all(self) -> list[M]:\n        \"\"\"Gets all objects from the database\n\n        Returns:\n            A list with all the rows in table as instances of the model\n        \"\"\"\n        q = f\"SELECT rowid, * FROM {self.tablename};\"\n\n        async with self.connection.execute(q) as cur:\n            return [self._row2obj(row) for row in await cur.fetchall()]\n\n    async def get_many(\n        self,\n        order_by: Optional[dict[str, str]] = None,\n        limit: Optional[int] = None,\n        **kws: SQLFieldType,\n    ) -> list[M]:\n        \"\"\"Queries the database and returns objects that meet the criteris\n\n        Args:\n            order_by (Optional[dict[str, str]], optional): An ordering dict. Defaults to None.\n                The ordering should have the structure: `{'column_name': 'ASC' OR 'DESC'}`\n                Case in values is insensitive\n            kws (SQLFieldType): the column names and values for the select query\n\n            limit (Optional[int], optional): The number of items to return. Defaults to None.\n\n        Returns:\n            a list of rows matching the criteria as intences of the model\n        \"\"\"\n        self.verify_kws(kws)\n\n        q, vals = queries.for_get_many(\n            self.Model, order_by=order_by, limit=limit, kws=kws\n        )\n        async with self.connection.execute(q, vals) as cur:\n            rows: list[Row] = await cur.fetchall()\n            return [self._row2obj(row) for row in rows]\n\n    async def save_one(self, obj: M) -> Literal[True]:\n        \"\"\"Saves one object to the database\n\n        Args:\n            obj (M): the object to persist\n\n        Returns:\n            The literal `True` if the method ran successfuly\n        \"\"\"\n        q, vals = queries.for_save_one(obj)\n\n        await self.connection.execute(q, vals)\n        await self.connection.commit()\n        return True\n\n    async def save_many(self, *objs: M) -> Literal[True]:\n        \"\"\"Saves all the passed objects to the database\n\n        Args:\n            objs (M): the objects to persist\n\n        Returns:\n            The literal `True` if the method ran successfuly\n        \"\"\"\n        q, vals = queries.for_save_many(objs)\n\n        await self.connection.executemany(q, vals)\n        await self.connection.commit()\n\n        return True\n\n    async def delete_one(self, obj: M) -> Literal[True]:\n        \"\"\"\n        Deletes the object from the database (won't delete the actual object)\n        If the object has a PK field or the rowid setup, those will be\n        used to locate the obj and delete it.\n        If not, this function will delete any row that meets the values of the object\n\n\n        Args:\n            obj (M): the object to delete\n\n        Returns:\n            The literal `True` if the method ran successfuly\n\n        \"\"\"\n        q, vals = queries.for_delete_one(obj)\n\n        await self.connection.execute(q, vals)\n        await self.connection.commit()\n        return True\n\n    async def delete_many(self, *objs: M) -> Literal[True]:\n        \"\"\"\n        Deletes all the objects passed\n\n        Args:\n            objs (M): the object to delete\n\n        Returns:\n            The literal `True` if the method ran successfuly\n\n        \"\"\"\n        q, vals = queries.for_delete_many(objs)\n\n        await self.connection.execute(q, vals)\n        await self.connection.commit()\n        \n    async def count(self, column: str = '*', /, **kws) -> int:\n        \"\"\"Returns an integer of the number of non null values in a column\n        Or the total number of rows if '*' is passed\n\n        Args:\n            column (str, optional): The column name to count rows on. \n                Defaults to '*' which counts all the rows in the table\n\n        Returns:\n            int: the number of rows with non null values in a column or the number of rows in a table\n        \"\"\"\n        tablename = self.Model.__tablename__\n        if column not in self.Model.__fields__ and column != '*':\n            raise BadQueryError(f'\"{column}\" is not a field of the \"{tablename}\" table')\n        \n        q, vals = queries.for_count(tablename, column, kws)\n        async with self.connection.execute(q, vals) as cur:\n            row = await cur.fetchone()    \n            count = row['total_count']\n                \n        return count"]}
{"filename": "tests/test_models.py", "chunked_list": ["import sqlite3\nfrom pathlib import Path\nfrom datetime import datetime\n\nfrom ardilla import Model, Field\nfrom ardilla.errors import ModelIntegrityError\n\nfrom pydantic import Json\n\n\ndef test_default_tablename():\n    class Foo(Model):\n        id: int\n    \n    assert Foo.__tablename__ == \"foo\"", "\n\ndef test_default_tablename():\n    class Foo(Model):\n        id: int\n    \n    assert Foo.__tablename__ == \"foo\"\n\ndef test_field_pk():\n    class Foo(Model):\n        id: str = Field(primary=True)\n    \n    assert Foo.__pk__ == 'id'", "def test_field_pk():\n    class Foo(Model):\n        id: str = Field(primary=True)\n    \n    assert Foo.__pk__ == 'id'\n\ndef test_int_pk_auto():\n    class Foo(Model):\n        id: int = Field(pk=True, auto=True)\n    \n    schema = Foo.__schema__\n    assert 'id INTEGER PRIMARY KEY AUTOINCREMENT' in schema", "\n\n\nbinary_data = b'some weird data'\n\nclass Complex(Model):\n    id: int = Field(pk=True, auto=True)\n    created: datetime = Field(auto=True)\n    name: str = 'me'\n    lastname: str | None = None\n    foo: str\n    data: bytes = binary_data", "\n\ndef test_default_schema():\n    complex_schema = f'''\n    \\rCREATE TABLE IF NOT EXISTS complex(\n    \\r    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    \\r    created DATETIME DEFAULT CURRENT_TIMESTAMP,\n    \\r    name TEXT DEFAULT 'me',\n    \\r    lastname TEXT,\n    \\r    foo TEXT NOT NULL,\n    \\r    data BLOB DEFAULT (X'{binary_data.hex()}')\n    \\r);\n    '''\n    assert Complex.__schema__.strip() == complex_schema.strip()", "\n\ndef test_complex_schema_works():\n    try:\n        db = Path(__file__).parent / 'db.sqlite3'\n        db.unlink(missing_ok=True)\n        con = sqlite3.connect(db)\n        con.execute(Complex.__schema__)\n        con.commit()\n    finally:\n        con.close()\n        db.unlink(missing_ok=True)", "\n\nclass User(Model):\n    id: int = Field(primary=True)\n    name: str\n\n\ntablename = \"user\"\nschema = \"\"\"\nCREATE TABLE IF NOT EXISTS user(", "schema = \"\"\"\nCREATE TABLE IF NOT EXISTS user(\n\\r    id INTEGER PRIMARY KEY,\n\\r    name TEXT NOT NULL\n);\n\"\"\"\n\ndef test_default_schema():\n    assert User.__schema__.strip() == schema.strip()\n", "\n\ndef test_pk():\n    assert User.__pk__ == \"id\"\n\ndef test_double_pks():\n    try:\n        class Book(Model):\n            id: int = Field(pk=True)\n            name: str = Field(pk=True)\n    except Exception as e:\n        assert isinstance(e, ModelIntegrityError)"]}
{"filename": "tests/test_sync.py", "chunked_list": ["import random\nimport sqlite3\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom functools import partial\n\n\nfrom ardilla import Engine, Model, Crud\nfrom ardilla.errors import QueryExecutionError, DisconnectedEngine\nfrom pydantic import Field", "from ardilla.errors import QueryExecutionError, DisconnectedEngine\nfrom pydantic import Field\n\nfrom ardilla.fields import ForeignField\n\n\npath = Path(__file__).parent\ndb = path / \"test_sync.sqlite\"\n\nunlinkdb = partial(db.unlink, missing_ok=True)", "\nunlinkdb = partial(db.unlink, missing_ok=True)\n\n@contextmanager\ndef cleanup():\n    unlinkdb()\n    try:\n        yield\n    finally:\n        unlinkdb()", "\nclass User(Model):\n    id: int = Field(pk=True, auto=True)\n    name: str\n\ndef test_context_engine():\n    with cleanup():\n        try:\n            with Engine(db) as engine:\n                crud = engine.crud(User)\n                u = crud.insert(name='chris') # should pass\n                assert u.name == 'chris'\n            crud.insert(name='moni')\n        except Exception as e:\n            assert isinstance(e, DisconnectedEngine), f'Wrong exception raised'", "\ndef test_st_engine():\n    unlinkdb()\n    try:\n        engine = Engine(db)\n        engine.connect()\n        crud = engine.crud(User)\n        u = crud.insert(name='chris') # should pass\n        assert u.name == 'chris'\n        engine.close()\n        crud.insert(name='moni')\n    except Exception as e:\n        assert isinstance(e, DisconnectedEngine), f'Wrong exception raised'\n    finally:\n        engine.close()\n        unlinkdb()", "\n\n# CREATE\n\ndef test_insert():\n   with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        u = crud.insert(name=\"chris\")\n        \n        assert u is not None, \"User wasn't created as expected\"\n        assert u.__rowid__ is not None, \"Created user did not have __rowid__ set\"\n        assert u.__rowid__ == 1, \"Created User did not have correct __rowid__ \"\n        try:\n            crud.insert(id=1, name=\"chris\")\n        except Exception as err:\n            assert isinstance(err, QueryExecutionError), f'Wrong error rised: {err}'\n        else:\n            raise Exception(\"QueryExcecutionError should have been rised\")", "\n\ndef test_insert_or_ignore():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        kws = dict(id=1, name='chris')\n        u1 = crud.insert(**kws)\n        u2= crud.insert_or_ignore(**kws)\n        \n        assert u2 is None", "\ndef test_save_one():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        u = crud.insert(name='chris')\n        u.name = 'alex'\n        crud.save_one(u)\n        \n        user = crud.get_or_none(name='alex')\n        assert user.id == 1", "\n\ndef test_save_many():\n    users = [User(name=f'user {n}') for n in range(20)]\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        crud.save_many(*users)\n\n        assert crud.count() == 20\n", "\n# READ\ndef test_get_all():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        for n in range(10):\n            crud.insert(name=f'user {n}')\n\n        total = crud.count()\n        assert total == 10", "\ndef test_get_many():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        names = ['chris', 'moni', 'elena', 'fran']\n        for name in names:\n            for _ in range(3):\n                crud.insert(name=name)\n        \n        chrises = crud.count(name='chris')\n        \n        assert chrises == 3", "\ndef test_get_or_create():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        chris, created = crud.get_or_create(name='chris')\n        assert chris.id == 1\n        assert created is True\n        chris, created = crud.get_or_create(name='chris')\n        assert chris.id == 1\n        assert created is False", "\ndef test_get_or_none():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        chris = crud.get_or_none(name='chris')\n        assert chris is None\n        crud.insert(name='chris')\n        chris = crud.get_or_none(name='chris')\n        assert chris is not None\n\ndef test_delete_one():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        chrises = [User(name='chris') for _ in range(10)]\n        crud.save_many(*chrises)\n        \n        x = User(id=5, name='chris')\n        crud.delete_one(x)\n        \n        users = crud.get_all()\n        assert len(users) == 9\n        assert all(u.id != 5 for u in users)", "\ndef test_delete_one():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        chrises = [User(name='chris') for _ in range(10)]\n        crud.save_many(*chrises)\n        \n        x = User(id=5, name='chris')\n        crud.delete_one(x)\n        \n        users = crud.get_all()\n        assert len(users) == 9\n        assert all(u.id != 5 for u in users)", "\n\ndef test_delete_many():\n    with cleanup(), Engine(db) as engine:\n        crud = engine.crud(User)\n        users = [\n            User(id=n, name='chris') for n in range(10)\n        ]\n        crud.save_many(*users)\n        \n        to_delete = users[:-1]\n        crud.delete_many(*to_delete)\n        \n        users = crud.get_all()\n        assert len(users) == 1, \"Delete many didn't delete the correct amount of users\"", "\n\ndef test_foreign_keys():\n    db = path / 'sync_test.sqlite'\n    db.unlink(missing_ok=True)\n    engine = Engine(db, enable_foreing_keys=True)\n    engine.connect()\n    \n    class Guild(Model):\n        id: int = Field(pk=True, auto=True)\n        name: str\n        \n    class User(Model):\n        id: int = Field(pk=True, auto=True)\n        name: str\n        guild_id: int = ForeignField(references=Guild, on_delete=ForeignField.CASCADE)\n    \n    gcrud = engine.crud(Guild)\n    ucrud = engine.crud(User)\n    \n    ga = gcrud.insert(name='guild a')\n    gb = gcrud.insert(name='guild b')\n    for guild in [ga, gb]:\n        for n in range(5):\n            ucrud.insert(name=f'user {n}', guild_id=guild.id)\n    \n    assert ucrud.count() == 10\n    gcrud.delete_one(ga)\n    assert ucrud.count() == 5 \n    engine.close()\n    db.unlink(missing_ok=True)", "\n\n\n"]}
{"filename": "tests/__init__.py", "chunked_list": [""]}
{"filename": "tests/test_migration.py", "chunked_list": ["\nfrom pathlib import Path\nfrom typing import Optional\nfrom functools import partial\nfrom contextlib import contextmanager\n\nfrom ardilla import Field, Model, Engine\nfrom ardilla.migration import generate_migration_script\n\ndb = Path(__file__).parent / 'test_db.sqlite3'", "\ndb = Path(__file__).parent / 'test_db.sqlite3'\nunlink_db = partial(db.unlink, missing_ok=True)\nengine = Engine(db)\n\n@contextmanager\ndef clean_db():\n    unlink_db()\n    yield\n    unlink_db()", "\n\ndef test_tablename_change():\n    with clean_db():\n        class A(Model):\n            field: str\n        \n        with engine:\n            crud = engine.crud(A)\n            crud.insert(field='something')\n        \n        class B(Model):\n            field: str\n\n        script = generate_migration_script(\n            A, B, original_tablename='a', new_tablename='b'\n        )\n\n        con = engine.get_connection()\n        con.executescript(script)\n        con.commit()\n        \n        cursor = con.cursor()\n\n        # Execute the query to get table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n\n        # Fetch all the table names\n        table_names = cursor.fetchall()\n        cursor.close()\n        con.close()\n\n        assert table_names[0]['name'] == 'b'", "\n\n\ndef test_full_migration():\n    \"\"\"\n    Tests:\n        - table rename\n        - dropping columns\n        - adding columns\n        - changing column type\n    \"\"\"\n    with clean_db():\n        \n        class User(Model):\n            id: int = Field(pk=True, auto=True)\n            name: str\n            age: str\n            glam: str = 'bling'\n        \n        with engine:\n            crud = engine.crud(User)\n            users = [User(name=f'user {n}', age=str(n)) for n in range(100)]\n            crud.save_many(*users)\n\n        class NewUser(Model):\n            __tablename__ = 'users'\n            id: int = Field(pk=True, auto=True)\n            name: str\n            age: int = 0\n            pet: Optional[str]\n        \n        script = generate_migration_script(\n            User, NewUser, original_tablename='user', new_tablename='users'\n        )\n\n        con = engine.get_connection()\n        con.executescript(script)\n        con.commit()\n        con.close()\n\n        with engine:\n            crud = engine.crud(NewUser)\n            crud.insert(name='chris', age=35, pet='liu')\n        \n        db.unlink(missing_ok=True)", "        \n\n\n\n\n\n\n\n", ""]}
{"filename": "tests/test_async.py", "chunked_list": ["\nfrom contextlib import asynccontextmanager\nfrom pathlib import Path\nfrom functools import partial\n\nimport pytest\n\nfrom ardilla import Model, Field, ForeignField\nfrom ardilla.asyncio import Engine\nfrom ardilla.errors import QueryExecutionError, DisconnectedEngine", "from ardilla.asyncio import Engine\nfrom ardilla.errors import QueryExecutionError, DisconnectedEngine\n\n\n\n\npath = Path(__file__).parent\ndb = path / \"test_sync.sqlite\"\n\nunlinkdb = partial(db.unlink, missing_ok=True)", "\nunlinkdb = partial(db.unlink, missing_ok=True)\n\n@asynccontextmanager\nasync def cleanup():\n    unlinkdb()\n    try:\n        yield\n    finally:\n        unlinkdb()", "\nclass User(Model):\n    id: int = Field(pk=True, auto=True)\n    name: str\n\n\n@pytest.mark.asyncio\nasync def test_context_engine():\n    async with cleanup():\n        try:\n            async with Engine(db) as engine:\n                crud = await engine.crud(User)\n                u = await crud.insert(name='chris') # should pass\n                assert u.name == 'chris'\n            await crud.insert(name='moni')\n        except Exception as e:\n            assert isinstance(e, DisconnectedEngine), f'Wrong exception raised'", "    async with cleanup():\n        try:\n            async with Engine(db) as engine:\n                crud = await engine.crud(User)\n                u = await crud.insert(name='chris') # should pass\n                assert u.name == 'chris'\n            await crud.insert(name='moni')\n        except Exception as e:\n            assert isinstance(e, DisconnectedEngine), f'Wrong exception raised'\n", "\n@pytest.mark.asyncio\nasync def test_st_engine():\n    unlinkdb()\n    try:\n        engine = Engine(db)\n        await engine.connect()\n        crud = await engine.crud(User)\n        u = await crud.insert(name='chris') # should pass\n        assert u.name == 'chris'\n        await engine.close()\n        await crud.insert(name='moni')\n    except Exception as e:\n        assert isinstance(e, DisconnectedEngine), f'Wrong exception raised'\n    finally:\n        await engine.close()\n        unlinkdb()", "\n\n# CREATE\n\n@pytest.mark.asyncio\nasync def test_insert():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        u = await crud.insert(name=\"chris\")\n        ", "        u = await crud.insert(name=\"chris\")\n        \n        assert u is not None, \"User wasn't created as expected\"\n        assert u.__rowid__ is not None, \"Created user did not have __rowid__ set\"\n        assert u.__rowid__ == 1, \"Created User did not have correct __rowid__ \"\n        try:\n            await crud.insert(id=1, name=\"chris\")\n        except Exception as err:\n            assert isinstance(err, QueryExecutionError), f'Wrong error rised: {err}'\n        else:\n            raise Exception(\"QueryExcecutionError should have been rised\")", "\n@pytest.mark.asyncio\nasync def test_insert_or_ignore():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        kws = dict(id=1, name='chris')\n        await crud.insert(**kws)\n        u2 = await crud.insert_or_ignore(**kws)\n        \n        assert u2 is None", "        \n        assert u2 is None\n\n\n@pytest.mark.asyncio\nasync def test_save_one():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        u = await crud.insert(name='chris')\n        u.name = 'alex'", "        u = await crud.insert(name='chris')\n        u.name = 'alex'\n        await crud.save_one(u)\n        \n        user = await crud.get_or_none(name='alex')\n        assert user.id == 1\n\n@pytest.mark.asyncio\nasync def test_save_many():\n    users = [User(name=f'user {n}') for n in range(20)]", "async def test_save_many():\n    users = [User(name=f'user {n}') for n in range(20)]\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        await crud.save_many(*users)\n\n        assert await crud.count() == 20\n\n# READ\n@pytest.mark.asyncio", "# READ\n@pytest.mark.asyncio\nasync def test_get_all():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        for n in range(10):\n            await crud.insert(name=f'user {n}')\n\n        assert await crud.count() == 10\n", "        assert await crud.count() == 10\n\n@pytest.mark.asyncio\nasync def test_get_many():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        names = ['chris', 'moni', 'elena', 'fran']\n        for name in names:\n            for _ in range(3):\n                await crud.insert(name=name)", "                \n        assert await crud.count(name='chris') == 3\n\n@pytest.mark.asyncio\nasync def test_get_or_create():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        chris, created = await crud.get_or_create(name='chris')\n        assert chris.id == 1\n        assert created is True", "        assert chris.id == 1\n        assert created is True\n        chris, created = await crud.get_or_create(name='chris')\n        assert chris.id == 1\n        assert created is False\n\n@pytest.mark.asyncio\nasync def test_get_or_none():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)", "    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        chris = await crud.get_or_none(name='chris')\n        assert chris is None\n        await crud.insert(name='chris')\n        chris = await crud.get_or_none(name='chris')\n        assert chris is not None\n\n@pytest.mark.asyncio\nasync def test_delete_one():", "@pytest.mark.asyncio\nasync def test_delete_one():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        chrises = [User(name='chris') for _ in range(10)]\n        await crud.save_many(*chrises)\n        \n        x = User(id=5, name='chris')\n        await crud.delete_one(x)\n        ", "        await crud.delete_one(x)\n        \n        users = await crud.get_all()\n        assert len(users) == 9\n        assert all(u.id != 5 for u in users)\n\n@pytest.mark.asyncio\nasync def test_delete_many():\n    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)", "    async with cleanup(), Engine(db) as engine:\n        crud = await engine.crud(User)\n        users = [\n            User(id=n, name='chris') for n in range(10)\n        ]\n        await crud.save_many(*users)\n        \n        to_delete = users[:-1]\n        await crud.delete_many(*to_delete)\n        ", "        await crud.delete_many(*to_delete)\n        \n        assert await crud.count() == 1, \"Delete many didn't delete the correct amount of users\"\n\n@pytest.mark.asyncio\nasync def test_foreign_keys():\n    db = path / 'sync_test.sqlite'\n    db.unlink(missing_ok=True)\n    engine = Engine(db, enable_foreing_keys=True)\n    await engine.connect()", "    engine = Engine(db, enable_foreing_keys=True)\n    await engine.connect()\n    \n    class Guild(Model):\n        id: int = Field(pk=True, auto=True)\n        name: str\n        \n    class User(Model):\n        id: int = Field(pk=True, auto=True)\n        name: str\n        guild_id: int = ForeignField(references=Guild, on_delete=ForeignField.CASCADE)", "    \n    gcrud = await engine.crud(Guild)\n    ucrud = await engine.crud(User)\n    \n    ga = await gcrud.insert(name='guild a')\n    gb = await gcrud.insert(name='guild b')\n    for guild in [ga, gb]:\n        for n in range(5):\n            await ucrud.insert(name=f'user {n}', guild_id=guild.id)\n    ", "    \n    assert await ucrud.count() == 10\n    await gcrud.delete_one(ga)\n    assert await ucrud.count() == 5 \n    await engine.close()\n    db.unlink(missing_ok=True)\n\n"]}
{"filename": "examples/fastapi_app.py", "chunked_list": ["from typing import Annotated\n\nfrom fastapi import FastAPI, Depends, status, HTTPException\nfrom pydantic import BaseModel, Field\n\nfrom ardilla import Model\nfrom ardilla.asyncio import Engine\nfrom ardilla.errors import QueryExecutionError\n\napp = FastAPI(docs_url=\"/\")  # set the docs to index for easier access", "\napp = FastAPI(docs_url=\"/\")  # set the docs to index for easier access\n\n\nclass Item(Model):\n    id: int | None = Field(\n        pk=True, auto=True\n    )  # this sets the id as primary key in the default schema\n    name: str\n    price: float", "\n\nclass PatchedItem(BaseModel):\n    name: str\n    price: float\n\n\nengine = Engine(\"fastapi_app.sqlite\")\n\n", "\n\n@app.on_event(\"startup\")\nasync def on_startup_event():\n    await engine.connect()  \n    await engine.crud(Item) # cruds are cached, calling this here means \n                            # we don't lose instantiating it elsewhere\n\n@app.on_event(\"shutdown\")\nasync def on_shutdown_event():", "@app.on_event(\"shutdown\")\nasync def on_shutdown_event():\n    await engine.close()\n\nasync def get_item_by_id(id_: int) -> Item:\n    \"\"\"Returns the item with the specified id\n\n    Args: \n        id_ (int): the id of the item to lookup\n    ", "        id_ (int): the id of the item to lookup\n    \n    Raises:\n        HTTPException: if there is no item with the given id_\n    \n    \"\"\"\n    crud =await engine.crud(Item)\n    item = await crud.get_or_none(id=id_)\n    if item is None:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"No item with {id_} was found in the database\",\n        )", "    if item is None:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"No item with {id_} was found in the database\",\n        )\n    return item\n\n\nitem_by_id_deps = Annotated[Item, Depends(get_item_by_id)]\n", "item_by_id_deps = Annotated[Item, Depends(get_item_by_id)]\n\n\n@app.post(\"/items/new\")\nasync def create_item(item: Item) -> Item:\n    try:\n        crud = await engine.crud(Item)\n        new_item = await crud.insert(**item.dict())\n    except QueryExecutionError:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=f\"Item with {item.id} was already found in the database\",\n        )", "    return new_item\n\n\n@app.get(\"/items/{id}\")\nasync def get_item_route(item: item_by_id_deps) -> Item:\n    return item\n\n\n@app.get(\"/items\")\nasync def get_all_items() -> list[Item]:", "@app.get(\"/items\")\nasync def get_all_items() -> list[Item]:\n    crud = await engine.crud(Item)\n    return await crud.get_all()\n\n\n@app.patch(\"/items/{id}\")\nasync def patch_item(item: item_by_id_deps, patched: PatchedItem) -> Item:\n    item.name = patched.name\n    item.price = patched.price", "    item.name = patched.name\n    item.price = patched.price\n    crud = await engine.crud(Item)\n    await crud.save_one(item)\n    return item\n\n\n@app.delete(\"/item/{id}\")\nasync def delete_item(item: item_by_id_deps) -> None:\n    crud = await engine.crud(Item)", "async def delete_item(item: item_by_id_deps) -> None:\n    crud = await engine.crud(Item)\n    await crud.delete_one(item)\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app)\n", ""]}
{"filename": "examples/rep_discord_bot.py", "chunked_list": ["from ardilla import Model, Field, ForeignField\nfrom ardilla.asyncio import Engine\n\nfrom discord import Intents, Member\nfrom discord.ext.commands import Bot, Context, guild_only\n\n# db engine\nengine = Engine(\"discobot.sqlite3\", enable_foreing_keys=True)\n\n", "\n\n# models\nclass GuildTable(Model):\n    __tablename__ = \"guilds\"\n    id: int = Field(primary=True)\n\n\nclass MembersTable(Model):\n    __tablename__ = \"members\"\n    id: int\n    guild_id: int = ForeignField(\n        references=GuildTable,\n        on_delete=ForeignField.CASCADE\n    )\n    reputation: int = 0", "class MembersTable(Model):\n    __tablename__ = \"members\"\n    id: int\n    guild_id: int = ForeignField(\n        references=GuildTable,\n        on_delete=ForeignField.CASCADE\n    )\n    reputation: int = 0\n\n", "\n\n# bot stuff\nTOKEN = \"GENERATE YOUR TOKEN FROM DISCORD'S DEVELOPERS' PORTAL\"\nintents = Intents.default()\nintents.members = True\nintents.message_content = True\n\nclass RepBot(Bot):\n    def __init__(self):\n        super().__init__(command_prefix='!', intents=intents)\n    \n    async def setup_hook(self):\n        # connect the engine\n        await engine.connect()\n        # setup the table's cache\n        self.gcrud = await engine.crud(GuildTable)\n        self.mcrud = await engine.crud(MembersTable)\n    \n    async def close(self):\n        # close engine\n        await engine.close()\n        return await super().close()", "class RepBot(Bot):\n    def __init__(self):\n        super().__init__(command_prefix='!', intents=intents)\n    \n    async def setup_hook(self):\n        # connect the engine\n        await engine.connect()\n        # setup the table's cache\n        self.gcrud = await engine.crud(GuildTable)\n        self.mcrud = await engine.crud(MembersTable)\n    \n    async def close(self):\n        # close engine\n        await engine.close()\n        return await super().close()", "\nbot = RepBot()\n\n\n@bot.command()\n@guild_only()\nasync def thank(ctx: Context, member: Member):\n    if member == ctx.author:\n        return await ctx.send(\"You can't thank yourself\")\n    ", "    \n    await bot.gcrud.insert_or_ignore(id=ctx.guild.id)\n    dbmember, _ = await bot.mcrud.get_or_create(id=member.id, guild_id=ctx.guild.id)\n    dbmember.reputation += 1\n    await bot.mcrud.save_one(dbmember)\n    await ctx.send(\n        f\"{member.mention} was thanked. Their reputation is now {dbmember.reputation}\"\n    )\n\n", "\n\n@bot.command()\n@guild_only()\nasync def reputation(ctx: Context, member: Member | None = None):\n    member = member or ctx.author\n    await bot.gcrud.insert_or_ignore(id=ctx.guild.id)\n    dbmember, _ = await bot.mcrud.get_or_create(id=member.id, guild_id=ctx.guild.id)\n    await ctx.send(f\"{member.mention} has a reputation of {dbmember.reputation}\")\n", "    await ctx.send(f\"{member.mention} has a reputation of {dbmember.reputation}\")\n\n\nbot.run(TOKEN)\n"]}
{"filename": "examples/basic_usage_fk.py", "chunked_list": ["# basic example\n\nfrom ardilla import Model, Engine, Field, ForeignField\n\nclass Owner(Model):\n    id: int = Field(pk=True, auto=True)\n    name: str\n\n\nclass Pet(Model):\n    id: int = Field(pk=True, auto=True)\n    name: str\n    owner_id: int = ForeignField(references=Owner, on_delete=ForeignField.CASCADE)", "\nclass Pet(Model):\n    id: int = Field(pk=True, auto=True)\n    name: str\n    owner_id: int = ForeignField(references=Owner, on_delete=ForeignField.CASCADE)\n\n\nwith Engine(\"foo.db\", enable_foreing_keys=True) as engine:\n# create crud helpers\n    owcrud = engine.crud(Owner)\n    petcrud = engine.crud(Pet)\n\n    # create owners\n    chris = owcrud.insert(name='chris')\n    liz = owcrud.insert(name='liz')\n\n    # Create objects with relationships\n    melly = petcrud.insert(name='melly', owner_id=liz.id)\n    wolke = petcrud.insert(name='wolke', owner_id=chris.id)\n    shirley = petcrud.insert(name='shirley', owner_id=chris.id)\n\n    # delete owner and test CASCADING EFFECT\n    owcrud.delete_one(chris)\n\n    pets = petcrud.get_all()\n    owners = owcrud.get_all()\n    print(pets)\n    print(owners)\n    assert len(pets) == 1, \"Foreign keys didn't cascade\"\n    print('All done, foreign key constrains work')", ""]}
{"filename": "examples/basic_usage.py", "chunked_list": ["# basic example\n\nfrom ardilla import Model, Engine, Field\n\n\n\nclass Pet(Model):\n    id: int = Field(pk=True, auto=True)\n    name: str\n    love: int = 0", "\n\nwith Engine(\"foo.db\") as engine:\n    crud = engine.crud(Pet)\n\n    # create a new pets\n    for pet_name in {\"fluffy\", \"fido\", \"snowball\"}:\n        crud.insert(name=pet_name)\n\n    # read your pets\n    fido = crud.get_or_none(name=\"fido\")\n    fluffy = crud.get_or_none(name=\"fluffy\")\n    snowball = crud.get_or_none(name=\"snowball\")\n    print(fido, fluffy, snowball, sep=\"\\n\")\n    # update your pets\n    fluffy.love += 10\n    crud.save_one(fluffy)\n    print(fluffy)\n    # delete your pet\n    crud.delete_many(fido, snowball)\n\n    # check if everything works:\n    pets = crud.get_all()\n    assert len(pets) == 1, \"Something went wrong!!\"\n    print(\"All done!\")", ""]}
