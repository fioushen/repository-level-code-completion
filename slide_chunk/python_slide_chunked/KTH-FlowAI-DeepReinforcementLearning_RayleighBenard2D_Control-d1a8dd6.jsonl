{"filename": "channelflow2d.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# channelflow2d.py: CFD solver from shenfun\n#\n# Mikael Mortenson\n#\n\nfrom warnings import WarningMessage", "\nfrom warnings import WarningMessage\nfrom shenfun import *\nnp.warnings.filterwarnings('ignore')\n\nclass KMM:\n    \"\"\"Navier Stokes channel flow solver in 2D\n\n    The wall normal direction is along the x-axis, the streamwise along the y-axis.\n\n    The solver is fully spectral with Chebyshev (or Legendre) in the wall-normal\n    direction and Fourier in the other.\n\n    Using the equations described by Kim, Moser, Moin (https://doi.org/10.1017/S0022112087000892)\n    but with the spectral Galerkin method in space and a chosen time stepper.\n\n    Parameters\n    ----------\n    N : 2-tuple of ints\n        The global shape in physical space (quadrature points)\n    domain : 2-tuple of 2-tuples\n        The size of the three domains\n    nu : Viscosity coefficient\n    dt : Timestep\n    conv : Choose convection method\n        - 0 - Standard convection\n        - 1 - Vortex type\n    filename : str, optional\n        Filenames are started with this name\n    family : str, optional\n        Chebyshev is normal, but Legendre works as well\n    padding_factor : 2-tuple of numbers, optional\n        For dealiasing, backward transforms to real space are\n        padded with zeros in spectral space using these many points\n    modplot : int, optional\n        Plot some results every modplot timestep. If negative, no plotting\n    modsave : int, optional\n        Save results to hdf5 every modsave timestep.\n    moderror : int, optional\n        Print diagnostics every moderror timestep\n    checkpoint : int, optional\n        Save required data for restart to hdf5 every checkpoint timestep.\n    timestepper : str, optional\n        Choose timestepper\n\n    Note\n    ----\n    Simulations may be killed gracefully by placing a file named 'killshenfun'\n    in the folder running the solver from. The solver will then first store\n    the results by checkpointing, before exiting.\n\n    \"\"\"\n    def __init__(self,\n                 N=(32, 32),\n                 domain=((-1, 1), (0, 2*np.pi)),\n                 nu=0.01,\n                 dt=0.1,\n                 conv=0,\n                 dpdy=1,\n                 filename='KMM',\n                 family='C',\n                 padding_factor=(1, 1.5),\n                 modplot=100,\n                 modsave=1e8,\n                 moderror=100,\n                 checkpoint=1000,\n                 timestepper='IMEXRK3'):\n        self.N = N\n        self.nu = nu\n        self.dt = dt\n        self.conv = conv\n        self.modplot = modplot\n        self.modsave = modsave\n        self.moderror = moderror\n        self.filename = filename\n        self.padding_factor = padding_factor\n        self.dpdy = dpdy\n        self.PDE = PDE = globals().get(timestepper)\n        self.im1 = None\n\n        # Regular spaces\n        self.B0 = FunctionSpace(N[0], family, bc=(0, 0, 0, 0), domain=domain[0])\n        self.D0 = FunctionSpace(N[0], family, bc=(0, 0), domain=domain[0])\n        self.C0 = FunctionSpace(N[0], family, domain=domain[0])\n        self.F1 = FunctionSpace(N[1], 'F', dtype='d', domain=domain[1])\n        self.D00 = FunctionSpace(N[0], family, bc=(0, 0), domain=domain[0])  # Streamwise velocity, not to be in tensorproductspace\n        self.C00 = self.D00.get_orthogonal()\n\n        # Regular tensor product spaces\n        self.TB = TensorProductSpace(comm, (self.B0, self.F1), modify_spaces_inplace=True) # Wall-normal velocity\n        self.TD = TensorProductSpace(comm, (self.D0, self.F1), modify_spaces_inplace=True) # Streamwise velocity\n        self.TC = TensorProductSpace(comm, (self.C0, self.F1), modify_spaces_inplace=True) # No bc\n        self.BD = VectorSpace([self.TB, self.TD])  # Velocity vector space\n        self.CD = VectorSpace(self.TD)             # Dirichlet vector space\n\n        # Padded space for dealiasing\n        self.TDp = self.TD.get_dealiased(padding_factor)\n\n        self.u_ = Function(self.BD)      # Velocity vector solution\n        self.H_ = Function(self.CD)      # convection\n        self.ub = Array(self.BD)\n\n        self.v00 = Function(self.D00)   # For solving 1D problem for Fourier wavenumber 0, 0\n        self.w00 = Function(self.D00)\n\n        self.work = CachedArrayDict()\n        self.mask = self.TB.get_mask_nyquist() # Used to set the Nyquist frequency to zero\n        self.X = self.TD.local_mesh(bcast=True)\n        self.K = self.TD.local_wavenumbers(scaled=True)\n\n        # Classes for fast projections. All are not used except if self.conv=0\n        self.dudx = Project(Dx(self.u_[0], 0, 1), self.TD)\n        if self.conv == 0:\n            self.dudy = Project(Dx(self.u_[0], 1, 1), self.TB)\n            self.dvdx = Project(Dx(self.u_[1], 0, 1), self.TC)\n            self.dvdy = Project(Dx(self.u_[1], 1, 1), self.TD)\n\n        self.curl = Project(curl(self.u_), self.TC)\n        self.divu = Project(div(self.u_), self.TC)\n        self.solP = None # For computing pressure\n\n        # File for storing the results\n        self.file_u = ShenfunFile('_'.join((filename, 'U')), self.BD, backend='hdf5', mode='w', mesh='uniform')\n\n        # Create a checkpoint file used to restart simulations\n        self.checkpoint = Checkpoint(filename,\n                                     checkevery=checkpoint,\n                                     data={'0': {'U': [self.u_]}})\n\n        # set up equations\n        v = TestFunction(self.TB)\n\n        # Chebyshev matrices are not sparse, so need a tailored solver. Legendre has simply 5 nonzero diagonals and can use generic solvers.\n        sol1 = chebyshev.la.Biharmonic if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\n        self.pdes = {\n\n            'u': PDE(v,                                   # test function\n                     div(grad(self.u_[0])),               # u\n                     lambda f: self.nu*div(grad(f)),      # linear operator on u\n                     Dx(Dx(self.H_[1], 0, 1), 1, 1)-Dx(self.H_[0], 1, 2),\n                     dt=self.dt,\n                     solver=sol1,\n                     latex=r\"\\frac{\\partial \\nabla^2 u}{\\partial t} = \\nu \\nabla^4 u + \\frac{\\partial^2 N_y}{\\partial x \\partial y} - \\frac{\\partial^2 N_x}{\\partial y^2}\"),\n\n        }\n\n        # v. Solve divergence constraint for all wavenumbers except 0\n        r\"\"\":math:`\\nabla \\cdot \\vec{u} = 0`\"\"\"\n\n        # v. Momentum equation for Fourier wavenumber 0\n        if comm.Get_rank() == 0:\n            v0 = TestFunction(self.D00)\n            self.h1 = Function(self.D00)  # Copy from H_[1, :, 0, 0] (cannot use view since not contiguous)\n            source = Array(self.C00)\n            source[:] = -self.dpdy        # dpdy set by subclass\n            sol = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.Solver\n            self.pdes1d = {\n                'v0': PDE(v0,\n                          self.v00,\n                          lambda f: self.nu*div(grad(f)),\n                          [-Expr(self.h1), source],\n                          dt=self.dt,\n                          solver=sol,\n                          latex=r\"\\frac{\\partial v}{\\partial t} = \\nu \\frac{\\partial^2 v}{\\partial x^2} - N_y - \\frac{\\partial p}{\\partial y}\"),\n            }\n            \n\n    def convection(self):\n        H = self.H_.v\n        self.up = self.u_.backward(padding_factor=self.padding_factor)\n        up = self.up.v\n        if self.conv == 0:\n            dudxp = self.dudx().backward(padding_factor=self.padding_factor).v\n            dudyp = self.dudy().backward(padding_factor=self.padding_factor).v\n            dvdxp = self.dvdx().backward(padding_factor=self.padding_factor).v\n            dvdyp = self.dvdy().backward(padding_factor=self.padding_factor).v\n            H[0] = self.TDp.forward(up[0]*dudxp+up[1]*dudyp, H[0])\n            H[1] = self.TDp.forward(up[0]*dvdxp+up[1]*dvdyp, H[1])\n\n        elif self.conv == 1:\n            curl = self.curl().backward(padding_factor=self.padding_factor)\n            H[0] = self.TDp.forward(-curl*up[1])\n            H[1] = self.TDp.forward(curl*up[0])\n        self.H_.mask_nyquist(self.mask)\n\n    def compute_v(self, rk):\n        u = self.u_.v\n        if comm.Get_rank() == 0:\n            self.v00[:] = u[1, :, 0].real\n            self.h1[:] = self.H_[1, :, 0].real\n\n        # Find velocity components v from div. constraint\n        u[1] = 1j*self.dudx()/self.K[1]\n\n        # Still have to compute for wavenumber = 0, 0\n        if comm.Get_rank() == 0:\n            # v component\n            self.pdes1d['v0'].compute_rhs(rk)\n            u[1, :, 0] = self.pdes1d['v0'].solve_step(rk)\n\n        return u\n\n    def compute_pressure(self):\n        if self.solP is None:\n            self.d2udx2 = Project(self.nu*Dx(self.u_[0], 0, 2), self.TC)\n            N0 = self.N0 = FunctionSpace(self.N[0], self.B0.family(), bc={'left': {'N': self.d2udx2()}, 'right': {'N': self.d2udx2()}})\n            TN = self.TN = TensorProductSpace(comm, (N0, self.F1), modify_spaces_inplace=True)\n            sol = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n            self.divH = Inner(TestFunction(TN), -div(self.H_))\n            self.solP = sol(inner(TestFunction(TN), div(grad(TrialFunction(TN)))))\n            self.p_ = Function(TN)\n\n        self.d2udx2()\n        self.N0.bc.set_tensor_bcs(self.N0, self.TN)\n        p_ = self.solP(self.divH(), self.p_, constraints=((0, 0),))\n        return p_\n\n    def print_energy_and_divergence(self, t, tstep):\n        if tstep % self.moderror == 0 and self.moderror > 0:\n            ub = self.u_.backward(self.ub)\n            e0 = inner(1, ub[0]*ub[0])\n            e1 = inner(1, ub[1]*ub[1])\n            divu = self.divu().backward()\n            e3 = np.sqrt(inner(1, divu*divu))\n            if comm.Get_rank() == 0:\n                print(\"Time %2.5f Energy %2.6e %2.6e div %2.6e\" %(t, e0, e1, e3))\n\n    def init_from_checkpoint(self):\n        self.checkpoint.read(self.u_, 'U', step=0)\n        self.checkpoint.open()\n        tstep = self.checkpoint.f.attrs['tstep']\n        t = self.checkpoint.f.attrs['t']\n        self.checkpoint.close()\n        return t, tstep\n\n    def initialize(self, from_checkpoint=False):\n        if from_checkpoint:\n            return self.init_from_checkpoint()\n        raise RuntimeError('Initialize solver in subclass')\n\n    def plot(self, t, tstep):\n        pass\n\n    def update(self, t, tstep):\n        self.plot(t, tstep)\n        self.print_energy_and_divergence(t, tstep)\n\n    def tofile(self, tstep):\n        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n\n    def prepare_step(self, rk):\n        self.convection()\n\n    def assemble(self):\n        for pde in self.pdes.values():\n            pde.assemble()\n        if comm.Get_rank() == 0:\n            for pde in self.pdes1d.values():\n                pde.assemble()\n\n    def solve(self, t=0, tstep=0, end_time=1000):\n        self.assemble()\n        while t < end_time-1e-8:\n            for rk in range(self.PDE.steps()):\n                self.prepare_step(rk)\n                for eq in self.pdes.values():\n                    eq.compute_rhs(rk)\n                for eq in self.pdes.values():\n                    eq.solve_step(rk)\n                self.compute_v(rk)\n            t += self.dt\n            tstep += 1\n            self.update(t, tstep)\n            self.checkpoint.update(t, tstep)\n            if tstep % self.modsave == 0:\n                self.tofile(tstep)", ""]}
{"filename": "rb_marl.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# rb_marl.py: Rayleigh Benard CFD environment\n#\n# Colin Vignon & Joel Vasanth\n#\n# FLOW, KTH Stockholm | 09/04/2023\n", "# FLOW, KTH Stockholm | 09/04/2023\n\nfrom shenfun import *\nimport matplotlib.pyplot as plt\nimport sympy\nimport os, csv, numpy as np\nimport shutil\nimport copy\nfrom time import time\nfrom mpi4py import MPI", "from time import time\nfrom mpi4py import MPI\nfrom tensorforce.environments import Environment\nfrom mpi4py_fft import generate_xdmf\nfrom channelflow2d import KMM\nfrom parameters import nb_actuations, num_episodes, num_servers, \\\n    simu_name, nb_inv_envs, simulation_duration\n\n\nnp.warnings.filterwarnings('ignore')", "\nnp.warnings.filterwarnings('ignore')\n\nx, y, tt = sympy.symbols('x,y,t', real=True)\n\ncomm = MPI.COMM_SELF\n\n\n\nclass RayleighBenard(KMM):\n\n    def __init__(self, N=(64, 96), domain=((-1, 1), (0, 2*sympy.pi)), Ra=10000., Pr=0.7, dt=0.05, bcT=(2, 1), \\\n         conv=0, filename='RB_2D', family='C', padding_factor=(1, 1.5), modplot=10, obsGrid=(8,32), modsave=10,  \\\n            moderror=10, checkpoint=10, timestepper='IMEXRK3'):\n        \n        plt.close('all')\n        KMM.__init__(self, N=N, domain=domain, nu=np.sqrt(Pr/Ra), dt=dt, conv=conv,\n                     filename=filename, family=family, padding_factor=padding_factor,\n                     modplot=modplot, modsave=modsave, moderror=moderror,\n                     checkpoint=checkpoint, timestepper=timestepper, dpdy=0)\n        self.kappa = 1./np.sqrt(Pr*Ra)\n        self.bcT = bcT\n        plt.close('all')\n        \n        # Additional spaces and functions for Temperature equation\n        self.T0 = FunctionSpace(N[0], family, bc=bcT, domain=domain[0])\n        self.TT = TensorProductSpace(comm, (self.T0, self.F1), modify_spaces_inplace=True) # Temperature\n        self.uT_ = Function(self.BD)     # Velocity vector times T\n        self.T_ = Function(self.TT)      # Temperature solution\n        self.Tb = Array(self.TT)\n        \n        self.file_T = ShenfunFile('_'.join((filename, 'T')), self.TT, backend='hdf5', mode='w', mesh='uniform')\n\n        # Modify checkpoint file\n        self.checkpoint.data['0']['T'] = [self.T_]\n\n        dt = self.dt\n        kappa = self.kappa\n        self.N = N\n\n        sol2 = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\n        # Addition to u equation.\n        self.pdes['u'].N = [self.pdes['u'].N, Dx(self.T_, 1, 2)]\n        self.pdes['u'].latex += r'\\frac{\\partial^2 T}{\\partial y^2}'\n\n        # Remove constant pressure gradient from v0 equation\n        self.pdes1d['v0'].N = self.pdes1d['v0'].N[0]\n\n        # Add T equation\n        q = TestFunction(self.TT)\n        self.pdes['T'] = self.PDE(q,\n                                  self.T_,\n                                  lambda f: kappa*div(grad(f)),\n                                  -div(self.uT_),\n                                  dt=self.dt,\n                                  solver=sol2,\n                                  latex=r\"\\frac{\\partial T}{\\partial t} = \\kappa \\nabla^2 T - \\nabla \\cdot \\vec{u}T\")\n\n        self.im1 = None\n        self.im2 = None\n\n        # Observation outputs\n        self.out = []\n        self.out2 = []\n        self.instant_Nusselt = []\n        self.instant_kinEn = []\n        \n        # Others\n        self.obsGrid = obsGrid\n        self.Nstep = (N[0]//self.obsGrid[0], N[1]//self.obsGrid[1])\n        \n      \n    def update_bc(self, t):\n        # Update time-dependent bcs.\n        self.T0.bc.update(t)\n        self.T_.get_dealiased_space(self.padding_factor).bases[0].bc.update(t)\n\n    def prepare_step(self, rk):\n        self.convection()\n        Tp = self.T_.backward(padding_factor=self.padding_factor)\n        self.uT_ = self.up.function_space().forward(self.up*Tp, self.uT_)\n\n    def tofile(self, tstep):\n        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n        self.file_T.write(tstep, {'T': [self.T_.backward(mesh='uniform')]})\n\n    def init_from_checkpoint(self):\n        self.checkpoint.read(self.u_, 'U', step=0)\n        self.checkpoint.read(self.T_, 'T', step=0)\n        self.checkpoint.open()\n        tstep = self.checkpoint.f.attrs['tstep']\n        t = self.checkpoint.f.attrs['t']\n        self.checkpoint.close()\n        return t, tstep\n\n    def print_energy_and_divergence(self, t, tstep):\n        if tstep % self.moderror == 0 and self.moderror > 0:\n            ub = self.u_.backward(self.ub)\n            Tb = self.T_.backward(self.Tb)\n            e0 = inner(1, ub[0]*ub[0])\n            e1 = inner(1, ub[1]*ub[1])\n            d0 = inner(1, Tb*Tb)\n            divu = self.divu().backward()\n            e3 = np.sqrt(inner(1, divu*divu))\n            if comm.Get_rank() == 0:\n                if tstep % (10*self.moderror) == 0 or tstep == 0:\n                    pass\n                   \n\n    def initialize(self, rand=0.001, from_checkpoint=False):\n        if from_checkpoint:\n            self.checkpoint.read(self.u_, 'U', step=0)\n            self.checkpoint.read(self.T_, 'T', step=0)\n            self.checkpoint.open()\n            tstep = self.checkpoint.f.attrs['tstep']\n            t = self.checkpoint.f.attrs['t']\n            self.checkpoint.close()\n            self.update_bc(t)\n            return t, tstep\n        X = self.X\n               \n        fun = self.bcT[0]\n        self.Tb[:] = 0.5*(1 + 0.5*self.bcT[1]-X[0]/(1+self.bcT[1])+ 0.125*(2-self.bcT[1])\\\n                          *np.sin(np.pi*X[0]))*fun + rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n        self.T_ = self.Tb.forward(self.T_)\n        self.T_.mask_nyquist(self.mask)\n        return 0, 0\n\n\n    def outputs(self, tstep, count):\n        if (tstep == 0 or count == 0):  # Make sure to reinitialize the outputs when a brand new simulation is launched\n            self.out = []\n            self.out2 = []\n            self.out_red = []\n            self.out_red2 = []\n        else:\n            ub = self.u_.backward(self.ub) \n            Tb = self.T_.backward(self.Tb)\n            new_out = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n            new_out[0] = ub[1, ::self.Nstep[0], ::self.Nstep[1]]  # horizontal (x) axis\n            new_out[1] = ub[0, ::self.Nstep[0], ::self.Nstep[1]]  # vertical (y) axis\n            new_out[2] = Tb[::self.Nstep[0], ::self.Nstep[1]]\n            self.out.append(new_out)\n            \n            # Normalization of the data\n            new_out2 = copy.copy(new_out)\n            new_out2[0]*= 1.5\n            new_out2[1]*= 1.5\n            new_out2[2] = 2*(new_out2[2] - 0.8)\n            new_out2 = new_out2.reshape(3*self.obsGrid[0]*self.obsGrid[1],)\n            self.out2.append(new_out2)\n  \n\n    def DRL_inputs(self):  # inputs for the DRL algo\n        return np.mean(np.array([self.out2[-1], self.out2[-2], self.out2[-3], self.out2[-4]]), axis=0)\n\n    def compute_Nusselt(self):\n        '''Used just to have the evolution of Nu during the baseline simulation'''\n        div = self.kappa*(2.-self.bcT[1])/2  # H = 2, Tb = 2.\n\n        gen_Nus = []\n        for i in range(1,5):\n            uyT_ = np.mean(np.mean(np.multiply(self.out[-i][1], self.out[-i][2]), axis=1), axis = 0)\n            T_ = np.mean(np.gradient(np.mean(self.out[-i][2], axis=1), axis=0))\n            gen_Nus.append((uyT_ - self.kappa*T_)/div)\n        \n        return np.mean(np.array(gen_Nus))\n                \n        \n    def compute_kinEn(self):\n        '''Used just to have the evolution of kinEn during the baseline simulation'''\n        \n        u2_xy = self.out[-1][1]*self.out[-1][1] + self.out[-1][0]*self.out[-1][0]\n        return np.sum(u2_xy)\n        \n        \n    def evolve(self, new_bcT, t_ini=None, tstep_ini = None):\n    \n        self.bcT = new_bcT    \n        new_t, new_tstep = t_ini, tstep_ini\n        self.T0.bc.bc['left']['D'] = self.bcT[0]\n        self.T0.bc.update()\n        self.T0.bc.set_tensor_bcs(self.T0, self.T0.tensorproductspace)\n        TP0 = self.T_.get_dealiased_space(self.padding_factor).bases[0]\n        TP0.bc.bc['left']['D'] = self.bcT[0]\n        TP0.bc.update()\n        TP0.bc.set_tensor_bcs(TP0, TP0.tensorproductspace)\n        \n        \n    def solve(self, which, t=0, tstep=0, end_time=1000, end_episode = False):\n        c = self.pdes['u'].stages()[2]\n        self.assemble()\n        count = 0\n        while t < end_time-1e-8:\n            for rk in range(self.PDE.steps()):\n                self.prepare_step(rk)\n                for eq in ['u', 'T']:\n                    self.pdes[eq].compute_rhs(rk)\n                for eq in ['u']:\n                    self.pdes[eq].solve_step(rk)\n                self.compute_v(rk)\n                self.update_bc(t+self.dt*c[rk+1])\n                self.pdes['T'].solve_step(rk)\n            self.outputs(tstep, count)\n            count += 1\n            if tstep >= 4 and which == 'baseline' and tstep%10 == 0:\n                self.instant_Nusselt.append(self.compute_Nusselt())\n                self.instant_kinEn.append(self.compute_kinEn())\n            t += self.dt\n            tstep += 1\n            self.update(t, tstep)\n            self.checkpoint.update(t, tstep)\n            \n            if tstep % self.modsave == 0:\n                self.tofile(tstep)\n        if end_episode:\n            self.tofile(tstep-1)  \n            self.TT.destroy()  \n            self.TB.destroy()\n            self.TD.destroy()\n            self.TC.destroy()\n            self.TDp.destroy()\n            self.BD.destroy()\n            self.CD.destroy()\n        return t, tstep         \n        \n        \n    def define_timeframe(self, which, Evolve = False, new_bcT = None, t_ini = None, tstep_ini = None):\n\n        if which == 'baseline':\n            t, tstep = self.initialize(rand=0.001, from_checkpoint=False)\n            #self.evolve(new_bcT, t, tstep)\n        else:\n            if Evolve:\n                t, tstep = t_ini, tstep_ini\n            else:\n                t, tstep = self.initialize(rand=0.001, from_checkpoint=True)\n            self.evolve(new_bcT, t, tstep)\n        return t, tstep\n\n\n    def launch(self, timeframe, which, t_ini = None, tstep_ini = None, Evolve = False, End_episode = False):\n\n        \n        t_end, tstep_end = self.solve(which, t=t_ini, tstep=tstep_ini, end_time=timeframe[1], end_episode = End_episode)\n        if which == 'baseline':\n            generate_xdmf('RB_'+str(self.N[0])+'_'+str(self.N[1])+'_T.h5')\n            generate_xdmf('RB_'+str(self.N[0])+'_'+str(self.N[1])+'_U.h5')\n        return self.DRL_inputs(), t_end, tstep_end", "\nclass RayleighBenard(KMM):\n\n    def __init__(self, N=(64, 96), domain=((-1, 1), (0, 2*sympy.pi)), Ra=10000., Pr=0.7, dt=0.05, bcT=(2, 1), \\\n         conv=0, filename='RB_2D', family='C', padding_factor=(1, 1.5), modplot=10, obsGrid=(8,32), modsave=10,  \\\n            moderror=10, checkpoint=10, timestepper='IMEXRK3'):\n        \n        plt.close('all')\n        KMM.__init__(self, N=N, domain=domain, nu=np.sqrt(Pr/Ra), dt=dt, conv=conv,\n                     filename=filename, family=family, padding_factor=padding_factor,\n                     modplot=modplot, modsave=modsave, moderror=moderror,\n                     checkpoint=checkpoint, timestepper=timestepper, dpdy=0)\n        self.kappa = 1./np.sqrt(Pr*Ra)\n        self.bcT = bcT\n        plt.close('all')\n        \n        # Additional spaces and functions for Temperature equation\n        self.T0 = FunctionSpace(N[0], family, bc=bcT, domain=domain[0])\n        self.TT = TensorProductSpace(comm, (self.T0, self.F1), modify_spaces_inplace=True) # Temperature\n        self.uT_ = Function(self.BD)     # Velocity vector times T\n        self.T_ = Function(self.TT)      # Temperature solution\n        self.Tb = Array(self.TT)\n        \n        self.file_T = ShenfunFile('_'.join((filename, 'T')), self.TT, backend='hdf5', mode='w', mesh='uniform')\n\n        # Modify checkpoint file\n        self.checkpoint.data['0']['T'] = [self.T_]\n\n        dt = self.dt\n        kappa = self.kappa\n        self.N = N\n\n        sol2 = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\n        # Addition to u equation.\n        self.pdes['u'].N = [self.pdes['u'].N, Dx(self.T_, 1, 2)]\n        self.pdes['u'].latex += r'\\frac{\\partial^2 T}{\\partial y^2}'\n\n        # Remove constant pressure gradient from v0 equation\n        self.pdes1d['v0'].N = self.pdes1d['v0'].N[0]\n\n        # Add T equation\n        q = TestFunction(self.TT)\n        self.pdes['T'] = self.PDE(q,\n                                  self.T_,\n                                  lambda f: kappa*div(grad(f)),\n                                  -div(self.uT_),\n                                  dt=self.dt,\n                                  solver=sol2,\n                                  latex=r\"\\frac{\\partial T}{\\partial t} = \\kappa \\nabla^2 T - \\nabla \\cdot \\vec{u}T\")\n\n        self.im1 = None\n        self.im2 = None\n\n        # Observation outputs\n        self.out = []\n        self.out2 = []\n        self.instant_Nusselt = []\n        self.instant_kinEn = []\n        \n        # Others\n        self.obsGrid = obsGrid\n        self.Nstep = (N[0]//self.obsGrid[0], N[1]//self.obsGrid[1])\n        \n      \n    def update_bc(self, t):\n        # Update time-dependent bcs.\n        self.T0.bc.update(t)\n        self.T_.get_dealiased_space(self.padding_factor).bases[0].bc.update(t)\n\n    def prepare_step(self, rk):\n        self.convection()\n        Tp = self.T_.backward(padding_factor=self.padding_factor)\n        self.uT_ = self.up.function_space().forward(self.up*Tp, self.uT_)\n\n    def tofile(self, tstep):\n        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n        self.file_T.write(tstep, {'T': [self.T_.backward(mesh='uniform')]})\n\n    def init_from_checkpoint(self):\n        self.checkpoint.read(self.u_, 'U', step=0)\n        self.checkpoint.read(self.T_, 'T', step=0)\n        self.checkpoint.open()\n        tstep = self.checkpoint.f.attrs['tstep']\n        t = self.checkpoint.f.attrs['t']\n        self.checkpoint.close()\n        return t, tstep\n\n    def print_energy_and_divergence(self, t, tstep):\n        if tstep % self.moderror == 0 and self.moderror > 0:\n            ub = self.u_.backward(self.ub)\n            Tb = self.T_.backward(self.Tb)\n            e0 = inner(1, ub[0]*ub[0])\n            e1 = inner(1, ub[1]*ub[1])\n            d0 = inner(1, Tb*Tb)\n            divu = self.divu().backward()\n            e3 = np.sqrt(inner(1, divu*divu))\n            if comm.Get_rank() == 0:\n                if tstep % (10*self.moderror) == 0 or tstep == 0:\n                    pass\n                   \n\n    def initialize(self, rand=0.001, from_checkpoint=False):\n        if from_checkpoint:\n            self.checkpoint.read(self.u_, 'U', step=0)\n            self.checkpoint.read(self.T_, 'T', step=0)\n            self.checkpoint.open()\n            tstep = self.checkpoint.f.attrs['tstep']\n            t = self.checkpoint.f.attrs['t']\n            self.checkpoint.close()\n            self.update_bc(t)\n            return t, tstep\n        X = self.X\n               \n        fun = self.bcT[0]\n        self.Tb[:] = 0.5*(1 + 0.5*self.bcT[1]-X[0]/(1+self.bcT[1])+ 0.125*(2-self.bcT[1])\\\n                          *np.sin(np.pi*X[0]))*fun + rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n        self.T_ = self.Tb.forward(self.T_)\n        self.T_.mask_nyquist(self.mask)\n        return 0, 0\n\n\n    def outputs(self, tstep, count):\n        if (tstep == 0 or count == 0):  # Make sure to reinitialize the outputs when a brand new simulation is launched\n            self.out = []\n            self.out2 = []\n            self.out_red = []\n            self.out_red2 = []\n        else:\n            ub = self.u_.backward(self.ub) \n            Tb = self.T_.backward(self.Tb)\n            new_out = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n            new_out[0] = ub[1, ::self.Nstep[0], ::self.Nstep[1]]  # horizontal (x) axis\n            new_out[1] = ub[0, ::self.Nstep[0], ::self.Nstep[1]]  # vertical (y) axis\n            new_out[2] = Tb[::self.Nstep[0], ::self.Nstep[1]]\n            self.out.append(new_out)\n            \n            # Normalization of the data\n            new_out2 = copy.copy(new_out)\n            new_out2[0]*= 1.5\n            new_out2[1]*= 1.5\n            new_out2[2] = 2*(new_out2[2] - 0.8)\n            new_out2 = new_out2.reshape(3*self.obsGrid[0]*self.obsGrid[1],)\n            self.out2.append(new_out2)\n  \n\n    def DRL_inputs(self):  # inputs for the DRL algo\n        return np.mean(np.array([self.out2[-1], self.out2[-2], self.out2[-3], self.out2[-4]]), axis=0)\n\n    def compute_Nusselt(self):\n        '''Used just to have the evolution of Nu during the baseline simulation'''\n        div = self.kappa*(2.-self.bcT[1])/2  # H = 2, Tb = 2.\n\n        gen_Nus = []\n        for i in range(1,5):\n            uyT_ = np.mean(np.mean(np.multiply(self.out[-i][1], self.out[-i][2]), axis=1), axis = 0)\n            T_ = np.mean(np.gradient(np.mean(self.out[-i][2], axis=1), axis=0))\n            gen_Nus.append((uyT_ - self.kappa*T_)/div)\n        \n        return np.mean(np.array(gen_Nus))\n                \n        \n    def compute_kinEn(self):\n        '''Used just to have the evolution of kinEn during the baseline simulation'''\n        \n        u2_xy = self.out[-1][1]*self.out[-1][1] + self.out[-1][0]*self.out[-1][0]\n        return np.sum(u2_xy)\n        \n        \n    def evolve(self, new_bcT, t_ini=None, tstep_ini = None):\n    \n        self.bcT = new_bcT    \n        new_t, new_tstep = t_ini, tstep_ini\n        self.T0.bc.bc['left']['D'] = self.bcT[0]\n        self.T0.bc.update()\n        self.T0.bc.set_tensor_bcs(self.T0, self.T0.tensorproductspace)\n        TP0 = self.T_.get_dealiased_space(self.padding_factor).bases[0]\n        TP0.bc.bc['left']['D'] = self.bcT[0]\n        TP0.bc.update()\n        TP0.bc.set_tensor_bcs(TP0, TP0.tensorproductspace)\n        \n        \n    def solve(self, which, t=0, tstep=0, end_time=1000, end_episode = False):\n        c = self.pdes['u'].stages()[2]\n        self.assemble()\n        count = 0\n        while t < end_time-1e-8:\n            for rk in range(self.PDE.steps()):\n                self.prepare_step(rk)\n                for eq in ['u', 'T']:\n                    self.pdes[eq].compute_rhs(rk)\n                for eq in ['u']:\n                    self.pdes[eq].solve_step(rk)\n                self.compute_v(rk)\n                self.update_bc(t+self.dt*c[rk+1])\n                self.pdes['T'].solve_step(rk)\n            self.outputs(tstep, count)\n            count += 1\n            if tstep >= 4 and which == 'baseline' and tstep%10 == 0:\n                self.instant_Nusselt.append(self.compute_Nusselt())\n                self.instant_kinEn.append(self.compute_kinEn())\n            t += self.dt\n            tstep += 1\n            self.update(t, tstep)\n            self.checkpoint.update(t, tstep)\n            \n            if tstep % self.modsave == 0:\n                self.tofile(tstep)\n        if end_episode:\n            self.tofile(tstep-1)  \n            self.TT.destroy()  \n            self.TB.destroy()\n            self.TD.destroy()\n            self.TC.destroy()\n            self.TDp.destroy()\n            self.BD.destroy()\n            self.CD.destroy()\n        return t, tstep         \n        \n        \n    def define_timeframe(self, which, Evolve = False, new_bcT = None, t_ini = None, tstep_ini = None):\n\n        if which == 'baseline':\n            t, tstep = self.initialize(rand=0.001, from_checkpoint=False)\n            #self.evolve(new_bcT, t, tstep)\n        else:\n            if Evolve:\n                t, tstep = t_ini, tstep_ini\n            else:\n                t, tstep = self.initialize(rand=0.001, from_checkpoint=True)\n            self.evolve(new_bcT, t, tstep)\n        return t, tstep\n\n\n    def launch(self, timeframe, which, t_ini = None, tstep_ini = None, Evolve = False, End_episode = False):\n\n        \n        t_end, tstep_end = self.solve(which, t=t_ini, tstep=tstep_ini, end_time=timeframe[1], end_episode = End_episode)\n        if which == 'baseline':\n            generate_xdmf('RB_'+str(self.N[0])+'_'+str(self.N[1])+'_T.h5')\n            generate_xdmf('RB_'+str(self.N[0])+'_'+str(self.N[1])+'_U.h5')\n        return self.DRL_inputs(), t_end, tstep_end", "    \n    \n\n"]}
{"filename": "rayleighbenard2d.py", "chunked_list": ["from shenfun import *\n\nimport matplotlib.pyplot as plt\nimport sympy\nimport os, csv, numpy as np\nimport shutil\nimport copy\nfrom time import time\nfrom mpi4py import MPI\nfrom tensorforce.environments import Environment", "from mpi4py import MPI\nfrom tensorforce.environments import Environment\n\nfrom channelflow2d import KMM\n#from witness import read_last_wit\n\n\nnp.warnings.filterwarnings('ignore')\n\n# pylint: disable=attribute-defined-outside-init", "\n# pylint: disable=attribute-defined-outside-init\n\nx, y, tt = sympy.symbols('x,y,t', real=True)\n\ncomm = MPI.COMM_SELF\n\nclass RayleighBenard(KMM):\n\n    def __init__(self, N=(64, 96), domain=((-1, 1), (0, 2*sympy.pi)), Ra=10000., Pr=0.7, dt=0.05, bcT=(2, 1), conv=0, filename='RB_2D', family='C', padding_factor=(1, 1.5), modplot=10, obsGrid=(8,32), modsave=10, moderror=10, checkpoint=10, timestepper='IMEXRK3'):", "\n    def __init__(self, N=(64, 96), domain=((-1, 1), (0, 2*sympy.pi)), Ra=10000., Pr=0.7, dt=0.05, bcT=(2, 1), conv=0, filename='RB_2D', family='C', padding_factor=(1, 1.5), modplot=10, obsGrid=(8,32), modsave=10, moderror=10, checkpoint=10, timestepper='IMEXRK3'):\n        \n        plt.close('all')\n        KMM.__init__(self, N=N, domain=domain, nu=np.sqrt(Pr/Ra), dt=dt, conv=conv,\n                     filename=filename, family=family, padding_factor=padding_factor,\n                     modplot=modplot, modsave=modsave, moderror=moderror,\n                     checkpoint=checkpoint, timestepper=timestepper, dpdy=0)\n        self.kappa = 1./np.sqrt(Pr*Ra)\n        self.bcT = bcT", "        self.kappa = 1./np.sqrt(Pr*Ra)\n        self.bcT = bcT\n        plt.close('all')\n        # Additional spaces and functions for Temperature equation\n        self.T0 = FunctionSpace(N[0], family, bc=bcT, domain=domain[0])\n        self.TT = TensorProductSpace(comm, (self.T0, self.F1), modify_spaces_inplace=True) # Temperature\n        self.uT_ = Function(self.BD)     # Velocity vector times T\n        self.T_ = Function(self.TT)      # Temperature solution\n        self.Tb = Array(self.TT)\n        ", "        self.Tb = Array(self.TT)\n        \n        self.file_T = ShenfunFile('_'.join((filename, 'T')), self.TT, backend='hdf5', mode='w', mesh='uniform')\n\n        # Modify checkpoint file\n        self.checkpoint.data['0']['T'] = [self.T_]\n\n        dt = self.dt\n        kappa = self.kappa\n", "        kappa = self.kappa\n\n        # Chebyshev matrices are not sparse, so need a tailored solver. Legendre has simply 5 nonzero diagonals\n        sol2 = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\n        # Addition to u equation.\n        self.pdes['u'].N = [self.pdes['u'].N, Dx(self.T_, 1, 2)]\n        self.pdes['u'].latex += r'\\frac{\\partial^2 T}{\\partial y^2}'\n\n        # Remove constant pressure gradient from v0 equation", "\n        # Remove constant pressure gradient from v0 equation\n        self.pdes1d['v0'].N = self.pdes1d['v0'].N[0]\n\n        # Add T equation\n        q = TestFunction(self.TT)\n        self.pdes['T'] = self.PDE(q,\n                                  self.T_,\n                                  lambda f: kappa*div(grad(f)),\n                                  -div(self.uT_),", "                                  lambda f: kappa*div(grad(f)),\n                                  -div(self.uT_),\n                                  dt=self.dt,\n                                  solver=sol2,\n                                  latex=r\"\\frac{\\partial T}{\\partial t} = \\kappa \\nabla^2 T - \\nabla \\cdot \\vec{u}T\")\n\n        self.im1 = None\n        self.im2 = None\n\n\t# Observation outputs", "\n\t# Observation outputs\n        self.out = []\n        self.out2 = []\n        self.instant_Nusselt = []\n        self.instant_kinEn = []\n        \n        # Others\n        self.obsGrid = obsGrid\n        self.Nstep = (N[0]//self.obsGrid[0], N[1]//self.obsGrid[1])", "        self.obsGrid = obsGrid\n        self.Nstep = (N[0]//self.obsGrid[0], N[1]//self.obsGrid[1])\n        \n      \n    def update_bc(self, t):\n        # Update time-dependent bcs.\n        self.T0.bc.update(t)\n        self.T_.get_dealiased_space(self.padding_factor).bases[0].bc.update(t)\n\n    def prepare_step(self, rk):", "\n    def prepare_step(self, rk):\n        self.convection()\n        Tp = self.T_.backward(padding_factor=self.padding_factor)\n        self.uT_ = self.up.function_space().forward(self.up*Tp, self.uT_)\n\n    def tofile(self, tstep):\n        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n        self.file_T.write(tstep, {'T': [self.T_.backward(mesh='uniform')]})\n", "        self.file_T.write(tstep, {'T': [self.T_.backward(mesh='uniform')]})\n\n    def init_from_checkpoint(self):\n        self.checkpoint.read(self.u_, 'U', step=0)\n        self.checkpoint.read(self.T_, 'T', step=0)\n        self.checkpoint.open()\n        tstep = self.checkpoint.f.attrs['tstep']\n        t = self.checkpoint.f.attrs['t']\n        self.checkpoint.close()\n        return t, tstep", "        self.checkpoint.close()\n        return t, tstep\n\n    def print_energy_and_divergence(self, t, tstep):\n        if tstep % self.moderror == 0 and self.moderror > 0:\n            ub = self.u_.backward(self.ub)\n            Tb = self.T_.backward(self.Tb)\n            e0 = inner(1, ub[0]*ub[0])\n            e1 = inner(1, ub[1]*ub[1])\n            d0 = inner(1, Tb*Tb)", "            e1 = inner(1, ub[1]*ub[1])\n            d0 = inner(1, Tb*Tb)\n            divu = self.divu().backward()\n            e3 = np.sqrt(inner(1, divu*divu))\n            if comm.Get_rank() == 0:\n                if tstep % (10*self.moderror) == 0 or tstep == 0:\n                    pass\n                    #print(f\"{'Time':^11}{'uu':^11}{'vv':^11}{'T*T':^11}{'div':^11}\")\n                #print(f\"{t:2.4e} {e0:2.4e} {e1:2.4e} {d0:2.4e} {e3:2.4e}\")\n", "                #print(f\"{t:2.4e} {e0:2.4e} {e1:2.4e} {d0:2.4e} {e3:2.4e}\")\n\n    def initialize(self, rand=0.001, from_checkpoint=False):\n        if from_checkpoint:\n            self.checkpoint.read(self.u_, 'U', step=0)\n            self.checkpoint.read(self.T_, 'T', step=0)\n            self.checkpoint.open()\n            tstep = self.checkpoint.f.attrs['tstep']\n            t = self.checkpoint.f.attrs['t']\n            self.checkpoint.close()", "            t = self.checkpoint.f.attrs['t']\n            self.checkpoint.close()\n            self.update_bc(t)\n            return t, tstep\n\n        X = self.X\n               \n        if self.bcT[0] == 1:\n            funT = 1\n        elif int(self.bcT[0]) == 0.6:", "            funT = 1\n        elif int(self.bcT[0]) == 0.6:\n            funT = 3\n        elif int(self.bcT[0]) == 2:\n            funT = 4\n        else:\n            funT = 2\n        fun = {1: 1,\n               2: (0.9+0.1*np.sin(2*X[1])),\n               3: 0.6,", "               2: (0.9+0.1*np.sin(2*X[1])),\n               3: 0.6,\n               4: 2.}[funT]\n        self.Tb[:] = 0.5*(1 + 0.5*self.bcT[1]-X[0]/(1+self.bcT[1])+ 0.125*(2-self.bcT[1])*np.sin(np.pi*X[0]))*fun + rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n        #self.Tb[:] = 0.5*(1-X[0]+0.25*np.sin(np.pi*X[0]))*fun+rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n        self.T_ = self.Tb.forward(self.T_)\n        self.T_.mask_nyquist(self.mask)\n        return 0, 0\n\n                ", "\n                \n    #def init_plots(self):\n    #    self.ub = ub = self.u_.backward()\n    #    Tb = self.T_.backward(self.Tb)\n    #    if comm.Get_rank() == 0:\n    #        plt.figure(1, figsize=(6, 3))\n    #        self.im1 = plt.quiver(self.X[1][::4, ::4], self.X[0][::4, ::4], ub[1, ::4, ::4], ub[0, ::4, ::4], pivot='mid', scale=0.01)\n    #        plt.draw()\n    #        plt.figure(2, figsize=(6, 3))", "    #        plt.draw()\n    #        plt.figure(2, figsize=(6, 3))\n    #        self.im2 = plt.contourf(self.X[1][:, :], self.X[0][:, :], Tb[:, :], 100, cmap ='plasma')\n    #        plt.draw()\n    #        plt.pause(1e-6) \n    \n    #def plot(self, t, tstep):\n    #    if self.im1 is None and self.modplot > 0:\n    #        self.init_plots()\n    #    if tstep % self.modplot == 0 and self.modplot > 0:", "    #        self.init_plots()\n    #    if tstep % self.modplot == 0 and self.modplot > 0:\n    #        ub = self.u_.backward(self.ub)\n    #        self.Tb = self.T_.backward(self.Tb)\n    #        if comm.Get_rank() == 0:\n    #            plt.figure(1)\n    #            self.im1.set_UVC(ub[1, ::4, ::4], ub[0, ::4, ::4])\n    #            self.im1.scale = np.linalg.norm(ub[1])\n    #            plt.pause(1e-6)\n    #            plt.figure(2)", "    #            plt.pause(1e-6)\n    #            plt.figure(2)\n    #            self.im2.axes.clear()\n    #            self.im2.axes.contourf(self.X[1][:, :], self.X[0][:, :], self.Tb[:, :], 100, cmap ='plasma')\n    #            self.im2.autoscale()\n    #            plt.pause(1e-6)\n\n\n    def outputs(self, tstep):\n    \tif tstep == 0:  # Make sure to reinitialize the outputs when a brand new simulation is launched", "    def outputs(self, tstep):\n    \tif tstep == 0:  # Make sure to reinitialize the outputs when a brand new simulation is launched\n            self.out = []\n            self.out2 = []\n            self.out_red = []\n            self.out_red2 = []\n        else:  # Bein20 environment with probes grid 8*8. Me: 16 horizontal, 8 vertical\n    \t    ub = self.u_.backward(self.ub)\n            Tb = self.T_.backward(self.Tb)\n    \t    ", "            Tb = self.T_.backward(self.Tb)\n    \t    \n    \t    new_out = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n    \t    new_out[0] = ub[1, ::self.Nstep[0], ::self.Nstep[1]]  # horizontal (x) axis\n    \t    new_out[1] = ub[0, ::self.Nstep[0], ::self.Nstep[1]]  # vertical (y) axis\n    \t    new_out[2] = Tb[::self.Nstep[0], ::self.Nstep[1]]\n    \t    self.out.append(new_out)\n    \t    \n    \t    new_out2 = copy.copy(new_out)\n    \t    new_out2[0]*= 1.5", "    \t    new_out2 = copy.copy(new_out)\n    \t    new_out2[0]*= 1.5\n    \t    new_out2[1]*= 1.5\n    \t    new_out2[2] = 2*(new_out2[2] - 0.8)\n    \t    new_out2 = new_out2.reshape(3*self.obsGrid[0]*self.obsGrid[1],)\n    \t    self.out2.append(new_out2)\n                \n\n    def DRL_inputs(self):  # inputs for the DRL algo\n        #inputs = [self.out2[-1], self.out2[-2], self.out2[-3], self.out2[-4]]  # Beintama takes into account the four last states", "    def DRL_inputs(self):  # inputs for the DRL algo\n        #inputs = [self.out2[-1], self.out2[-2], self.out2[-3], self.out2[-4]]  # Beintama takes into account the four last states\n        return np.mean(np.array([self.out2[-1], self.out2[-2], self.out2[-3], self.out2[-4]]), axis=0)\n       # else:\n        #    return self.out_red2[-1]\n        \n\n    def compute_Nusselt(self):\n        div = self.kappa*(2.-self.bcT[1])/2  # H = 2, Tb = 2.\n", "        div = self.kappa*(2.-self.bcT[1])/2  # H = 2, Tb = 2.\n\n        uyT_ = np.mean(np.mean(np.multiply(self.out[-1][1], self.out[-1][2]), axis=1), axis = 0)\n        T_ = np.mean(np.gradient(np.mean(self.out[-1][2], axis=1), axis=0))\n        gen_Nus = (uyT_ - self.kappa*T_)/div\n        \n        uyT_2 = np.mean(np.mean(np.multiply(self.out[-2][1], self.out[-2][2]), axis=1), axis = 0)\n        T_2 = np.mean(np.gradient(np.mean(self.out[-2][2], axis=1), axis=0))\n        gen_Nus2 = (uyT_ - self.kappa*T_)/div\n        uyT_3 = np.mean(np.mean(np.multiply(self.out[-3][1], self.out[-3][2]), axis=1), axis = 0)", "        gen_Nus2 = (uyT_ - self.kappa*T_)/div\n        uyT_3 = np.mean(np.mean(np.multiply(self.out[-3][1], self.out[-3][2]), axis=1), axis = 0)\n        T_3 = np.mean(np.gradient(np.mean(self.out[-3][2], axis=1), axis=0))\n        gen_Nus3 = (uyT_ - self.kappa*T_)/div\n        \n        uyT_4 = np.mean(np.mean(np.multiply(self.out[-4][1], self.out[-4][2]), axis=1), axis = 0)\n        T_4 = np.mean(np.gradient(np.mean(self.out[-4][2], axis=1), axis=0))\n        gen_Nus4 = (uyT_ - self.kappa*T_)/div\n        \n        return np.mean(np.array([gen_Nus, gen_Nus2, gen_Nus3, gen_Nus4]))", "        \n        return np.mean(np.array([gen_Nus, gen_Nus2, gen_Nus3, gen_Nus4]))\n        \n        \n    def compute_kinEn(self):\n        \n        u2_xy = self.out[-1][1]*self.out[-1][1] + self.out[-1][0]*self.out[-1][0]\n        return np.sum(u2_xy)\n        \n        ", "        \n        \n    def evolve(self, new_bcT, t_ini=None, tstep_ini = None):\n    \n        self.bcT = new_bcT    \n        new_t, new_tstep = t_ini, tstep_ini\n        self.T0.bc.bc['left']['D'] = self.bcT[0]\n        self.T0.bc.update()\n        self.T0.bc.set_tensor_bcs(self.T0, self.T0.tensorproductspace)\n        TP0 = self.T_.get_dealiased_space(self.padding_factor).bases[0]", "        self.T0.bc.set_tensor_bcs(self.T0, self.T0.tensorproductspace)\n        TP0 = self.T_.get_dealiased_space(self.padding_factor).bases[0]\n        TP0.bc.bc['left']['D'] = self.bcT[0]\n        TP0.bc.update()\n        TP0.bc.set_tensor_bcs(TP0, TP0.tensorproductspace)\n        \n        \n    def solve(self, which, t=0, tstep=0, end_time=1000, end_episode = False):\n        c = self.pdes['u'].stages()[2]\n        self.assemble()", "        c = self.pdes['u'].stages()[2]\n        self.assemble()\n        \n        #print('Temperature values of the segments : ', self.bcT)\n        while t < end_time-1e-8:\n            for rk in range(self.PDE.steps()):\n                self.prepare_step(rk)\n                for eq in ['u', 'T']:\n                    self.pdes[eq].compute_rhs(rk)\n                for eq in ['u']:", "                    self.pdes[eq].compute_rhs(rk)\n                for eq in ['u']:\n                    self.pdes[eq].solve_step(rk)\n                self.compute_v(rk)\n                self.update_bc(t+self.dt*c[rk+1])\n                self.pdes['T'].solve_step(rk)\n            self.outputs(tstep)\n            if tstep >= 4 and which == 'baseline' and tstep%10 == 0:\n                self.instant_Nusselt.append(self.compute_Nusselt())\n                self.instant_kinEn.append(self.compute_kinEn())", "                self.instant_Nusselt.append(self.compute_Nusselt())\n                self.instant_kinEn.append(self.compute_kinEn())\n                #print('Nusselt at tstep : ', tstep, ' = ', self.instant_Nusselt[-1])\n            #elif tstep % 20 > 4 and which != 'baseline':\n             #   print('Nusselt at tstep : ', tstep, ' = ', self.compute_Nusselt())\n            t += self.dt\n            tstep += 1\n            self.update(t, tstep)\n            self.checkpoint.update(t, tstep)\n            ", "            self.checkpoint.update(t, tstep)\n            \n            if tstep % self.modsave == 0:\n                self.tofile(tstep)\n        if end_episode:\n            self.TT.destroy()  # To solve issue #19\n            self.TB.destroy()\n            self.TD.destroy()\n            self.TC.destroy()\n            self.TDp.destroy()", "            self.TC.destroy()\n            self.TDp.destroy()\n            self.BD.destroy()\n            self.CD.destroy()\n        return t, tstep\n\n\n    def launch(self, timeframe, which, Evolve = False, End_episode = False, new_bcT = None, t_ini = None, tstep_ini = None):\n        #t0 = time()\n        if which == 'baseline':", "        #t0 = time()\n        if which == 'baseline':\n            t, tstep = self.initialize(rand=0.001, from_checkpoint=False)\n        else:\n            if Evolve:\n                t, tstep = t_ini, tstep_ini\n                self.evolve(new_bcT, t, tstep)\n            else:\n                t, tstep = self.initialize(rand=0.001, from_checkpoint=True)\n        t_end, tstep_end = self.solve(which, t=t, tstep=tstep, end_time=timeframe[1], end_episode = End_episode)", "                t, tstep = self.initialize(rand=0.001, from_checkpoint=True)\n        t_end, tstep_end = self.solve(which, t=t, tstep=tstep, end_time=timeframe[1], end_episode = End_episode)\n        \n        #plt.close('all')\n        #print('Computing time %2.4f'%(time()-t0))\n        return [self.compute_Nusselt(), self.compute_kinEn(), 0], self.DRL_inputs(), t_end, tstep_end\n\t\n\t\n\t\n", "\t\n\n"]}
{"filename": "deterministic.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n'''\n\ndeterministic.py: Deterministinc runner for trained agent evaluation\n\nCreated: 2/5/2023\n\nAuthor: Pol Suarez, adapted for shenfun by Colin Vignon\n", "Author: Pol Suarez, adapted for shenfun by Colin Vignon\n\n'''\n\nimport os, time, sys\nimport subprocess\nimport copy as cp\nfrom tensorforce.agents import Agent\nfrom tensorforce.execution import Runner\n", "from tensorforce.execution import Runner\n\n# Change to your case name here \ncase_name = 'RB_2D_multiAgent_6_4pi'\ngeneral_path = os.getcwd()\n\n# Set case path \ncase_path = general_path+'/shenfun_files/cases/'+case_name\nsys.path.append(case_path)\n", "sys.path.append(case_path)\n\nfrom MARL_env import Environment2D\nfrom parameters import nb_actuations, num_episodes, num_servers, simu_name, nb_inv_envs, n_seg\n\n# Set to Fasle for SARL \nMARL = True\nif MARL:\n    nb_envs = nb_inv_envs\nelse:\n    nb_envs = num_servers", "\n# Begin timer\ninitial_time = time.time()\n\n\n# Read the list of nodes\nfp = open('nodelist','r')\nnodelist = [h.strip() for h in fp.readlines()]\nfp.close()\n\ndef split(environment, np):  \n    \n    \n    ''' input: one of the parallel environments (np); output: a list of nb_inv_envs invariant \n    environments identical to np. \n    \n    Their ID card: (np, ni)\n    \n    np:= number of the parallel environment. e.g. between [1,4] for 4 parallel environments\n    ni:= env_ID[1]:= number of the 'pseudo-parallel' invariant environment. e.g. between [1, 10] for 10 invariant envs\n    nb_inv_envs:= total number of 'pseudo-parallel' invariant environments. e.g. 10\n\n    '''\n\n    list_inv_envs = []\n    for i in range(nb_inv_envs):\n        env = cp.copy(environment)\n        env.ENV_ID = [np, i+1]\n        env.host=\"environment{}\".format((np-1)*nb_inv_envs + (i+1))\n        list_inv_envs.append(env)\n    return list_inv_envs", "fp.close()\n\ndef split(environment, np):  \n    \n    \n    ''' input: one of the parallel environments (np); output: a list of nb_inv_envs invariant \n    environments identical to np. \n    \n    Their ID card: (np, ni)\n    \n    np:= number of the parallel environment. e.g. between [1,4] for 4 parallel environments\n    ni:= env_ID[1]:= number of the 'pseudo-parallel' invariant environment. e.g. between [1, 10] for 10 invariant envs\n    nb_inv_envs:= total number of 'pseudo-parallel' invariant environments. e.g. 10\n\n    '''\n\n    list_inv_envs = []\n    for i in range(nb_inv_envs):\n        env = cp.copy(environment)\n        env.ENV_ID = [np, i+1]\n        env.host=\"environment{}\".format((np-1)*nb_inv_envs + (i+1))\n        list_inv_envs.append(env)\n    return list_inv_envs", "\nenvironment_base = Environment2D(simu_name = simu_name, path=general_path, do_baseline=False, ENV_ID=[1,0], deterministic=True, host=\"environment1\", node=nodelist)  # Baseline\nenvironments_MARL = [split(environment_base, 1)[j] for j in range(nb_inv_envs)]\n\n\n# Load TensorForce Agent from saved agent during training \nagent = Agent.load(directory=os.path.join(case_path, 'saver_data'), format='checkpoint', environment=environment_base)\n\n# Initialise TensorForce Runner\nrunner = Runner(agent=agent, environments=environments_MARL, remote='multiprocessing', max_episode_timesteps=5000)", "# Initialise TensorForce Runner\nrunner = Runner(agent=agent, environments=environments_MARL, remote='multiprocessing', max_episode_timesteps=5000)\n\n# Run the runner\nrunner.run(num_episodes=nb_envs, evaluation=True)\n\n# Close agent, runner and end timer \nrunner.close()\nagent.close()\nend_time = time.time()", "agent.close()\nend_time = time.time()\n\nprint(\"Deterministic Runner time :\\nStart at : {}.\\nEnd at {}\\nDone in : {}\".format(initial_time,end_time,end_time-initial_time))\n"]}
{"filename": "sarl_env.py", "chunked_list": ["from shenfun import *\nimport matplotlib.pyplot as plt\nimport sympy\nimport os, csv, numpy as np\nimport shutil\nimport time\nimport json\nfrom tensorforce.environments import Environment\nfrom mpi4py import MPI\nfrom Tfunc import Tfunc", "from mpi4py import MPI\nfrom Tfunc import Tfunc\nfrom rayleighbenard2d import RayleighBenard\nfrom channelflow2d import KMM\nfrom parameters import case, simulation_params, reward_function, optimization_params, output_params, nb_proc, nb_actuations, nb_actuations_deterministic, n_seg, simu_name\nfrom env_utils import run_subprocess\n\n\ngeneral_path = os.getcwd()\ncase_path = general_path+'/data/'+simu_name", "general_path = os.getcwd()\ncase_path = general_path+'/data/'+simu_name\nos.chdir(case_path)\n\n\n\nnp.warnings.filterwarnings('ignore')\n\n# pylint: disable=attribute-defined-outside-init\n", "# pylint: disable=attribute-defined-outside-init\n\nx, y, tt = sympy.symbols('x,y,t', real=True)\n\ncomm = MPI.COMM_SELF\n\nclass Environment2D(Environment):\n\n    def __init__(self, simu_name, path, number_steps_execution=1, do_baseline=True, continue_training=False, deterministic=False, ENV_ID=-1, host='', node=None, inv_ID = 1, nb_inv_envs = 1):\n                 \n        #cr_start('ENV.init',0)\n        self.simu_name = simu_name\n        self.general_path = path\n        self.case_path = self.general_path+'/data/'+self.simu_name\n        self.case      = case\n        self.ENV_ID    = ENV_ID\n        self.host      = host\n        self.node      = node\n        \n        self.number_steps_execution = number_steps_execution\n        self.reward_function        = reward_function\n        self.output_params          = output_params\n        self.optimization_params  = optimization_params\n        \n        self.simulation_timeframe = simulation_params[\"simulation_timeframe\"]\n        self.last_time            = round(self.simulation_timeframe[1],3)\n        self.delta_t_smooth       = simulation_params[\"delta_t_smooth\"]\n        #self.smooth_func          = simulation_params[\"smooth_func\"]\n\n\n        # Others\n        self.n_seg = n_seg\n        N = (64, 96)  # (cartesian) meshgrid\n        self.obsGrid = output_params['nb_probes']  # (cartesian) grid of observation probes\n        self.dicTemp = {'T0':1., 'T1':1., 'T2':1., 'T3':1., 'T4':1., 'T5':1., 'T6':1., 'T7':1., 'T8':1., 'T9':1.}  # starting temperatures\n        self.d = {\n     \t    'N': N,\n            'Ra': 10000.,\n     \t    'Pr': 0.7,\n     \t    'dt': 0.05,\n     \t    'filename': f'RB_{N[0]}_{N[1]}',\n     \t    'conv': 0,\n     \t    'modplot': 1000,\n     \t    'obsGrid':self.obsGrid,\n    \t    'moderror': 10000,\n    \t    'modsave': 10000,\n     \t    'bcT': (Tfunc(nb_seg=n_seg, dicTemp=self.dicTemp).apply_T(y), 1),  # Tfunc: Temperature function of the lower boundary (enforce ten different temperatures on ten segments)\n     \t    'family': 'C',\n     \t    'checkpoint': 10,\n     \t    #'padding_factor': 1,\n     \t    'timestepper': 'IMEXRK3'\n     \t    }\n        self.simu = None\n        \n        #postprocess values\n        self.history_parameters = {}\n        self.history_parameters['Nusselt'] = []\n        self.history_parameters['kinEn'] = []\n        self.history_parameters[\"time\"] = []\n        self.history_parameters[\"episode_number\"] = []\n        \n        name=\"output.csv\"\n        # if we start from other episode already done\n        last_row = None\n        if(os.path.exists(\"saved_models/\"+name)):\n            with open(\"saved_models/\"+name, 'r') as f:\n                for row in reversed(list(csv.reader(f, delimiter=\";\", lineterminator=\"\\n\"))):\n                    last_row = row\n                    break\n        if(not last_row is None):\n            self.episode_number = int(last_row[0])\n            self.last_episode_number = int(last_row[0])\n        else:\n            self.last_episode_number = 0\n            self.episode_number = 0\n            \n        self.episode_Nusselts = np.array([])\n        self.episode_kinEns = np.array([])\n        \n        self.do_baseline = do_baseline\n        self.continue_training = continue_training\n        self.deterministic = deterministic\n        \n        self.start_class()\n        \n        self.do_baseline = True\n        #start episodes        \n        super().__init__()\n        #cr_stop('ENV.init',0)\n\n\n    ## Start baseline_flow from scratch, creating cfd setup\n    \n    def start_class(self):\n\n        t0 = time.time()\n        \n        self.clean(True)\n        self.create_baseline()\n        \n        #----------------------------------------------------------------------\n        # Run the first case\n        t0 = time.time()\n        \n        #shenfun run in baseline\n        self.run(which = 'reset')\n        print(\"Done. time elapsed : \", time.time() - t0)\n        \n        # Get the new avg drag and lift and SAVE \n        self.action_count=0\n        \n        if self.continue_training == True or self.deterministic == True:\n            temp_id = '{}'.format(self.host)\n        else:\n            temp_id = ''\n        \n        self.check_id = True\n\n    def clean(self,full):\n        \n        if full:\n            if self.do_baseline == True:\n                if os.path.exists(\"saved_models\"):\n                    run_subprocess('./','rm -r','saved_models')\n                \n                ## Best model at the end of each episode\n                if os.path.exists(\"best_model\"):\n                    run_subprocess('./','rm -r','best_model')\n            \n            \n        else:\n            self.action_count = 1\n            \n     \n    def create_baseline(self):\n        if self.do_baseline == True:\n            os.mkdir(self.case_path+'/baseline')\n           \n          \n    def run(self, which, evolve = False): \n                \n        if which == 'baseline':\n            os.chdir(self.case_path+'/baseline')\n\n            self.base = RayleighBenard(**self.d)\n            if self.do_baseline == True:\n                data_reward, self.probes_values, self.t_end_ini, self.tstep_end_ini = self.base.launch(self.simulation_timeframe, which)\n                self.t_end_baseline, self.tstep_end_baseline = self.t_end_ini, self.tstep_end_ini\n                evo_Nusselt_baseline = self.base.instant_Nusselt\n                evo_kinEn_baseline = self.base.instant_kinEn\n                with open('evo_Nusselt_baseline.json', 'w') as f:\n                    json.dump(evo_Nusselt_baseline, f)\n                with open('evo_kinEn_baseline.json', 'w') as f2:\n                    json.dump(evo_kinEn_baseline, f2)\n                    \n                info_baseline = [data_reward[0], data_reward[1], data_reward[2], self.t_end_ini, self.tstep_end_ini]+list(self.probes_values)\n                with open('data_baseline.json', 'w') as f3:\n                    json.dump(info_baseline, f3)\n            else:\n                with open('data_baseline.json', 'r') as f3:\n                    info_baseline = json.load(f3)\n                Nusselt, kinEn, meanFlow, self.t_end_ini, self.tstep_end_ini, self.probes_values = info_baseline[0], info_baseline[1], info_baseline[2], info_baseline[3], info_baseline[4], info_baseline[5:]\n                data_reward = [Nusselt, kinEn, meanFlow]  \n                self.t_end_baseline, self.tstep_end_baseline = self.t_end_ini, self.tstep_end_ini\n            print('baseline run finished')\n            os.chdir(self.case_path)          \n            \n        elif which == 'reset':\n            os.chdir(self.case_path+'/baseline')\n            os.system('mkdir -p logs') \n            self.run('baseline')\n\n        elif which == 'execute':\n            casepath = os.path.join(self.case_path,'%s'%self.host,'EP_%d'%self.episode_number)\n            logsrun  = os.path.join('logs','log_last_execute_run.log')\n            logssets = os.path.join('logs','log_sets.log')\n            run_subprocess(casepath,'mkdir -p','logs') \n            os.chdir(casepath)\n           \n            if self.action_count ==1:\n                self.d.update({'moderror':10000, 'modsave':10000})\n                self.simu = RayleighBenard(**self.d)\n                evolve = False\n                \n            end_episode = (self.action_count == nb_actuations)\n            data_reward, self.probes_values, self.t_end_ini, self.tstep_end_ini = self.simu.launch(self.simulation_timeframe, which, evolve, end_episode, self.d.get('bcT'), self.t_end_ini, self.tstep_end_ini)\n            os.chdir(self.case_path)\n            return data_reward, self.probes_values\n\n\n\n    def save_history_parameters(self, nb_actuations):\n                \n        # Save at the end of every episode\n        self.episode_Nusselts = np.append(self.episode_Nusselts, self.history_parameters['Nusselt'])\n        self.episode_kinEns = np.append(self.episode_kinEns, self.history_parameters['kinEn'])        \n        \n        if self.action_count == nb_actuations or self.episode_number == 0:\n            self.last_episode_number = self.episode_number\n            \n            last_instant_Nusselt = self.history_parameters['Nusselt'][-1]\n            last_instant_kinEn = self.history_parameters['kinEn'][-1]\n                        \n            if self.do_baseline == True:\n                name = \"output.csv\"\n                if(not os.path.exists(\"saved_models\")):\n                    os.mkdir(\"saved_models\")\n                if(not os.path.exists(\"saved_models/\"+name)):\n                    with open(\"saved_models/\"+name, \"w\") as csv_file:\n                        spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                        if self.reward_function == 'Nusselt': \n                            spam_writer.writerow([\"Episode\", \"instantNusselt\"])\n                            spam_writer.writerow([self.last_episode_number, last_instant_Nusselt])\n                        else: \n                            spam_writer.writerow([\"Episode\", \"instant_kinEn\"])\n                            spam_writer.writerow([self.last_episode_number, last_instant_kinEn])\n                else:\n                    with open(\"saved_models/\"+name, \"a\") as csv_file:\n                        spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                        if self.reward_function == 'Nusselt':\n                            spam_writer.writerow([self.last_episode_number, last_instant_Nusselt])\n                        else:\n                            spam_writer.writerow([self.last_episode_number, last_instant_kinEn])\n            self.episode_Nusselts = np.array([])\n            self.episode_kinEns = np.array([])\n            \n            if self.do_baseline == True:\n                if(os.path.exists(\"saved_models/output.csv\")):\n                    if(not os.path.exists(\"best_model\")):\n                        shutil.copytree(\"saved_models\", \"best_model\")\n                    else:\n                        with open(\"saved_models/output.csv\", 'r') as csvfile:\n                            data = csv.reader(csvfile, delimiter = ';')\n                            for row in data:\n                                lastrow = row\n                            last_iter = lastrow[1]\n                        with open(\"best_model/output.csv\", 'r') as csvfile:\n                            data = csv.reader(csvfile, delimiter = ';')\n                            for row in data:\n                                lastrow = row\n                            best_iter = lastrow[1]\n                        if float(best_iter) < float(last_iter):\n                            if(os.path.exists(\"best_model\")):\n                                shutil.rmtree(\"best_model\")\n                            shutil.copytree(\"saved_models\", \"best_model\")\n                        \n            \n        \n         \n    def save_this_action(self):\n        \n        name_a = \"output_actions.csv\"\n        if(not os.path.exists(\"actions\")):\n            os.mkdir(\"actions\")    \n        if(not os.path.exists(\"actions/{}\".format(self.host))):\n            os.mkdir(\"actions/{}\".format(self.host))\n        if(not os.path.exists(\"actions/{}/ep_{}/\".format(self.host, self.episode_number))):\n            os.mkdir(\"actions/{}/ep_{}/\".format(self.host, self.episode_number))\n        \n        path_a = \"actions/{}/ep_{}/\".format(self.host, self.episode_number)\n        action_line = \"{}\".format(self.action_count)\n        for i in range(self.n_seg):\n            action_line = action_line + \"; {}\".format(self.action[i])\n        \n        if(not os.path.exists(path_a+name_a)):\n            header_line = \"Action\"\n            for i in range(self.n_seg):\n                header_line = header_line + \"; Segment_{}\".format(i+1)  # TODO: \"Jet\" -> modify\n            with open(path_a+name_a, \"w\") as csv_file:\n                spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n                spam_writer.writerow([header_line])\n                spam_writer.writerow([action_line])\n        else:\n            with open(path_a+name_a, \"a\") as csv_file:\n                spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n                spam_writer.writerow([action_line])\n\n\n\n    def save_reward(self,reward, Nusselt):  \n        \n        name_a = \"output_rewards.csv\"\n        name_N = \"output_Nusselts.csv\"  \n\n        if(not os.path.exists(\"rewards\")):\n            os.mkdir(\"rewards\")\n            \n        if(not os.path.exists(\"rewards/{}\".format(self.host))):\n            os.mkdir(\"rewards/{}\".format(self.host))\n            \n        if(not os.path.exists(\"rewards/{}/ep_{}/\".format(self.host, self.episode_number))):\n            os.mkdir(\"rewards/{}/ep_{}/\".format(self.host, self.episode_number))\n            \n        path_a = \"rewards/{}/ep_{}/\".format(self.host, self.episode_number)\n        \n        if(not os.path.exists(path_a+name_a)):\n                with open(path_a+name_a, \"w\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([\"Action\", \"Reward\"])\n                    spam_writer.writerow([self.action_count, reward])\n                with open(path_a+name_N, \"w\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([\"Action\", \"Nusselt\"])\n                    spam_writer.writerow([self.action_count, Nusselt])\n        else:\n                with open(path_a+name_a, \"a\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([self.action_count, reward])\n                with open(path_a+name_N, \"a\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([self.action_count, Nusselt])\n \n        \n    def save_final_reward(self,reward):  # TODO: nothing to change ?\n    \n        name_a = \"output_final_rewards.csv\"\n        \n        if(not os.path.exists(\"final_rewards\")):\n            os.mkdir(\"final_rewards\")\n        time.sleep(0.5)\n        if(not os.path.exists(\"final_rewards/{}\".format(self.host))):\n            os.mkdir(\"final_rewards/{}\".format(self.host))\n            \n        path_a = \"final_rewards/{}/\".format(self.host)\n        \n        if(not os.path.exists(path_a+name_a)):\n            with open(path_a+name_a, \"w\") as csv_file:\n                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                spam_writer.writerow([\"EPISODE\", \"REWARD\"])\n                spam_writer.writerow([self.episode_number, reward])\n        else:\n            with open(path_a+name_a, \"a\") as csv_file:\n                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                spam_writer.writerow([self.episode_number, reward])\n \n      \n   \n    def save_comms_probes(self): \n     \n        name_a = \"output_probes_comms.csv\"\n        \n        if(not os.path.exists(\"probes_comms\")):\n            os.mkdir(\"probes_comms\")\n            \n        if(not os.path.exists(\"probes_comms/ep_{}/\".format(self.episode_number))):\n            os.mkdir(\"probes_comms/ep_{}/\".format(self.episode_number))\n            \n        path_a = \"probes_comms/ep_{}/\".format(self.episode_number)\n        \n        if(not os.path.exists(path_a+name_a)):\n                with open(path_a+name_a, \"w\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    array_acts = np.linspace(1, 24, dtype=int) \n                    spam_writer.writerow([\"Action\", array_acts])\n                    spam_writer.writerow([self.action_count, self.probes_values])\n        else:\n                with open(path_a+name_a, \"a\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([self.action_count, self.probes_values])\n \n\n\n    def recover_start(self):  \n        runpath = self.case_path\n        runbin  = 'cp -r'\n        runargs = self.case_path+'/baseline %s'%os.path.join('%s'%self.host,'EP_%d'%self.episode_number)\n        logs    = os.path.join(self.case_path+'/baseline','logs','log_restore_last_episode.log')\n        run_subprocess(runpath,runbin,runargs,log=logs)\n        \n        self.action = np.zeros(self.n_seg)\n        self.t_end_ini, self.tstep_end_ini = self.t_end_baseline, self.tstep_end_baseline\n         \n        if(self.episode_number>1):\n            runbin  = 'rm -r'\n            runargs = os.path.join('%s'%self.host,'EP_%d'%(self.episode_number-1))\n            if self.deterministic == False:\n               run_subprocess(runpath,runbin,runargs)\n    \n    def create_cpuID(self):\n        os.chdir(self.general_path)\n        runpath = self.case_path\n        runbin  = 'mkdir'\n        if self.deterministic == False:\n            runargs = self.host\n            run_subprocess(runpath,runbin,runargs)\n            \n            name = \"nodes\"\n            if(not os.path.exists(self.case_path+\"/{}/\".format(self.host)+name)):\n                with open(self.case_path+\"/{}/\".format(self.host)+name, \"w\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([\"Nodes in this learning\"])\n                    spam_writer.writerow([self.node])\n            else:\n                with open(self.case_path+\"/{}/\".format(self.host)+name, \"a\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([\"Nodes in this learning\"])\n                    spam_writer.writerow([self.node])\n        else:\n            runargs = 'deterministic'\n            run_subprocess(runpath,runbin,runargs,check_return=False)\n            \n   \n    \n    def close(self):\n        super().close()       \n \n \n \n    def states(self):\n\n        return dict(type='float',\n                    shape=(3*self.obsGrid[0]*self.obsGrid[1], )\n                    ) \n    \n\n    def actions(self):\n        \n        \"\"\"Action is a list of n_seg capped values of Temp\"\"\"\n        return dict(type='float',\n                    shape=(self.n_seg), \n                           min_value=self.optimization_params[\"min_ampl_temp\"],\n                           max_value=self.optimization_params[\"max_ampl_temp\"]\n                    )\n    \n        \n                \n    def execute(self, actions):\n        \n        self.action = actions        \n        self.last_time = self.simulation_timeframe[1]\n        t1 = round(self.last_time,3)\n        t2 = t1 + self.delta_t_smooth\n            \n        self.simulation_timeframe = [t1,t2]\n        \n        simu_path = os.path.join(self.case_path,'%s'%self.host,'EP_%d'%self.episode_number)\n        if case == 'RB_2D':\n            for i in range(self.n_seg):\n\n                self.dicTemp.update({'T'+str(i):self.action[i]})  \n                \n                \n        self.d.update({'bcT':(Tfunc(nb_seg=n_seg, dicTemp=self.dicTemp).apply_T(y), 1)})\n        t0 = time.time()\n        data_reward, self.probes_values = self.run('execute', evolve=True)\n\n        self.history_parameters['Nusselt'].extend([data_reward[0]])\n        self.history_parameters['kinEn'].extend([data_reward[1]])\n        self.history_parameters[\"time\"].extend([self.last_time])\n        self.history_parameters[\"episode_number\"].extend([self.episode_number])\n        self.save_history_parameters(nb_actuations)\n        # Write the action\n        self.save_this_action()\n        # Compute the reward\n        reward = self.compute_reward(data_reward)\n\n        self.save_reward(reward, data_reward[0])\n       \n        self.action_count += 1\n        \n        if self.deterministic == False and self.action_count <= nb_actuations:\n            terminal = False  \n        elif self.deterministic == True and self.action_count <= nb_actuations_deterministic:\n            terminal = False  \n        else:\n            terminal = True   \n            \n            self.save_final_reward(reward)\n            time.sleep(0.1)\n           \n        return self.probes_values, terminal, reward\n        \n        \n    def reset(self):\n        \"\"\"Reset state\"\"\"\n        \n        # Create a folder for each environment\n        if self.check_id == True:\n            self.create_cpuID()\n            self.check_id = False\n        \n        # Clean\n        self.clean(False)\n        \n        # Apply new time frame\n        self.simulation_timeframe = simulation_params[\"simulation_timeframe\"]\n        t1 = self.simulation_timeframe[0]\n        t2 = self.simulation_timeframe[1]\n        self.simulation_timeframe = [t1,t2]\n        \n        # Advance in episode\n        self.episode_number += 1\n        if self.deterministic == True:\n            self.host = 'deterministic'\n        \n        # Copy the baseline in the environment directory     \n        if self.action_count == 1:\n            self.recover_start()\n        \n        NWIT_TO_READ=1 \n\n        filename     = os.path.join('shenfun_files','%s'%self.host,'EP_%d'%self.episode_number,'%s.nsi.wit'%self.case)\n\n        probes_value = self.probes_values\n        return probes_value      \n\n\n    def compute_reward(self, data):\n        if self.reward_function == 'Nusselt':  \n            reward = self.optimization_params[\"norm_reward\"]*(-data[0] + self.optimization_params[\"offset_reward\"])\n        elif self.reward_function == 'kinEn':  \n            reward = self.optimization_params[\"norm_reward\"]*(-data[1] + self.optimization_params[\"offset_reward\"])\n        elif self.reward_function == 'meanFlow':  \n            reward = self.optimization_params[\"norm_reward\"]*(-data[2] + self.optimization_params[\"offset_reward\"])\n        else:\n            print(\"ERROR: Choose 'Nusselt' or 'kinEn' or 'meanFlow' for the reward function\") \n        return reward         "]}
{"filename": "wrapper.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# wrapper.py: Wrapper file that serves as a link between the DRL (tensorforce environments) and the CFD (shenfun).\n#\n# Colin Vignon\n#\n# FLOW, KTH Stockholm | 09/04/2023\n", "# FLOW, KTH Stockholm | 09/04/2023\n\nimport matplotlib.pyplot as plt\nimport os, csv, numpy as np\nimport shutil\nimport time\nimport json\nimport copy as cp\nimport sympy\nimport random", "import sympy\nimport random\nfrom shenfun import *\nfrom Tfunc import Tfunc \nfrom rb_marl import RayleighBenard\nfrom channelflow2d import KMM  \nfrom parameters import nb_inv_envs, n_seg, simu_name, num_servers, \\\n    num_episodes, CFD_params, simulation_params, alphaRestart\n\nx, y, tt = sympy.symbols('x,y,t', real=True)", "\nx, y, tt = sympy.symbols('x,y,t', real=True)\n\n\n\nclass Wrapper():\n\n\n    def __init__(self, episode, general_path):\n        \n        self.ep = episode\n        self.local_path = general_path+'/data/'+simu_name\n\n\n    def run_CFD(self, simu, env_ID, act, simulation_timeframe, which, evolve, End_episode, t_end_ini, tstep_end_ini):\n        ''' for all the invariant environments (of one parallel env),\n            run_CFD() runs a unique simulation and gives the results to all of them \n        '''\n        np = env_ID[0]\n        ep_path = self.local_path+'/CFD_n'+str(np)+'/EP_'+str(self.ep)+'/'\n        os.chdir(ep_path)\n        \n        self.d = CFD_params['dico_d']\n        \n        if env_ID[1]==1:  # the environment(s) with ID (., 1) launches the CFD simulation(s)\n            if act==1:\n                alpha = random.random()\n                if alpha > alphaRestart and self.ep > 1:\n                    os.system('cp '+self.local_path+'/CFD_n'+str(np)+'/EP_'+str(self.ep-1)+'/*.h5 '+ep_path)\n                else:\n                     os.system('cp '+self.local_path+'/baseline/*.h5 '+ep_path)\n                    \n                if self.ep > 1:  \n                    os.system('rm -r '+self.local_path+'/CFD_n'+str(np)+'/EP_'+str(self.ep-1))\n                simu = RayleighBenard(**self.d)\n                evolve = False\n\n            # prepare the lower boundary\n            actions = self.pull_actions(act, env_ID)\n            dicTemp = {'T'+str(i):actions[i] for i in range(n_seg)}\n            self.d.update({'bcT':(Tfunc(nb_seg=n_seg, dicTemp=dicTemp).apply_T(y), 1)})\n\n            # Launch simulation\n            t_ini, tstep_ini = simu.define_timeframe(which, evolve, \\\n                                                     self.d.get('bcT'), t_end_ini, tstep_end_ini)\n            if act == 1:\n                simulation_timeframe = [t_ini, t_ini+simulation_params[\"delta_t_smooth\"]]\n            probes_values, t_end_ini, tstep_end_ini = simu.launch(simulation_timeframe, which, \\\n                                                                  t_ini, tstep_ini, evolve, End_episode)\n\n            # low cost mode: clean useless files\n            if act > 1:\n                os.system('rm '+ep_path+'Results_ep'+str(self.ep)+'_env_'+\\\n                          str(np)+'_actuation_'+str(act-1)+'.json')\n                os.system('rm '+ep_path+'is_finished'+'_Actuation'+str(act-1)+'.csv')\n\n            # write results  \n            file_w = ep_path+'Results_ep'+str(self.ep)+'_env_'+str(np)+'_actuation_'+str(act)+'.json'\n            push_info = [t_end_ini, float(tstep_end_ini)]+actions+list(probes_values)\n            with open(file_w, 'w') as f:\n                json.dump(push_info, f)\n\n            # tell the other environments that the results are ready-to-be-read\n            open(ep_path+'is_finished'+'_Actuation'+str(act)+'.csv', 'w').close()  \n                        \n        else:\n            while(not os.path.isfile(ep_path+'is_finished'+'_Actuation'+str(act)+'.csv')):  \n                time.sleep(0.05)\n\n            file_r = ep_path+'Results_ep'+str(self.ep)+'_env_'+str(np)+'_actuation_'+str(act)+'.json'\n            with open(file_r, 'r') as f:\n               pull_info = json.load(f)\n            t_end_ini, tstep_end_ini, actions, probes_values = pull_info[0], pull_info[1],\\\n                  pull_info[2:2+n_seg], pull_info[2+n_seg:]\n            \n        return probes_values, actions, t_end_ini, tstep_end_ini, simu\n        \n        \n\n    def run_baseline_CFD(self, base, do_baseline, simulation_timeframe, which):\n\n        if do_baseline == True:\n            dico = CFD_params['dico_d']\n            dico.update({'moderror':10, 'modsave':10}) \n            base = RayleighBenard(**dico)\n            t_ini, tstep_ini = base.define_timeframe(which)\n            probes_values, t_end_ini, tstep_end_ini = base.launch(simulation_timeframe, \\\n                                                                  which, t_ini, tstep_ini)\n            evo_Nusselt_baseline, evo_kinEn_baseline = base.instant_Nusselt, base.instant_kinEn\n\n            with open('evo_Nusselt_baseline.json', 'w') as f:\n                json.dump(evo_Nusselt_baseline, f)\n            with open('evo_kinEn_baseline.json', 'w') as f2:\n                json.dump(evo_kinEn_baseline, f2)\n\n            info_baseline = [t_end_ini, tstep_end_ini]+list(probes_values)\n            with open('data_baseline.json', 'w') as f3:\n                json.dump(info_baseline, f3)\n        else:\n            with open('data_baseline.json', 'r') as f3:\n                info_baseline = json.load(f3)\n            t_end_ini, tstep_end_ini, probes_values = info_baseline[0], \\\n                info_baseline[1], info_baseline[2:]\n        \n        return probes_values, t_end_ini, tstep_end_ini, base\n        \n    \n    def env1_give_answers(self, Port, env_ID):\n        for par_env in range(num_servers):\n            for inv_env in range(2,nb_inv_envs+1):\n                c = 0\n                while c<30:\n                    try:\n                        socket_client((par_env+1, inv_env), PORT=Port-\\\n                                      (inv_env+nb_inv_envs*par_env))\n                        c+=50\n                    except:\n                        time.sleep(0.1)\n                        c +=1\n\n\n    def other_wait_env1(self, Port, env_ID):\n\n        socket_server(PORT=Port-(env_ID[1]+nb_inv_envs*(env_ID[0]-1)))\n             \n\n        \n    def merge_actions(self, action, actuation, env_ID):\n        \n        CFD_path = self.local_path+'/CFD_n'+str(env_ID[0])\n        ep_path = CFD_path+'/EP_'+str(self.ep)\n        \n        if env_ID[1]==1:  \n            if actuation==1:\n                if self.ep==1:\n                    os.mkdir(CFD_path)\n                os.mkdir(ep_path)\n            \n            act_file = ep_path+'/Actions_ep'+str(self.ep)+'_env'+str(env_ID[0])+\\\n                '_actuation'+str(actuation)+'.csv'\n            with open(act_file, 'a') as csv_file:\n                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                spam_writer.writerow([env_ID[1], action])\n  \n        else:\n            while(not os.path.exists(ep_path)):\n                time.sleep(0.1)\n            act_file = ep_path+'/Actions_ep'+str(self.ep)+'_env'+str(env_ID[0])+\\\n                '_actuation'+str(actuation)+'.csv'\n            with open(act_file, 'a') as csv_file:\n                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                spam_writer.writerow([env_ID[1], action])\n\n            \n            \n    def pull_actions(self, actuation, env_ID):\n        \n        ep_path = self.local_path+'/CFD_n'+str(env_ID[0])+'/EP_'+str(self.ep)\n        Flag = False\n        while Flag == False:\n            with open(ep_path+'/Actions_ep'+str(self.ep)+'_env'+str(env_ID[0])+\\\n                    '_actuation'+str(actuation)+'.csv', 'r') as f:\n                Flag = (len(f.readlines())==n_seg)\n               \n        actions = {}        \n        with open(ep_path+'/Actions_ep'+str(self.ep)+'_env'+str(env_ID[0])+\\\n                  '_actuation'+str(actuation)+'.csv', 'r') as fbis:        \n            for line in fbis:\n                segment, action = line.split(';')\n                action = action.strip('\\n')\n                action = action.strip('[]')\n                actions.update({segment:float(action)})\n    \n        Actions = []\n        for i in range(n_seg): \n            Actions.append(actions.get(str(i+1)))\n        \n        return Actions", "                    \n                    \n                    \n                    \n                    \n                    \n        \n"]}
{"filename": "train_sarl.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# Single-Agent Reinforcement Learning launcher\n#\n# train_sarl.py: main launcher for the SARL framework. \n#\n# Pol Suarez, Francisco Alcantara, Colin Vignon & Joel Vasanth\n#", "# Pol Suarez, Francisco Alcantara, Colin Vignon & Joel Vasanth\n#\n# FLOW, KTH Stockholm | 09/04/2023\n\nfrom __future__ import print_function, division\nimport os, sys, time\nfrom tensorforce.agents import Agent\nfrom tensorforce.execution import Runner\nfrom env_utils     import run_subprocess, generate_node_list, read_node_list\n", "from env_utils     import run_subprocess, generate_node_list, read_node_list\n\n\n#### Set up which case to run\ntraining_case = \"RB_2D_SARL\"  \nsimu_name = training_case\n\ngeneral_path = os.getcwd()\ncase_path = general_path+'/data/'+simu_name\nsys.path.append(case_path)", "case_path = general_path+'/data/'+simu_name\nsys.path.append(case_path)\n\nos.system('rm -r '+case_path)\nos.mkdir(case_path)\n\nos.system('cp ./parameters/parameters_{}.py '.format(training_case)+case_path+'/parameters.py')\n\nfrom sarl_env import Environment2D\nfrom parameters import nb_actuations, num_episodes, num_servers, simu_name", "from sarl_env import Environment2D\nfrom parameters import nb_actuations, num_episodes, num_servers, simu_name\n\n\n#### Run\ninitial_time = time.time()\n\n# Generate the list of nodes\ngenerate_node_list(num_servers=num_servers) \n", "generate_node_list(num_servers=num_servers) \n\n# Read the list of nodes\nnodelist = read_node_list()\n\nprint(\"\\n\\nDRL for 2D Rayleigh-Benard convection\\n\")\nprint(\"---------------------------------------\\n\")\nprint('Case: '+simu_name+' (Single-Agent RL)\\n')\nenvironment_base = Environment2D(simu_name=simu_name, path=general_path, node=nodelist[0]) # Baseline  #+simu_name\n", "environment_base = Environment2D(simu_name=simu_name, path=general_path, node=nodelist[0]) # Baseline  #+simu_name\n\nnetwork = [dict(type='dense', size=512), dict(type='dense', size=512)]\n\nagent = Agent.create(\n    # Agent + Environment\n    agent='ppo', environment=environment_base, max_episode_timesteps=nb_actuations,\n    # Network\n    network=network,\n    # Optimization", "    network=network,\n    # Optimization\n    batch_size=20, learning_rate=1e-3, subsampling_fraction=0.2, multi_step=25,\n    # Reward estimation\n    likelihood_ratio_clipping=0.2, predict_terminal_values=True,\n    baseline=network,\n    baseline_optimizer=dict(\n        type='multi_step', num_steps=5,\n        optimizer=dict(type='adam', learning_rate=1e-3)\n    ),", "        optimizer=dict(type='adam', learning_rate=1e-3)\n    ),\n    # Regularization\n    entropy_regularization=0.01,\n    parallel_interactions=num_servers,\n    saver=dict(directory=os.path.join(os.getcwd(), 'saver_data'), frequency=1, max_checkpoints=1),#parallel_interactions=number_servers,\n)\n\nenvironments = [Environment2D(simu_name=simu_name, path=general_path, do_baseline=False, ENV_ID=i, host=\"environment{}\".format(i+1), node=nodelist[i+1]) for i in range(num_servers)]\n", "environments = [Environment2D(simu_name=simu_name, path=general_path, do_baseline=False, ENV_ID=i, host=\"environment{}\".format(i+1), node=nodelist[i+1]) for i in range(num_servers)]\n\n\n#start all environments at the same time\nrunner = Runner(agent=agent, environments=environments, remote='multiprocessing')\n\n#now start the episodes and sync_episodes is very useful to update the DANN efficiently\nrunner.run(num_episodes=num_episodes, sync_episodes=False)\nrunner.close()\n", "runner.close()\n\n#saving all the model data in model-numpy format \nagent.save(directory=os.path.join(os.getcwd(),'model-numpy'), format='numpy', append='episodes')\n\nagent.close()\n\nend_time = time.time()\n\nprint(\"DRL simulation :\\nStart at : {}.\\nEnd at {}\\nDone in : {}\".format(initial_time,end_time,end_time-initial_time))", "\nprint(\"DRL simulation :\\nStart at : {}.\\nEnd at {}\\nDone in : {}\".format(initial_time,end_time,end_time-initial_time))\n\n"]}
{"filename": "reward_functions.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# reward_functions.py: computes reward, Nusselt number and kinetic energy.\n#\n# Colin Vignon\n#\n# FLOW, KTH Stockholm | 09/04/2023\n", "# FLOW, KTH Stockholm | 09/04/2023\n\nimport copy as cp\nimport numpy as np\nfrom parameters import CFD_params, nb_inv_envs, optimization_params\n\n\ndef compute_reward(probes_values, reward_function):\n    out = cp.copy(probes_values)\n    obsGrid = CFD_params.get('dico_d').get('obsGrid')\n    out2 = np.array(out).reshape(3, obsGrid[0], obsGrid[1])\n\n    #un-normalization of the data\n    out2[0] *= 1/1.5  # horizontal speed (ux) un-normalization\n    out2[1] *= 1/1.5  # vertical speed (uy)  un-normalization\n    out2[2] *= 1/2  # temperature un-normalization\n    out2[2] += 0.8\n\n    hor_inv_probes = CFD_params.get('hor_inv_probes')\n    out_red = np.zeros((3, obsGrid[0], hor_inv_probes))  \n    out_red = out2[:, :, (nb_inv_envs//2)*hor_inv_probes:((nb_inv_envs//2)+1)*hor_inv_probes]  \n\n    kappa = 1./np.sqrt(CFD_params.get('dico_d').get('Pr')*CFD_params.get('dico_d').get('Ra'))\n    T_up = CFD_params['dico_d'].get('bcT')[1]\n    div = kappa*(2.-T_up)/2  # H = 2, Tb = 2.\n\n    uyT_ = np.mean(np.mean(np.multiply(out2[1], out2[2]), axis=1), axis = 0)\n    T_ = np.mean(np.gradient(np.mean(out2[2], axis=1), axis=0))\n    gen_Nus = (uyT_ - kappa*T_)/div\n\n    uyT_loc = np.mean(np.mean(np.multiply(out_red[1], out_red[2]), axis=1), axis = 0)\n    T_loc = np.mean(np.gradient(np.mean(out_red[2], axis=1), axis=0))\n    loc_Nus = (uyT_loc - kappa*T_loc)/div\n\n    gen_kinEn = np.sum(out2[1]*out2[1] + out2[0]*out2[0])\n    loc_kinEn = np.sum(out_red[1]*out_red[1] + out_red[0]*out_red[0])\n\n    Reward_Nus   = 0.9985*gen_Nus + 0.0015*loc_Nus\n    Reward_kinEn = 0.4*gen_kinEn + 0.6*loc_kinEn\n    if reward_function == 'Nusselt':\n        reward = optimization_params[\"norm_reward\"]*(-Reward_Nus + optimization_params[\"offset_reward\"])\n    elif reward_function == 'kinEn':\n        reward = optimization_params[\"norm_reward\"]*(-Reward_kinEn + optimization_params[\"offset_reward\"])\n    elif reward_function == 'meanFlow':\n        reward = None\n        print(\"ERROR: 'meanFlow' not encoded yet\")\n    else:\n        print(\"ERROR: Choose 'Nusselt' or 'kinEn' or 'meanFlow' for the reward function\") \n\n    return reward, gen_Nus, gen_kinEn"]}
{"filename": "train_marl.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# Multi-Agent Reinforcement Learning launcher\n#\n# train_marl.py: main launcher for the MARL framework. \n#\n# Pol Suarez, Francisco Alcantara, Colin Vignon & Joel Vasanth\n#", "# Pol Suarez, Francisco Alcantara, Colin Vignon & Joel Vasanth\n#\n# FLOW, KTH Stockholm | 09/04/2023\n\nfrom __future__ import print_function, division\nimport os, sys\nimport copy as cp\nimport time\nfrom tensorforce.agents import Agent\nfrom tensorforce.execution import Runner", "from tensorforce.agents import Agent\nfrom tensorforce.execution import Runner\nfrom env_utils import run_subprocess, generate_node_list, read_node_list\n\n\n#### Set up which case to run:\n# this is the name of the parameters file without the 'parameters_' prefix\ntraining_case = \"RB_2D_MARL\"  \n\nsimu_name = training_case", "\nsimu_name = training_case\ngeneral_path = os.getcwd()\ncase_path = general_path+'/data/'+simu_name\nsys.path.append(case_path)\n\ntry:\n    os.system('rm -r '+case_path)\nexcept:\n    print('No existing case with this name')", "os.mkdir(case_path)\nos.system('cp ./parameters/parameters_{}.py '.format(training_case)+case_path+'/parameters.py')\n\nfrom marl_env import Environment2D \nfrom parameters import nb_actuations, num_episodes, num_servers, simu_name, nb_inv_envs\n\n\n#### Run\ninitial_time = time.time()\n", "initial_time = time.time()\n\n# Generate the list of nodes\ngenerate_node_list(num_servers=num_servers) \nnodelist = read_node_list()\n\nprint(\"\\n\\nDRL for 2D Rayleigh-Benard convection\\n\")\nprint(\"---------------------------------------\\n\")\nprint('Case: '+simu_name+' (Multi-Agent RL)\\n')\nenvironment_base = Environment2D(simu_name=simu_name, path=general_path, node=nodelist[0])", "print('Case: '+simu_name+' (Multi-Agent RL)\\n')\nenvironment_base = Environment2D(simu_name=simu_name, path=general_path, node=nodelist[0])\nnetwork = [dict(type='dense', size=512), dict(type='dense', size=512)]\n\n# Define tensorforce agent\nagent = Agent.create(\n    # Agent + Environment\n    agent='ppo', environment=environment_base, max_episode_timesteps=nb_actuations,\n    # Network\n    network=network,", "    # Network\n    network=network,\n    # Optimization\n    batch_size=20, learning_rate=1e-3, subsampling_fraction=0.2, multi_step=25,\n    # Reward estimation\n    likelihood_ratio_clipping=0.2, predict_terminal_values=True,\n    # Critic\n    baseline=network,\n    baseline_optimizer=dict(\n        type='multi_step', num_steps=5,", "    baseline_optimizer=dict(\n        type='multi_step', num_steps=5,\n        optimizer=dict(type='adam', learning_rate=1e-3)\n    ),\n    # Regularization\n    entropy_regularization=0.01,\n    parallel_interactions=num_servers*nb_inv_envs,\n    saver=dict(directory=os.path.join(os.getcwd(), 'saver_data'), frequency=1, max_checkpoints=1),\n)\n", ")\n\n\ndef split(environment, np): \n    ''' input: one of the parallel environments (np); \n        output: a list of nb_inv_envs invariant environments identical to np. \n        Their ID card: (np, ni)\n    '''\n    list_inv_envs = []\n    for i in range(nb_inv_envs):\n        env = cp.copy(environment)\n        env.ENV_ID = [np, i+1]\n        env.host=\"environment{}\".format((np-1)*nb_inv_envs + (i+1))\n        list_inv_envs.append(env)\n    return list_inv_envs", "\nparallel_environments = [Environment2D(simu_name=simu_name, path=general_path, do_baseline=False, \\\n                                       ENV_ID=[i+1,0], host=\"environment{}\".format(i+1), node=nodelist[i+1]) \\\n                                        for i in range(num_servers)]\n\nenvironments = [split(parallel_environments[i], i+1)[j] for i in range(num_servers) for j in range(nb_inv_envs)]\n\n\nrunner = Runner(agent=agent, environments=environments, remote='multiprocessing')    \nrunner.run(num_episodes=num_episodes, sync_episodes=False)", "runner = Runner(agent=agent, environments=environments, remote='multiprocessing')    \nrunner.run(num_episodes=num_episodes, sync_episodes=False)\nrunner.close()\n\nagent.save(directory=os.path.join(os.getcwd(),'model-numpy'), format='numpy', append='episodes')\n\nagent.close()\n\nfor env in environments:\n    env.close()", "for env in environments:\n    env.close()\nend_time = time.time()\n\nprint(\"DRL simulation :\\nStart at : {}.\\nEnd at {}\\nDone in : {}\".format(initial_time,end_time,end_time-initial_time))\n\n\n\n\n", "\n\n\n\n"]}
{"filename": "Tfunc.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# Tfunc.py: defines temperature profiles on bottom wall that are fed to agent for actuation \n#\n# Colin Vignon\n#\n# FLOW, KTH Stockholm | 09/04/2023\n", "# FLOW, KTH Stockholm | 09/04/2023\n\nfrom shenfun import *\nimport sympy\nfrom sympy.parsing.sympy_parser import parse_expr\n\ndomain = ((-1, 1), (0, 2*sympy.pi))\n\nclass Tfunc():\n\n\tdef __init__(self, nb_seg = None, dicTemp = None):\n\t\t''' N = number of actuators/segments on the hot boundary layer\n\t\tdicTemp = temperature variations of the segments: Ti' = Tnormal + Ti, Tnormal = 0.6 here''' \n\t\n\t\tself.nb_seg = nb_seg\n\t\tself.dicTemp = dicTemp\n\n\t\t# Amplitude of variation of T\n\t\tself.ampl = 0.75  \n\n\t\t# half-length of the interval on which we do the smoothing\n\t\tself.dx = 0.03  \n\t\t\n\t\t\n\tdef apply_T(self, x):\n\t\tvalues = self.ampl*np.array(list(self.dicTemp.values()))\n\t\tMean = values.mean()\n\t\tK2 = max(1, np.abs(values-np.array([Mean]*self.nb_seg)).max()/self.ampl)\n\t\t\n\t\t# Position:\n\t\txmax = domain[1][1]\n\t\tind = sympy.floor(self.nb_seg*x//xmax)\n\n\t\tseq=[]\n\t\tcount = 0\n\t\twhile count<self.nb_seg-1:  # Temperatures will vary between: 2 +- 0.75\n\t\t\t\n\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\n\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count+1))-Mean)/K2\n\t\t\tif count == 0:\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(self.nb_seg-1))-Mean)/K2\n\t\t\telse:\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\t\n\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))  # cubic smoothing\t\t\n\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, x<x1))  # cubic smoothing\n\n\t\t\tcount += 1\n\t\t\t\n\t\t\tif count == self.nb_seg-1:\n\t\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T0\")-Mean)/K2\n\t\t\t\t\n\t\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))\n\t\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, True))\n\t\t\t\t\n\t\treturn sympy.Piecewise(*seq)", "class Tfunc():\n\n\tdef __init__(self, nb_seg = None, dicTemp = None):\n\t\t''' N = number of actuators/segments on the hot boundary layer\n\t\tdicTemp = temperature variations of the segments: Ti' = Tnormal + Ti, Tnormal = 0.6 here''' \n\t\n\t\tself.nb_seg = nb_seg\n\t\tself.dicTemp = dicTemp\n\n\t\t# Amplitude of variation of T\n\t\tself.ampl = 0.75  \n\n\t\t# half-length of the interval on which we do the smoothing\n\t\tself.dx = 0.03  \n\t\t\n\t\t\n\tdef apply_T(self, x):\n\t\tvalues = self.ampl*np.array(list(self.dicTemp.values()))\n\t\tMean = values.mean()\n\t\tK2 = max(1, np.abs(values-np.array([Mean]*self.nb_seg)).max()/self.ampl)\n\t\t\n\t\t# Position:\n\t\txmax = domain[1][1]\n\t\tind = sympy.floor(self.nb_seg*x//xmax)\n\n\t\tseq=[]\n\t\tcount = 0\n\t\twhile count<self.nb_seg-1:  # Temperatures will vary between: 2 +- 0.75\n\t\t\t\n\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\n\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count+1))-Mean)/K2\n\t\t\tif count == 0:\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(self.nb_seg-1))-Mean)/K2\n\t\t\telse:\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\t\n\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))  # cubic smoothing\t\t\n\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, x<x1))  # cubic smoothing\n\n\t\t\tcount += 1\n\t\t\t\n\t\t\tif count == self.nb_seg-1:\n\t\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T0\")-Mean)/K2\n\t\t\t\t\n\t\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))\n\t\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, True))\n\t\t\t\t\n\t\treturn sympy.Piecewise(*seq)", "\t\t"]}
{"filename": "marl_env.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# marl_env.py: Defines the tensorforce environments and adapts them for use in the MARL framework.\n#\n# Colin Vignon & Joel Vasanth\n#\n# FLOW, KTH Stockholm | 09/04/2023\n", "# FLOW, KTH Stockholm | 09/04/2023\n\nfrom shenfun import *\nimport matplotlib.pyplot as plt\nimport sympy\nimport os, csv, numpy as np\nimport shutil\nimport time\nimport json\n", "import json\n\n# Environment\nfrom tensorforce.environments import Environment\nfrom mpi4py import MPI\nfrom wrapper import Wrapper\nfrom reward_functions import compute_reward\nimport copy as cp\n\nfrom parameters import CFD_params, simulation_params, reward_function, optimization_params, \\", "\nfrom parameters import CFD_params, simulation_params, reward_function, optimization_params, \\\n    nb_proc, nb_actuations, nb_actuations_deterministic, simu_name, nb_inv_envs\nfrom env_utils import run_subprocess\n\n\ngeneral_path = os.getcwd()\ncase_path = general_path+'/data/'+simu_name\nos.chdir(case_path)\n", "os.chdir(case_path)\n\nnp.warnings.filterwarnings('ignore')\n\nx, y, tt = sympy.symbols('x,y,t', real=True)\ncomm = MPI.COMM_SELF\n\nclass Environment2D(Environment):\n\n    def __init__(self, simu_name, path, number_steps_execution=1, do_baseline=True, \\\n                 continue_training=False, deterministic=False, ENV_ID=[1,1], host='', node=None):\n                 \n        self.simu_name = simu_name\n        self.general_path = path\n        self.case_path = self.general_path+'/data/'+self.simu_name\n        self.ENV_ID    = ENV_ID\n        self.nb_inv_envs = nb_inv_envs\n        self.host      = host\n        self.node      = node\n        \n        self.number_steps_execution = number_steps_execution\n        self.reward_function        = reward_function\n        self.optimization_params  = optimization_params\n        \n        self.simulation_timeframe = simulation_params[\"simulation_timeframe\"]\n        self.last_time            = round(self.simulation_timeframe[1],3)\n        self.delta_t_smooth       = simulation_params[\"delta_t_smooth\"]\n\n\n        #### CFD-related attributes\n         # number of segments on the lower boundary\n        self.n_acts = CFD_params['number_of_actuators'] \n        # (cartesian) grid of probes\n        self.obsGrid = CFD_params['dico_d'].get('obsGrid')  \n        # number of columns of probes per invariant environment\n        self.hor_inv_probes = CFD_params.get('hor_inv_probes')  \n\n        self.simu = None\n        self.base = None\n\n        # postprocess values\n        self.history_parameters = {}\n        self.history_parameters['Nusselt'] = []\n        self.history_parameters['kinEn'] = []\n        self.history_parameters[\"time\"] = []\n        self.history_parameters[\"episode_number\"] = []\n        \n        name=\"output.csv\"\n        # if we start from other episode already done\n        last_row = None\n        if(os.path.exists(\"saved_models/\"+name)):\n            with open(\"saved_models/\"+name, 'r') as f:\n                for row in reversed(list(csv.reader(f, delimiter=\";\", lineterminator=\"\\n\"))):\n                    last_row = row\n                    break\n        if(not last_row is None):\n            self.episode_number = int(last_row[0])\n            self.last_episode_number = int(last_row[0])\n        else:\n            self.last_episode_number = 0\n            self.episode_number = 0\n            \n        self.episode_Nusselts = np.array([])\n        self.episode_kinEns = np.array([])\n        \n        self.do_baseline = do_baseline\n        self.continue_training = continue_training\n        self.deterministic = deterministic\n        \n        self.start_class()\n        self.do_baseline = True\n\n\n        #start episodes        \n        super().__init__()\n\n\n    #### Start baseline_flow from scratch, creating cfd setup\n    def start_class(self):\n\n        \n        self.clean(True)\n        self.create_baseline()\n        t0 = time.time()\n        self.run(which = 'reset', ep = None)\n        print(\"Done. Time elapsed : \", np.round(time.time() - t0, 3),\" seconds\\n\")\n        \n        self.action_count=0\n        if self.continue_training == True or self.deterministic == True:\n            temp_id = '{}'.format(self.host)\n        else:\n            temp_id = ''\n        \n        self.check_id = True\n\n    \n    def clean(self,full):\n        \n        if full:\n            if self.do_baseline == True:\n                if os.path.exists(\"saved_models\"):\n                    run_subprocess('./','rm -r','saved_models')        \n        else:\n            self.action_count = 1\n            \n    def create_baseline(self):\n        if self.do_baseline == True:\n            \n            os.mkdir(self.case_path+'/baseline')\n            \n          \n    def run(self, which, ep, evolve=False): \n         # Run a simulation with shenfun\n            \n        if which == 'baseline':\n            os.chdir(self.case_path+'/baseline')\n            wrap = Wrapper(ep, self.general_path)\n            print(\"Running baseline simulation ... \")\n            self.probes_values, self.t_end_ini, self.tstep_end_ini, \\\n                self.base = wrap.run_baseline_CFD(self.base, self.do_baseline, \\\n                                                  self.simulation_timeframe, which)\n            self.t_end_baseline, self.tstep_end_baseline = self.t_end_ini, self.tstep_end_ini\n            os.chdir(self.case_path)\n            \n        elif which == 'reset':\n            os.chdir(self.case_path+'/baseline')\n            os.system('mkdir -p logs') # Create logs folder\n            self.run('baseline', ep)\n\n        elif which == 'execute':\n            wrap = Wrapper(ep, self.general_path)\n            end_episode = (self.action_count == nb_actuations)\n            self.probes_values, self.actions, self.t_end_ini, self.tstep_end_ini, \\\n                self.simu = wrap.run_CFD(self.simu, self.ENV_ID, self.action_count, \\\n                                         self.simulation_timeframe, which, evolve, \\\n                                         end_episode, self.t_end_ini, self.tstep_end_ini)\n            \n            if self.action_count == 1:\n                self.simulation_timeframe = [self.t_end_ini-self.delta_t_smooth, self.t_end_ini]            \n            os.chdir(self.case_path)\n            \n            return self.probes_values\n\n\n\n    def save_history_parameters(self, nb_actuations):\n        # Save at the end of every episode\n\n        self.episode_Nusselts = np.append(self.episode_Nusselts, self.history_parameters['Nusselt'])\n        self.episode_kinEns = np.append(self.episode_kinEns, self.history_parameters['kinEn'])        \n        \n        if self.action_count == nb_actuations or self.episode_number == 0:\n            self.last_episode_number = self.episode_number\n            last_instant_Nusselt = self.history_parameters['Nusselt'][-1]\n            last_instant_kinEn = self.history_parameters['kinEn'][-1]\n                        \n            if self.do_baseline == True:\n                name = \"output.csv\"\n                if(not os.path.exists(\"saved_models\")):\n                    try:\n                        os.mkdir(\"saved_models\")\n                    except:\n                        pass\n                if(not os.path.exists(\"saved_models/\"+name)):\n                    with open(\"saved_models/\"+name, \"w\") as csv_file:\n                        spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                        if self.reward_function == 'Nusselt': \n                            spam_writer.writerow([\"Episode\", \"instantNusselt\"])\n                            spam_writer.writerow([self.last_episode_number, last_instant_Nusselt])\n                        else: \n                            spam_writer.writerow([\"Episode\", \"instant_kinEn\"])\n                            spam_writer.writerow([self.last_episode_number, last_instant_kinEn])\n                else:\n                    with open(\"saved_models/\"+name, \"a\") as csv_file:\n                        spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                        if self.reward_function == 'Nusselt':\n                            spam_writer.writerow([self.last_episode_number, last_instant_Nusselt])\n                        else:\n                            spam_writer.writerow([self.last_episode_number, last_instant_kinEn])\n            self.episode_Nusselts = np.array([])\n            self.episode_kinEns = np.array([])\n            \n            if self.do_baseline == True:\n                pass\n                        \n            \n\n    def save_this_action(self):\n        \n        if self.ENV_ID[1] == 1:\n            name_a = \"output_actions.csv\"\n            if(not os.path.exists(\"actions\")):\n                try:\n                    os.mkdir(\"actions\")    \n                except:\n                    pass\n            if(not os.path.exists(\"actions/ep_{}/\".format(self.episode_number))):\n                os.mkdir(\"actions/ep_{}/\".format(self.episode_number))\n\n            path_a = \"actions/ep_{}/\".format(self.episode_number)\n            action_line = \"{}\".format(self.action_count)\n            for i in range(self.n_acts):\n                action_line = action_line + \"; {}\".format(self.actions[i])\n\n            if(not os.path.exists(path_a+name_a)):\n                header_line = \"Action\"\n                for i in range(self.n_acts):\n                    header_line = header_line + \"; Segment_{}\".format(i+1)\n                with open(path_a+name_a, \"w\") as csv_file:\n                    spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n                    spam_writer.writerow([header_line])\n                    spam_writer.writerow([action_line])\n            else:\n                with open(path_a+name_a, \"a\") as csv_file:\n                    spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n                    spam_writer.writerow([action_line])        \n\n\n    def save_reward(self,reward, Nusselt):\n                \n        name_a = \"output_rewards.csv\"\n        name_N = \"output_Nusselts.csv\"  \n\n        if(not os.path.exists(\"rewards\")):\n            try:\n                os.mkdir(\"rewards\")\n            except:\n                pass\n        if(not os.path.exists(\"rewards/{}\".format(self.host))):\n            os.mkdir(\"rewards/{}\".format(self.host))\n            \n        if(not os.path.exists(\"rewards/{}/ep_{}/\".format(self.host, self.episode_number))):\n            os.mkdir(\"rewards/{}/ep_{}/\".format(self.host, self.episode_number))\n            \n        path_a = \"rewards/{}/ep_{}/\".format(self.host, self.episode_number)\n        \n        if(not os.path.exists(path_a+name_a)):\n                with open(path_a+name_a, \"w\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([\"Action\", \"Reward\"])\n                    spam_writer.writerow([self.action_count, reward])\n                with open(path_a+name_N, \"w\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([\"Action\", \"Nusselt\"])\n                    spam_writer.writerow([self.action_count, Nusselt])\n        else:\n                with open(path_a+name_a, \"a\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([self.action_count, reward])\n                with open(path_a+name_N, \"a\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([self.action_count, Nusselt])\n \n       \n    def save_final_reward(self,reward): \n    \n     \n        name_a = \"output_final_rewards.csv\"\n        \n        if(not os.path.exists(\"final_rewards\")):\n            try:\n                os.mkdir(\"final_rewards\")\n            except:\n                pass\n        if(not os.path.exists(\"final_rewards/{}\".format(self.host))):\n            os.mkdir(\"final_rewards/{}\".format(self.host))\n            \n        path_a = \"final_rewards/{}/\".format(self.host)\n        \n        if(not os.path.exists(path_a+name_a)):\n            with open(path_a+name_a, \"w\") as csv_file:\n                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                spam_writer.writerow([\"EPISODE\", \"REWARD\"])\n                spam_writer.writerow([self.episode_number, reward])\n        else:\n            with open(path_a+name_a, \"a\") as csv_file:\n                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                spam_writer.writerow([self.episode_number, reward])\n      \n   \n    def save_comms_probes(self): \n         \n        name_a = \"output_probes_comms.csv\"\n        \n        if(not os.path.exists(\"probes_comms\")):\n            os.mkdir(\"probes_comms\")\n            \n        if(not os.path.exists(\"probes_comms/ep_{}/\".format(self.episode_number))):\n            os.mkdir(\"probes_comms/ep_{}/\".format(self.episode_number))\n            \n        path_a = \"probes_comms/ep_{}/\".format(self.episode_number)\n        \n        if(not os.path.exists(path_a+name_a)):\n                with open(path_a+name_a, \"w\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    array_acts = np.linspace(1, 24, dtype=int) \n                    spam_writer.writerow([\"Action\", array_acts])\n                    spam_writer.writerow([self.action_count, self.probes_values])\n        else:\n                with open(path_a+name_a, \"a\") as csv_file:\n                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n                    spam_writer.writerow([self.action_count, self.probes_values])\n \n\n    def recover_start(self): \n        runpath = self.case_path\n        self.actions = np.zeros(self.n_acts)\n        self.action = 0 \n        self.t_end_ini, self.tstep_end_ini = self.t_end_baseline, self.tstep_end_baseline\n\n    def create_cpuID(self):\n        os.chdir(self.general_path)\n        runpath = self.case_path\n        runbin  = 'mkdir'\n        if self.deterministic == False:\n            pass\n        else:\n            runargs = 'deterministic'\n            run_subprocess(runpath,runbin,runargs,check_return=False)\n               \n          \n    def close(self):\n        super().close()       \n       \n\n    def states(self):\n\n        return dict(type='float',\n                    shape=(3*self.obsGrid[0]*self.obsGrid[1], )\n                    ) \n    \n\n    def actions(self):\n        \n        \"\"\" Actions now correspond to the temperature of one segment. \n            All the actions are then gathered thanks to Wrapper().merge_actions()\n            Return: dict_values(['float', 1, -1, 1]) (e.g)\n        \"\"\"\n        \n        return dict(type='float',\n                    shape=(1), \n                           min_value=self.optimization_params[\"min_ampl_temp\"],\n                           max_value=self.optimization_params[\"max_ampl_temp\"]\n                    )\n    \n        \n                \n    def execute(self, actions):\n\n         \n        self.action = actions \n        wrap = Wrapper(self.episode_number, self.general_path)\n        wrap.merge_actions(self.action, self.action_count, self.ENV_ID)\n\n        \n        self.last_time = self.simulation_timeframe[1]\n        t1 = round(self.last_time,5)\n        t2 = t1 + self.delta_t_smooth\n            \n        self.simulation_timeframe = [t1,t2]\n        \n        # Start a run\n        t0 = time.time()\n       \n        # Run + get the new Nusselt: self.run give the global data, \n        # self.recentre_obs recenters the data according to the invariant env\n        self.probes_values = self.recentre_obs(self.run('execute', self.episode_number, evolve=True))\n\n        # Compute the reward\n        reward, gen_Nus, gen_kinEn = compute_reward(self.probes_values, self.reward_function)\n        self.history_parameters['Nusselt'].extend([gen_Nus])\n        self.history_parameters['kinEn'].extend([gen_kinEn])\n        self.history_parameters[\"time\"].extend([self.last_time])\n        self.history_parameters[\"episode_number\"].extend([self.episode_number])\n        self.save_history_parameters(nb_actuations)\n        \n        # Write the action\n        self.save_this_action()\n        \n        self.save_reward(reward, gen_Nus)\n        \n        self.action_count += 1\n        \n        if self.deterministic == False and self.action_count <= nb_actuations:\n            terminal = False  \n        elif self.deterministic == True and self.action_count <= nb_actuations_deterministic:\n            terminal = False  \n        else:\n            terminal = True   \n            \n            # write the last rewards at each episode to see the improvement \n            self.save_final_reward(reward)\n        \n        return self.probes_values, terminal, reward\n        \n        \n    def reset(self):\n        \"\"\"Reset state\"\"\"\n        \n        # Create a folder for each environment\n        if self.check_id == True:\n            self.create_cpuID()\n            self.check_id = False\n        \n        # Clean\n        self.clean(False)\n        \n        # Apply new time frame\n        t1 = simulation_params[\"simulation_timeframe\"][0]\n        t2 = simulation_params[\"simulation_timeframe\"][1]\n        self.simulation_timeframe = [t1,t2]\n        \n        # Advance in episode\n        self.episode_number += 1\n        if self.deterministic == True:\n            self.host = 'deterministic'\n        \n        # Copy the baseline in the environment directory     \n        if self.action_count == 1:\n            self.recover_start()\n        \n        return self.probes_values\n        \n\n    def recentre_obs(self, probes_values):\n\n        ''' This function is aimed at centering the data around the environment-segment \n        (1 env is attached to the behaviour of 1 segment)\n        '''\n\n        obs_array = np.array(probes_values).reshape(3, self.obsGrid[0], self.obsGrid[1])\n        centered_array = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n        ux = obs_array[0]\n        uy = obs_array[1]\n        Temp = obs_array[2]\n        \n        ind = ((self.ENV_ID[1]-(nb_inv_envs-nb_inv_envs//2))%nb_inv_envs)*self.hor_inv_probes\n\n        centered_array[0] = np.array(list(ux.T)[ind:]+list(ux.T)[:ind]).T\n        centered_array[1] = np.array(list(uy.T)[ind:]+list(uy.T)[:ind]).T        \n        centered_array[2] = np.array(list(Temp.T)[ind:]+list(Temp.T)[:ind]).T       \n        centered_list = list(centered_array.reshape(3*self.obsGrid[0]*self.obsGrid[1],))\n\n        return centered_list"]}
{"filename": "env_utils.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# Xavier Garcia, Pol Suarez, Arnau Miro, Francisco Alcantara\n#\n# 08/11/2022\n\n\nfrom __future__ import print_function, division", "\nfrom __future__ import print_function, division\n\nimport os, subprocess\nfrom configuration import NODELIST\n\n\ndef run_subprocess(runpath,runbin,runargs,nprocs=1,host=None,log=None,srun=False,check_return=True):\n\t'''\n\tUse python to call a terminal command\n\t'''\n\t# Build command to run\n\tif srun:\n\t\t# Sometimes we will need to use srun...\n\t\tcmd = 'cd %s && srun -n %d %s %s'%(runpath,nprocs,runbin,runargs) if log is None else 'cd %s && srun -n %d %s %s > %s 2>&1'%(runpath,nprocs,runbin,runargs,log)\n\telse:\n\t\tif nprocs == 1:\n\t\t\t# Run a serial command\n\t\t\tcmd = 'cd %s && %s %s'%(runpath,runbin,runargs) if log is None else 'cd %s && %s %s > %s 2>&1'%(runpath,runbin,runargs,log)\n\t\telse:\n\t\t\t# Run a parallel command\n\t\t\tif host is None:\n\t\t\t\tcmd = 'cd %s && mpirun -np %d %s %s'%(runpath,nprocs,runbin,runargs) if log is None else 'cd %s && mpirun -np %d %s %s > %s 2>&1'%(runpath,nprocs,runbin,runargs,log)\n\t\t\telse:\n\t\t\t\tcmd = 'cd %s && mpirun -np %d -host %s %s %s'%(runpath,nprocs,host,runbin,runargs) if log is None else 'cd %s && mpirun -np %d -host {3} %s %s > %s 2>&1'%(runpath,nprocs,host,runbin,runargs,log)\n\t# Execute run\n\tretval = subprocess.call(cmd,shell=True)\n\t# Check return\n\tif check_return and retval != 0: raise ValueError('Error running command <%s>!'%cmd)\n\t# Return value\n\treturn retval", "\n\ndef detect_system():\n\t'''\n\tTest if we are in a cluster or on a local machine\n\t'''\n\t# Start assuming we are on the local machine\n\tout = 'LOCAL' \n\t# 1. Test for SRUN, if so we are in a SLURM machine\n\t# and hence we should use SLURM to check the available nodes\n#\tif (run_subprocess('./','which','srun',check_return=False) == 0): out = 'SLURM'\n\t# Return system value\n\treturn out", "\n\ndef _slurm_generate_node_list(outfile,num_servers = os.getenv('SLURM_NNODES'),num_cores_server = os.getenv('SLURM_NTASKS_PER_CORE')):\n\t'''\n\tGenerate the list of nodes using slurm\n\t'''\n\t# Recover some information from SLURM environmental variables\n\thostlist = os.getenv('SLURM_JOB_NODELIST') # List of nodes used by the job\n\t# Perform some sanity checks\n\tif not len(hostlist) == num_servers: raise ValueError('Inconsistent number of nodes in SLURM or configuration!')\n\trun_subprocess('./','echo','\"%s\"'%hostlist,log=outfile)", "#\trun_subprocess('./','scontrol','show hostnames',log=outfile) \n\ndef _localhost_generate_node_list(outfile,num_servers):\n\t'''\n\tGenerate the list of nodes for a local run\n\t'''\n\thostlist = 'localhost'\n\tfor iserver in range(num_servers): hostlist += '\\nlocalhost'\n\t# Basically write localhost as the list of nodes\n\t# Add n+1 nodes as required per the nodelist\n\trun_subprocess('./','echo','\"%s\"'%hostlist,log=outfile)", "\ndef generate_node_list(outfile=NODELIST,num_servers=1):\n\t'''\n\tDetect the system and generate the node list\n\t'''\n\tsystem  = detect_system()\n\tif system == 'LOCAL': _localhost_generate_node_list(outfile,num_servers)\n\tif system == 'SLURM': _slurm_generate_node_list(outfile,num_servers)\n\ndef read_node_list(file=NODELIST):\n\t'''\n\tRead the list of nodes\n\t'''\n\tfp = open(file,'r')\n\tnodelist = [h.strip() for h in fp.readlines()]\n\tfp.close()\n\treturn nodelist", "\ndef read_node_list(file=NODELIST):\n\t'''\n\tRead the list of nodes\n\t'''\n\tfp = open(file,'r')\n\tnodelist = [h.strip() for h in fp.readlines()]\n\tfp.close()\n\treturn nodelist\n", ""]}
{"filename": "configuration.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# configuration.py: Path to the binaries used for the DRL tool\n#\n# Pol Suarez, Arnau Miro\n#\n# 29/09/2022\n", "# 29/09/2022\n\nfrom __future__ import print_function, division\n\nimport os\n\n\n## PATHS\n# Absolute path to the DRL directory\nDRL_PATH  = os.path.join(os.path.dirname(os.path.abspath(__file__)))", "# Absolute path to the DRL directory\nDRL_PATH  = os.path.join(os.path.dirname(os.path.abspath(__file__)))\n# Absolute path to the shenfun_files folder\nALYA_PATH = os.path.join(DRL_PATH,'shenfun_files')\n# Absolute path to the binaries folder\nBIN_PATH  = os.path.join(DRL_PATH,'shenfun_files','bin')\n\n\n## FILE NAMES\nNODELIST   = 'nodelist'", "## FILE NAMES\nNODELIST   = 'nodelist'\n\n"]}
{"filename": "Postprocess_routines/plotLearningCurve.py", "chunked_list": ["import numpy as np\nimport os, sys, time\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import (MultipleLocator)\nimport json\nfrom scipy.signal import savgol_filter\n\n'''\n", "'''\n\nThe following plots can be generated with this script, one at a time.\n \n1. Plots learning curve - instantaneous reward vs episode.\n2. Plots learning curve - instantaneous Nusselt number vs episode.\n3. Plots learning curve (Nu) from a single training episode (ep_no), along with the Nu from the baseine. Horizontal axis is time.\n4. Plots many learning curves (Nu) from diff episodes\n5. Plot of learning curves from SARL and MARL for comparison \n6. Plots learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time, along with the removing control ", "5. Plot of learning curves from SARL and MARL for comparison \n6. Plots learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time, along with the removing control \n7. Plots Nu after control is removed   \n\nYou can plot either one, by setting the 'cas' variable below to any index number above.\n\nAuthor: Joel Vasanth | FLOW, KTH Stockholm\n\nDate: 3/25/2023\n", "Date: 3/25/2023\n\n'''\n\n# Set which case to plot. See options above \ncas = 7\n\n# Set simulation name and path \nsimu_name = 'RB_2D_MARL' \ngeneral_path = os.getcwd()", "simu_name = 'RB_2D_MARL' \ngeneral_path = os.getcwd()\npath = general_path+'/../shenfun_files/cases/'+simu_name\nos.chdir(path)\nsys.path.append(path)\nfrom parameters import simulation_params, reward_function, optimization_params, nb_proc, nb_actuations, nb_actuations_deterministic, n_seg\n\n\n# Number of actions/actuations per episode\nnb_actions = 100  ", "# Number of actions/actuations per episode\nnb_actions = 100  \n\n# CFD time duration between two actuations\ndt = 1.5  \n\n# duration of the baseline simulation\nbaseline_t = 1000  \n\n# Amplitude of variation of T", "\n# Amplitude of variation of T\nampl = 0.75  \n\n# Number of segments \nnb_seg = 10\n\n# Number of pseudo-environments \nnb_envs = 10\n", "nb_envs = 10\n\n\n# Evolution of the reward obtained at the end of an episode, for all episodes, for all environments (list(R1, R2, R3,...))\ntotal_rewards = [] \n\nrewards_interEps = {}  \n\n# Evolution of the reward obtained at the end of an episode, for all episodes, for all environments (dictionary {env 1: , env2: ...})\ntotal_rewards_averaged = []", "# Evolution of the reward obtained at the end of an episode, for all episodes, for all environments (dictionary {env 1: , env2: ...})\ntotal_rewards_averaged = []\nrewards_interEps_averaged = {}\n\n# Evolution of the normalized actions during all the episodes, for all episodes, for all environment for all segment (actuator) (between [-1,+1])\nActions_interEnvs = {}  \n\n# Evolution of the actions during all the episodes, for all episodes, for all environment for all segment (actuator) (between [2-0.75,2+0.75])\nActions_unN_interEnvs = {}  \n", "Actions_unN_interEnvs = {}  \n\n# Evolution of the rewards during an episode, for all episodes, for all environment ({environment i: array([[R1_ep1, R2_ep1, ...], [R1_ep2, R2_ep2, ...]])})\nreward_in_ep = {}  \nNusselt_in_ep = {}  \n\n# the episodes we consider (num_episode, num_environment)\nepisodes = [(204,9), (234,6), (224, 2)]  \n\n# Episodes considered in the last figure (where we plot the evolution of the actions)", "\n# Episodes considered in the last figure (where we plot the evolution of the actions)\nepisodes_trace_action = [(1,1)]  \ncolors = ['red', 'blue', 'green', 'black']\n\nmax_ep = 1e8\nmax_ep_arr = []\n\n\n\nif (cas == 1):\n\n    ### PLOTS INSTANTANEOUS REWARD VS EPISODES\n    ## the inst. reward is the reward at the end of each episode, and averaged over all environments.\n    ## ------------------------------------\n\n    num_eps = 451 # number of episodes you want to plot\n\n    f = plt.figure()\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    for num_env in range (1,nb_envs+1):\n        os.chdir(path+'/final_rewards/environment'+str(num_env))\n        eps, rewards = [], []\n        \n        with open('output_final_rewards.csv', 'r') as f:\n            c = 0\n            for line in f:\n                if c == 0:\n                    c +=1\n                else:\n                    episode, reward = line.split(';')\n                    eps.append(int(episode))\n                    rewards.append(float(reward.strip('\\n')))\n                    c += 1 \n        \n        rewards_interEps.update({'env'+str(num_env):rewards})\n\n    lmm = np.zeros((num_eps,),dtype=np.float64)\n    print(\"No. of episodes printed: \", num_eps)\n\n    # averaging over no fo envs\n    for envno in range(1,nb_envs+1):\n        ar1 = np.array(rewards_interEps['env'+str(envno)])\n        lmm = lmm + ar1\n\n    lmm = lmm/float(nb_envs)\n    # plt.rcParams[\"figure.figsize\"] = (15,6)\n    plt.plot(lmm)\n    plt.xlabel('Episode')\n    plt.ylabel('Reward')\n    # plt.xlim(0,450)\n    # plt.ylim(-0.2,1)\n    #plt.show()\n    os.chdir(general_path+'/../shenfun_files/cases/')\n    plt.savefig('FR_1_LearningCurve_reward.png')\n\nelif (cas == 2):\n    ## PLOTS INSTANTANEOUS NUSSELT VS EPISODE\n    # the Nusselt is the value at the end of each episode, and averaged over all environments.\n    # ------------------------------------\n\n    numeps = 446\n    nusselts = []\n    for num_epis in range (1,numeps+1):\n        totalEnvNusselt = 0.0\n        for num_env in range (1,nb_envs+1):\n            os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(num_epis))\n            eps, rewards = [], []\n            with open('output_Nusselts.csv', 'r') as f:\n                for line in f:\n                    pass\n                last_line = line\n            actionNumber, envNusselt = last_line.split(';')\n            # nusselts.append(float(envNusselt.strip('\\n')))\n            totalEnvNusselt += float(envNusselt.strip('\\n'))\n        nusselts.append(totalEnvNusselt/float(num_env))\n\n\n    os.chdir(path+'/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:\n        Nusselt_baseline = json.load(f)\n    print(\"No. of episodes printed: \", num_epis)\n\n    baselineNusselt = np.array(Nusselt_baseline)\n    # xax_base = np.linspace(0,400,799)-400\n    xax_epis = np.arange(0,300, 1.5)\n    # print(len(nusselts))\n\n    # plt.rcParams[\"figure.figsize\"] = (15,6)\n    plt.plot(nusselts, lw = 1)\n    # plt.plot(xax_base, baselineNusselt)\n    plt.xlabel('Episode')\n    #plt.xlim(0,numeps)\n    # plt.grid()\n    plt.ylabel('$Nu$')\n    # plt.xlim(0,365)\n    # plt.ylim(1.8,3.0)\n    #plt.show()\n    os.chdir(general_path+'/../')\n    print(general_path)\n    plt.savefig('FR_2_LearningCurve.png')\n\nelif (cas == 3):\n    # PLOTS learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time.\n    f = plt.figure()\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    ep_no = 130\n    total_nusselts = np.zeros((nb_actions,))\n    for num_env in range(1,nb_envs+1):\n        print(num_env)\n        os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep_no))\n        nusselts = []\n        c = 0\n        with open('output_Nusselts.csv', 'r') as f:\n            for line in f:\n                if (c > 0):\n                    _ , envNusselt = line.split(';')\n                    nusselts.append(float(envNusselt.strip('\\n')))\n                c += 1\n        if (len(nusselts) != nb_actions):\n            print('Length of episode wrong')\n        total_nusselts += np.array(nusselts)\n\n    os.chdir(path+'/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:\n        Nusselt_baseline = json.load(f)\n\n    # print(len(Nusselt_baseline))\n    \n    x_bs = np.arange(1, baseline_t)-baseline_t\n    x_ep = np.arange(0,100)\n    print(np.size(x_ep))\n    print(len(total_nusselts))\n    x_ep_vid = np.arange(0,600,3)\n    x_join = [0.0, 1.5]\n    join_line = [Nusselt_baseline[-1], total_nusselts[0]]\n    plt.plot(x_bs,Nusselt_baseline, color='black', linewidth=1)\n    # plt.plot(x_join, join_line, lw = 1, color='black')\n    plt.plot(x_ep,total_nusselts/float(nb_envs), lw = 1, color= 'blue')\n    # nno = np.mean(total_nusselts[99:199])\n    # nno_line = [nno, nno, nno]\n    # rem_con = [2.0546285693099984,2.0546285693099984,2.0546285693099984]\n    # plt.plot([-100,0,300],nno_line,linewidth=0.8,linestyle='--', color='black', label='Actively controlled')\n    # plt.plot([-100,0,300],rem_con,linewidth=0.8,linestyle='--', color='red', label='Control Removed')\n    # x_pts = [0, 50, 100, 114, 116, 118, 135, 200]\n    # pts = [2.6785, 2.675, 2.587, 2.325, 2.2855, 2.3408, 2.5139, 1.9636]\n    # plt.scatter(x_pts,pts, lw = 1, color= 'red', marker='o')\n    # baseline_array = [2.675,2.675,2.675]\n    # plt.plot([-100,0,300],baseline_array,linewidth=0.8,linestyle='--', color='blue', label='Baseline')\n    # plt.axvspan(148.54, 300, color='0.8', alpha = 0.5)\n    # print(nno)\n    plt.xlabel('Time')\n    # plt.legend()\n    # plt.grid()\n    plt.xlim(-800,100)\n    # plt.ylim(1.78,3)\n    # plt.ylabel('$Nu$')\n    plt.show()\n    # os.chdir(general_path+'/../')\n    # plt.savefig('FR_8_mainEpisode.png')\n    \n\n\nelif (cas ==4):\n    # Plots many curves (Nu) from diff episodes\n    eps_nos = [45, 275, 357]\n    eps_nos_paper = [45,275,350]\n    colors = ['green', 'red', 'blue']\n    \n\n    def moving_averge(a, n):\n        mean_array = np.zeros((a.size-n+1,))\n        for i in range(a.size-n+1):\n            mean_array[i] = np.mean(a[i:i+n-1])\n        return mean_array\n\n    os.chdir(path+'/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:\n        Nusselt_baseline = json.load(f)\n    x_bs = np.arange(0, baseline_t-0.5,0.5) - 400\n    x_join = [-1,0]\n\n    f = plt.figure(figsize=(10,5))\n    plt.rcParams.update({'font.size': 15})\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    \n    n=0\n    for ep in eps_nos:\n        total_nusselts = np.zeros((nb_actions,))\n        for num_env in range(1,nb_envs+1):\n            os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep))\n            nusselts = []\n            c = 0\n            with open('output_Nusselts.csv', 'r') as f:\n                for line in f:\n                    if (c > 0):\n                        _ , envNusselt = line.split(';')\n                        nusselts.append(float(envNusselt.strip('\\n')))\n                    c += 1\n            if (len(nusselts) != nb_actions):\n                print('Length of episode wrong')\n            total_nusselts += np.array(nusselts)\n        \n        x_ep = np.arange(0,300,1.5)\n        # x_ep_vid = np.arange(0,600,3)\n        # plt.plot(x_bs,Nusselt_baseline)\n        plt.plot(x_ep,total_nusselts, lw = 0.5, color=colors[n],)\n        nusavg = moving_averge(total_nusselts,20)\n        x_avg = moving_averge(x_ep,20)\n        plt.plot(x_avg,nusavg,color=colors[n], lw = 1.4,  label='Episode '+str(eps_nos_paper[n]))\n        join_line = [Nusselt_baseline[-1], total_nusselts[0]]\n        plt.plot(x_join, join_line, lw = 0.3, color=colors[n])\n        n += 1\n    \n    \n    plt.plot(x_bs, Nusselt_baseline, color = 'black', lw = 1,label='Baseline')\n    baseline_array = [2.678,2.678,2.678]\n    plt.plot([0,150,350],baseline_array,linewidth=1.2,linestyle='--', color='black')\n    nno_line = [2.0546, 2.0546, 2.0546]\n    nno_line2 = [2.0496, 2.0496, 2.0496]\n    plt.plot([-50,0,400],nno_line,linewidth=1.2,linestyle='-.', color='black', label='Control Removed')\n    plt.plot([-50,0,400],nno_line2,linewidth=1.2,linestyle='--', color='blue', label='Actively Controlled')\n    plt.xlabel('Time')\n    plt.legend(fontsize=12, ncol=2)\n    # plt.grid()\n    plt.xlim(-50,300)\n    plt.ylim(1.75,3)\n    plt.ylabel('$Nu$')\n    # plt.show()\n    os.chdir(general_path+'/../')\n    print(general_path)\n    plt.savefig('FR_3_multipleEpisodeLearningCurve')\n\nelif (cas == 5): \n    # Plot of SARL vs MARL\n    simu_names = ['RB_2D_MARL_2pi_drl_3', 'RB_2D_SARL']  # RB_2D_MARL_2pi_drl_2 RB_2D_SARL\n    colors = ['0', '0.45']\n    labels = ['MARL', 'SARL']\n    ep_nos = [365, 500] # num of total episodes in MARL (first entry) and SARL (second entry)\n    si = 0\n\n    def moving_averge(a, n):\n        mean_array = np.zeros((a.size-n+1,))\n        for i in range(a.size-n+1):\n            mean_array[i] = np.mean(a[i:i+n-1])\n        return mean_array\n\n    f = plt.figure()\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    for simu_name in simu_names:\n        path = general_path+'/../shenfun_files/cases/'+simu_name\n        os.chdir(path)\n        sys.path.append(path)\n\n        numeps = ep_nos[0]\n        nusselts = []\n        \n        for num_epis in range (1,numeps+1):\n            totalEnvNusselt = 0.0\n            for num_env in range (1,nb_envs+1):\n                os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(num_epis))\n                eps, rewards = [], []\n                with open('output_Nusselts.csv', 'r') as f:\n                    for line in f:\n                        pass\n                    last_line = line\n                actionNumber, envNusselt = last_line.split(';')\n                # nusselts.append(float(envNusselt.strip('\\n')))\n                totalEnvNusselt += float(envNusselt.strip('\\n'))\n            nusselts.append(totalEnvNusselt/float(num_env))\n\n        # plt.rcParams[\"figure.figsize\"] = (15,6)\n        nusarr = np.array(nusselts)\n        nusavg = moving_averge(nusarr,25)\n        x = np.arange(1,365+1)\n        x_avg = moving_averge(x,25)\n        plt.plot(x, nusselts, lw = 0.5, linestyle='--', color = colors[si])\n        plt.plot(x_avg, nusavg, linewidth=1.5, color = colors[si], label=labels[si])\n        si += 1\n        # plt.plot(xax_base, baselineNusselt)\n    plt.xlabel('Episode')\n    baseline_array = [2.675,2.675,2.675]\n    nuc = 2.0546247073036668 # this is Nu of the controlled single RB cell, after the control has been removed\n    controlled_array = [nuc, nuc, nuc]\n    plt.plot([0,150,350],baseline_array,linewidth=2,linestyle='--', color='blue', label='Baseline')\n    plt.plot([0,150,350],controlled_array,linewidth=2,linestyle='--', color='black', label='Controlled')\n    #plt.xlim(0,numeps)\n    # plt.grid()\n    plt.ylabel('$Nu$')\n    plt.legend()\n    plt.xlim(0,350)\n    plt.ylim(1.8,3.0)\n    plt.show()\n    # os.chdir(general_path+'/../')\n    # plt.savefig('FR_4_MARLvsSARL.png')\n\nelif (cas == 6):\n    # Plots learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time, along with the removing control \n    f = plt.figure()\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    # ax.rcParams[\"figure.figsize\"] = (10,6)\n    plt.figure(figsize=(10,5))\n    plt.rcParams.update({'font.size': 15})\n\n    ep_no = 357 # in drl2\n    total_nusselts = np.zeros((nb_actions,))\n    for num_env in range(1,nb_envs+1):\n        os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep_no))\n        nusselts = []\n        c = 0\n        with open('output_Nusselts.csv', 'r') as f:\n            for line in f:\n                if (c > 0):\n                    _ , envNusselt = line.split(';')\n                    nusselts.append(float(envNusselt.strip('\\n')))\n                c += 1\n        if (len(nusselts) != nb_actions):\n            print('Length of episode wrong')\n        total_nusselts += np.array(nusselts)\n\n    os.chdir(path+'/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:\n        Nusselt_baseline = json.load(f)\n\n    os.chdir(general_path+'/../Postprocess_routines/drl3_ep357/removeControl/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:   \n        Nusselt_removeControl = json.load(f)\n\n    x_bs = np.arange(0, baseline_t-0.5,0.5)-baseline_t\n    x_ep = np.arange(1.5,300+1.5,1.5)\n    x_rc = np.arange(300+0.5,500,0.5)\n    print(\"Length 1:\", len(total_nusselts), len(x_rc))\n    x_ep_vid = np.arange(0,600,3)\n    x_join_bs = [0.0, 1.5]\n    join_line_bs = [Nusselt_baseline[-1], total_nusselts[0]]\n    x_join_rc = [300.0, 300.5]\n    join_line_rc = [total_nusselts[-1], Nusselt_removeControl[0]]\n    \n    plt.plot(x_bs,Nusselt_baseline, color='black', linewidth=1)\n    plt.plot(x_rc,Nusselt_removeControl, color='black', linewidth=1)\n    plt.plot(x_join_bs, join_line_bs, lw = 1, color='black')\n    plt.plot(x_join_rc, join_line_rc, lw = 1, color='black')\n    plt.plot(x_ep,total_nusselts, lw = 1, color= 'black')\n    nno = np.mean(total_nusselts[119:199])\n    nno_line = [nno, nno, nno]\n    print(nno)\n    print(Nusselt_removeControl[-1])\n    rem_con = [Nusselt_removeControl[-1],Nusselt_removeControl[-1],Nusselt_removeControl[-1]]\n    plt.plot([-50,0,400],nno_line,linewidth=0.8,linestyle='--', color='black', label='Actively controlled')\n    plt.plot([-50,0,400],rem_con,linewidth=0.8,linestyle='--', color='red', label='Control Removed')\n    x_pts = [51, 102, 114, 120, 123, 126, 141, 252]\n    pts = [total_nusselts[33], total_nusselts[67],total_nusselts[75],total_nusselts[79],total_nusselts[81], \\\n           total_nusselts[83],total_nusselts[93],total_nusselts[167]]\n    \n    baseline_array = [2.675,2.675,2.675]\n    plt.plot([-50,0,400],baseline_array,linewidth=0.8,linestyle='--', color='blue', label='Baseline')\n    plt.axvspan(0, 112, color='purple', alpha = 0.5)\n    plt.axvspan(112, 130, color='yellow', alpha = 0.5)\n    plt.axvspan(130, 300, color='green', alpha = 0.5)\n    plt.axvspan(300, 400, color='grey', alpha = 0.5)\n    plt.scatter(x_pts,pts, lw = 1, color= 'red', marker='o')\n    # print(nno)\n    plt.xlabel('Time')\n    plt.legend()\n    # plt.grid()\n    plt.xlim(-50,400)\n    plt.ylim(1.78,3)\n    plt.ylabel('$Nu$')\n    # plt.show()\n    # os.chdir(general_path+'/../')\n    # print(general_path)\n    # plt.savefig('FR_8_mainEpisode.png')\n\n\nelif (cas == 7):\n    # Plots Nu after control is removed\n\n    plt.rcParams.update({'font.size': 15})\n    f = plt.figure(figsize=(7,3))\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n\n    ep_no = 357 # in drl2\n\n    os.chdir(general_path+'/../Postprocess_routines/drl3_ep357/removeControl/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:   \n        Nusselt_removeControl = json.load(f)\n\n    x_rc = np.arange(300+0.5,500,0.5)\n    plt.plot(x_rc,Nusselt_removeControl, color='black', linewidth=1)    \n    plt.axvspan(300, 500, color='grey', alpha = 0.5)\n    # print(nno)\n    plt.tight_layout()\n    plt.xlabel('Time')\n    #plt.ylim(2,2.1)\n    plt.ylabel('$Nu$', labelpad=-1)\n    #plt.show()\n    os.chdir(general_path+'/../')\n    print(general_path)\n    plt.savefig('controlRemoved.png')", "\n\nif (cas == 1):\n\n    ### PLOTS INSTANTANEOUS REWARD VS EPISODES\n    ## the inst. reward is the reward at the end of each episode, and averaged over all environments.\n    ## ------------------------------------\n\n    num_eps = 451 # number of episodes you want to plot\n\n    f = plt.figure()\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    for num_env in range (1,nb_envs+1):\n        os.chdir(path+'/final_rewards/environment'+str(num_env))\n        eps, rewards = [], []\n        \n        with open('output_final_rewards.csv', 'r') as f:\n            c = 0\n            for line in f:\n                if c == 0:\n                    c +=1\n                else:\n                    episode, reward = line.split(';')\n                    eps.append(int(episode))\n                    rewards.append(float(reward.strip('\\n')))\n                    c += 1 \n        \n        rewards_interEps.update({'env'+str(num_env):rewards})\n\n    lmm = np.zeros((num_eps,),dtype=np.float64)\n    print(\"No. of episodes printed: \", num_eps)\n\n    # averaging over no fo envs\n    for envno in range(1,nb_envs+1):\n        ar1 = np.array(rewards_interEps['env'+str(envno)])\n        lmm = lmm + ar1\n\n    lmm = lmm/float(nb_envs)\n    # plt.rcParams[\"figure.figsize\"] = (15,6)\n    plt.plot(lmm)\n    plt.xlabel('Episode')\n    plt.ylabel('Reward')\n    # plt.xlim(0,450)\n    # plt.ylim(-0.2,1)\n    #plt.show()\n    os.chdir(general_path+'/../shenfun_files/cases/')\n    plt.savefig('FR_1_LearningCurve_reward.png')\n\nelif (cas == 2):\n    ## PLOTS INSTANTANEOUS NUSSELT VS EPISODE\n    # the Nusselt is the value at the end of each episode, and averaged over all environments.\n    # ------------------------------------\n\n    numeps = 446\n    nusselts = []\n    for num_epis in range (1,numeps+1):\n        totalEnvNusselt = 0.0\n        for num_env in range (1,nb_envs+1):\n            os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(num_epis))\n            eps, rewards = [], []\n            with open('output_Nusselts.csv', 'r') as f:\n                for line in f:\n                    pass\n                last_line = line\n            actionNumber, envNusselt = last_line.split(';')\n            # nusselts.append(float(envNusselt.strip('\\n')))\n            totalEnvNusselt += float(envNusselt.strip('\\n'))\n        nusselts.append(totalEnvNusselt/float(num_env))\n\n\n    os.chdir(path+'/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:\n        Nusselt_baseline = json.load(f)\n    print(\"No. of episodes printed: \", num_epis)\n\n    baselineNusselt = np.array(Nusselt_baseline)\n    # xax_base = np.linspace(0,400,799)-400\n    xax_epis = np.arange(0,300, 1.5)\n    # print(len(nusselts))\n\n    # plt.rcParams[\"figure.figsize\"] = (15,6)\n    plt.plot(nusselts, lw = 1)\n    # plt.plot(xax_base, baselineNusselt)\n    plt.xlabel('Episode')\n    #plt.xlim(0,numeps)\n    # plt.grid()\n    plt.ylabel('$Nu$')\n    # plt.xlim(0,365)\n    # plt.ylim(1.8,3.0)\n    #plt.show()\n    os.chdir(general_path+'/../')\n    print(general_path)\n    plt.savefig('FR_2_LearningCurve.png')\n\nelif (cas == 3):\n    # PLOTS learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time.\n    f = plt.figure()\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    ep_no = 130\n    total_nusselts = np.zeros((nb_actions,))\n    for num_env in range(1,nb_envs+1):\n        print(num_env)\n        os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep_no))\n        nusselts = []\n        c = 0\n        with open('output_Nusselts.csv', 'r') as f:\n            for line in f:\n                if (c > 0):\n                    _ , envNusselt = line.split(';')\n                    nusselts.append(float(envNusselt.strip('\\n')))\n                c += 1\n        if (len(nusselts) != nb_actions):\n            print('Length of episode wrong')\n        total_nusselts += np.array(nusselts)\n\n    os.chdir(path+'/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:\n        Nusselt_baseline = json.load(f)\n\n    # print(len(Nusselt_baseline))\n    \n    x_bs = np.arange(1, baseline_t)-baseline_t\n    x_ep = np.arange(0,100)\n    print(np.size(x_ep))\n    print(len(total_nusselts))\n    x_ep_vid = np.arange(0,600,3)\n    x_join = [0.0, 1.5]\n    join_line = [Nusselt_baseline[-1], total_nusselts[0]]\n    plt.plot(x_bs,Nusselt_baseline, color='black', linewidth=1)\n    # plt.plot(x_join, join_line, lw = 1, color='black')\n    plt.plot(x_ep,total_nusselts/float(nb_envs), lw = 1, color= 'blue')\n    # nno = np.mean(total_nusselts[99:199])\n    # nno_line = [nno, nno, nno]\n    # rem_con = [2.0546285693099984,2.0546285693099984,2.0546285693099984]\n    # plt.plot([-100,0,300],nno_line,linewidth=0.8,linestyle='--', color='black', label='Actively controlled')\n    # plt.plot([-100,0,300],rem_con,linewidth=0.8,linestyle='--', color='red', label='Control Removed')\n    # x_pts = [0, 50, 100, 114, 116, 118, 135, 200]\n    # pts = [2.6785, 2.675, 2.587, 2.325, 2.2855, 2.3408, 2.5139, 1.9636]\n    # plt.scatter(x_pts,pts, lw = 1, color= 'red', marker='o')\n    # baseline_array = [2.675,2.675,2.675]\n    # plt.plot([-100,0,300],baseline_array,linewidth=0.8,linestyle='--', color='blue', label='Baseline')\n    # plt.axvspan(148.54, 300, color='0.8', alpha = 0.5)\n    # print(nno)\n    plt.xlabel('Time')\n    # plt.legend()\n    # plt.grid()\n    plt.xlim(-800,100)\n    # plt.ylim(1.78,3)\n    # plt.ylabel('$Nu$')\n    plt.show()\n    # os.chdir(general_path+'/../')\n    # plt.savefig('FR_8_mainEpisode.png')\n    \n\n\nelif (cas ==4):\n    # Plots many curves (Nu) from diff episodes\n    eps_nos = [45, 275, 357]\n    eps_nos_paper = [45,275,350]\n    colors = ['green', 'red', 'blue']\n    \n\n    def moving_averge(a, n):\n        mean_array = np.zeros((a.size-n+1,))\n        for i in range(a.size-n+1):\n            mean_array[i] = np.mean(a[i:i+n-1])\n        return mean_array\n\n    os.chdir(path+'/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:\n        Nusselt_baseline = json.load(f)\n    x_bs = np.arange(0, baseline_t-0.5,0.5) - 400\n    x_join = [-1,0]\n\n    f = plt.figure(figsize=(10,5))\n    plt.rcParams.update({'font.size': 15})\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    \n    n=0\n    for ep in eps_nos:\n        total_nusselts = np.zeros((nb_actions,))\n        for num_env in range(1,nb_envs+1):\n            os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep))\n            nusselts = []\n            c = 0\n            with open('output_Nusselts.csv', 'r') as f:\n                for line in f:\n                    if (c > 0):\n                        _ , envNusselt = line.split(';')\n                        nusselts.append(float(envNusselt.strip('\\n')))\n                    c += 1\n            if (len(nusselts) != nb_actions):\n                print('Length of episode wrong')\n            total_nusselts += np.array(nusselts)\n        \n        x_ep = np.arange(0,300,1.5)\n        # x_ep_vid = np.arange(0,600,3)\n        # plt.plot(x_bs,Nusselt_baseline)\n        plt.plot(x_ep,total_nusselts, lw = 0.5, color=colors[n],)\n        nusavg = moving_averge(total_nusselts,20)\n        x_avg = moving_averge(x_ep,20)\n        plt.plot(x_avg,nusavg,color=colors[n], lw = 1.4,  label='Episode '+str(eps_nos_paper[n]))\n        join_line = [Nusselt_baseline[-1], total_nusselts[0]]\n        plt.plot(x_join, join_line, lw = 0.3, color=colors[n])\n        n += 1\n    \n    \n    plt.plot(x_bs, Nusselt_baseline, color = 'black', lw = 1,label='Baseline')\n    baseline_array = [2.678,2.678,2.678]\n    plt.plot([0,150,350],baseline_array,linewidth=1.2,linestyle='--', color='black')\n    nno_line = [2.0546, 2.0546, 2.0546]\n    nno_line2 = [2.0496, 2.0496, 2.0496]\n    plt.plot([-50,0,400],nno_line,linewidth=1.2,linestyle='-.', color='black', label='Control Removed')\n    plt.plot([-50,0,400],nno_line2,linewidth=1.2,linestyle='--', color='blue', label='Actively Controlled')\n    plt.xlabel('Time')\n    plt.legend(fontsize=12, ncol=2)\n    # plt.grid()\n    plt.xlim(-50,300)\n    plt.ylim(1.75,3)\n    plt.ylabel('$Nu$')\n    # plt.show()\n    os.chdir(general_path+'/../')\n    print(general_path)\n    plt.savefig('FR_3_multipleEpisodeLearningCurve')\n\nelif (cas == 5): \n    # Plot of SARL vs MARL\n    simu_names = ['RB_2D_MARL_2pi_drl_3', 'RB_2D_SARL']  # RB_2D_MARL_2pi_drl_2 RB_2D_SARL\n    colors = ['0', '0.45']\n    labels = ['MARL', 'SARL']\n    ep_nos = [365, 500] # num of total episodes in MARL (first entry) and SARL (second entry)\n    si = 0\n\n    def moving_averge(a, n):\n        mean_array = np.zeros((a.size-n+1,))\n        for i in range(a.size-n+1):\n            mean_array[i] = np.mean(a[i:i+n-1])\n        return mean_array\n\n    f = plt.figure()\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    for simu_name in simu_names:\n        path = general_path+'/../shenfun_files/cases/'+simu_name\n        os.chdir(path)\n        sys.path.append(path)\n\n        numeps = ep_nos[0]\n        nusselts = []\n        \n        for num_epis in range (1,numeps+1):\n            totalEnvNusselt = 0.0\n            for num_env in range (1,nb_envs+1):\n                os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(num_epis))\n                eps, rewards = [], []\n                with open('output_Nusselts.csv', 'r') as f:\n                    for line in f:\n                        pass\n                    last_line = line\n                actionNumber, envNusselt = last_line.split(';')\n                # nusselts.append(float(envNusselt.strip('\\n')))\n                totalEnvNusselt += float(envNusselt.strip('\\n'))\n            nusselts.append(totalEnvNusselt/float(num_env))\n\n        # plt.rcParams[\"figure.figsize\"] = (15,6)\n        nusarr = np.array(nusselts)\n        nusavg = moving_averge(nusarr,25)\n        x = np.arange(1,365+1)\n        x_avg = moving_averge(x,25)\n        plt.plot(x, nusselts, lw = 0.5, linestyle='--', color = colors[si])\n        plt.plot(x_avg, nusavg, linewidth=1.5, color = colors[si], label=labels[si])\n        si += 1\n        # plt.plot(xax_base, baselineNusselt)\n    plt.xlabel('Episode')\n    baseline_array = [2.675,2.675,2.675]\n    nuc = 2.0546247073036668 # this is Nu of the controlled single RB cell, after the control has been removed\n    controlled_array = [nuc, nuc, nuc]\n    plt.plot([0,150,350],baseline_array,linewidth=2,linestyle='--', color='blue', label='Baseline')\n    plt.plot([0,150,350],controlled_array,linewidth=2,linestyle='--', color='black', label='Controlled')\n    #plt.xlim(0,numeps)\n    # plt.grid()\n    plt.ylabel('$Nu$')\n    plt.legend()\n    plt.xlim(0,350)\n    plt.ylim(1.8,3.0)\n    plt.show()\n    # os.chdir(general_path+'/../')\n    # plt.savefig('FR_4_MARLvsSARL.png')\n\nelif (cas == 6):\n    # Plots learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time, along with the removing control \n    f = plt.figure()\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n    # ax.rcParams[\"figure.figsize\"] = (10,6)\n    plt.figure(figsize=(10,5))\n    plt.rcParams.update({'font.size': 15})\n\n    ep_no = 357 # in drl2\n    total_nusselts = np.zeros((nb_actions,))\n    for num_env in range(1,nb_envs+1):\n        os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep_no))\n        nusselts = []\n        c = 0\n        with open('output_Nusselts.csv', 'r') as f:\n            for line in f:\n                if (c > 0):\n                    _ , envNusselt = line.split(';')\n                    nusselts.append(float(envNusselt.strip('\\n')))\n                c += 1\n        if (len(nusselts) != nb_actions):\n            print('Length of episode wrong')\n        total_nusselts += np.array(nusselts)\n\n    os.chdir(path+'/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:\n        Nusselt_baseline = json.load(f)\n\n    os.chdir(general_path+'/../Postprocess_routines/drl3_ep357/removeControl/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:   \n        Nusselt_removeControl = json.load(f)\n\n    x_bs = np.arange(0, baseline_t-0.5,0.5)-baseline_t\n    x_ep = np.arange(1.5,300+1.5,1.5)\n    x_rc = np.arange(300+0.5,500,0.5)\n    print(\"Length 1:\", len(total_nusselts), len(x_rc))\n    x_ep_vid = np.arange(0,600,3)\n    x_join_bs = [0.0, 1.5]\n    join_line_bs = [Nusselt_baseline[-1], total_nusselts[0]]\n    x_join_rc = [300.0, 300.5]\n    join_line_rc = [total_nusselts[-1], Nusselt_removeControl[0]]\n    \n    plt.plot(x_bs,Nusselt_baseline, color='black', linewidth=1)\n    plt.plot(x_rc,Nusselt_removeControl, color='black', linewidth=1)\n    plt.plot(x_join_bs, join_line_bs, lw = 1, color='black')\n    plt.plot(x_join_rc, join_line_rc, lw = 1, color='black')\n    plt.plot(x_ep,total_nusselts, lw = 1, color= 'black')\n    nno = np.mean(total_nusselts[119:199])\n    nno_line = [nno, nno, nno]\n    print(nno)\n    print(Nusselt_removeControl[-1])\n    rem_con = [Nusselt_removeControl[-1],Nusselt_removeControl[-1],Nusselt_removeControl[-1]]\n    plt.plot([-50,0,400],nno_line,linewidth=0.8,linestyle='--', color='black', label='Actively controlled')\n    plt.plot([-50,0,400],rem_con,linewidth=0.8,linestyle='--', color='red', label='Control Removed')\n    x_pts = [51, 102, 114, 120, 123, 126, 141, 252]\n    pts = [total_nusselts[33], total_nusselts[67],total_nusselts[75],total_nusselts[79],total_nusselts[81], \\\n           total_nusselts[83],total_nusselts[93],total_nusselts[167]]\n    \n    baseline_array = [2.675,2.675,2.675]\n    plt.plot([-50,0,400],baseline_array,linewidth=0.8,linestyle='--', color='blue', label='Baseline')\n    plt.axvspan(0, 112, color='purple', alpha = 0.5)\n    plt.axvspan(112, 130, color='yellow', alpha = 0.5)\n    plt.axvspan(130, 300, color='green', alpha = 0.5)\n    plt.axvspan(300, 400, color='grey', alpha = 0.5)\n    plt.scatter(x_pts,pts, lw = 1, color= 'red', marker='o')\n    # print(nno)\n    plt.xlabel('Time')\n    plt.legend()\n    # plt.grid()\n    plt.xlim(-50,400)\n    plt.ylim(1.78,3)\n    plt.ylabel('$Nu$')\n    # plt.show()\n    # os.chdir(general_path+'/../')\n    # print(general_path)\n    # plt.savefig('FR_8_mainEpisode.png')\n\n\nelif (cas == 7):\n    # Plots Nu after control is removed\n\n    plt.rcParams.update({'font.size': 15})\n    f = plt.figure(figsize=(7,3))\n    ax = f.add_subplot(111)\n    ax.tick_params(direction=\"in\")\n    ax.yaxis.set_ticks_position('both')\n\n    ep_no = 357 # in drl2\n\n    os.chdir(general_path+'/../Postprocess_routines/drl3_ep357/removeControl/baseline/')    \n    with open('evo_Nusselt_baseline.json', 'r') as f:   \n        Nusselt_removeControl = json.load(f)\n\n    x_rc = np.arange(300+0.5,500,0.5)\n    plt.plot(x_rc,Nusselt_removeControl, color='black', linewidth=1)    \n    plt.axvspan(300, 500, color='grey', alpha = 0.5)\n    # print(nno)\n    plt.tight_layout()\n    plt.xlabel('Time')\n    #plt.ylim(2,2.1)\n    plt.ylabel('$Nu$', labelpad=-1)\n    #plt.show()\n    os.chdir(general_path+'/../')\n    print(general_path)\n    plt.savefig('controlRemoved.png')", ""]}
{"filename": "Postprocess_routines/plotBaselines.py", "chunked_list": ["import numpy as np\nimport os, sys, time\nimport matplotlib.pyplot as plt\nimport json\n\n\n'''\nThis script plots the baseline Nu and KE over the time of the baseline simulation.\n\nAuthor: Joel Vasanth", "\nAuthor: Joel Vasanth\n\nDate: 3/20/2023\n\n'''\n\n# Set case\nsimu_name = 'RB_3D_MARL_01'  \ngeneral_path = os.getcwd()", "simu_name = 'RB_3D_MARL_01'  \ngeneral_path = os.getcwd()\npath = general_path+'/../shenfun_files/cases/'+simu_name\nos.chdir(path)\n\n\n# Set parameters\nbaseline_t = 400  # duration baseline simulation\nampl = 0.75  # Amplitude of variation of T\nnb_parr_envs = 1  # number of parallel environments", "ampl = 0.75  # Amplitude of variation of T\nnb_parr_envs = 1  # number of parallel environments\nnb_seg = 10 # number of segments\n\n\nMARL = True\nif MARL:\n    nb_envs = nb_parr_envs*nb_seg\nelse:\n    nb_envs = nb_parr_envs", "\nreward_function = 'Nusselt'  # choose 'Nusselt' or 'kinEn'\n\n\nos.chdir(path+'/baseline/')    \nwith open('evo_Nusselt_baseline.json', 'r') as f:\n    Nusselt_baseline = json.load(f)\nwith open('evo_kinEn_baseline.json', 'r') as f2:\n    kinEn_baseline = json.load(f2)\n", "\n# Time of simulation. 0.5 here is the dt, can be changed.\ntimerange = np.arange(0.5,baseline_t,0.5)\n\n# Perform plotting \nfig, ax = plt.subplots()\np1 = ax.plot(Nusselt_baseline, 'b-', label='Nusselt Number')\nax2 = ax.twinx()\np2 = ax2.plot(kinEn_baseline, 'r-', label='Kinetic Energy')\nallp = p1+p2", "p2 = ax2.plot(kinEn_baseline, 'r-', label='Kinetic Energy')\nallp = p1+p2\nlabs = [p.get_label() for p in allp]\nax.legend(allp, labs, loc = 4)\nax.set_xlabel('Time')\nax.set_ylabel('Nusselt Number', color='b')\nax2.set_ylabel('Kinetic Energy', color='r')\n# plt.grid()\nsavepath = general_path+'/../baseline3D.png'\nprint(savepath)", "savepath = general_path+'/../baseline3D.png'\nprint(savepath)\nplt.savefig(savepath)\n# plt.show()\n"]}
{"filename": "Postprocess_routines/ChannelFlow2D.py", "chunked_list": ["from warnings import WarningMessage\nfrom shenfun import *\nnp.warnings.filterwarnings('ignore')\n\nclass KMM:\n    \"\"\"Navier Stokes channel flow solver in 2D\n\n    The wall normal direction is along the x-axis, the streamwise along the y-axis.\n\n    The solver is fully spectral with Chebyshev (or Legendre) in the wall-normal\n    direction and Fourier in the other.\n\n    Using the equations described by Kim, Moser, Moin (https://doi.org/10.1017/S0022112087000892)\n    but with the spectral Galerkin method in space and a chosen time stepper.\n\n    Parameters\n    ----------\n    N : 2-tuple of ints\n        The global shape in physical space (quadrature points)\n    domain : 2-tuple of 2-tuples\n        The size of the three domains\n    nu : Viscosity coefficient\n    dt : Timestep\n    conv : Choose convection method\n        - 0 - Standard convection\n        - 1 - Vortex type\n    filename : str, optional\n        Filenames are started with this name\n    family : str, optional\n        Chebyshev is normal, but Legendre works as well\n    padding_factor : 2-tuple of numbers, optional\n        For dealiasing, backward transforms to real space are\n        padded with zeros in spectral space using these many points\n    modplot : int, optional\n        Plot some results every modplot timestep. If negative, no plotting\n    modsave : int, optional\n        Save results to hdf5 every modsave timestep.\n    moderror : int, optional\n        Print diagnostics every moderror timestep\n    checkpoint : int, optional\n        Save required data for restart to hdf5 every checkpoint timestep.\n    timestepper : str, optional\n        Choose timestepper\n\n    Note\n    ----\n    Simulations may be killed gracefully by placing a file named 'killshenfun'\n    in the folder running the solver from. The solver will then first store\n    the results by checkpointing, before exiting.\n\n    \"\"\"\n    def __init__(self,\n                 N=(32, 32),\n                 domain=((-1, 1), (0, 2*np.pi)),\n                 nu=0.01,\n                 dt=0.1,\n                 conv=0,\n                 dpdy=1,\n                 filename='KMM',\n                 family='C',\n                 padding_factor=(1, 1.5),\n                 modplot=100,\n                 modsave=1e8,\n                 moderror=100,\n                 checkpoint=1000,\n                 timestepper='IMEXRK3'):\n        self.N = N\n        self.nu = nu\n        self.dt = dt\n        self.conv = conv\n        self.modplot = modplot\n        self.modsave = modsave\n        self.moderror = moderror\n        self.filename = filename\n        self.padding_factor = padding_factor\n        self.dpdy = dpdy\n        self.PDE = PDE = globals().get(timestepper)\n        self.im1 = None\n\n        # Regular spaces\n        self.B0 = FunctionSpace(N[0], family, bc=(0, 0, 0, 0), domain=domain[0])\n        self.D0 = FunctionSpace(N[0], family, bc=(0, 0), domain=domain[0])\n        self.C0 = FunctionSpace(N[0], family, domain=domain[0])\n        self.F1 = FunctionSpace(N[1], 'F', dtype='d', domain=domain[1])\n        self.D00 = FunctionSpace(N[0], family, bc=(0, 0), domain=domain[0])  # Streamwise velocity, not to be in tensorproductspace\n        self.C00 = self.D00.get_orthogonal()\n\n        # Regular tensor product spaces\n        self.TB = TensorProductSpace(comm, (self.B0, self.F1), modify_spaces_inplace=True) # Wall-normal velocity\n        self.TD = TensorProductSpace(comm, (self.D0, self.F1), modify_spaces_inplace=True) # Streamwise velocity\n        self.TC = TensorProductSpace(comm, (self.C0, self.F1), modify_spaces_inplace=True) # No bc\n        self.BD = VectorSpace([self.TB, self.TD])  # Velocity vector space\n        self.CD = VectorSpace(self.TD)             # Dirichlet vector space\n\n        # Padded space for dealiasing\n        self.TDp = self.TD.get_dealiased(padding_factor)\n\n        self.u_ = Function(self.BD)      # Velocity vector solution\n        self.H_ = Function(self.CD)      # convection\n        self.ub = Array(self.BD)\n\n        self.v00 = Function(self.D00)   # For solving 1D problem for Fourier wavenumber 0, 0\n        self.w00 = Function(self.D00)\n\n        self.work = CachedArrayDict()\n        self.mask = self.TB.get_mask_nyquist() # Used to set the Nyquist frequency to zero\n        self.X = self.TD.local_mesh(bcast=True)\n        self.K = self.TD.local_wavenumbers(scaled=True)\n\n        # Classes for fast projections. All are not used except if self.conv=0\n        self.dudx = Project(Dx(self.u_[0], 0, 1), self.TD)\n        if self.conv == 0:\n            self.dudy = Project(Dx(self.u_[0], 1, 1), self.TB)\n            self.dvdx = Project(Dx(self.u_[1], 0, 1), self.TC)\n            self.dvdy = Project(Dx(self.u_[1], 1, 1), self.TD)\n\n        self.curl = Project(curl(self.u_), self.TC)\n        self.divu = Project(div(self.u_), self.TC)\n        self.solP = None # For computing pressure\n\n        # File for storing the results\n        self.file_u = ShenfunFile('_'.join((filename, 'U')), self.BD, backend='hdf5', mode='w', mesh='uniform')\n\n        # Create a checkpoint file used to restart simulations\n        self.checkpoint = Checkpoint(filename,\n                                     checkevery=checkpoint,\n                                     data={'0': {'U': [self.u_]}})\n\n        # set up equations\n        v = TestFunction(self.TB)\n\n        # Chebyshev matrices are not sparse, so need a tailored solver. Legendre has simply 5 nonzero diagonals and can use generic solvers.\n        sol1 = chebyshev.la.Biharmonic if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\n        self.pdes = {\n\n            'u': PDE(v,                                   # test function\n                     div(grad(self.u_[0])),               # u\n                     lambda f: self.nu*div(grad(f)),      # linear operator on u\n                     Dx(Dx(self.H_[1], 0, 1), 1, 1)-Dx(self.H_[0], 1, 2),\n                     dt=self.dt,\n                     solver=sol1,\n                     latex=r\"\\frac{\\partial \\nabla^2 u}{\\partial t} = \\nu \\nabla^4 u + \\frac{\\partial^2 N_y}{\\partial x \\partial y} - \\frac{\\partial^2 N_x}{\\partial y^2}\"),\n\n        }\n\n        # v. Solve divergence constraint for all wavenumbers except 0\n        r\"\"\":math:`\\nabla \\cdot \\vec{u} = 0`\"\"\"\n\n        # v. Momentum equation for Fourier wavenumber 0\n        if comm.Get_rank() == 0:\n            v0 = TestFunction(self.D00)\n            self.h1 = Function(self.D00)  # Copy from H_[1, :, 0, 0] (cannot use view since not contiguous)\n            source = Array(self.C00)\n            source[:] = -self.dpdy        # dpdy set by subclass\n            sol = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.Solver\n            self.pdes1d = {\n                'v0': PDE(v0,\n                          self.v00,\n                          lambda f: self.nu*div(grad(f)),\n                          [-Expr(self.h1), source],\n                          dt=self.dt,\n                          solver=sol,\n                          latex=r\"\\frac{\\partial v}{\\partial t} = \\nu \\frac{\\partial^2 v}{\\partial x^2} - N_y - \\frac{\\partial p}{\\partial y}\"),\n            }\n            \n\n    def convection(self):\n        H = self.H_.v\n        self.up = self.u_.backward(padding_factor=self.padding_factor)\n        up = self.up.v\n        if self.conv == 0:\n            dudxp = self.dudx().backward(padding_factor=self.padding_factor).v\n            dudyp = self.dudy().backward(padding_factor=self.padding_factor).v\n            dvdxp = self.dvdx().backward(padding_factor=self.padding_factor).v\n            dvdyp = self.dvdy().backward(padding_factor=self.padding_factor).v\n            H[0] = self.TDp.forward(up[0]*dudxp+up[1]*dudyp, H[0])\n            H[1] = self.TDp.forward(up[0]*dvdxp+up[1]*dvdyp, H[1])\n\n        elif self.conv == 1:\n            curl = self.curl().backward(padding_factor=self.padding_factor)\n            H[0] = self.TDp.forward(-curl*up[1])\n            H[1] = self.TDp.forward(curl*up[0])\n        self.H_.mask_nyquist(self.mask)\n\n    def compute_v(self, rk):\n        u = self.u_.v\n        if comm.Get_rank() == 0:\n            self.v00[:] = u[1, :, 0].real\n            self.h1[:] = self.H_[1, :, 0].real\n\n        # Find velocity components v from div. constraint\n        u[1] = 1j*self.dudx()/self.K[1]\n\n        # Still have to compute for wavenumber = 0, 0\n        if comm.Get_rank() == 0:\n            # v component\n            self.pdes1d['v0'].compute_rhs(rk)\n            u[1, :, 0] = self.pdes1d['v0'].solve_step(rk)\n\n        return u\n\n    def compute_pressure(self):\n        if self.solP is None:\n            self.d2udx2 = Project(self.nu*Dx(self.u_[0], 0, 2), self.TC)\n            N0 = self.N0 = FunctionSpace(self.N[0], self.B0.family(), bc={'left': {'N': self.d2udx2()}, 'right': {'N': self.d2udx2()}})\n            TN = self.TN = TensorProductSpace(comm, (N0, self.F1), modify_spaces_inplace=True)\n            sol = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n            self.divH = Inner(TestFunction(TN), -div(self.H_))\n            self.solP = sol(inner(TestFunction(TN), div(grad(TrialFunction(TN)))))\n            self.p_ = Function(TN)\n\n        self.d2udx2()\n        self.N0.bc.set_tensor_bcs(self.N0, self.TN)\n        p_ = self.solP(self.divH(), self.p_, constraints=((0, 0),))\n        return p_\n\n    def print_energy_and_divergence(self, t, tstep):\n        if tstep % self.moderror == 0 and self.moderror > 0:\n            ub = self.u_.backward(self.ub)\n            e0 = inner(1, ub[0]*ub[0])\n            e1 = inner(1, ub[1]*ub[1])\n            divu = self.divu().backward()\n            e3 = np.sqrt(inner(1, divu*divu))\n            if comm.Get_rank() == 0:\n                print(\"Time %2.5f Energy %2.6e %2.6e div %2.6e\" %(t, e0, e1, e3))\n\n    def init_from_checkpoint(self):\n        self.checkpoint.read(self.u_, 'U', step=0)\n        self.checkpoint.open()\n        tstep = self.checkpoint.f.attrs['tstep']\n        t = self.checkpoint.f.attrs['t']\n        self.checkpoint.close()\n        return t, tstep\n\n    def initialize(self, from_checkpoint=False):\n        if from_checkpoint:\n            return self.init_from_checkpoint()\n        raise RuntimeError('Initialize solver in subclass')\n\n    def plot(self, t, tstep):\n        pass\n\n    def update(self, t, tstep):\n        self.plot(t, tstep)\n        self.print_energy_and_divergence(t, tstep)\n\n    def tofile(self, tstep):\n        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n\n    def prepare_step(self, rk):\n        self.convection()\n\n    def assemble(self):\n        for pde in self.pdes.values():\n            pde.assemble()\n        if comm.Get_rank() == 0:\n            for pde in self.pdes1d.values():\n                pde.assemble()\n\n    def solve(self, t=0, tstep=0, end_time=1000):\n        self.assemble()\n        while t < end_time-1e-8:\n            for rk in range(self.PDE.steps()):\n                self.prepare_step(rk)\n                for eq in self.pdes.values():\n                    eq.compute_rhs(rk)\n                for eq in self.pdes.values():\n                    eq.solve_step(rk)\n                self.compute_v(rk)\n            t += self.dt\n            tstep += 1\n            self.update(t, tstep)\n            self.checkpoint.update(t, tstep)\n            if tstep % self.modsave == 0:\n                self.tofile(tstep)", ""]}
{"filename": "Postprocess_routines/VisualizeSol.py", "chunked_list": ["from shenfun import *\nfrom ChannelFlow2D import KMM\nimport matplotlib.pyplot as plt\nimport sympy\nfrom Tfunc import Tfunc\nfrom mpi4py_fft import generate_xdmf\nimport numpy as np\n\n'''\nVisualizeSol.py: Script aimed at visualizing the control sequence of a given episode", "'''\nVisualizeSol.py: Script aimed at visualizing the control sequence of a given episode\n\nAuthor: Colin Vignon | FLOW, KTH Stockholm\n\nDate: 3/25/2023\n\nSet parameters in the __main__ function, as desired.\n\n'''", "\n'''\n\nnp.warnings.filterwarnings('ignore')\nx, y, tt = sympy.symbols('x,y,t', real=True)\ncomm = MPI.COMM_WORLD\n\nclass RayleighBenard(KMM):\n\n    def __init__(self,\n                 N=(64, 96),\n                 domain=((-1, 1), (0, 2*sympy.pi)),\n                 Ra=10000.,\n                 Pr=0.7,\n                 dt=0.05,\n                 bcT=(2, 1),\n                 conv=0,\n                 filename='RB',\n                 family='C',\n                 padding_factor=(1, 1.5),\n                 modplot=10,\n                 modsave=1e8,\n                 moderror=10,\n                 checkpoint=10,\n                 timestepper='IMEXRK3'):\n        KMM.__init__(self, N=N, domain=domain, nu=np.sqrt(Pr/Ra), dt=dt, conv=conv,\n                     filename=filename, family=family, padding_factor=padding_factor,\n                     modplot=modplot, modsave=modsave, moderror=moderror,\n                     checkpoint=checkpoint, timestepper=timestepper, dpdy=0)\n        self.kappa = 1./np.sqrt(Pr*Ra)\n        self.bcT = bcT\n        plt.close('all')\n        # Additional spaces and functions for Temperature equation\n        self.T0 = FunctionSpace(N[0], family, bc=bcT, domain=domain[0])\n        self.TT = TensorProductSpace(comm, (self.T0, self.F1), modify_spaces_inplace=True) # Temperature\n        self.uT_ = Function(self.BD)     # Velocity vector times T\n        self.T_ = Function(self.TT)      # Temperature solution\n        self.Tb = Array(self.TT)\n        \n        self.file_T = ShenfunFile('_'.join((filename, 'T')), self.TT, backend='hdf5', mode='w', mesh='uniform')\n\n        # Modify checkpoint file\n        self.checkpoint.data['0']['T'] = [self.T_]\n\n        dt = self.dt\n        kappa = self.kappa\n\n        # Chebyshev matrices are not sparse, so need a tailored solver. Legendre has simply 5 nonzero diagonals\n        sol2 = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\n        # Addition to u equation.\n        self.pdes['u'].N = [self.pdes['u'].N, Dx(self.T_, 1, 2)]\n        self.pdes['u'].latex += r'\\frac{\\partial^2 T}{\\partial y^2}'\n\n        # Remove constant pressure gradient from v0 equation\n        self.pdes1d['v0'].N = self.pdes1d['v0'].N[0]\n\n        # Add T equation\n        q = TestFunction(self.TT)\n        self.pdes['T'] = self.PDE(q,\n                                  self.T_,\n                                  lambda f: kappa*div(grad(f)),\n                                  -div(self.uT_),\n                                  dt=self.dt,\n                                  solver=sol2,\n                                  latex=r\"\\frac{\\partial T}{\\partial t} = \\kappa \\nabla^2 T - \\nabla \\cdot \\vec{u}T\")\n\n        self.im1 = None\n        self.im2 = None\n\n        \n\t# Observation outputs\n        self.out = []\n        self.out2 = []\n        self.instant_Nusselt = []\n        \n        # Others\n        self.obsGrid = (8,32)\n        self.Nstep = (N[0]//self.obsGrid[0], N[1]//self.obsGrid[1])\n        \n\n    def update_bc(self, t):\n        # Update time-dependent bcs.\n        self.T0.bc.update(t)\n        self.T_.get_dealiased_space(self.padding_factor).bases[0].bc.update(t)\n\n    def prepare_step(self, rk):\n        self.convection()\n        Tp = self.T_.backward(padding_factor=self.padding_factor)\n        self.uT_ = self.up.function_space().forward(self.up*Tp, self.uT_)\n\n    def tofile(self, tstep):\n        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n        self.file_T.write(tstep, {'T': [self.T_.backward(mesh='uniform')]})\n\n    def init_from_checkpoint(self):\n        self.checkpoint.read(self.u_, 'U', step=0)\n        self.checkpoint.read(self.T_, 'T', step=0)\n        self.checkpoint.open()\n        tstep = self.checkpoint.f.attrs['tstep']\n        t = self.checkpoint.f.attrs['t']\n        self.checkpoint.close()\n        return t, tstep\n\n    def print_energy_and_divergence(self, t, tstep):\n        if tstep % self.moderror == 0 and self.moderror > 0:\n            ub = self.u_.backward(self.ub)\n            Tb = self.T_.backward(self.Tb)\n            e0 = inner(1, ub[0]*ub[0])\n            e1 = inner(1, ub[1]*ub[1])\n            d0 = inner(1, Tb*Tb)\n            divu = self.divu().backward()\n            e3 = np.sqrt(inner(1, divu*divu))\n            if comm.Get_rank() == 0:\n                if tstep % (10*self.moderror) == 0 or tstep == 0:\n                    print(f\"{'Time':^11}{'uu':^11}{'vv':^11}{'T*T':^11}{'div':^11}\")\n                print(f\"{t:2.4e} {e0:2.4e} {e1:2.4e} {d0:2.4e} {e3:2.4e}\")\n\n    def initialize(self, rand=0.001, from_checkpoint=False):\n        if from_checkpoint:\n            self.checkpoint.read(self.u_, 'U', step=0)\n            self.checkpoint.read(self.T_, 'T', step=0)\n            self.checkpoint.open()\n            tstep = self.checkpoint.f.attrs['tstep']\n            t = self.checkpoint.f.attrs['t']\n            self.checkpoint.close()\n            self.update_bc(t)\n            return t, tstep\n\n        X = self.X\n        fun = self.bcT[0]\n        self.Tb[:] = 0.5*(1 + 0.5*self.bcT[1]-X[0]/(1+self.bcT[1])+ 0.125*(2-self.bcT[1])*np.sin(np.pi*X[0]))*fun + rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n\n        self.T_ = self.Tb.forward(self.T_)\n        self.T_.mask_nyquist(self.mask)\n        return 0, 0\n                \n                \n    def outputs(self, tstep):\n    \tif tstep == 0:  \n            self.out = []\n            self.out2 = []\n    \telse:  \n            new_out = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n            ub = self.u_.backward(self.ub)\n            Tb = self.T_.backward(self.Tb)\n            new_out[0] = ub[1, ::self.Nstep[0], ::self.Nstep[1]]  # horizontal speed\n            new_out[1] = ub[0, ::self.Nstep[0], ::self.Nstep[1]]  # vertical speed\n            new_out[2] = Tb[::self.Nstep[0], ::self.Nstep[1]]\n            self.out.append(new_out)\n            new_out2 = new_out.reshape(3*self.obsGrid[0]*self.obsGrid[1],)\n            self.out2.append(new_out2)\n\n    def DRL_inputs(self, D = 4):  # inputs for the DRL algo\n\n        return self.out2[-1]\n\n    def compute_Nusselt(self):\n\n        div = self.kappa*(1/2)\n        uyT_ = np.mean(np.mean(np.multiply(self.out[-1][1], self.out[-1][2]), axis=1), axis = 0)\n        T_ = np.mean(np.gradient(np.mean(self.out[-1][2], axis=1), axis=0))\n        return (uyT_ - self.kappa*T_)/div\n\n    \n    \n    def evolve(self, new_bcT, t_ini=None, tstep_ini = None):\n    \n        self.bcT = new_bcT    \n        new_t, new_tstep = t_ini, tstep_ini\n        self.T0.bc.bc['left']['D'] = self.bcT[0]\n        self.T0.bc.update()\n        self.T0.bc.set_tensor_bcs(self.T0, self.T0.tensorproductspace)\n        TP0 = self.T_.get_dealiased_space(self.padding_factor).bases[0]\n        TP0.bc.bc['left']['D'] = self.bcT[0]\n        TP0.bc.update()\n        TP0.bc.set_tensor_bcs(TP0, TP0.tensorproductspace)\n        \n        \n    def solve(self, t=0, tstep=0, end_time=10000):\n        c = self.pdes['u'].stages()[2]\n        self.assemble()\n        while t < end_time-1e-8:\n            for rk in range(self.PDE.steps()):\n                self.prepare_step(rk)\n                for eq in ['u', 'T']:\n                    self.pdes[eq].compute_rhs(rk)\n                for eq in ['u']:\n                    self.pdes[eq].solve_step(rk)\n                self.compute_v(rk)\n                self.update_bc(t+self.dt*c[rk+1]) # modify time-dep boundary condition\n                self.pdes['T'].solve_step(rk)\n            self.outputs(tstep)\n            if tstep >= 1:\n                self.instant_Nusselt.append(self.compute_Nusselt())\n            t += self.dt\n            tstep += 1\n            self.update(t, tstep)\n            self.checkpoint.update(t, tstep)\n            if tstep % self.modsave == 0:\n                self.tofile(tstep)\n        return t, tstep", "\nif __name__ == '__main__':\n    from time import time\n    import csv\n    import os\n    \n    # Set parameters here, as desired\n    nb_actions = 200  \n    duration_baseline = 400.0\n    duration_action = 1.5\n    simu_name = 'RB_2D_SARL'\n    num_ep = 20 # Which episode to visualise\n    nb_segs = 10\n    name = 'output_actions.csv'\n    \n    # Set paths here\n    general_path = '/scratch/jvasanth/2022_Rayleigh_Benard_Control_DRL_Shenfun_2D_3D/shenfun_files/cases/'+simu_name\n    specific_path = general_path+'/actions/environment1/ep_'+str(num_ep)+'/'\n    move_path = general_path+'/CFD_n1/EP_'+str(num_ep)+'/'\n    \n    dicTemps = {}  # dictionary with the nb_actions successive boundary conditions\n    with open(specific_path+name, 'r') as f:\n        reader = csv.reader(f, delimiter=';')\n        line = next(reader)\n        for i in range(nb_actions):\n            line = next(reader)\n            dicTi = {}\n\n            dicTi.update({'T'+str(k):float(line[k+1]) for k in range(nb_segs)})\n            dicTemps.update({'Action_'+str(i):dicTi})\n\n    os.system('cp '+general_path+'/baseline/*.h5 /scratch/jvasanth/2022_Rayleigh_Benard_Control_DRL_Shenfun_2D_3D/Postprocess_routines/')\n    os.chdir('/scratch/jvasanth/2022_Rayleigh_Benard_Control_DRL_Shenfun_2D_3D/Postprocess_routines/')\n\n    for i in range(nb_actions):\t\n        N = (64, 96)\n        d = {\n            'N': N,\n            'Ra': 10000.,\n            'Pr': 0.7,\n            'dt': 0.05,\n            'filename': f'RB_{N[0]}_{N[1]}',\n            'conv': 0,\n            'modplot': 10,\n            'moderror': 10,\n            'modsave': 10,\n            'bcT': (Tfunc(nb_seg=nb_segs, dicTemp=dicTemps.get('Action_'+str(i))).apply_T(y), 1),\n            'family': 'C',\n            'checkpoint': 10,\n            'timestepper': 'IMEXRK3'\n            }\n        if i == 0:\n            c = RayleighBenard(**d)\n            t, tstep = c.initialize(rand=0.001, from_checkpoint=True)\n            t0 = time()\n            new_t, new_tstep = c.solve(t=t, tstep=tstep, end_time=duration_baseline + (i+1)*duration_action)\n            print('Computing time %2.4f'%(time()-t0))\n        else:\n            c.evolve(d.get('bcT'), t_ini=new_t, tstep_ini = new_tstep)\n            new_t, new_tstep = c.solve(t=new_t, tstep=new_tstep, end_time=duration_baseline + (i+1)*duration_action)\n\n        plt.close('all')\n\n    # Produces the visualisation of Temperature and velocity. \n    generate_xdmf('RB_'+str(N[0])+'_'+str(N[1])+'_T.h5')\n    generate_xdmf('RB_'+str(N[0])+'_'+str(N[1])+'_U.h5')", "\n\n"]}
{"filename": "Postprocess_routines/Tfunc.py", "chunked_list": ["from shenfun import *\nimport sympy\nfrom sympy.parsing.sympy_parser import parse_expr\n\n'''\n\nTfunc.py: script needed for the postprocess routines, that generates bounday conditions\n\nAuthor: Colin Vignon | FLOW, KTH Stockholm\n", "Author: Colin Vignon | FLOW, KTH Stockholm\n\nDate: 3/25/2023\n\n'''\n\n# IMPORTANT: redefine the domain here\ndomain = ((-1, 1), (0, 2*sympy.pi))\n\nclass Tfunc():\n\n\tdef __init__(self, nb_seg = None, dicTemp = None):\n\t\t''' N = number of actuators/segments on the hot boundary layer\n\t\tdicTemp = temperature variations of the segments: Ti' = Tnormal + Ti, Tnormal = 0.6 here''' \n\t\n\t\tself.nb_seg = nb_seg\n\t\tself.dicTemp = dicTemp\n\t\tself.ampl = 0.75  # Amplitude of variation of T\n\t\tself.dx = 0.03  # half-length of the interval on which we do the smoothing\n\t\t#self.length = length  # length of the domain\n\t\t\n\t\t\n\tdef apply_T(self, x):\n\t\tvalues = self.ampl*np.array(list(self.dicTemp.values()))\n\t\tMean = values.mean()\n\t\tK2 = max(1, np.abs(values-np.array([Mean]*self.nb_seg)).max()/self.ampl)\n\t\t\n\t\t# Position:\n\t\txmax = domain[1][1]\n\t\tind = sympy.floor(self.nb_seg*x//xmax)\n\n\t\tseq=[]\n\t\tcount = 0\n\t\twhile count<self.nb_seg-1:  # Temperatures will vary between: 2 +- 0.75\n\t\t\t\n\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\n\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count+1))-Mean)/K2\n\t\t\tif count == 0:\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(self.nb_seg-1))-Mean)/K2\n\t\t\telse:\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\t\n\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))  # cubic smoothing\t\t\n\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, x<x1))  # cubic smoothing\n\n\t\t\tcount += 1\n\t\t\t\n\t\t\tif count == self.nb_seg-1:\n\t\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T0\")-Mean)/K2\n\t\t\t\t\n\t\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))\n\t\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, True))\n\t\t\t\t\n\t\treturn sympy.Piecewise(*seq)", "\nclass Tfunc():\n\n\tdef __init__(self, nb_seg = None, dicTemp = None):\n\t\t''' N = number of actuators/segments on the hot boundary layer\n\t\tdicTemp = temperature variations of the segments: Ti' = Tnormal + Ti, Tnormal = 0.6 here''' \n\t\n\t\tself.nb_seg = nb_seg\n\t\tself.dicTemp = dicTemp\n\t\tself.ampl = 0.75  # Amplitude of variation of T\n\t\tself.dx = 0.03  # half-length of the interval on which we do the smoothing\n\t\t#self.length = length  # length of the domain\n\t\t\n\t\t\n\tdef apply_T(self, x):\n\t\tvalues = self.ampl*np.array(list(self.dicTemp.values()))\n\t\tMean = values.mean()\n\t\tK2 = max(1, np.abs(values-np.array([Mean]*self.nb_seg)).max()/self.ampl)\n\t\t\n\t\t# Position:\n\t\txmax = domain[1][1]\n\t\tind = sympy.floor(self.nb_seg*x//xmax)\n\n\t\tseq=[]\n\t\tcount = 0\n\t\twhile count<self.nb_seg-1:  # Temperatures will vary between: 2 +- 0.75\n\t\t\t\n\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\n\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count+1))-Mean)/K2\n\t\t\tif count == 0:\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(self.nb_seg-1))-Mean)/K2\n\t\t\telse:\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\t\n\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))  # cubic smoothing\t\t\n\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, x<x1))  # cubic smoothing\n\n\t\t\tcount += 1\n\t\t\t\n\t\t\tif count == self.nb_seg-1:\n\t\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T0\")-Mean)/K2\n\t\t\t\t\n\t\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))\n\t\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, True))\n\t\t\t\t\n\t\treturn sympy.Piecewise(*seq)", "\t"]}
{"filename": "parameters/parameters_RB_2D_MARL.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# parameters file for the MARL framework\n#\n#\n# FLOW, KTH Stockholm | 09/04/2023\n\nfrom __future__ import print_function, division", "\nfrom __future__ import print_function, division\nfrom Tfunc import Tfunc, domain\nimport numpy as np\nimport math\nimport sympy\n\n\n# case name - should be the same name as this file, without the prefix parameters_\ncase            = 'RB_2D_MARL'", "# case name - should be the same name as this file, without the prefix parameters_\ncase            = 'RB_2D_MARL'\nsimu_name       = case\ndimension       = '2D'\nreward_function = 'Nusselt' \n\n# Number of calculation processors\nnb_proc     = 1  \n\n# Number of environments in parallNel", "\n# Number of environments in parallNel\nnum_servers = 1  \n\n# Number of segments (actuators) on the lower boundary \nn_seg = 10  \n\n# Number of invariant parallel environments ('multi-agents') : \nnb_inv_envs = n_seg  \n# always take nb_inv_envs = n_seg for MARL", "nb_inv_envs = n_seg  \n# always take nb_inv_envs = n_seg for MARL\n\n\n# Duration of baseline simulation (in nondimensional simulation time)\nsimulation_duration   = 10.0   \nsimulation_time_start = 0.0\n\n# Duration of each actuation (in nondimensional simulation time)\ndelta_t_smooth   = 1.5      ", "# Duration of each actuation (in nondimensional simulation time)\ndelta_t_smooth   = 1.5      \ndelta_t_converge = 0.0       \nsmooth_func      = 'linear' \n\n\n# Total number of episodes : \n# CHOOSE A MULTIPLE OF nb_inv_envs*num_servers and add +1 \nnum_episodes = 11 \n", "num_episodes = 11 \n\n# Number of actuations per episode \nnb_actuations = 2 \nnb_actuations_deterministic = nb_actuations*4\n\n# Probes\nprobes_location      = 'cartesian_grid'\nnumber_of_probes     = (8,32)\nN = (64,96)  # simulation mesh grid", "number_of_probes     = (8,32)\nN = (64,96)  # simulation mesh grid\n\n# misc\npost_process_steps = 200  \nalphaRestart = 0.9 \nx, y, tt = sympy.symbols('x,y,t', real=True)\n\n\n", "\n\nCFD_params = {\n            'number_of_actuators': n_seg, \n            'hor_inv_probes':number_of_probes[1]//nb_inv_envs,  \n            'dico_d':        {'N': N,\n                              'domain': domain,\n                              'Ra': 10000.,\n     \t                      'Pr': 0.7,\n     \t                      'dt': 0.05,", "     \t                      'Pr': 0.7,\n     \t                      'dt': 0.05,\n     \t                      'filename': f'RB_{N[0]}_{N[1]}',\n     \t                      'conv': 0,\n     \t                      'modplot': 10,\n     \t                      'obsGrid': number_of_probes,  \n    \t                      'moderror': 10000,\n    \t                      'modsave': 10000,\n     \t                      'bcT': (Tfunc(nb_seg=n_seg, dicTemp={'T'+str(i):1. for i in range(n_seg)}).apply_T(y), 1), \n     \t                      'family': 'C',", "     \t                      'bcT': (Tfunc(nb_seg=n_seg, dicTemp={'T'+str(i):1. for i in range(n_seg)}).apply_T(y), 1), \n     \t                      'family': 'C',\n     \t                      'checkpoint': 10,\n     \t                      #'padding_factor': 1,\n     \t                      'timestepper': 'IMEXRK3'\n     \t                     }\n}\n     \t    \n\nsimulation_params = {", "\nsimulation_params = {\n\t'simulation_duration':  simulation_duration,  \n\t'simulation_timeframe': [simulation_time_start,simulation_time_start+simulation_duration],\n\t'delta_t_smooth':       delta_t_smooth,\n\t'delta_t_converge':     delta_t_converge,\n\t'smooth_func':          smooth_func,\n\t'post_process_steps' :  post_process_steps\n}\n", "}\n\n\n\n# Optimization\noptimization_params = {\n\t\"min_ampl_temp\":             -1.,\n\t\"max_ampl_temp\":             1.,\n\t\"norm_reward\":               1.,\n\t\"offset_reward\":             2.6726  ", "\t\"norm_reward\":               1.,\n\t\"offset_reward\":             2.6726  \n}\n\ninspection_params = {\n\t\"plot\":                False,  \n\t\"step\":                50,\n\t\"dump\":                100,\n\t\"show_all_at_reset\":   True,\n\t\"single_run\":          False", "\t\"show_all_at_reset\":   True,\n\t\"single_run\":          False\n}\n\n\n\n\n"]}
{"filename": "parameters/parameters_RB_2D_SARL.py", "chunked_list": ["#!/bin/env python\n#\n# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n#\n# parameters file for the SARL framework\n#\n#\n# FLOW, KTH Stockholm | 09/04/2023\n\nfrom __future__ import print_function, division", "\nfrom __future__ import print_function, division\nimport numpy as np\nimport math\n\n\n# case name - should be the same name as this file, without the prefix parameters_\ncase            = 'RB_2D_SARL'\nsimu_name       = case\ndimension       = '2D'", "simu_name       = case\ndimension       = '2D'\nreward_function = 'Nusselt' \n\n\n# Number of calculation processors\nnb_proc     = 1 \n\n# number of environment in parallel\nnum_servers = 1 ", "# number of environment in parallel\nnum_servers = 1 \n\n# Number of segments (actuators) on the lower boundary  \nn_seg = 10   \n\n# Number of invariant parallel environments ('multi-agents' - set to one for single agent)\nnb_inv_envs = 1  \n\n# Duration of baseline simulation (in nondimensional simulation time)", "\n# Duration of baseline simulation (in nondimensional simulation time)\nsimulation_duration   = 10.0   \nsimulation_time_start = 0.0\n\n# Duration of each actuation (in nondimensional simulation time)\ndelta_t_smooth   = 1.5      \ndelta_t_converge = 0.0       \nsmooth_func      = 'linear' \n", "smooth_func      = 'linear' \n\n\n# post options\npost_process_steps = 200 \n\n# Total number of episodes\nnum_episodes = 1 \n\n# Number of actuations per episode ", "\n# Number of actuations per episode \nnb_actuations = 2 \nnb_actuations_deterministic = nb_actuations*4\n\n# Probes\nprobes_location      = 'cartesian_grid'\nnumber_of_probes     = (8,32)\n\n", "\n\n# Simulation parameters\nsimulation_params = {\n\t'simulation_duration':  simulation_duration,  \n\t'simulation_timeframe': [simulation_time_start,simulation_time_start+simulation_duration],\n\t'delta_t_smooth':       delta_t_smooth,\n\t'delta_t_converge':     delta_t_converge,\n\t'smooth_func':          smooth_func,\n\t'post_process_steps' :  post_process_steps", "\t'smooth_func':          smooth_func,\n\t'post_process_steps' :  post_process_steps\n}\n\n# Variational input  \nvariational_input = {\n\t'filename':        'RB_2D', \n\t'porous':          False, \n\t\"d\":               0, \n\t\"time\":            -0.25, ", "\t\"d\":               0, \n\t\"time\":            -0.25, \n\t\"initial_time\":    None, \n}\n\n\noutput_params = {\n\t'nb_probes':  number_of_probes,\n\t'probe_type': 'u_T'\n}", "\t'probe_type': 'u_T'\n}\n\n# Optimization\noptimization_params = {\n\t\"min_ampl_temp\":             -1.,\n\t\"max_ampl_temp\":             1.,\n\t#\"norm_Temp\":                 0.4,  \n\t\"norm_reward\":               1.,  \n\t#\"norm_press\":                    2,  ", "\t\"norm_reward\":               1.,  \n\t#\"norm_press\":                    2,  \n\t\"offset_reward\":                 2.6788,  \n}\n\ninspection_params = {\n\t\"plot\":                False,  \n\t\"step\":                50,\n\t\"dump\":                100,\n\t\"show_all_at_reset\":   True,", "\t\"dump\":                100,\n\t\"show_all_at_reset\":   True,\n\t\"single_run\":          False\n}\n"]}
