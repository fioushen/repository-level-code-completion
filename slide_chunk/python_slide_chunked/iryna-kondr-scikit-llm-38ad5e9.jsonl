{"filename": "skllm/gpt4all_client.py", "chunked_list": ["from typing import Dict\n\ntry:\n    from gpt4all import GPT4All\nexcept (ImportError, ModuleNotFoundError):\n    GPT4All = None\n\n_loaded_models = {}\n\n\ndef _make_openai_compatabile(message: str) -> Dict:\n    return {\"choices\": [{\"message\": {\"content\": message, \"role\": \"assistant\"}}]}", "\n\ndef _make_openai_compatabile(message: str) -> Dict:\n    return {\"choices\": [{\"message\": {\"content\": message, \"role\": \"assistant\"}}]}\n\n\ndef get_chat_completion(\n    messages: Dict, model: str = \"ggml-model-gpt4all-falcon-q4_0.bin\"\n) -> Dict:\n    \"\"\"Gets a chat completion from GPT4All.\n\n    Parameters\n    ----------\n    messages : Dict\n        The messages to use as a prompt for the chat completion.\n    model : str\n        The model to use for the chat completion. Defaults to \"ggml-gpt4all-j-v1.3-groovy\".\n\n    Returns\n    -------\n    completion : Dict\n    \"\"\"\n    if GPT4All is None:\n        raise ImportError(\n            \"gpt4all is not installed, try `pip install scikit-llm[gpt4all]`\"\n        )\n    if model not in _loaded_models.keys():\n        loaded_model = GPT4All(model)\n        _loaded_models[model] = loaded_model\n        loaded_model._current_prompt_template = loaded_model.config[\"promptTemplate\"]\n\n    prompt = _loaded_models[model]._format_chat_prompt_template(\n        messages, _loaded_models[model].config[\"systemPrompt\"]\n    )\n    generated = _loaded_models[model].generate(\n        prompt,\n        streaming=False,\n        temp=1e-10,\n    )\n\n    return _make_openai_compatabile(generated)", "\n\ndef unload_models() -> None:\n    global _loaded_models\n    _loaded_models = {}\n"]}
{"filename": "skllm/config.py", "chunked_list": ["import os\nfrom typing import Optional\n\n_OPENAI_KEY_VAR = \"SKLLM_CONFIG_OPENAI_KEY\"\n_OPENAI_ORG_VAR = \"SKLLM_CONFIG_OPENAI_ORG\"\n_AZURE_API_BASE_VAR = \"SKLLM_CONFIG_AZURE_API_BASE\"\n_AZURE_API_VERSION_VAR = \"SKLLM_CONFIG_AZURE_API_VERSION\"\n_GOOGLE_PROJECT = \"GOOGLE_CLOUD_PROJECT\"\n\n\nclass SKLLMConfig:\n    @staticmethod\n    def set_openai_key(key: str) -> None:\n        \"\"\"Sets the OpenAI key.\n\n        Parameters\n        ----------\n        key : str\n            OpenAI key.\n        \"\"\"\n        os.environ[_OPENAI_KEY_VAR] = key\n\n    @staticmethod\n    def get_openai_key() -> Optional[str]:\n        \"\"\"Gets the OpenAI key.\n\n        Returns\n        -------\n        Optional[str]\n            OpenAI key.\n        \"\"\"\n        return os.environ.get(_OPENAI_KEY_VAR, None)\n\n    @staticmethod\n    def set_openai_org(key: str) -> None:\n        \"\"\"Sets OpenAI organization ID.\n\n        Parameters\n        ----------\n        key : str\n            OpenAI organization ID.\n        \"\"\"\n        os.environ[_OPENAI_ORG_VAR] = key\n\n    @staticmethod\n    def get_openai_org() -> str:\n        \"\"\"Gets the OpenAI organization ID.\n\n        Returns\n        -------\n        str\n            OpenAI organization ID.\n        \"\"\"\n        return os.environ.get(_OPENAI_ORG_VAR, \"\")\n\n    @staticmethod\n    def get_azure_api_base() -> str:\n        \"\"\"Gets the API base for Azure.\n\n        Returns\n        -------\n        str\n            URL to be used as the base for the Azure API.\n        \"\"\"\n        base = os.environ.get(_AZURE_API_BASE_VAR, None)\n        if base is None:\n            raise RuntimeError(\"Azure API base is not set\")\n        return base\n\n    @staticmethod\n    def set_azure_api_base(base: str) -> None:\n        \"\"\"Set the API base for Azure.\n\n        Parameters\n        ----------\n        base : str\n            URL to be used as the base for the Azure API.\n        \"\"\"\n        os.environ[_AZURE_API_BASE_VAR] = base\n\n    @staticmethod\n    def set_azure_api_version(ver: str) -> None:\n        \"\"\"Set the API version for Azure.\n\n        Parameters\n        ----------\n        ver : str\n            Azure API version.\n        \"\"\"\n        os.environ[_AZURE_API_VERSION_VAR] = ver\n\n    @staticmethod\n    def get_azure_api_version() -> str:\n        \"\"\"Gets the API version for Azure.\n\n        Returns\n        -------\n        str\n            Azure API version.\n        \"\"\"\n        return os.environ.get(_AZURE_API_VERSION_VAR, \"2023-05-15\")\n\n    @staticmethod\n    def get_google_project() -> Optional[str]:\n        \"\"\"Gets the Google Cloud project ID.\n\n        Returns\n        -------\n        Optional[str]\n            Google Cloud project ID.\n        \"\"\"\n        return os.environ.get(_GOOGLE_PROJECT, None)\n\n    @staticmethod\n    def set_google_project(project: str) -> None:\n        \"\"\"Sets the Google Cloud project ID.\n\n        Parameters\n        ----------\n        project : str\n            Google Cloud project ID.\n        \"\"\"\n        os.environ[_GOOGLE_PROJECT] = project", "\n\nclass SKLLMConfig:\n    @staticmethod\n    def set_openai_key(key: str) -> None:\n        \"\"\"Sets the OpenAI key.\n\n        Parameters\n        ----------\n        key : str\n            OpenAI key.\n        \"\"\"\n        os.environ[_OPENAI_KEY_VAR] = key\n\n    @staticmethod\n    def get_openai_key() -> Optional[str]:\n        \"\"\"Gets the OpenAI key.\n\n        Returns\n        -------\n        Optional[str]\n            OpenAI key.\n        \"\"\"\n        return os.environ.get(_OPENAI_KEY_VAR, None)\n\n    @staticmethod\n    def set_openai_org(key: str) -> None:\n        \"\"\"Sets OpenAI organization ID.\n\n        Parameters\n        ----------\n        key : str\n            OpenAI organization ID.\n        \"\"\"\n        os.environ[_OPENAI_ORG_VAR] = key\n\n    @staticmethod\n    def get_openai_org() -> str:\n        \"\"\"Gets the OpenAI organization ID.\n\n        Returns\n        -------\n        str\n            OpenAI organization ID.\n        \"\"\"\n        return os.environ.get(_OPENAI_ORG_VAR, \"\")\n\n    @staticmethod\n    def get_azure_api_base() -> str:\n        \"\"\"Gets the API base for Azure.\n\n        Returns\n        -------\n        str\n            URL to be used as the base for the Azure API.\n        \"\"\"\n        base = os.environ.get(_AZURE_API_BASE_VAR, None)\n        if base is None:\n            raise RuntimeError(\"Azure API base is not set\")\n        return base\n\n    @staticmethod\n    def set_azure_api_base(base: str) -> None:\n        \"\"\"Set the API base for Azure.\n\n        Parameters\n        ----------\n        base : str\n            URL to be used as the base for the Azure API.\n        \"\"\"\n        os.environ[_AZURE_API_BASE_VAR] = base\n\n    @staticmethod\n    def set_azure_api_version(ver: str) -> None:\n        \"\"\"Set the API version for Azure.\n\n        Parameters\n        ----------\n        ver : str\n            Azure API version.\n        \"\"\"\n        os.environ[_AZURE_API_VERSION_VAR] = ver\n\n    @staticmethod\n    def get_azure_api_version() -> str:\n        \"\"\"Gets the API version for Azure.\n\n        Returns\n        -------\n        str\n            Azure API version.\n        \"\"\"\n        return os.environ.get(_AZURE_API_VERSION_VAR, \"2023-05-15\")\n\n    @staticmethod\n    def get_google_project() -> Optional[str]:\n        \"\"\"Gets the Google Cloud project ID.\n\n        Returns\n        -------\n        Optional[str]\n            Google Cloud project ID.\n        \"\"\"\n        return os.environ.get(_GOOGLE_PROJECT, None)\n\n    @staticmethod\n    def set_google_project(project: str) -> None:\n        \"\"\"Sets the Google Cloud project ID.\n\n        Parameters\n        ----------\n        project : str\n            Google Cloud project ID.\n        \"\"\"\n        os.environ[_GOOGLE_PROJECT] = project", ""]}
{"filename": "skllm/completions.py", "chunked_list": ["from skllm.gpt4all_client import get_chat_completion as _g4a_get_chat_completion\nfrom skllm.openai.chatgpt import get_chat_completion as _oai_get_chat_completion\n\n\ndef get_chat_completion(\n    messages: dict,\n    openai_key: str = None,\n    openai_org: str = None,\n    model: str = \"gpt-3.5-turbo\",\n    max_retries: int = 3,\n):\n    \"\"\"Gets a chat completion from the OpenAI API.\"\"\"\n    if model.startswith(\"gpt4all::\"):\n        return _g4a_get_chat_completion(messages, model[9:])\n    else:\n        api = \"azure\" if model.startswith(\"azure::\") else \"openai\"\n        if api == \"azure\":\n            model = model[7:]\n        return _oai_get_chat_completion(\n            messages, openai_key, openai_org, model, max_retries, api=api\n        )", ""]}
{"filename": "skllm/__init__.py", "chunked_list": ["# ordering is important here to prevent circular imports\nfrom skllm.models.gpt.gpt_zero_shot_clf import (\n    MultiLabelZeroShotGPTClassifier,\n    ZeroShotGPTClassifier,\n)\nfrom skllm.models.gpt.gpt_few_shot_clf import FewShotGPTClassifier\nfrom skllm.models.gpt.gpt_dyn_few_shot_clf import DynamicFewShotGPTClassifier\n"]}
{"filename": "skllm/utils.py", "chunked_list": ["import json\nfrom typing import Any\n\nimport numpy as np\nimport pandas as pd\n\n\ndef to_numpy(X: Any) -> np.ndarray:\n    \"\"\"Converts a pandas Series or list to a numpy array.\n\n    Parameters\n    ----------\n    X : Any\n        The data to convert to a numpy array.\n\n    Returns\n    -------\n    X : np.ndarray\n    \"\"\"\n    if isinstance(X, pd.Series):\n        X = X.to_numpy().astype(object)\n    elif isinstance(X, list):\n        X = np.asarray(X, dtype=object)\n    if isinstance(X, np.ndarray) and len(X.shape) > 1:\n        X = np.squeeze(X)\n    return X", "\n\ndef find_json_in_string(string: str) -> str:\n    \"\"\"Finds the JSON object in a string.\n\n    Parameters\n    ----------\n    string : str\n        The string to search for a JSON object.\n\n    Returns\n    -------\n    json_string : str\n    \"\"\"\n    start = string.find(\"{\")\n    end = string.rfind(\"}\")\n    if start != -1 and end != -1:\n        json_string = string[start : end + 1]\n    else:\n        json_string = \"{}\"\n    return json_string", "\n\ndef extract_json_key(json_: str, key: str):\n    \"\"\"Extracts JSON key from a string.\n\n    json_ : str\n        The JSON string to extract the key from.\n    key : str\n        The key to extract.\n    \"\"\"\n    original_json = json_\n    for i in range(2):\n        try:\n            json_ = original_json.replace(\"\\n\", \"\")\n            if i == 1:\n                json_ = json_.replace(\"'\", '\"')\n            json_ = find_json_in_string(json_)\n            as_json = json.loads(json_)\n            if key not in as_json.keys():\n                raise KeyError(\"The required key was not found\")\n            return as_json[key]\n        except Exception:\n            if i == 0:\n                continue\n            return None", ""]}
{"filename": "skllm/preprocessing/gpt_vectorizer.py", "chunked_list": ["from __future__ import annotations\n\nfrom typing import Any, List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nfrom numpy import ndarray\nfrom sklearn.base import BaseEstimator as _BaseEstimator\nfrom sklearn.base import TransformerMixin as _TransformerMixin\nfrom tqdm import tqdm", "from sklearn.base import TransformerMixin as _TransformerMixin\nfrom tqdm import tqdm\n\nfrom skllm.openai.embeddings import get_embedding as _get_embedding\nfrom skllm.openai.mixin import OpenAIMixin as _OAIMixin\nfrom skllm.utils import to_numpy as _to_numpy\n\n\nclass GPTVectorizer(_BaseEstimator, _TransformerMixin, _OAIMixin):\n    \"\"\"\n    A class that uses OPEN AI embedding model that converts text to GPT embeddings.\n\n    Parameters\n    ----------\n    openai_embedding_model : str\n        The OPEN AI embedding model to use. Defaults to \"text-embedding-ada-002\".\n    openai_key : str, optional\n        The OPEN AI key to use. Defaults to None.\n    openai_org : str, optional\n        The OPEN AI organization ID to use. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        openai_embedding_model: str = \"text-embedding-ada-002\",\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n    ):\n        self.openai_embedding_model = openai_embedding_model\n        self._set_keys(openai_key, openai_org)\n\n    def fit(self, X: Any = None, y: Any = None, **kwargs) -> GPTVectorizer:\n        \"\"\"\n        Fits the GPTVectorizer to the data.\n        This is modelled to function as the sklearn fit method.\n\n        Parameters\n        ----------\n        X : Any, optional\n        y : Any, optional\n        kwargs : dict, optional\n\n        Returns\n        -------\n        self : GPTVectorizer\n        \"\"\"\n        return self\n\n    def transform(self, X: Optional[Union[np.ndarray, pd.Series, List[str]]]) -> ndarray:\n        \"\"\"\n        Transforms a list of strings into a list of GPT embeddings.\n        This is modelled to function as the sklearn transform method\n\n        Parameters\n        ----------\n        X : Optional[Union[np.ndarray, pd.Series, List[str]]]\n            The input array of strings to transform into GPT embeddings.\n        \n        Returns\n        -------\n        embeddings : np.ndarray\n        \"\"\"\n        X = _to_numpy(X)\n        embeddings = []\n        for i in tqdm(range(len(X))):\n            embeddings.append(\n                _get_embedding(X[i], self._get_openai_key(), self._get_openai_org())\n            )\n        embeddings = np.asarray(embeddings)\n        return embeddings\n\n    def fit_transform(self, X: Optional[Union[np.ndarray, pd.Series, List[str]]], y=None, **fit_params) -> ndarray:\n        \"\"\"\n        Fits and transforms a list of strings into a list of GPT embeddings.\n        This is modelled to function as the sklearn fit_transform method\n\n        Parameters\n        ----------\n        X : Optional[Union[np.ndarray, pd.Series, List[str]]]\n            The input array of strings to transform into GPT embeddings.\n        y : Any, optional\n\n        Returns\n        -------\n        embeddings : np.ndarray\n        \"\"\"\n        return self.fit(X, y).transform(X)", "class GPTVectorizer(_BaseEstimator, _TransformerMixin, _OAIMixin):\n    \"\"\"\n    A class that uses OPEN AI embedding model that converts text to GPT embeddings.\n\n    Parameters\n    ----------\n    openai_embedding_model : str\n        The OPEN AI embedding model to use. Defaults to \"text-embedding-ada-002\".\n    openai_key : str, optional\n        The OPEN AI key to use. Defaults to None.\n    openai_org : str, optional\n        The OPEN AI organization ID to use. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        openai_embedding_model: str = \"text-embedding-ada-002\",\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n    ):\n        self.openai_embedding_model = openai_embedding_model\n        self._set_keys(openai_key, openai_org)\n\n    def fit(self, X: Any = None, y: Any = None, **kwargs) -> GPTVectorizer:\n        \"\"\"\n        Fits the GPTVectorizer to the data.\n        This is modelled to function as the sklearn fit method.\n\n        Parameters\n        ----------\n        X : Any, optional\n        y : Any, optional\n        kwargs : dict, optional\n\n        Returns\n        -------\n        self : GPTVectorizer\n        \"\"\"\n        return self\n\n    def transform(self, X: Optional[Union[np.ndarray, pd.Series, List[str]]]) -> ndarray:\n        \"\"\"\n        Transforms a list of strings into a list of GPT embeddings.\n        This is modelled to function as the sklearn transform method\n\n        Parameters\n        ----------\n        X : Optional[Union[np.ndarray, pd.Series, List[str]]]\n            The input array of strings to transform into GPT embeddings.\n        \n        Returns\n        -------\n        embeddings : np.ndarray\n        \"\"\"\n        X = _to_numpy(X)\n        embeddings = []\n        for i in tqdm(range(len(X))):\n            embeddings.append(\n                _get_embedding(X[i], self._get_openai_key(), self._get_openai_org())\n            )\n        embeddings = np.asarray(embeddings)\n        return embeddings\n\n    def fit_transform(self, X: Optional[Union[np.ndarray, pd.Series, List[str]]], y=None, **fit_params) -> ndarray:\n        \"\"\"\n        Fits and transforms a list of strings into a list of GPT embeddings.\n        This is modelled to function as the sklearn fit_transform method\n\n        Parameters\n        ----------\n        X : Optional[Union[np.ndarray, pd.Series, List[str]]]\n            The input array of strings to transform into GPT embeddings.\n        y : Any, optional\n\n        Returns\n        -------\n        embeddings : np.ndarray\n        \"\"\"\n        return self.fit(X, y).transform(X)", ""]}
{"filename": "skllm/preprocessing/gpt_summarizer.py", "chunked_list": ["from typing import Any, List, Optional, Union\n\nimport numpy as np\nfrom numpy import ndarray\nfrom pandas import Series\n\nfrom skllm.openai.base_gpt import BaseZeroShotGPTTransformer as _BaseGPT\nfrom skllm.prompts.builders import build_focused_summary_prompt, build_summary_prompt\n\n\nclass GPTSummarizer(_BaseGPT):\n    \"\"\"\n    A text summarizer.\n    \n    Parameters\n    ----------\n    openai_key : str, optional\n        The OPEN AI key to use. Defaults to None.\n    openai_org : str, optional\n        The OPEN AI organization ID to use. Defaults to None.\n    openai_model : str, optional\n        The OPEN AI model to use. Defaults to \"gpt-3.5-turbo\".\n    max_words : int, optional\n        The maximum number of words to use in the summary. Defaults to 15.\n    \n    \"\"\"\n    system_msg = \"You are a text summarizer.\"\n    default_output = \"Summary is unavailable.\"\n\n    def __init__(\n        self,\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n        openai_model: str = \"gpt-3.5-turbo\",\n        max_words: int = 15,\n        focus: Optional[str] = None,\n    ):\n        self._set_keys(openai_key, openai_org)\n        self.openai_model = openai_model\n        self.max_words = max_words\n        self.focus = focus\n\n    def _get_prompt(self, X: str) -> str:\n        \"\"\"\n        Generates the prompt for the given input.\n\n        Parameters\n        ----------\n        X : str\n            sample to summarize\n\n        Returns\n        -------\n        str\n        \"\"\"\n        if self.focus:\n            return build_focused_summary_prompt(X, self.max_words, self.focus)\n        else:\n            return build_summary_prompt(X, self.max_words)\n\n    def transform(self, X: Union[ndarray, Series, List[str]], **kwargs: Any) -> ndarray:\n        y = super().transform(X, **kwargs)\n        if self.focus:\n            # remove \"Mentioned concept is not present in the text.\" from the output\n            y = np.asarray(\n                [\n                    i.replace(\"Mentioned concept is not present in the text.\", \"\")\n                    .replace(\"The general summary is:\", \"\")\n                    .strip()\n                    for i in y\n                ],\n                dtype=object,\n            )\n        return y", "\n\nclass GPTSummarizer(_BaseGPT):\n    \"\"\"\n    A text summarizer.\n    \n    Parameters\n    ----------\n    openai_key : str, optional\n        The OPEN AI key to use. Defaults to None.\n    openai_org : str, optional\n        The OPEN AI organization ID to use. Defaults to None.\n    openai_model : str, optional\n        The OPEN AI model to use. Defaults to \"gpt-3.5-turbo\".\n    max_words : int, optional\n        The maximum number of words to use in the summary. Defaults to 15.\n    \n    \"\"\"\n    system_msg = \"You are a text summarizer.\"\n    default_output = \"Summary is unavailable.\"\n\n    def __init__(\n        self,\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n        openai_model: str = \"gpt-3.5-turbo\",\n        max_words: int = 15,\n        focus: Optional[str] = None,\n    ):\n        self._set_keys(openai_key, openai_org)\n        self.openai_model = openai_model\n        self.max_words = max_words\n        self.focus = focus\n\n    def _get_prompt(self, X: str) -> str:\n        \"\"\"\n        Generates the prompt for the given input.\n\n        Parameters\n        ----------\n        X : str\n            sample to summarize\n\n        Returns\n        -------\n        str\n        \"\"\"\n        if self.focus:\n            return build_focused_summary_prompt(X, self.max_words, self.focus)\n        else:\n            return build_summary_prompt(X, self.max_words)\n\n    def transform(self, X: Union[ndarray, Series, List[str]], **kwargs: Any) -> ndarray:\n        y = super().transform(X, **kwargs)\n        if self.focus:\n            # remove \"Mentioned concept is not present in the text.\" from the output\n            y = np.asarray(\n                [\n                    i.replace(\"Mentioned concept is not present in the text.\", \"\")\n                    .replace(\"The general summary is:\", \"\")\n                    .strip()\n                    for i in y\n                ],\n                dtype=object,\n            )\n        return y", ""]}
{"filename": "skllm/preprocessing/__init__.py", "chunked_list": ["from skllm.preprocessing.gpt_summarizer import GPTSummarizer\nfrom skllm.preprocessing.gpt_translator import GPTTranslator\nfrom skllm.preprocessing.gpt_vectorizer import GPTVectorizer\n"]}
{"filename": "skllm/preprocessing/gpt_translator.py", "chunked_list": ["from typing import Any, List, Optional, Union\n\nimport numpy as np\nfrom numpy import ndarray\nfrom pandas import Series\n\nfrom skllm.openai.base_gpt import BaseZeroShotGPTTransformer as _BaseGPT\nfrom skllm.prompts.builders import build_translation_prompt\n\n\nclass GPTTranslator(_BaseGPT):\n    \"\"\"A text translator.\"\"\"\n\n    system_msg = \"You are a text translator.\"\n    default_output = \"Translation is unavailable.\"\n\n    def __init__(\n        self,\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n        openai_model: str = \"gpt-3.5-turbo\",\n        output_language: str = \"English\",\n    ) -> None:\n        self._set_keys(openai_key, openai_org)\n        self.openai_model = openai_model\n        self.output_language = output_language\n\n    def _get_prompt(self, X: str) -> str:\n        \"\"\"Generates the prompt for the given input.\n\n        Parameters\n        ----------\n        X : str\n            sample to translate\n\n        Returns\n        -------\n        str\n            translated sample\n        \"\"\"\n        return build_translation_prompt(X, self.output_language)\n\n    def transform(self, X: Union[ndarray, Series, List[str]], **kwargs: Any) -> ndarray:\n        y = super().transform(X, **kwargs)\n        y = np.asarray(\n            [i.replace(\"[Translated text:]\", \"\").replace(\"```\", \"\").strip() for i in y],\n            dtype=object,\n        )\n        return y", "\n\nclass GPTTranslator(_BaseGPT):\n    \"\"\"A text translator.\"\"\"\n\n    system_msg = \"You are a text translator.\"\n    default_output = \"Translation is unavailable.\"\n\n    def __init__(\n        self,\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n        openai_model: str = \"gpt-3.5-turbo\",\n        output_language: str = \"English\",\n    ) -> None:\n        self._set_keys(openai_key, openai_org)\n        self.openai_model = openai_model\n        self.output_language = output_language\n\n    def _get_prompt(self, X: str) -> str:\n        \"\"\"Generates the prompt for the given input.\n\n        Parameters\n        ----------\n        X : str\n            sample to translate\n\n        Returns\n        -------\n        str\n            translated sample\n        \"\"\"\n        return build_translation_prompt(X, self.output_language)\n\n    def transform(self, X: Union[ndarray, Series, List[str]], **kwargs: Any) -> ndarray:\n        y = super().transform(X, **kwargs)\n        y = np.asarray(\n            [i.replace(\"[Translated text:]\", \"\").replace(\"```\", \"\").strip() for i in y],\n            dtype=object,\n        )\n        return y", ""]}
{"filename": "skllm/prompts/templates.py", "chunked_list": ["ZERO_SHOT_CLF_PROMPT_TEMPLATE = \"\"\"\nYou will be provided with the following information:\n1. An arbitrary text sample. The sample is delimited with triple backticks.\n2. List of categories the text sample can be assigned to. The list is delimited with square brackets. The categories in the list are enclosed in the single quotes and comma separated.\n\nPerform the following tasks:\n1. Identify to which category the provided text belongs to with the highest probability.\n2. Assign the provided text to that category.\n3. Provide your response in a JSON format containing a single key `label` and a value corresponding to the assigned category. Do not provide any additional information except the JSON.\n", "3. Provide your response in a JSON format containing a single key `label` and a value corresponding to the assigned category. Do not provide any additional information except the JSON.\n\nList of categories: {labels}\n\nText sample: ```{x}```\n\nYour JSON response:\n\"\"\"\n\nFEW_SHOT_CLF_PROMPT_TEMPLATE = \"\"\"", "\nFEW_SHOT_CLF_PROMPT_TEMPLATE = \"\"\"\nYou will be provided with the following information:\n1. An arbitrary text sample. The sample is delimited with triple backticks.\n2. List of categories the text sample can be assigned to. The list is delimited with square brackets. The categories in the list are enclosed in the single quotes and comma separated.\n3. Examples of text samples and their assigned categories. The examples are delimited with triple backticks. The assigned categories are enclosed in a list-like structure. These examples are to be used as training data.\n\nPerform the following tasks:\n1. Identify to which category the provided text belongs to with the highest probability.\n2. Assign the provided text to that category.", "1. Identify to which category the provided text belongs to with the highest probability.\n2. Assign the provided text to that category.\n3. Provide your response in a JSON format containing a single key `label` and a value corresponding to the assigned category. Do not provide any additional information except the JSON.\n\nList of categories: {labels}\n\nTraining data:\n{training_data}\n\nText sample: ```{x}```", "\nText sample: ```{x}```\n\nYour JSON response:\n\"\"\"\n\nZERO_SHOT_MLCLF_PROMPT_TEMPLATE = \"\"\"\nYou will be provided with the following information:\n1. An arbitrary text sample. The sample is delimited with triple backticks.\n2. List of categories the text sample can be assigned to. The list is delimited with square brackets. The categories in the list are enclosed in the single quotes and comma separated. The text sample belongs to at least one category but cannot exceed {max_cats}.", "1. An arbitrary text sample. The sample is delimited with triple backticks.\n2. List of categories the text sample can be assigned to. The list is delimited with square brackets. The categories in the list are enclosed in the single quotes and comma separated. The text sample belongs to at least one category but cannot exceed {max_cats}.\n\nPerform the following tasks:\n1. Identify to which categories the provided text belongs to with the highest probability.\n2. Assign the text sample to at least 1 but up to {max_cats} categories based on the probabilities.\n3. Provide your response in a JSON format containing a single key `label` and a value corresponding to the array of assigned categories. Do not provide any additional information except the JSON.\n\nList of categories: {labels}\n", "List of categories: {labels}\n\nText sample: ```{x}```\n\nYour JSON response:\n\"\"\"\n\nSUMMARY_PROMPT_TEMPLATE = \"\"\"\nYour task is to generate a summary of the text sample.\nSummarize the text sample provided below, delimited by triple backticks, in at most {max_words} words.", "Your task is to generate a summary of the text sample.\nSummarize the text sample provided below, delimited by triple backticks, in at most {max_words} words.\n\nText sample: ```{x}```\nSummarized text:\n\"\"\"\n\nFOCUSED_SUMMARY_PROMPT_TEMPLATE = \"\"\"\nAs an input you will receive:\n1. A focus parameter delimited with square brackets.", "As an input you will receive:\n1. A focus parameter delimited with square brackets.\n2. A single text sample delimited with triple backticks.\n\nPerform the following actions:\n1. Determine whether there is something in the text that matches focus. Do not output anything.\n2. Summarise the text in at most {max_words} words.\n3. If possible, make the summarisation focused on the concept provided in the focus parameter. Otherwise, provide a general summarisation. Do not state that general summary is provided.\n4. Do not output anything except of the summary. Do not output any text that was not present in the original text.\n5. If no focused summary possible, or the mentioned concept is not present in the text, output \"Mentioned concept is not present in the text.\" and the general summary. Do not state that general summary is provided.", "4. Do not output anything except of the summary. Do not output any text that was not present in the original text.\n5. If no focused summary possible, or the mentioned concept is not present in the text, output \"Mentioned concept is not present in the text.\" and the general summary. Do not state that general summary is provided.\n\nFocus: [{focus}]\n\nText sample: ```{x}```\n\nSummarized text:\n\"\"\"\n", "\"\"\"\n\nTRANSLATION_PROMPT_TEMPLATE = \"\"\"\nIf the original text, delimited by triple backticks, is already in {output_language} language, output the original text.\nOtherwise, translate the original text, delimited by triple backticks, to {output_language} language, and output the translated text only. Do not output any additional information except the translated text.\n\nOriginal text: ```{x}```\nOutput:\n\"\"\"\n", "\"\"\"\n"]}
{"filename": "skllm/prompts/builders.py", "chunked_list": ["from typing import Union\n\nfrom skllm.prompts.templates import (\n    FEW_SHOT_CLF_PROMPT_TEMPLATE,\n    FOCUSED_SUMMARY_PROMPT_TEMPLATE,\n    SUMMARY_PROMPT_TEMPLATE,\n    TRANSLATION_PROMPT_TEMPLATE,\n    ZERO_SHOT_CLF_PROMPT_TEMPLATE,\n    ZERO_SHOT_MLCLF_PROMPT_TEMPLATE,\n)", "    ZERO_SHOT_MLCLF_PROMPT_TEMPLATE,\n)\n\n# TODO add validators\n\n\ndef build_zero_shot_prompt_slc(\n    x: str, labels: str, template: str = ZERO_SHOT_CLF_PROMPT_TEMPLATE\n) -> str:\n    \"\"\"Builds a prompt for zero-shot single-label classification.\n\n    Parameters\n    ----------\n    x : str\n        sample to classify\n    labels : str\n        candidate labels in a list-like representation\n    template : str\n        prompt template to use, must contain placeholders for all variables, by default ZERO_SHOT_CLF_PROMPT_TEMPLATE\n\n    Returns\n    -------\n    str\n        prepared prompt\n    \"\"\"\n    return template.format(x=x, labels=labels)", "\n\ndef build_few_shot_prompt_slc(\n    x: str,\n    labels: str,\n    training_data: str,\n    template: str = FEW_SHOT_CLF_PROMPT_TEMPLATE,\n) -> str:\n    \"\"\"Builds a prompt for zero-shot single-label classification.\n\n    Parameters\n    ----------\n    x : str\n        sample to classify\n    labels : str\n        candidate labels in a list-like representation\n    training_data : str\n        training data to be used for few-shot learning\n    template : str\n        prompt template to use, must contain placeholders for all variables, by default ZERO_SHOT_CLF_PROMPT_TEMPLATE\n\n    Returns\n    -------\n    str\n        prepared prompt\n    \"\"\"\n    return template.format(x=x, labels=labels, training_data=training_data)", "\n\ndef build_zero_shot_prompt_mlc(\n    x: str,\n    labels: str,\n    max_cats: Union[int, str],\n    template: str = ZERO_SHOT_MLCLF_PROMPT_TEMPLATE,\n) -> str:\n    \"\"\"Builds a prompt for zero-shot multi-label classification.\n\n    Parameters\n    ----------\n    x : str\n        sample to classify\n    labels : str\n        candidate labels in a list-like representation\n    max_cats : Union[int,str]\n        maximum number of categories to assign\n    template : str\n        prompt template to use, must contain placeholders for all variables, by default ZERO_SHOT_MLCLF_PROMPT_TEMPLATE\n\n    Returns\n    -------\n    str\n        prepared prompt\n    \"\"\"\n    return template.format(x=x, labels=labels, max_cats=max_cats)", "\n\ndef build_summary_prompt(\n    x: str, max_words: Union[int, str], template: str = SUMMARY_PROMPT_TEMPLATE\n) -> str:\n    \"\"\"Builds a prompt for text summarization.\n\n    Parameters\n    ----------\n    x : str\n        sample to summarize\n    max_words : Union[int,str]\n        maximum number of words to use in the summary\n    template : str\n        prompt template to use, must contain placeholders for all variables, by default SUMMARY_PROMPT_TEMPLATE\n\n    Returns\n    -------\n    str\n        prepared prompt\n    \"\"\"\n    return template.format(x=x, max_words=max_words)", "\n\ndef build_focused_summary_prompt(\n    x: str,\n    max_words: Union[int, str],\n    focus: Union[int, str],\n    template: str = FOCUSED_SUMMARY_PROMPT_TEMPLATE,\n) -> str:\n    \"\"\"Builds a prompt for focused text summarization.\n\n    Parameters\n    ----------\n    x : str\n        sample to summarize\n    max_words : Union[int,str]\n        maximum number of words to use in the summary\n    focus : Union[int,str]\n        the topic(s) to focus on\n    template : str\n        prompt template to use, must contain placeholders for all variables, by default FOCUSED_SUMMARY_PROMPT_TEMPLATE\n\n    Returns\n    -------\n    str\n        prepared prompt\n    \"\"\"\n    return template.format(x=x, max_words=max_words, focus=focus)", "\n\ndef build_translation_prompt(\n    x: str, output_language: str, template: str = TRANSLATION_PROMPT_TEMPLATE\n) -> str:\n    \"\"\"Builds a prompt for text translation.\n\n    Parameters\n    ----------\n    x : str\n        sample to translate\n    output_language : str\n        language to translate to\n    template : str\n        prompt template to use, must contain placeholders for all variables, by default TRANSLATION_PROMPT_TEMPLATE\n\n    Returns\n    -------\n    str\n        prepared prompt\n    \"\"\"\n    return template.format(x=x, output_language=output_language)", ""]}
{"filename": "skllm/models/_base.py", "chunked_list": ["import random\nfrom abc import ABC, abstractmethod\nfrom collections import Counter\nfrom typing import Any, List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom tqdm import tqdm\n", "from tqdm import tqdm\n\nfrom skllm.completions import get_chat_completion\nfrom skllm.openai.chatgpt import construct_message\nfrom skllm.openai.mixin import OpenAIMixin as _OAIMixin\nfrom skllm.utils import extract_json_key\nfrom skllm.utils import to_numpy as _to_numpy\n\n\nclass BaseClassifier(ABC, BaseEstimator, ClassifierMixin):\n    default_label: Optional[str] = \"Random\"\n\n    def _to_np(self, X):\n        \"\"\"Converts X to a numpy array.\n\n        Parameters\n        ----------\n        X : Any\n            The input data to convert to a numpy array.\n\n        Returns\n        -------\n        np.ndarray\n            The input data as a numpy array.\n        \"\"\"\n        return _to_numpy(X)\n\n    @abstractmethod\n    def _predict_single(self, x: str) -> Any:\n        \"\"\"Predicts the class of a single input.\"\"\"\n        pass\n\n    def fit(\n        self,\n        X: Optional[Union[np.ndarray, pd.Series, List[str]]],\n        y: Union[np.ndarray, pd.Series, List[str], List[List[str]]],\n    ):\n        \"\"\"Extracts the target for each datapoint in X.\n\n        Parameters\n        ----------\n        X : Optional[Union[np.ndarray, pd.Series, List[str]]]\n            The input array data to fit the model to.\n\n        y : Union[np.ndarray, pd.Series, List[str], List[List[str]]]\n            The target array data to fit the model to.\n        \"\"\"\n        X = self._to_np(X)\n        self.classes_, self.probabilities_ = self._get_unique_targets(y)\n        return self\n\n    def predict(self, X: Union[np.ndarray, pd.Series, List[str]]):\n        \"\"\"Predicts the class of each input.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n            The input data to predict the class of.\n\n        Returns\n        -------\n        List[str]\n        \"\"\"\n        X = self._to_np(X)\n        predictions = []\n        for i in tqdm(range(len(X))):\n            predictions.append(self._predict_single(X[i]))\n        return predictions\n\n    def _get_unique_targets(self, y: Any):\n        labels = self._extract_labels(y)\n\n        counts = Counter(labels)\n\n        total = sum(counts.values())\n\n        classes, probs = [], []\n        for l, c in counts.items():\n            classes.append(l)\n            probs.append(c / total)\n\n        return classes, probs\n\n    def _extract_labels(self, y: Any) -> List[str]:\n        \"\"\"Return the class labels as a list.\n\n        Parameters\n        ----------\n        y : Any\n\n        Returns\n        -------\n        List[str]\n        \"\"\"\n        if isinstance(y, (pd.Series, np.ndarray)):\n            labels = y.tolist()\n        else:\n            labels = y\n        return labels\n\n    def _get_default_label(self):\n        \"\"\"Returns the default label based on the default_label argument.\"\"\"\n        if self.default_label == \"Random\":\n            return random.choices(self.classes_, self.probabilities_)[0]\n        else:\n            return self.default_label", "\nclass BaseClassifier(ABC, BaseEstimator, ClassifierMixin):\n    default_label: Optional[str] = \"Random\"\n\n    def _to_np(self, X):\n        \"\"\"Converts X to a numpy array.\n\n        Parameters\n        ----------\n        X : Any\n            The input data to convert to a numpy array.\n\n        Returns\n        -------\n        np.ndarray\n            The input data as a numpy array.\n        \"\"\"\n        return _to_numpy(X)\n\n    @abstractmethod\n    def _predict_single(self, x: str) -> Any:\n        \"\"\"Predicts the class of a single input.\"\"\"\n        pass\n\n    def fit(\n        self,\n        X: Optional[Union[np.ndarray, pd.Series, List[str]]],\n        y: Union[np.ndarray, pd.Series, List[str], List[List[str]]],\n    ):\n        \"\"\"Extracts the target for each datapoint in X.\n\n        Parameters\n        ----------\n        X : Optional[Union[np.ndarray, pd.Series, List[str]]]\n            The input array data to fit the model to.\n\n        y : Union[np.ndarray, pd.Series, List[str], List[List[str]]]\n            The target array data to fit the model to.\n        \"\"\"\n        X = self._to_np(X)\n        self.classes_, self.probabilities_ = self._get_unique_targets(y)\n        return self\n\n    def predict(self, X: Union[np.ndarray, pd.Series, List[str]]):\n        \"\"\"Predicts the class of each input.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n            The input data to predict the class of.\n\n        Returns\n        -------\n        List[str]\n        \"\"\"\n        X = self._to_np(X)\n        predictions = []\n        for i in tqdm(range(len(X))):\n            predictions.append(self._predict_single(X[i]))\n        return predictions\n\n    def _get_unique_targets(self, y: Any):\n        labels = self._extract_labels(y)\n\n        counts = Counter(labels)\n\n        total = sum(counts.values())\n\n        classes, probs = [], []\n        for l, c in counts.items():\n            classes.append(l)\n            probs.append(c / total)\n\n        return classes, probs\n\n    def _extract_labels(self, y: Any) -> List[str]:\n        \"\"\"Return the class labels as a list.\n\n        Parameters\n        ----------\n        y : Any\n\n        Returns\n        -------\n        List[str]\n        \"\"\"\n        if isinstance(y, (pd.Series, np.ndarray)):\n            labels = y.tolist()\n        else:\n            labels = y\n        return labels\n\n    def _get_default_label(self):\n        \"\"\"Returns the default label based on the default_label argument.\"\"\"\n        if self.default_label == \"Random\":\n            return random.choices(self.classes_, self.probabilities_)[0]\n        else:\n            return self.default_label", "\n\nclass _BaseZeroShotGPTClassifier(BaseClassifier, _OAIMixin):\n    \"\"\"Base class for zero-shot classifiers.\n\n    Parameters\n    ----------\n    openai_key : Optional[str] , default : None\n        Your OpenAI API key. If None, the key will be read from the SKLLM_CONFIG_OPENAI_KEY environment variable.\n    openai_org : Optional[str] , default : None\n        Your OpenAI organization. If None, the organization will be read from the SKLLM_CONFIG_OPENAI_ORG\n         environment variable.\n    openai_model : str , default : \"gpt-3.5-turbo\"\n        The OpenAI model to use. See https://beta.openai.com/docs/api-reference/available-models for a list of\n        available models.\n    default_label : Optional[Union[List[str], str]] , default : 'Random'\n        The default label to use if the LLM could not generate a response for a sample. If set to 'Random' a random\n        label will be chosen based on probabilities from the training set.\n    \"\"\"\n\n    def __init__(\n        self,\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n        openai_model: str = \"gpt-3.5-turbo\",\n        default_label: Optional[Union[List[str], str]] = \"Random\",\n    ):\n        self._set_keys(openai_key, openai_org)\n        self.openai_model = openai_model\n        self.default_label = default_label\n\n    @abstractmethod\n    def _get_prompt(self, x: str) -> str:\n        \"\"\"Generates a prompt for the given input.\"\"\"\n        pass\n\n    def _get_chat_completion(self, x):\n        prompt = self._get_prompt(x)\n        msgs = []\n        msgs.append(construct_message(\"system\", \"You are a text classification model.\"))\n        msgs.append(construct_message(\"user\", prompt))\n        completion = get_chat_completion(\n            msgs, self._get_openai_key(), self._get_openai_org(), self.openai_model\n        )\n        return completion\n\n    def _predict_single(self, x):\n        \"\"\"Predicts the labels for a single sample.\n\n        Should work for all (single label) GPT based classifiers.\n        \"\"\"\n        completion = self._get_chat_completion(x)\n        try:\n            label = str(\n                extract_json_key(\n                    completion[\"choices\"][0][\"message\"][\"content\"], \"label\"\n                )\n            )\n        except Exception as e:\n            print(completion)\n            print(f\"Could not extract the label from the completion: {str(e)}\")\n            label = \"\"\n\n        if label not in self.classes_:\n            label = label.replace(\"'\", \"\").replace('\"', \"\")\n            if label not in self.classes_:  # try again\n                label = self._get_default_label()\n        return label", "\n\nclass _BasePaLMClassifier(BaseClassifier):\n    def __init__(self, model: str, default_label: Optional[str] = \"Random\"):\n        self.model = model\n        self.default_label = default_label\n"]}
{"filename": "skllm/models/gpt/gpt_zero_shot_clf.py", "chunked_list": ["import random\nfrom typing import List, Literal, Optional, Union\n\nimport numpy as np\nimport pandas as pd\n\nfrom skllm.models._base import _BaseZeroShotGPTClassifier\nfrom skllm.prompts.builders import (\n    build_zero_shot_prompt_mlc,\n    build_zero_shot_prompt_slc,", "    build_zero_shot_prompt_mlc,\n    build_zero_shot_prompt_slc,\n)\nfrom skllm.utils import extract_json_key\n\n\nclass ZeroShotGPTClassifier(_BaseZeroShotGPTClassifier):\n    \"\"\"Zero-shot classifier for multiclass classification.\n\n    Parameters\n    ----------\n    openai_key : Optional[str] , default : None\n        Your OpenAI API key. If None, the key will be read from the SKLLM_CONFIG_OPENAI_KEY environment variable.\n    openai_org : Optional[str] , default : None\n        Your OpenAI organization. If None, the organization will be read from the SKLLM_CONFIG_OPENAI_ORG\n         environment variable.\n    openai_model : str , default : \"gpt-3.5-turbo\"\n        The OpenAI model to use. See https://beta.openai.com/docs/api-reference/available-models for a list of\n        available models.\n    default_label : Optional[str] , default : 'Random'\n        The default label to use if the LLM could not generate a response for a sample. If set to 'Random' a random\n        label will be chosen based on probabilities from the training set.\n    \"\"\"\n\n    def __init__(\n        self,\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n        openai_model: str = \"gpt-3.5-turbo\",\n        default_label: Optional[str] = \"Random\",\n    ):\n        super().__init__(openai_key, openai_org, openai_model, default_label)\n\n    def _get_prompt(self, x) -> str:\n        return build_zero_shot_prompt_slc(x, repr(self.classes_))\n\n    def fit(\n        self,\n        X: Optional[Union[np.ndarray, pd.Series, List[str]]],\n        y: Union[np.ndarray, pd.Series, List[str]],\n    ):\n        y = self._to_np(y)\n        return super().fit(X, y)", "\n\nclass MultiLabelZeroShotGPTClassifier(_BaseZeroShotGPTClassifier):\n    \"\"\"Zero-shot classifier for multilabel classification.\n\n    Parameters\n    ----------\n    openai_key : Optional[str] , default : None\n        Your OpenAI API key. If None, the key will be read from the SKLLM_CONFIG_OPENAI_KEY environment variable.\n    openai_org : Optional[str] , default : None\n        Your OpenAI organization. If None, the organization will be read from the SKLLM_CONFIG_OPENAI_ORG\n         environment variable.\n    openai_model : str , default : \"gpt-3.5-turbo\"\n        The OpenAI model to use. See https://beta.openai.com/docs/api-reference/available-models for a list of\n        available models.\n    default_label : Optional[Union[List[str], Literal['Random']] , default : 'Random'\n        The default label to use if the LLM could not generate a response for a sample. If set to 'Random' a random\n        label will be chosen based on probabilities from the training set.\n    max_labels : int , default : 3\n        The maximum number of labels to predict for each sample.\n    \"\"\"\n\n    def __init__(\n        self,\n        openai_key: Optional[str] = None,\n        openai_org: Optional[str] = None,\n        openai_model: str = \"gpt-3.5-turbo\",\n        default_label: Optional[Union[List[str], Literal[\"Random\"]]] = \"Random\",\n        max_labels: int = 3,\n    ):\n        super().__init__(openai_key, openai_org, openai_model, default_label)\n        if max_labels < 2:\n            raise ValueError(\"max_labels should be at least 2\")\n        if isinstance(default_label, str) and default_label != \"Random\":\n            raise ValueError(\"default_label should be a list of strings or 'Random'\")\n        self.max_labels = max_labels\n\n    def _extract_labels(self, y) -> List[str]:\n        \"\"\"Extracts the labels into a list.\n\n        Parameters\n        ----------\n        y : Any\n\n        Returns\n        -------\n        List[str]\n        \"\"\"\n        labels = []\n        for l in y:\n            for j in l:\n                labels.append(j)\n        return labels\n\n    def _get_prompt(self, x) -> str:\n        return build_zero_shot_prompt_mlc(x, repr(self.classes_), self.max_labels)\n\n    def _get_default_label(self):\n        \"\"\"Returns the default label based on the default_label argument.\"\"\"\n        result = []\n        if isinstance(self.default_label, str) and self.default_label == \"Random\":\n            for cls, probability in zip(self.classes_, self.probabilities_):\n                coin_flip = random.choices([0, 1], [1 - probability, probability])[0]\n                if coin_flip == 1:\n                    result.append(cls)\n        else:\n            result = self.default_label\n\n        return result\n\n    def _predict_single(self, x):\n        \"\"\"Predicts the labels for a single sample.\"\"\"\n        completion = self._get_chat_completion(x)\n        try:\n            labels = extract_json_key(\n                completion[\"choices\"][0][\"message\"][\"content\"], \"label\"\n            )\n            if not isinstance(labels, list):\n                labels = labels.split(\",\")\n                labels = [l.strip() for l in labels]\n        except Exception as e:\n            print(completion)\n            print(f\"Could not extract the label from the completion: {str(e)}\")\n            labels = []\n\n        labels = list(filter(lambda l: l in self.classes_, labels))\n        if len(labels) == 0:\n            labels = self._get_default_label()\n        if labels is not None and len(labels) > self.max_labels:\n            labels = labels[: self.max_labels - 1]\n        return labels\n\n    def fit(\n        self,\n        X: Optional[Union[np.ndarray, pd.Series, List[str]]],\n        y: List[List[str]],\n    ):\n        \"\"\"Calls the parent fit method on input data.\n\n        Parameters\n        ----------\n        X : Optional[Union[np.ndarray, pd.Series, List[str]]]\n            Input array data\n        y : List[List[str]]\n            The labels.\n        \"\"\"\n        return super().fit(X, y)", ""]}
{"filename": "skllm/models/gpt/gpt_dyn_few_shot_clf.py", "chunked_list": ["from __future__ import annotations\n\nimport numpy as np\nimport pandas as pd\n\nfrom skllm.memory import AnnoyMemoryIndex\nfrom skllm.models._base import _BaseZeroShotGPTClassifier\nfrom skllm.preprocessing import GPTVectorizer\nfrom skllm.prompts.builders import build_few_shot_prompt_slc\nfrom skllm.utils import to_numpy", "from skllm.prompts.builders import build_few_shot_prompt_slc\nfrom skllm.utils import to_numpy\n\n_TRAINING_SAMPLE_PROMPT_TEMPLATE = \"\"\"\nSample input:\n```{x}```\n\nSample target: {label}\n\"\"\"\n", "\"\"\"\n\n\nclass DynamicFewShotGPTClassifier(_BaseZeroShotGPTClassifier):\n    \"\"\"Dynamic few-shot single-label classifier.\n\n    Parameters\n    ----------\n    n_examples : int, optional\n        number of examples per class, by default 3\n    openai_key : Optional[str] , default : None\n        Your OpenAI API key. If None, the key will be read from the SKLLM_CONFIG_OPENAI_KEY environment variable.\n    openai_org : Optional[str] , default : None\n        Your OpenAI organization. If None, the organization will be read from the SKLLM_CONFIG_OPENAI_ORG\n        environment variable.\n    openai_model : str , default : \"gpt-3.5-turbo\"\n        The OpenAI model to use. See https://beta.openai.com/docs/api-reference/available-models for a list of\n        available models.\n    default_label : Optional[Union[List[str], str]] , default : 'Random'\n        The default label to use if the LLM could not generate a response for a sample. If set to 'Random' a random\n        label will be chosen based on probabilities from the training set.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_examples: int = 3,\n        openai_key: str | None = None,\n        openai_org: str | None = None,\n        openai_model: str = \"gpt-3.5-turbo\",\n        default_label: str | None = \"Random\",\n    ):\n        super().__init__(openai_key, openai_org, openai_model, default_label)\n        self.n_examples = n_examples\n\n    def fit(\n        self,\n        X: np.ndarray | pd.Series | list[str],\n        y: np.ndarray | pd.Series | list[str],\n    ) -> DynamicFewShotGPTClassifier:\n        \"\"\"Fits the model to the given data.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n            training data\n        y : Union[np.ndarray, pd.Series, List[str]]\n            training labels\n\n        Returns\n        -------\n        DynamicFewShotGPTClassifier\n            self\n        \"\"\"\n        X = to_numpy(X)\n        y = to_numpy(y)\n        self.embedding_model_ = GPTVectorizer().fit(X)\n        self.classes_, self.probabilities_ = self._get_unique_targets(y)\n\n        self.data_ = {}\n        for cls in self.classes_:\n            print(f\"Building index for class `{cls}` ...\")\n            self.data_[cls] = {}\n            partition = X[y == cls]\n            self.data_[cls][\"partition\"] = partition\n            embeddings = self.embedding_model_.transform(partition)\n            index = AnnoyMemoryIndex(embeddings.shape[1])\n            for i, embedding in enumerate(embeddings):\n                index.add(i, embedding)\n            index.build()\n            self.data_[cls][\"index\"] = index\n\n        return self\n\n    def _get_prompt(self, x: str) -> str:\n        \"\"\"Generates the prompt for the given input.\n\n        Parameters\n        ----------\n        x : str\n            sample to classify\n\n        Returns\n        -------\n        str\n            final prompt\n        \"\"\"\n        embedding = self.embedding_model_.transform([x])\n        training_data = []\n        for cls in self.classes_:\n            index = self.data_[cls][\"index\"]\n            partition = self.data_[cls][\"partition\"]\n            neighbors = index.retrieve(embedding, min(self.n_examples, len(partition)))\n            neighbors = [partition[i] for i in neighbors[0]]\n            training_data.extend(\n                [\n                    _TRAINING_SAMPLE_PROMPT_TEMPLATE.format(x=neighbor, label=cls)\n                    for neighbor in neighbors\n                ]\n            )\n\n        training_data_str = \"\\n\".join(training_data)\n\n        return build_few_shot_prompt_slc(\n            x=x, training_data=training_data_str, labels=repr(self.classes_)\n        )", ""]}
{"filename": "skllm/models/gpt/__init__.py", "chunked_list": ["from skllm.models.gpt.gpt_dyn_few_shot_clf import DynamicFewShotGPTClassifier\nfrom skllm.models.gpt.gpt_few_shot_clf import FewShotGPTClassifier\nfrom skllm.models.gpt.gpt_zero_shot_clf import (\n    ZeroShotGPTClassifier,\n    MultiLabelZeroShotGPTClassifier,\n)\n"]}
{"filename": "skllm/models/gpt/gpt_few_shot_clf.py", "chunked_list": ["from typing import List, Union\n\nimport numpy as np\nimport pandas as pd\n\nfrom skllm.models._base import _BaseZeroShotGPTClassifier\nfrom skllm.prompts.builders import build_few_shot_prompt_slc\nfrom skllm.utils import to_numpy as _to_numpy\n\n_TRAINING_SAMPLE_PROMPT_TEMPLATE = \"\"\"", "\n_TRAINING_SAMPLE_PROMPT_TEMPLATE = \"\"\"\nSample input:\n```{x}```\n\nSample target: {label}\n\"\"\"\n\n\nclass FewShotGPTClassifier(_BaseZeroShotGPTClassifier):\n    \"\"\"Few-shot single-label classifier.\"\"\"\n\n    def fit(\n        self,\n        X: Union[np.ndarray, pd.Series, List[str]],\n        y: Union[np.ndarray, pd.Series, List[str]],\n    ):\n        \"\"\"Fits the model to the given data.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n            training data\n        y : Union[np.ndarray, pd.Series, List[str]]\n            training labels\n\n        Returns\n        -------\n        FewShotGPTClassifier\n            self\n        \"\"\"\n        if not len(X) == len(y):\n            raise ValueError(\"X and y must have the same length.\")\n        X = _to_numpy(X)\n        y = _to_numpy(y)\n        self.training_data_ = (X, y)\n        self.classes_, self.probabilities_ = self._get_unique_targets(y)\n        return self\n\n    def _get_prompt(self, x: str) -> str:\n        \"\"\"Generates the prompt for the given input.\n\n        Parameters\n        ----------\n        x : str\n            sample to classify\n\n        Returns\n        -------\n        str\n            final prompt\n        \"\"\"\n        training_data = []\n        for xt, yt in zip(*self.training_data_):\n            training_data.append(\n                _TRAINING_SAMPLE_PROMPT_TEMPLATE.format(x=xt, label=yt)\n            )\n\n        training_data_str = \"\\n\".join(training_data)\n\n        return build_few_shot_prompt_slc(\n            x=x, training_data=training_data_str, labels=repr(self.classes_)\n        )", "\nclass FewShotGPTClassifier(_BaseZeroShotGPTClassifier):\n    \"\"\"Few-shot single-label classifier.\"\"\"\n\n    def fit(\n        self,\n        X: Union[np.ndarray, pd.Series, List[str]],\n        y: Union[np.ndarray, pd.Series, List[str]],\n    ):\n        \"\"\"Fits the model to the given data.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n            training data\n        y : Union[np.ndarray, pd.Series, List[str]]\n            training labels\n\n        Returns\n        -------\n        FewShotGPTClassifier\n            self\n        \"\"\"\n        if not len(X) == len(y):\n            raise ValueError(\"X and y must have the same length.\")\n        X = _to_numpy(X)\n        y = _to_numpy(y)\n        self.training_data_ = (X, y)\n        self.classes_, self.probabilities_ = self._get_unique_targets(y)\n        return self\n\n    def _get_prompt(self, x: str) -> str:\n        \"\"\"Generates the prompt for the given input.\n\n        Parameters\n        ----------\n        x : str\n            sample to classify\n\n        Returns\n        -------\n        str\n            final prompt\n        \"\"\"\n        training_data = []\n        for xt, yt in zip(*self.training_data_):\n            training_data.append(\n                _TRAINING_SAMPLE_PROMPT_TEMPLATE.format(x=xt, label=yt)\n            )\n\n        training_data_str = \"\\n\".join(training_data)\n\n        return build_few_shot_prompt_slc(\n            x=x, training_data=training_data_str, labels=repr(self.classes_)\n        )", ""]}
{"filename": "skllm/models/palm/palm_clf.py", "chunked_list": ["from typing import List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\n\nfrom skllm.google.completions import get_completion, get_completion_chat_mode\nfrom skllm.google.tuning import tune\nfrom skllm.models._base import _BasePaLMClassifier\nfrom skllm.prompts.builders import build_zero_shot_prompt_slc\nfrom skllm.utils import extract_json_key", "from skllm.prompts.builders import build_zero_shot_prompt_slc\nfrom skllm.utils import extract_json_key\n\n_SHORT_PROMPT = \"\"\"\nClassify the following text into one of the following classes: {labels}.\nText: ```{x}```\n\"\"\"\n\n\nclass ZeroShotPaLMClassifier(_BasePaLMClassifier):\n    \"\"\"Google PaLM zero-shot classifier for single-label classification.\n\n    Parameters\n    ----------\n    model : str\n        The name of the model to use. Must be one of the models supported by google. Defaults to \"text-bison@001\".\n    default_label : str, optional\n        The default label to use if the model does not return a valid label. Defaults to \"Random\".\n    \"\"\"\n\n    def __init__(\n        self, model: str = \"text-bison@001\", default_label: Optional[str] = \"Random\"\n    ) -> None:\n        super().__init__(model, default_label)\n\n    def _predict_single(self, x: str) -> str:\n        \"\"\"Predicts the class of a single input.\"\"\"\n        input_ = self._get_prompt(x)\n        if self.model.startswith(\"chat-\"):\n            context = \"You are a text classification model.\"\n            completion = get_completion_chat_mode(self.model, context, input_)\n        else:\n            completion = get_completion(self.model, input_)\n        try:\n            label = str(extract_json_key(str(completion), \"label\"))\n        except Exception as e:\n            print(completion)\n            print(f\"Could not extract the label from the completion: {str(e)}\")\n            label = \"\"\n\n        if label not in self.classes_:\n            label = label.replace(\"'\", \"\").replace('\"', \"\")\n            if label not in self.classes_:  # try again\n                label = self._get_default_label()\n        return label\n\n    def _get_prompt(self, x) -> str:\n        return build_zero_shot_prompt_slc(x, repr(self.classes_))", "\nclass ZeroShotPaLMClassifier(_BasePaLMClassifier):\n    \"\"\"Google PaLM zero-shot classifier for single-label classification.\n\n    Parameters\n    ----------\n    model : str\n        The name of the model to use. Must be one of the models supported by google. Defaults to \"text-bison@001\".\n    default_label : str, optional\n        The default label to use if the model does not return a valid label. Defaults to \"Random\".\n    \"\"\"\n\n    def __init__(\n        self, model: str = \"text-bison@001\", default_label: Optional[str] = \"Random\"\n    ) -> None:\n        super().__init__(model, default_label)\n\n    def _predict_single(self, x: str) -> str:\n        \"\"\"Predicts the class of a single input.\"\"\"\n        input_ = self._get_prompt(x)\n        if self.model.startswith(\"chat-\"):\n            context = \"You are a text classification model.\"\n            completion = get_completion_chat_mode(self.model, context, input_)\n        else:\n            completion = get_completion(self.model, input_)\n        try:\n            label = str(extract_json_key(str(completion), \"label\"))\n        except Exception as e:\n            print(completion)\n            print(f\"Could not extract the label from the completion: {str(e)}\")\n            label = \"\"\n\n        if label not in self.classes_:\n            label = label.replace(\"'\", \"\").replace('\"', \"\")\n            if label not in self.classes_:  # try again\n                label = self._get_default_label()\n        return label\n\n    def _get_prompt(self, x) -> str:\n        return build_zero_shot_prompt_slc(x, repr(self.classes_))", "\n\nclass PaLMClassifier(_BasePaLMClassifier):\n    \"\"\"Tunable Google PaLM classifier for single-label classification.\n\n    Parameters\n    ----------\n    model : str\n        The name of the model to use. Must be one of the models supported by google. Defaults to \"text-bison@001\".\n    n_update_steps : int, optional\n        The number of update steps to use when tuning the model. Defaults to 1.\n    default_label : str, optional\n        The default label to use if the model does not return a valid label. Defaults to \"Random\".\n    \"\"\"\n\n    _supported_models = [\"text-bison@001\"]\n\n    def __init__(\n        self,\n        model=\"text-bison@001\",\n        n_update_steps: int = 1,\n        default_label: Optional[str] = \"Random\",\n    ) -> None:\n        super().__init__(model, default_label)\n        if model not in self._supported_models:\n            raise ValueError(\n                f\"Model {model} not supported. Supported models:\"\n                f\" {self._supported_models}\"\n            )\n        self.n_update_steps = int(n_update_steps)\n        self.default_label = default_label\n\n    def fit(\n        self,\n        X: Union[np.ndarray, pd.Series, List[str]],\n        y: Union[np.ndarray, pd.Series, List[str]],\n    ):\n        \"\"\"Fits the model to the data.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n            Inputs\n        y : Union[np.ndarray, pd.Series, List[str]]\n            Targets\n        \"\"\"\n        X = self._to_np(X)\n        y = self._to_np(y)\n        if len(X) != len(y):\n            raise ValueError(\n                f\"X and y must be the same length. Got {len(X)} and {len(y)}\"\n            )\n        if len(X) < 10:\n            raise ValueError(\n                f\"The dataset must have at least 10 datapoints. Got {len(X)}.\"\n            )\n        self.classes_, self.probabilities_ = self._get_unique_targets(y)\n        inputs = np.asarray(\n            [\n                build_zero_shot_prompt_slc(x, repr(self.classes_), _SHORT_PROMPT)\n                for x in X\n            ],\n            dtype=str,\n        )\n        df = pd.DataFrame({\"input_text\": inputs, \"output_text\": y})\n        job = tune(self.model, df, self.n_update_steps)._job\n        tuned_model = job.result()\n        self.tuned_model_ = tuned_model._model_resource_name\n        return self\n\n    def _predict_single(self, x: str) -> str:\n        input_ = self._get_prompt(x)\n\n        label = str(get_completion(self.tuned_model_, input_))\n\n        if label not in self.classes_:\n            label = label.replace(\"'\", \"\").replace('\"', \"\")\n            if label not in self.classes_:  # try again\n                label = self._get_default_label()\n\n        return label\n\n    def _get_prompt(self, x: str) -> str:\n        return build_zero_shot_prompt_slc(x, repr(self.classes_), _SHORT_PROMPT)", ""]}
{"filename": "skllm/models/palm/__init__.py", "chunked_list": ["from skllm.models.palm.palm_clf import ZeroShotPaLMClassifier, PaLMClassifier\nfrom skllm.models.palm.palm_est import PaLM\n"]}
{"filename": "skllm/models/palm/palm_est.py", "chunked_list": ["from typing import List, Union\n\nimport numpy as np\nimport pandas as pd\n\nfrom skllm.google.completions import get_completion\nfrom skllm.google.tuning import tune\nfrom skllm.models._base import _BasePaLMClassifier\n\n", "\n\n# This is not a classifier, but inherits from the base classifier anyway for simplicity reasons.\nclass PaLM(_BasePaLMClassifier):\n    \"\"\"Google PaLM for single-label classification.\n\n    Parameters\n    ----------\n    model : str\n        The name of the model to use. Must be one of the models supported by google. Defaults to \"text-bison@001\".\n    n_update_steps : int, optional\n        The number of update steps to perform during tuning. Defaults to 1.\n    \"\"\"\n\n    _supported_models = [\"text-bison@001\"]\n\n    def __init__(self, model=\"text-bison@001\", n_update_steps: int = 1) -> None:\n        super().__init__(model, default_label=None)\n        if model not in self._supported_models:\n            raise ValueError(\n                f\"Model {model} not supported. Supported models:\"\n                f\" {self._supported_models}\"\n            )\n        self.n_update_steps = int(n_update_steps)\n\n    def fit(\n        self,\n        X: Union[np.ndarray, pd.Series, List[str]],\n        y: Union[np.ndarray, pd.Series, List[str]],\n    ):\n        \"\"\"Fits the model to the data.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n            Inputs\n        y : Union[np.ndarray, pd.Series, List[str]]\n            Targets\n        \"\"\"\n        X = self._to_np(X)\n        y = self._to_np(y)\n        if len(X) != len(y):\n            raise ValueError(\n                f\"X and y must be the same length. Got {len(X)} and {len(y)}\"\n            )\n        if len(X) < 10:\n            raise ValueError(\n                f\"The dataset must have at least 10 datapoints. Got {len(X)}.\"\n            )\n        df = pd.DataFrame({\"input_text\": X, \"output_text\": y})\n        job = tune(self.model, df, self.n_update_steps)._job\n        tuned_model = job.result()\n        self.tuned_model_ = tuned_model._model_resource_name\n        return self\n\n    def _predict_single(self, x: str) -> str:\n        label = str(get_completion(self.tuned_model_, x))\n        return label\n\n    def _get_prompt(self, x: str) -> str:\n        \"\"\"For compatibility with the parent class.\"\"\"\n        return x", ""]}
{"filename": "skllm/datasets/multi_label.py", "chunked_list": ["def get_multilabel_classification_dataset():\n    X = [\n    \"The product was of excellent quality, and the packaging was also very good. Highly recommend!\",\n    \"The delivery was super fast, but the product did not match the information provided on the website.\",\n    \"Great variety of products, but the customer support was quite unresponsive.\",\n    \"Affordable prices and an easy-to-use website. A great shopping experience overall.\",\n    \"The delivery was delayed, and the packaging was damaged. Not a good experience.\",\n    \"Excellent customer support, but the return policy is quite complicated.\",\n    \"The product was not as described. However, the return process was easy and quick.\",\n    \"Great service and fast delivery. The product was also of high quality.\",\n    \"The prices are a bit high. However, the product quality and user experience are worth it.\",\n    \"The website provides detailed information about products. The delivery was also very fast.\"\n    ]\n\n    y = [\n        [\"Quality\", \"Packaging\"],\n        [\"Delivery\", \"Product Information\"],\n        [\"Product Variety\", \"Customer Support\"],\n        [\"Price\", \"User Experience\"],\n        [\"Delivery\", \"Packaging\"],\n        [\"Customer Support\", \"Return Policy\"],\n        [\"Product Information\", \"Return Policy\"],\n        [\"Service\", \"Delivery\", \"Quality\"],\n        [\"Price\", \"Quality\", \"User Experience\"],\n        [\"Product Information\", \"Delivery\"],\n    ]\n\n    return X, y"]}
{"filename": "skllm/datasets/__init__.py", "chunked_list": ["from skllm.datasets.multi_class import get_classification_dataset\nfrom skllm.datasets.multi_label import get_multilabel_classification_dataset\nfrom skllm.datasets.summarization import get_summarization_dataset\nfrom skllm.datasets.translation import get_translation_dataset\n"]}
{"filename": "skllm/datasets/summarization.py", "chunked_list": ["def get_summarization_dataset():\n    X = [\n    r\"The AI research company, OpenAI, has launched a new language model called GPT-4. This model is the latest in a series of transformer-based AI systems designed to perform complex tasks, such as generating human-like text, translating languages, and answering questions. According to OpenAI, GPT-4 is even more powerful and versatile than its predecessors.\",\n    r\"John went to the grocery store in the morning to prepare for a small get-together at his house. He bought fresh apples, juicy oranges, and a bottle of milk. Once back home, he used the apples and oranges to make a delicious fruit salad, which he served to his guests in the evening.\",\n    r\"The first Mars rover, named Sojourner, was launched by NASA in 1996. The mission was a part of the Mars Pathfinder project and was a major success. The data Sojourner provided about Martian terrain and atmosphere greatly contributed to our understanding of the Red Planet.\",\n    r\"A new study suggests that regular exercise can improve memory and cognitive function in older adults. The study, which monitored the health and habits of 500 older adults, recommends 30 minutes of moderate exercise daily for the best results.\",\n    r\"The Eiffel Tower, a globally recognized symbol of Paris and France, was completed in 1889 for the World's Fair. Despite its initial criticism and controversy over its unconventional design, the Eiffel Tower has become a beloved landmark and a symbol of French architectural innovation.\",\n    r\"Microsoft has announced a new version of its flagship operating system, Windows. The update, which will be rolled out later this year, features improved security protocols and a redesigned user interface, promising a more streamlined and safer user experience.\",\n    r\"The WHO declared a new public health emergency due to an outbreak of a previously unknown virus. As the number of cases grows globally, the organization urges nations to ramp up their disease surveillance and response systems.\",\n    r\"The 2024 Olympics have been confirmed to take place in Paris, France. This marks the third time the city will host the games, with previous occasions in 1900 and 1924. Preparations are already underway to make the event a grand spectacle.\",\n    r\"Apple has introduced its latest iPhone model. The new device boasts a range of features, including an improved camera system, a faster processor, and a longer battery life. It is set to hit the market later this year.\",\n    r\"Scientists working in the Amazon rainforest have discovered a new species of bird. The bird, characterized by its unique bright plumage, has created excitement among the global ornithological community.\"\n    ]\n\n    return X"]}
{"filename": "skllm/datasets/multi_class.py", "chunked_list": ["def get_classification_dataset():\n    X = [\n        r\"I was absolutely blown away by the performances in 'Summer's End'. The acting was top-notch, and the plot had me gripped from start to finish. A truly captivating cinematic experience that I would highly recommend.\",\n        r\"The special effects in 'Star Battles: Nebula Conflict' were out of this world. I felt like I was actually in space. The storyline was incredibly engaging and left me wanting more. Excellent film.\",\n        r\"'The Lost Symphony' was a masterclass in character development and storytelling. The score was hauntingly beautiful and complimented the intense, emotional scenes perfectly. Kudos to the director and cast for creating such a masterpiece.\",\n        r\"I was pleasantly surprised by 'Love in the Time of Cholera'. The romantic storyline was heartwarming and the characters were incredibly realistic. The cinematography was also top-notch. A must-watch for all romance lovers.\",\n        r\"I went into 'Marble Street' with low expectations, but I was pleasantly surprised. The suspense was well-maintained throughout, and the twist at the end was something I did not see coming. Bravo!\",\n        r\"'The Great Plains' is a touching portrayal of life in rural America. The performances were heartfelt and the scenery was breathtaking. I was moved to tears by the end. It's a story that will stay with me for a long time.\",\n        r\"The screenwriting in 'Under the Willow Tree' was superb. The dialogue felt real and the characters were well-rounded. The performances were also fantastic. I haven't enjoyed a movie this much in a while.\",\n        r\"'Nightshade' is a brilliant take on the superhero genre. The protagonist was relatable and the villain was genuinely scary. The action sequences were thrilling and the storyline was engaging. I can't wait for the sequel.\",\n        r\"The cinematography in 'Awakening' was nothing short of spectacular. The visuals alone are worth the ticket price. The storyline was unique and the performances were solid. An overall fantastic film.\",\n        r\"'Eternal Embers' was a cinematic delight. The storytelling was original and the performances were exceptional. The director's vision was truly brought to life on the big screen. A must-see for all movie lovers.\",\n        r\"I was thoroughly disappointed with 'Silver Shadows'. The plot was confusing and the performances were lackluster. I wouldn't recommend wasting your time on this one.\",\n        r\"'The Darkened Path' was a disaster. The storyline was unoriginal, the acting was wooden and the special effects were laughably bad. Save your money and skip this one.\",\n        r\"I had high hopes for 'The Final Frontier', but it failed to deliver. The plot was full of holes and the characters were poorly developed. It was a disappointing experience.\",\n        r\"'The Fall of the Phoenix' was a letdown. The storyline was confusing and the characters were one-dimensional. I found myself checking my watch multiple times throughout the movie.\",\n        r\"I regret wasting my time on 'Emerald City'. The plot was nonsensical and the performances were uninspired. It was a major disappointment.\",\n        r\"I found 'Hollow Echoes' to be a complete mess. The plot was non-existent, the performances were overdone, and the pacing was all over the place. Definitely not worth the hype.\",\n        r\"'Underneath the Stars' was a huge disappointment. The storyline was predictable and the acting was mediocre at best. I was expecting so much more.\",\n        r\"I was left unimpressed by 'River's Edge'. The plot was convoluted, the characters were uninteresting, and the ending was unsatisfying. It's a pass for me.\",\n        r\"The acting in 'Desert Mirage' was subpar, and the plot was boring. I found myself yawning multiple times throughout the movie. Save your time and skip this one.\",\n        r\"'Crimson Dawn' was a major letdown. The plot was cliched and the characters were flat. The special effects were also poorly executed. I wouldn't recommend it.\",\n        r\"'Remember the Days' was utterly forgettable. The storyline was dull, the performances were bland, and the dialogue was cringeworthy. A big disappointment.\",\n        r\"'The Last Frontier' was simply okay. The plot was decent and the performances were acceptable. However, it lacked a certain spark to make it truly memorable.\",\n        r\"'Through the Storm' was not bad, but it wasn't great either. The storyline was somewhat predictable, and the characters were somewhat stereotypical. It was an average movie at best.\",\n        r\"I found 'After the Rain' to be pretty average. The plot was okay and the performances were decent, but it didn't leave a lasting impression on me.\",\n        r\"'Beyond the Horizon' was neither good nor bad. The plot was interesting enough, but the characters were not very well developed. It was an okay watch.\",\n        r\"'The Silent Echo' was a mediocre movie. The storyline was passable and the performances were fair, but it didn't stand out in any way.\",\n        r\"I thought 'The Scent of Roses' was pretty average. The plot was somewhat engaging, and the performances were okay, but it didn't live up to my expectations.\",\n        r\"'Under the Same Sky' was an okay movie. The plot was decent, and the performances were fine, but it lacked depth and originality. It's not a movie I would watch again.\",\n        r\"'Chasing Shadows' was fairly average. The plot was not bad, and the performances were passable, but it lacked a certain spark. It was just okay.\",\n        r\"'Beneath the Surface' was pretty run-of-the-mill. The plot was decent, the performances were okay, but it wasn't particularly memorable. It was an okay movie.\",\n    ]\n\n\n    y = (\n        [\"positive\" for _ in range(10)]\n        + [\"negative\" for _ in range(10)]\n        + [\"neutral\" for _ in range(10)]\n    )\n\n    return X, y"]}
{"filename": "skllm/datasets/translation.py", "chunked_list": ["def get_translation_dataset():\n    X = [\n        r\"Me encanta bailar salsa y bachata. Es una forma divertida de expresarme.\",\n        r\"J'ai pass\u00e9 mes derni\u00e8res vacances en Gr\u00e8ce. Les plages \u00e9taient magnifiques.\",\n        (\n            r\"Ich habe gestern ein tolles Buch gelesen. Die Geschichte war fesselnd bis\"\n            r\" zum Ende.\"\n        ),\n        (\n            r\"Gosto de cozinhar pratos tradicionais italianos. O espaguete \u00e0 carbonara\"\n            r\" \u00e9 um dos meus favoritos.\"\n        ),\n        (\n            r\"M\u00e1m v pl\u00e1nu letos v l\u00e9t\u011b vyrazit na v\u00fdlet do It\u00e1lie. Douf\u00e1m, \u017ee nav\u0161t\u00edv\u00edm\"\n            r\" \u0158\u00edm a Ben\u00e1tky.\"\n        ),\n        (\n            r\"Mijn favoriete hobby is fotograferen. Ik hou ervan om mooie momenten vast\"\n            r\" te leggen.\"\n        ),\n    ]\n\n    return X", ""]}
{"filename": "skllm/openai/base_gpt.py", "chunked_list": ["from __future__ import annotations\n\nfrom typing import Any\n\nimport numpy as np\nimport pandas as pd\nfrom numpy import ndarray\nfrom sklearn.base import BaseEstimator as _BaseEstimator\nfrom sklearn.base import TransformerMixin as _TransformerMixin\nfrom tqdm import tqdm", "from sklearn.base import TransformerMixin as _TransformerMixin\nfrom tqdm import tqdm\n\nfrom skllm.openai.chatgpt import construct_message, get_chat_completion\nfrom skllm.openai.mixin import OpenAIMixin as _OAIMixin\nfrom skllm.utils import to_numpy as _to_numpy\n\n\nclass BaseZeroShotGPTTransformer(_BaseEstimator, _TransformerMixin, _OAIMixin):\n    system_msg = \"You are an scikit-learn transformer.\"\n    default_output = \"Output is unavailable\"\n\n    def _get_chat_completion(self, X):\n        \"\"\"Gets the chat completion for the given input using open ai API.\n\n        Parameters\n        ----------\n        X : str\n            Input string\n\n        Returns\n        -------\n        str\n        \"\"\"\n        prompt = self._get_prompt(X)\n        msgs = []\n        msgs.append(construct_message(\"system\", self.system_msg))\n        msgs.append(construct_message(\"user\", prompt))\n        completion = get_chat_completion(\n            msgs, self._get_openai_key(), self._get_openai_org(), self.openai_model\n        )\n        try:\n            return completion.choices[0].message[\"content\"]\n        except Exception as e:\n            print(f\"Skipping a sample due to the following error: {str(e)}\")\n            return self.default_output\n\n    def fit(\n        self, X: Any = None, y: Any = None, **kwargs: Any\n    ) -> BaseZeroShotGPTTransformer:\n        \"\"\"Fits the model to the data.\n\n        Parameters\n        ----------\n        X : Any, optional\n        y : Any, optional\n        kwargs : dict, optional\n\n        Returns\n        -------\n        self : BaseZeroShotGPTTransformer\n        \"\"\"\n        return self\n\n    def transform(\n        self, X: np.ndarray | pd.Series | list[str], **kwargs: Any\n    ) -> ndarray:\n        \"\"\"Converts a list of strings using the open ai API and a predefined\n        prompt.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n\n        Returns\n        -------\n        ndarray\n        \"\"\"\n        X = _to_numpy(X)\n        transformed = []\n        for i in tqdm(range(len(X))):\n            transformed.append(self._get_chat_completion(X[i]))\n        transformed = np.asarray(transformed, dtype=object)\n        return transformed\n\n    def fit_transform(\n        self, X: np.ndarray | pd.Series | list[str], y=None, **fit_params\n    ) -> ndarray:\n        \"\"\"Fits and transforms a list of strings using the transform method.\n        This is modelled to function as the sklearn fit_transform method.\n\n        Parameters\n        ----------\n        X : np.ndarray, pd.Series, or list\n\n        Returns\n        -------\n        ndarray\n        \"\"\"\n        return self.fit(X, y).transform(X)", "class BaseZeroShotGPTTransformer(_BaseEstimator, _TransformerMixin, _OAIMixin):\n    system_msg = \"You are an scikit-learn transformer.\"\n    default_output = \"Output is unavailable\"\n\n    def _get_chat_completion(self, X):\n        \"\"\"Gets the chat completion for the given input using open ai API.\n\n        Parameters\n        ----------\n        X : str\n            Input string\n\n        Returns\n        -------\n        str\n        \"\"\"\n        prompt = self._get_prompt(X)\n        msgs = []\n        msgs.append(construct_message(\"system\", self.system_msg))\n        msgs.append(construct_message(\"user\", prompt))\n        completion = get_chat_completion(\n            msgs, self._get_openai_key(), self._get_openai_org(), self.openai_model\n        )\n        try:\n            return completion.choices[0].message[\"content\"]\n        except Exception as e:\n            print(f\"Skipping a sample due to the following error: {str(e)}\")\n            return self.default_output\n\n    def fit(\n        self, X: Any = None, y: Any = None, **kwargs: Any\n    ) -> BaseZeroShotGPTTransformer:\n        \"\"\"Fits the model to the data.\n\n        Parameters\n        ----------\n        X : Any, optional\n        y : Any, optional\n        kwargs : dict, optional\n\n        Returns\n        -------\n        self : BaseZeroShotGPTTransformer\n        \"\"\"\n        return self\n\n    def transform(\n        self, X: np.ndarray | pd.Series | list[str], **kwargs: Any\n    ) -> ndarray:\n        \"\"\"Converts a list of strings using the open ai API and a predefined\n        prompt.\n\n        Parameters\n        ----------\n        X : Union[np.ndarray, pd.Series, List[str]]\n\n        Returns\n        -------\n        ndarray\n        \"\"\"\n        X = _to_numpy(X)\n        transformed = []\n        for i in tqdm(range(len(X))):\n            transformed.append(self._get_chat_completion(X[i]))\n        transformed = np.asarray(transformed, dtype=object)\n        return transformed\n\n    def fit_transform(\n        self, X: np.ndarray | pd.Series | list[str], y=None, **fit_params\n    ) -> ndarray:\n        \"\"\"Fits and transforms a list of strings using the transform method.\n        This is modelled to function as the sklearn fit_transform method.\n\n        Parameters\n        ----------\n        X : np.ndarray, pd.Series, or list\n\n        Returns\n        -------\n        ndarray\n        \"\"\"\n        return self.fit(X, y).transform(X)", ""]}
{"filename": "skllm/openai/credentials.py", "chunked_list": ["import openai\n\nfrom skllm.config import SKLLMConfig as _Config\n\n\ndef set_credentials(key: str, org: str) -> None:\n    \"\"\"Set the OpenAI key and organization.\n\n    Parameters\n    ----------\n    key : str\n        The OpenAI key to use.\n    org : str\n        The OPEN AI organization ID to use.\n    \"\"\"\n    openai.api_key = key\n    openai.organization = org\n    openai.api_type = \"open_ai\"\n    openai.api_version = None\n    openai.api_base = \"https://api.openai.com/v1\"", "\n\ndef set_azure_credentials(key: str, org: str) -> None:\n    \"\"\"Sets OpenAI credentials for Azure.\n\n    Parameters\n    ----------\n    key : str\n        The OpenAI (Azure) key to use.\n    org : str\n        The OpenAI (Azure) organization ID to use.\n    \"\"\"\n    if not openai.api_type or not openai.api_type.startswith(\"azure\"):\n        openai.api_type = \"azure\"\n    openai.api_key = key\n    openai.organization = org\n    openai.api_base = _Config.get_azure_api_base()\n    openai.api_version = _Config.get_azure_api_version()"]}
{"filename": "skllm/openai/embeddings.py", "chunked_list": ["from time import sleep\n\nimport openai\n\nfrom skllm.openai.credentials import set_credentials\n\n\ndef get_embedding(\n    text: str, key: str, org: str, model: str=\"text-embedding-ada-002\", max_retries: int=3\n):  \n    \"\"\"\n    Encodes a string and return the embedding for a string.\n\n    Parameters\n    ----------\n    text : str\n        The string to encode.\n    key : str\n        The OPEN AI key to use.\n    org : str\n        The OPEN AI organization ID to use.\n    model : str, optional  \n        The model to use. Defaults to \"text-embedding-ada-002\".\n    max_retries : int, optional\n        The maximum number of retries to use. Defaults to 3.\n    \n    Returns\n    -------\n    emb : list\n        The GPT embedding for the string.\n    \"\"\"\n    set_credentials(key, org)\n    text = text.replace(\"\\n\", \" \")\n    error_msg = None\n    error_type = None\n    for _ in range(max_retries):\n        try:\n            emb = openai.Embedding.create(input=[text], model=model)[\"data\"][0][\n                \"embedding\"\n            ]\n            if not isinstance(emb, list):\n                raise ValueError(f\"Encountered unknown embedding format. Expected list, got {type(emb)}\")\n            return emb\n        except Exception as e:\n            error_msg = str(e)\n            error_type =  type(e).__name__\n            sleep(3)\n    raise RuntimeError(\n        f\"Could not obtain the embedding after {max_retries} retries: `{error_type} :: {error_msg}`\"\n    )", ""]}
{"filename": "skllm/openai/mixin.py", "chunked_list": ["from typing import Optional\n\nfrom skllm.config import SKLLMConfig as _Config\n\n\nclass OpenAIMixin:\n    \"\"\"\n    A mixin class that provides OpenAI key and organization to other classes.\n    \"\"\"\n    def _set_keys(self, key: Optional[str] = None, org: Optional[str] = None) -> None:\n        \"\"\"\n        Set the OpenAI key and organization.\n        \"\"\"\n        self.openai_key = key\n        self.openai_org = org\n\n    def _get_openai_key(self) -> str:\n        \"\"\"\n        Get the OpenAI key from the class or the config file.\n        \n        Returns\n        -------\n        openai_key: str\n        \"\"\"\n        key = self.openai_key\n        if key is None:\n            key = _Config.get_openai_key()\n        if key is None:\n            raise RuntimeError(\"OpenAI key was not found\")\n        return key\n\n    def _get_openai_org(self) -> str:\n        \"\"\"\n        Get the OpenAI organization ID from the class or the config file.\n\n        Returns\n        -------\n        openai_org: str\n        \"\"\"\n        key = self.openai_org\n        if key is None:\n            key = _Config.get_openai_org()\n        if key is None:\n            raise RuntimeError(\"OpenAI organization was not found\")\n        return key", " "]}
{"filename": "skllm/openai/chatgpt.py", "chunked_list": ["from time import sleep\n\nimport openai\n\nfrom skllm.openai.credentials import set_azure_credentials, set_credentials\n\n\ndef construct_message(role: str, content: str) -> dict:\n    \"\"\"Constructs a message for the OpenAI API.\n\n    Parameters\n    ----------\n    role : str\n        The role of the message. Must be one of \"system\", \"user\", or \"assistant\".\n    content : str\n        The content of the message.\n\n    Returns\n    -------\n    message : dict\n    \"\"\"\n    if role not in (\"system\", \"user\", \"assistant\"):\n        raise ValueError(\"Invalid role\")\n    return {\"role\": role, \"content\": content}", "\n\ndef get_chat_completion(\n    messages: dict,\n    key: str,\n    org: str,\n    model: str = \"gpt-3.5-turbo\",\n    max_retries: int = 3,\n    api=\"openai\",\n):\n    \"\"\"Gets a chat completion from the OpenAI API.\n\n    Parameters\n    ----------\n    messages : dict\n        input messages to use.\n    key : str\n        The OPEN AI key to use.\n    org : str\n        The OPEN AI organization ID to use.\n    model : str, optional\n        The OPEN AI model to use. Defaults to \"gpt-3.5-turbo\".\n    max_retries : int, optional\n        The maximum number of retries to use. Defaults to 3.\n    api : str\n        The API to use. Must be one of \"openai\" or \"azure\". Defaults to \"openai\".\n\n    Returns\n    -------\n    completion : dict\n    \"\"\"\n    if api == \"openai\":\n        set_credentials(key, org)\n        model_dict = {\"model\": model}\n    elif api == \"azure\":\n        set_azure_credentials(key, org)\n        model_dict = {\"engine\": model}\n    else:\n        raise ValueError(\"Invalid API\")\n    error_msg = None\n    error_type = None\n    for _ in range(max_retries):\n        try:\n            completion = openai.ChatCompletion.create(\n                temperature=0.0, messages=messages, **model_dict\n            )\n            return completion\n        except Exception as e:\n            error_msg = str(e)\n            error_type = type(e).__name__\n            sleep(3)\n    print(\n        f\"Could not obtain the completion after {max_retries} retries: `{error_type} ::\"\n        f\" {error_msg}`\"\n    )", ""]}
{"filename": "skllm/memory/base.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import Any, List\n\nfrom numpy import ndarray\n\n\nclass _BaseMemoryIndex(ABC):\n    @abstractmethod\n    def add(self, id: Any, vector: ndarray):\n        \"\"\"Adds a vector to the index.\n\n        Parameters\n        ----------\n        id : Any\n            identifier for the vector\n        vector : ndarray\n            vector to add to the index\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def retrieve(self, vectors: ndarray, k: int) -> List:\n        \"\"\"Retrieves the k nearest neighbors for each vector.\n\n        Parameters\n        ----------\n        vectors : ndarray\n            vectors to retrieve nearest neighbors for\n        k : int\n            number of nearest neighbors to retrieve\n\n        Returns\n        -------\n        List\n            ids of retrieved nearest neighbors\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def build(self) -> None:\n        \"\"\"Builds the index.\n\n        All build parameters should be passed to the constructor.\n        \"\"\"\n        pass", ""]}
{"filename": "skllm/memory/_annoy.py", "chunked_list": ["import os\nimport tempfile\nfrom typing import Any, List\n\ntry:\n    from annoy import AnnoyIndex\nexcept (ImportError, ModuleNotFoundError):\n    AnnoyIndex = None\n\nfrom numpy import ndarray", "\nfrom numpy import ndarray\n\nfrom skllm.memory.base import _BaseMemoryIndex\n\n\nclass AnnoyMemoryIndex(_BaseMemoryIndex):\n    \"\"\"Memory index using Annoy.\n\n    Parameters\n    ----------\n    dim : int\n        dimensionality of the vectors\n    metric : str, optional\n        metric to use, by default \"euclidean\"\n    \"\"\"\n\n    def __init__(self, dim: int, metric: str = \"euclidean\", **kwargs: Any) -> None:\n        if AnnoyIndex is None:\n            raise ImportError(\n                \"Annoy is not installed. Please install annoy by running `pip install scikit-llm[annoy]`.\"\n            )\n        self._index = AnnoyIndex(dim, metric)\n        self.metric = metric\n        self.dim = dim\n        self.built = False\n\n    def add(self, id: int, vector: ndarray) -> None:\n        \"\"\"Adds a vector to the index.\n\n        Parameters\n        ----------\n        id : Any\n            identifier for the vector\n        vector : ndarray\n            vector to add to the index\n        \"\"\"\n        if self.built:\n            raise RuntimeError(\"Cannot add vectors after index is built.\")\n        self._index.add_item(id, vector)\n\n    def build(self) -> None:\n        \"\"\"Builds the index.\n\n        No new vectors can be added after building.\n        \"\"\"\n        self._index.build(-1)\n        self.built = True\n\n    def retrieve(self, vectors: ndarray, k: int) -> List[List[int]]:\n        \"\"\"Retrieves the k nearest neighbors for each vector.\n\n        Parameters\n        ----------\n        vectors : ndarray\n            vectors to retrieve nearest neighbors for\n        k : int\n            number of nearest neighbors to retrieve\n\n        Returns\n        -------\n        List\n            ids of retrieved nearest neighbors\n        \"\"\"\n        if not self.built:\n            raise RuntimeError(\"Cannot retrieve vectors before the index is built.\")\n        return [\n            self._index.get_nns_by_vector(v, k, search_k=-1, include_distances=False)\n            for v in vectors\n        ]\n\n    def __getstate__(self) -> dict:\n        \"\"\"Returns the state of the object. To store the actual annoy index, it\n        has to be written to a temporary file.\n\n        Returns\n        -------\n        dict\n            state of the object\n        \"\"\"\n        state = self.__dict__.copy()\n\n        # save index to temporary file\n        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n            temp_filename = tmp.name\n            self._index.save(temp_filename)\n\n        # read bytes from the file\n        with open(temp_filename, \"rb\") as tmp:\n            index_bytes = tmp.read()\n\n        # store bytes representation in state\n        state[\"_index\"] = index_bytes\n\n        # remove temporary file\n        os.remove(temp_filename)\n\n        return state\n\n    def __setstate__(self, state: dict) -> None:\n        \"\"\"Sets the state of the object. It restores the annoy index from the\n        bytes representation.\n\n        Parameters\n        ----------\n        state : dict\n            state of the object\n        \"\"\"\n        self.__dict__.update(state)\n        # restore index from bytes\n        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n            temp_filename = tmp.name\n            tmp.write(self._index)\n\n        self._index = AnnoyIndex(self.dim, self.metric)\n        self._index.load(temp_filename)\n\n        # remove temporary file\n        os.remove(temp_filename)", ""]}
{"filename": "skllm/memory/__init__.py", "chunked_list": ["from skllm.memory._annoy import AnnoyMemoryIndex\n"]}
{"filename": "skllm/google/tuning.py", "chunked_list": ["from pandas import DataFrame\nfrom vertexai.preview.language_models import TextGenerationModel\n\n\ndef tune(model: str, data: DataFrame, train_steps: int = 100):\n    model = TextGenerationModel.from_pretrained(model)\n    model.tune_model(\n        training_data=data,\n        train_steps=train_steps,\n        tuning_job_location=\"europe-west4\",  # the only supported training location atm\n        tuned_model_location=\"us-central1\",  # the only supported deployment location atm\n    )\n    return model  # ._job", ""]}
{"filename": "skllm/google/completions.py", "chunked_list": ["from time import sleep\n\nfrom vertexai.preview.language_models import ChatModel, TextGenerationModel\n\n# TODO reduce code duplication for retrying logic\n\n\ndef get_completion(model: str, text: str, max_retries: int = 3):\n    for _ in range(max_retries):\n        try:\n            if model.startswith(\"text-\"):\n                model = TextGenerationModel.from_pretrained(model)\n            else:\n                model = TextGenerationModel.get_tuned_model(model)\n            response = model.predict(text, temperature=0.0)\n            return response.text\n        except Exception as e:\n            error_msg = str(e)\n            error_type = type(e).__name__\n            sleep(3)\n    print(\n        f\"Could not obtain the completion after {max_retries} retries: `{error_type} ::\"\n        f\" {error_msg}`\"\n    )", "\n\ndef get_completion_chat_mode(model: str, context: str, text: str, max_retries: int = 3):\n    for _ in range(max_retries):\n        try:\n            model = ChatModel.from_pretrained(model)\n            chat = model.start_chat(context=context)\n            response = chat.send_message(text, temperature=0.0)\n            return response.text\n        except Exception as e:\n            error_msg = str(e)\n            error_type = type(e).__name__\n            sleep(3)\n    print(\n        f\"Could not obtain the completion after {max_retries} retries: `{error_type} ::\"\n        f\" {error_msg}`\"\n    )", ""]}
{"filename": "tests/test_gpt_zero_shot_clf.py", "chunked_list": ["import json\nimport random\nimport unittest\nfrom unittest.mock import MagicMock, patch\n\nimport numpy as np\n\nfrom skllm.models.gpt_zero_shot_clf import (\n    MultiLabelZeroShotGPTClassifier,\n    ZeroShotGPTClassifier,", "    MultiLabelZeroShotGPTClassifier,\n    ZeroShotGPTClassifier,\n)\n\n\ndef _get_ret(label):\n    return {\"choices\": [{\"message\": {\"content\": json.dumps({\"label\": label})}}]}\n\n\nclass TestZeroShotGPTClassifier(unittest.TestCase):\n    def get_mock_clf_model(self):\n        clf = ZeroShotGPTClassifier(\n            openai_key=\"mock_key\", openai_org=\"mock_org\"\n        )  # Mock keys\n        X = np.array([\"text1\", \"text2\", \"text3\"])\n        y = np.array([\"class1\", \"class2\", \"class1\"])\n        clf.fit(X, y)\n\n        self.assertEqual(set(clf.classes_), set([\"class1\", \"class2\"]))\n        self.assertEqual(clf.probabilities_, [2 / 3, 1 / 3])\n        return clf\n\n    @patch(\"skllm.models._base.get_chat_completion\", return_value=MagicMock())\n    def test_fit_predict(self, mock_get_chat_completion):\n        clf = self.get_mock_clf_model()\n        mock_get_chat_completion.return_value.choices[0].message = {\n            \"content\": json.dumps({\"label\": \"class1\"})\n        }\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n\n        self.assertEqual(predictions, [\"class1\", \"class1\", \"class1\"])\n\n    @patch(\"skllm.models._base.get_chat_completion\", return_value=MagicMock())\n    def test_fit_predict_unknown_label_set_default(self, mock_get_chat_completion):\n        clf = self.get_mock_clf_model()\n\n        # Random choice\n        mock_get_chat_completion.return_value.choices[0].message = {\n            \"content\": json.dumps({\"label\": \"new_class\"})\n        }\n        clf.probabilities_ = [0, 1]\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        random.seed(42)\n        np.random.seed(42)\n\n        self.assertEqual(predictions, [\"class2\", \"class2\", \"class2\"])  # Random choice\n\n        clf.default_label = \"default_class\"\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        self.assertEqual(\n            predictions, [\"default_class\", \"default_class\", \"default_class\"]\n        )\n\n        clf.default_label = None\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        self.assertEqual(predictions, [None, None, None])", "\nclass TestZeroShotGPTClassifier(unittest.TestCase):\n    def get_mock_clf_model(self):\n        clf = ZeroShotGPTClassifier(\n            openai_key=\"mock_key\", openai_org=\"mock_org\"\n        )  # Mock keys\n        X = np.array([\"text1\", \"text2\", \"text3\"])\n        y = np.array([\"class1\", \"class2\", \"class1\"])\n        clf.fit(X, y)\n\n        self.assertEqual(set(clf.classes_), set([\"class1\", \"class2\"]))\n        self.assertEqual(clf.probabilities_, [2 / 3, 1 / 3])\n        return clf\n\n    @patch(\"skllm.models._base.get_chat_completion\", return_value=MagicMock())\n    def test_fit_predict(self, mock_get_chat_completion):\n        clf = self.get_mock_clf_model()\n        mock_get_chat_completion.return_value.choices[0].message = {\n            \"content\": json.dumps({\"label\": \"class1\"})\n        }\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n\n        self.assertEqual(predictions, [\"class1\", \"class1\", \"class1\"])\n\n    @patch(\"skllm.models._base.get_chat_completion\", return_value=MagicMock())\n    def test_fit_predict_unknown_label_set_default(self, mock_get_chat_completion):\n        clf = self.get_mock_clf_model()\n\n        # Random choice\n        mock_get_chat_completion.return_value.choices[0].message = {\n            \"content\": json.dumps({\"label\": \"new_class\"})\n        }\n        clf.probabilities_ = [0, 1]\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        random.seed(42)\n        np.random.seed(42)\n\n        self.assertEqual(predictions, [\"class2\", \"class2\", \"class2\"])  # Random choice\n\n        clf.default_label = \"default_class\"\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        self.assertEqual(\n            predictions, [\"default_class\", \"default_class\", \"default_class\"]\n        )\n\n        clf.default_label = None\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        self.assertEqual(predictions, [None, None, None])", "\n\nclass TestMultiLabelZeroShotGPTClassifier(unittest.TestCase):\n    def get_mock_clf_model(self):\n        clf = MultiLabelZeroShotGPTClassifier(\n            openai_key=\"mock_key\", openai_org=\"mock_org\", default_label=\"Random\"\n        )  # Mock keys\n        X = np.array([\"text1\", \"text2\", \"text3\"])\n        y = [\n            [\"class1\", \"class2\"],\n            [\"class1\", \"class2\"],\n            [\"class1\", \"class2\"],\n        ]  # Adjusted y to ensure [0.5, 0.5] probability\n        clf.fit(X, y)\n\n        self.assertEqual(set(clf.classes_), set([\"class1\", \"class2\"]))\n        self.assertEqual(clf.probabilities_, [0.5, 0.5])\n        return clf\n\n    @patch(\"skllm.models._base.get_chat_completion\", return_value=MagicMock())\n    def test_fit_predict(self, mock_get_chat_completion):\n        clf = self.get_mock_clf_model()\n        mock_get_chat_completion.return_value = _get_ret([\"class1\", \"class2\"])\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        self.assertEqual(\n            predictions,\n            [[\"class1\", \"class2\"], [\"class1\", \"class2\"], [\"class1\", \"class2\"]],\n        )\n\n    @patch(\"skllm.models._base.get_chat_completion\", return_value=MagicMock())\n    def test_fit_predict_unknown_label_set_default(self, mock_get_chat_completion):\n        clf = self.get_mock_clf_model()\n        mock_get_chat_completion.return_value.choices[0].message = {\n            \"content\": json.dumps({\"label\": \"new_class\"})\n        }\n\n        clf.probabilities_ = [0.0, 1.0]\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        random.seed(42)\n        np.random.seed(42)\n        self.assertEqual(\n            predictions, [[\"class2\"], [\"class2\"], [\"class2\"]]\n        )  # Random choice\n\n        clf.default_label = [\"default_class\"]\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        self.assertEqual(\n            predictions, [[\"default_class\"], [\"default_class\"], [\"default_class\"]]\n        )\n\n        clf.default_label = None\n        predictions = clf.predict([\"text1\", \"text2\", \"text3\"])\n        self.assertEqual(predictions, [None, None, None])", "\n\nif __name__ == \"__main__\":\n    unittest.main()\n"]}
{"filename": "tests/test_gpt_few_shot_clf.py", "chunked_list": ["import json\nimport random\nimport unittest\nfrom unittest.mock import MagicMock, patch\n\nimport numpy as np\n\nfrom skllm.models.gpt_dyn_few_shot_clf import DynamicFewShotGPTClassifier\nfrom skllm.models.gpt_few_shot_clf import FewShotGPTClassifier\n", "from skllm.models.gpt_few_shot_clf import FewShotGPTClassifier\n\n\nclass TestFewShotGPTClassifier(unittest.TestCase):\n    def get_mock_clf_model(self, clf=\"dynamic\"):\n        if clf == \"dynamic\":\n            clf = DynamicFewShotGPTClassifier(\n                openai_key=\"mock_key\", openai_org=\"mock_org\"\n            )\n        else:\n            clf = FewShotGPTClassifier(\n                openai_key=\"mock_key\", openai_org=\"mock_org\"\n            )  # Mock keys\n        X = np.array([\"text1\", \"text2\", \"text3\"])\n        y = np.array([\"class1\", \"class2\", \"class1\"])\n        clf.fit(X, y)\n\n        self.assertEqual(set(clf.classes_), set([\"class1\", \"class2\"]))\n        self.assertEqual(clf.probabilities_, [2 / 3, 1 / 3])\n        return clf\n\n    def test_prompt_generation(self):\n        clf = self.get_mock_clf_model(\"few_shot\")\n        prompt = clf._get_prompt(\"new_text\")\n        self.assertIn(\"text1\", prompt)\n        self.assertIn(\"text2\", prompt)\n        self.assertIn(\"text3\", prompt)\n        self.assertIn(\"class1\", prompt)\n        self.assertIn(\"class2\", prompt)\n        self.assertIn(\"new_text\", prompt)\n\n    def test_fit(self):\n        clf = self.get_mock_clf_model(\"few_shot\")\n        X = [\"text1\", \"text2\", \"text3\"]\n        y = [\"class1\", \"class2\", \"class1\"]\n        self.assertEqual(len(clf.training_data_[0]), len(X))\n        self.assertEqual(len(clf.training_data_[1]), len(y))\n        for x in X:\n            self.assertIn(x, clf.training_data_[0])\n        for y_ in y:\n            self.assertIn(y_, clf.training_data_[1])", "\n    # TODO Add prompt generation test for dynamic few shot\n\n    # TODO Add tests for dynamic few_show fit\n"]}
{"filename": "tests/__init__.py", "chunked_list": ["from . import test_chatgpt, test_gpt_zero_shot_clf\n"]}
{"filename": "tests/test_chatgpt.py", "chunked_list": ["import unittest\nfrom unittest.mock import patch\n\nfrom skllm.openai.chatgpt import (\n    construct_message,\n    extract_json_key,\n    get_chat_completion,\n)\n\n\nclass TestChatGPT(unittest.TestCase):\n\n    @patch(\"skllm.openai.credentials.set_credentials\")\n    @patch(\"openai.ChatCompletion.create\")\n    def test_get_chat_completion(self, mock_create, mock_set_credentials):\n        messages = [{\"role\": \"system\", \"content\": \"Hello\"}]\n        key = \"some_key\"\n        org = \"some_org\"\n        model = \"gpt-3.5-turbo\"\n        mock_create.side_effect = [Exception(\"API error\"), \"success\"]\n\n        result = get_chat_completion(messages, key, org, model)\n\n        self.assertTrue(mock_set_credentials.call_count <= 1, \"set_credentials should be called at most once\")\n        self.assertEqual(mock_create.call_count, 2, \"ChatCompletion.create should be called twice due to an exception \"\n                                                    \"on the first call\")\n        self.assertEqual(result, \"success\")\n\n    def test_construct_message(self):\n        role = \"user\"\n        content = \"Hello, World!\"\n        message = construct_message(role, content)\n        self.assertEqual(message, {\"role\": role, \"content\": content})\n        with self.assertRaises(ValueError):\n            construct_message(\"invalid_role\", content)\n\n    def test_extract_json_key(self):\n        json_ = '{\"key\": \"value\"}'\n        key = \"key\"\n        result = extract_json_key(json_, key)\n        self.assertEqual(result, \"value\")\n\n        # Given that the function returns None when a KeyError occurs, adjust the assertion\n        result_with_invalid_key = extract_json_key(json_, \"invalid_key\")\n        self.assertEqual(result_with_invalid_key, None)", "\n\nclass TestChatGPT(unittest.TestCase):\n\n    @patch(\"skllm.openai.credentials.set_credentials\")\n    @patch(\"openai.ChatCompletion.create\")\n    def test_get_chat_completion(self, mock_create, mock_set_credentials):\n        messages = [{\"role\": \"system\", \"content\": \"Hello\"}]\n        key = \"some_key\"\n        org = \"some_org\"\n        model = \"gpt-3.5-turbo\"\n        mock_create.side_effect = [Exception(\"API error\"), \"success\"]\n\n        result = get_chat_completion(messages, key, org, model)\n\n        self.assertTrue(mock_set_credentials.call_count <= 1, \"set_credentials should be called at most once\")\n        self.assertEqual(mock_create.call_count, 2, \"ChatCompletion.create should be called twice due to an exception \"\n                                                    \"on the first call\")\n        self.assertEqual(result, \"success\")\n\n    def test_construct_message(self):\n        role = \"user\"\n        content = \"Hello, World!\"\n        message = construct_message(role, content)\n        self.assertEqual(message, {\"role\": role, \"content\": content})\n        with self.assertRaises(ValueError):\n            construct_message(\"invalid_role\", content)\n\n    def test_extract_json_key(self):\n        json_ = '{\"key\": \"value\"}'\n        key = \"key\"\n        result = extract_json_key(json_, key)\n        self.assertEqual(result, \"value\")\n\n        # Given that the function returns None when a KeyError occurs, adjust the assertion\n        result_with_invalid_key = extract_json_key(json_, \"invalid_key\")\n        self.assertEqual(result_with_invalid_key, None)", "\n\nif __name__ == '__main__':\n    unittest.main()\n"]}
