{"filename": "test/test_extract_typed_completion.py", "chunked_list": ["import jiggybase\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\nfrom datetime import date\nfrom pydantic import BaseModel, Field, ValidationError, validator\nfrom time import time\n\njb = jiggybase.JiggyBase()\n\ngpt3_times =0 ", "\ngpt3_times =0 \ngpt4_times = 0\ncount  = 0\n\n\n\n\n# Define the pydantic model\nclass BookInformation(BaseModel):\n    title: str = Field(description=\"The title of the book\")\n    author: str = Field(description=\"The name of the book's author\")\n    publication_year: Optional[int] = Field(description=\"The publication year of the book\")\n    genre: Optional[str] = Field(description=\"The genre of the book\")\n    characters: Optional[List[str]] = Field(description=\"A list of the main characters in the book\")\n    summary: Optional[str] = Field(min_length=10, description=\"A brief summary of the book's plot\")", "# Define the pydantic model\nclass BookInformation(BaseModel):\n    title: str = Field(description=\"The title of the book\")\n    author: str = Field(description=\"The name of the book's author\")\n    publication_year: Optional[int] = Field(description=\"The publication year of the book\")\n    genre: Optional[str] = Field(description=\"The genre of the book\")\n    characters: Optional[List[str]] = Field(description=\"A list of the main characters in the book\")\n    summary: Optional[str] = Field(min_length=10, description=\"A brief summary of the book's plot\")\n\n# Input unstructured text", "\n# Input unstructured text\nunstructured_text = \"\"\"\nPride and Prejudice is a novel by Jane Austen, published in 1813.\nThis classic novel follows the story of Elizabeth Bennet, the protagonist, as she navigates issues of manners, morality, education, and marriage in the society of the landed gentry of early 19th-century England.\nThe story revolves primarily around Elizabeth and her relationship with the haughty yet enigmatic Mr. Darcy.\nThe book is set in rural England, and it is notable for its wit and humor as well as its commentary on class distinctions, social norms, and values.\nSome of the main characters in the novel include Elizabeth Bennet, Mr. Darcy, Jane Bennet, Mr. Bingley, Lydia Bennet, and Mr. Wickham.\nPride and Prejudice is considered a classic work of English literature and has been adapted numerous times for television, film, and stage.\nIt is often categorized as a romantic novel, but it also has elements of satire and social commentary.", "Pride and Prejudice is considered a classic work of English literature and has been adapted numerous times for television, film, and stage.\nIt is often categorized as a romantic novel, but it also has elements of satire and social commentary.\n\"\"\"\n\nt0 = time()\nmodel3 = jb.extract_typed_completion(unstructured_text, BookInformation, temperature=0, model='gpt-3.5-turbo')\ngpt3_times += time() - t0\nprint(model3)\n\nt0 = time()", "\nt0 = time()\nmodel4 = jb.extract_typed_completion(unstructured_text, BookInformation, temperature=0, model='gpt-4')\ngpt4_times += time() - t0\nprint(model4)\ncount += 1\n\n\n\n", "\n\n\nclass DocumentMetadata(BaseModel):\n    title      : Optional[str] = Field(description='The title of the content')\n    author     : Optional[str] = Field(description='The author of the content')\n    created_at : Optional[str] = Field(description='The date in the format YYYY-MM-DD that the content was created if it appears in the content')\n    language   : str           = Field(description='The 2 character ISO 639-1 language code of the primary language of the content')\n\n", "\n\nunstructured_text = \"\"\"Updated 24th March 2023\nGenerative AI - Chapter 1: Establishing the Investment Framework\nBlackLake Equity Research\nThe advent of cloud computing paved the way for new investment opportunities by facilitating the provision of software as a service. Generative AI takes this a step further, offering additional tools to boost end-user productivity. While traditional AI has proven useful in predicting outcomes, Generative AI specializes in creating content such as text, video, images, or computer code - a feat previously unachievable. Large Language Models (LLMs) play a crucial role as enablers of GAI, displaying an unprecedented level of expertise and intelligence. AI holds the potential to give rise to new enterprises and furnish existing players with fresh growth opportunities by greatly enhancing end-user productivity.\"\"\"\n\n\n\nt0 = time()", "\nt0 = time()\nmodel3 = jb.extract_typed_completion(unstructured_text, DocumentMetadata, temperature=0, model='gpt-3.5-turbo')\ngpt3_times += time() - t0\nprint(model3)\n\nt0 = time()\nmodel4 = jb.extract_typed_completion(unstructured_text, DocumentMetadata, temperature=0, model='gpt-4')\ngpt4_times += time() - t0\nprint(model4)", "gpt4_times += time() - t0\nprint(model4)\ncount += 1\n\n\n\n# Define the pydantic models\nclass Course(BaseModel):\n    title: str = Field(description=\"The title of the course\")\n    instructor: str = Field(description=\"The name of the course's instructor\")\n    duration_hours: Optional[int] = Field(description=\"The duration of the course in hours\")", "\nclass Curriculum(BaseModel):\n    curriculum_title: str = Field(description=\"The title of the curriculum\")\n    description: Optional[str] = Field(description=\"A brief description of the curriculum\")\n    courses: List[Course] = Field(description=\"A list of the courses included in the curriculum\")\n\n# Input unstructured text\nunstructured_text = \"\"\"\nThe Data Science Bootcamp is a comprehensive curriculum designed to provide students with the fundamental knowledge and practical skills required for a career in data science.\nThe bootcamp includes the following four courses:", "The Data Science Bootcamp is a comprehensive curriculum designed to provide students with the fundamental knowledge and practical skills required for a career in data science.\nThe bootcamp includes the following four courses:\n\n1. Introduction to Python: This course, taught by John Doe, covers the basics of the Python programming language and its applications in data science. It lasts for 20 hours.\n\n2. Data Wrangling and Visualization: Led by Jane Smith, this course teaches students how to clean, manipulate, and visualize data using popular Python libraries like pandas and Matplotlib. The course duration is 30 hours.\n\n3. Machine Learning Foundations: In this 40-hour course, instructor Michael Brown introduces the core concepts and algorithms of machine learning, including supervised and unsupervised learning techniques.\n\n4. Advanced Topics in Data Science: Taught by Sarah Johnson and lasting 35 hours, this course explores advanced data science techniques such as deep learning, natural language processing, and time series analysis.", "\n4. Advanced Topics in Data Science: Taught by Sarah Johnson and lasting 35 hours, this course explores advanced data science techniques such as deep learning, natural language processing, and time series analysis.\n\"\"\"\n\nt0 = time()\nmodel3 = jb.extract_typed_completion(unstructured_text, Curriculum, temperature=0, model='gpt-3.5-turbo')\ngpt3_times += time() - t0\nprint(model3)\n\nt0 = time()", "\nt0 = time()\nmodel4 = jb.extract_typed_completion(unstructured_text, Curriculum, temperature=0, model='gpt-4')\ngpt4_times += time() - t0\nprint(model4)\ncount += 1\n\n\n\n", "\n\n# Define the pydantic model\nclass Event(BaseModel):\n    event_name: str = Field(description=\"The name of the event\")\n    start_date: date = Field(description=\"The start date of the event\")\n    end_date: date = Field(description=\"The end date of the event\")\n\n    @validator('end_date')\n    def start_date_must_be_prior_to_end_date(cls, end_date, values):\n        start_date = values.get('start_date')\n        if start_date and end_date <= start_date:\n            raise ValidationError(f\"End date ({end_date}) must be after start date ({start_date})\")\n        return end_date", "\nclass EventList(BaseModel):\n    events: List[Event] = Field(description=\"A list of events\")\n\n# Input unstructured text\nunstructured_text = \"\"\"\nCalendar Update\nTuesday, April 27, 2023\nWe have a series of exciting events happening over the next few weeks!\n", "We have a series of exciting events happening over the next few weeks!\n\n1. Next Monday, the Annual AI Conference will kick off, ending on Wednesday. The event will focus on the latest advancements in artificial intelligence and machine learning, with discussions led by industry experts.\n\n2. In two weeks, the three-day Startup Showcase will take place, where new tech startups will demonstrate their innovative products and services. The event aims to foster collaboration and investment opportunities.\n\n3. The following week, we are hosting a Blockchain Summit, running from Tuesday to Thursday. The summit will explore the potential applications of blockchain technology across various industries, featuring engaging panel discussions and presentations.\n\n4. Finally, at the end of the month, a four-day Virtual Reality Festival will commence. This event celebrates the rapid progress of virtual and augmented reality technologies, with immersive exhibits and experiences available for all attendees.\n", "4. Finally, at the end of the month, a four-day Virtual Reality Festival will commence. This event celebrates the rapid progress of virtual and augmented reality technologies, with immersive exhibits and experiences available for all attendees.\n\nMake sure to mark your calendars for these thrilling events and seize the opportunity to learn more about the ever-evolving world of technology!\n\"\"\"\n\nt0 = time()\n\nmodel3 = jb.extract_typed_completion(unstructured_text, EventList, temperature=0, model='gpt-3.5-turbo')\ngpt3_times += time() - t0\nprint(model3)", "gpt3_times += time() - t0\nprint(model3)\n\nt0 = time()\nmodel4 = jb.extract_typed_completion(unstructured_text, EventList, temperature=0, model='gpt-4')\ngpt4_times += time() - t0\nprint(model4)\ncount += 1\n\n", "\n\n\n\n# Define the pydantic model\nclass MovieInformation(BaseModel):\n    title: str = Field(description=\"The title of the movie\")\n    director: str = Field(description=\"The name of the movie's director\")\n    release_year: Optional[int] = Field(description=\"The release year of the movie\")\n    cast: Optional[List[str]] = Field(description=\"A list of the main actors in the movie\")\n    genre: Optional[List[str]] = Field(description=\"The genres of the movie\")\n    duration_minutes: Optional[int] = Field(description=\"The duration of the movie in minutes\")\n    plot: Optional[str] = Field(min_length=10, description=\"A brief summary of the movie's plot\")\n    awards: Optional[List[str]] = Field(description=\"A list of the awards won by the movie\")", "\n# Input unstructured text\nunstructured_text = \"\"\"\nThe Godfather is a 1972 American crime film directed by Francis Ford Coppola, who co-wrote the screenplay with Mario Puzo, based on Puzo's best-selling 1969 novel of the same name.\nThe film stars Marlon Brando, Al Pacino, and James Caan, and tells the story of the powerful Italian-American crime family of Don Vito Corleone (played by Brando).\nWhen an organized crime dynasty's aging patriarch transfers control of his clandestine empire to his reluctant son, Michael Corleone (played by Pacino), a series of events unfold that threatens the stability of the family and the entire criminal underworld.\nSet in New York City and spanning the years 1945 to 1955, The Godfather is notable for its realistic depiction of the Mafia and its exploration of themes such as power, loyalty, betrayal, and family dynamics.\nThe film was met with widespread critical acclaim upon release and is commonly regarded as one of the greatest films in world cinema.\nIt won three Academy Awards, including Best Picture, Best Actor (Marlon Brando), and Best Adapted Screenplay, and has been selected for preservation in the United States National Film Registry.\nThe Godfather is a crime drama film and is widely regarded as one of the most influential films in the gangster genre.", "It won three Academy Awards, including Best Picture, Best Actor (Marlon Brando), and Best Adapted Screenplay, and has been selected for preservation in the United States National Film Registry.\nThe Godfather is a crime drama film and is widely regarded as one of the most influential films in the gangster genre.\nIts running time is approximately 175 minutes.\n\"\"\"\n\n\n\nt0 = time()\nmodel3 = jb.extract_typed_completion(unstructured_text, MovieInformation, temperature=0, model='gpt-3.5-turbo')\ngpt3_times += time() - t0", "model3 = jb.extract_typed_completion(unstructured_text, MovieInformation, temperature=0, model='gpt-3.5-turbo')\ngpt3_times += time() - t0\nprint(model3)\n\nt0 = time()\nmodel4 = jb.extract_typed_completion(unstructured_text, MovieInformation, temperature=0, model='gpt-4')\ngpt4_times += time() - t0\nprint(model4)\ncount += 1\n", "count += 1\n\n\n\n    \n# The data class we wish to extract from the unstructured text\nclass UserDetails(BaseModel):\n    name: str = Field(description=\"The name of the user\")\n    age: Optional[int] = Field(description=\"The age of the user\")\n    email: Optional[str] = Field(description=\"The email address of the user\")\n    country: str = Field(description=\"The country the user resides in\")", "\n# Example unstructured text from which to extract the UserDetails\nunstructured_text = \"\"\"\nJohn Doe, a software engineer from San Francisco, California, started his career in the tech industry in the United States in 2010.\nHe initially worked for a small startup before joining a larger multinational company in 2014.\nJohn, currently 30 years old, is passionate about programming and solving complex problems.\nHe has attended multiple conferences across the world and has collaborated with colleagues from various countries on numerous projects.\nDespite his busy work life, John finds time for his hobbies, such as photography and hiking.\nHe enjoys traveling to different countries, and one of his favorite trips was to Japan in 2019.\nDo you need to get in touch with John? Feel free to reach out to him at john.doe@example.com.", "He enjoys traveling to different countries, and one of his favorite trips was to Japan in 2019.\nDo you need to get in touch with John? Feel free to reach out to him at john.doe@example.com.\n\"\"\"\n\nt0 = time()\nmodel3 = jb.extract_typed_completion(unstructured_text, UserDetails, temperature=0, model='gpt-3.5-turbo')\ngpt3_times += time() - t0\nprint(model3)\n\nt0 = time()", "\nt0 = time()\nmodel4 = jb.extract_typed_completion(unstructured_text, UserDetails, temperature=0, model='gpt-4')\ngpt4_times += time() - t0\nprint(model4)    \ncount += 1\n\n\nprint(f\"GPT-3.5 Turbo: {gpt3_times/count} s\")\nprint(f\"GPT-4:         {gpt4_times/count} s\")", "print(f\"GPT-3.5 Turbo: {gpt3_times/count} s\")\nprint(f\"GPT-4:         {gpt4_times/count} s\")"]}
{"filename": "test/test.py", "chunked_list": ["import jiggybase\n\n\nfrom jiggybase.models import (\n    ApiKey,\n    ChatModelName,\n    ChunkConfig,\n    Collection,\n    CollectionPatchRequest,\n    CollectionPostRequest,", "    CollectionPatchRequest,\n    CollectionPostRequest,\n    EmbeddingConfig,\n    EmbeddingModelName,\n    ExtractMetadataConfig,\n    Org,\n    OrgMember,\n    OrgMemberPostRequest,\n    OrgPatchRequest,\n    OrgPostRequest,", "    OrgPatchRequest,\n    OrgPostRequest,\n    OrgRole,\n    PatchPluginOAuthConfigRequest,\n    PluginAuthConfigOAuth,\n    PluginAuthType,\n    PluginBearerTokenConfig,\n    PluginConfig,\n    User,\n    UserPostPatchRequest,", "    User,\n    UserPostPatchRequest,\n    UserPostRequest,\n    PromptTask\n)\n\n\n\n\nif __name__ == \"__main__\":\n    jb = jiggybase.JiggyBase()\n    orgs = jb.orgs()\n    for org in orgs:\n        print(f'Org: {org}')\n        print(org.prompt_tasks())\n        for c in org.collections():\n            print(f'   Collection: {c}')    \n    collections = jb.collections()", "\nif __name__ == \"__main__\":\n    jb = jiggybase.JiggyBase()\n    orgs = jb.orgs()\n    for org in orgs:\n        print(f'Org: {org}')\n        print(org.prompt_tasks())\n        for c in org.collections():\n            print(f'   Collection: {c}')    \n    collections = jb.collections()"]}
{"filename": "jiggybase/ijiggy.py", "chunked_list": ["#!/usr/bin/env python3\n\nimport jiggybase\ntry:\n    import IPython\nexcept:\n    raise Exception(\"'pip install IPython' run this command first\")\n\ndef main():\n    \n    print(\"\\nStarting JiggyBase IPython environment\\n\")\n\n    jb = jiggybase.JiggyBase()\n    orgs = jb.orgs()\n    collections = jb.collections()\n    \n    print(f\"'jb'          set to jiggybase.JiggyBase() instance\")\n    print(f\"'orgs'        set to list of your orgs\")\n    print(f\"'collections' set to list of your collections\")    \n    print()    \n    IPython.start_ipython(argv=[], user_ns={\"jb\": jb, \"orgs\": orgs, \"collections\": collections})", "def main():\n    \n    print(\"\\nStarting JiggyBase IPython environment\\n\")\n\n    jb = jiggybase.JiggyBase()\n    orgs = jb.orgs()\n    collections = jb.collections()\n    \n    print(f\"'jb'          set to jiggybase.JiggyBase() instance\")\n    print(f\"'orgs'        set to list of your orgs\")\n    print(f\"'collections' set to list of your collections\")    \n    print()    \n    IPython.start_ipython(argv=[], user_ns={\"jb\": jb, \"orgs\": orgs, \"collections\": collections})", "    \n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "jiggybase/collection.py", "chunked_list": ["import os\nfrom typing import Optional, List, Iterator, Tuple\nfrom pydantic import BaseModel, Field, BaseConfig, HttpUrl\nfrom enum import Enum\nfrom .models import collection, CollectionChatConfig, PatchCollectionChatConfig\nfrom .jiggybase_session import JiggyBaseSession\nfrom .models import UpsertResponse,  Query, QueryRequest, QueryResponse, UpsertRequest, Document, DocumentChunk, DeleteRequest, DeleteResponse, DocumentMetadataFilter, DocChunksResponse\nfrom .models import Message, CompletionRequest, ChatCompletion \nfrom .chat_stream import extract_content_from_sse_bytes\nfrom .models import ExtractMetadataConfig", "from .chat_stream import extract_content_from_sse_bytes\nfrom .models import ExtractMetadataConfig\nfrom .models import CollectionPatchRequest, PluginAuthConfigOAuth, PatchPluginOAuthConfigRequest\nfrom .models import DocumentMetadata\nfrom typing import Union, List\n\n\n        \nclass Collection(collection.Collection):\n    \"\"\"\n    derived from models.collection.Collection data model for purposes of adding management methods\n    \"\"\"\n    class Config(BaseConfig):\n        extra = \"allow\"\n\n    def __init__(self, session, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.session = session        \n        api_key = self.session.api_key\n        self.plugin_session = JiggyBaseSession(host=f'https://{kwargs[\"fqdn\"]}', api='', api_key=api_key)\n        self.chat_session = JiggyBaseSession(host=session.host, api='v1', api_key=api_key)\n        \n    def set_description(self, description:str) -> \"Collection\":\n        \"\"\"\n        Update an existing collection using its ID and the provided description.\n        \"\"\"\n        patch_request = CollectionPatchRequest(description=description)\n        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}\", model=patch_request)\n        self.description = rsp.json()['description']\n\n\n    def set_oauth_verification_token(self, openai_verification_token: str) -> PluginAuthConfigOAuth:\n        \"\"\"\n        Set the OpenAI verification token for this collection's plugin.\n        This is the token that OpenAI provides during while registering a plugin configured to use Oauth.\n        \"\"\"\n        patch_request = PatchPluginOAuthConfigRequest(openai_verification_token=openai_verification_token)\n        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/plugin_oauth\", model=patch_request)\n        return PluginAuthConfigOAuth(**rsp.json())\n\n    def plugin_oauth_config(self) -> PluginAuthConfigOAuth:\n        \"\"\"\n        Get the OAuth configuration for this collection's plugin.\n        The client_id and client_secret returned here are configured with OpenAI while \n        registering a plugin configured to use Oauth.\n        \"\"\"\n        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/plugin_oauth\")\n        return PluginAuthConfigOAuth(**rsp.json())\n\n    def delete(self):\n        \"\"\"\n        Delete a collection.  Warning: this is permanent.\n        \"\"\"\n        self.session.delete(f\"/orgs/{self.org_id}/collections/{self.id}\")\n\n\n    def get_chat_config(self) -> CollectionChatConfig:\n        \"\"\"\n        Get the chat configuration for this collection.\n        \"\"\"\n        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/chat_config\")\n        return collection.CollectionChatConfig(**rsp.json())\n\n    def update_chat_config(self, model: str, prompt_task_id: int) -> CollectionChatConfig:\n        \"\"\"\n        Update the chat configuration for this collection.\n        \"\"\"\n        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/chat_config/{model}\", model=PatchCollectionChatConfig(prompt_task_id=prompt_task_id))\n        return CollectionChatConfig(**rsp.json())\n\n \n    def upsert_file(self, file_path: str, mimetype: str = None, id: str = None, metadata : DocumentMetadata = None) -> UpsertResponse:\n        \"\"\"\n        Add a file to the collection.\n        Mimetype can be specified, otherwise it will be inferred from the file extension.\n        The doc id can be specified, otherwise it will be generated.\n        Metadata can be specified, otherwise some metadata will be inferred from the file.\n        \"\"\"\n        if not os.path.exists(file_path):\n            raise ValueError(\"File not found\")\n        with open(file_path, \"rb\") as file:\n            files = {\"file\": (os.path.basename(file_path), file, mimetype)}\n            params = {'id': id} if id else {}\n            if metadata:\n                rsp = self.plugin_session.post(\"/upsert-file\", \n                                               files=files, \n                                               params=params,\n                                               data={'metadata': metadata.json(exclude_unset=True)})\n            else:\n                rsp = self.plugin_session.post(\"/upsert-file\", params=params, files=files)\n        return UpsertResponse.parse_obj(rsp.json())\n\n    def upsert(self, documents: List[Document]) -> UpsertResponse:\n        \"\"\"\n        Add a list of Document objects to the collection.\n        \"\"\"\n        upsert_request = UpsertRequest(documents=documents)\n        rsp = self.plugin_session.post(\"/upsert\", model=upsert_request)\n        return  UpsertResponse.parse_obj(rsp.json())\n    \n    def query(self, queries: Union[str, List[str], Query], top_k : int = 10) -> QueryResponse:\n        \"\"\"\n        Query the collection returning the top_k results for each query.\n        queries can be either a single string, a list of strings, or a list of Query objects.\n        if it is a string or list of strings, the specified top_k will be used for each of the queries.\n        Returns a QueryResponse object.\n        \"\"\"\n        if isinstance(queries, str):\n            queries = [Query(query=queries, top_k=top_k)]\n        elif isinstance(queries, Query):\n            queries = [Query(query=q, top_k=top_k) for q in queries]\n        qr = QueryRequest(queries=queries)\n        rsp = self.plugin_session.post(\"/query\", model=qr)\n        return  QueryResponse.parse_obj(rsp.json())\n\n    def get_doc(self, id: str) -> list[DocumentChunk]:\n        \"\"\"\n        Get a document by id\n        \"\"\"\n        rsp = self.plugin_session.get(f\"/docs/{id}\")\n        return [DocumentChunk.parse_obj(c) for c in rsp.json()]\n    \n    def get_chunks(self, \n                   start: int = 0, \n                   limit: int = 10, \n                   reverse: bool = True) -> List[DocumentChunk]:\n        \"\"\"\n        low level interface for iterating through the chunks in a collection\n        start - Offset of the first result to return\n        limit - Number of results to return starting from the offset\n        reverse - Reverse the order of the items returned\n        \"\"\"\n        params = {\"start\": start, \"limit\": limit, \"reverse\": reverse}\n        rsp = self.plugin_session.get(\"/chunks\", params=params)\n        return [DocumentChunk.parse_obj(chunk) for chunk in rsp.json()]\n\n    def get_doc_chunks(self, \n                       index: int = -1, \n                       limit: int = 10, \n                       reverse: bool = True,\n                       max_chunks_per_doc = 1) -> Tuple[List[List[DocumentChunk]], int]:\n         \"\"\"\n         low level interface for iterating through the initial chunks for all docs in a collection\n         index - index of the first result to return, should be -1 to start at the end\n         limit - Number of results to return starting from the offset\n         reverse - Reverse the order of the items returned; True to return newest first\n         max_chunks_per_doc - maximum number of chunks to return for each document\n         \"\"\"\n         params = {\"index\": index, \"limit\": limit, \"reverse\": reverse, \"max_chunks_per_doc\": max_chunks_per_doc}\n         rsp = self.plugin_session.get(\"/doc_chunks\", params=params)\n         dcr_rsp = DocChunksResponse.parse_obj(rsp.json())\n         return dcr_rsp.docs, dcr_rsp.next_index\n\n    def delete_docs(self, \n                    ids                      : Optional[List[str]] = None, \n                    document_metadata_filter : Optional[DocumentMetadataFilter] = None, \n                    delete_all               : Optional[bool] = False) -> DeleteResponse:\n        \"\"\"\n        Delete items in the collection by document id's or document metadata filter.\n        A delete_all option is also provided to delete all documents in the collection.\n        \"\"\"\n        delete_request = DeleteRequest(ids=ids, filter=document_metadata_filter, delete_all=delete_all)\n        rsp = self.plugin_session.delete(\"/delete\", model=delete_request)\n        return DeleteResponse.parse_obj(rsp.json())\n\n\n    def _chat_completion(self, \n                         messages: List[Message],\n                         model = 'gpt-3.5-turbo',\n                         max_tokens = None,\n                         temperature = .1) -> ChatCompletion:\n        \"\"\"\n        low level interface for chat completion\n        The input here mirrors openai chat completion parameters, while the output is different\n        \"\"\"\n        cr = CompletionRequest(model       = f'{self.name}_{model}', \n                               messages    = messages,\n                               max_tokens  = max_tokens,\n                               temperature = temperature,\n                               stream      = False)\n        rsp = self.chat_session.post(\"/chat/completions\", model=cr)          \n        return ChatCompletion.parse_obj(rsp.json())\n\n    def _chat_completion_stream_str(self, \n                         messages: List[Message],\n                         model = 'gpt-3.5-turbo',\n                         max_tokens = None,\n                         temperature = .1) -> Iterator[str]:\n        \"\"\"\n        low level interface for chat completion with streaming\n        yields the model output as an iteration of strings\n        \"\"\"\n        cr = CompletionRequest(model       = f'{self.name}_{model}', \n                               messages    = messages,\n                               max_tokens  = max_tokens,\n                               temperature = temperature,\n                               stream      = True)\n        rsp = self.chat_session.post(\"/chat/completions\", model=cr, stream=True)\n        for line in rsp.iter_lines():\n            if line:  # filter out keep-alive newlines        \n                yield extract_content_from_sse_bytes(line)\n\n    def get_extract_metadata_config(self):\n        \"\"\"\n        Get the metadata configuration for this collection.\n        \"\"\"\n        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/extract_metadata_config\")\n        return ExtractMetadataConfig(**rsp.json())\n\n    def patch_extract_metadata_config(self, config: ExtractMetadataConfig):\n        \"\"\"\n        Get the metadata configuration for this collection.\n        \"\"\"\n        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/extract_metadata_config\", model=config)\n        return ExtractMetadataConfig(**rsp.json())    \n\n    def __str__(self) -> str:\n        return f\"Collection(id={self.id:4}, name={self.display_name:30}, hostname={self.hostname:30}, org_id={self.org_id:4},\\n\" \\\n               f\"           description='{self.description}')\"\n\n    def __repr__(self) -> str:\n        return str(self)    ", "class Collection(collection.Collection):\n    \"\"\"\n    derived from models.collection.Collection data model for purposes of adding management methods\n    \"\"\"\n    class Config(BaseConfig):\n        extra = \"allow\"\n\n    def __init__(self, session, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.session = session        \n        api_key = self.session.api_key\n        self.plugin_session = JiggyBaseSession(host=f'https://{kwargs[\"fqdn\"]}', api='', api_key=api_key)\n        self.chat_session = JiggyBaseSession(host=session.host, api='v1', api_key=api_key)\n        \n    def set_description(self, description:str) -> \"Collection\":\n        \"\"\"\n        Update an existing collection using its ID and the provided description.\n        \"\"\"\n        patch_request = CollectionPatchRequest(description=description)\n        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}\", model=patch_request)\n        self.description = rsp.json()['description']\n\n\n    def set_oauth_verification_token(self, openai_verification_token: str) -> PluginAuthConfigOAuth:\n        \"\"\"\n        Set the OpenAI verification token for this collection's plugin.\n        This is the token that OpenAI provides during while registering a plugin configured to use Oauth.\n        \"\"\"\n        patch_request = PatchPluginOAuthConfigRequest(openai_verification_token=openai_verification_token)\n        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/plugin_oauth\", model=patch_request)\n        return PluginAuthConfigOAuth(**rsp.json())\n\n    def plugin_oauth_config(self) -> PluginAuthConfigOAuth:\n        \"\"\"\n        Get the OAuth configuration for this collection's plugin.\n        The client_id and client_secret returned here are configured with OpenAI while \n        registering a plugin configured to use Oauth.\n        \"\"\"\n        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/plugin_oauth\")\n        return PluginAuthConfigOAuth(**rsp.json())\n\n    def delete(self):\n        \"\"\"\n        Delete a collection.  Warning: this is permanent.\n        \"\"\"\n        self.session.delete(f\"/orgs/{self.org_id}/collections/{self.id}\")\n\n\n    def get_chat_config(self) -> CollectionChatConfig:\n        \"\"\"\n        Get the chat configuration for this collection.\n        \"\"\"\n        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/chat_config\")\n        return collection.CollectionChatConfig(**rsp.json())\n\n    def update_chat_config(self, model: str, prompt_task_id: int) -> CollectionChatConfig:\n        \"\"\"\n        Update the chat configuration for this collection.\n        \"\"\"\n        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/chat_config/{model}\", model=PatchCollectionChatConfig(prompt_task_id=prompt_task_id))\n        return CollectionChatConfig(**rsp.json())\n\n \n    def upsert_file(self, file_path: str, mimetype: str = None, id: str = None, metadata : DocumentMetadata = None) -> UpsertResponse:\n        \"\"\"\n        Add a file to the collection.\n        Mimetype can be specified, otherwise it will be inferred from the file extension.\n        The doc id can be specified, otherwise it will be generated.\n        Metadata can be specified, otherwise some metadata will be inferred from the file.\n        \"\"\"\n        if not os.path.exists(file_path):\n            raise ValueError(\"File not found\")\n        with open(file_path, \"rb\") as file:\n            files = {\"file\": (os.path.basename(file_path), file, mimetype)}\n            params = {'id': id} if id else {}\n            if metadata:\n                rsp = self.plugin_session.post(\"/upsert-file\", \n                                               files=files, \n                                               params=params,\n                                               data={'metadata': metadata.json(exclude_unset=True)})\n            else:\n                rsp = self.plugin_session.post(\"/upsert-file\", params=params, files=files)\n        return UpsertResponse.parse_obj(rsp.json())\n\n    def upsert(self, documents: List[Document]) -> UpsertResponse:\n        \"\"\"\n        Add a list of Document objects to the collection.\n        \"\"\"\n        upsert_request = UpsertRequest(documents=documents)\n        rsp = self.plugin_session.post(\"/upsert\", model=upsert_request)\n        return  UpsertResponse.parse_obj(rsp.json())\n    \n    def query(self, queries: Union[str, List[str], Query], top_k : int = 10) -> QueryResponse:\n        \"\"\"\n        Query the collection returning the top_k results for each query.\n        queries can be either a single string, a list of strings, or a list of Query objects.\n        if it is a string or list of strings, the specified top_k will be used for each of the queries.\n        Returns a QueryResponse object.\n        \"\"\"\n        if isinstance(queries, str):\n            queries = [Query(query=queries, top_k=top_k)]\n        elif isinstance(queries, Query):\n            queries = [Query(query=q, top_k=top_k) for q in queries]\n        qr = QueryRequest(queries=queries)\n        rsp = self.plugin_session.post(\"/query\", model=qr)\n        return  QueryResponse.parse_obj(rsp.json())\n\n    def get_doc(self, id: str) -> list[DocumentChunk]:\n        \"\"\"\n        Get a document by id\n        \"\"\"\n        rsp = self.plugin_session.get(f\"/docs/{id}\")\n        return [DocumentChunk.parse_obj(c) for c in rsp.json()]\n    \n    def get_chunks(self, \n                   start: int = 0, \n                   limit: int = 10, \n                   reverse: bool = True) -> List[DocumentChunk]:\n        \"\"\"\n        low level interface for iterating through the chunks in a collection\n        start - Offset of the first result to return\n        limit - Number of results to return starting from the offset\n        reverse - Reverse the order of the items returned\n        \"\"\"\n        params = {\"start\": start, \"limit\": limit, \"reverse\": reverse}\n        rsp = self.plugin_session.get(\"/chunks\", params=params)\n        return [DocumentChunk.parse_obj(chunk) for chunk in rsp.json()]\n\n    def get_doc_chunks(self, \n                       index: int = -1, \n                       limit: int = 10, \n                       reverse: bool = True,\n                       max_chunks_per_doc = 1) -> Tuple[List[List[DocumentChunk]], int]:\n         \"\"\"\n         low level interface for iterating through the initial chunks for all docs in a collection\n         index - index of the first result to return, should be -1 to start at the end\n         limit - Number of results to return starting from the offset\n         reverse - Reverse the order of the items returned; True to return newest first\n         max_chunks_per_doc - maximum number of chunks to return for each document\n         \"\"\"\n         params = {\"index\": index, \"limit\": limit, \"reverse\": reverse, \"max_chunks_per_doc\": max_chunks_per_doc}\n         rsp = self.plugin_session.get(\"/doc_chunks\", params=params)\n         dcr_rsp = DocChunksResponse.parse_obj(rsp.json())\n         return dcr_rsp.docs, dcr_rsp.next_index\n\n    def delete_docs(self, \n                    ids                      : Optional[List[str]] = None, \n                    document_metadata_filter : Optional[DocumentMetadataFilter] = None, \n                    delete_all               : Optional[bool] = False) -> DeleteResponse:\n        \"\"\"\n        Delete items in the collection by document id's or document metadata filter.\n        A delete_all option is also provided to delete all documents in the collection.\n        \"\"\"\n        delete_request = DeleteRequest(ids=ids, filter=document_metadata_filter, delete_all=delete_all)\n        rsp = self.plugin_session.delete(\"/delete\", model=delete_request)\n        return DeleteResponse.parse_obj(rsp.json())\n\n\n    def _chat_completion(self, \n                         messages: List[Message],\n                         model = 'gpt-3.5-turbo',\n                         max_tokens = None,\n                         temperature = .1) -> ChatCompletion:\n        \"\"\"\n        low level interface for chat completion\n        The input here mirrors openai chat completion parameters, while the output is different\n        \"\"\"\n        cr = CompletionRequest(model       = f'{self.name}_{model}', \n                               messages    = messages,\n                               max_tokens  = max_tokens,\n                               temperature = temperature,\n                               stream      = False)\n        rsp = self.chat_session.post(\"/chat/completions\", model=cr)          \n        return ChatCompletion.parse_obj(rsp.json())\n\n    def _chat_completion_stream_str(self, \n                         messages: List[Message],\n                         model = 'gpt-3.5-turbo',\n                         max_tokens = None,\n                         temperature = .1) -> Iterator[str]:\n        \"\"\"\n        low level interface for chat completion with streaming\n        yields the model output as an iteration of strings\n        \"\"\"\n        cr = CompletionRequest(model       = f'{self.name}_{model}', \n                               messages    = messages,\n                               max_tokens  = max_tokens,\n                               temperature = temperature,\n                               stream      = True)\n        rsp = self.chat_session.post(\"/chat/completions\", model=cr, stream=True)\n        for line in rsp.iter_lines():\n            if line:  # filter out keep-alive newlines        \n                yield extract_content_from_sse_bytes(line)\n\n    def get_extract_metadata_config(self):\n        \"\"\"\n        Get the metadata configuration for this collection.\n        \"\"\"\n        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/extract_metadata_config\")\n        return ExtractMetadataConfig(**rsp.json())\n\n    def patch_extract_metadata_config(self, config: ExtractMetadataConfig):\n        \"\"\"\n        Get the metadata configuration for this collection.\n        \"\"\"\n        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/extract_metadata_config\", model=config)\n        return ExtractMetadataConfig(**rsp.json())    \n\n    def __str__(self) -> str:\n        return f\"Collection(id={self.id:4}, name={self.display_name:30}, hostname={self.hostname:30}, org_id={self.org_id:4},\\n\" \\\n               f\"           description='{self.description}')\"\n\n    def __repr__(self) -> str:\n        return str(self)    "]}
{"filename": "jiggybase/chat_stream.py", "chunked_list": ["from loguru import logger\nimport json\n\ndef extract_content_from_sse_bytes(sse_bytes: bytes) -> str:\n    \"\"\"\n    Extracts the \"content\" value from the raw SSE byte string. This is the incremental model output text.\n    \"\"\"\n    sse_str = sse_bytes.decode('utf-8')\n    lines = sse_str.strip().split('\\n\\n')\n    results = \"\"\n    for line in lines:        \n        if line.startswith(\"data:\"):\n            event_str = line.split(\":\", 1)[1].strip()\n            if '[DONE]' in event_str:\n                continue\n            try:\n                event_data = json.loads(event_str)\n                content = event_data.get(\"choices\", [])[0].get(\"delta\", {}).get(\"content\", \"\")\n                results += content\n            except (json.JSONDecodeError, IndexError, KeyError, TypeError) as e:\n                logger.error(f\"Failed to parse SSE event data for line: '{line}'\")\n                logger.error(f\"Failed to parse SSE event data with err: {e}\")\n                continue\n    return results"]}
{"filename": "jiggybase/org.py", "chunked_list": ["\nfrom typing import Any, Optional, List\nfrom pydantic import BaseConfig, EmailStr\nimport enum\n\nfrom .models import  CollectionPostRequest\n\nfrom .models.org import Org as OrgModel\nfrom .models.org import OrgRole, OrgMember, OrgPatchRequest\nfrom .models import PromptTask, PromptMessage, PromptTaskPostRequest, PromptTaskType", "from .models.org import OrgRole, OrgMember, OrgPatchRequest\nfrom .models import PromptTask, PromptMessage, PromptTaskPostRequest, PromptTaskType\n\nfrom .collection import Collection\n    \n###\n## Org\n###\nclass Org(OrgModel):\n\n    class Config(BaseConfig):\n        extra = \"allow\"\n\n    def __init__(self, session, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.session = session\n        \n    def create_collection(self, \n                          display_name: str,\n                          description: Optional[str] = None) -> Collection:\n        rsp = self.session.post(f\"/orgs/{self.id}/collections\", model=CollectionPostRequest(**locals()))\n        print(rsp.json())\n        return Collection(self.session, **rsp.json())\n\n    def collections(self) -> list[Collection]:\n        rsp = self.session.get(f\"/orgs/{self.id}/collections\")\n        return [Collection(self.session, **c) for c in rsp.json()]\n\n    def collection(self, name: str) -> Collection:\n        collections = [c for c in self.collections() if c.name == name or c.display_name.lower() == name.lower()]\n        if not collections:\n            raise ValueError(f\"Collection {name} not found\")\n        return collections[0]\n    \n    def members(self) -> List[OrgMember]:\n        return [OrgMember(**tm) for tm in self.session.get(f'/orgs/{self.id}/members').json()]\n    \n    def add_member(self, email : EmailStr, role : OrgRole) -> OrgMember:\n        \"\"\"\n        Invite the specified email to this org with the corresponding OrgRole.\n        If the email does not have an account, the system will send an invite to this email.\n        \"\"\"\n        rsp = self.session.post(f\"/orgs/{self.id}/members\", json={\"email\": email, 'role':role})\n        return OrgMember(**rsp.json())\n\n    def delete_member(self, email : str):\n        \"\"\"\n        attempt to remove the specified name from this org\n        \"\"\"\n        member = [m for m in self.members() if m.email == email]\n        if not member:\n            raise Exception(f\"{email} not found in Org\")\n        self.session.delete(f\"/orgs/{self.id}/members/{member[0].id}\")\n\n    def update(self, name: Optional[str] = None, description: Optional[str] = None) -> 'Org':\n        \"\"\"\n        update the org name or description\n        \"\"\"\n        patch_request = OrgPatchRequest(name=name, description=description)\n        rsp = self.session.patch(f\"/orgs/{self.id}\", model=patch_request)\n        updated_org_data = rsp.json()\n        self.name = updated_org_data.get(\"name\", self.name)\n        self.description = updated_org_data.get(\"description\", self.description)\n        return self\n        \n    def prompt_tasks(self, name=None, version=None) -> list[PromptTask]:\n        query = ''\n        if name:\n            query += f\"?name={name}\"\n            if version:\n                query += f\"&version={version}\"\n        return [PromptTask(**pt) for pt in self.session.get(f\"/orgs/{self.id}/prompt_tasks{query}\").json()]\n\n    def create_prompt_task(self, \n                           name       : str, \n                           version    : int, \n                           prompts    : List[PromptMessage],\n                           type       : Optional[PromptTaskType] = None, \n                           description: Optional[str] = None, \n                           ) -> PromptTask:\n        rsp = self.session.post(f\"/orgs/{self.id}/prompt_tasks\", model=PromptTaskPostRequest(**locals()))\n        return PromptTask(**rsp.json())\n\n    def update_prompt_task(self,\n                           name       : str,\n                           prompts    : List[PromptMessage]) -> PromptTask:\n        pt = self.prompt_tasks(name=name)\n        if not pt:\n            raise ValueError(f\"PromptTask {name} not found\")\n        pt = pt[0]\n        self.create_prompt_task(name        = name, \n                                version     = pt.version+1, \n                                type        = pt.type, \n                                description = pt.description, \n                                prompts     = prompts)\n        \n    def get_prompt_task(self, prompt_task_id: int) -> PromptTask:\n        \n        return PromptTask(**self.session.get(f\"/orgs/{self.id}/prompt_tasks/{prompt_task_id}\").json())\n\n    def delete_prompt_task(self, prompt_task_id: int):\n        self.session.delete(f\"/orgs/{self.id}/prompt_tasks/{prompt_task_id}\")\n\n    def __str__(self) -> str:\n        return f\"Org(id={self.id:4}, status={self.subscription_status:8}, gpt4_credts={self.gpt4_credits:4}, name={self.name:20}, description={self.description})\"\n\n    def __repr__(self) -> str:\n        return str(self)", "class Org(OrgModel):\n\n    class Config(BaseConfig):\n        extra = \"allow\"\n\n    def __init__(self, session, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.session = session\n        \n    def create_collection(self, \n                          display_name: str,\n                          description: Optional[str] = None) -> Collection:\n        rsp = self.session.post(f\"/orgs/{self.id}/collections\", model=CollectionPostRequest(**locals()))\n        print(rsp.json())\n        return Collection(self.session, **rsp.json())\n\n    def collections(self) -> list[Collection]:\n        rsp = self.session.get(f\"/orgs/{self.id}/collections\")\n        return [Collection(self.session, **c) for c in rsp.json()]\n\n    def collection(self, name: str) -> Collection:\n        collections = [c for c in self.collections() if c.name == name or c.display_name.lower() == name.lower()]\n        if not collections:\n            raise ValueError(f\"Collection {name} not found\")\n        return collections[0]\n    \n    def members(self) -> List[OrgMember]:\n        return [OrgMember(**tm) for tm in self.session.get(f'/orgs/{self.id}/members').json()]\n    \n    def add_member(self, email : EmailStr, role : OrgRole) -> OrgMember:\n        \"\"\"\n        Invite the specified email to this org with the corresponding OrgRole.\n        If the email does not have an account, the system will send an invite to this email.\n        \"\"\"\n        rsp = self.session.post(f\"/orgs/{self.id}/members\", json={\"email\": email, 'role':role})\n        return OrgMember(**rsp.json())\n\n    def delete_member(self, email : str):\n        \"\"\"\n        attempt to remove the specified name from this org\n        \"\"\"\n        member = [m for m in self.members() if m.email == email]\n        if not member:\n            raise Exception(f\"{email} not found in Org\")\n        self.session.delete(f\"/orgs/{self.id}/members/{member[0].id}\")\n\n    def update(self, name: Optional[str] = None, description: Optional[str] = None) -> 'Org':\n        \"\"\"\n        update the org name or description\n        \"\"\"\n        patch_request = OrgPatchRequest(name=name, description=description)\n        rsp = self.session.patch(f\"/orgs/{self.id}\", model=patch_request)\n        updated_org_data = rsp.json()\n        self.name = updated_org_data.get(\"name\", self.name)\n        self.description = updated_org_data.get(\"description\", self.description)\n        return self\n        \n    def prompt_tasks(self, name=None, version=None) -> list[PromptTask]:\n        query = ''\n        if name:\n            query += f\"?name={name}\"\n            if version:\n                query += f\"&version={version}\"\n        return [PromptTask(**pt) for pt in self.session.get(f\"/orgs/{self.id}/prompt_tasks{query}\").json()]\n\n    def create_prompt_task(self, \n                           name       : str, \n                           version    : int, \n                           prompts    : List[PromptMessage],\n                           type       : Optional[PromptTaskType] = None, \n                           description: Optional[str] = None, \n                           ) -> PromptTask:\n        rsp = self.session.post(f\"/orgs/{self.id}/prompt_tasks\", model=PromptTaskPostRequest(**locals()))\n        return PromptTask(**rsp.json())\n\n    def update_prompt_task(self,\n                           name       : str,\n                           prompts    : List[PromptMessage]) -> PromptTask:\n        pt = self.prompt_tasks(name=name)\n        if not pt:\n            raise ValueError(f\"PromptTask {name} not found\")\n        pt = pt[0]\n        self.create_prompt_task(name        = name, \n                                version     = pt.version+1, \n                                type        = pt.type, \n                                description = pt.description, \n                                prompts     = prompts)\n        \n    def get_prompt_task(self, prompt_task_id: int) -> PromptTask:\n        \n        return PromptTask(**self.session.get(f\"/orgs/{self.id}/prompt_tasks/{prompt_task_id}\").json())\n\n    def delete_prompt_task(self, prompt_task_id: int):\n        self.session.delete(f\"/orgs/{self.id}/prompt_tasks/{prompt_task_id}\")\n\n    def __str__(self) -> str:\n        return f\"Org(id={self.id:4}, status={self.subscription_status:8}, gpt4_credts={self.gpt4_credits:4}, name={self.name:20}, description={self.description})\"\n\n    def __repr__(self) -> str:\n        return str(self)"]}
{"filename": "jiggybase/client.py", "chunked_list": ["from typing import List\nfrom .org import Org\nfrom .collection import Collection\nfrom .models.user import User, ApiKey\nfrom .jiggybase_session import JiggyBaseSession\nfrom .models.chat import Message, TypedCompletionRequest\nfrom pydantic import BaseModel    \n\nclass JiggyBase():\n\n    def __init__(self, api_key=None):\n        self.session = JiggyBaseSession(api_key=api_key)     \n        \n    def orgs(self) -> List[Org]:\n        \"\"\"\n        return all Orgs that the user is a member of\n        \"\"\"\n        resp = self.session.get('/orgs')\n        return [Org(self.session, **i) for i in resp.json()]\n\n    def get_org(self, name_or_id) -> Org:\n        \"\"\"\n        get org by name or id\n        raises Exception if an exact match for name is not found\n        \"\"\"\n        orgs = [t for t in self.session.get('/orgs').json() if t['name'] == name_or_id or t['id'] == name_or_id]\n        if len(orgs):\n            return Org(self.session, **orgs[0])\n        raise Exception(f'Org \"{name_or_id}\" not found')\n\n\n    def api_keys(self) -> List[ApiKey]:\n        \"\"\"\n        return user's api keys\n        \"\"\"\n        return [ApiKey(**i) for i in self.session.get('/apikey').json()]\n\n\n    def authenticated_user(self) -> User:\n        \"\"\"\n        return the authenticated user's User object\n        \"\"\"\n        return User(**self.session.get(\"/users/current\").json())\n\n\n    def create_org(self, name : str) -> Org:\n        \"\"\"\n        create an Org\n        \"\"\"\n        resp = self.session.post(\"/orgs\", json={\"name\":name})\n        return Org(self.session, **resp.json())\n\n    def collections(self) -> List[Collection]:\n        \"\"\"\n        return all Collections in all Orgs that the user is a member of\n        \"\"\"\n        resp = self.session.get(\"/collections\")\n        return [Collection(self.session, **c) for c in resp.json()]\n   \n    def collection_names(self) -> List[Collection]:\n        \"\"\"\n        return the collection display names for all collections in all Orgs that the user is a member of\n        \"\"\"\n        return [c.disply_name for c in self.collections()]\n\n    def collection_hostnames(self) -> List[Collection]:\n        \"\"\"\n        return the unique collection hostname for all collections in all Orgs that the user is a member of\n        \"\"\"\n        return [c.hostname for c in self.collections()]\n\n            \n    def collection(self, name : str) -> Collection:        \n        \"\"\"\n        return a collection of the specified display name or hostname\n        \"\"\"\n        for collection in self.collections():\n            if collection.hostname == name or collection.display_name.lower() == name.lower():\n                return collection\n        raise ValueError(f'Collection \"{name}\" not found')\n\n\n    def _extract_typed_completion(self,\n                                 messages       : List[Message],\n                                 pydantic_model : BaseModel,\n                                 temperature    : float = 0,\n                                 model          : str   = 'gpt-3.5-turbo') -> BaseModel:\n        \"\"\"\n        lower-level interface to the extract_typed_completion endpoint\n        \"\"\"\n        tcr = TypedCompletionRequest(model       = model, \n                                     messages    = messages,\n                                     json_schema = pydantic_model.schema_json(),\n                                     temperature = temperature,\n                                     stream      = False)\n        \n        rsp = self.session.post(\"/extract/typed_completions\", model=tcr)\n        return pydantic_model.parse_obj(rsp.json())\n\n\n    def  extract_typed_completion(self,\n                                  content       : str,\n                                  pydantic_model : BaseModel, \n                                  temperature    : float = 0,\n                                  model          : str   = 'gpt-3.5-turbo') -> BaseModel:\n        \"\"\"\n        Higher-level interface to structured extraction from unstructured content.\n        Just provide the unstructured text and the pydantic model to extract.\n        \"\"\"\n        # Set up messages\n        messages = [{\"role\": \"user\", \"content\": f\"Extract the {pydantic_model.__name__} information from the following content:\"},\n                    {\"role\": \"user\", \"content\": content}]\n\n        return self._extract_typed_completion(messages, pydantic_model, temperature, model)", "class JiggyBase():\n\n    def __init__(self, api_key=None):\n        self.session = JiggyBaseSession(api_key=api_key)     \n        \n    def orgs(self) -> List[Org]:\n        \"\"\"\n        return all Orgs that the user is a member of\n        \"\"\"\n        resp = self.session.get('/orgs')\n        return [Org(self.session, **i) for i in resp.json()]\n\n    def get_org(self, name_or_id) -> Org:\n        \"\"\"\n        get org by name or id\n        raises Exception if an exact match for name is not found\n        \"\"\"\n        orgs = [t for t in self.session.get('/orgs').json() if t['name'] == name_or_id or t['id'] == name_or_id]\n        if len(orgs):\n            return Org(self.session, **orgs[0])\n        raise Exception(f'Org \"{name_or_id}\" not found')\n\n\n    def api_keys(self) -> List[ApiKey]:\n        \"\"\"\n        return user's api keys\n        \"\"\"\n        return [ApiKey(**i) for i in self.session.get('/apikey').json()]\n\n\n    def authenticated_user(self) -> User:\n        \"\"\"\n        return the authenticated user's User object\n        \"\"\"\n        return User(**self.session.get(\"/users/current\").json())\n\n\n    def create_org(self, name : str) -> Org:\n        \"\"\"\n        create an Org\n        \"\"\"\n        resp = self.session.post(\"/orgs\", json={\"name\":name})\n        return Org(self.session, **resp.json())\n\n    def collections(self) -> List[Collection]:\n        \"\"\"\n        return all Collections in all Orgs that the user is a member of\n        \"\"\"\n        resp = self.session.get(\"/collections\")\n        return [Collection(self.session, **c) for c in resp.json()]\n   \n    def collection_names(self) -> List[Collection]:\n        \"\"\"\n        return the collection display names for all collections in all Orgs that the user is a member of\n        \"\"\"\n        return [c.disply_name for c in self.collections()]\n\n    def collection_hostnames(self) -> List[Collection]:\n        \"\"\"\n        return the unique collection hostname for all collections in all Orgs that the user is a member of\n        \"\"\"\n        return [c.hostname for c in self.collections()]\n\n            \n    def collection(self, name : str) -> Collection:        \n        \"\"\"\n        return a collection of the specified display name or hostname\n        \"\"\"\n        for collection in self.collections():\n            if collection.hostname == name or collection.display_name.lower() == name.lower():\n                return collection\n        raise ValueError(f'Collection \"{name}\" not found')\n\n\n    def _extract_typed_completion(self,\n                                 messages       : List[Message],\n                                 pydantic_model : BaseModel,\n                                 temperature    : float = 0,\n                                 model          : str   = 'gpt-3.5-turbo') -> BaseModel:\n        \"\"\"\n        lower-level interface to the extract_typed_completion endpoint\n        \"\"\"\n        tcr = TypedCompletionRequest(model       = model, \n                                     messages    = messages,\n                                     json_schema = pydantic_model.schema_json(),\n                                     temperature = temperature,\n                                     stream      = False)\n        \n        rsp = self.session.post(\"/extract/typed_completions\", model=tcr)\n        return pydantic_model.parse_obj(rsp.json())\n\n\n    def  extract_typed_completion(self,\n                                  content       : str,\n                                  pydantic_model : BaseModel, \n                                  temperature    : float = 0,\n                                  model          : str   = 'gpt-3.5-turbo') -> BaseModel:\n        \"\"\"\n        Higher-level interface to structured extraction from unstructured content.\n        Just provide the unstructured text and the pydantic model to extract.\n        \"\"\"\n        # Set up messages\n        messages = [{\"role\": \"user\", \"content\": f\"Extract the {pydantic_model.__name__} information from the following content:\"},\n                    {\"role\": \"user\", \"content\": content}]\n\n        return self._extract_typed_completion(messages, pydantic_model, temperature, model)", ""]}
{"filename": "jiggybase/jiggybase_session.py", "chunked_list": ["# Jiggy Client\nimport os\nfrom requests.auth import HTTPBasicAuth\nfrom requests.packages.urllib3 import Retry\nfrom requests.adapters import HTTPAdapter\nimport requests\nfrom time import sleep\nfrom .login import window_open\n\nJIGGYBASE_HOST     = os.environ.get('JIGGYBASE_HOST', 'https://api.gpt-gateway.com')   # transition to jiggy.ai in progress", "\nJIGGYBASE_HOST     = os.environ.get('JIGGYBASE_HOST', 'https://api.gpt-gateway.com')   # transition to jiggy.ai in progress\n\nJB_KEY_FILE = os.path.expanduser('~') + '/.jiggybase'   # local file to store user entered apikey \n\n\"\"\"\nRetry the following status codes:\n500 Internal Server Error: The server encountered an error while processing the request.\n502 Bad Gateway: The server, while acting as a gateway, received an invalid response from the upstream server.\n503 Service Unavailable: The server is currently unable to handle the request due to maintenance or overload.", "502 Bad Gateway: The server, while acting as a gateway, received an invalid response from the upstream server.\n503 Service Unavailable: The server is currently unable to handle the request due to maintenance or overload.\n504 Gateway Timeout: The server, while acting as a gateway, did not receive a timely response from the upstream server.\n\"\"\"\nRETRY_STATUS_CODES = [500, 502, 503, 504]\n\nclass ClientError(Exception):\n    \"\"\"\n    API returned 4xx client error\n    \"\"\"", "\nclass ServerError(Exception):\n    \"\"\"\n    API returned 5xx Server error\n    \"\"\"\n\n    \nclass JiggyBaseSession(requests.Session):\n    def __init__(self, host=JIGGYBASE_HOST, api='gpt-gateway-v1', bearer_token=None, api_key=None, *args, **kwargs):\n        \"\"\"\n        Extend requests.Session with common GPTG authentication, retry, and exceptions.\n\n        host: The url host prefix of the form \"https:/api.gpt-gateway.com\"\n              if host arg is not set, will use \n                    JIGGYBASE_HOST environment variable or \"api.gpt-gateway.com\" as final default.\n\n        api:  The api & version to use. defaults to 'gpt-gateway-v1'\n\n        bearer_token:  usually None, but can be specified if this is used by an endpoint has already has one handy\n        \n        final url prefix are of the form \"https://{host}/{api}\"\n        \"\"\"\n        super(JiggyBaseSession, self).__init__(*args, **kwargs)\n        if not host.startswith('http'):\n            host = f\"https://{host}\" if not host.startswith('localhost') else f'http://{host}'\n        self.host = host\n        if api:\n            self.prefix_url = f\"{host}/{api}\"\n        else:\n            self.prefix_url = host          \n\n        self.bearer_token = None            \n        self.api_key = None\n        if api_key:\n            self.api_key = api_key\n            self._getjwt(api_key)\n        elif bearer_token:\n            self._set_bearer(bearer_token)\n            \n        super(JiggyBaseSession, self).mount('https://',\n                                            HTTPAdapter(max_retries=Retry(connect=5,\n                                                                          read=5,\n                                                                          status=5,\n                                                                          redirect=2,\n                                                                          backoff_factor=.001,\n                                                                          status_forcelist=None)))\n\n    def _set_bearer(self, jwt):\n        self.bearer_token = jwt\n        self.headers['Authorization'] = f\"Bearer {jwt}\"\n\n    def _getjwt(self, key):        \n        resp = requests.post(f\"{JIGGYBASE_HOST}/gpt-gateway-v1/auth\", json={'key': key})\n        if resp.status_code == 200:\n            self._set_bearer(resp.json()['jwt'])\n        elif resp.status_code == 401:\n            raise ClientError(\"Invalid API Key\")\n        else:\n            raise ServerError(resp.content)\n\n    def _auth(self):\n        if 'JIGGYBASE_API_KEY' in os.environ:\n            self._getjwt(os.environ['JIGGYBASE_API_KEY'])\n        elif os.path.exists(JB_KEY_FILE):\n            self._getjwt(open(JB_KEY_FILE).read())\n        else: ## check interactive?\n            while True:\n                window_open(\"https://jiggy.ai/authorize\")\n                key_input = input(\"Enter your JiggyBase API Key: \")\n                if key_input[:4] == \"jgy-\":\n                    # try using the key to see if it is valid\n                    try:\n                        self._getjwt(key_input)\n                        # key validated, save to key file\n                        open(JB_KEY_FILE, 'w').write(key_input)\n                        os.chmod(JB_KEY_FILE, 0o600)  # -rw-------\n                        break\n                    except:\n                        pass\n                print(\"Invalid API Key\")\n\n        \n    def request(self, method, url, *args, **kwargs):\n        if not self.bearer_token:\n            self._auth()\n        url = self.prefix_url + url\n        # support 'model' (pydantic BaseModel) arg which we convert to json parameter\n        if 'model' in kwargs:\n            kwargs['data'] = kwargs.pop('model').json()\n\n        max_attempts = 7\n        backoff_factor = 0.5\n\n        for attempt in range(max_attempts):        \n            try:        \n                resp =  super(JiggyBaseSession, self).request(method, url, *args, **kwargs)\n            except Exception as e:\n                print(f\"Exception: {e}\")\n                if attempt == max_attempts - 1:\n                    raise\n                continue\n\n            if resp.status_code == 401:\n                self.bearer_token = None\n                del self.headers['Authorization']\n                self._auth()\n                if attempt == max_attempts - 1:\n                    print(\"Unable to authenticate\")\n                    raise ValueError(\"Unable to authenticate\")\n                continue\n            if resp.status_code not in RETRY_STATUS_CODES:\n                break\n            sleep_duration = backoff_factor * (2 ** attempt)\n            sleep(sleep_duration)\n            \n        if resp.status_code >= 500:\n            raise ServerError(resp.content)\n        if resp.status_code >= 400:\n            raise ClientError(resp.content)\n        return resp", "\n"]}
{"filename": "jiggybase/__init__.py", "chunked_list": ["from .client import JiggyBase\n"]}
{"filename": "jiggybase/login.py", "chunked_list": ["\nimport webbrowser\n\ndef is_notebook() -> bool:\n    \"\"\"\n    Returns True if code is executed in a notebook (Jupyter, Colab, QTconsole), False otherwise.\n    https://stackoverflow.com/a/39662359\n    \"\"\"\n    try:\n        shell_class = get_ipython().__class__\n        for parent_class in shell_class.__mro__:\n            if parent_class.__name__ == \"ZMQInteractiveShell\":\n                return True  # Jupyter notebook, Google colab or qtconsole\n        return False\n    except NameError:\n        return False  # Probably standard Python interpreter", "\n    \ndef window_open(url):    \n    print(f\"You can find your API Key here: {url}\")\n    if not is_notebook():\n        print(\"(Attempting to open browser window...)\")            \n        webbrowser.open(url)\n    else:\n        pass\n        # The following code seems to work to open a web page from a notebook,", "        # The following code seems to work to open a web page from a notebook,\n        # but when successful it takes the user away to this page somewhat unexpectedly\n        # so we will instead rely on the user clicking the above url so they\n        # understand what is happening.\n        #from IPython.display import Javascript        \n        #display(Javascript('window.open(\"{url}\");'.format(url=url)))\n"]}
{"filename": "jiggybase/models/auth.py", "chunked_list": ["\nfrom pydantic import BaseModel, Field, HttpUrl\nfrom typing import List\n\n\n\nclass PluginAuthConfigOAuth(BaseModel):\n    \"\"\"\n    The Plugin Oauth configuration when plugin_auth == PluginAuthType.oauth\n    \"\"\"    \n    client_url:                 HttpUrl     = Field(description=\"ChatGPT will direct the user\u2019s browser to this url to log in to the plugin\")\n    authorization_url:          HttpUrl     = Field(description=\"After successful login ChatGPT will complete the OAuth flow by making a POST request to this URL\")\n    scope:                      str         = Field(description=\"The scope used for the OAuth flow\")\n    client_id:                  str         = Field(unique=True, index=True, description=\"The client id to send to OpenAI for the plugin\")\n    client_secret:              str         = Field(description=\"The client secret to send to OpenAI for the plugin\")\n    openai_verification_token:  str         = Field(description=\"The verification token specified by OpenAI to configure in the plugin\")", "\n\n\n\nclass PluginBearerTokenConfig(BaseModel):\n    \"\"\"\n    A list of bearer tokens that are authorized to access the /plugin api when plugin_auth == PluginAuthType.bearer\n    \"\"\"\n    authorized_tokens : List[str]  =  []    "]}
{"filename": "jiggybase/models/collection.py", "chunked_list": ["from typing import Optional\nfrom pydantic import BaseModel, Field\n\n\n        \nclass CollectionPostRequest(BaseModel):\n    \"\"\"\n    Used to create a new Collection service\n    \"\"\"\n    display_name: str                      = Field(description=\"The human friendly display name for the collection.\")\n    description:  Optional[str]            = Field(description=\"A description of the collection.\")", "\n\nclass CollectionPatchRequest(BaseModel):\n    \"\"\"\n    Used to modify an existing service\n    \"\"\"\n    description:  Optional[str] = Field(description=\"A description of the collection.\")\n    display_name: Optional[str] = Field(description=\"The human friendly display name for the collection.\")\n\n", "\n\n\n\n\nclass Collection(BaseModel):\n    \"\"\"\n    A managed collection of searchable documents exposed via as a ChatGPT plugin and a REST API.\n    \"\"\"\n    id:           int           = Field(description=\"The unique ID of the service\")\n    display_name: str           = Field(description=\"The human friendly display name for the collection.\")    \n    description:  Optional[str] = Field(description=\"A description of the collection.\")\n    hostname:     str           = Field(description=\"The unique hostname for the collection service. The hostname part of the fqdn\")\n    fqdn:         str           = Field(description=\"The FQDN for the collection service\")\n    org_id:       int           = Field(description='The Org that owns this Service.')\n    created_by:   int           = Field(description='The user_id that created this item.')\n    updated_by:   int           = Field(description='The user_id that last modified this item.')\n    created_at:   float         = Field(description='The epoch timestamp when the collection was created.')\n    updated_at:   float         = Field(description='The epoch timestamp when the collection was created.')", "\n"]}
{"filename": "jiggybase/models/embedding.py", "chunked_list": ["from typing import Optional, List\nfrom pydantic import BaseModel, Field, HttpUrl, validator\nfrom enum import Enum\n\n\n\n\nclass EmbeddingModelName(str, Enum):\n    ada002 :str = \"text-embedding-ada-002\"\n    \n    def __str__(self):\n        return str(self.value)    ", "\n    \nclass EmbeddingConfig(BaseModel):\n    model : EmbeddingModelName =  Field(EmbeddingModelName.ada002, description=\"The name of the model to use for embedding the collection content.\")\n    "]}
{"filename": "jiggybase/models/plugin.py", "chunked_list": ["from typing import Optional, Union, List\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\nfrom pydantic import BaseModel, Field, HttpUrl\n\n\n\n\nclass PluginAuthType(str, Enum):\n    \"\"\"\n    Note that this is for custom plugins available in the JiggyBase enterprise tier and unrelated to the main JiggyBase plugin in the OpenAI plugin store.\n    \"\"\"\n    bearer :str = \"bearer\"\n    none   :str = \"none\"\n    oauth  :str = \"oauth\"", "class PluginAuthType(str, Enum):\n    \"\"\"\n    Note that this is for custom plugins available in the JiggyBase enterprise tier and unrelated to the main JiggyBase plugin in the OpenAI plugin store.\n    \"\"\"\n    bearer :str = \"bearer\"\n    none   :str = \"none\"\n    oauth  :str = \"oauth\"\n\n    \nclass PluginAuthConfigOAuth(BaseModel):\n    \"\"\"\n    The Plugin Oauth configuration as managed by JiggyBase\n    Note that this is for custom plugins available in the JiggyBase enterprise tier and unrelated to the main JiggyBase plugin in the OpenAI plugin store.\n    \"\"\"    \n    client_url:                 HttpUrl     = Field(description=\"ChatGPT will direct the user\u2019s browser to this url to log in to the plugin\")\n    authorization_url:          HttpUrl     = Field(description=\"After successful login ChatGPT will complete the OAuth flow by making a POST request to this URL\")\n    scope:                      str         = Field(description=\"The scope used for the OAuth flow\")\n    client_id:                  str         = Field(unique=True, index=True, description=\"The client id to send to OpenAI for the plugin\")\n    client_secret:              str         = Field(description=\"The client secret to send to OpenAI for the plugin\")\n    openai_verification_token:  str         = Field(description=\"The verification token specified by OpenAI to configure in the plugin\")", "    \nclass PluginAuthConfigOAuth(BaseModel):\n    \"\"\"\n    The Plugin Oauth configuration as managed by JiggyBase\n    Note that this is for custom plugins available in the JiggyBase enterprise tier and unrelated to the main JiggyBase plugin in the OpenAI plugin store.\n    \"\"\"    \n    client_url:                 HttpUrl     = Field(description=\"ChatGPT will direct the user\u2019s browser to this url to log in to the plugin\")\n    authorization_url:          HttpUrl     = Field(description=\"After successful login ChatGPT will complete the OAuth flow by making a POST request to this URL\")\n    scope:                      str         = Field(description=\"The scope used for the OAuth flow\")\n    client_id:                  str         = Field(unique=True, index=True, description=\"The client id to send to OpenAI for the plugin\")\n    client_secret:              str         = Field(description=\"The client secret to send to OpenAI for the plugin\")\n    openai_verification_token:  str         = Field(description=\"The verification token specified by OpenAI to configure in the plugin\")", "\nclass PatchPluginOAuthConfigRequest(BaseModel):\n    openai_verification_token: str  \n\nclass Source(str, Enum):\n    email = \"email\"\n    file = \"file\"\n    chat = \"chat\"\n    web  = \"web\"\n", "\n\nclass DocumentMetadata(BaseModel):\n    source: Optional[Source] = None\n    source_id: Optional[str] = None\n    url: Optional[str] = None\n    created_at: Optional[str] = None\n    author: Union[str, List[str]] = None\n    title: Optional[str] = None\n    description: Optional[str] = None\n    language: Optional[str] = Field(description=\"The 2 character ISO 639-1 language code of the primary language of the content.\")\n    version: str = None", "\nclass DocumentChunkMetadata(DocumentMetadata):\n    document_id: Optional[str] = None\n\n\nclass DocumentChunk(BaseModel):\n    id: Optional[str] = None\n    text: str\n    metadata: DocumentChunkMetadata\n    embedding: Optional[list[float]] = None\n    token_count: Optional[int] = None\n    reference_url: Optional[str] = None\n\n    def __str__(self):\n        if len(self.text) > 100:\n            text = self.text[:100] + '...'\n        else: \n            text = self.text\n        text = text.replace('\\n', ' ')\n        estr = \"DocumentChunk(\"\n        if self.id is not None:\n            estr += f\"id={self.id}, \"\n        if self.metadata is not None:\n            estr += f\"metadata={str(self.metadata)}, \"\n        if self.embedding is not None:\n            estr += f\"embedding=dim{len(self.embedding)}, \"\n        estr += f\"text={text})\"\n        return estr", "\n    \nclass DocumentChunkWithScore(DocumentChunk):\n    score: float\n\n\nclass Document(BaseModel):\n    id: Optional[str]\n    text: str\n    metadata: Optional[DocumentMetadata] = None\n    mimetype: Optional[str] = None\n    token_count: Optional[int] = None", "\n\nclass DocumentWithChunks(Document):\n    chunks: List[DocumentChunk]\n\nclass DocumentMetadataFilter(BaseModel):\n    document_id: Optional[str] = None\n    source: Optional[Source] = None\n    source_id: Optional[str] = None\n    author: Optional[str] = None\n    start_date: Optional[str] = None  # any date string format\n    end_date: Optional[str] = None  # any date string format\n    title: Optional[str] = None", "\n\nclass Query(BaseModel):\n    query: str\n    filter: Optional[DocumentMetadataFilter] = None\n    top_k: Optional[int] = 3\n\nclass QueryWithEmbedding(Query):\n    embedding: list[float]\n", "\n\nclass QueryResult(BaseModel):\n    query: str\n    results: list[DocumentChunkWithScore]\n\n\nclass UpsertRequest(BaseModel):\n    documents: List[Document]\n", "\n\nclass UpsertResponse(BaseModel):\n    ids: List[str]\n\n\nclass QueryRequest(BaseModel):\n    queries: List[Query]\n\n\nclass QueryResponse(BaseModel):\n    results: List[QueryResult]", "\n\nclass QueryResponse(BaseModel):\n    results: List[QueryResult]\n\n\nclass DeleteRequest(BaseModel):\n    ids: Optional[List[str]] = None\n    filter: Optional[DocumentMetadataFilter] = None\n    delete_all: Optional[bool] = False", "\n\nclass DeleteResponse(BaseModel):\n    success: bool\n\n\nclass Accounting(BaseModel):\n    chunk_count: int\n    doc_count: int\n    page_count: int", "\n\n\nclass DocChunksResponse(BaseModel):\n    docs       : list[list[DocumentChunk]] = Field(..., description=\"A list of documents, each containing a list of chunks\")\n    next_index : int                       = Field(..., description=\"The index of the next document to return.  Use this value as the index parameter in the next request to get the next set of documents\")  \n          "]}
{"filename": "jiggybase/models/org.py", "chunked_list": ["from typing import Optional, List\nfrom pydantic import BaseModel, Field, EmailStr, HttpUrl\nfrom enum import Enum\n\n\n\nclass OrgRole(str, Enum):\n    admin   = 'admin'\n    member  = 'member'\n    service = 'service'\n    view    = 'view'", "    \n\nclass OrgPostRequest(BaseModel):\n    name:        str           = Field(min_length=1, max_length=39, description='Unique name for this org.')\n    description: Optional[str] = Field(default=None, description='Optional user supplied description.')\n\nclass OrgPatchRequest(BaseModel):\n    name:        Optional[str] = Field(max_length=39, description='Unique name for this org.')\n    description: Optional[str] = Field(max_length=255, description='Optional user supplied description.')\n\nclass OrgMemberPostRequest(BaseModel):\n    email:  EmailStr     = Field(description='The user_id of a member to invite to the org.')\n    role:   OrgRole      = Field(description='The users role in the org')", "\nclass OrgMemberPostRequest(BaseModel):\n    email:  EmailStr     = Field(description='The user_id of a member to invite to the org.')\n    role:   OrgRole      = Field(description='The users role in the org')\n\nclass OrgMember(BaseModel):\n    id:                  int      = Field(description=\"Unique membership id\")\n    name:                str      = Field(description=\"Member name\")\n    email:               EmailStr = Field(description=\"Member email\")    \n    created_at:          float    = Field(description='The epoch timestamp when the membership was created.')\n    updated_at:          float    = Field(description='The epoch timestamp when the membership was updated.')\n    invited_by_name:     str      = Field(description=\"The name that invited this member to the org.\")\n    role:                OrgRole  = Field(description=\"The user's role in the org\")\n    accepted:            bool     = Field(description='True if the user has accepted the org membership.')", "    \n\n\nclass Org(BaseModel):\n    id:                  int           = Field(escription=\"Internal org id\")\n    name:                str           = Field(max_length=39, description='Unique name for this org.')\n    description:         Optional[str] = Field(max_length=255, description='Optional user supplied description.')\n    created_at:          float         = Field(description='The epoch timestamp when the org was created.')\n    updated_at:          float         = Field(description='The epoch timestamp when the org was updated.')\n    created_by:          Optional[int] = Field(description='The user_id of the user that created the org.')\n    subscription_id:     str           = Field(description='The subscription_id for the org.')    \n    gpt4_credits:        int           = Field(description='The number of GPT-4 message credits currently available to the org users for chat.jiggy.ai.')\n    gpt3_5_credits:      int           = Field(description='The number of GPT-3 message credits currently available to the org users for chat.jiggy.ai.')\n    subscription_status: str           = Field(description='The stripe subscription status.')", "     "]}
{"filename": "jiggybase/models/metadata.py", "chunked_list": ["from typing import Optional, List\nfrom pydantic import BaseModel, Field, HttpUrl, validator\nfrom enum import Enum\n\nfrom .chatmodel import ChatModelName\n\nclass ExtractMetadataConfig(BaseModel):\n    \"\"\"\n    configuration for metadata extraction\n    \"\"\"\n    created_at:  bool          = Field(True, description=\"Attempt to extract the created_at metadata field\")\n    author:      bool          = Field(True, description=\"Attempt to extract the author metadata field\")\n    title:       bool          = Field(True, description=\"Attempt to extract the title metadata field\")\n    model:       ChatModelName = Field(ChatModelName.gpt4, description=\"The name of the model to use for metadata extraction\")", ""]}
{"filename": "jiggybase/models/__init__.py", "chunked_list": ["from .auth import *\nfrom .user import *\nfrom .org import *\nfrom .embedding import *\nfrom .metadata import *\nfrom .chunk import *\nfrom .chatmodel import *\nfrom .plugin_config import *\nfrom .plugin import *\nfrom .collection import *", "from .plugin import *\nfrom .collection import *\nfrom .prompt import *\nfrom .chat import *\n"]}
{"filename": "jiggybase/models/prompt.py", "chunked_list": ["from typing import Optional, List\nfrom pydantic import BaseModel, Field, HttpUrl, validator\nfrom enum import Enum\nfrom time import time\n\n\nclass PromptMessageRole(str, Enum):\n    system              : str = \"system\"\n    user                : str = \"user\"\n    assistant           : str = \"assistant\"\n    collection_context  : str = \"collection_context\"   # this is a special role that pulls in collection context in subsequent system messages\n        \n    def __str__(self):\n        return str(self.value)", "\n           \nclass PromptMessage(BaseModel):\n    role      : PromptMessageRole  = Field(description=\"The role of the prompt\")\n    content   : str                = Field(description=\"The text of the prompt\")\n    position  : int                = Field(description=\"The position offset of the item in the prompt message list. 0-based, with negative values counting from the end.\")\n\n\nclass PromptTaskType(str, Enum):\n    chat            = \"chat\"             # iterative chat (e.g. chat with a model with user/assistant message history)\n    collection_chat = \"collection_chat\"  # iterative chat augmented with retreival from a collection\n    plugin_chat     = \"plugin_chat\"      # iterative chat augmented with tool use via plugin interface\n    read_write      = \"read_write\"       # non-iterative task that involve reading a document and producing text or data", "class PromptTaskType(str, Enum):\n    chat            = \"chat\"             # iterative chat (e.g. chat with a model with user/assistant message history)\n    collection_chat = \"collection_chat\"  # iterative chat augmented with retreival from a collection\n    plugin_chat     = \"plugin_chat\"      # iterative chat augmented with tool use via plugin interface\n    read_write      = \"read_write\"       # non-iterative task that involve reading a document and producing text or data\n\n       \nclass PromptTask(BaseModel):\n    id          :   int                      = Field(description=\"The unique ID of the prompt task\")\n    org_id      :   int                      = Field(description='The Org that owns this.')    \n    name        :   str                      = Field(description=\"The name of the task. Unique within the org.\")    \n    type        :   Optional[PromptTaskType] = Field(description=\"The type of task\")\n    version     :   int                      = Field(description=\"The version of the task. Unique for a given org and task name.\")\n    description :   Optional[str]            = Field(description=\"The description of the task\")\n    prompts     :   List[PromptMessage]      = Field(description=\"The prompt messages used in the prompt task\")\n    created_at  :   float                    = Field(description='The epoch timestamp when the item was created.')", "\n \nclass PromptTaskPostRequest(BaseModel):\n    name:          str                      = Field(description=\"The name of the task. Unique within the org.\")\n    version:       int                      = Field(description=\"The version of the task. Unique for a given org and task name.\")\n    type:          Optional[PromptTaskType] = Field(description=\"The type of task\")        \n    description:   Optional[str]            = Field(description=\"The description of the task\")\n    prompts:       List[PromptMessage]      = Field(description=\"The items that make up the prompt task\")\n\n", "\n\n\n\n"]}
{"filename": "jiggybase/models/plugin_config.py", "chunked_list": ["import os\nfrom pydantic import BaseModel, HttpUrl, Field, validator\nfrom typing import List, Optional\nfrom enum import Enum\nfrom .plugin import PluginAuthType        \nimport re\n\nMODELNAME = re.compile(\"[a-zA-Z][a-zA-Z0-9_]*\")\n\nclass PluginConfig(BaseModel): \n    \"\"\"\n    The user-customizable part of PluginConfig\n    \"\"\"\n    name_for_model:        str = Field(\"retrieval\", max_length=50, description=\"The name of the plugin as it will be appear to the model.\")\n    name_for_human:        str = Field(max_length=50, description=\"The name of the plugin as it will be appear to the human user.\")\n    description_for_model: str = Field(max_length=4000, description=\"Description of the plugin as it will appear to the model.\")\n    description_for_human: str = Field(max_length=120, description=\"Description of the plugin as it will appear to the human user.\")\n    logo:                  Optional[str] = Field(description=\"The logo for the plugin\")\n    logo_url:              Optional[HttpUrl] = Field(description=\"The logo url for the plugin\")\n\n    @validator('name_for_model')\n    def _name_for_model(cls, v):\n        if len(v) > 50 or not v:\n            raise ValueError(f'\"{v}\" is an invalid model name. It must not be empty and is limited to 50 characters.')\n        elif not bool(MODELNAME.match(v)):\n         raise ValueError(f'\"{v}\" is an invalid model name. It can only contain letters, numbers, and underscores, and must start with a letter.')\n        return v", "\nclass PluginConfig(BaseModel): \n    \"\"\"\n    The user-customizable part of PluginConfig\n    \"\"\"\n    name_for_model:        str = Field(\"retrieval\", max_length=50, description=\"The name of the plugin as it will be appear to the model.\")\n    name_for_human:        str = Field(max_length=50, description=\"The name of the plugin as it will be appear to the human user.\")\n    description_for_model: str = Field(max_length=4000, description=\"Description of the plugin as it will appear to the model.\")\n    description_for_human: str = Field(max_length=120, description=\"Description of the plugin as it will appear to the human user.\")\n    logo:                  Optional[str] = Field(description=\"The logo for the plugin\")\n    logo_url:              Optional[HttpUrl] = Field(description=\"The logo url for the plugin\")\n\n    @validator('name_for_model')\n    def _name_for_model(cls, v):\n        if len(v) > 50 or not v:\n            raise ValueError(f'\"{v}\" is an invalid model name. It must not be empty and is limited to 50 characters.')\n        elif not bool(MODELNAME.match(v)):\n         raise ValueError(f'\"{v}\" is an invalid model name. It can only contain letters, numbers, and underscores, and must start with a letter.')\n        return v", "\n\nclass PatchPluginConfigRequest(BaseModel):\n    name_for_model:        Optional[str] = Field(description=\"The plugin name for the model\")\n    name_for_human:        Optional[str] = Field(description=\"The plugin name for human\")\n    description_for_model: Optional[str] = Field(description=\"The plugin description for the model\")\n    description_for_human: Optional[str] = Field(description=\"The plugin description for human\")\n    logo:                  Optional[str] = Field(description=\"The logo for the plugin\")\n    logo_url:              Optional[HttpUrl] = Field(description=\"The logo url for the plugin\")\n\n    @validator('name_for_model')\n    def _name_for_model(cls, v):\n        if len(v) > 50 or not v:\n            raise ValueError(f'\"{v}\" is an invalid model name. It must not be empty and is limited to 50 characters.')\n        elif not bool(MODELNAME.match(v)):\n         raise ValueError(f'\"{v}\" is an invalid model name. It can only contain letters, numbers, and underscores, and must start with a letter.')\n        return v", "\n\n\nclass OpenAIVerificationToken(BaseModel):\n    openai: str\n\n\nclass OpenAIPluginAuthConfigOAuth(BaseModel):\n    \"\"\"\n    The Plugin Oauth configuration as it is presented in the ai-plugin.json \n    \"\"\"\n    type:                       str         = Field(\"oauth\", const=True)\n    client_url:                 HttpUrl     = Field(description=\"ChatGPT will direct the user\u2019s browser to this url to log in to the plugin\")\n    authorization_url:          HttpUrl     = Field(description=\"After successful login ChatGPT will complete the OAuth flow by making a POST request to this URL\")\n    scope:                      str         = Field(description=\"The scope used for the OAuth flow\")    \n    authorization_content_type: str         = Field(\"application/json\", const=True)\n    verification_tokens:        OpenAIVerificationToken = Field(description=\"The verification token to send to OpenAI for the plugin\")", "\n"]}
{"filename": "jiggybase/models/user.py", "chunked_list": ["from typing import Optional\nfrom pydantic import BaseModel, Field, EmailStr\n\n###\n## User\n###\n\nclass User(BaseModel):\n    id:              int = Field(description='Internal user_id')\n    name:            str = Field(min_length=1, max_length=39, description='Unique name for the user.')\n    email:           EmailStr  = Field(description='Email address for the user.')    \n    auth0_userid:    str = Field(description='Auth0 userid.  This can be None for anonymous accounts created via api key')", "\n\nclass UserPostRequest(BaseModel):\n    name:            str           = Field(min_length=1, max_length=39, description='Name for the user.')\n    email:           EmailStr      = Field(description='Email address for the user.')\n    \n\nclass UserPostPatchRequest(BaseModel):\n    name:      Optional[str]      = Field(min_length=1, max_length=39, description='Unique name for the user.')\n", "\n\n\n###\n##  API Key Authentication\n###\n\nclass AuthRequest(BaseModel):\n    key : str = Field(description = \"The API key\")\n    \nclass Jwt(BaseModel):\n    jwt: str = Field(description='The JWT to used as bearer token')", "    \nclass Jwt(BaseModel):\n    jwt: str = Field(description='The JWT to used as bearer token')\n\n\n###\n## API Key\n###\n\n\nclass  ApiKey(BaseModel):\n    key:         str           = Field(default=None, description='The api key.')\n    description: Optional[str] = Field(default=None, description='Optional user supplied description of the key.')\n    created_at:  float         = Field(description='The epoch timestamp when the key was created.')\n    last_used :  float         = Field(description='The epoch timestamp when the key was last used to create a JWT.')", "\n\nclass  ApiKey(BaseModel):\n    key:         str           = Field(default=None, description='The api key.')\n    description: Optional[str] = Field(default=None, description='Optional user supplied description of the key.')\n    created_at:  float         = Field(description='The epoch timestamp when the key was created.')\n    last_used :  float         = Field(description='The epoch timestamp when the key was last used to create a JWT.')\n\n\nclass  ApiKeyRequest(BaseModel):\n    description: Optional[str] = Field(default=None, description='Optional user supplied description of the key.')", "\nclass  ApiKeyRequest(BaseModel):\n    description: Optional[str] = Field(default=None, description='Optional user supplied description of the key.')\n\nclass AllApiKeyResponse(BaseModel):\n    items: list[ApiKey] = Field(description=\"List of all Api Keys\")\n        "]}
{"filename": "jiggybase/models/chat.py", "chunked_list": ["\"\"\"\nConfig for chat-related functionality\n\"\"\"\n\nfrom pydantic import BaseModel, Field\nfrom .chatmodel import ChatModelName\nfrom typing import Optional, List\n\n\nclass CollectionChatConfig(BaseModel):\n    \"\"\"Config for Collection chat-related functionality\"\"\"    \n    model_name          : str           = Field(description=\"The model associated with this configuration\")\n    rate_limit_messages : int           = Field(description=\"The total number of messages allowed in the rate limit time period across all collection users\")\n    rate_limit_hours    : int           = Field(description=\"The number of hours in the rate limit time period\")\n    prompt_task_id      : Optional[int] = Field(description=\"The prompt task id of the prompt to use for chat with this collection\")", "\nclass CollectionChatConfig(BaseModel):\n    \"\"\"Config for Collection chat-related functionality\"\"\"    \n    model_name          : str           = Field(description=\"The model associated with this configuration\")\n    rate_limit_messages : int           = Field(description=\"The total number of messages allowed in the rate limit time period across all collection users\")\n    rate_limit_hours    : int           = Field(description=\"The number of hours in the rate limit time period\")\n    prompt_task_id      : Optional[int] = Field(description=\"The prompt task id of the prompt to use for chat with this collection\")\n\n\nclass PatchCollectionChatConfig(BaseModel):\n    \"\"\"Config for Collection chat-related functionality\"\"\"    \n    prompt_task_id      : Optional[int] = Field(description=\"The prompt task id of the prompt to use for chat with this collection\")", "\nclass PatchCollectionChatConfig(BaseModel):\n    \"\"\"Config for Collection chat-related functionality\"\"\"    \n    prompt_task_id      : Optional[int] = Field(description=\"The prompt task id of the prompt to use for chat with this collection\")\n\n\n\n\n## Chat Completion Request objects sent to the chat completion endpoint\n\nclass Message(BaseModel):\n    role: str\n    content: str", "## Chat Completion Request objects sent to the chat completion endpoint\n\nclass Message(BaseModel):\n    role: str\n    content: str\n    \nclass CompletionRequest(BaseModel):\n    model: str\n    messages: list[Message]\n    max_tokens: Optional[int] = None\n    temperature: float\n    stream: bool", "\n\nclass TypedCompletionRequest(CompletionRequest):\n    json_schema : str\n\n\nclass Choice(BaseModel):\n    finish_reason: str\n    index: int\n    message: Message", "\nclass Usage(BaseModel):\n    completion_tokens: int\n    prompt_tokens: int\n    total_tokens: int\n\nclass ChatCompletion(BaseModel):\n    id: str\n    choices: List[Choice]\n    created: int\n    model: str\n    object: str\n    usage: Usage\n\n    def __str__(self):\n        return self.choices[0].message.content", "    \n\n\nclass ChatUsage(BaseModel):\n    \"\"\"\n    JiggyBase chat completion that was temporarily used before transitioning to the OpenAI ChatCompletion\n    \"\"\"\n    collection_id:   int           = Field(description=\"The collection ID used to inform the completion\")\n    model:           str           = Field(description=\"The name of the model used to generate the completion\")\n    user_message:    str           = Field(description=\"The user's input message\")\n    input_tokens:    int           = Field(description=\"The number of input tokens sent to the model\")\n    output_tokens:   int           = Field(description=\"The number of output tokens generated by the model\")\n    messages_json:   Optional[str] = Field(description=\"JSON representation of the input messages sent to model endpoint\")    \n    completion:      Optional[str] = Field(description=\"The completion text returned by the model\")\n    created_at:      float         = Field(description=\"The epoch timestamp associated with the completion.\")\n    endpoint:        str           = Field(description=\"The JiggyBase endpoint that requested the model completion\")\n    \n    def __str__(self):\n        return self.completion"]}
{"filename": "jiggybase/models/chatmodel.py", "chunked_list": ["\nfrom enum import Enum\n\n \nclass ChatModelName(str, Enum):\n    gpt3_5_turbo :str = \"gpt-3-5-turbo\"\n    gpt4         :str = \"gpt-4\"\n\n    def __str__(self):\n        return str(self.value)    "]}
{"filename": "jiggybase/models/chunk.py", "chunked_list": ["from pydantic import BaseModel, Field\nfrom typing import Optional\n\n\nclass ChunkConfig(BaseModel):\n    \"\"\"\n    configuration for chunking policy\n    \"\"\"\n    chunk_size:                 int = Field(200,   description=\"The target size of each text chunk in tokens\")\n    min_chunk_size_chars:       int = Field(350,   description=\"The minimum size of each text chunk in characters\")\n    min_chunk_length_to_embed:  int = Field(  5,   description=\"Discard chunks shorter than this\")\n    embeddings_batch_size:      int = Field(128,   description=\"The number of embeddings to request at a time\")\n    max_num_chunks:             int = Field(10000, description=\"The maximum number of chunks to generate from a text\")", "\n\n\nclass PatchChunkConfigRequest(BaseModel):\n    chunk_size:                Optional[int] = Field(description=\"The target size of each text chunk in tokens\")\n    min_chunk_size_chars:      Optional[int] = Field(description=\"The minimum size of each text chunk in characters\")\n    min_chunk_length_to_embed: Optional[int] = Field(description=\"Discard chunks shorter than this\")\n    embeddings_batch_size:     Optional[int] = Field(description=\"The number of embeddings to request at a time\")\n    max_num_chunks:            Optional[int] = Field(description=\"The maximum number of chunks to generate from a text\")\n", "\n"]}
{"filename": "jiggybase/models/providers.py", "chunked_list": ["from pydantic import BaseModel, Field\nfrom typing import Optional\n\n\nclass PineconeConfig(BaseModel):\n    api_key: str = Field(..., description=\"Your Pinecone API Key\")\n    environment: str = Field(..., description=\"Your Pinecone environment\")\n    index: str = Field(..., description=\"Your Pinecone index\")\n\n\nclass WeaviateConfig(BaseModel):\n    host: str = Field(..., description=\"Your Weaviate host\")\n    port: int = Field(..., description=\"Your Weaviate port\")\n    index: str = Field(..., description=\"Your Weaviate index\")\n    username: Optional[str] = Field(None, description=\"Your Weaviate username\")\n    password: Optional[str] = Field(None, description=\"Your Weaviate password\")\n    scopes: Optional[str] = Field(None, description=\"Your Weaviate scopes\")\n    batch_size: Optional[int] = Field(None, description=\"Your Weaviate batch size\")\n    batch_dynamic: Optional[bool] = Field(None, description=\"Your Weaviate batch dynamic\")\n    batch_timeout_retries: Optional[int] = Field(None, description=\"Your Weaviate batch timeout retries\")\n    batch_num_workers: Optional[int] = Field(None, description=\"Your Weaviate batch number of workers\")", "\n\nclass WeaviateConfig(BaseModel):\n    host: str = Field(..., description=\"Your Weaviate host\")\n    port: int = Field(..., description=\"Your Weaviate port\")\n    index: str = Field(..., description=\"Your Weaviate index\")\n    username: Optional[str] = Field(None, description=\"Your Weaviate username\")\n    password: Optional[str] = Field(None, description=\"Your Weaviate password\")\n    scopes: Optional[str] = Field(None, description=\"Your Weaviate scopes\")\n    batch_size: Optional[int] = Field(None, description=\"Your Weaviate batch size\")\n    batch_dynamic: Optional[bool] = Field(None, description=\"Your Weaviate batch dynamic\")\n    batch_timeout_retries: Optional[int] = Field(None, description=\"Your Weaviate batch timeout retries\")\n    batch_num_workers: Optional[int] = Field(None, description=\"Your Weaviate batch number of workers\")", "\n\nclass ZillizConfig(BaseModel):\n    collection: str = Field(..., description=\"Your Zilliz collection\")\n    uri: str = Field(..., description=\"Your Zilliz URI\")\n    user: str = Field(..., description=\"Your Zilliz username\")\n    password: str = Field(..., description=\"Your Zilliz password\")\n\n\nclass MilvusConfig(BaseModel):\n    collection: str = Field(..., description=\"Your Milvus collection\")\n    host: str = Field(..., description=\"Your Milvus host\")\n    port: str = Field(default=\"19530\", description=\"Your Milvus port\")\n    user: str = Field(None, description=\"Your Milvus username\")\n    password: str = Field(None, description=\"Your Milvus password\")\n    index_params: Optional[str] = Field(..., description=\"Custom index options for the collection.\")\n    search_params: Optional[str] = Field(..., description=\"Custom search options for the collection\")\n    consistency_level: Optional[str] = Field(..., description=\"Custom consistency level for the collection\")", "\nclass MilvusConfig(BaseModel):\n    collection: str = Field(..., description=\"Your Milvus collection\")\n    host: str = Field(..., description=\"Your Milvus host\")\n    port: str = Field(default=\"19530\", description=\"Your Milvus port\")\n    user: str = Field(None, description=\"Your Milvus username\")\n    password: str = Field(None, description=\"Your Milvus password\")\n    index_params: Optional[str] = Field(..., description=\"Custom index options for the collection.\")\n    search_params: Optional[str] = Field(..., description=\"Custom search options for the collection\")\n    consistency_level: Optional[str] = Field(..., description=\"Custom consistency level for the collection\")", "    \nclass QdrantConfig(BaseModel):\n    url: str = Field(..., description=\"Your Qdrant URL\")\n    port: str = Field(\"6333\", description=\"Your Qdrant port\")\n    grpc_port: str = Field(\"6334\", description=\"Your Qdrant gRPC port\")\n    api_key: str = Field(..., description=\"Your Qdrant API key\")\n    collection: str = Field(..., description=\"Your Qdrant collection\")\n\n\nclass RedisConfig(BaseModel):\n    host: str = Field(..., description=\"Your Redis host\")\n    port: int = Field(..., description=\"Your Redis port\")\n    password: str = Field(None, description=\"Your Redis password\")\n    index_name: str = Field(..., description=\"Your Redis index name\")\n    doc_prefix: str = Field(..., description=\"Your Redis document prefix\")\n    distance_metric: Optional[str] = Field(None, description=\"Your Redis distance metric\")\n    index_type: Optional[str] = Field(None, description=\"Your Redis index type\")", "\nclass RedisConfig(BaseModel):\n    host: str = Field(..., description=\"Your Redis host\")\n    port: int = Field(..., description=\"Your Redis port\")\n    password: str = Field(None, description=\"Your Redis password\")\n    index_name: str = Field(..., description=\"Your Redis index name\")\n    doc_prefix: str = Field(..., description=\"Your Redis document prefix\")\n    distance_metric: Optional[str] = Field(None, description=\"Your Redis distance metric\")\n    index_type: Optional[str] = Field(None, description=\"Your Redis index type\")\n", "\n"]}
{"filename": "jiggybase/examples/chat_completion_stream.py", "chunked_list": ["import jiggybase\nimport sys\n\n\ncollection = jiggybase.JiggyBase().collection('hackernews-summary')\n\nmessages = [{'role':'user',  'content': 'articles about python 3.11'}]\n\nfor outstr in collection._chat_completion_stream_str(messages, temperature=0):\n    sys.stdout.write(outstr)\n    sys.stdout.flush()", "for outstr in collection._chat_completion_stream_str(messages, temperature=0):\n    sys.stdout.write(outstr)\n    sys.stdout.flush()\nprint()\n"]}
{"filename": "jiggybase/examples/qa_example.py", "chunked_list": ["import csv\nimport os\nimport tempfile\nimport shutil\nfrom dotenv import load_dotenv\nimport jiggybase\n\ndef get_answer(question):\n    messages = [{'role':'user',  'content': question}]\n    collection_name = os.getenv(\"JIGGYBASE_COLLECTION_NAME\")\n    collection = jiggybase.JiggyBase().collection(collection_name)\n    rsp = collection._chat_completion(messages)\n    return rsp", "\ndef fill_answers(input_csv):\n    with tempfile.NamedTemporaryFile(mode='w+', newline='', delete=False) as temp_file:\n        with open(input_csv, \"r\", newline='') as infile, open(temp_file.name, \"w\", newline='') as outfile:\n            reader = csv.reader(infile)\n            writer = csv.writer(outfile)\n    \n            # Verify the header and write it to the output file\n            header = next(reader)\n            assert header == [\"question\", \"answer\"], \"Invalid header\"\n            writer.writerow(header)\n    \n            # Iterate over the rows, filling in answers when needed\n            for row in reader:\n                question, answer = row\n                if not answer or answer.strip() == \"\":\n                    answer = get_answer(question)\n                    row = [question, answer]\n                writer.writerow(row)\n\n        # Replace the original input file with the updated file\n        shutil.move(temp_file.name, input_csv)", "\nload_dotenv()\ninput_csv = \"input.csv\"\nfill_answers(input_csv)\n"]}
{"filename": "jiggybase/examples/upload_email_example.py", "chunked_list": ["import os\nimport json\nimport jiggybase\nfrom  jiggybase.models import Document, DocumentMetadata, Source\n\n\njb = jiggybase.JiggyBase()\n\nJIGGYBASE_ORG = os.environ[\"JIGGYBASE_ORG\"]\nJIGGYBASE_COLLECTION = os.environ[\"JIGGYBASE_COLLECTION\"]", "JIGGYBASE_ORG = os.environ[\"JIGGYBASE_ORG\"]\nJIGGYBASE_COLLECTION = os.environ[\"JIGGYBASE_COLLECTION\"]\n\norg = jb.get_org(JIGGYBASE_ORG)\ncollection = org.collection(JIGGYBASE_COLLECTION)\n\n\nother_metadata = {\"to\": ['bob@example.com'], \"cc\": ['hr@example.com', 'legal@example.com']}\n\n# Example email metadata", "\n# Example email metadata\nemail_metadata = DocumentMetadata(\n    source     = Source.email,\n    created_at = \"2022-02-15T10:30:00\",        # using ISO 8601 format (YYYY-MM-DDTHH:MM:SS) makes it possible to filter by date\n    author     = \"Alice <alice@example.com>\",  # sender name and optional email address\n    title      = \"Reminder: Friday Meeting\",   # subject\n    description = json.dumps(other_metadata)   # put any other metadata here that is associated with the entire document \n)\n", ")\n\n# Create a Document object with the email text and metadata\nemail_document = Document(\n    id       = \"XX4HJ823930JK\",   # unique ID for the document\n    metadata = email_metadata,\n    text     = \"Hello Bob, I hope you're doing well. I just wanted to remind you about the upcoming meeting on Friday. Best, Alice\",    \n)\n\n# Upsert the email_document into test_collection", "\n# Upsert the email_document into test_collection\nupsert_response = collection.upsert(documents=[email_document])\nprint(upsert_response)\n"]}
{"filename": "jiggybase/examples/jiggybase_upload.py", "chunked_list": ["#! /usr/bin/env python3\n\nimport os\nimport sys\nimport argparse\nimport jiggybase\n\njb = jiggybase.JiggyBase()\n\nJIGGYBASE_ORG = os.environ.get(\"JIGGYBASE_ORG\")", "\nJIGGYBASE_ORG = os.environ.get(\"JIGGYBASE_ORG\")\nJIGGYBASE_COLLECTION = os.environ.get(\"JIGGYBASE_COLLECTION\")\n\n\ndef upload_file(collection : jiggybase.models.Collection, filename : str):\n    print(f'Uploading {filename}')\n    try:\n        upsert_rsp = collection.upsert_file(filename)\n    except Exception as e:            \n        print(f'error on {filename}: {e}')\n        return\n    doc_id = upsert_rsp.ids[0]\n    dcl =  collection.get_doc(doc_id)\n    text_len = len(\" \".join([dc.text for dc in dcl]))\n    title = dcl[0].metadata.title if dcl[0].metadata.title else \"Unnown Title\"\n    print(f'Processed {filename}: \"{title}\"  {text_len//1024} KB text ({len(dcl)} chunks)')", "    \n\ndef upload_directory(collection : jiggybase.models.Collection, dirname : str):\n    for fn in os.listdir(dirname):\n        fn = os.path.join(dirname, fn)\n        upload_file(collection, fn)\n\n\nepilog = \"If neither '--file' nor '--dir' options are provided, the script will automatically process other arguments as a file or directory\"\n", "epilog = \"If neither '--file' nor '--dir' options are provided, the script will automatically process other arguments as a file or directory\"\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Upload a file or directory to a JiggyBase collection\",  epilog=epilog )    \n    parser.add_argument(\"--org\", type=str, help=\"The name of your JiggyBase organization.  Alternatively, set JIGGYBASE_ORG environment variable or be a member of a single Org.\")\n    parser.add_argument(\"--collection\", type=str, help=\"The name of your JiggyBase collection. Alternatively, set JIGGYBASE_COLLECTION environment variable or have a single collection in your org.\")\n    parser.add_argument(\"--dir\", type=str, help=\"The directory you want to upload.\")\n    parser.add_argument(\"--file\", type=str, help=\"The file you want to upload\")\n\n    if len(sys.argv) == 1:\n        parser.print_help(sys.stderr)\n        sys.exit(1)\n\n    parsed_args, unknown_args = parser.parse_known_args(sys.argv[1:])\n    if not parsed_args.org:\n        orgs = jb.orgs()\n        if len(orgs) > 1:\n            print(\"Please provide an organization name using the --org option\")\n            sys.exit(1)\n        elif JIGGYBASE_ORG:\n            org = jb.get_org(JIGGYBASE_ORG)\n        else:\n            org = orgs[0]\n    else:\n        org = jb.get_org(parsed_args.org)\n\n    if not parsed_args.collection:\n        collections = org.collections()\n        if len(collections) > 1:\n            print(\"Please provide a collection name using the --collection option\")\n            sys.exit(1)\n        elif JIGGYBASE_COLLECTION:\n            collection = org.collection(JIGGYBASE_COLLECTION)\n        else:\n            collection = collections[0]\n    else:\n        collection = org.collection(parsed_args.collection)\n\n    if parsed_args.dir:\n        upload_directory(collection, parsed_args.dir)\n    elif parsed_args.file:\n        upload_file(collection, parsed_args.file)\n    elif unknown_args:\n        for arg in unknown_args:\n            if os.path.isfile(arg):\n                upload_file(collection, arg)\n            elif os.path.isdir(arg):\n                upload_directory(collection, arg)\n            else:\n                print(f\"Skipping unknown argument: {arg}\")\n    else:\n        print(\"Please provide a valid file or directory to upload\")\n        parser.print_help(sys.stderr)\n        sys.exit(1)", "\n\nif __name__ == \"__main__\":\n    main()\n"]}
{"filename": "jiggybase/examples/confluence_sync.py", "chunked_list": ["#!/usr/bin/env python3\n\"\"\"\nSpecification:\n\nSync the text content in a Confluence Space into a JiggyBase Collection\n\n\nTakes the following config from the command line or via environment variables:\n\n--user  or ATLASSIAN_USER   environment variable", "\n--user  or ATLASSIAN_USER   environment variable\n--token or ATLASSIAN_TOKEN  environment variable   \n--url   or CONFLUENCE_URL   environment variable   \n--space or CONFLUENCE_SPACE environment variable   The space key, id, or name of the space to sync\n--org   or JIGGYBASE_ORG    environment variable   The JiggyBase org to sync to\n\n\nTo create an Atlassian API token go to \nhttps://id.atlassian.com/manage-profile/security/api-tokens", "To create an Atlassian API token go to \nhttps://id.atlassian.com/manage-profile/security/api-tokens\nand click on Create API token. Save the value into an environment variable.\nE.g. on Macos\nexport ATLASSIAN_TOKEN=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n\n\nIf a JiggyBase API token is not set then the JiggyBase SDK will open a web browser on the page to copy it from the JiggyBase dashboard.\n\nImplementation notes:", "\nImplementation notes:\nUses page['version']['when'] as document created_at timestamp and version indicator\nUses page['id'] as document id (unique within a collection)\n\nIf a given document ID exists in both confluence and jiggybase, check  \nRe-uploads a page if the version has changed from what is in the metadata\n\n\"\"\"\n", "\"\"\"\n\n# pip install atlassian-python-api\nfrom atlassian import Confluence\nimport os\nimport argparse\nimport jiggybase\nimport requests \n\n\ndef upsert_file(collection : jiggybase.models.Collection, filename : str):\n    print(f'Uploading {filename}')\n    try:\n        upsert_rsp = collection.upsert_file(filename)\n    except Exception as e:            \n        print(f'error on {filename}: {e}')\n        return\n    doc_id = upsert_rsp.ids[0]\n    dcl =  collection.get_doc(doc_id)\n    text_len = len(\" \".join([dc.text for dc in dcl]))\n    title = dcl[0].metadata.title if dcl[0].metadata.title else \"Unnown Title\"\n    print(f'Processed {filename}: \"{title}\"  {text_len//1024} KB text ({len(dcl)} chunks)')", "\n\ndef upsert_file(collection : jiggybase.models.Collection, filename : str):\n    print(f'Uploading {filename}')\n    try:\n        upsert_rsp = collection.upsert_file(filename)\n    except Exception as e:            \n        print(f'error on {filename}: {e}')\n        return\n    doc_id = upsert_rsp.ids[0]\n    dcl =  collection.get_doc(doc_id)\n    text_len = len(\" \".join([dc.text for dc in dcl]))\n    title = dcl[0].metadata.title if dcl[0].metadata.title else \"Unnown Title\"\n    print(f'Processed {filename}: \"{title}\"  {text_len//1024} KB text ({len(dcl)} chunks)')", "\n\ndef save_attachment_to_file(confluence, attachment):\n    title = attachment['title']\n    download_link = attachment['_links']['download']\n    download_url = f'{confluence.url}{download_link}'\n    \n    response = requests.get(download_url, auth=(confluence.username, confluence.password))\n    \n    if response.status_code == 200:\n        with open(title, 'wb') as file:\n            file.write(response.content)\n        return title\n    else:\n        print(f\"Error downloading attachment '{title}': {response.status_code}\")\n        return None", "\n\n\ndef sync_confluence_space_to_jiggybase_collection(confluence, space, org):\n    \"\"\"\n    \"\"\"\n    try:\n        space_collection = org.collection(space['name'])\n        print(f\"Found existing JiggyBase collection {space['name']}\")\n    except:\n        space_collection = org.create_collection(space['name'])\n        print(f\"Created new JiggyBase collection {space['name']}\")\n\n    # Delete all documents in the collection\n    print(f\"Deleting all prior documents in JiggyBase collection {space['name']}\")\n    space_collection.delete_docs(delete_all=True)\n\n    # Get all pages in the space\n    pages = confluence.get_all_pages_from_space(space['key'])\n\n    # Loop through each page and process it\n    for page in pages:\n        # Download page as Word document\n        doc_content = confluence.get_page_as_word(page['id'])\n        doc_filename = f\"{page['title']}.doc\"\n        \n        # Save the Word document locally\n        with open(doc_filename, 'wb') as doc_file:\n            doc_file.write(doc_content)\n        \n        # Upload the Word document to JiggyBase collection\n        upsert_file(space_collection, doc_filename)\n        os.remove(doc_filename)\n        \n        # Get all attachments from the page\n        attachments = confluence.get_attachments_from_content(page['id'])['results']\n\n        # Download and upload each attachment to JiggyBase collection\n        for attachment in attachments:\n            if attachment['title'].split('.')[-1] in ['svg']:\n                # skip unsupported file types\n                continue\n            print(f\"Downloading attachment {attachment['title']} from page {page['title']}\")\n            attachment_filename = save_attachment_to_file(confluence, attachment)\n            if attachment_filename:\n                upsert_file(space_collection, attachment_filename)            \n            os.remove(attachment_filename)\n                \n        print(f\"Finished syncing {page['title']} and its attachments.\")", "\n\n        \n\ndef main():\n    # Handle command line arguments and environment variables\n    parser = argparse.ArgumentParser(description=\"Sync Confluence Space to JiggyBase Collection\")\n    parser.add_argument('--user', default=os.environ.get('ATLASSIAN_USER'))\n    parser.add_argument('--token', default=os.environ.get('ATLASSIAN_TOKEN'))\n    parser.add_argument('--url', default=os.environ.get('CONFLUENCE_URL'))\n    parser.add_argument('--space', default=os.environ.get('CONFLUENCE_SPACE'))\n    parser.add_argument('--org', default=os.environ.get('JIGGYBASE_ORG'))\n    \n    args = parser.parse_args()\n\n    jb = jiggybase.JiggyBase()\n\n    orgs = jb.orgs()\n        \n   # Check if all required arguments are provided\n    missing_args = []\n    if not args.user:\n        missing_args.append('--user  or ATLASSIAN_USER   environment variable')\n    if not args.token:\n        missing_args.append('--token or ATLASSIAN_TOKEN  environment variable')\n    if not args.url:\n        missing_args.append('--url   or CONFLUENCE_URL   environment variable')\n    if not args.org and len(orgs) > 1:\n        missing_args.append('--org   or JIGGYBASE_ORG   environment variable')\n        \n    if missing_args:\n        print(\"\\nError: The following required arguments are missing:\")\n        for arg in missing_args:\n            print(f\"- {arg}\")\n        print()\n        parser.print_help()\n        return\n    \n    # Connect to Confluence API\n    confluence = Confluence(args.url, username=args.user, password=args.token)\n    \n    # Get all spaces and find the matching space\n    all_spaces = confluence.get_all_spaces()\n    matching_space = None\n    \n    for space in all_spaces['results']:\n        if args.space in [space['key'], space['name'], str(space['id'])]:\n            matching_space = space\n            break\n\n    if matching_space:\n        print(f\"Matched Space: {matching_space['name']} (ID: {matching_space['id']})\")\n    else:\n        print(\"No matching space found. Available spaces:\")\n        for space in all_spaces['results']:\n            print(f\"- {space['name']:20}  (ID: {space['id']})  key = {space['key']}\")\n        return\n    \n    if len(orgs) == 1:\n        org = orgs[0]\n    else:\n        org = jb.get_org(args.org)\n    print(f\"Using JiggyBase org {org.name} (ID: {org.id})\")\n    \n    sync_confluence_space_to_jiggybase_collection(confluence, matching_space, org)", "\nif __name__ == \"__main__\":\n    main()\n\n"]}
{"filename": "jiggybase/examples/chat_completion.py", "chunked_list": ["import jiggybase\n\ncollection = jiggybase.JiggyBase().collection('hackernews-summary')   # replace with your collection name\n\nmessages = [{'role':'user',  'content': 'articles about python 3.11'}]\n\nrsp = collection._chat_completion(messages, temperature=0, model=\"gpt-3.5-turbo\")   # note _ as this is preliminary low-level interface\n\nprint(rsp)\n", "print(rsp)\n\n\"\"\"\nHere are some articles about Python 3.11:\n\n1. Python 3.11.1, 3.10.9, 3.9.16, 3.8.16, 3.7.16, and 3.12.0 alpha 3 now available - This is a blog post from the official Python Software Foundation blog. The post is announcing the release of Python 3.11.1, 3.10.9, 3.9.16, 3.8.16, 3.7.16, and 3.12.0 alpha 3. The post goes over some of the security content in the new releases.\n\n2. Python 3.11 Is Much Faster, but Pyston and PyPy Still Show Advantages - This is a news article from the website www.phoronix.com. It discusses the recent Python 3.11 beta benchmarks and compares them to alternative Python implementations like PyPy and Pyston. It also includes Python 3.11b3 results.\n\n3. A Team at Microsoft Is Helping Make Python Faster - This is a blog post about the Faster CPython Team at Microsoft. It details the team's mission to make Python faster, the specialized knowledge and collaboration of the team, and Microsoft's commitment to the Python community. It also highlights the team's work on Python 3.11 and their plans for Python 3.12.", "\n3. A Team at Microsoft Is Helping Make Python Faster - This is a blog post about the Faster CPython Team at Microsoft. It details the team's mission to make Python faster, the specialized knowledge and collaboration of the team, and Microsoft's commitment to the Python community. It also highlights the team's work on Python 3.11 and their plans for Python 3.12.\n\nI hope this helps!\n\"\"\"\n"]}
