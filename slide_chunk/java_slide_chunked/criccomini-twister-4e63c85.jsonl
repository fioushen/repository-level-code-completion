{"filename": "twister-proto/src/test/java/dev/twister/proto/ProtoWriterTest.java", "chunked_list": ["package dev.twister.proto;\n\nimport com.github.os72.protobuf.dynamic.DynamicSchema;\nimport com.github.os72.protobuf.dynamic.MessageDefinition;\nimport com.google.protobuf.ByteString;\nimport com.google.protobuf.Descriptors.Descriptor;\nimport com.google.protobuf.DynamicMessage;\nimport junit.framework.TestCase;\n\nimport java.math.BigInteger;", "\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.*;\n\npublic class ProtoWriterTest extends TestCase {\n    public void testWrite() throws Exception {\n        // Define a message with all necessary fields\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"required\", \"int32\", \"int32_field\", 1)\n                .addField(\"required\", \"int64\", \"int64_field\", 2)\n                .addField(\"required\", \"uint32\", \"uint32_field\", 3)\n                .addField(\"required\", \"uint64\", \"uint64_field\", 4)\n                .addField(\"required\", \"sint32\", \"sint32_field\", 5)\n                .addField(\"required\", \"sint64\", \"sint64_field\", 6)\n                .addField(\"required\", \"bool\", \"bool_field\", 7)\n                .addField(\"required\", \"string\", \"enum_field\", 8)\n                .addField(\"required\", \"fixed64\", \"fixed64_field\", 9)\n                .addField(\"required\", \"sfixed64\", \"sfixed64_field\", 10)\n                .addField(\"required\", \"double\", \"double_field\", 11)\n                .addField(\"required\", \"string\", \"string_field\", 12)\n                .addField(\"required\", \"bytes\", \"bytes_field\", 13)\n                .addField(\"required\", \"fixed32\", \"fixed32_field\", 14)\n                .addField(\"required\", \"sfixed32\", \"sfixed32_field\", 15)\n                .addField(\"required\", \"uint32\", \"big_uint32_field\", 16)\n                .addField(\"required\", \"uint64\", \"big_uint64_field\", 17)\n                .addField(\"required\", \"fixed32\", \"big_fixed32_field\", 18)\n                .addField(\"required\", \"fixed64\", \"big_fixed64_field\", 19)\n                .build();\n\n        // Create a dynamic schema\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .setName(\"TestSchema.proto\")\n                .addMessageDefinition(msgDef)\n                .build();\n\n        // Get descriptor for the dynamic message\n        Descriptor descriptor = schema.getMessageDescriptor(\"TestMessage\");\n\n        // Create a map with the same field names and values\n        Map<String, Object> object = new HashMap<>();\n        object.put(\"int32_field\", 1);\n        object.put(\"int64_field\", 2L);\n        object.put(\"uint32_field\", 3L);\n        object.put(\"uint64_field\", BigInteger.valueOf(4));\n        object.put(\"sint32_field\", 5);\n        object.put(\"sint64_field\", 6L);\n        object.put(\"bool_field\", true);\n        object.put(\"enum_field\", \"ENUM_VALUE\");\n        object.put(\"fixed64_field\", BigInteger.valueOf(9));\n        object.put(\"sfixed64_field\", 10L);\n        object.put(\"double_field\", 11.0);\n        object.put(\"string_field\", \"test string\");\n        object.put(\"bytes_field\", ByteBuffer.wrap(new byte[]{1, 2, 3, 4}));\n        object.put(\"fixed32_field\", 14L);\n        object.put(\"sfixed32_field\", 15);\n        object.put(\"big_uint32_field\", 4294967295L);\n        object.put(\"big_uint64_field\", new BigInteger(\"18446744073709551615\"));\n        object.put(\"big_fixed32_field\", 4294967295L);\n        object.put(\"big_fixed64_field\", new BigInteger(\"18446744073709551615\"));\n\n\n        // Create ProtoWriter instance and write the map into a ByteBuffer\n        ProtoWriter writer = new ProtoWriter();\n        ByteBuffer outputBuffer = writer.write(object, descriptor);\n\n        // Parse the ByteBuffer back into a DynamicMessage\n        byte[] outputBytes = new byte[outputBuffer.remaining()];\n        outputBuffer.get(outputBytes);\n        DynamicMessage dynamicMessage = DynamicMessage.parseFrom(descriptor, outputBytes);\n\n        // Assert that the values of each field are as expected\n        assertEquals(1, dynamicMessage.getField(descriptor.findFieldByName(\"int32_field\")));\n        assertEquals(2L, dynamicMessage.getField(descriptor.findFieldByName(\"int64_field\")));\n        assertEquals(3, dynamicMessage.getField(descriptor.findFieldByName(\"uint32_field\")));\n        assertEquals(4L, dynamicMessage.getField(descriptor.findFieldByName(\"uint64_field\")));\n        assertEquals(5, dynamicMessage.getField(descriptor.findFieldByName(\"sint32_field\")));\n        assertEquals(6L, dynamicMessage.getField(descriptor.findFieldByName(\"sint64_field\")));\n        assertEquals(true, dynamicMessage.getField(descriptor.findFieldByName(\"bool_field\")));\n        assertEquals(\"ENUM_VALUE\", dynamicMessage.getField(descriptor.findFieldByName(\"enum_field\")));\n        assertEquals(9L, dynamicMessage.getField(descriptor.findFieldByName(\"fixed64_field\")));\n        assertEquals(10L, dynamicMessage.getField(descriptor.findFieldByName(\"sfixed64_field\")));\n        assertEquals(11.0, dynamicMessage.getField(descriptor.findFieldByName(\"double_field\")));\n        assertEquals(\"test string\", dynamicMessage.getField(descriptor.findFieldByName(\"string_field\")));\n        assertTrue(Arrays.equals(new byte[]{1, 2, 3, 4}, ((ByteString) dynamicMessage.getField(descriptor.findFieldByName(\"bytes_field\"))).toByteArray()));\n        assertEquals(14, dynamicMessage.getField(descriptor.findFieldByName(\"fixed32_field\")));\n        assertEquals(15, dynamicMessage.getField(descriptor.findFieldByName(\"sfixed32_field\")));\n        assertEquals((int) 4294967295L, dynamicMessage.getField(descriptor.findFieldByName(\"big_uint32_field\")));\n        assertEquals(Long.parseUnsignedLong(\"18446744073709551615\"), dynamicMessage.getField(descriptor.findFieldByName(\"big_uint64_field\")));\n        assertEquals((int) 4294967295L, dynamicMessage.getField(descriptor.findFieldByName(\"big_fixed32_field\")));\n        assertEquals(Long.parseUnsignedLong(\"18446744073709551615\"), dynamicMessage.getField(descriptor.findFieldByName(\"big_fixed64_field\")));\n    }\n", "    public void testRepeatedFields() throws Exception {\n        // Define a message with a repeated field\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"repeated\", \"int32\", \"int32_field\", 1)\n                .build();\n\n        // Create a dynamic schema\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .setName(\"TestSchema.proto\")\n                .addMessageDefinition(msgDef)\n                .build();\n\n        // Get descriptor for the dynamic message\n        Descriptor descriptor = schema.getMessageDescriptor(\"TestMessage\");\n\n        // Create a map with a repeated field\n        Map<String, Object> object = new HashMap<>();\n        object.put(\"int32_field\", Arrays.asList(1, 2, 3, 4, 5));\n\n        // Create ProtoWriter instance and write the map into a ByteBuffer\n        ByteBuffer outputBuffer = new ProtoWriter().write(object, descriptor);\n\n        // Parse the ByteBuffer back into a DynamicMessage\n        byte[] outputBytes = new byte[outputBuffer.remaining()];\n        outputBuffer.get(outputBytes);\n        DynamicMessage dynamicMessage = DynamicMessage.parseFrom(descriptor, outputBytes);\n\n        // Assert that the values of the repeated field are as expected\n        @SuppressWarnings(\"unchecked\")\n        List<Integer> actualValues = (List<Integer>) dynamicMessage.getField(descriptor.findFieldByName(\"int32_field\"));\n        List<Integer> expectedValues = Arrays.asList(1, 2, 3, 4, 5);\n        assertEquals(expectedValues, actualValues);\n    }\n", "    public void testNestedMessage() throws Exception {\n        // Define a nested message\n        MessageDefinition nestedMsgDef = MessageDefinition.newBuilder(\"NestedMessage\")\n                .addField(\"required\", \"int32\", \"nested_int32_field\", 1)\n                .build();\n\n        // Define a message with a nested message field\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"required\", \"NestedMessage\", \"nested_message_field\", 1)\n                .build();\n\n        // Create a dynamic schema\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .setName(\"TestSchema.proto\")\n                .addMessageDefinition(nestedMsgDef)\n                .addMessageDefinition(msgDef)\n                .build();\n\n        // Get descriptor for the dynamic message\n        Descriptor descriptor = schema.getMessageDescriptor(\"TestMessage\");\n\n        // Create a map with a nested map\n        Map<String, Object> nestedObject = new HashMap<>();\n        nestedObject.put(\"nested_int32_field\", 42);\n\n        Map<String, Object> object = new HashMap<>();\n        object.put(\"nested_message_field\", nestedObject);\n\n        // Create ProtoWriter instance and write the map into a ByteBuffer\n        ByteBuffer outputBuffer = new ProtoWriter().write(object, descriptor);\n\n        // Parse the ByteBuffer back into a DynamicMessage\n        byte[] outputBytes = new byte[outputBuffer.remaining()];\n        outputBuffer.get(outputBytes);\n        DynamicMessage dynamicMessage = DynamicMessage.parseFrom(descriptor, outputBytes);\n\n        // Assert that the values of the nested message field are as expected\n        DynamicMessage nestedMessage = (DynamicMessage) dynamicMessage.getField(descriptor.findFieldByName(\"nested_message_field\"));\n        assertEquals(42, nestedMessage.getField(nestedMessage.getDescriptorForType().findFieldByName(\"nested_int32_field\")));\n    }\n", "    public void testWriteWithInferredDescriptor() throws Exception {\n        // Define a simple message\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"required\", \"int32\", \"id\", 1)\n                .addField(\"optional\", \"string\", \"name\", 2)\n                .build();\n\n        // Create a dynamic schema\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .setName(\"TestSchema.proto\")\n                .addMessageDefinition(msgDef)\n                .build();\n\n        // Create a map with primitive values\n        Map<String, Object> object = new LinkedHashMap<>();\n        object.put(\"id\", 42);\n        object.put(\"name\", \"Test\");\n\n        // Create ProtoWriter instance and write the map into a ByteBuffer\n        ByteBuffer outputBuffer = new ProtoWriter().write(object, \"TestMessage\");\n\n        // Parse the ByteBuffer back into a DynamicMessage\n        byte[] outputBytes = new byte[outputBuffer.remaining()];\n        outputBuffer.get(outputBytes);\n\n        Descriptor descriptor = schema.getMessageDescriptor(\"TestMessage\");\n        DynamicMessage dynamicMessage = DynamicMessage.parseFrom(descriptor, outputBytes);\n\n        // Assert that the values of the message fields are as expected\n        assertEquals(42, dynamicMessage.getField(descriptor.findFieldByName(\"id\")));\n        assertEquals(\"Test\", dynamicMessage.getField(descriptor.findFieldByName(\"name\")));\n    }\n}\n"]}
{"filename": "twister-proto/src/test/java/dev/twister/proto/ProtoReaderTest.java", "chunked_list": ["package dev.twister.proto;\n\nimport com.github.os72.protobuf.dynamic.DynamicSchema;\nimport com.github.os72.protobuf.dynamic.EnumDefinition;\nimport com.github.os72.protobuf.dynamic.MessageDefinition;\nimport com.google.protobuf.Descriptors;\nimport com.google.protobuf.Descriptors.Descriptor;\nimport com.google.protobuf.DynamicMessage;\n\nimport junit.framework.TestCase;", "\nimport junit.framework.TestCase;\n\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.List;\nimport java.util.Map;\n\npublic class ProtoReaderTest extends TestCase {\n    public void testRead() throws Exception {\n        // Load the schema from the .proto schema string\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"PersonSchemaDynamic.proto\");\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"required\", \"int32\", \"int_field\", 1)\n                .addField(\"required\", \"string\", \"str_field\", 2)\n                .addField(\"repeated\", \"int32\", \"repeated_field\", 3)\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema schema = schemaBuilder.build();\n        Descriptor descriptor = schema.getMessageDescriptor(\"TestMessage\");\n\n        // Create a test message using the descriptor\n        DynamicMessage.Builder dynamicMessageBuilder = DynamicMessage.newBuilder(descriptor);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"int_field\"), 150);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"str_field\"), \"foo\");\n        dynamicMessageBuilder.addRepeatedField(descriptor.findFieldByName(\"repeated_field\"), 2147483647);\n        dynamicMessageBuilder.addRepeatedField(descriptor.findFieldByName(\"repeated_field\"), 7);\n\n        // Serialize the DynamicMessage to a ByteBuffer\n        ByteBuffer byteBuffer = ByteBuffer.wrap(dynamicMessageBuilder.build().toByteArray());\n\n        // Convert the byte buffer to a map using the descriptor\n        Map<String, Object> resultMap = ProtoReader.read(byteBuffer, descriptor);\n\n        // Verify the result\n        assertEquals(150, resultMap.get(\"int_field\"));\n        assertEquals(\"foo\", resultMap.get(\"str_field\"));\n        assertEquals(List.of(2147483647, 7), resultMap.get(\"repeated_field\"));\n    }\n", "public class ProtoReaderTest extends TestCase {\n    public void testRead() throws Exception {\n        // Load the schema from the .proto schema string\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"PersonSchemaDynamic.proto\");\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"required\", \"int32\", \"int_field\", 1)\n                .addField(\"required\", \"string\", \"str_field\", 2)\n                .addField(\"repeated\", \"int32\", \"repeated_field\", 3)\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema schema = schemaBuilder.build();\n        Descriptor descriptor = schema.getMessageDescriptor(\"TestMessage\");\n\n        // Create a test message using the descriptor\n        DynamicMessage.Builder dynamicMessageBuilder = DynamicMessage.newBuilder(descriptor);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"int_field\"), 150);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"str_field\"), \"foo\");\n        dynamicMessageBuilder.addRepeatedField(descriptor.findFieldByName(\"repeated_field\"), 2147483647);\n        dynamicMessageBuilder.addRepeatedField(descriptor.findFieldByName(\"repeated_field\"), 7);\n\n        // Serialize the DynamicMessage to a ByteBuffer\n        ByteBuffer byteBuffer = ByteBuffer.wrap(dynamicMessageBuilder.build().toByteArray());\n\n        // Convert the byte buffer to a map using the descriptor\n        Map<String, Object> resultMap = ProtoReader.read(byteBuffer, descriptor);\n\n        // Verify the result\n        assertEquals(150, resultMap.get(\"int_field\"));\n        assertEquals(\"foo\", resultMap.get(\"str_field\"));\n        assertEquals(List.of(2147483647, 7), resultMap.get(\"repeated_field\"));\n    }\n", "    public void testReadOneof() throws Exception {\n        // Load the schema from the .proto schema string\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"OneofSchemaDynamic.proto\");\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"OneofTestMessage\")\n                .addField(\"optional\", \"int32\", \"optional_field\", 3)\n                .addField(\"required\", \"string\", \"required_field\", 4)\n                .addOneof(\"oneof_field\")\n                .addField(\"int32\", \"int_field\", 1)\n                .addField(\"string\", \"str_field\", 2)\n                .msgDefBuilder()\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema schema = schemaBuilder.build();\n        Descriptor descriptor = schema.getMessageDescriptor(\"OneofTestMessage\");\n\n        // Create a test message using the descriptor\n        DynamicMessage.Builder dynamicMessageBuilder = DynamicMessage.newBuilder(descriptor);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"required_field\"), \"bar\");\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"str_field\"), \"oneof string\");\n\n        // Serialize the DynamicMessage to a ByteBuffer\n        ByteBuffer byteBuffer = ByteBuffer.wrap(dynamicMessageBuilder.build().toByteArray());\n\n        // Convert the byte buffer to a map using the descriptor\n        Map<String, Object> resultMap = ProtoReader.read(byteBuffer, descriptor);\n\n        // Verify the result\n        assertNull(resultMap.get(\"int_field\"));\n        assertNull(resultMap.get(\"optional_field\"));\n        assertEquals(\"bar\", resultMap.get(\"required_field\"));\n        assertEquals(\"oneof string\", resultMap.get(\"str_field\"));\n        assertNull(resultMap.get(\"float_field\"));\n    }\n", "    public void testReadNestedMessage() throws Exception {\n        // Load the schema from the .proto schema string\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"NestedSchemaDynamic.proto\");\n\n        MessageDefinition nestedMsgDef = MessageDefinition.newBuilder(\"NestedMessage\")\n                .addField(\"required\", \"int32\", \"nested_int_field\", 1)\n                .addField(\"required\", \"string\", \"nested_str_field\", 2)\n                .build();\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"OuterMessage\")\n                .addField(\"required\", \"int32\", \"outer_int_field\", 1)\n                .addField(\"required\", \"NestedMessage\", \"nested_message\", 2)\n                .build();\n\n        schemaBuilder.addMessageDefinition(nestedMsgDef);\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema schema = schemaBuilder.build();\n\n        Descriptor nestedDescriptor = schema.getMessageDescriptor(\"NestedMessage\");\n        Descriptor outerDescriptor = schema.getMessageDescriptor(\"OuterMessage\");\n\n        // Create a nested message using the descriptor\n        DynamicMessage.Builder nestedMessageBuilder = DynamicMessage.newBuilder(nestedDescriptor);\n        nestedMessageBuilder.setField(nestedDescriptor.findFieldByName(\"nested_int_field\"), 42);\n        nestedMessageBuilder.setField(nestedDescriptor.findFieldByName(\"nested_str_field\"), \"nested string\");\n\n        // Create an outer message using the descriptor\n        DynamicMessage.Builder outerMessageBuilder = DynamicMessage.newBuilder(outerDescriptor);\n        outerMessageBuilder.setField(outerDescriptor.findFieldByName(\"outer_int_field\"), 100);\n        outerMessageBuilder.setField(outerDescriptor.findFieldByName(\"nested_message\"), nestedMessageBuilder.build());\n\n        // Serialize the outer DynamicMessage to a ByteBuffer\n        ByteBuffer byteBuffer = ByteBuffer.wrap(outerMessageBuilder.build().toByteArray());\n\n        // Convert the byte buffer to a map using the descriptor\n        Map<String, Object> resultMap = ProtoReader.read(byteBuffer, outerDescriptor);\n\n        // Verify the result\n        assertEquals(100, resultMap.get(\"outer_int_field\"));\n        Map<String, Object> nestedResultMap = (Map<String, Object>) resultMap.get(\"nested_message\");\n        assertNotNull(nestedResultMap);\n        assertEquals(42, nestedResultMap.get(\"nested_int_field\"));\n        assertEquals(\"nested string\", nestedResultMap.get(\"nested_str_field\"));\n    }\n", "    public void testPrimitiveTypes() throws Exception {\n        // Load the schema from the .proto schema string\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"PrimitiveSchemaDynamic.proto\");\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"PrimitiveMessage\")\n                .addField(\"optional\", \"int32\", \"int32_field\", 1)\n                .addField(\"optional\", \"int64\", \"int64_field\", 2)\n                .addField(\"optional\", \"uint32\", \"uint32_field\", 3)\n                .addField(\"optional\", \"uint64\", \"uint64_field\", 4)\n                .addField(\"optional\", \"sint32\", \"sint32_field\", 5)\n                .addField(\"optional\", \"sint64\", \"sint64_field\", 6)\n                .addField(\"optional\", \"bool\", \"bool_field\", 7)\n                .addField(\"optional\", \"fixed64\", \"fixed64_field\", 8)\n                .addField(\"optional\", \"sfixed64\", \"sfixed64_field\", 9)\n                .addField(\"optional\", \"double\", \"double_field\", 10)\n                .addField(\"optional\", \"fixed32\", \"fixed32_field\", 11)\n                .addField(\"optional\", \"sfixed32\", \"sfixed32_field\", 12)\n                .addField(\"optional\", \"float\", \"float_field\", 13)\n                .addField(\"optional\", \"bytes\", \"bytes_field\", 14)\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema schema = schemaBuilder.build();\n        Descriptor descriptor = schema.getMessageDescriptor(\"PrimitiveMessage\");\n\n        // Create a test message using the descriptor\n        DynamicMessage.Builder dynamicMessageBuilder = DynamicMessage.newBuilder(descriptor);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"int32_field\"), 123);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"int64_field\"), 1234567890123456789L);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"uint32_field\"), 456);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"uint64_field\"), Long.parseUnsignedLong(\"9876543210987654321\"));\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"sint32_field\"), -789);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"sint64_field\"), -1234567890987654321L);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"bool_field\"), true);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"fixed64_field\"), 1234567890L);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"sfixed64_field\"), -1234567890L);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"double_field\"), 1234.5678);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"fixed32_field\"), 12345678);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"sfixed32_field\"), -12345678);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"float_field\"), 12.34f);\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"bytes_field\"), new byte[]{1, 2, 3, 4, 5});\n\n        // Serialize the DynamicMessage to a ByteBuffer\n        ByteBuffer byteBuffer = ByteBuffer.wrap(dynamicMessageBuilder.build().toByteArray());\n\n        // Convert the byte buffer to a map using the descriptor\n        Map<String, Object> resultMap = ProtoReader.read(byteBuffer, descriptor);\n\n        // Verify the result\n        assertEquals(123, resultMap.get(\"int32_field\"));\n        assertEquals(1234567890123456789L, resultMap.get(\"int64_field\"));\n        assertEquals(456L, resultMap.get(\"uint32_field\"));\n        assertEquals(new BigInteger(\"9876543210987654321\"), resultMap.get(\"uint64_field\"));\n        assertEquals(-789, resultMap.get(\"sint32_field\"));\n        assertEquals(-1234567890987654321L, resultMap.get(\"sint64_field\"));\n        assertEquals(true, resultMap.get(\"bool_field\"));\n        assertEquals(new BigInteger(\"1234567890\"), resultMap.get(\"fixed64_field\"));\n        assertEquals(-1234567890L, resultMap.get(\"sfixed64_field\"));\n        assertEquals(1234.5678, resultMap.get(\"double_field\"));\n        assertEquals(12345678L, resultMap.get(\"fixed32_field\"));\n        assertEquals(-12345678, resultMap.get(\"sfixed32_field\"));\n        assertEquals(12.34f, resultMap.get(\"float_field\"));\n        assertEquals(ByteBuffer.wrap(new byte[]{1, 2, 3, 4, 5}), resultMap.get(\"bytes_field\"));\n    }\n", "    public void testEnumType() throws Exception {\n        // Define an enum type\n        EnumDefinition enumDefinition = EnumDefinition.newBuilder(\"TestEnum\")\n                .addValue(\"ENUM_VALUE_1\", 1)\n                .addValue(\"ENUM_VALUE_2\", 2)\n                .build();\n\n        // Load the schema from the .proto schema string\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"EnumSchemaDynamic.proto\");\n\n        schemaBuilder.addEnumDefinition(enumDefinition);\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"EnumMessage\")\n                .addField(\"optional\", \"TestEnum\", \"enum_field\", 1)\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema schema = schemaBuilder.build();\n\n        Descriptor descriptor = schema.getMessageDescriptor(\"EnumMessage\");\n        Descriptors.EnumDescriptor enumDescriptor = schema.getEnumDescriptor(\"TestEnum\");\n\n        // Create a test message using the descriptor\n        DynamicMessage.Builder dynamicMessageBuilder = DynamicMessage.newBuilder(descriptor);\n        Descriptors.EnumValueDescriptor enumValueDescriptor = enumDescriptor.findValueByName(\"ENUM_VALUE_2\");\n        dynamicMessageBuilder.setField(descriptor.findFieldByName(\"enum_field\"), enumValueDescriptor);\n\n        // Serialize the DynamicMessage to a ByteBuffer\n        ByteBuffer byteBuffer = ByteBuffer.wrap(dynamicMessageBuilder.build().toByteArray());\n\n        // Convert the byte buffer to a map using the descriptor\n        Map<String, Object> resultMap = ProtoReader.read(byteBuffer, descriptor);\n\n        // Verify the result\n        assertEquals(\"ENUM_VALUE_2\", resultMap.get(\"enum_field\"));\n    }\n}\n"]}
{"filename": "twister-proto/src/test/java/dev/twister/proto/ProtoWrapperTest.java", "chunked_list": ["package dev.twister.proto;\n\nimport com.github.os72.protobuf.dynamic.DynamicSchema;\nimport com.github.os72.protobuf.dynamic.EnumDefinition;\nimport com.github.os72.protobuf.dynamic.MessageDefinition;\nimport com.google.protobuf.ByteString;\nimport com.google.protobuf.Descriptors;\nimport com.google.protobuf.DynamicMessage;\nimport junit.framework.TestCase;\n", "import junit.framework.TestCase;\n\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.Arrays;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\n\npublic class ProtoWrapperTest extends TestCase {\n    private final ProtoWrapper wrapper = new ProtoWrapper();\n", "\npublic class ProtoWrapperTest extends TestCase {\n    private final ProtoWrapper wrapper = new ProtoWrapper();\n\n    public void testWrapPrimitives() throws Exception {\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"Test\")\n                .addField(\"optional\", \"int32\", \"testInt32\", 1)\n                .addField(\"optional\", \"sint32\", \"testSint32\", 2)\n                .addField(\"optional\", \"sfixed32\", \"testSfixed32\", 3)\n                .addField(\"optional\", \"int64\", \"testInt64\", 4)\n                .addField(\"optional\", \"sint64\", \"testSint64\", 5)\n                .addField(\"optional\", \"bool\", \"testBool\", 6)\n                .addField(\"optional\", \"string\", \"testString\", 7)\n                .addField(\"optional\", \"double\", \"testDouble\", 8)\n                .addField(\"optional\", \"float\", \"testFloat\", 9)\n                .addField(\"optional\", \"uint32\", \"testUint32\", 10)\n                .addField(\"optional\", \"fixed32\", \"testFixed32\", 11)\n                .addField(\"optional\", \"uint64\", \"testUint64\", 12)\n                .addField(\"optional\", \"fixed64\", \"testFixed64\", 13)\n                .addField(\"optional\", \"sfixed64\", \"testSfixed64\", 14)\n                .addField(\"optional\", \"bytes\", \"testBytes\", 15)\n                .build();\n\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .addMessageDefinition(msgDef)\n                .build();\n\n        Descriptors.Descriptor descriptor = schema.getMessageDescriptor(\"Test\");\n        DynamicMessage message = DynamicMessage.newBuilder(descriptor)\n                .setField(descriptor.findFieldByName(\"testInt32\"), 123)\n                .setField(descriptor.findFieldByName(\"testSint32\"), 123)\n                .setField(descriptor.findFieldByName(\"testSfixed32\"), 123)\n                .setField(descriptor.findFieldByName(\"testInt64\"), 123L)\n                .setField(descriptor.findFieldByName(\"testSint64\"), 123L)\n                .setField(descriptor.findFieldByName(\"testBool\"), true)\n                .setField(descriptor.findFieldByName(\"testString\"), \"string\")\n                .setField(descriptor.findFieldByName(\"testDouble\"), 123.45)\n                .setField(descriptor.findFieldByName(\"testFloat\"), 123.45f)\n                .setField(descriptor.findFieldByName(\"testUint32\"), Integer.parseUnsignedInt(\"4294967295\")) // Value larger than maximum int\n                .setField(descriptor.findFieldByName(\"testFixed32\"), Integer.parseUnsignedInt(\"4294967295\"))\n                .setField(descriptor.findFieldByName(\"testUint64\"), Long.parseUnsignedLong(\"18446744073709551615\")) // Maximum uint64 value\n                .setField(descriptor.findFieldByName(\"testFixed64\"), Long.parseUnsignedLong(\"18446744073709551615\"))\n                .setField(descriptor.findFieldByName(\"testSfixed64\"), 123L)\n                .setField(descriptor.findFieldByName(\"testBytes\"), ByteString.copyFrom(new byte[]{1, 2, 3}))\n                .build();\n\n        Map<String, Object> result = wrapper.wrap(message);\n\n        assertEquals(123, result.get(\"testInt32\"));\n        assertEquals(123, result.get(\"testSint32\"));\n        assertEquals(123, result.get(\"testSfixed32\"));\n        assertEquals(123L, result.get(\"testInt64\"));\n        assertEquals(123L, result.get(\"testSint64\"));\n        assertEquals(true, result.get(\"testBool\"));\n        assertEquals(\"string\", result.get(\"testString\"));\n        assertEquals(123.45, result.get(\"testDouble\"));\n        assertEquals(123.45f, result.get(\"testFloat\"));\n        assertEquals(4294967295L, result.get(\"testUint32\"));\n        assertEquals(4294967295L, result.get(\"testFixed32\"));\n        assertEquals(new BigInteger(\"18446744073709551615\"), result.get(\"testUint64\"));\n        assertEquals(new BigInteger(\"18446744073709551615\"), result.get(\"testFixed64\"));\n        assertEquals(123L, result.get(\"testSfixed64\"));\n        assertEquals(ByteBuffer.wrap(new byte[]{1, 2, 3}), result.get(\"testBytes\"));\n    }\n", "    public void testWrapNestedMessage() throws Exception {\n        MessageDefinition nestedMsgDef = MessageDefinition.newBuilder(\"Nested\")\n                .addField(\"optional\", \"int32\", \"testNestedInt\", 1)\n                .build();\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"Test\")\n                .addField(\"optional\", \"Nested\", \"testNested\", 1)\n                .build();\n\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .addMessageDefinition(nestedMsgDef)\n                .addMessageDefinition(msgDef)\n                .build();\n\n        Descriptors.Descriptor descriptor = schema.getMessageDescriptor(\"Test\");\n        Descriptors.Descriptor nestedDescriptor = schema.getMessageDescriptor(\"Nested\");\n\n        DynamicMessage nestedMessage = DynamicMessage.newBuilder(nestedDescriptor)\n                .setField(nestedDescriptor.findFieldByName(\"testNestedInt\"), 456)\n                .build();\n\n        DynamicMessage message = DynamicMessage.newBuilder(descriptor)\n                .setField(descriptor.findFieldByName(\"testNested\"), nestedMessage)\n                .build();\n\n        Map<String, Object> result = wrapper.wrap(message);\n        Map<String, Object> nestedResult = (Map<String, Object>) result.get(\"testNested\");\n\n        assertEquals(456, nestedResult.get(\"testNestedInt\"));\n    }\n", "    public void testWrapRepeated() throws Exception {\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"Test\")\n                .addField(\"repeated\", \"int32\", \"testRepeatedInt\", 1)\n                .build();\n\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .addMessageDefinition(msgDef)\n                .build();\n\n        Descriptors.Descriptor descriptor = schema.getMessageDescriptor(\"Test\");\n\n        DynamicMessage message = DynamicMessage.newBuilder(descriptor)\n                .addRepeatedField(descriptor.findFieldByName(\"testRepeatedInt\"), 123)\n                .addRepeatedField(descriptor.findFieldByName(\"testRepeatedInt\"), 456)\n                .addRepeatedField(descriptor.findFieldByName(\"testRepeatedInt\"), 789)\n                .build();\n\n        Map<String, Object> result = wrapper.wrap(message);\n        List<Integer> repeatedResult = (List<Integer>) result.get(\"testRepeatedInt\");\n\n        assertEquals(Arrays.asList(123, 456, 789), repeatedResult);\n    }\n", "    public void testWrapEnum() throws Exception {\n        EnumDefinition enumDef = EnumDefinition.newBuilder(\"TestEnum\")\n                .addValue(\"FIRST\", 1)\n                .addValue(\"SECOND\", 2)\n                .build();\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"Test\")\n                .addField(\"optional\", \"TestEnum\", \"testEnum\", 1)\n                .build();\n\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .addEnumDefinition(enumDef)\n                .addMessageDefinition(msgDef)\n                .build();\n\n        Descriptors.Descriptor descriptor = schema.getMessageDescriptor(\"Test\");\n        Descriptors.EnumDescriptor enumDescriptor = schema.getEnumDescriptor(\"TestEnum\");\n\n        DynamicMessage message = DynamicMessage.newBuilder(descriptor)\n                .setField(descriptor.findFieldByName(\"testEnum\"), enumDescriptor.getValues().get(1))\n                .build();\n\n        Map<String, Object> result = wrapper.wrap(message);\n\n        assertEquals(\"SECOND\", result.get(\"testEnum\"));\n    }\n", "    public void testWrapRepeatedMessages() throws Exception {\n        MessageDefinition repeatedMsgDef = MessageDefinition.newBuilder(\"Repeated\")\n                .addField(\"optional\", \"int32\", \"testRepeatedInt\", 1)\n                .build();\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"Test\")\n                .addField(\"repeated\", \"Repeated\", \"testRepeated\", 1)\n                .build();\n\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .addMessageDefinition(repeatedMsgDef)\n                .addMessageDefinition(msgDef)\n                .build();\n\n        Descriptors.Descriptor descriptor = schema.getMessageDescriptor(\"Test\");\n        Descriptors.Descriptor repeatedDescriptor = schema.getMessageDescriptor(\"Repeated\");\n\n        DynamicMessage repeatedMessage1 = DynamicMessage.newBuilder(repeatedDescriptor)\n                .setField(repeatedDescriptor.findFieldByName(\"testRepeatedInt\"), 123)\n                .build();\n\n        DynamicMessage repeatedMessage2 = DynamicMessage.newBuilder(repeatedDescriptor)\n                .setField(repeatedDescriptor.findFieldByName(\"testRepeatedInt\"), 456)\n                .build();\n\n        DynamicMessage message = DynamicMessage.newBuilder(descriptor)\n                .addRepeatedField(descriptor.findFieldByName(\"testRepeated\"), repeatedMessage1)\n                .addRepeatedField(descriptor.findFieldByName(\"testRepeated\"), repeatedMessage2)\n                .build();\n\n        Map<String, Object> result = wrapper.wrap(message);\n        List<Map<String, Object>> repeatedResult = (List<Map<String, Object>>) result.get(\"testRepeated\");\n\n        assertEquals(123, repeatedResult.get(0).get(\"testRepeatedInt\"));\n        assertEquals(456, repeatedResult.get(1).get(\"testRepeatedInt\"));\n    }\n", "    public void testOneOfFieldHandling() throws Exception {\n        // Define a protobuf message type with a 'oneof' field using the dynamic schema library.\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"MyMessage\")\n                .addField(\"optional\", \"string\", \"option_one\", 1)\n                .addOneof(\"my_oneof\")\n                .addField(\"string\", \"oneof_option_one\", 3)\n                .addField(\"string\", \"oneof_option_two\", 4)\n                .msgDefBuilder()\n                .build();\n\n        DynamicSchema schema = DynamicSchema.newBuilder()\n                .setName(\"MyMessage.proto\")\n                .addMessageDefinition(msgDef)\n                .build();\n\n        Descriptors.Descriptor descriptor = schema.getMessageDescriptor(\"MyMessage\");\n        // Build a dynamic message where 'oneof_option_two' is set.\n        DynamicMessage message = DynamicMessage.newBuilder(descriptor)\n                .setField(descriptor.findFieldByName(\"option_one\"), \"a string\")\n                .setField(descriptor.findFieldByName(\"oneof_option_two\"), \"some value\")\n                .build();\n\n        ProtoWrapper protoWrapper = new ProtoWrapper();\n        Map<String, Object> map = protoWrapper.wrap(message);\n\n        // Check basic map usage\n        assertEquals(\"a string\", map.get(\"option_one\"));\n        assertEquals(\"some value\", map.get(\"oneof_option_two\"));\n        assertNull(map.get(\"oneof_option_one\"));\n\n        // Check size()\n        assertEquals(2, map.size());\n\n        // Check that iteration works\n        Iterator<Map.Entry<String, Object>> entrySet = map.entrySet().iterator();\n        assertTrue(entrySet.hasNext());\n        Map.Entry<String, Object> entry = entrySet.next();\n        assertEquals(\"option_one\", entry.getKey());\n        assertEquals(\"a string\", entry.getValue());\n        assertTrue(entrySet.hasNext());\n        entry = entrySet.next();\n        assertEquals(\"oneof_option_two\", entry.getKey());\n        assertEquals(\"some value\", entry.getValue());\n        assertFalse(entrySet.hasNext());\n    }\n}\n"]}
{"filename": "twister-proto/src/test/java/dev/twister/proto/ProtoDescriptorInferrerTest.java", "chunked_list": ["package dev.twister.proto;\n\nimport com.github.os72.protobuf.dynamic.DynamicSchema;\nimport com.github.os72.protobuf.dynamic.MessageDefinition;\nimport com.google.protobuf.Descriptors;\nimport junit.framework.TestCase;\n\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.Arrays;", "import java.nio.ByteBuffer;\nimport java.util.Arrays;\nimport java.util.LinkedHashMap;\nimport java.util.List;\nimport java.util.Map;\n\npublic class ProtoDescriptorInferrerTest extends TestCase {\n\n    public void testPrimitives() throws Exception {\n        Map<String, Object> object = new LinkedHashMap<>();\n        object.put(\"fieldInt\", Integer.valueOf(32));\n        object.put(\"fieldLong\", Long.valueOf(64));\n        object.put(\"fieldBool\", Boolean.TRUE);\n        object.put(\"fieldStr\", \"string\");\n        object.put(\"fieldDouble\", Double.valueOf(64.0));\n        object.put(\"fieldBytes\", ByteBuffer.wrap(new byte[] {1, 2, 3}));\n        object.put(\"fieldFloat\", Float.valueOf(32.0f));\n        object.put(\"fieldBigInt\", BigInteger.valueOf(Long.MAX_VALUE));\n\n        Descriptors.Descriptor descriptor = new ProtoDescriptorInferrer().infer(object, \"TestMessage\");\n\n        // Create expected schema using DynamicSchema\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"TestMessage.proto\");\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"optional\", \"int32\", \"fieldInt\", 1)\n                .addField(\"optional\", \"int64\", \"fieldLong\", 2)\n                .addField(\"optional\", \"bool\", \"fieldBool\", 3)\n                .addField(\"optional\", \"string\", \"fieldStr\", 4)\n                .addField(\"optional\", \"double\", \"fieldDouble\", 5)\n                .addField(\"optional\", \"bytes\", \"fieldBytes\", 6)\n                .addField(\"optional\", \"float\", \"fieldFloat\", 7)\n                .addField(\"optional\", \"uint64\", \"fieldBigInt\", 8)\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema expectedSchema = schemaBuilder.build();\n        Descriptors.Descriptor expectedDescriptor = expectedSchema.getMessageDescriptor(\"TestMessage\");\n\n        // Compare the descriptors\n        assertEquals(expectedDescriptor.toProto(), descriptor.toProto());\n    }\n", "    public void testPrimitives() throws Exception {\n        Map<String, Object> object = new LinkedHashMap<>();\n        object.put(\"fieldInt\", Integer.valueOf(32));\n        object.put(\"fieldLong\", Long.valueOf(64));\n        object.put(\"fieldBool\", Boolean.TRUE);\n        object.put(\"fieldStr\", \"string\");\n        object.put(\"fieldDouble\", Double.valueOf(64.0));\n        object.put(\"fieldBytes\", ByteBuffer.wrap(new byte[] {1, 2, 3}));\n        object.put(\"fieldFloat\", Float.valueOf(32.0f));\n        object.put(\"fieldBigInt\", BigInteger.valueOf(Long.MAX_VALUE));\n\n        Descriptors.Descriptor descriptor = new ProtoDescriptorInferrer().infer(object, \"TestMessage\");\n\n        // Create expected schema using DynamicSchema\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"TestMessage.proto\");\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"optional\", \"int32\", \"fieldInt\", 1)\n                .addField(\"optional\", \"int64\", \"fieldLong\", 2)\n                .addField(\"optional\", \"bool\", \"fieldBool\", 3)\n                .addField(\"optional\", \"string\", \"fieldStr\", 4)\n                .addField(\"optional\", \"double\", \"fieldDouble\", 5)\n                .addField(\"optional\", \"bytes\", \"fieldBytes\", 6)\n                .addField(\"optional\", \"float\", \"fieldFloat\", 7)\n                .addField(\"optional\", \"uint64\", \"fieldBigInt\", 8)\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema expectedSchema = schemaBuilder.build();\n        Descriptors.Descriptor expectedDescriptor = expectedSchema.getMessageDescriptor(\"TestMessage\");\n\n        // Compare the descriptors\n        assertEquals(expectedDescriptor.toProto(), descriptor.toProto());\n    }\n", "    public void testRepeatedFields() throws Exception {\n        Map<String, Object> object = new LinkedHashMap<>();\n        List<Integer> intList = Arrays.asList(32, 33, 34);\n        object.put(\"fieldRepeated\", intList);\n\n        Descriptors.Descriptor descriptor = new ProtoDescriptorInferrer().infer(object, \"TestMessage\");\n\n        // Create expected schema using DynamicSchema\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"TestMessage.proto\");\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"repeated\", \"int32\", \"fieldRepeated\", 1)\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema expectedSchema = schemaBuilder.build();\n        Descriptors.Descriptor expectedDescriptor = expectedSchema.getMessageDescriptor(\"TestMessage\");\n\n        // Compare the descriptors\n        assertEquals(expectedDescriptor.toProto(), descriptor.toProto());\n    }\n", "    public void testNestedMessages() throws Exception {\n        ProtoDescriptorInferrer inferrer = new ProtoDescriptorInferrer();\n\n        Map<String, Object> nestedObject = new LinkedHashMap<>();\n        nestedObject.put(\"nestedFieldInt\", Integer.valueOf(32));\n\n        Map<String, Object> nestedNestedObject = new LinkedHashMap<>();\n        nestedNestedObject.put(\"nestedNestedFieldStr\", \"nested string\");\n        nestedObject.put(\"nestedNestedMessage\", nestedNestedObject);\n\n        Map<String, Object> object = new LinkedHashMap<>();\n        object.put(\"fieldStr\", \"string\");\n        object.put(\"nestedMessage\", nestedObject);\n\n        Descriptors.Descriptor descriptor = inferrer.infer(object, \"TestMessage\");\n\n        // Create expected schema using DynamicSchema\n        DynamicSchema.Builder schemaBuilder = DynamicSchema.newBuilder();\n        schemaBuilder.setName(\"TestMessage.proto\");\n\n        MessageDefinition nestedNestedMsgDef = MessageDefinition.newBuilder(\"TestMessage_nestedMessage_nestedNestedMessage\")\n                .addField(\"optional\", \"string\", \"nestedNestedFieldStr\", 1)\n                .build();\n\n        MessageDefinition nestedMsgDef = MessageDefinition.newBuilder(\"TestMessage_nestedMessage\")\n                .addField(\"optional\", \"int32\", \"nestedFieldInt\", 1)\n                .addMessageDefinition(nestedNestedMsgDef)\n                .addField(\"optional\", \"TestMessage_nestedMessage_nestedNestedMessage\", \"nestedNestedMessage\", 2)\n                .build();\n\n        MessageDefinition msgDef = MessageDefinition.newBuilder(\"TestMessage\")\n                .addField(\"optional\", \"string\", \"fieldStr\", 1)\n                .addMessageDefinition(nestedMsgDef)\n                .addField(\"optional\", \"TestMessage_nestedMessage\", \"nestedMessage\", 2)\n                .build();\n\n        schemaBuilder.addMessageDefinition(msgDef);\n        DynamicSchema expectedSchema = schemaBuilder.build();\n\n        Descriptors.Descriptor expectedDescriptor = expectedSchema.getMessageDescriptor(\"TestMessage\");\n\n        // Compare the descriptors\n        assertEquals(expectedDescriptor.toProto(), descriptor.toProto());\n    }\n}\n"]}
{"filename": "twister-proto/src/main/java/dev/twister/proto/ProtoWriter.java", "chunked_list": ["package dev.twister.proto;\n\nimport com.google.protobuf.ByteString;\nimport com.google.protobuf.Descriptors.Descriptor;\nimport com.google.protobuf.Descriptors.EnumDescriptor;\nimport com.google.protobuf.Descriptors.FieldDescriptor;\nimport com.google.protobuf.DynamicMessage;\n\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;", "import java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.Map;\n\n/**\n * A utility class for converting a Map into a Protocol Buffers message and writing it to a ByteBuffer.\n */\npublic class ProtoWriter {\n\n    /**\n     * Writes a given object map into a ByteBuffer using the specified message name.\n     * It uses a new instance of ProtoDescriptorInferrer to generate the descriptor.\n     *\n     * @param object The Map representing the Protocol Buffers message.\n     * @param messageName The name of the Protocol Buffers message.\n     * @return A ByteBuffer containing the Protocol Buffers message.\n     */", "    public ByteBuffer write(Map<String, Object> object, String messageName) {\n        return write(object, new ProtoDescriptorInferrer().infer(object, messageName));\n    }\n\n    /**\n     * Converts a Map into a Protocol Buffers message and writes it to a ByteBuffer.\n     *\n     * @param object The Map representing the Protocol Buffers message.\n     * @param descriptor The Descriptor of the Protocol Buffers message.\n     * @return A ByteBuffer containing the Protocol Buffers message.\n     * @throws RuntimeException If an unsupported field type is encountered.\n     */", "    public ByteBuffer write(Map<String, Object> object, Descriptor descriptor) {\n        DynamicMessage message = toMessage(object, descriptor);\n        return ByteBuffer.wrap(message.toByteArray());\n    }\n\n    /**\n     * Converts a Map into a DynamicMessage representing a Protocol Buffers message.\n     *\n     * @param object The Map representing the Protocol Buffers message.\n     * @param descriptor The Descriptor of the Protocol Buffers message.\n     * @return A DynamicMessage representing the Protocol Buffers message.\n     * @throws RuntimeException If an unsupported field type is encountered.\n     */", "    public DynamicMessage toMessage(Map<String, Object> object, Descriptor descriptor) {\n        DynamicMessage.Builder messageBuilder = DynamicMessage.newBuilder(descriptor);\n\n        for (FieldDescriptor fieldDescriptor : descriptor.getFields()) {\n            String fieldName = fieldDescriptor.getName();\n            Object value = object.get(fieldName);\n\n            if (value != null) {\n                if (fieldDescriptor.isRepeated()) {\n                    for (Object element : (Iterable<?>) value) {\n                        messageBuilder.addRepeatedField(fieldDescriptor, toProtobufValue(fieldDescriptor, element));\n                    }\n                } else {\n                    messageBuilder.setField(fieldDescriptor, toProtobufValue(fieldDescriptor, value));\n                }\n            }\n        }\n\n        return messageBuilder.build();\n    }\n\n    /**\n     * Converts a Java object into a Protocol Buffers value according to the provided field descriptor.\n     *\n     * @param fieldDescriptor The descriptor of the field.\n     * @param value The Java object to convert.\n     * @return The converted Protocol Buffers value.\n     * @throws RuntimeException If an unsupported field type is encountered.\n     */\n    private Object toProtobufValue(FieldDescriptor fieldDescriptor, Object value) {\n        switch (fieldDescriptor.getType()) {\n            case INT32:\n            case SINT32:\n            case SFIXED32:\n            case INT64:\n            case SINT64:\n            case SFIXED64:\n            case BOOL:\n            case FLOAT:\n            case STRING:\n            case DOUBLE:\n                return value;\n            case ENUM:\n                EnumDescriptor enumDescriptor = fieldDescriptor.getEnumType();\n                return enumDescriptor.findValueByName((String) value);\n            case FIXED64:\n            case UINT64:\n                BigInteger bigInt = (BigInteger) value;\n                return bigInt.longValue();\n            case BYTES:\n                ByteBuffer byteBuffer = (ByteBuffer) value;\n                return ByteString.copyFrom(byteBuffer);\n            case FIXED32:\n            case UINT32:\n                return ((Long) value).intValue();\n            case MESSAGE:\n                Descriptor messageDescriptor = fieldDescriptor.getMessageType();\n                return toMessage((Map<String, Object>) value, messageDescriptor);\n            default:\n                throw new RuntimeException(\"Unsupported field type: \" + fieldDescriptor.getType());\n        }\n    }\n}\n", "                if (fieldDescriptor.isRepeated()) {\n                    for (Object element : (Iterable<?>) value) {\n                        messageBuilder.addRepeatedField(fieldDescriptor, toProtobufValue(fieldDescriptor, element));\n                    }\n                } else {\n                    messageBuilder.setField(fieldDescriptor, toProtobufValue(fieldDescriptor, value));\n                }\n            }\n        }\n\n        return messageBuilder.build();\n    }\n\n    /**\n     * Converts a Java object into a Protocol Buffers value according to the provided field descriptor.\n     *\n     * @param fieldDescriptor The descriptor of the field.\n     * @param value The Java object to convert.\n     * @return The converted Protocol Buffers value.\n     * @throws RuntimeException If an unsupported field type is encountered.\n     */\n    private Object toProtobufValue(FieldDescriptor fieldDescriptor, Object value) {\n        switch (fieldDescriptor.getType()) {\n            case INT32:\n            case SINT32:\n            case SFIXED32:\n            case INT64:\n            case SINT64:\n            case SFIXED64:\n            case BOOL:\n            case FLOAT:\n            case STRING:\n            case DOUBLE:\n                return value;\n            case ENUM:\n                EnumDescriptor enumDescriptor = fieldDescriptor.getEnumType();\n                return enumDescriptor.findValueByName((String) value);\n            case FIXED64:\n            case UINT64:\n                BigInteger bigInt = (BigInteger) value;\n                return bigInt.longValue();\n            case BYTES:\n                ByteBuffer byteBuffer = (ByteBuffer) value;\n                return ByteString.copyFrom(byteBuffer);\n            case FIXED32:\n            case UINT32:\n                return ((Long) value).intValue();\n            case MESSAGE:\n                Descriptor messageDescriptor = fieldDescriptor.getMessageType();\n                return toMessage((Map<String, Object>) value, messageDescriptor);\n            default:\n                throw new RuntimeException(\"Unsupported field type: \" + fieldDescriptor.getType());\n        }\n    }\n}\n"]}
{"filename": "twister-proto/src/main/java/dev/twister/proto/ProtoWrapper.java", "chunked_list": ["package dev.twister.proto;\n\nimport com.google.protobuf.ByteString;\nimport com.google.protobuf.Descriptors;\nimport com.google.protobuf.Message;\n\nimport java.math.BigInteger;\nimport java.util.AbstractList;\nimport java.util.AbstractMap;\nimport java.util.AbstractSet;", "import java.util.AbstractMap;\nimport java.util.AbstractSet;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.NoSuchElementException;\nimport java.util.Set;\n\n/**\n * Wraps a Protobuf message into a Java map, providing a convenient way to access the fields of", "/**\n * Wraps a Protobuf message into a Java map, providing a convenient way to access the fields of\n * the message using standard Java methods. This can be useful when you need to work with Protobuf\n * messages but don't have access to the generated Java classes for them.\n * <p>\n * The keys of the map are the names of the Protobuf fields. The values are the field values,\n * converted to more Java-friendly types when necessary (for example, byte fields are converted to\n * ByteBuffer instances, and enum fields are converted to the names of the enum values).\n * <p>\n * Nested messages and repeated fields are also supported. Nested messages are themselves wrapped", " * <p>\n * Nested messages and repeated fields are also supported. Nested messages are themselves wrapped\n * into Facade instances, and repeated fields are wrapped into FacadeList instances. This means that\n * you can navigate the entire structure of a Protobuf message using just the standard Map and List\n * interfaces.\n */\npublic class ProtoWrapper {\n    public Map<String, Object> wrap(Message message) {\n        return new Facade(message);\n    }\n\n    /**\n     * Converts a Protobuf field value to a more Java-friendly form.\n     *\n     * <p>The method supports various types of fields, including repeated fields and nested messages.\n     * Scalar types (like integers, strings, booleans, etc.) are converted as-is. Some other types\n     * (like enum values or bytes) are converted to more convenient or idiomatic Java types. Repeated\n     * fields are wrapped into a {@link FacadeList} instance, and nested messages are wrapped into a\n     * {@link Facade} instance.\n     *\n     * <p>The treatment of repeated fields is special. When a repeated field is first encountered,\n     * it's wrapped into a {@link FacadeList}. The {@code isRepeated} argument should be true in this\n     * case. The {@link FacadeList} will later call this method for individual elements of the list,\n     * and in this case {@code isRepeated} should be false, because those individual elements are not\n     * repeated fields themselves.\n     *\n     * @param field the field descriptor\n     * @param value the field value\n     * @param isRepeated whether the field is a repeated field\n     * @return the converted value\n     * @throws IllegalArgumentException if the field type is unsupported\n     */\n    private Object convertValue(Descriptors.FieldDescriptor field, Object value, boolean isRepeated) {", "        if (isRepeated) {\n            return new FacadeList(field, (List<?>) value);\n        } else if (field.getType() == Descriptors.FieldDescriptor.Type.MESSAGE) {\n            return new Facade((Message) value);\n        } else {\n            switch (field.getType()) {\n                case INT32:\n                case SINT32:\n                case SFIXED32:\n                case INT64:\n                case SINT64:\n                case SFIXED64:\n                case BOOL:\n                case STRING:\n                case DOUBLE:\n                case FLOAT:\n                    return value;\n                case UINT32:\n                case FIXED32:\n                    return ((Integer) value).longValue() & 0xFFFFFFFFL;\n                case UINT64:\n                case FIXED64:\n                    return BigInteger.valueOf((Long) value).and(BigInteger.valueOf(Long.MAX_VALUE)).setBit(63);\n                case ENUM:\n                    return ((Descriptors.EnumValueDescriptor) value).getName();\n                case BYTES:\n                    return ((ByteString) value).asReadOnlyByteBuffer();\n                default:\n                    throw new IllegalArgumentException(\"Unsupported type: \" + field.getType());\n            }\n        }\n    }\n\n    /**\n     * Provides a view of a Protobuf message as a Java Map. The map keys are the names of the fields\n     * in the Protobuf message, and the map values are the corresponding field values, converted to\n     * Java-friendly types where necessary.\n     * <p>\n     * This class supports all Protobuf field types, including nested messages and repeated fields.\n     * Nested messages are wrapped into Facade instances, and repeated fields are wrapped into\n     * FacadeList instances. This means that you can navigate the entire structure of a Protobuf\n     * message using just the standard Map and List interfaces.\n     * <p>\n     * This class also takes into account 'oneof' fields. Only the field that is currently set in\n     * the 'oneof' is included in the map.\n     */\n    private class Facade extends AbstractMap<String, Object> {\n\n        private final Message message;\n        private final List<Descriptors.FieldDescriptor> allFields;\n        private int size;\n\n        /**\n         * Constructor to create Facade wrapping the protobuf message.\n         *\n         * @param message the protobuf message\n         */\n        Facade(Message message) {\n            this.message = message;\n            this.allFields = message.getDescriptorForType().getFields();\n            this.size = calculateSize();\n        }\n\n        /**\n         * Calculates the size (the number of set fields), taking 'oneof' fields into account.\n         *\n         * @return the size\n         */\n        private int calculateSize() {\n            int size = 0;", "            for (Descriptors.FieldDescriptor field : allFields) {\n                if (field.getContainingOneof() != null) {\n                    if (message.getOneofFieldDescriptor(field.getContainingOneof()) == field) {\n                        size++;  // Count the field if it's the one currently set in the 'oneof'.\n                    }\n                } else {\n                    size++;  // Regular field, always count it.\n                }\n            }\n            return size;\n        }\n\n        @Override\n        public Set<Entry<String, Object>> entrySet() {\n            return new AbstractSet<>() {\n                /**\n                 * This iterator iterates over both regular and 'oneof' fields of the Protobuf message, maintaining the\n                 * order of fields as they are defined in the proto file. If a 'oneof' field is currently set, it is\n                 * returned when its turn comes according to its order in the proto file.\n                 */\n                @Override\n                public Iterator<Entry<String, Object>> iterator() {\n                    return new Iterator<>() {\n                        private int index = 0;  // Current field index.\n\n                        /**\n                         * Checks if there is a next field. This method also prepares the next field to be returned,\n                         * taking 'oneof' fields into account.\n                         */\n                        @Override", "                        public boolean hasNext() {\n                            return index < allFields.size();\n                        }\n\n                        /**\n                         * Returns the next field. If a 'oneof' field is set and its turn comes, it is returned.\n                         */\n                        @Override\n                        public Entry<String, Object> next() {\n                            if (!hasNext()) {\n                                throw new NoSuchElementException();\n                            }\n\n                            Descriptors.FieldDescriptor field = allFields.get(index);\n\n                            // If the field is part of a `oneof`, and it is not the one currently set in the `oneof`,\n                            // continue to the next field.", "                            if (!hasNext()) {\n                                throw new NoSuchElementException();\n                            }\n\n                            Descriptors.FieldDescriptor field = allFields.get(index);\n\n                            // If the field is part of a `oneof`, and it is not the one currently set in the `oneof`,\n                            // continue to the next field.\n                            while (field.getContainingOneof() != null\n                                    && field != message.getOneofFieldDescriptor(field.getContainingOneof())) {\n                                if (++index >= allFields.size()) {\n                                    throw new NoSuchElementException();\n                                }\n                                field = allFields.get(index);\n                            }\n\n                            Object value = message.getField(field);\n                            index++;\n                            return new SimpleImmutableEntry<>(field.getName(),\n                                    convertValue(field, value, field.isRepeated()));\n                        }\n                    };\n                }\n\n                /**\n                 * Returns the number of set fields in the Protobuf message. This includes the set field of any 'oneof'\n                 * field group, if any.\n                 */\n                @Override", "                            while (field.getContainingOneof() != null\n                                    && field != message.getOneofFieldDescriptor(field.getContainingOneof())) {\n                                if (++index >= allFields.size()) {\n                                    throw new NoSuchElementException();\n                                }\n                                field = allFields.get(index);\n                            }\n\n                            Object value = message.getField(field);\n                            index++;\n                            return new SimpleImmutableEntry<>(field.getName(),\n                                    convertValue(field, value, field.isRepeated()));\n                        }\n                    };\n                }\n\n                /**\n                 * Returns the number of set fields in the Protobuf message. This includes the set field of any 'oneof'\n                 * field group, if any.\n                 */\n                @Override", "                public int size() {\n                    return size;\n                }\n            };\n        }\n    }\n\n    /**\n     * Provides a view of a Protobuf repeated field as a Java List. The list elements are the\n     * values of the repeated field, converted to Java-friendly types where necessary.\n     * <p>\n     * This class supports all Protobuf field types, including nested messages. Nested messages are\n     * wrapped into Facade instances. This means that you can navigate the entire structure of a\n     * Protobuf message using just the standard Map and List interfaces.\n     */\n    private class FacadeList extends AbstractList<Object> {\n\n        private final Descriptors.FieldDescriptor field;\n        private final List<?> list;\n\n        FacadeList(Descriptors.FieldDescriptor field, List<?> list) {\n            this.field = field;\n            this.list = list;\n        }\n\n        @Override", "        public Object get(int index) {\n            // Pass `false` for the `isRepeated` parameter to handle individual elements correctly\n            return convertValue(field, list.get(index), false);\n        }\n\n        @Override\n        public int size() {\n            return list.size();\n        }\n    }\n}\n"]}
{"filename": "twister-proto/src/main/java/dev/twister/proto/ProtoDescriptorInferrer.java", "chunked_list": ["package dev.twister.proto;\n\nimport com.google.protobuf.DescriptorProtos;\nimport com.google.protobuf.Descriptors;\n\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.List;\nimport java.util.Map;\n", "import java.util.Map;\n\n/**\n * A utility class to infer a Protocol Buffers message descriptor from a Map of objects.\n */\npublic class ProtoDescriptorInferrer {\n\n    /**\n     * Infers a Protocol Buffers message descriptor from a Map of objects and assigns it a message name.\n     *\n     * @param object The Map of objects to infer the descriptor from.\n     * @param messageName The name to assign to the message in the descriptor.\n     * @return The inferred Protocol Buffers message descriptor.\n     * @throws RuntimeException If there is an error validating the inferred descriptor.\n     */\n    public Descriptors.Descriptor infer(Map<String, Object> object, String messageName) {\n        DescriptorProtos.FileDescriptorProto.Builder fileDescriptorBuilder =\n                DescriptorProtos.FileDescriptorProto.newBuilder();\n        DescriptorProtos.DescriptorProto.Builder messageBuilder = DescriptorProtos.DescriptorProto.newBuilder();\n        int fieldNumber = 1;\n\n        // Set message name\n        messageBuilder.setName(messageName);\n", "        for (Map.Entry<String, Object> entry : object.entrySet()) {\n            String fieldName = entry.getKey();\n            Object fieldValue = entry.getValue();\n            DescriptorProtos.FieldDescriptorProto.Builder fieldBuilder =\n                    DescriptorProtos.FieldDescriptorProto.newBuilder();\n\n            // Set field name and number\n            fieldBuilder.setName(fieldName);\n            fieldBuilder.setNumber(fieldNumber++);\n\n            if (fieldValue instanceof List) {\n                fieldBuilder.setLabel(DescriptorProtos.FieldDescriptorProto.Label.LABEL_REPEATED);\n                // assuming all elements in the list are of the same type\n                Descriptors.FieldDescriptor.Type fieldType = inferFieldType(((List<?>) fieldValue).get(0));\n                fieldBuilder.setType(fieldType.toProto());", "            if (fieldValue instanceof List) {\n                fieldBuilder.setLabel(DescriptorProtos.FieldDescriptorProto.Label.LABEL_REPEATED);\n                // assuming all elements in the list are of the same type\n                Descriptors.FieldDescriptor.Type fieldType = inferFieldType(((List<?>) fieldValue).get(0));\n                fieldBuilder.setType(fieldType.toProto());\n            } else if (fieldValue instanceof Map) {\n                DescriptorProtos.DescriptorProto nestedMessage = infer(\n                        (Map<String, Object>) fieldValue,\n                        messageName + \"_\" + fieldName).toProto();\n                messageBuilder.addNestedType(nestedMessage);\n                fieldBuilder.setTypeName(nestedMessage.getName());\n                fieldBuilder.setLabel(DescriptorProtos.FieldDescriptorProto.Label.LABEL_OPTIONAL);\n            } else {\n                fieldBuilder.setLabel(DescriptorProtos.FieldDescriptorProto.Label.LABEL_OPTIONAL);\n                Descriptors.FieldDescriptor.Type fieldType = inferFieldType(fieldValue);\n                fieldBuilder.setType(fieldType.toProto());\n            }\n\n            // Add field to the message\n            messageBuilder.addField(fieldBuilder.build());\n        }\n\n        // Add message to the file descriptor\n        fileDescriptorBuilder.addMessageType(messageBuilder.build());\n", "        try {\n            Descriptors.FileDescriptor fileDescriptor = Descriptors.FileDescriptor.buildFrom(\n                    fileDescriptorBuilder.build(),\n                    new Descriptors.FileDescriptor[0]);\n            return fileDescriptor.findMessageTypeByName(messageName);\n        } catch (Descriptors.DescriptorValidationException e) {\n            throw new RuntimeException(\"Error inferring descriptor: \" + e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Infers the Protocol Buffers field type from an Object.\n     *\n     * @param value The object to infer the field type from.\n     * @return The inferred Protocol Buffers field type.\n     * @throws IllegalArgumentException If the object type is unsupported.\n     */\n    private Descriptors.FieldDescriptor.Type inferFieldType(Object value) {", "        if (value instanceof Integer) {\n            return Descriptors.FieldDescriptor.Type.INT32;\n        } else if (value instanceof Long) {\n            return Descriptors.FieldDescriptor.Type.INT64;\n        } else if (value instanceof BigInteger) {\n            BigInteger bigInt = (BigInteger) value;\n            if (bigInt.compareTo(BigInteger.ZERO) < 0 || bigInt.compareTo(BigInteger.valueOf(Long.MAX_VALUE)) > 0) {\n                throw new IllegalArgumentException(\"BigInteger value does not fit in uint64\");\n            }\n            return Descriptors.FieldDescriptor.Type.UINT64;\n        } else if (value instanceof Boolean) {\n            return Descriptors.FieldDescriptor.Type.BOOL;", "        } else if (value instanceof Boolean) {\n            return Descriptors.FieldDescriptor.Type.BOOL;\n        } else if (value instanceof String) {\n            return Descriptors.FieldDescriptor.Type.STRING;\n        } else if (value instanceof Double) {\n            return Descriptors.FieldDescriptor.Type.DOUBLE;\n        } else if (value instanceof ByteBuffer) {\n            return Descriptors.FieldDescriptor.Type.BYTES;\n        } else if (value instanceof Float) {\n            return Descriptors.FieldDescriptor.Type.FLOAT;\n        } else if (value instanceof Map) {\n            return Descriptors.FieldDescriptor.Type.MESSAGE;\n        } else {\n            throw new IllegalArgumentException(\"Unsupported field value type: \" + value.getClass().getName());\n        }\n    }\n}\n", "        } else if (value instanceof Float) {\n            return Descriptors.FieldDescriptor.Type.FLOAT;\n        } else if (value instanceof Map) {\n            return Descriptors.FieldDescriptor.Type.MESSAGE;\n        } else {\n            throw new IllegalArgumentException(\"Unsupported field value type: \" + value.getClass().getName());\n        }\n    }\n}\n"]}
{"filename": "twister-proto/src/main/java/dev/twister/proto/ProtoReader.java", "chunked_list": ["package dev.twister.proto;\n\nimport com.google.protobuf.Descriptors;\nimport com.google.protobuf.Descriptors.Descriptor;\nimport com.google.protobuf.Descriptors.FieldDescriptor;\nimport com.google.protobuf.Descriptors.OneofDescriptor;\n\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.nio.ByteOrder;", "import java.nio.ByteBuffer;\nimport java.nio.ByteOrder;\nimport java.nio.charset.StandardCharsets;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\n/**\n * A utility class for reading a Protocol Buffers message from a ByteBuffer and converting it into a Map.", "/**\n * A utility class for reading a Protocol Buffers message from a ByteBuffer and converting it into a Map.\n */\npublic class ProtoReader {\n\n    /**\n     * Reads a Protocol Buffers message from a ByteBuffer and converts it into a Map.\n     *\n     * @param inputBuffer The ByteBuffer containing the Protocol Buffers message.\n     * @param descriptor The Descriptor of the Protocol Buffers message.\n     * @return A Map representing the Protocol Buffers message.\n     * @throws IllegalArgumentException If an unknown field number or enum value is encountered.\n     * @throws UnsupportedOperationException If an unsupported wire type or field type is encountered.\n     */", "    public static Map<String, Object> read(ByteBuffer inputBuffer, Descriptor descriptor) {\n        Map<String, Object> resultMap = new HashMap<>();\n\n        // Initialize resultMap with default values\n        for (FieldDescriptor fieldDescriptor : descriptor.getFields()) {\n            if (fieldDescriptor.hasDefaultValue()) {\n                String fieldName = fieldDescriptor.getName();\n                Object defaultValue = fieldDescriptor.getDefaultValue();\n                resultMap.put(fieldName, defaultValue);\n            }\n        }\n", "        while (inputBuffer.hasRemaining()) {\n            int key = (int) readVarint(inputBuffer);\n            int wireType = key & 0x07;\n            int fieldNumber = key >>> 3;\n\n            FieldDescriptor fieldDescriptor = descriptor.findFieldByNumber(fieldNumber);\n\n            if (fieldDescriptor == null) {\n                throw new IllegalArgumentException(\"Unknown field number: \" + fieldNumber);\n            }\n\n            OneofDescriptor oneofDescriptor = fieldDescriptor.getContainingOneof();\n            boolean isOneof = oneofDescriptor != null;\n\n            String fieldName = fieldDescriptor.getName();\n\n            switch (wireType) {\n                case 0: // Varint, SignedVarint, Bool, Enum\n                    long rawValue = readVarint(inputBuffer);\n                    Object value;\n\n                    switch (fieldDescriptor.getType()) {\n                        case BOOL:\n                            value = rawValue != 0;\n                            break;\n                        case INT32:\n                            value = (int) rawValue;\n                            break;\n                        case SINT32:\n                            value = decodeZigZag32((int) rawValue);\n                            break;\n                        case SINT64:\n                            value = decodeZigZag64(rawValue);\n                            break;\n                        case ENUM:\n                            Descriptors.EnumValueDescriptor enumValueDescriptor =\n                                    fieldDescriptor.getEnumType().findValueByNumber((int) rawValue);", "                            if (enumValueDescriptor == null) {\n                                throw new IllegalArgumentException(\"Unknown enum value: \" + rawValue\n                                        + \" for field number: \" + fieldNumber);\n                            }\n                            value = enumValueDescriptor.getName();\n                            break;\n                        case UINT32:\n                        case FIXED32:\n                            value = rawValue & 0xFFFFFFFFL; // convert to long treating as unsigned\n                            break;\n                        case UINT64:\n                        case FIXED64:\n                            // convert to BigInteger treating as unsigned\n                            value = new BigInteger(Long.toUnsignedString(rawValue));\n                            break;\n                        default:\n                            value = rawValue;\n                            break;\n                    }\n\n                    addToResultMap(resultMap, fieldName, value, fieldDescriptor.isRepeated(), isOneof);\n                    break;\n                case 1: // Fixed64, SFixed64, Double\n                    long rawFixed64Value = inputBuffer.order(ByteOrder.LITTLE_ENDIAN).getLong();\n                    switch (fieldDescriptor.getType()) {\n                        case DOUBLE:\n                            value = Double.longBitsToDouble(rawFixed64Value);\n                            break;\n                        case FIXED64:\n                            value = BigInteger.valueOf(rawFixed64Value);\n                            break;\n                        case SFIXED64:\n                            value = rawFixed64Value;\n                            break;\n                        default:\n                            throw new UnsupportedOperationException(\"Unsupported type: \" + fieldDescriptor.getType());\n                    }\n                    addToResultMap(resultMap, fieldName, value, fieldDescriptor.isRepeated(), isOneof);\n                    break;\n                case 2: // Length-Delimited\n                    // Check if the field is a map field", "                    if (fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE\n                            && fieldDescriptor.getMessageType().getOptions().getMapEntry()) {\n                        Descriptor mapEntryDescriptor = fieldDescriptor.getMessageType();\n                        FieldDescriptor keyField = mapEntryDescriptor.findFieldByNumber(1);\n                        FieldDescriptor valueField = mapEntryDescriptor.findFieldByNumber(2);\n\n                        int length = (int) readVarint(inputBuffer);\n                        byte[] bytes = new byte[length];\n                        inputBuffer.get(bytes);\n                        ByteBuffer nestedByteBuffer = ByteBuffer.wrap(bytes);\n                        Map<String, Object> mapEntry = read(nestedByteBuffer, mapEntryDescriptor);\n\n                        Object mapKey = mapEntry.get(keyField.getName());\n                        Object mapValue = mapEntry.get(valueField.getName());\n\n                        Map<Object, Object> map = (Map<Object, Object>) resultMap.computeIfAbsent(\n                                fieldName,\n                                k -> new HashMap<>());\n                        map.put(mapKey, mapValue);\n                    } else {\n                        int length = (int) readVarint(inputBuffer);\n                        byte[] bytes = new byte[length];\n                        inputBuffer.get(bytes);", "                        if (fieldDescriptor.getType() == FieldDescriptor.Type.STRING) {\n                            String string = new String(bytes, StandardCharsets.UTF_8);\n                            addToResultMap(resultMap, fieldName, string, fieldDescriptor.isRepeated(), isOneof);\n                        } else if (fieldDescriptor.getType() == FieldDescriptor.Type.BYTES) {\n                            ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);\n                            addToResultMap(resultMap, fieldName, byteBuffer, fieldDescriptor.isRepeated(), isOneof);\n                        } else if (!isOneof && fieldDescriptor.getType() == FieldDescriptor.Type.MESSAGE) {\n                            ByteBuffer nestedByteBuffer = ByteBuffer.wrap(bytes);\n                            Map<String, Object> nestedMessage = read(\n                                    nestedByteBuffer,\n                                    fieldDescriptor.getMessageType());\n                            addToResultMap(resultMap, fieldName, nestedMessage, fieldDescriptor.isRepeated(), isOneof);\n                        } else {\n                            addToResultMap(resultMap, fieldName, bytes, fieldDescriptor.isRepeated(), isOneof);\n                        }\n                    }\n                    break;\n                case 5: // Fixed32, SFixed32, Float\n                    int rawFixed32Value = inputBuffer.order(ByteOrder.LITTLE_ENDIAN).getInt();\n                    switch (fieldDescriptor.getType()) {\n                        case FLOAT:\n                            value = Float.intBitsToFloat(rawFixed32Value);\n                            break;\n                        case FIXED32:\n                            value = Long.valueOf(rawFixed32Value);\n                            break;\n                        case SFIXED32:\n                            value = rawFixed32Value;\n                            break;\n                        default:\n                            throw new UnsupportedOperationException(\"Unsupported type: \" + fieldDescriptor.getType());\n                    }\n                    addToResultMap(resultMap, fieldName, value, fieldDescriptor.isRepeated(), isOneof);\n                    break;\n                default:\n                    throw new UnsupportedOperationException(\"Unsupported wire type: \" + wireType);\n            }\n        }\n\n        return resultMap;\n    }\n\n    /**\n     * Adds a field value to the result Map, handling repeated and oneof fields.\n     *\n     * @param resultMap The result Map.\n     * @param fieldName The name of the field.\n     * @param value The value of the field.\n     * @param isRepeated Whether the field is a repeated field.\n     * @param isOneof Whether the field is part of a oneof.\n     */\n    private static void addToResultMap(Map<String, Object> resultMap, String fieldName, Object value,\n                                       boolean isRepeated, boolean isOneof) {", "        if (isOneof || !isRepeated) {\n            resultMap.put(fieldName, value);\n        } else {\n            if (resultMap.containsKey(fieldName)) {\n                @SuppressWarnings(\"unchecked\")\n                List<Object> values = (List<Object>) resultMap.get(fieldName);\n                values.add(value);\n            } else {\n                List<Object> values = new ArrayList<>();\n                values.add(value);\n                resultMap.put(fieldName, values);\n            }\n        }\n    }\n\n    /**\n     * Reads a varint from a ByteBuffer and converts it to a long.\n     *\n     * @param byteBuffer The ByteBuffer to read from.\n     * @return The varint as a long.\n     */\n    private static long readVarint(ByteBuffer byteBuffer) {\n        long result = 0;\n        int shift = 0;\n        int currentByte;\n\n        do {\n            currentByte = byteBuffer.get() & 0xFF;\n            result |= (long) (currentByte & 0x7F) << shift;\n            shift += 7;", "        } while ((currentByte & 0x80) != 0);\n\n        return result;\n    }\n\n    /**\n     * Decodes a ZigZag-encoded 32-bit integer.\n     *\n     * @param n The ZigZag-encoded integer to decode.\n     * @return The decoded integer.\n     */\n    private static int decodeZigZag32(int n) {\n        return (n >>> 1) ^ -(n & 1);\n    }\n\n    /**\n     * Decodes a ZigZag-encoded 64-bit integer.\n     *\n     * @param n The ZigZag-encoded integer to decode.\n     * @return The decoded integer.\n     */\n    private static long decodeZigZag64(long n) {\n        return (n >>> 1) ^ -(n & 1);\n    }\n}\n"]}
{"filename": "twister-avro/src/test/java/dev/twister/avro/AvroSchemaInferrerTest.java", "chunked_list": ["package dev.twister.avro;\n\nimport junit.framework.TestCase;\nimport org.apache.avro.Schema;\nimport org.apache.avro.SchemaBuilder;\n\nimport java.math.BigDecimal;\nimport java.time.Instant;\nimport java.time.LocalDate;\nimport java.time.LocalDateTime;", "import java.time.LocalDate;\nimport java.time.LocalDateTime;\nimport java.time.LocalTime;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.UUID;\nimport java.util.concurrent.TimeUnit;\n\npublic class AvroSchemaInferrerTest extends TestCase {\n    public void testSchemaInferrer() {\n        Map<String, Object> testMap = new HashMap<>();\n        testMap.put(\"stringField\", \"Hello, World!\");\n        testMap.put(\"intField\", 42);\n        testMap.put(\"booleanField\", true);\n        testMap.put(\"longField\", 123456789L);\n        testMap.put(\"floatField\", 3.14f);\n        testMap.put(\"doubleField\", 2.718281828);\n        testMap.put(\"nullField\", null);\n\n        Schema inferredSchema = new AvroSchemaInferrer().infer(testMap, \"TestSchema\");\n\n        // Define expected schema with fields added in alphabetical order\n        Schema expectedSchema = SchemaBuilder.record(\"TestSchema\").fields()\n                .name(\"booleanField\").type(SchemaBuilder.unionOf().nullType().and().booleanType().endUnion()).noDefault()\n                .name(\"doubleField\").type(SchemaBuilder.unionOf().nullType().and().doubleType().endUnion()).noDefault()\n                .name(\"floatField\").type(SchemaBuilder.unionOf().nullType().and().floatType().endUnion()).noDefault()\n                .name(\"intField\").type(SchemaBuilder.unionOf().nullType().and().intType().endUnion()).noDefault()\n                .name(\"longField\").type(SchemaBuilder.unionOf().nullType().and().longType().endUnion()).noDefault()\n                .name(\"nullField\").type().nullType().noDefault()\n                .name(\"stringField\").type(SchemaBuilder.unionOf().nullType().and().stringType().endUnion()).noDefault()\n                .endRecord();\n\n        // Compare inferred schema with expected schema\n        assertEquals(expectedSchema, inferredSchema);\n    }\n", "\npublic class AvroSchemaInferrerTest extends TestCase {\n    public void testSchemaInferrer() {\n        Map<String, Object> testMap = new HashMap<>();\n        testMap.put(\"stringField\", \"Hello, World!\");\n        testMap.put(\"intField\", 42);\n        testMap.put(\"booleanField\", true);\n        testMap.put(\"longField\", 123456789L);\n        testMap.put(\"floatField\", 3.14f);\n        testMap.put(\"doubleField\", 2.718281828);\n        testMap.put(\"nullField\", null);\n\n        Schema inferredSchema = new AvroSchemaInferrer().infer(testMap, \"TestSchema\");\n\n        // Define expected schema with fields added in alphabetical order\n        Schema expectedSchema = SchemaBuilder.record(\"TestSchema\").fields()\n                .name(\"booleanField\").type(SchemaBuilder.unionOf().nullType().and().booleanType().endUnion()).noDefault()\n                .name(\"doubleField\").type(SchemaBuilder.unionOf().nullType().and().doubleType().endUnion()).noDefault()\n                .name(\"floatField\").type(SchemaBuilder.unionOf().nullType().and().floatType().endUnion()).noDefault()\n                .name(\"intField\").type(SchemaBuilder.unionOf().nullType().and().intType().endUnion()).noDefault()\n                .name(\"longField\").type(SchemaBuilder.unionOf().nullType().and().longType().endUnion()).noDefault()\n                .name(\"nullField\").type().nullType().noDefault()\n                .name(\"stringField\").type(SchemaBuilder.unionOf().nullType().and().stringType().endUnion()).noDefault()\n                .endRecord();\n\n        // Compare inferred schema with expected schema\n        assertEquals(expectedSchema, inferredSchema);\n    }\n", "    public void testArray() {\n        AvroSchemaInferrer inferrer = new AvroSchemaInferrer();\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"array\", Arrays.asList(1, 2, 3));\n        Schema schema = inferrer.infer(map, \"TestArray\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestArray\\\",\\\"fields\\\":[{\\\"name\\\":\\\"array\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"array\\\",\\\"items\\\":[\\\"null\\\",\\\"int\\\"]}]}]}\";\n        assertEquals(expectedSchema, schema.toString());\n    }\n\n    public void testNestedRecord() {\n        AvroSchemaInferrer inferrer = new AvroSchemaInferrer();\n        Map<String, Object> map = new HashMap<>();\n        Map<String, Object> subMap = new HashMap<>();\n        subMap.put(\"subField\", \"subValue\");\n        map.put(\"field\", subMap);\n        Schema schema = inferrer.infer(map, \"TestComplexMap\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestComplexMap\\\",\\\"fields\\\":[{\\\"name\\\":\\\"field\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestComplexMap_field\\\",\\\"fields\\\":[{\\\"name\\\":\\\"subField\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"]}]}]}]}\";\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testNestedRecord() {\n        AvroSchemaInferrer inferrer = new AvroSchemaInferrer();\n        Map<String, Object> map = new HashMap<>();\n        Map<String, Object> subMap = new HashMap<>();\n        subMap.put(\"subField\", \"subValue\");\n        map.put(\"field\", subMap);\n        Schema schema = inferrer.infer(map, \"TestComplexMap\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestComplexMap\\\",\\\"fields\\\":[{\\\"name\\\":\\\"field\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestComplexMap_field\\\",\\\"fields\\\":[{\\\"name\\\":\\\"subField\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"]}]}]}]}\";\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testSchemaWithMapAsMap() {\n        // Create a test map with multiple different types of values\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"field1\", \"string\");\n        map.put(\"field2\", 123);\n        map.put(\"field3\", 45.67);\n\n        // Create an AvroSchemaInferrer with mapAsRecord = false\n        AvroSchemaInferrer inferrer = new AvroSchemaInferrer(AvroSchemaInferrer.mapOfDefaultInferrers(TimeUnit.MILLISECONDS), false);\n\n        // Infer the Avro schema for the map\n        Schema schema = inferrer.infer(map, \"TestRecord\");\n\n        // Check that the resulting schema is a map schema with a union value type\n        assertEquals(Schema.Type.MAP, schema.getType());\n        assertEquals(Schema.Type.UNION, schema.getValueType().getType());\n    }\n", "    public void testBigDecimal() {\n        Map<String, Object> map = new HashMap<>();\n        BigDecimal decimalValue = new BigDecimal(\"123.456\");\n        map.put(\"decimalField\", decimalValue);\n\n        Schema schema = new AvroSchemaInferrer().infer(map, \"TestDecimal\");\n        String expectedSchema = String.format(\"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestDecimal\\\",\\\"fields\\\":[{\\\"name\\\":\\\"decimalField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"bytes\\\",\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":%d,\\\"scale\\\":%d}]}]}\", decimalValue.precision(), decimalValue.scale());\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testUUID() {\n        Map<String, Object> map = new HashMap<>();\n        UUID uuid = UUID.randomUUID();\n        map.put(\"uuidField\", uuid);\n\n        Schema schema = new AvroSchemaInferrer().infer(map, \"TestUUID\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestUUID\\\",\\\"fields\\\":[{\\\"name\\\":\\\"uuidField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"string\\\",\\\"logicalType\\\":\\\"uuid\\\"}]}]}\";\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testLocalDate() {\n        Map<String, Object> map = new HashMap<>();\n        LocalDate date = LocalDate.now();\n        map.put(\"dateField\", date);\n\n        Schema schema = new AvroSchemaInferrer().infer(map, \"TestDate\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestDate\\\",\\\"fields\\\":[{\\\"name\\\":\\\"dateField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"int\\\",\\\"logicalType\\\":\\\"date\\\"}]}]}\";\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testLocalTimeMillis() {\n        Map<String, Object> map = new HashMap<>();\n        LocalTime time = LocalTime.now();\n        map.put(\"timeField\", time);\n\n        Schema schema = new AvroSchemaInferrer().infer(map, \"TestTime\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestTime\\\",\\\"fields\\\":[{\\\"name\\\":\\\"timeField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"int\\\",\\\"logicalType\\\":\\\"time-millis\\\"}]}]}\";\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testLocalTimeMicros() {\n        Map<String, Object> map = new HashMap<>();\n        LocalTime time = LocalTime.now();\n        map.put(\"timeField\", time);\n\n        AvroSchemaInferrer inferrer = new AvroSchemaInferrer(AvroSchemaInferrer.mapOfDefaultInferrers(TimeUnit.MICROSECONDS), true);\n        Schema schema = inferrer.infer(map, \"TestTimeMicros\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestTimeMicros\\\",\\\"fields\\\":[{\\\"name\\\":\\\"timeField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"time-micros\\\"}]}]}\";\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testInstantMillis() {\n        Map<String, Object> map = new HashMap<>();\n        Instant instant = Instant.now();\n        map.put(\"timestampField\", instant);\n\n        Schema schema = new AvroSchemaInferrer().infer(map, \"TestTimestamp\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestTimestamp\\\",\\\"fields\\\":[{\\\"name\\\":\\\"timestampField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"timestamp-millis\\\"}]}]}\";\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testInstantMicros() {\n        Map<String, Object> map = new HashMap<>();\n        Instant instant = Instant.now();\n        map.put(\"timestampField\", instant);\n\n        AvroSchemaInferrer inferrer = new AvroSchemaInferrer(AvroSchemaInferrer.mapOfDefaultInferrers(TimeUnit.MICROSECONDS), true);\n        Schema schema = inferrer.infer(map, \"TestTimestampMicros\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestTimestampMicros\\\",\\\"fields\\\":[{\\\"name\\\":\\\"timestampField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"timestamp-micros\\\"}]}]}\";\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testLocalDateTimeMillis() {\n        Map<String, Object> map = new HashMap<>();\n        LocalDateTime dateTime = LocalDateTime.now();\n        map.put(\"dateTimeField\", dateTime);\n\n        Schema schema = new AvroSchemaInferrer().infer(map, \"TestDateTime\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestDateTime\\\",\\\"fields\\\":[{\\\"name\\\":\\\"dateTimeField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"timestamp-millis\\\"}]}]}\";\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n", "    public void testLocalDateTimeMicros() {\n        Map<String, Object> map = new HashMap<>();\n        LocalDateTime dateTime = LocalDateTime.now();\n        map.put(\"dateTimeField\", dateTime);\n\n        AvroSchemaInferrer inferrer = new AvroSchemaInferrer(AvroSchemaInferrer.mapOfDefaultInferrers(TimeUnit.MICROSECONDS), true);\n        Schema schema = inferrer.infer(map, \"TestDateTimeMicros\");\n        String expectedSchema = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestDateTimeMicros\\\",\\\"fields\\\":[{\\\"name\\\":\\\"dateTimeField\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"timestamp-micros\\\"}]}]}\";\n\n        assertEquals(expectedSchema, schema.toString());\n    }\n}\n"]}
{"filename": "twister-avro/src/test/java/dev/twister/avro/AvroWriterTest.java", "chunked_list": ["package dev.twister.avro;\n\nimport junit.framework.TestCase;\nimport org.apache.avro.Schema;\nimport org.apache.avro.SchemaBuilder;\nimport org.apache.avro.generic.GenericDatumReader;\nimport org.apache.avro.generic.GenericRecord;\nimport org.apache.avro.io.DatumReader;\nimport org.apache.avro.io.Decoder;\nimport org.apache.avro.io.DecoderFactory;", "import org.apache.avro.io.Decoder;\nimport org.apache.avro.io.DecoderFactory;\nimport org.apache.avro.specific.SpecificDatumReader;\nimport org.apache.avro.util.Utf8;\n\nimport java.io.ByteArrayInputStream;\nimport java.math.BigDecimal;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.time.*;", "import java.nio.ByteBuffer;\nimport java.time.*;\nimport java.time.temporal.ChronoUnit;\nimport java.time.temporal.TemporalUnit;\nimport java.util.*;\nimport java.util.stream.Collectors;\n\npublic class AvroWriterTest extends TestCase {\n    public void testPrimitives() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"nullField\\\", \\\"type\\\": \\\"null\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"booleanField\\\", \\\"type\\\": \\\"boolean\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"intField\\\", \\\"type\\\": \\\"int\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"longField\\\", \\\"type\\\": \\\"long\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"floatField\\\", \\\"type\\\": \\\"float\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"doubleField\\\", \\\"type\\\": \\\"double\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"stringField\\\", \\\"type\\\": \\\"string\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"bytesField\\\", \\\"type\\\": \\\"bytes\\\"}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        recordMap.put(\"nullField\", null);\n        recordMap.put(\"booleanField\", true);\n        recordMap.put(\"intField\", 42);\n        recordMap.put(\"longField\", 123456789L);\n        recordMap.put(\"floatField\", 3.14f);\n        recordMap.put(\"doubleField\", 2.718281828);\n        recordMap.put(\"stringField\", \"Hello, World!\");\n        recordMap.put(\"bytesField\", ByteBuffer.wrap(new byte[]{1, 2, 3, 4, 5}));\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        // Read data back using a GenericDatumReader and Decoder\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        assertNull(genericRecord.get(\"nullField\"));\n        assertTrue((Boolean) genericRecord.get(\"booleanField\"));\n        assertEquals(42, genericRecord.get(\"intField\"));\n        assertEquals(123456789L, genericRecord.get(\"longField\"));\n        assertEquals(3.14f, (Float) genericRecord.get(\"floatField\"), 0.001);\n        assertEquals(2.718281828, (Double) genericRecord.get(\"doubleField\"), 0.000000001);\n        assertEquals(\"Hello, World!\", genericRecord.get(\"stringField\").toString());\n\n        ByteBuffer decodedBytes = (ByteBuffer) genericRecord.get(\"bytesField\");\n        ByteBuffer expectedBytes = ByteBuffer.wrap(new byte[]{1, 2, 3, 4, 5});\n        assertEquals(expectedBytes, decodedBytes);\n    }\n", "    public void testPrimitives() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"nullField\\\", \\\"type\\\": \\\"null\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"booleanField\\\", \\\"type\\\": \\\"boolean\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"intField\\\", \\\"type\\\": \\\"int\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"longField\\\", \\\"type\\\": \\\"long\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"floatField\\\", \\\"type\\\": \\\"float\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"doubleField\\\", \\\"type\\\": \\\"double\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"stringField\\\", \\\"type\\\": \\\"string\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"bytesField\\\", \\\"type\\\": \\\"bytes\\\"}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        recordMap.put(\"nullField\", null);\n        recordMap.put(\"booleanField\", true);\n        recordMap.put(\"intField\", 42);\n        recordMap.put(\"longField\", 123456789L);\n        recordMap.put(\"floatField\", 3.14f);\n        recordMap.put(\"doubleField\", 2.718281828);\n        recordMap.put(\"stringField\", \"Hello, World!\");\n        recordMap.put(\"bytesField\", ByteBuffer.wrap(new byte[]{1, 2, 3, 4, 5}));\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        // Read data back using a GenericDatumReader and Decoder\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        assertNull(genericRecord.get(\"nullField\"));\n        assertTrue((Boolean) genericRecord.get(\"booleanField\"));\n        assertEquals(42, genericRecord.get(\"intField\"));\n        assertEquals(123456789L, genericRecord.get(\"longField\"));\n        assertEquals(3.14f, (Float) genericRecord.get(\"floatField\"), 0.001);\n        assertEquals(2.718281828, (Double) genericRecord.get(\"doubleField\"), 0.000000001);\n        assertEquals(\"Hello, World!\", genericRecord.get(\"stringField\").toString());\n\n        ByteBuffer decodedBytes = (ByteBuffer) genericRecord.get(\"bytesField\");\n        ByteBuffer expectedBytes = ByteBuffer.wrap(new byte[]{1, 2, 3, 4, 5});\n        assertEquals(expectedBytes, decodedBytes);\n    }\n", "    public void testBidirectionalPrimitives() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"nullField\\\", \\\"type\\\": \\\"null\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"booleanField\\\", \\\"type\\\": \\\"boolean\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"intField\\\", \\\"type\\\": \\\"int\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"longField\\\", \\\"type\\\": \\\"long\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"floatField\\\", \\\"type\\\": \\\"float\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"doubleField\\\", \\\"type\\\": \\\"double\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"stringField\\\", \\\"type\\\": \\\"string\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"bytesField\\\", \\\"type\\\": \\\"bytes\\\"}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        recordMap.put(\"nullField\", null);\n        recordMap.put(\"booleanField\", true);\n        recordMap.put(\"intField\", 42);\n        recordMap.put(\"longField\", 123456789L);\n        recordMap.put(\"floatField\", 3.14f);\n        recordMap.put(\"doubleField\", 2.718281828);\n        recordMap.put(\"stringField\", \"Hello, World!\");\n        recordMap.put(\"bytesField\", ByteBuffer.wrap(new byte[]{1, 2, 3, 4, 5}));\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(recordMap, resultMap);\n    }\n", "    public void testEnumField() throws Exception {\n        String schemaJson = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestEnumRecord\\\",\\\"fields\\\":[{\\\"name\\\":\\\"enumField\\\",\\\"type\\\":{\\\"type\\\":\\\"enum\\\",\\\"name\\\":\\\"TestEnum\\\",\\\"symbols\\\":[\\\"RED\\\",\\\"GREEN\\\",\\\"BLUE\\\"]}}]}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        Map<String, Object> recordMap = new HashMap<>();\n        recordMap.put(\"enumField\", \"GREEN\");\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        assertEquals(\"GREEN\", genericRecord.get(\"enumField\").toString());\n    }\n", "    public void testArrayField() throws Exception {\n        String schemaJson = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestArrayRecord\\\",\\\"fields\\\":[{\\\"name\\\":\\\"arrayField\\\",\\\"type\\\":{\\\"type\\\":\\\"array\\\",\\\"items\\\":\\\"string\\\"}}]}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        Map<String, Object> recordMap = new HashMap<>();\n        recordMap.put(\"arrayField\", Arrays.asList(\"Aa\", \"Bb\", \"Cc\"));\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        List<CharSequence> utf8List = (List<CharSequence>) genericRecord.get(\"arrayField\");\n        List<String> stringList = utf8List.stream().map(CharSequence::toString).collect(Collectors.toList());\n        assertEquals(Arrays.asList(\"Aa\", \"Bb\", \"Cc\"), stringList);\n    }\n", "    public void testMapField() throws Exception {\n        String schemaJson = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestMapRecord\\\",\\\"fields\\\":[{\\\"name\\\":\\\"mapField\\\",\\\"type\\\":{\\\"type\\\":\\\"map\\\",\\\"values\\\":\\\"int\\\"}}]}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        Map<String, Object> recordMap = new HashMap<>();\n        Map<String, Integer> map = new TreeMap<>();\n        map.put(\"one\", 1);\n        map.put(\"two\", 2);\n        map.put(\"three\", 3);\n        recordMap.put(\"mapField\", map);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        Map<Object, Object> actualMap = (Map<Object, Object>) genericRecord.get(\"mapField\");\n        assertEquals(1, actualMap.get(new Utf8(\"one\")));\n        assertEquals(2, actualMap.get(new Utf8(\"two\")));\n        assertEquals(3, actualMap.get(new Utf8(\"three\")));\n    }\n", "    public void testUnionField() throws Exception {\n        String schemaJson = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestUnionRecord\\\",\\\"fields\\\":[{\\\"name\\\":\\\"unionField\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"]}]}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        Map<String, Object> recordMap = new HashMap<>();\n        recordMap.put(\"unionField\", \"example\");\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        assertEquals(\"example\", genericRecord.get(\"unionField\").toString());\n    }\n", "    public void testBidirectionalComplexTypes() throws Exception {\n        String schemaJson = \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestComplexTypes\\\",\\\"fields\\\":[{\\\"name\\\":\\\"enumField\\\",\\\"type\\\":{\\\"type\\\":\\\"enum\\\",\\\"name\\\":\\\"TestEnum\\\",\\\"symbols\\\":[\\\"RED\\\",\\\"GREEN\\\",\\\"BLUE\\\"]}},{\\\"name\\\":\\\"arrayField\\\",\\\"type\\\":{\\\"type\\\":\\\"array\\\",\\\"items\\\":\\\"string\\\"}},{\\\"name\\\":\\\"mapField\\\",\\\"type\\\":{\\\"type\\\":\\\"map\\\",\\\"values\\\":\\\"int\\\"}},{\\\"name\\\":\\\"unionField\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"]},{\\\"name\\\":\\\"fixedField\\\",\\\"type\\\":{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"TestFixed\\\",\\\"size\\\":4}}]}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        Map<String, Object> recordMap = new HashMap<>();\n        recordMap.put(\"enumField\", \"GREEN\");\n        recordMap.put(\"arrayField\", Arrays.asList(\"Aa\", \"Bb\", \"Cc\"));\n        Map<String, Integer> map = new HashMap<>();\n        map.put(\"one\", 1);\n        map.put(\"two\", 2);\n        map.put(\"three\", 3);\n        recordMap.put(\"mapField\", map);\n        recordMap.put(\"unionField\", \"example\");\n        recordMap.put(\"fixedField\", ByteBuffer.wrap(new byte[]{1, 2, 3, 4}));\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n        Map<String, Object> result = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(\"GREEN\", result.get(\"enumField\"));\n        assertEquals(Arrays.asList(\"Aa\", \"Bb\", \"Cc\"), result.get(\"arrayField\"));\n        assertEquals(map, result.get(\"mapField\"));\n        assertEquals(\"example\", result.get(\"unionField\"));\n        ByteBuffer decodedBytes = (ByteBuffer) result.get(\"fixedField\");\n        assertEquals(4, decodedBytes.remaining());", "        for (int i = 1; i <= 4; i++) {\n            assertEquals(i, decodedBytes.get());\n        }\n    }\n\n    public void testWriteWithInferredSchema() throws Exception {\n        // Define a map of values\n        Map<String, Object> testMap = new HashMap<>();\n        testMap.put(\"stringField\", \"Hello, World!\");\n        testMap.put(\"intField\", 42);\n        testMap.put(\"booleanField\", true);\n        testMap.put(\"longField\", 123456789L);\n        testMap.put(\"floatField\", 3.14f);\n        testMap.put(\"doubleField\", 2.718281828);\n        testMap.put(\"nullField\", null);\n\n        // Write the map to Avro\n        AvroWriter avroWriter = new AvroWriter();\n        ByteBuffer avroData = avroWriter.write(testMap, \"TestSchema\");\n\n        // Manually create expected schema\n        Schema expectedSchema = SchemaBuilder.record(\"TestSchema\").fields()\n                .name(\"booleanField\").type().unionOf().nullType().and().booleanType().endUnion().noDefault()\n                .name(\"doubleField\").type().unionOf().nullType().and().doubleType().endUnion().noDefault()\n                .name(\"floatField\").type().unionOf().nullType().and().floatType().endUnion().noDefault()\n                .name(\"intField\").type().unionOf().nullType().and().intType().endUnion().noDefault()\n                .name(\"longField\").type().unionOf().nullType().and().longType().endUnion().noDefault()\n                .name(\"nullField\").type().nullType().noDefault()\n                .name(\"stringField\").type().unionOf().nullType().and().stringType().endUnion().noDefault()\n                .endRecord();\n\n        DatumReader<GenericRecord> reader = new SpecificDatumReader<>(expectedSchema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(new ByteArrayInputStream(avroData.array()), null);\n        GenericRecord record = reader.read(null, decoder);\n\n        // Validate the read back data\n        assertEquals(\"Hello, World!\", record.get(\"stringField\").toString());\n        assertEquals(42, record.get(\"intField\"));\n        assertEquals(true, record.get(\"booleanField\"));\n        assertEquals(123456789L, record.get(\"longField\"));\n        assertEquals(3.14f, (float)record.get(\"floatField\"), 0.001);\n        assertEquals(2.718281828, (double)record.get(\"doubleField\"), 0.001);\n        assertNull(record.get(\"nullField\"));\n    }\n", "    public void testDecimal() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"decimalField\\\", \\\"type\\\": {\\\"type\\\": \\\"bytes\\\", \\\"logicalType\\\": \\\"decimal\\\", \\\"precision\\\": 4, \\\"scale\\\": 2}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        recordMap.put(\"decimalField\", new BigDecimal(\"12.34\"));\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        BigDecimal decodedDecimal = new BigDecimal(new BigInteger(((ByteBuffer) genericRecord.get(\"decimalField\")).array()), 2);\n        assertEquals(new BigDecimal(\"12.34\"), decodedDecimal);\n    }\n", "    public void testUUID() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"uuidField\\\", \\\"type\\\": {\\\"type\\\": \\\"string\\\", \\\"logicalType\\\": \\\"uuid\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        UUID uuid = UUID.randomUUID();\n        recordMap.put(\"uuidField\", uuid);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        assertEquals(uuid.toString(), genericRecord.get(\"uuidField\").toString());\n    }\n", "    public void testDate() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"dateField\\\", \\\"type\\\": {\\\"type\\\": \\\"int\\\", \\\"logicalType\\\": \\\"date\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        LocalDate date = LocalDate.now();\n        recordMap.put(\"dateField\", date);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        int readDays = (Integer) genericRecord.get(\"dateField\");\n        assertEquals(date, LocalDate.ofEpochDay(readDays));\n    }\n", "    public void testTimeMillis() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"timeMillisField\\\", \\\"type\\\": {\\\"type\\\": \\\"int\\\", \\\"logicalType\\\": \\\"time-millis\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        LocalTime time = LocalTime.now();\n        recordMap.put(\"timeMillisField\", time);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        int readMillis = (Integer) genericRecord.get(\"timeMillisField\");\n        assertEquals(time.truncatedTo(ChronoUnit.MILLIS), LocalTime.ofNanoOfDay((long) readMillis * 1_000_000));\n    }\n", "    public void testTimeMicros() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"timeMicrosField\\\", \\\"type\\\": {\\\"type\\\": \\\"long\\\", \\\"logicalType\\\": \\\"time-micros\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        LocalTime time = LocalTime.now();\n        recordMap.put(\"timeMicrosField\", time);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        long readMicros = (Long) genericRecord.get(\"timeMicrosField\");\n        assertEquals(time.truncatedTo(ChronoUnit.MICROS), LocalTime.ofNanoOfDay(readMicros * 1_000));\n    }\n", "    public void testTimestampMillis() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"timestampMillisField\\\", \\\"type\\\": {\\\"type\\\": \\\"long\\\", \\\"logicalType\\\": \\\"timestamp-millis\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        Instant timestamp = Instant.now();\n        recordMap.put(\"timestampMillisField\", timestamp);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        long readMillis = (Long) genericRecord.get(\"timestampMillisField\");\n        assertEquals(timestamp.truncatedTo(ChronoUnit.MILLIS), Instant.ofEpochMilli(readMillis));\n    }\n", "    public void testTimestampMicros() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"timestampMicrosField\\\", \\\"type\\\": {\\\"type\\\": \\\"long\\\", \\\"logicalType\\\": \\\"timestamp-micros\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        Instant timestamp = Instant.now();\n        recordMap.put(\"timestampMicrosField\", timestamp);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        long readMicros = (Long) genericRecord.get(\"timestampMicrosField\");\n        assertEquals(timestamp.truncatedTo(ChronoUnit.MICROS), Instant.ofEpochSecond(0, readMicros * 1_000));\n    }\n", "    public void testLocalTimestampMillis() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"localTimestampMillisField\\\", \\\"type\\\": {\\\"type\\\": \\\"long\\\", \\\"logicalType\\\": \\\"local-timestamp-millis\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        LocalDateTime localTimestamp = LocalDateTime.now();\n        recordMap.put(\"localTimestampMillisField\", localTimestamp);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        long readMillis = (Long) genericRecord.get(\"localTimestampMillisField\");\n        assertEquals(localTimestamp.truncatedTo(ChronoUnit.MILLIS), LocalDateTime.ofInstant(Instant.ofEpochMilli(readMillis), ZoneOffset.UTC));\n    }\n", "    public void testLocalTimestampMicros() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"localTimestampMicrosField\\\", \\\"type\\\": {\\\"type\\\": \\\"long\\\", \\\"logicalType\\\": \\\"local-timestamp-micros\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        Map<String, Object> recordMap = new HashMap<>();\n        LocalDateTime localTimestamp = LocalDateTime.now();\n        recordMap.put(\"localTimestampMicrosField\", localTimestamp);\n\n        ByteBuffer byteBuffer = new AvroWriter().write(recordMap, schema);\n\n        GenericDatumReader<GenericRecord> datumReader = new GenericDatumReader<>(schema);\n        Decoder decoder = DecoderFactory.get().binaryDecoder(byteBuffer.array(), null);\n        GenericRecord genericRecord = datumReader.read(null, decoder);\n\n        long readMicros = (Long) genericRecord.get(\"localTimestampMicrosField\");\n        assertEquals(localTimestamp.truncatedTo(ChronoUnit.MICROS), LocalDateTime.ofInstant(Instant.ofEpochSecond(0, readMicros * 1_000), ZoneOffset.UTC));\n    }\n}"]}
{"filename": "twister-avro/src/test/java/dev/twister/avro/AvroReaderTest.java", "chunked_list": ["package dev.twister.avro;\n\nimport junit.framework.TestCase;\nimport org.apache.avro.Schema;\nimport org.apache.avro.generic.GenericData;\nimport org.apache.avro.generic.GenericDatumWriter;\nimport org.apache.avro.io.BinaryEncoder;\nimport org.apache.avro.io.EncoderFactory;\n\nimport java.io.ByteArrayOutputStream;", "\nimport java.io.ByteArrayOutputStream;\nimport java.math.BigDecimal;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.time.*;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.UUID;", "import java.util.Map;\nimport java.util.UUID;\n\npublic class AvroReaderTest extends TestCase {\n    public void testPrimitives() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"nullField\\\", \\\"type\\\": \\\"null\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"booleanField\\\", \\\"type\\\": \\\"boolean\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"intField\\\", \\\"type\\\": \\\"int\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"longField\\\", \\\"type\\\": \\\"long\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"floatField\\\", \\\"type\\\": \\\"float\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"doubleField\\\", \\\"type\\\": \\\"double\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"stringField\\\", \\\"type\\\": \\\"string\\\"},\\n\" +\n                \"    {\\\"name\\\": \\\"bytesField\\\", \\\"type\\\": \\\"bytes\\\"}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"nullField\", null);\n        record.put(\"booleanField\", true);\n        record.put(\"intField\", 42);\n        record.put(\"longField\", 123456789L);\n        record.put(\"floatField\", 3.14f);\n        record.put(\"doubleField\", 2.718281828);\n        record.put(\"stringField\", \"Hello, World!\");\n        record.put(\"bytesField\", ByteBuffer.wrap(new byte[]{1, 2, 3, 4, 5}));\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        assertNull(resultMap.get(\"nullField\"));\n        assertTrue((Boolean) resultMap.get(\"booleanField\"));\n        assertEquals(42, resultMap.get(\"intField\"));\n        assertEquals(123456789L, resultMap.get(\"longField\"));\n        assertEquals(3.14f, (Float) resultMap.get(\"floatField\"), 0.001);\n        assertEquals(2.718281828, (Double) resultMap.get(\"doubleField\"), 0.000000001);\n        assertEquals(\"Hello, World!\", resultMap.get(\"stringField\"));\n\n        ByteBuffer decodedBytes = (ByteBuffer) resultMap.get(\"bytesField\");\n        assertEquals(5, decodedBytes.remaining());", "        for (int i = 1; i <= 5; i++) {\n            assertEquals(i, decodedBytes.get());\n        }\n    }\n\n    public void testComplexTypes() throws Exception {\n        Schema schema = Schema.parse(\"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"TestComplexTypes\\\",\\\"fields\\\":[{\\\"name\\\":\\\"enumField\\\",\\\"type\\\":{\\\"type\\\":\\\"enum\\\",\\\"name\\\":\\\"TestEnum\\\",\\\"symbols\\\":[\\\"RED\\\",\\\"GREEN\\\",\\\"BLUE\\\"]}},{\\\"name\\\":\\\"arrayField\\\",\\\"type\\\":{\\\"type\\\":\\\"array\\\",\\\"items\\\":\\\"string\\\"}},{\\\"name\\\":\\\"mapField\\\",\\\"type\\\":{\\\"type\\\":\\\"map\\\",\\\"values\\\":\\\"int\\\"}},{\\\"name\\\":\\\"unionField\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"]},{\\\"name\\\":\\\"fixedField\\\",\\\"type\\\":{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"TestFixed\\\",\\\"size\\\":4}}]}\");\n\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"enumField\", new GenericData.EnumSymbol(schema.getField(\"enumField\").schema(), \"GREEN\"));\n        record.put(\"arrayField\", new GenericData.Array<>(schema.getField(\"arrayField\").schema(), Arrays.asList(\"Aa\", \"Bb\", \"Cc\")));\n        Map<String, Integer> map = new HashMap<>();\n        map.put(\"one\", 1);\n        map.put(\"two\", 2);\n        map.put(\"three\", 3);\n        record.put(\"mapField\", map);\n        record.put(\"unionField\", \"example\");\n        record.put(\"fixedField\", new GenericData.Fixed(schema.getField(\"fixedField\").schema(), new byte[]{1, 2, 3, 4}));\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> result = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(\"GREEN\", result.get(\"enumField\"));\n        assertEquals(Arrays.asList(\"Aa\", \"Bb\", \"Cc\"), result.get(\"arrayField\"));\n        assertEquals(map, result.get(\"mapField\"));\n        assertEquals(\"example\", result.get(\"unionField\"));\n        assertEquals(ByteBuffer.wrap(new byte[]{1, 2, 3, 4}), result.get(\"fixedField\"));\n    }\n", "    public void testNullStringUnionType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"unionField\\\", \\\"type\\\": [\\\"null\\\", \\\"string\\\"]}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        // Test with string value\n        GenericData.Record recordWithString = new GenericData.Record(schema);\n        recordWithString.put(\"unionField\", \"Hello, World!\");\n\n        ByteBuffer byteBufferWithString = encodeRecordToByteBuffer(recordWithString, schema);\n        Map<String, Object> resultMapWithString = new AvroReader().read(byteBufferWithString, schema);\n\n        assertEquals(\"Hello, World!\", resultMapWithString.get(\"unionField\"));\n\n        // Test with null value\n        GenericData.Record recordWithNull = new GenericData.Record(schema);\n        recordWithNull.put(\"unionField\", null);\n\n        ByteBuffer byteBufferWithNull = encodeRecordToByteBuffer(recordWithNull, schema);\n        Map<String, Object> resultMapWithNull = new AvroReader().read(byteBufferWithNull, schema);\n\n        assertNull(resultMapWithNull.get(\"unionField\"));\n    }\n", "    public void testDecimalLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"decimalField\\\", \\\"type\\\": {\\\"type\\\":\\\"bytes\\\",\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":4,\\\"scale\\\":2}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        BigDecimal decimalValue = new BigDecimal(\"12.34\");\n        BigInteger unscaledValue = decimalValue.unscaledValue();\n        byte[] bytesValue = unscaledValue.toByteArray();\n\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"decimalField\", ByteBuffer.wrap(bytesValue));\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        BigDecimal resultDecimal = (BigDecimal) resultMap.get(\"decimalField\");\n\n        assertEquals(decimalValue, resultDecimal);\n    }\n", "    public void testUuidLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"uuidField\\\", \\\"type\\\": {\\\"type\\\":\\\"string\\\",\\\"logicalType\\\":\\\"uuid\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        UUID uuidValue = UUID.randomUUID();\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"uuidField\", uuidValue.toString());\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(uuidValue, resultMap.get(\"uuidField\"));\n    }\n", "    public void testDateLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"dateField\\\", \\\"type\\\": {\\\"type\\\":\\\"int\\\",\\\"logicalType\\\":\\\"date\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        LocalDate dateValue = LocalDate.of(2023, 5, 22);\n        int daysSinceEpoch = (int) dateValue.toEpochDay();\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"dateField\", daysSinceEpoch);\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(dateValue, resultMap.get(\"dateField\"));\n    }\n", "    public void testTimeMillisLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"timeMillisField\\\", \\\"type\\\": {\\\"type\\\":\\\"int\\\",\\\"logicalType\\\":\\\"time-millis\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        int millisInDay = 12345678; // Represents the number of milliseconds past midnight.\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"timeMillisField\", millisInDay);\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(LocalTime.ofNanoOfDay(millisInDay * 1000000L), resultMap.get(\"timeMillisField\"));\n    }\n", "    public void testTimeMicrosLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"timeMicrosField\\\", \\\"type\\\": {\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"time-micros\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        long microsInDay = 12345678910L; // Represents the number of microseconds past midnight.\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"timeMicrosField\", microsInDay);\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(LocalTime.ofNanoOfDay(microsInDay * 1000L), resultMap.get(\"timeMicrosField\"));\n    }\n", "    public void testTimestampMillisLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"timestampMillisField\\\", \\\"type\\\": {\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"timestamp-millis\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        long timestampMillis = 1234567891011L; // Represents a timestamp in milliseconds since the Unix epoch.\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"timestampMillisField\", timestampMillis);\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(Instant.ofEpochMilli(timestampMillis), resultMap.get(\"timestampMillisField\"));\n    }\n", "    public void testTimestampMicrosLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"timestampMicrosField\\\", \\\"type\\\": {\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"timestamp-micros\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        long timestampMicros = 12345678910111213L; // Represents a timestamp in microseconds since the Unix epoch.\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"timestampMicrosField\", timestampMicros);\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        assertEquals(Instant.ofEpochSecond(timestampMicros / 1_000_000, (timestampMicros % 1_000_000) * 1_000), resultMap.get(\"timestampMicrosField\"));\n    }\n", "    public void testLocalTimestampMillisLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"localTimestampMillisField\\\", \\\"type\\\": {\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"local-timestamp-millis\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        long localTimestampMillis = 1234567891011L; // Represents a timestamp in milliseconds since midnight.\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"localTimestampMillisField\", localTimestampMillis);\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        LocalDateTime expectedDateTime = LocalDateTime.ofInstant(Instant.ofEpochMilli(localTimestampMillis), ZoneOffset.UTC);\n        assertEquals(expectedDateTime, resultMap.get(\"localTimestampMillisField\"));\n    }\n", "    public void testLocalTimestampMicrosLogicalType() throws Exception {\n        String schemaJson = \"{\\n\" +\n                \"  \\\"type\\\": \\\"record\\\",\\n\" +\n                \"  \\\"name\\\": \\\"TestRecord\\\",\\n\" +\n                \"  \\\"fields\\\": [\\n\" +\n                \"    {\\\"name\\\": \\\"localTimestampMicrosField\\\", \\\"type\\\": {\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"local-timestamp-micros\\\"}}\\n\" +\n                \"  ]\\n\" +\n                \"}\";\n        Schema schema = new Schema.Parser().parse(schemaJson);\n\n        long localTimestampMicros = 12345678910111213L; // Represents a timestamp in microseconds since midnight.\n        GenericData.Record record = new GenericData.Record(schema);\n        record.put(\"localTimestampMicrosField\", localTimestampMicros);\n\n        ByteBuffer byteBuffer = encodeRecordToByteBuffer(record, schema);\n        Map<String, Object> resultMap = new AvroReader().read(byteBuffer, schema);\n\n        LocalDateTime expectedDateTime = LocalDateTime.ofInstant(Instant.ofEpochSecond(localTimestampMicros / 1_000_000, (localTimestampMicros % 1_000_000) * 1_000), ZoneOffset.UTC);\n        assertEquals(expectedDateTime, resultMap.get(\"localTimestampMicrosField\"));\n    }\n\n    private ByteBuffer encodeRecordToByteBuffer(GenericData.Record record, Schema schema) throws Exception {\n        ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();\n        BinaryEncoder binaryEncoder = EncoderFactory.get().binaryEncoder(byteArrayOutputStream, null);\n        GenericDatumWriter<GenericData.Record> datumWriter = new GenericDatumWriter<>(schema);\n        datumWriter.write(record, binaryEncoder);\n        binaryEncoder.flush();\n        return ByteBuffer.wrap(byteArrayOutputStream.toByteArray());\n    }\n}\n"]}
{"filename": "twister-avro/src/test/java/dev/twister/avro/AvroWrapperTest.java", "chunked_list": ["package dev.twister.avro;\n\nimport junit.framework.TestCase;\nimport org.apache.avro.Conversions;\nimport org.apache.avro.LogicalTypes;\nimport org.apache.avro.Schema;\nimport org.apache.avro.generic.GenericData;\nimport org.apache.avro.generic.GenericRecord;\nimport org.apache.avro.generic.GenericRecordBuilder;\n", "import org.apache.avro.generic.GenericRecordBuilder;\n\nimport java.math.BigDecimal;\nimport java.nio.ByteBuffer;\nimport java.time.*;\nimport java.time.temporal.ChronoUnit;\nimport java.time.temporal.TemporalUnit;\nimport java.util.*;\nimport java.util.concurrent.TimeUnit;\n\npublic class AvroWrapperTest extends TestCase {", "import java.util.concurrent.TimeUnit;\n\npublic class AvroWrapperTest extends TestCase {\n    public void testWrapPrimitives() {\n        Schema schema = Schema.createRecord(\"Test\", \"\", \"\", false);\n        schema.setFields(Arrays.asList(\n                new Schema.Field(\"testString\", Schema.create(Schema.Type.STRING), \"\", null),\n                new Schema.Field(\"testInt\", Schema.create(Schema.Type.INT), \"\", null),\n                new Schema.Field(\"testBoolean\", Schema.create(Schema.Type.BOOLEAN), \"\", null),\n                new Schema.Field(\"testLong\", Schema.create(Schema.Type.LONG), \"\", null),\n                new Schema.Field(\"testFloat\", Schema.create(Schema.Type.FLOAT), \"\", null),\n                new Schema.Field(\"testDouble\", Schema.create(Schema.Type.DOUBLE), \"\", null),\n                new Schema.Field(\"testBytesArray\", Schema.create(Schema.Type.BYTES), \"\", null),\n                new Schema.Field(\"testBytesBuffer\", Schema.create(Schema.Type.BYTES), \"\", null),\n                new Schema.Field(\"testNull\", Schema.create(Schema.Type.NULL), \"\", null)\n        ));\n\n        GenericRecord record = new GenericData.Record(schema);\n        record.put(\"testString\", \"string\");\n        record.put(\"testInt\", 123);\n        record.put(\"testBoolean\", true);\n        record.put(\"testLong\", 123L);\n        record.put(\"testFloat\", 123.45f);\n        record.put(\"testDouble\", 123.45);\n        record.put(\"testBytesArray\", new byte[] {1, 2, 3});\n        record.put(\"testBytesBuffer\", ByteBuffer.wrap(new byte[] {4, 5, 6}));\n        record.put(\"testNull\", null);\n\n        AvroWrapper wrapper = new AvroWrapper();\n\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(\"string\", result.get(\"testString\"));\n        assertEquals(123, result.get(\"testInt\"));\n        assertEquals(true, result.get(\"testBoolean\"));\n        assertEquals(123L, result.get(\"testLong\"));\n        assertEquals(123.45f, result.get(\"testFloat\"));\n        assertEquals(123.45, result.get(\"testDouble\"));\n        assertEquals(ByteBuffer.wrap(new byte[] {1, 2, 3}), result.get(\"testBytesArray\"));\n        assertEquals(ByteBuffer.wrap(new byte[] {4, 5, 6}), result.get(\"testBytesBuffer\"));\n        assertNull(result.get(\"testNull\"));\n    }\n", "    public void testWrapNestedRecord() {\n        Schema nestedSchema = Schema.createRecord(\"Nested\", \"\", \"\", false);\n        nestedSchema.setFields(List.of(new Schema.Field(\"nestedField\", Schema.create(Schema.Type.STRING), \"\", null)));\n        GenericRecord nestedRecord = new GenericData.Record(nestedSchema);\n        nestedRecord.put(\"nestedField\", \"nestedValue\");\n\n        Schema schema = Schema.createRecord(\"Test\", \"\", \"\", false);\n        schema.setFields(List.of(new Schema.Field(\"nested\", nestedSchema, \"\", null)));\n        GenericRecord record = new GenericData.Record(schema);\n        record.put(\"nested\", nestedRecord);\n        AvroWrapper wrapper = new AvroWrapper();\n\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertTrue(result.get(\"nested\") instanceof Map);\n        assertEquals(\"nestedValue\", ((Map) result.get(\"nested\")).get(\"nestedField\"));\n    }\n", "    public void testWrapArray() {\n        Schema arraySchema = Schema.createArray(Schema.create(Schema.Type.STRING));\n        GenericData.Array<String> array = new GenericData.Array<>(arraySchema, Arrays.asList(\"element1\", \"element2\"));\n\n        Schema schema = Schema.createRecord(\"Test\", \"\", \"\", false);\n        schema.setFields(List.of(new Schema.Field(\"array\", arraySchema, \"\", null)));\n        GenericRecord record = new GenericData.Record(schema);\n        record.put(\"array\", array);\n        AvroWrapper wrapper = new AvroWrapper();\n\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertTrue(result.get(\"array\") instanceof List);\n        assertEquals(\"element1\", ((List) result.get(\"array\")).get(0));\n        assertEquals(\"element2\", ((List) result.get(\"array\")).get(1));\n    }\n", "    public void testWrapUnion() {\n        Schema unionSchema = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.STRING), Schema.create(Schema.Type.NULL)));\n        Schema schema = Schema.createRecord(\"Test\", \"\", \"\", false);\n        schema.setFields(List.of(new Schema.Field(\"union\", unionSchema, \"\", null)));\n        GenericRecord record = new GenericData.Record(schema);\n        record.put(\"union\", \"string\");\n        AvroWrapper wrapper = new AvroWrapper();\n\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(\"string\", result.get(\"union\"));\n    }\n", "    public void testWrapUnionWithString() {\n        List<Schema> unionTypes = Arrays.asList(Schema.create(Schema.Type.INT), Schema.create(Schema.Type.STRING));\n        Schema unionSchema = Schema.createUnion(unionTypes);\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testUnion\", unionSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        record.put(\"testUnion\", \"a string\");\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertTrue(result.get(\"testUnion\") instanceof String);\n        assertEquals(\"a string\", result.get(\"testUnion\"));\n    }\n", "    public void testWrapEnum() {\n        Schema enumSchema = Schema.createEnum(\"TestEnum\", \"\", \"\", Arrays.asList(\"A\", \"B\", \"C\"));\n        GenericData.EnumSymbol enumSymbol = new GenericData.EnumSymbol(enumSchema, \"B\");\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testEnum\", enumSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        record.put(\"testEnum\", enumSymbol);\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(\"B\", result.get(\"testEnum\"));\n    }\n", "    public void testWrapFixed() {\n        Schema fixedSchema = Schema.createFixed(\"TestFixed\", \"\", \"\", 4);\n        GenericData.Fixed fixed = new GenericData.Fixed(fixedSchema, new byte[] {1, 2, 3, 4});\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testFixed\", fixedSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        record.put(\"testFixed\", fixed);\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(ByteBuffer.wrap(new byte[] {1, 2, 3, 4}), result.get(\"testFixed\"));\n    }\n", "    public void testWrapMap() {\n        Schema mapSchema = Schema.createMap(Schema.create(Schema.Type.STRING));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testMap\", mapSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        record.put(\"testMap\", new HashMap<String, Object>() {{\n            put(\"key1\", \"value1\");\n            put(\"key2\", \"value2\");\n        }});\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertTrue(result.get(\"testMap\") instanceof Map);\n        Map<String, Object> resultMap = (Map<String, Object>) result.get(\"testMap\");\n        assertEquals(\"value1\", resultMap.get(\"key1\"));\n        assertEquals(\"value2\", resultMap.get(\"key2\"));\n    }\n", "    public void testListOfRecords() {\n        Schema subRecordSchema = Schema.createRecord(\"SubRecord\", \"\", \"test\", false);\n        subRecordSchema.setFields(List.of(new Schema.Field(\"subField\", Schema.create(Schema.Type.INT), \"\", null)));\n\n        Schema arraySchema = Schema.createArray(subRecordSchema);\n        Schema mainRecordSchema = Schema.createRecord(\"MainRecord\", \"\", \"test\", false);\n        mainRecordSchema.setFields(List.of(new Schema.Field(\"mainField\", arraySchema, \"\", null)));\n\n        GenericRecord subRecord1 = new GenericRecordBuilder(subRecordSchema).set(\"subField\", 1).build();\n        GenericRecord subRecord2 = new GenericRecordBuilder(subRecordSchema).set(\"subField\", 2).build();\n        GenericData.Array<GenericRecord> array = new GenericData.Array<>(mainRecordSchema.getField(\"mainField\").schema(), Arrays.asList(subRecord1, subRecord2));\n\n        GenericRecord mainRecord = new GenericRecordBuilder(mainRecordSchema).set(\"mainField\", array).build();\n\n        AvroWrapper avroWrapper = new AvroWrapper();\n        Map<String, Object> wrapped = avroWrapper.wrap(mainRecord);\n\n        assertTrue(wrapped.get(\"mainField\") instanceof List);\n        List<?> list = (List<?>) wrapped.get(\"mainField\");\n\n        assertEquals(2, list.size());\n\n        assertTrue(list.get(0) instanceof Map);\n        Map<String, Object> subRecord1Map = (Map<String, Object>) list.get(0);\n        assertEquals(1, subRecord1Map.get(\"subField\"));\n\n        assertTrue(list.get(1) instanceof Map);\n        Map<String, Object> subRecord2Map = (Map<String, Object>) list.get(1);\n        assertEquals(2, subRecord2Map.get(\"subField\"));\n    }\n", "    public void testWrapLogicalDate() {\n        Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testDate\", dateSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        LocalDate testDate = LocalDate.now();\n        record.put(\"testDate\", (int) testDate.toEpochDay());\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(testDate, result.get(\"testDate\"));\n    }\n", "    public void testWrapLogicalTimestampMillis() {\n        Schema timestampMillisSchema = LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testTimestampMillis\", timestampMillisSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        Instant now = Instant.now();\n        record.put(\"testTimestampMillis\", now.toEpochMilli());\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(now.truncatedTo(ChronoUnit.MILLIS), result.get(\"testTimestampMillis\"));\n    }\n", "    public void testWrapLogicalTimestampMicros() {\n        Schema timestampMicrosSchema = LogicalTypes.timestampMicros().addToSchema(Schema.create(Schema.Type.LONG));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testTimestampMicros\", timestampMicrosSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        Instant now = Instant.now();\n        long epochMicros = TimeUnit.SECONDS.toMicros(now.getEpochSecond()) + now.getNano() / 1000;\n        record.put(\"testTimestampMicros\", epochMicros);\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(now.truncatedTo(ChronoUnit.MICROS), result.get(\"testTimestampMicros\"));\n    }\n", "    public void testWrapLogicalLocalTimestampMillis() {\n        Schema localTimestampMillisSchema = LogicalTypes.localTimestampMillis().addToSchema(Schema.create(Schema.Type.LONG));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testLocalTimestampMillis\", localTimestampMillisSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        LocalDateTime now = LocalDateTime.now();\n        long epochMillis = now.atZone(ZoneOffset.UTC).toInstant().toEpochMilli();\n        record.put(\"testLocalTimestampMillis\", epochMillis);\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(now.truncatedTo(ChronoUnit.MILLIS), result.get(\"testLocalTimestampMillis\"));\n    }\n", "    public void testWrapLogicalLocalTimestampMicros() {\n        Schema localTimestampMicrosSchema = LogicalTypes.localTimestampMicros().addToSchema(Schema.create(Schema.Type.LONG));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testLocalTimestampMicros\", localTimestampMicrosSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        LocalDateTime now = LocalDateTime.now();\n        long epochMicros = TimeUnit.SECONDS.toMicros(now.atZone(ZoneOffset.UTC).toEpochSecond()) + now.getNano() / 1000;\n        record.put(\"testLocalTimestampMicros\", epochMicros);\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(now.truncatedTo(ChronoUnit.MICROS), result.get(\"testLocalTimestampMicros\"));\n    }\n", "    public void testWrapLogicalTimeMillis() {\n        Schema timeMillisSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testTimeMillis\", timeMillisSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        LocalTime now = LocalTime.now();\n        int millisOfDay = (int) (TimeUnit.SECONDS.toMillis(now.toSecondOfDay()) + (now.getNano() / 1_000_000));\n        record.put(\"testTimeMillis\", millisOfDay);\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(now.truncatedTo(ChronoUnit.MILLIS), result.get(\"testTimeMillis\"));\n    }\n", "    public void testWrapLogicalTimeMicros() {\n        Schema timeMicrosSchema = LogicalTypes.timeMicros().addToSchema(Schema.create(Schema.Type.LONG));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testTimeMicros\", timeMicrosSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        LocalTime now = LocalTime.now();\n        long microsOfDay = TimeUnit.SECONDS.toMicros(now.toSecondOfDay()) + now.getNano() / 1000;\n        record.put(\"testTimeMicros\", microsOfDay);\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(now.truncatedTo(ChronoUnit.MICROS), result.get(\"testTimeMicros\"));\n    }\n", "    public void testWrapLogicalDecimal() {\n        LogicalTypes.Decimal decimalLogicalType = LogicalTypes.decimal(9, 2);\n        Schema decimalSchema = decimalLogicalType.addToSchema(Schema.createFixed(\"TestDecimal\", \"\", \"\", 5));\n        Schema recordSchema = Schema.createRecord(\"TestRecord\", \"\", \"\", false);\n        recordSchema.setFields(Collections.singletonList(new Schema.Field(\"testDecimal\", decimalSchema, \"\", null)));\n\n        GenericRecord record = new GenericData.Record(recordSchema);\n        BigDecimal decimalValue = new BigDecimal(\"12345.67\");\n        record.put(\"testDecimal\", new Conversions.DecimalConversion().toFixed(decimalValue, decimalSchema, decimalLogicalType));\n\n        AvroWrapper wrapper = new AvroWrapper();\n        Map<String, Object> result = wrapper.wrap(record);\n\n        assertEquals(decimalValue, result.get(\"testDecimal\"));\n    }\n}\n"]}
{"filename": "twister-avro/src/main/java/dev/twister/avro/AvroWriter.java", "chunked_list": ["package dev.twister.avro;\n\nimport org.apache.avro.LogicalType;\nimport org.apache.avro.Schema;\nimport org.apache.avro.io.BinaryEncoder;\nimport org.apache.avro.io.DatumWriter;\nimport org.apache.avro.io.Encoder;\nimport org.apache.avro.io.EncoderFactory;\n\nimport java.io.ByteArrayOutputStream;", "\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.math.BigDecimal;\nimport java.nio.ByteBuffer;\nimport java.time.Instant;\nimport java.time.LocalDate;\nimport java.time.LocalDateTime;\nimport java.time.LocalTime;\nimport java.time.ZoneOffset;", "import java.time.LocalTime;\nimport java.time.ZoneOffset;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\n\n/**\n * This class provides functionality to write Avro data based on the provided Avro schema and data.\n */\npublic class AvroWriter {\n\n    /**\n     * A map of default logical type writers provided out-of-the-box by AvroWriter. Each entry maps a logical type name\n     * to a LogicalTypeWriter capable of writing data of that logical type.\n     */", " */\npublic class AvroWriter {\n\n    /**\n     * A map of default logical type writers provided out-of-the-box by AvroWriter. Each entry maps a logical type name\n     * to a LogicalTypeWriter capable of writing data of that logical type.\n     */\n    public static final Map<String, LogicalTypeWriter> DEFAULT_LOGICAL_TYPE_WRITERS;\n\n    /**\n     * A map of logical type writers that will be used by this AvroWriter instance. Each entry maps a logical type name\n     * to a LogicalTypeWriter capable of writing data of that logical type.\n     * Can be replaced with a custom map to override the default logical type writers.\n     */\n    private final Map<String, LogicalTypeWriter> logicalTypeWriters;\n\n    /**\n     * Default constructor that uses the default logical type writers.\n     */\n    public AvroWriter() {\n        this(DEFAULT_LOGICAL_TYPE_WRITERS);\n    }\n\n    /**\n     * Constructor that accepts a custom map of logical type writers.\n     *\n     * @param logicalTypeWriters A map of logical type writers. Each entry maps a logical type name\n     *                           to a LogicalTypeWriter capable of writing data of that logical type.\n     */\n    public AvroWriter(Map<String, LogicalTypeWriter> logicalTypeWriters) {\n        this.logicalTypeWriters = logicalTypeWriters;\n    }\n\n    /**\n     * This class provides functionality to write Avro data based on a provided Avro schema and map data.\n     */", "    public class MapDatumWriter implements DatumWriter<Map<String, Object>> {\n        private Schema schema;\n\n        public MapDatumWriter(Schema schema) {\n            this.schema = schema;\n        }\n\n        @Override\n        public void setSchema(Schema schema) {\n            this.schema = schema;\n        }\n\n        /**\n         * Writes an object to the encoder output based on the provided Avro schema.\n         *\n         * @param value The object to be written.\n         * @param schema The Avro schema to use for writing.\n         * @param out The encoder output to write to.\n         * @throws IOException If an error occurs during writing.\n         */\n        private void writeObject(Object value, Schema schema, Encoder out) throws IOException {\n            LogicalType logicalType = schema.getLogicalType();", "        public void setSchema(Schema schema) {\n            this.schema = schema;\n        }\n\n        /**\n         * Writes an object to the encoder output based on the provided Avro schema.\n         *\n         * @param value The object to be written.\n         * @param schema The Avro schema to use for writing.\n         * @param out The encoder output to write to.\n         * @throws IOException If an error occurs during writing.\n         */\n        private void writeObject(Object value, Schema schema, Encoder out) throws IOException {\n            LogicalType logicalType = schema.getLogicalType();", "            if (logicalType != null) {\n                LogicalTypeWriter logicalTypeWriter = logicalTypeWriters.get(logicalType.getName());\n                if (logicalTypeWriter != null) {\n                    logicalTypeWriter.write(value, schema, out);\n                    return;\n                }\n            }\n\n            switch (schema.getType()) {\n                case BOOLEAN:\n                    out.writeBoolean((Boolean) value);\n                    break;\n                case INT:\n                    out.writeInt((Integer) value);\n                    break;\n                case LONG:\n                    out.writeLong((Long) value);\n                    break;\n                case FLOAT:\n                    out.writeFloat((Float) value);\n                    break;\n                case DOUBLE:\n                    out.writeDouble((Double) value);\n                    break;\n                case STRING:\n                    out.writeString((String) value);\n                    break;\n                case BYTES:\n                    out.writeBytes((ByteBuffer) value);\n                    break;\n                case RECORD:\n                    Map<String, Object> recordValue = (Map<String, Object>) value;\n                    MapDatumWriter recordWriter = new MapDatumWriter(schema);\n                    recordWriter.write(recordValue, out);\n                    break;\n                case ENUM:\n                    String enumValue = (String) value;\n                    int index = schema.getEnumSymbols().indexOf(enumValue);", "                    if (index < 0) {\n                        throw new IOException(\"Invalid enum value: \" + enumValue + \" for schema: \" + schema);\n                    }\n                    out.writeEnum(index);\n                    break;\n                case ARRAY:\n                    List<Object> arrayValue = (List<Object>) value;\n                    out.writeArrayStart();\n                    out.setItemCount(arrayValue.size());\n                    Schema arraySchema = schema.getElementType();\n                    for (Object item : arrayValue) {\n                        out.startItem();\n                        writeObject(item, arraySchema, out);\n                    }\n                    out.writeArrayEnd();\n                    break;\n                case MAP:\n                    Map<String, Object> mapValue = (Map<String, Object>) value;\n                    out.writeMapStart();\n                    out.setItemCount(mapValue.size());\n                    Schema mapValueSchema = schema.getValueType();", "                    for (Object item : arrayValue) {\n                        out.startItem();\n                        writeObject(item, arraySchema, out);\n                    }\n                    out.writeArrayEnd();\n                    break;\n                case MAP:\n                    Map<String, Object> mapValue = (Map<String, Object>) value;\n                    out.writeMapStart();\n                    out.setItemCount(mapValue.size());\n                    Schema mapValueSchema = schema.getValueType();", "                    for (Map.Entry<String, Object> entry : mapValue.entrySet()) {\n                        out.startItem();\n                        out.writeString(entry.getKey());\n                        writeObject(entry.getValue(), mapValueSchema, out);\n                    }\n                    out.writeMapEnd();\n                    break;\n                case UNION:\n                    List<Schema> unionSchemas = schema.getTypes();\n                    int matchingSchemaIndex = getMatchingSchemaIndex(value, unionSchemas);\n                    out.writeIndex(matchingSchemaIndex);\n                    writeObject(value, unionSchemas.get(matchingSchemaIndex), out);\n                    break;\n                case FIXED:\n                    ByteBuffer fixedValueBuffer = (ByteBuffer) value;", "                    if (fixedValueBuffer.remaining() != schema.getFixedSize()) {\n                        throw new IOException(\"Invalid fixed value size: \" + fixedValueBuffer.remaining()\n                                + \" for schema: \" + schema);\n                    }\n                    out.writeFixed(fixedValueBuffer);\n                    break;\n                default:\n                    throw new UnsupportedOperationException(\"Unsupported type: \" + schema.getType());\n            }\n        }\n\n        @Override", "        public void write(Map<String, Object> datum, Encoder out) throws IOException {\n            for (Schema.Field field : schema.getFields()) {\n                Object value = datum.get(field.name());\n                if (value == null) {\n                    out.writeNull();\n                } else {\n                    writeObject(value, field.schema(), out);\n                }\n            }\n        }\n\n        /**\n         * Returns the expected Java class for the provided Avro schema.\n         *\n         * @param schema The Avro schema to get the expected class for.\n         * @return The expected Java class for the provided Avro schema.\n         * @throws UnsupportedOperationException If the schema type is unsupported.\n         */\n        private Class<?> getExpectedClass(Schema schema) {\n            LogicalType logicalType = schema.getLogicalType();", "            if (logicalType != null) {\n                LogicalTypeWriter logicalTypeWriter = logicalTypeWriters.get(logicalType.getName());\n                if (logicalTypeWriter != null) {\n                    return logicalTypeWriter.getExpectedClass();\n                }\n            }\n\n            switch (schema.getType()) {\n                case BOOLEAN: return Boolean.class;\n                case INT:     return Integer.class;\n                case LONG:    return Long.class;\n                case FLOAT:   return Float.class;\n                case DOUBLE:  return Double.class;\n                case ENUM:\n                case STRING:  return String.class;\n                case FIXED:\n                case BYTES:   return ByteBuffer.class;\n                case ARRAY:   return List.class;\n                case RECORD:\n                case MAP:     return Map.class;\n                case NULL:    return null;\n                default:      throw new UnsupportedOperationException(\"Unsupported type: \" + schema.getType());\n            }\n        }\n\n        /**\n         * Returns the index of the matching schema in the list of union schemas.\n         *\n         * @param value The value to match the schema with.\n         * @param unionSchemas The list of union schemas.\n         * @return The index of the matching schema in the list of union schemas.\n         * @throws IOException If no matching schema is found.\n         */\n        private int getMatchingSchemaIndex(Object value, List<Schema> unionSchemas) throws IOException {", "            for (int i = 0; i < unionSchemas.size(); i++) {\n                Schema unionSchema = unionSchemas.get(i);\n                Class<?> expectedClass = getExpectedClass(unionSchema);\n                if (value == null && expectedClass == null) {\n                    return i;\n                }\n                if (value != null && expectedClass != null && expectedClass.isInstance(value)) {\n                    return i;\n                }\n            }\n            throw new IOException(\"Invalid union value: \" + value + \" for schema: \" + unionSchemas);\n        }\n    }\n\n    /**\n     * Writes the given object to a ByteBuffer based on the inferred Avro schema.\n     *\n     * @param object The object to be written.\n     * @param recordName The name of the Avro record.\n     * @return A ByteBuffer containing the written Avro data.\n     * @throws IOException If an error occurs during writing.\n     */", "    public ByteBuffer write(Map<String, Object> object, String recordName) throws IOException {\n        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n        BinaryEncoder encoder = EncoderFactory.get().binaryEncoder(outputStream, null);\n        MapDatumWriter writer = new MapDatumWriter(new AvroSchemaInferrer().infer(object, recordName));\n        writer.write(object, encoder);\n        encoder.flush();\n        return ByteBuffer.wrap(outputStream.toByteArray());\n    }\n\n    /**\n     * Writes the given object to a ByteBuffer based on the provided Avro schema.\n     *\n     * @param object The object to be written.\n     * @param schema The Avro schema to use for writing.\n     * @return A ByteBuffer containing the written Avro data.\n     * @throws IOException If an error occurs during writing.\n     */", "    public ByteBuffer write(Map<String, Object> object, Schema schema) throws IOException {\n        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n        BinaryEncoder encoder = EncoderFactory.get().binaryEncoder(outputStream, null);\n        MapDatumWriter writer = new MapDatumWriter(schema);\n        writer.write(object, encoder);\n        encoder.flush();\n        return ByteBuffer.wrap(outputStream.toByteArray());\n    }\n\n    /**\n     * This interface provides a contract for classes that write logical types based on a provided Avro schema and data.\n     */", "    public interface LogicalTypeWriter {\n        /**\n         * Writes a logical type value to the output Encoder.\n         *\n         * @param value  The value to write, expected to be of the class returned by getExpectedClass().\n         * @param schema The Avro Schema for the data being written.\n         * @param out    The Encoder to write to.\n         * @throws IOException If there's an error writing the data.\n         */\n        void write(Object value, Schema schema, Encoder out) throws IOException;\n\n        /**\n         * Returns the Java class that this LogicalTypeWriter expects to write.\n         *\n         * @return The Java class that this LogicalTypeWriter expects to write.\n         */\n        Class<?> getExpectedClass();\n    }\n\n    static {\n        DEFAULT_LOGICAL_TYPE_WRITERS = Map.of(\n                \"decimal\", new DecimalWriter(),\n                \"uuid\", new UuidWriter(),\n                \"date\", new DateWriter(),\n                \"time-millis\", new TimeMillisWriter(),\n                \"time-micros\", new TimeMicrosWriter(),\n                \"timestamp-millis\", new TimestampMillisWriter(),\n                \"timestamp-micros\", new TimestampMicrosWriter(),\n                \"local-timestamp-millis\", new LocalTimestampMillisWriter(),\n                \"local-timestamp-micros\", new LocalTimestampMicrosWriter()\n        );\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"decimal\" Avro logical type data.\n     * The expected Java class is java.math.BigDecimal.\n     */", "    public static class DecimalWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            out.writeBytes(((BigDecimal) value).unscaledValue().toByteArray());\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return BigDecimal.class;\n        }\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"uuid\" Avro logical type data.\n     * The expected Java class is java.util.UUID.\n     */", "    public static class UuidWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            out.writeString(value.toString());\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return UUID.class;\n        }\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"date\" Avro logical type data.\n     * The expected Java class is java.time.LocalDate.\n     */", "    public static class DateWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            out.writeInt((int) ((LocalDate) value).toEpochDay());\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return LocalDate.class;\n        }\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"time-millis\" Avro logical type data.\n     * The expected Java class is java.time.LocalTime.\n     */", "    public static class TimeMillisWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            out.writeInt((int) (((LocalTime) value).toNanoOfDay() / 1_000_000));\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return LocalTime.class;\n        }\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"time-micros\" Avro logical type data.\n     * The expected Java class is java.time.LocalTime.\n     */", "    public static class TimeMicrosWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            out.writeLong(((LocalTime) value).toNanoOfDay() / 1_000);\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return LocalTime.class;\n        }\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"timestamp-millis\" Avro logical type data.\n     * The expected Java class is java.time.Instant.\n     */", "    public static class TimestampMillisWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            out.writeLong(((Instant) value).toEpochMilli());\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return Instant.class;\n        }\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"timestamp-micros\" Avro logical type data.\n     * The expected Java class is java.time.Instant.\n     */", "    public static class TimestampMicrosWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            out.writeLong(((Instant) value).getEpochSecond() * 1_000_000 + ((Instant) value).getNano() / 1_000);\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return Instant.class;\n        }\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"local-timestamp-millis\" Avro logical type data.\n     * The expected Java class is java.time.LocalDateTime.\n     */", "    public static class LocalTimestampMillisWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            out.writeLong(((LocalDateTime) value).toInstant(ZoneOffset.UTC).toEpochMilli());\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return LocalDateTime.class;\n        }\n    }\n\n    /**\n     * A LogicalTypeWriter implementation for writing \"local-timestamp-micros\" Avro logical type data.\n     * The expected Java class is java.time.LocalDateTime.\n     */", "    public static class LocalTimestampMicrosWriter implements AvroWriter.LogicalTypeWriter {\n        @Override\n        public void write(Object value, Schema schema, Encoder out) throws IOException {\n            LocalDateTime dateTime = (LocalDateTime) value;\n            long micros = dateTime.toEpochSecond(ZoneOffset.UTC) * 1_000_000 + dateTime.getNano() / 1_000;\n            out.writeLong(micros);\n        }\n\n        @Override\n        public Class<?> getExpectedClass() {\n            return LocalDateTime.class;\n        }\n    }\n}\n"]}
{"filename": "twister-avro/src/main/java/dev/twister/avro/AvroSchemaInferrer.java", "chunked_list": ["package dev.twister.avro;\n\nimport org.apache.avro.LogicalTypes;\nimport org.apache.avro.Schema;\nimport org.apache.avro.SchemaBuilder;\n\nimport java.math.BigDecimal;\nimport java.nio.ByteBuffer;\nimport java.time.Instant;\nimport java.time.LocalDate;", "import java.time.Instant;\nimport java.time.LocalDate;\nimport java.time.LocalDateTime;\nimport java.time.LocalTime;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.TreeMap;\nimport java.util.UUID;", "import java.util.TreeMap;\nimport java.util.UUID;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * A utility class to infer Avro schema from Java objects.\n */\npublic class AvroSchemaInferrer {\n\n    /**\n     * A map storing LogicalTypeInferrer instances associated with specific classes. Each LogicalTypeInferrer\n     * is responsible for inferring the Avro logical type for instances of its associated class.\n     * <p>\n     * The keys of the map are Class objects representing the classes that the inferrers can handle. The values\n     * are instances of LogicalTypeInferrer, each capable of inferring the Avro logical type for instances of its\n     * associated class.\n     * <p>\n     * For example, if there is a key-value pair (java.time.Instant.class, timestampInferrer), this means the\n     * timestampInferrer is used to infer the Avro logical type for instances of java.time.Instant.\n     */\n    private final Map<Class<?>, LogicalTypeInferrer<?>> inferrers;\n\n    /**\n     * Flag indicating whether maps should be treated as records during Avro schema inference.\n     * Default value is {@code true}.\n     */\n    private final boolean mapAsRecord;\n\n    /**\n     * Creates an AvroSchemaInferrer with the default behavior of treating maps as records.\n     */\n    public AvroSchemaInferrer() {\n        this(mapOfDefaultInferrers(TimeUnit.MILLISECONDS), true);\n    }\n\n    /**\n     * Constructs a new instance of the AvroSchemaInferrer.\n     *\n     * @param inferrers A map containing the inferrers for logical types.\n     *                  The map keys are the classes of the objects the inferrer can process,\n     *                  and the values are the corresponding inferrer instances.\n     * @param mapAsRecord A flag to indicate whether maps should be treated as Avro records.\n     *                    If set to true, maps are converted to Avro records; otherwise,\n     *                    they're converted to Avro maps.\n     * @throws IllegalArgumentException if timePrecision is not either TimeUnit.MILLISECONDS\n     *                                  or TimeUnit.MICROSECONDS.\n     */\n    public AvroSchemaInferrer(\n            Map<Class<?>, LogicalTypeInferrer<?>> inferrers,\n            boolean mapAsRecord) {\n        this.inferrers = inferrers;\n        this.mapAsRecord = mapAsRecord;\n    }\n\n    /**\n     * Infers an Avro schema from a given Java Map and a record name.\n     *\n     * @param object The Java Map to infer the schema from.\n     * @param recordName The name of the record.\n     * @return The inferred Avro schema.\n     */", "    public Schema infer(Map<String, Object> object, String recordName) {\n        return getSchemaBasedOnObjectType(object, recordName, null);\n    }\n\n    /**\n     * Infers an Avro schema based on the type of the given object.\n     *\n     * @param value The object to infer the schema from.\n     * @param fieldName The name of the field for the object.\n     * @param parentName The name of the parent field, or null if there's no parent.\n     * @return The inferred Avro schema.\n     * @throws IllegalArgumentException If the object's type is unsupported or if the object is an empty array.\n     */\n    private Schema getSchemaBasedOnObjectType(Object value, String fieldName, String parentName) {\n        Schema schema;\n        String finalRecordName = (parentName != null) ? parentName + \"_\" + fieldName : fieldName;\n\n        LogicalTypeInferrer inferrer = value != null ? inferrers.get(value.getClass()) : null;", "        if (inferrer != null) {\n            schema = inferrer.infer(value);\n        } else if (value == null) {\n            schema = SchemaBuilder.builder().nullType();\n        } else if (value instanceof Integer) {\n            schema = SchemaBuilder.builder().intType();\n        } else if (value instanceof Long) {\n            schema = SchemaBuilder.builder().longType();\n        } else if (value instanceof Float) {\n            schema = SchemaBuilder.builder().floatType();\n        } else if (value instanceof Double) {\n            schema = SchemaBuilder.builder().doubleType();", "        } else if (value instanceof Float) {\n            schema = SchemaBuilder.builder().floatType();\n        } else if (value instanceof Double) {\n            schema = SchemaBuilder.builder().doubleType();\n        } else if (value instanceof Boolean) {\n            schema = SchemaBuilder.builder().booleanType();\n        } else if (value instanceof String) {\n            schema = SchemaBuilder.builder().stringType();\n        } else if (value instanceof Byte || value instanceof byte[] || value instanceof ByteBuffer) {\n            // Byte, byte array, byte buffer\n            schema = SchemaBuilder.builder().bytesType();", "        } else if (value instanceof Byte || value instanceof byte[] || value instanceof ByteBuffer) {\n            // Byte, byte array, byte buffer\n            schema = SchemaBuilder.builder().bytesType();\n        } else if (value instanceof Map) {\n            // Recursive call for nested map\n            Map<String, Object> sortedMap = new TreeMap<>((Map<String, Object>) value);\n\n            if (mapAsRecord) {\n                schema = handleMapAsRecord(sortedMap, finalRecordName);\n            } else {\n                schema = handleMapAsMap(sortedMap, finalRecordName);\n            }", "        } else if (value instanceof List) {\n            // Array type\n            List<?> list = (List<?>) value;\n            if (!list.isEmpty()) {\n                Object firstItem = list.get(0);\n                Schema elementType = getSchemaBasedOnObjectType(firstItem, fieldName, finalRecordName);\n                schema = SchemaBuilder.array().items(nullableSchema(elementType));\n            } else {\n                throw new IllegalArgumentException(\"Cannot infer schema for an empty array\");\n            }\n        } else {\n            throw new IllegalArgumentException(\"Unsupported type: \" + value.getClass().getName());\n        }\n\n        return schema;\n    }\n\n    /**\n     * Handles the inference of an Avro schema for a map treated as a record.\n     *\n     * @param sortedMap The sorted map to infer the schema from.\n     * @param finalRecordName The final name of the record.\n     * @return The inferred Avro schema.\n     */\n    private Schema handleMapAsRecord(Map<String, Object> sortedMap, String finalRecordName) {\n        SchemaBuilder.FieldAssembler<Schema> fields = SchemaBuilder.record(finalRecordName).fields();\n", "        for (Map.Entry<String, Object> entry : sortedMap.entrySet()) {\n            Schema fieldSchema = getSchemaBasedOnObjectType(entry.getValue(), entry.getKey(), finalRecordName);\n            fields.name(entry.getKey()).type(nullableSchema(fieldSchema)).noDefault();\n        }\n\n        return fields.endRecord();\n    }\n\n    /**\n     * Handles the inference of an Avro schema for a map treated as a map.\n     *\n     * @param sortedMap The sorted map to infer the schema from.\n     * @param finalRecordName The final name of the record.\n     * @return The inferred Avro schema.\n     */\n    private Schema handleMapAsMap(Map<String, Object> sortedMap, String finalRecordName) {\n        Set<Schema> fieldSchemas = new HashSet<>();\n        Set<String> schemaTypes = new HashSet<>();\n", "        for (Map.Entry<String, Object> entry : sortedMap.entrySet()) {\n            Schema fieldSchema = getSchemaBasedOnObjectType(entry.getValue(), entry.getKey(), finalRecordName);\n\n            // Only add the schema if its type hasn't been added before\n            if (schemaTypes.add(fieldSchema.getType().getName())) {\n                fieldSchemas.add(fieldSchema);\n            }\n        }\n\n        SchemaBuilder.UnionAccumulator<Schema> union = SchemaBuilder.unionOf().nullType();\n        for (Schema schema : fieldSchemas) {\n            union = union.and().type(schema);\n        }\n\n        return SchemaBuilder.map().values(union.endUnion());\n    }\n\n    /**\n     * Returns a nullable version of the given schema.\n     *\n     * @param schema The schema to make nullable.\n     * @return The nullable schema.\n     */\n    private Schema nullableSchema(Schema schema) {", "        for (Schema schema : fieldSchemas) {\n            union = union.and().type(schema);\n        }\n\n        return SchemaBuilder.map().values(union.endUnion());\n    }\n\n    /**\n     * Returns a nullable version of the given schema.\n     *\n     * @param schema The schema to make nullable.\n     * @return The nullable schema.\n     */\n    private Schema nullableSchema(Schema schema) {", "        if (schema.getType() != Schema.Type.NULL) {\n            return SchemaBuilder.unionOf().nullType().and().type(schema).endUnion();\n        } else {\n            return schema;\n        }\n    }\n\n    public static Map<Class<?>, LogicalTypeInferrer<?>> mapOfDefaultInferrers(TimeUnit timePrecision) {\n        return Map.of(\n                BigDecimal.class, (LogicalTypeInferrer<BigDecimal>) value ->\n                        LogicalTypes.decimal(value.precision(), value.scale())\n                                .addToSchema(Schema.create(Schema.Type.BYTES)),\n                UUID.class, (LogicalTypeInferrer<UUID>) value ->\n                        LogicalTypes.uuid().addToSchema(Schema.create(Schema.Type.STRING)),\n                LocalDate.class, (LogicalTypeInferrer<LocalDate>) value ->\n                        LogicalTypes.date().addToSchema(Schema.create(Schema.Type.INT)),\n                LocalTime.class, (LogicalTypeInferrer<LocalTime>) value -> {\n                    return (timePrecision == TimeUnit.MILLISECONDS)\n                            ? LogicalTypes.timeMillis().addToSchema(Schema.create(Schema.Type.INT))\n                            : LogicalTypes.timeMicros().addToSchema(Schema.create(Schema.Type.LONG));\n                },\n                Instant.class, (LogicalTypeInferrer<Instant>) value -> {\n                    return (timePrecision == TimeUnit.MILLISECONDS)\n                            ? LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG))\n                            : LogicalTypes.timestampMicros().addToSchema(Schema.create(Schema.Type.LONG));\n                },\n                LocalDateTime.class, (LogicalTypeInferrer<LocalDateTime>) value -> {\n                    return (timePrecision == TimeUnit.MILLISECONDS)\n                            ? LogicalTypes.timestampMillis().addToSchema(Schema.create(Schema.Type.LONG))\n                            : LogicalTypes.timestampMicros().addToSchema(Schema.create(Schema.Type.LONG));\n                }\n        );\n    }\n\n    /**\n     * The LogicalTypeInferrer interface defines a method for inferring an Avro schema from a given object.\n     * <p>\n     * Implementations of this interface should provide the logic to generate an Avro schema that correctly\n     * describes the structure and data types of the object, including any nested objects.\n     * <p>\n     * The infer method is expected to return a Schema object that accurately reflects the object's structure.\n     *\n     * @param <T> The type of objects this inferrer can process.\n     */", "    public interface LogicalTypeInferrer<T> {\n\n        /**\n         * Infers an Avro schema from the provided object.\n         *\n         * @param object The object to infer the schema from.\n         * @return The inferred Avro schema.\n         */\n        Schema infer(T object);\n    }\n}\n"]}
{"filename": "twister-avro/src/main/java/dev/twister/avro/AvroReader.java", "chunked_list": ["package dev.twister.avro;\n\nimport org.apache.avro.LogicalType;\nimport org.apache.avro.LogicalTypes;\nimport org.apache.avro.Schema;\nimport org.apache.avro.io.BinaryDecoder;\nimport org.apache.avro.io.DecoderFactory;\n\nimport java.io.IOException;\nimport java.math.BigDecimal;", "import java.io.IOException;\nimport java.math.BigDecimal;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.time.Instant;\nimport java.time.LocalDate;\nimport java.time.LocalDateTime;\nimport java.time.LocalTime;\nimport java.time.ZoneOffset;\nimport java.util.ArrayList;", "import java.time.ZoneOffset;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\n\n/**\n * A utility class to read Avro-encoded data into Java Map objects.\n */\npublic class AvroReader {\n\n    /**\n     * A {@link Map} of default {@link LogicalTypeReader}s used to interpret Avro logical types.\n     * <p>\n     * The map's keys are the names of Avro logical types, and the values are the {@link LogicalTypeReader}s\n     * that are used to read and interpret these types. By default, this includes readers for the following Avro logical\n     * types:\n     * <ul>\n     *   <li>decimal</li>\n     *   <li>uuid</li>\n     *   <li>date</li>\n     *   <li>time-millis</li>\n     *   <li>time-micros</li>\n     *   <li>timestamp-millis</li>\n     *   <li>timestamp-micros</li>\n     * </ul>\n     */", " * A utility class to read Avro-encoded data into Java Map objects.\n */\npublic class AvroReader {\n\n    /**\n     * A {@link Map} of default {@link LogicalTypeReader}s used to interpret Avro logical types.\n     * <p>\n     * The map's keys are the names of Avro logical types, and the values are the {@link LogicalTypeReader}s\n     * that are used to read and interpret these types. By default, this includes readers for the following Avro logical\n     * types:\n     * <ul>\n     *   <li>decimal</li>\n     *   <li>uuid</li>\n     *   <li>date</li>\n     *   <li>time-millis</li>\n     *   <li>time-micros</li>\n     *   <li>timestamp-millis</li>\n     *   <li>timestamp-micros</li>\n     * </ul>\n     */", "    public static final Map<String, LogicalTypeReader> DEFAULT_LOGICAL_TYPE_READERS;\n\n    /**\n     * A {@link Map} of {@link LogicalTypeReader}s used to interpret Avro logical types.\n     *\n     * The map's keys are the names of Avro logical types, and the values are the {@link LogicalTypeReader}s\n     * that are used to read and interpret these types. This map is initialized with either the default logical type\n     * readers or a custom set provided via the constructor.\n     */\n    private final Map<String, LogicalTypeReader> logicalTypeReaders;\n\n    /**\n     * Constructs a new {@link AvroReader} with the default logical type readers.\n     * <p>\n     * The default logical type readers are capable of handling the following Avro logical types:\n     * <ul>\n     *   <li>decimal</li>\n     *   <li>uuid</li>\n     *   <li>date</li>\n     *   <li>time-millis</li>\n     *   <li>time-micros</li>\n     *   <li>timestamp-millis</li>\n     *   <li>timestamp-micros</li>\n     * </ul>\n     */\n    public AvroReader() {\n        this(DEFAULT_LOGICAL_TYPE_READERS);\n    }\n\n    /**\n     * Constructs a new {@link AvroReader} with the provided logical type readers.\n     *\n     * @param logicalTypeReaders a {@link Map} of {@link String} keys and {@link LogicalTypeReader} values, where each\n     * key is the name of an Avro logical type and each value is a {@link LogicalTypeReader} capable of reading that\n     * type.\n     */\n    public AvroReader(Map<String, LogicalTypeReader> logicalTypeReaders) {\n        this.logicalTypeReaders = logicalTypeReaders;\n    }\n\n    /**\n     * Reads Avro-encoded data from a ByteBuffer using a provided schema.\n     *\n     * @param inputBuffer The ByteBuffer containing the Avro-encoded data.\n     * @param schema The Avro schema that describes the data structure.\n     * @return A Map representing the Avro data.\n     * @throws IOException If there is a problem reading from the ByteBuffer.\n     */\n    public Map<String, Object> read(ByteBuffer inputBuffer, Schema schema) throws IOException {\n        BinaryDecoder decoder = DecoderFactory.get().binaryDecoder(inputBuffer.array(), null);\n        return (Map<String, Object>) readBasedOnSchema(decoder, schema);\n    }\n\n    /**\n     * Reads Avro-encoded data from a BinaryDecoder based on a provided schema.\n     *\n     * @param decoder The BinaryDecoder to read data from.\n     * @param schema The Avro schema that describes the data structure.\n     * @return An Object representing the Avro data.\n     * @throws IOException If there is a problem reading from the BinaryDecoder.\n     */\n    private Object readBasedOnSchema(BinaryDecoder decoder, Schema schema) throws IOException {\n        LogicalType logicalType = schema.getLogicalType();", "        if (logicalType != null) {\n            LogicalTypeReader reader = logicalTypeReaders.get(logicalType.getName());\n            if (reader != null) {\n                return reader.read(decoder, schema);\n            }\n        }\n\n        switch (schema.getType()) {\n            case RECORD:\n                Map<String, Object> resultMap = new HashMap<>();\n                for (Schema.Field field : schema.getFields()) {\n                    resultMap.put(field.name(), readBasedOnSchema(decoder, field.schema()));\n                }\n                return resultMap;\n            case ENUM:\n                return schema.getEnumSymbols().get(decoder.readEnum());\n            case UNION:\n                int unionIndex = decoder.readIndex();\n                return readBasedOnSchema(decoder, schema.getTypes().get(unionIndex));\n            case FIXED:\n                byte[] fixedBytes = new byte[schema.getFixedSize()];\n                decoder.readFixed(fixedBytes);\n                return ByteBuffer.wrap(fixedBytes);\n            case ARRAY:\n                Schema elementSchema = schema.getElementType();\n                long arraySize = decoder.readArrayStart();\n                List<Object> array = new ArrayList<>();", "                for (Schema.Field field : schema.getFields()) {\n                    resultMap.put(field.name(), readBasedOnSchema(decoder, field.schema()));\n                }\n                return resultMap;\n            case ENUM:\n                return schema.getEnumSymbols().get(decoder.readEnum());\n            case UNION:\n                int unionIndex = decoder.readIndex();\n                return readBasedOnSchema(decoder, schema.getTypes().get(unionIndex));\n            case FIXED:\n                byte[] fixedBytes = new byte[schema.getFixedSize()];\n                decoder.readFixed(fixedBytes);\n                return ByteBuffer.wrap(fixedBytes);\n            case ARRAY:\n                Schema elementSchema = schema.getElementType();\n                long arraySize = decoder.readArrayStart();\n                List<Object> array = new ArrayList<>();", "                while (arraySize > 0) {\n                    for (long i = 0; i < arraySize; i++) {\n                        array.add(readBasedOnSchema(decoder, elementSchema));\n                    }\n                    arraySize = decoder.arrayNext();\n                }\n                return array;\n            case MAP:\n                Schema valueSchema = schema.getValueType();\n                long mapSize = decoder.readMapStart();\n                Map<String, Object> map = new HashMap<>();", "                while (mapSize > 0) {\n                    for (long i = 0; i < mapSize; i++) {\n                        String key = decoder.readString();\n                        map.put(key, readBasedOnSchema(decoder, valueSchema));\n                    }\n                    mapSize = decoder.mapNext();\n                }\n                return map;\n            default:\n                return readPrimitive(decoder, schema.getType());\n        }\n    }\n\n    /**\n     * Reads a primitive value from a BinaryDecoder based on a provided schema type.\n     *\n     * @param decoder The BinaryDecoder to read data from.\n     * @param type The Avro schema type of the primitive value.\n     * @return An Object representing the Avro primitive value.\n     * @throws IOException If there is a problem reading from the BinaryDecoder.\n     * @throws IllegalArgumentException If the schema type is unsupported.\n     */\n    private Object readPrimitive(BinaryDecoder decoder, Schema.Type type) throws IOException {\n        switch (type) {\n            case BOOLEAN:\n                return decoder.readBoolean();\n            case INT:\n                return decoder.readInt();\n            case LONG:\n                return decoder.readLong();\n            case FLOAT:\n                return decoder.readFloat();\n            case DOUBLE:\n                return decoder.readDouble();\n            case STRING:\n                return decoder.readString();\n            case BYTES:\n                return decoder.readBytes(null);\n            case NULL:\n                return null;\n            default:\n                throw new IllegalArgumentException(\"Unsupported Avro type: \" + type);\n        }\n    }\n\n    /**\n     * The {@link LogicalTypeReader} interface defines a contract for reading Avro logical types.\n     * <p>\n     * A logical type in Avro is a way of specifying a predefined type, which informs how the data should be\n     * interpreted.\n     * <p>\n     * For example, the 'date' logical type represents the number of days since the Unix epoch, and can be interpreted\n     * as a date.\n     * <p>\n     * A {@link LogicalTypeReader} is capable of reading a logical type from an Avro {@link BinaryDecoder} based on the\n     * logical type's {@link Schema}.\n     */", "    public interface LogicalTypeReader {\n\n        /**\n         * Reads an Avro logical type from a {@link BinaryDecoder} based on the logical type's {@link Schema}.\n         *\n         * @param decoder the {@link BinaryDecoder} to read the data from\n         * @param schema the {@link Schema} of the logical type to read\n         * @return an {@link Object} representing the data of the logical type\n         * @throws IOException if an error occurs while reading the data\n         */\n        Object read(BinaryDecoder decoder, Schema schema) throws IOException;\n    }\n\n    static {\n        DEFAULT_LOGICAL_TYPE_READERS = Map.of(\"decimal\", (decoder, schema) -> {\n            BigInteger unscaledValue = new BigInteger(decoder.readBytes(null).array());\n            return new BigDecimal(unscaledValue, ((LogicalTypes.Decimal) schema.getLogicalType()).getScale());\n        }, \"uuid\", (decoder, schema) -> {\n            return UUID.fromString(decoder.readString().toString());\n        }, \"date\", (decoder, schema) -> {\n            int daysSinceEpoch = decoder.readInt();\n            return LocalDate.ofEpochDay(daysSinceEpoch);\n        }, \"time-millis\", (decoder, schema) -> {\n            int millisOfDay = decoder.readInt();\n            return LocalTime.ofNanoOfDay(millisOfDay * 1_000_000L);\n        }, \"time-micros\", (decoder, schema) -> {\n            long microsOfDay = decoder.readLong();\n            return LocalTime.ofNanoOfDay(microsOfDay * 1_000L);\n        }, \"timestamp-millis\", (decoder, schema) -> {\n            long millisSinceEpoch = decoder.readLong();\n            return Instant.ofEpochMilli(millisSinceEpoch);\n        }, \"timestamp-micros\", (decoder, schema) -> {\n            long microsSinceEpoch = decoder.readLong();\n            return Instant.ofEpochSecond(microsSinceEpoch / 1_000_000, (microsSinceEpoch % 1_000_000) * 1_000);\n        }, \"local-timestamp-millis\", (decoder, schema) -> {\n            long millisSinceEpoch = decoder.readLong();\n            return LocalDateTime.ofInstant(Instant.ofEpochMilli(millisSinceEpoch), ZoneOffset.UTC);\n        }, \"local-timestamp-micros\", (decoder, schema) -> {\n            long microsSinceEpoch = decoder.readLong();\n            return LocalDateTime.ofInstant(Instant.ofEpochSecond(microsSinceEpoch / 1_000_000,\n                    (microsSinceEpoch % 1_000_000) * 1_000), ZoneOffset.UTC);\n        });\n    }\n}\n"]}
{"filename": "twister-avro/src/main/java/dev/twister/avro/AvroWrapper.java", "chunked_list": ["package dev.twister.avro;\n\nimport org.apache.avro.LogicalTypes;\nimport org.apache.avro.Schema;\nimport org.apache.avro.generic.GenericData;\nimport org.apache.avro.generic.GenericFixed;\nimport org.apache.avro.generic.IndexedRecord;\n\nimport java.math.BigDecimal;\nimport java.math.BigInteger;", "import java.math.BigDecimal;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.time.Instant;\nimport java.time.LocalDate;\nimport java.time.LocalDateTime;\nimport java.time.LocalTime;\nimport java.time.ZoneOffset;\nimport java.util.AbstractList;\nimport java.util.AbstractMap;", "import java.util.AbstractList;\nimport java.util.AbstractMap;\nimport java.util.AbstractSet;\nimport java.util.Arrays;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.UUID;\nimport java.util.concurrent.TimeUnit;", "import java.util.UUID;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * This class provides functionality to wrap Avro IndexedRecord objects\n * into a Map representation for easier data manipulation.\n */\npublic class AvroWrapper {\n\n    public static final Map<String, LogicalTypeConverter> DEFAULT_LOGICAL_TYPE_CONVERTERS;\n\n    private final Map<String, LogicalTypeConverter> logicalTypeConverters;\n\n    public AvroWrapper() {\n        this(DEFAULT_LOGICAL_TYPE_CONVERTERS);\n    }\n\n    public AvroWrapper(Map<String, LogicalTypeConverter> logicalTypeConverters) {\n        this.logicalTypeConverters = logicalTypeConverters;\n    }\n\n    /**\n     * Wraps the given IndexedRecord into a Map.\n     *\n     * @param record the IndexedRecord to be wrapped\n     * @return a Map representing the IndexedRecord\n     */\n    public Map<String, Object> wrap(IndexedRecord record) {\n        return new Facade(record);\n    }\n\n    /**\n     * This method coerces the value into the correct Java type based on the Avro schema.\n     * It supports Avro primitives, as well as complex types like records (which it wraps\n     * with Facade), arrays (which it wraps with FacadeList), and maps (which it wraps with FacadeMap).\n     *\n     * @param schema the Avro schema of the value\n     * @param value the value to be coerced\n     * @return the coerced value, or throws IllegalArgumentException if the Avro type is unsupported\n     */\n    private Object coerceType(Schema schema, Object value) {", "    public static final Map<String, LogicalTypeConverter> DEFAULT_LOGICAL_TYPE_CONVERTERS;\n\n    private final Map<String, LogicalTypeConverter> logicalTypeConverters;\n\n    public AvroWrapper() {\n        this(DEFAULT_LOGICAL_TYPE_CONVERTERS);\n    }\n\n    public AvroWrapper(Map<String, LogicalTypeConverter> logicalTypeConverters) {\n        this.logicalTypeConverters = logicalTypeConverters;\n    }\n\n    /**\n     * Wraps the given IndexedRecord into a Map.\n     *\n     * @param record the IndexedRecord to be wrapped\n     * @return a Map representing the IndexedRecord\n     */\n    public Map<String, Object> wrap(IndexedRecord record) {\n        return new Facade(record);\n    }\n\n    /**\n     * This method coerces the value into the correct Java type based on the Avro schema.\n     * It supports Avro primitives, as well as complex types like records (which it wraps\n     * with Facade), arrays (which it wraps with FacadeList), and maps (which it wraps with FacadeMap).\n     *\n     * @param schema the Avro schema of the value\n     * @param value the value to be coerced\n     * @return the coerced value, or throws IllegalArgumentException if the Avro type is unsupported\n     */\n    private Object coerceType(Schema schema, Object value) {", "        if (schema.getLogicalType() != null) {\n            LogicalTypeConverter converter = logicalTypeConverters.get(schema.getLogicalType().getName());\n            if (converter != null) {\n                return converter.convert(value);\n            }\n        }\n\n        switch (schema.getType()) {\n            case RECORD:\n                return new Facade((IndexedRecord) value);\n            case ENUM:\n                return value.toString();\n            case UNION:\n                return coerceType(schema.getTypes().get(0), value);\n            case FIXED:\n                return ByteBuffer.wrap(((GenericFixed) value).bytes());\n            case ARRAY:\n                return new FacadeList(schema.getElementType(), (List<?>) value);\n            case MAP:\n                return new FacadeMap(schema.getValueType(), (Map<String, Object>) value);\n            case BOOLEAN:\n            case INT:\n            case LONG:\n            case FLOAT:\n            case DOUBLE:\n            case STRING:\n                return value;\n            case BYTES:", "                if (value instanceof ByteBuffer) {\n                    return value;\n                } else if (value instanceof byte[]) {\n                    return ByteBuffer.wrap((byte[]) value);\n                } else {\n                    throw new IllegalArgumentException(\"Unsupported type for BYTES: \" + value.getClass());\n                }\n            case NULL:\n                return null;\n            default:\n                throw new IllegalArgumentException(\"Unsupported type: \" + schema.getType());\n        }\n    }\n\n    /**\n     * Facade is a private class that provides a Map view of a given IndexedRecord.\n     * This facilitates easier manipulation of the IndexedRecord's data.\n     * The map's keys are the field names in the IndexedRecord, and the values are the field values,\n     * which are coerced to appropriate Java types using the coerceType method.\n     */\n    private class Facade extends AbstractMap<String, Object> {\n\n        private final IndexedRecord record;\n\n        Facade(IndexedRecord record) {\n            this.record = record;\n        }\n\n        @Override\n        public Set<Entry<String, Object>> entrySet() {\n            return new AbstractSet<>() {\n\n                @Override\n                public Iterator<Entry<String, Object>> iterator() {\n                    return new Iterator<>() {\n                        private final Iterator<Schema.Field> iterator = record.getSchema().getFields().iterator();\n\n                        @Override", "                        public boolean hasNext() {\n                            return iterator.hasNext();\n                        }\n\n                        @Override\n                        public Entry<String, Object> next() {\n                            Schema.Field field = iterator.next();\n                            return new SimpleImmutableEntry<>(field.name(), coerceType(field.schema(),\n                                    record.get(field.pos())));\n                        }\n                    };\n                }\n\n                @Override", "                public int size() {\n                    return record.getSchema().getFields().size();\n                }\n            };\n        }\n    }\n\n    /**\n     * FacadeList is a private class that provides a List view of a given Avro array.\n     * This facilitates easier manipulation of the array's data.\n     * The list's elements are the array items, which are coerced to appropriate Java types\n     * using the coerceType method.\n     */\n    private class FacadeList extends AbstractList<Object> {\n\n        private final Schema elementSchema;\n        private final List<?> list;\n\n        /**\n         * Creates a new FacadeList object that provides a List view of the given Avro array.\n         * The List's elements will be the array items, coerced to appropriate Java types\n         * using the coerceType method.\n         *\n         * @param elementSchema the Avro schema of the elements in the array\n         * @param list the actual list of elements, which will be coerced to appropriate Java types\n         */\n        FacadeList(Schema elementSchema, List<?> list) {\n            this.elementSchema = elementSchema;\n            this.list = list;\n        }\n\n        @Override", "        public Object get(int index) {\n            return coerceType(elementSchema, list.get(index));\n        }\n\n        @Override\n        public int size() {\n            return list.size();\n        }\n    }\n\n    /**\n     * FacadeMap is a private class that provides a Map view of a given Avro map.\n     * This facilitates easier manipulation of the map's data.\n     * The map's keys are the Avro map's keys, and the values are the map values,\n     * which are coerced to appropriate Java types using the coerceType method.\n     */\n    private class FacadeMap extends AbstractMap<String, Object> {\n\n        private final Schema valueSchema;\n        private final Map<String, Object> map;\n\n        /**\n         * Creates a new FacadeMap object that provides a Map view of the given Avro map.\n         * The Map's values will be the map values, coerced to appropriate Java types\n         * using the coerceType method.\n         *\n         * @param valueSchema the Avro schema of the values in the map\n         * @param map the actual map of keys to values, which will be coerced to appropriate Java types\n         */\n        FacadeMap(Schema valueSchema, Map<String, Object> map) {\n            this.valueSchema = valueSchema;\n            this.map = map;\n        }\n\n        @Override\n        public Set<Entry<String, Object>> entrySet() {\n            return new AbstractSet<>() {\n                @Override\n                public Iterator<Entry<String, Object>> iterator() {\n                    return new Iterator<>() {\n                        private final Iterator<Entry<String, Object>> iterator = map.entrySet().iterator();\n\n                        @Override", "                        public boolean hasNext() {\n                            return iterator.hasNext();\n                        }\n\n                        @Override\n                        public Entry<String, Object> next() {\n                            Entry<String, Object> entry = iterator.next();\n                            return new SimpleImmutableEntry<>(entry.getKey(), coerceType(valueSchema,\n                                    entry.getValue()));\n                        }\n                    };\n                }\n\n                @Override", "                public int size() {\n                    return map.size();\n                }\n            };\n        }\n    }\n\n    public interface LogicalTypeConverter {\n        Object convert(Object value);\n    }\n\n    static {\n        DEFAULT_LOGICAL_TYPE_CONVERTERS = Map.of(\n                \"decimal\", value -> {\n                    GenericData.Fixed fixed = (GenericData.Fixed) value;\n                    byte[] bytes = fixed.bytes();\n                    int scale = ((LogicalTypes.Decimal) fixed.getSchema().getLogicalType()).getScale();\n                    byte[] valueBytes = Arrays.copyOfRange(bytes, 0, bytes.length);\n                    return new BigDecimal(new BigInteger(valueBytes), scale);\n                },\n                \"uuid\", value -> UUID.fromString((String) value),\n                \"date\", value -> LocalDate.ofEpochDay((int) value),\n                \"time-millis\", value -> LocalTime.ofNanoOfDay(TimeUnit.MILLISECONDS.toNanos((int) value)),\n                \"time-micros\", value -> LocalTime.ofNanoOfDay(TimeUnit.MICROSECONDS.toNanos((long) value)),\n                \"timestamp-millis\", value -> Instant.ofEpochMilli((long) value),\n                \"timestamp-micros\", value -> Instant.ofEpochSecond(0, (long) value * 1000),\n                \"local-timestamp-millis\", value -> {\n                    long longValue = (long) value;\n                    long seconds = longValue / 1000;\n                    int nanos = (int) (longValue % 1000) * 1000000;\n                    return LocalDateTime.ofEpochSecond(seconds, nanos, ZoneOffset.UTC);\n                },\n                \"local-timestamp-micros\", value -> {\n                    long longValue = (long) value;\n                    long seconds = longValue / 1000000;\n                    int nanos = (int) (longValue % 1000000) * 1000;\n                    return LocalDateTime.ofEpochSecond(seconds, nanos, ZoneOffset.UTC);\n                }\n        );\n    }\n\n}\n"]}
